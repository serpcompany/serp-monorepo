[
  {
    "owner": "tensorflow",
    "repo": "docs",
    "content": "TITLE: Checking GPU Availability in TensorFlow\nDESCRIPTION: Code to detect if TensorFlow is configured to use GPU acceleration for operations, providing a clear message to the user.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  print(\"TensorFlow **IS** using the GPU\")\nelse:\n  print(\"TensorFlow **IS NOT** using the GPU\")\n```\n\n----------------------------------------\n\nTITLE: Defining Utility Functions for Image Loading and Model Selection\nDESCRIPTION: This snippet defines utility functions for loading images into numpy arrays and provides a dictionary mapping model names to their TensorFlow Hub handles. It also includes a list of sample images and keypoint definitions for human pose estimation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef load_image_into_numpy_array(path):\n  \"\"\"Load an image from file into a numpy array.\n\n  Puts image into numpy array to feed into tensorflow graph.\n  Note that by convention we put it into a numpy array with shape\n  (height, width, channels), where channels=3 for RGB.\n\n  Args:\n    path: the file path to the image\n\n  Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n  \"\"\"\n  image = None\n  if(path.startswith('http')):\n    response = urlopen(path)\n    image_data = response.read()\n    image_data = BytesIO(image_data)\n    image = Image.open(image_data)\n  else:\n    image_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(BytesIO(image_data))\n\n  (im_width, im_height) = image.size\n  return np.array(image.getdata()).reshape(\n      (1, im_height, im_width, 3)).astype(np.uint8)\n\n\nALL_MODELS = {\n'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n}\n\nIMAGES_FOR_TEST = {\n  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',\n  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',\n}\n\nCOCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n (0, 2),\n (1, 3),\n (2, 4),\n (0, 5),\n (0, 6),\n (5, 7),\n (7, 9),\n (6, 8),\n (8, 10),\n (5, 6),\n (5, 11),\n (6, 12),\n (11, 12),\n (11, 13),\n (13, 15),\n (12, 14),\n (14, 16)]\n```\n\n----------------------------------------\n\nTITLE: Building a Transfer Learning Model with TensorFlow Hub\nDESCRIPTION: Constructs a TensorFlow graph that uses a pre-trained MobileNetV2 model from TensorFlow Hub for feature extraction and adds a linear classifier on top for flower classification. Includes image preprocessing, feature extraction, and model definition.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nLEARNING_RATE = 0.01\n\ntf.reset_default_graph()\n\n# Load a pre-trained TF-Hub module for extracting features from images. We've\n# chosen this particular module for speed, but many other choices are available.\nimage_module = hub.Module('https://tfhub.dev/google/imagenet/mobilenet_v2_035_128/feature_vector/2')\n\n# Preprocessing images into tensors with size expected by the image module.\nencoded_images = tf.placeholder(tf.string, shape=[None])\nimage_size = hub.get_expected_image_size(image_module)\n\n\ndef decode_and_resize_image(encoded):\n  decoded = tf.image.decode_jpeg(encoded, channels=3)\n  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n  return tf.image.resize_images(decoded, image_size)\n\n\nbatch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n\n# The image module can be applied as a function to extract feature vectors for a\n# batch of images.\nfeatures = image_module(batch_images)\n\n\ndef create_model(features):\n  \"\"\"Build a model for classification from extracted features.\"\"\"\n  # Currently, the model is just a single linear layer. You can try to add\n  # another layer, but be careful... two linear layers (when activation=None)\n  # are equivalent to a single linear layer. You can create a nonlinear layer\n  # like this:\n  # layer = tf.layers.dense(inputs=..., units=..., activation=tf.nn.relu)\n  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n  return layer\n\n\n# For each class (kind of flower), the model outputs some real number as a score\n# how much the input resembles this class. This vector of numbers is often\n# called the \"logits\".\nlogits = create_model(features)\nlabels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n\n# Mathematically, a good way to measure how much the predicted probabilities\n# diverge from the truth is the \"cross-entropy\" between the two probability\n# distributions. For numerical stability, this is best done directly from the\n# logits, not the probabilities extracted from them.\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\ncross_entropy_mean = tf.reduce_mean(cross_entropy)\n\n# Let's add an optimizer so we can train the network.\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\ntrain_op = optimizer.minimize(loss=cross_entropy_mean)\n\n# The \"softmax\" function transforms the logits vector into a vector of\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Windows into Inputs and Labels in Python\nDESCRIPTION: This method splits a window of time series data into input features and labels. It handles both single and multi-output scenarios and preserves the shape information for TensorFlow datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef split_window(self, features):\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\nWindowGenerator.split_window = split_window\n```\n\n----------------------------------------\n\nTITLE: Loading a Pre-trained Model with TensorFlow Hub in Python\nDESCRIPTION: Demonstrates how to use the hub.KerasLayer API to load a pre-trained text embedding model from TFHub.dev and generate embeddings for text inputs. The example shows the basic pattern of importing the library, loading a model by URL, and applying it to input data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/lib_overview.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_hub as hub\n\nembed = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\nembeddings = embed([\"A long sentence.\", \"single-word\", \"http://example.com\"])\nprint(embeddings.shape, embeddings.dtype)\n```\n\n----------------------------------------\n\nTITLE: Implementing Hessian Calculation in TensorFlow\nDESCRIPTION: This snippet shows how to compute the Hessian matrix using nested GradientTapes in TensorFlow. It calculates the Hessian of the mean squared output of a two-layer neural network with respect to the first layer's kernel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.normal([7, 5])\nlayer1 = tf.keras.layers.Dense(8, activation=tf.nn.relu)\nlayer2 = tf.keras.layers.Dense(6, activation=tf.nn.relu)\n\nwith tf.GradientTape() as t2:\n  with tf.GradientTape() as t1:\n    x = layer1(x)\n    x = layer2(x)\n    loss = tf.reduce_mean(x**2)\n\n  g = t1.gradient(loss, layer1.kernel)\n\nh = t2.jacobian(g, layer1.kernel)\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Model for Text Classification in TensorFlow\nDESCRIPTION: This snippet constructs a full sequential model for text classification. It includes the TensorFlow Hub embedding layer and additional dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Dense Layer\nDESCRIPTION: Demonstrates how to create a custom layer by extending tf.keras.Layer and implementing __init__, build, and call methods. This example creates a simple dense (fully-connected) layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass MyDenseLayer(tf.keras.layers.Layer):\n  def __init__(self, num_outputs):\n    super(MyDenseLayer, self).__init__()\n    self.num_outputs = num_outputs\n\n  def build(self, input_shape):\n    self.kernel = self.add_weight(\"kernel\",\n                                  shape=[int(input_shape[-1]),\n                                         self.num_outputs])\n\n  def call(self, inputs):\n    return tf.matmul(inputs, self.kernel)\n\nlayer = MyDenseLayer(10)\n```\n\n----------------------------------------\n\nTITLE: Explicit Device Placement\nDESCRIPTION: Matrix multiplication benchmark comparing CPU and GPU execution times\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\ndef time_matmul(x):\n  start = time.time()\n  for loop in range(10):\n    tf.linalg.matmul(x, x)\n\n  result = time.time()-start\n\n  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n\n# Force execution on CPU\nprint(\"On CPU:\")\nwith tf.device(\"CPU:0\"):\n  x = tf.random.uniform([1000, 1000])\n  assert x.device.endswith(\"CPU:0\")\n  time_matmul(x)\n\n# Force execution on GPU #0 if available\nif tf.config.list_physical_devices(\"GPU\"):\n  print(\"On GPU:\")\n  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n    x = tf.random.uniform([1000, 1000])\n    assert x.device.endswith(\"GPU:0\")\n    time_matmul(x)\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed Training Steps in TensorFlow\nDESCRIPTION: Defines distributed training and test steps using tf.function and strategy.run. These functions are used in the training loop to perform distributed computations across multiple devices or machines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n@tf.function\ndef distributed_train_step(dataset_inputs):\n  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n                         axis=None)\n\n@tf.function\ndef distributed_test_step(dataset_inputs):\n  return strategy.run(test_step, args=(dataset_inputs,))\n```\n\n----------------------------------------\n\nTITLE: Compiling Keras Model with Custom Parameters in Python\nDESCRIPTION: This code snippet shows how to compile a Keras model with custom training parameters. It sets the optimizer, loss function, and other configuration options like eager execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nkeras_model = MyModelKeras()\n\n# compile sets the training parameters\nkeras_model.compile(\n    # By default, fit() uses tf.function().  You can\n    # turn that off for debugging, but it is on now.\n    run_eagerly=False,\n\n    # Using a built-in optimizer, configuring as an object\n    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n\n    # Keras comes with built-in MSE error\n    # However, you could use the loss function\n    # defined above\n    loss=tf.keras.losses.mean_squared_error,\n)\n```\n\n----------------------------------------\n\nTITLE: Custom Training Loop for Multi-Worker Training\nDESCRIPTION: This snippet implements a custom training loop for multi-worker training. It iterates through epochs and steps, performs training steps, calculates metrics, saves checkpoints, and manages checkpoint cleanup for non-chief workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 3\nnum_steps_per_epoch = 70\n\nwhile epoch.numpy() < num_epochs:\n  iterator = iter(multi_worker_dataset)\n  total_loss = 0.0\n  num_batches = 0\n\n  while step_in_epoch.numpy() < num_steps_per_epoch:\n    total_loss += train_step(iterator)\n    num_batches += 1\n    step_in_epoch.assign_add(1)\n\n  train_loss = total_loss / num_batches\n  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n                %(epoch.numpy(), train_accuracy.result(), train_loss))\n\n  train_accuracy.reset_states()\n\n  # Once the `CheckpointManager` is set up, you're now ready to save, and remove\n  # the checkpoints non-chief workers saved.\n  checkpoint_manager.save()\n  if not _is_chief(task_type, task_id, cluster_spec):\n    tf.io.gfile.rmtree(write_checkpoint_dir)\n\n  epoch.assign_add(1)\n  step_in_epoch.assign(0)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using a Custom TensorFlow Module\nDESCRIPTION: Creates an instance of a custom TensorFlow module called MySequentialModule and demonstrates its usage with different input shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmy_model = MySequentialModule(name=\"the_model\")\n\nprint(my_model([[2.0, 2.0, 2.0]]))\nprint(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))\n```\n\n----------------------------------------\n\nTITLE: Implementing a Flexible Keras Layer with Build Step\nDESCRIPTION: Creates a flexible dense layer that uses the build step to create variables based on input shape, allowing for dynamic input sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass FlexibleDense(tf.keras.layers.Layer):\n  def __init__(self, out_features, **kwargs):\n    super().__init__(**kwargs)\n    self.out_features = out_features\n\n  def build(self, input_shape):\n    self.w = tf.Variable(\n      tf.random.normal([input_shape[-1], self.out_features]), name='w')\n    self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n\n  def call(self, inputs):\n    return tf.matmul(inputs, self.w) + self.b\n\nflexible_dense = FlexibleDense(out_features=3)\nprint(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0], [3.0, 3.0, 3.0]])))\n```\n\n----------------------------------------\n\nTITLE: Handling TensorFlow Variable Creation in Functions\nDESCRIPTION: This example demonstrates the correct way to create tf.Variables within tf.functions. It shows how to use a conditional creation pattern to ensure that Variables are only created once and reused across function calls.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f(x):\n  v = tf.Variable(1.0)\n  return v\n\nwith assert_raises(ValueError):\n  f(1.0)\n\nclass Count(tf.Module):\n  def __init__(self):\n    self.count = None\n\n  @tf.function\n  def __call__(self):\n    if self.count is None:\n      self.count = tf.Variable(0)\n    return self.count.assign_add(1)\n\nc = Count()\nprint(c())\nprint(c())\n```\n\n----------------------------------------\n\nTITLE: Padded Batching for Variable-Length Tensors in TensorFlow\nDESCRIPTION: Demonstrates how to use padded_batch to handle tensors of different shapes by specifying dimensions that may be padded, useful for sequence models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_62\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=(None,))\n\nfor batch in dataset.take(2):\n  print(batch.numpy())\n  print()\n\n```\n\n----------------------------------------\n\nTITLE: Exporting Production-Ready Text Classification Model with Integrated Preprocessing in TensorFlow\nDESCRIPTION: Creating a deployment-ready model by integrating the TextVectorization layer with the trained model. This allows the exported model to process raw text strings directly, simplifying deployment and inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nexport_model = tf.keras.Sequential([\n  vectorize_layer,\n  model,\n  layers.Activation('sigmoid')\n])\n\nexport_model.compile(\n    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n)\n\n# Test it with `raw_test_ds`, which yields raw strings\nmetrics = export_model.evaluate(raw_test_ds, return_dict=True)\nprint(metrics)\n```\n\n----------------------------------------\n\nTITLE: Converting a Keras Model to TensorFlow Lite in Python\nDESCRIPTION: This code snippet shows how to convert a trained Keras model to a TensorFlow Lite model. It uses the TFLiteConverter to convert the model and saves it to a file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)\n```\n\n----------------------------------------\n\nTITLE: Loading Latest Checkpoint Weights in TensorFlow\nDESCRIPTION: Creates a new model instance and loads the weights from the latest checkpoint file. This demonstrates how to continue training or perform inference using the most recent saved model state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Create a new model instance\nmodel = create_model()\n\n# Load the previously saved weights\nmodel.load_weights(latest)\n```\n\n----------------------------------------\n\nTITLE: Creating Per-Worker Datasets with ParameterServerStrategy\nDESCRIPTION: Example showing how to create per-worker datasets when using ParameterServerStrategy with a custom training loop. The ClusterCoordinator API is used to create datasets for each worker, which are then distributed using the strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef per_worker_dataset_fn():\n  return strategy.distribute_datasets_from_function(dataset_fn)\n\nper_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)\nper_worker_iterator = iter(per_worker_dataset)\n```\n\n----------------------------------------\n\nTITLE: Initializing MirroredStrategy for Distributed Training\nDESCRIPTION: Sets up a MirroredStrategy instance that will automatically detect available devices for distributing the training workload.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# If the list of devices is not specified in\n# `tf.distribute.MirroredStrategy` constructor, they will be auto-detected.\nstrategy = tf.distribute.MirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Building a Convolutional Neural Network for Image Classification\nDESCRIPTION: This code defines a sequential Keras model for image classification. The model consists of convolutional layers, max pooling layers, and dense layers. It includes a rescaling layer to normalize input values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nnum_classes = len(class_names)\n\nmodel = Sequential([\n  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Training Loop in TensorFlow\nDESCRIPTION: Defines and executes a custom training loop using gradient tape for parameter updates and loss tracking.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n# Set training parameters\nepochs = 100\nlearning_rate = 0.01\nlosses = []\n\n# Format training loop\nfor epoch in range(epochs):\n  for x_batch, y_batch in dataset:\n    with tf.GradientTape() as tape:\n      batch_loss = mse_loss(quad_model(x_batch), y_batch)\n    # Update parameters with respect to the gradient calculations\n    grads = tape.gradient(batch_loss, quad_model.variables)\n    for g,v in zip(grads, quad_model.variables):\n        v.assign_sub(learning_rate*g)\n  # Keep track of model loss per epoch\n  loss = mse_loss(quad_model(x), y)\n  losses.append(loss)\n  if epoch % 10 == 0:\n    print(f'Mean squared error for step {epoch}: {loss.numpy():0.3f}')\n\n# Plot model results\nprint(\"\\n\")\nplt.plot(range(epochs), losses)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Mean Squared Error (MSE)\")\nplt.title('MSE loss vs training iterations');\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow\nDESCRIPTION: Importing the TensorFlow library after setting up the environment configurations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Implementing Train and Test Steps for Distributed TensorFlow Training\nDESCRIPTION: These functions define the train_step and test_step for distributed training. They handle forward passes, loss computation, gradient calculation, and metric updates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef train_step(inputs):\n  images, labels = inputs\n\n  with tf.GradientTape() as tape:\n    predictions = model(images, training=True)\n    loss = compute_loss(labels, predictions, model.losses)\n\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n  train_accuracy.update_state(labels, predictions)\n  return loss\n\ndef test_step(inputs):\n  images, labels = inputs\n\n  predictions = model(images, training=False)\n  t_loss = loss_object(labels, predictions)\n\n  test_loss.update_state(t_loss)\n  test_accuracy.update_state(labels, predictions)\n```\n\n----------------------------------------\n\nTITLE: Converting Pandas DataFrame to Dictionary of Tensors\nDESCRIPTION: Transforms a pandas DataFrame into a dictionary of NumPy arrays, which is required for feeding data to Keras models that expect dictionary inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntitanic_features_dict = {name: np.array(value) \n                         for name, value in titanic_features.items()}\n```\n\n----------------------------------------\n\nTITLE: Defining Training Step Function\nDESCRIPTION: Implements training step with gradient computation and optimization using tf.function for performance. Includes loss calculation and metric updates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef step_fn(iterator):\n\n  def replica_fn(batch_data, labels):\n    with tf.GradientTape() as tape:\n      pred = model(batch_data, training=True)\n      per_example_loss = tf.keras.losses.BinaryCrossentropy(\n          reduction=tf.keras.losses.Reduction.NONE)(labels, pred)\n      loss = tf.nn.compute_average_loss(per_example_loss)\n      model_losses = model.losses\n      if model_losses:\n        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n    gradients = tape.gradient(loss, model.trainable_variables)\n\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n    accuracy.update_state(labels, actual_pred)\n    return loss\n\n  batch_data, labels = next(iterator)\n  losses = strategy.run(replica_fn, args=(batch_data, labels))\n  return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)\n```\n\n----------------------------------------\n\nTITLE: Building Complete Model with Functional API\nDESCRIPTION: Constructs the full model by combining data augmentation, preprocessing, base model, and classification layers using Keras Functional API. Sets training=False for BatchNormalization layers in the base model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ninputs = tf.keras.Input(shape=(160, 160, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Pre-trained MobileNet Model\nDESCRIPTION: Loads a pre-trained MobileNet model, performs inference on the sample image, and displays top 5 prediction results before saving the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npretrained_model = tf.keras.applications.MobileNet()\nresult_before_save = pretrained_model(x)\n\ndecoded = imagenet_labels[np.argsort(result_before_save)[0,::-1][:5]+1]\n\nprint(\"Result before saving:\\n\", decoded)\n```\n\n----------------------------------------\n\nTITLE: Creating Model and Training Functions for Custom TPU Training Loop\nDESCRIPTION: Sets up the model, optimizer, metrics, and defines a tf.function for a single training step within a TPU strategy scope. It demonstrates how to distribute datasets across TPU devices and implement the gradient calculation and optimization steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Create the model, optimizer and metrics inside the `tf.distribute.Strategy`\n# scope, so that the variables can be mirrored on each device.\nwith strategy.scope():\n  model = create_model()\n  optimizer = tf.keras.optimizers.Adam()\n  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      'training_accuracy', dtype=tf.float32)\n\n# Calculate per replica batch size, and distribute the `tf.data.Dataset`s\n# on each TPU worker.\nper_replica_batch_size = batch_size // strategy.num_replicas_in_sync\n\ntrain_dataset = strategy.distribute_datasets_from_function(\n    lambda _: get_dataset(per_replica_batch_size, is_training=True))\n\n@tf.function\ndef train_step(iterator):\n  \"\"\"The step function for one training step.\"\"\"\n\n  def step_fn(inputs):\n    \"\"\"The computation to run on each TPU device.\"\"\"\n    images, labels = inputs\n    with tf.GradientTape() as tape:\n      logits = model(images, training=True)\n      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n          labels, logits, from_logits=True)\n      loss = tf.nn.compute_average_loss(per_example_loss)\n      model_losses = model.losses\n      if model_losses:\n        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n    training_accuracy.update_state(labels, logits)\n\n  strategy.run(step_fn, args=(next(iterator),))\n```\n\n----------------------------------------\n\nTITLE: Embedding Weighted Categorical Data with Feature Columns in Python\nDESCRIPTION: This snippet shows how to embed weighted categorical data in TensorFlow using feature columns with a combiner to handle multiple entries. Dependencies include `tensorflow` and `tf.feature_column` APIs. Inputs are ids and weights, resulting in combined embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nids = tf.constant([[5, 11, 5, 17, 17]])\nweights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n\ncategorical_col = tf1.feature_column.categorical_column_with_identity(\n    'ids', num_buckets=20)\nweighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n    categorical_col, 'weights')\nembedding_col = tf1.feature_column.embedding_column(\n    weighted_categorical_col, 4, combiner='mean')\ncall_feature_columns(embedding_col, {'ids': ids, 'weights': weights})\n```\n\n----------------------------------------\n\nTITLE: Classifying video with MoViNet and displaying results\nDESCRIPTION: Uses the loaded MoViNet model to classify the sample video, converts logits to probabilities, and displays the top 5 predicted activities with their probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlogits = sig(image = jumpingjack[tf.newaxis, ...])\nlogits = logits['classifier_head'][0]\n\nprobs = tf.nn.softmax(logits, axis=-1)\nfor label, p in get_top_k(probs):\n  print(f'{label:20s}: {p:.3f}')\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Model with Keras API\nDESCRIPTION: Demonstrates saving and loading a model using the high-level Keras API, including restoration with different distribution strategies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nkeras_model_path = '/tmp/keras_save.keras'\nmodel.save(keras_model_path)\n\nrestored_keras_model = tf.keras.models.load_model(keras_model_path)\nrestored_keras_model.fit(train_dataset, epochs=2)\n\nanother_strategy = tf.distribute.OneDeviceStrategy('/cpu:0')\nwith another_strategy.scope():\n  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n  restored_keras_model_ds.fit(train_dataset, epochs=2)\n```\n\n----------------------------------------\n\nTITLE: Creating MultiWorkerMirroredStrategy in TensorFlow\nDESCRIPTION: This code shows how to create a MultiWorkerMirroredStrategy object for distributed training across multiple workers. It includes cleaning up the previous TF_CONFIG environment variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# To clean up the `TF_CONFIG` used for `ParameterServerStrategy`.\ndel os.environ['TF_CONFIG']\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Worker Training Script in TensorFlow\nDESCRIPTION: Complete script for multi-worker training using TensorFlow. It includes setting up the strategy, preparing the dataset, building the model, and fitting the model. The global batch size is adjusted based on the number of workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n%%writefile main.py\n\nimport os\nimport json\n\nimport tensorflow as tf\nimport mnist_setup\n\nper_worker_batch_size = 64\ntf_config = json.loads(os.environ['TF_CONFIG'])\nnum_workers = len(tf_config['cluster']['worker'])\n\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n\nglobal_batch_size = per_worker_batch_size * num_workers\nmulti_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)\n\nwith strategy.scope():\n  # Model building/compiling need to be within `strategy.scope()`.\n  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n\n\nmulti_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n```\n\n----------------------------------------\n\nTITLE: Assigning Values to TensorFlow Variables\nDESCRIPTION: This code demonstrates how to assign new values to existing TensorFlow variables, including the use of assign, assign_add, and assign_sub methods.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable([2.0, 3.0])\n# This will keep the same dtype, float32\na.assign([1, 2]) \n# Not allowed as it resizes the variable: \ntry:\n  a.assign([1.0, 2.0, 3.0])\nexcept Exception as e:\n  print(f\"{type(e).__name__}: {e}\")\n\na = tf.Variable([2.0, 3.0])\n# Create b based on the value of a\nb = tf.Variable(a)\na.assign([5, 6])\n\n# a and b are different\nprint(a.numpy())\nprint(b.numpy())\n\n# There are other versions of assign\nprint(a.assign_add([2,3]).numpy())  # [7. 9.]\nprint(a.assign_sub([7,9]).numpy())  # [0. 0.]\n```\n\n----------------------------------------\n\nTITLE: Loading a TensorFlow Model from HDF5 Format\nDESCRIPTION: Shows how to load a TensorFlow model from an HDF5 (.h5) file and display its architecture summary to verify it was restored correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Recreate the exact same model, including its weights and the optimizer\nnew_model = tf.keras.models.load_model('my_model.h5')\n\n# Show the model architecture\nnew_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Keras Layer\nDESCRIPTION: Defines a custom Keras layer called MyDense, which inherits from tf.keras.layers.Layer and implements a dense layer with ReLU activation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass MyDense(tf.keras.layers.Layer):\n  def __init__(self, in_features, out_features, **kwargs):\n    super().__init__(**kwargs)\n\n    self.w = tf.Variable(\n      tf.random.normal([in_features, out_features]), name='w')\n    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n  def call(self, x):\n    y = tf.matmul(x, self.w) + self.b\n    return tf.nn.relu(y)\n\nsimple_layer = MyDense(name=\"simple\", in_features=3, out_features=3)\nsimple_layer([[2.0, 2.0, 2.0]])\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Hub Model for Image Feature Extraction in Python\nDESCRIPTION: This code snippet allows users to select a pre-trained model from TensorFlow Hub for image feature extraction. It sets up the model handle, input image size, and batch size based on the chosen model. The script includes a comprehensive list of available models and their corresponding TensorFlow Hub URLs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title\n\nmodel_name = \"efficientnetv2-xl-21k\" # @param ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n\nmodel_handle_map = {\n  \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\",\n  \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/2\",\n  \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\",\n  \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\",\n  \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/2\",\n  \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/feature_vector/2\",\n  \"efficientnetv2-xl-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/feature_vector/2\",\n  \"efficientnetv2-b0-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/feature_vector/2\",\n  \"efficientnetv2-b1-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b1/feature_vector/2\",\n  \"efficientnetv2-b2-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/feature_vector/2\",\n  \"efficientnetv2-b3-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b3/feature_vector/2\",\n  \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_vector/2\",\n  \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/2\",\n  \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/feature_vector/2\",\n  \"efficientnetv2-xl-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/feature_vector/2\",\n  \"efficientnetv2-b0-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/feature_vector/2\",\n  \"efficientnetv2-b1-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b1/feature_vector/2\",\n  \"efficientnetv2-b2-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/feature_vector/2\",\n  \"efficientnetv2-b3-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/feature_vector/2\",\n  \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n  \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/2\",\n  \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/feature_vector/2\",\n  \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/feature_vector/2\",\n  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\",\n  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\",\n  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\",\n  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n}\n\nmodel_image_size_map = {\n  \"efficientnetv2-s\": 384,\n  \"efficientnetv2-m\": 480,\n  \"efficientnetv2-l\": 480,\n  \"efficientnetv2-b0\": 224,\n  \"efficientnetv2-b1\": 240,\n  \"efficientnetv2-b2\": 260,\n  \"efficientnetv2-b3\": 300,\n  \"efficientnetv2-s-21k\": 384,\n  \"efficientnetv2-m-21k\": 480,\n  \"efficientnetv2-l-21k\": 480,\n  \"efficientnetv2-xl-21k\": 512,\n  \"efficientnetv2-b0-21k\": 224,\n  \"efficientnetv2-b1-21k\": 240,\n  \"efficientnetv2-b2-21k\": 260,\n  \"efficientnetv2-b3-21k\": 300,\n  \"efficientnetv2-s-21k-ft1k\": 384,\n  \"efficientnetv2-m-21k-ft1k\": 480,\n  \"efficientnetv2-l-21k-ft1k\": 480,\n  \"efficientnetv2-xl-21k-ft1k\": 512,\n  \"efficientnetv2-b0-21k-ft1k\": 224,\n  \"efficientnetv2-b1-21k-ft1k\": 240,\n  \"efficientnetv2-b2-21k-ft1k\": 260,\n  \"efficientnetv2-b3-21k-ft1k\": 300, \n  \"efficientnet_b0\": 224,\n  \"efficientnet_b1\": 240,\n  \"efficientnet_b2\": 260,\n  \"efficientnet_b3\": 300,\n  \"efficientnet_b4\": 380,\n  \"efficientnet_b5\": 456,\n  \"efficientnet_b6\": 528,\n  \"efficientnet_b7\": 600,\n  \"inception_v3\": 299,\n  \"inception_resnet_v2\": 299,\n  \"nasnet_large\": 331,\n  \"pnasnet_large\": 331,\n}\n\nmodel_handle = model_handle_map.get(model_name)\npixels = model_image_size_map.get(model_name, 224)\n\nprint(f\"Selected model: {model_name} : {model_handle}\")\n\nIMAGE_SIZE = (pixels, pixels)\nprint(f\"Input size {IMAGE_SIZE}\")\n\nBATCH_SIZE = 16#@param {type:\"integer\"}\n```\n\n----------------------------------------\n\nTITLE: Training and Saving Subclassed Model\nDESCRIPTION: This snippet shows how to train a subclassed model using tf.keras.Model.fit, which defines the save_spec and allows for successful model saving. It creates a dataset, compiles the model, trains it, and then saves it.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nBATCH_SIZE_PER_REPLICA = 4\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n\ndataset_size = 100\ndataset = tf.data.Dataset.from_tensors(\n    (tf.range(5, dtype=tf.float32), tf.range(5, dtype=tf.float32))\n    ).repeat(dataset_size).batch(BATCH_SIZE)\n\nmy_model.compile(optimizer='adam', loss='mean_squared_error')\nmy_model.fit(dataset, epochs=2)\n\nprint(my_model.save_spec() is None)\nmy_model.save(saved_model_path)\n```\n\n----------------------------------------\n\nTITLE: Enabling Device Placement Logging in TensorFlow\nDESCRIPTION: This code enables logging of device placement for TensorFlow operations and demonstrates matrix multiplication on the default device.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\n\n# Create some tensors\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\n\nprint(c)\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Model with Shuffled Batches and Validation\nDESCRIPTION: Trains a TensorFlow model for 10 epochs using mini-batches of 512 samples. The training data is shuffled with a buffer size of 10000, and validation is performed on a separate validation dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(train_data.shuffle(10000).batch(512),\n                    epochs=10,\n                    validation_data=validation_data.batch(512),\n                    verbose=1)\n```\n\n----------------------------------------\n\nTITLE: Creating ExportModule for TensorFlow Model Preprocessing and Prediction\nDESCRIPTION: Defines an ExportModule class that encapsulates feature extraction, normalization, prediction, and unnormalization steps for a TensorFlow model. It uses tf.function for optimized execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass ExportModule(tf.Module):\n  def __init__(self, model, extract_features, norm_x, norm_y):\n    # Initialize pre and postprocessing functions\n    self.model = model\n    self.extract_features = extract_features\n    self.norm_x = norm_x\n    self.norm_y = norm_y\n\n  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.float32)]) \n  def __call__(self, x):\n    # Run the ExportModule for new data points\n    x = self.extract_features(x)\n    x = self.norm_x.norm(x)\n    y = self.model(x)\n    y = self.norm_y.unnorm(y)\n    return y \n\nlin_reg_export = ExportModule(model=lin_reg,\n                              extract_features=onehot_origin,\n                              norm_x=norm_x,\n                              norm_y=norm_y)\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients for Intermediate Results in TensorFlow\nDESCRIPTION: This example shows how to compute gradients with respect to intermediate values in a computation graph using tf.GradientTape. It also demonstrates the use of persistent tapes for multiple gradient calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(3.0)\n\nwith tf.GradientTape() as tape:\n  tape.watch(x)\n  y = x * x\n  z = y * y\n\nprint(tape.gradient(z, y).numpy())\n\nx = tf.constant([1, 3.0])\nwith tf.GradientTape(persistent=True) as tape:\n  tape.watch(x)\n  y = x * x\n  z = y * y\n\nprint(tape.gradient(z, x).numpy())  # [4.0, 108.0] (4 * x**3 at x = [1.0, 3.0])\nprint(tape.gradient(y, x).numpy())  # [2.0, 6.0] (2 * x at x = [1.0, 3.0])\n\ndel tape   # Drop the reference to the tape\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Accuracy in TensorFlow with Matplotlib\nDESCRIPTION: Creating a visualization of training and validation accuracy metrics over training epochs. This plot helps in identifying when the model starts overfitting by showing divergence between training and validation accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Performance for Image Classification\nDESCRIPTION: This snippet configures the dataset for optimal performance by using caching and prefetching. These techniques help to reduce I/O bottlenecks during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Enabling NumPy Behavior in TensorFlow\nDESCRIPTION: Shows how to enable NumPy-compatible behavior in TensorFlow, which changes type promotion and type inference to follow NumPy standards throughout TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior()\n```\n\n----------------------------------------\n\nTITLE: Setting Up ModelCheckpoint Callback in TensorFlow\nDESCRIPTION: Creates a ModelCheckpoint callback to save model weights during training. The checkpoint is configured to save weights only (not the full model) and includes verbose output during the saving process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_path = \"training_1/cp.weights.h5\" # Since you're only saving weights, you should use the .weights.h5 extension. If you're saving the whole model, you would use the .keras extension instead\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\n# Train the model with the new callback\nmodel.fit(train_images,\n          train_labels,\n          epochs=10,\n          validation_data=(test_images, test_labels),\n          callbacks=[cp_callback])  # Pass callback to training\n\n# This may generate warnings related to saving the state of the optimizer.\n# These warnings (and similar warnings throughout this notebook)\n# are in place to discourage outdated usage, and can be ignored.\n```\n\n----------------------------------------\n\nTITLE: DeepDream Core Implementation Class\nDESCRIPTION: Main DeepDream class implementation using TensorFlow, including gradient calculation and image enhancement logic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass DeepDream(tf.Module):\n  def __init__(self, model):\n    self.model = model\n\n  @tf.function(\n      input_signature=(\n        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n        tf.TensorSpec(shape=[], dtype=tf.int32),\n        tf.TensorSpec(shape=[], dtype=tf.float32),)\n  )\n  def __call__(self, img, steps, step_size):\n      print(\"Tracing\")\n      loss = tf.constant(0.0)\n      for n in tf.range(steps):\n        with tf.GradientTape() as tape:\n          tape.watch(img)\n          loss = calc_loss(img, self.model)\n\n        gradients = tape.gradient(loss, img)\n        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n        img = img + gradients*step_size\n        img = tf.clip_by_value(img, -1, 1)\n\n      return loss, img\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Custom Dataset for Transfer Learning\nDESCRIPTION: This code loads a custom flower dataset, splits it into training and validation sets, and applies preprocessing including image resizing and pixel value normalization. It uses tf.keras.utils.image_dataset_from_directory for efficient data loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndata_file = tf.keras.utils.get_file(\n  'flower_photos.tgz',\n  'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n  cache_dir='.',\n   extract=True)\n\ndata_root = pathlib.Path(data_file).with_suffix('')\n\nbatch_size = 32\nimg_height = 224\nimg_width = 224\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  str(data_root),\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n  str(data_root),\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size\n)\n\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Generating New Music Sequence in Python\nDESCRIPTION: Uses the trained model to generate a sequence of musical notes, starting from an initial seed sequence and producing the specified number of new notes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ntemperature = 2.0\nnum_predictions = 120\n\nsample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n\n# The initial sequence of notes; pitch is normalized similar to training\n# sequences\ninput_notes = (\n    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n\ngenerated_notes = []\nprev_start = 0\nfor _ in range(num_predictions):\n  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n  start = prev_start + step\n  end = start + duration\n  input_note = (pitch, step, duration)\n  generated_notes.append((*input_note, start, end))\n  input_notes = np.delete(input_notes, 0, axis=0)\n  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n  prev_start = start\n\ngenerated_notes = pd.DataFrame(\n    generated_notes, columns=(*key_order, 'start', 'end'))\n```\n\n----------------------------------------\n\nTITLE: Creating MultiWorkerMirroredStrategy for Distributed Training\nDESCRIPTION: Instantiates tf.distribute.experimental.MultiWorkerMirroredStrategy which creates copies of model variables across devices and workers, and uses CollectiveOps for gradient aggregation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential Neural Network for Text Classification in TensorFlow\nDESCRIPTION: Creating a sequential model with embedding, dropout, pooling, and dense layers for text classification. This architecture transforms text vectors into predictions with an emphasis on preventing overfitting through dropout layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  layers.Embedding(max_features, embedding_dim),\n  layers.Dropout(0.2),\n  layers.GlobalAveragePooling1D(),\n  layers.Dropout(0.2),\n  layers.Dense(1, activation='sigmoid')])\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Using tf.init_scope to Fix Python Counter Side Effects\nDESCRIPTION: Demonstrates how to use tf.init_scope to lift operations outside of the function graph, ensuring variable increments happen correctly during tracing time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = tf.Variable(0)\n    self.counter = 0\n\n  @tf.function\n  def __call__(self):\n    if self.counter == 0:\n      # Lifts ops out of function-building graphs\n      with tf.init_scope():\n        self.counter += 1\n        self.v.assign_add(1)\n\n    return self.v\n\nm = Model()\nfor n in range(3):\n  print(m().numpy()) # prints 1, 1, 1\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow Variables for Global Value Updates\nDESCRIPTION: This snippet demonstrates how to use tf.Variables to update global values within tf.functions. It shows that using Variable.assign allows for changes to be reflected in subsequent function calls without retracing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef variable_add():\n  return 1 + foo\n\nfoo = tf.Variable(1)\nprint(\"Variable:\", variable_add())\n\nprint(\"Updating the value of `foo` to 100!\")\nfoo.assign(100)\nprint(\"Variable:\", variable_add())\n```\n\n----------------------------------------\n\nTITLE: Training Linear Regression Model with TensorFlow\nDESCRIPTION: Implements a training loop for a linear regression model using TensorFlow. It iterates through epochs, processes batches of training and test data, updates model parameters, and tracks losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Format training loop\nfor epoch in range(epochs):\n  batch_losses_train, batch_losses_test = [], []\n\n  # Iterate through the training data\n  for x_batch, y_batch in train_dataset:\n    with tf.GradientTape() as tape:\n      y_pred_batch = lin_reg(x_batch)\n      batch_loss = mse_loss(y_pred_batch, y_batch)\n    # Update parameters with respect to the gradient calculations\n    grads = tape.gradient(batch_loss, lin_reg.variables)\n    for g,v in zip(grads, lin_reg.variables):\n      v.assign_sub(learning_rate * g)\n    # Keep track of batch-level training performance \n    batch_losses_train.append(batch_loss)\n  \n  # Iterate through the testing data\n  for x_batch, y_batch in test_dataset:\n    y_pred_batch = lin_reg(x_batch)\n    batch_loss = mse_loss(y_pred_batch, y_batch)\n    # Keep track of batch-level testing performance \n    batch_losses_test.append(batch_loss)\n\n  # Keep track of epoch-level model performance\n  train_loss = tf.reduce_mean(batch_losses_train)\n  test_loss = tf.reduce_mean(batch_losses_test)\n  train_losses.append(train_loss)\n  test_losses.append(test_loss)\n  if epoch % 10 == 0:\n    print(f'Mean squared error for step {epoch}: {train_loss.numpy():0.3f}')\n\n# Output final losses\nprint(f\"\\nFinal train loss: {train_loss:0.3f}\")\nprint(f\"Final test loss: {test_loss:0.3f}\")\n```\n\n----------------------------------------\n\nTITLE: Training Loop with Reward Tracking in TensorFlow\nDESCRIPTION: Implementation of the training loop for the Actor-Critic reinforcement learning model, tracking episode rewards and monitoring convergence criteria. It uses tqdm for progress tracking and statistics for calculating the running average reward.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Keep the last episodes reward\nepisodes_reward: collections.deque = collections.deque(maxlen=min_episodes_criterion)\n\nt = tqdm.trange(max_episodes)\nfor i in t:\n    initial_state, info = env.reset()\n    initial_state = tf.constant(initial_state, dtype=tf.float32)\n    episode_reward = int(train_step(\n        initial_state, model, optimizer, gamma, max_steps_per_episode))\n\n    episodes_reward.append(episode_reward)\n    running_reward = statistics.mean(episodes_reward)\n\n\n    t.set_postfix(\n        episode_reward=episode_reward, running_reward=running_reward)\n\n    # Show the average episode reward every 10 episodes\n    if i % 10 == 0:\n      pass # print(f'Episode {i}: average reward: {avg_reward}')\n\n    if running_reward > reward_threshold and i >= min_episodes_criterion:\n        break\n\nprint(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Layer for Random Image Inversion via Subclassing\nDESCRIPTION: Creates a custom layer by subclassing tf.keras.layers.Layer to perform random image inversion. This approach offers more control over layer behavior than Lambda layers and allows integration into Keras model architectures with proper serialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass RandomInvert(layers.Layer):\n  def __init__(self, factor=0.5, **kwargs):\n    super().__init__(**kwargs)\n    self.factor = factor\n\n  def call(self, x):\n    return random_invert_img(x)\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss for U-Net Model in TensorFlow\nDESCRIPTION: This code creates a plot to visualize the training and validation loss over epochs, helping to assess the model's learning progress and potential overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\n\nplt.figure()\nplt.plot(model_history.epoch, loss, 'r', label='Training loss')\nplt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss Value')\nplt.ylim([0, 1])\nplt.legend()\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Augmented Images in TensorFlow\nDESCRIPTION: This snippet applies the data augmentation layers to a single image multiple times and displays the results to visualize the effects of augmentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfor image, _ in train_dataset.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] / 255)\n    plt.axis('off')\n```\n\n----------------------------------------\n\nTITLE: Custom Training Loop with Metrics Tracking in TensorFlow\nDESCRIPTION: This example shows a complete custom training loop that tracks both loss and accuracy metrics. It demonstrates creating metrics, updating them during training steps, and retrieving their values at the end of each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Create the metrics\nloss_metric = tf.keras.metrics.Mean(name='train_loss')\naccuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\n@tf.function\ndef train_step(inputs, labels):\n  with tf.GradientTape() as tape:\n    predictions = model(inputs, training=True)\n    regularization_loss=tf.math.add_n(model.losses)\n    pred_loss=loss_fn(labels, predictions)\n    total_loss=pred_loss + regularization_loss\n\n  gradients = tape.gradient(total_loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n  # Update the metrics\n  loss_metric.update_state(total_loss)\n  accuracy_metric.update_state(labels, predictions)\n\n\nfor epoch in range(NUM_EPOCHS):\n  # Reset the metrics\n  loss_metric.reset_states()\n  accuracy_metric.reset_states()\n\n  for inputs, labels in train_data:\n    train_step(inputs, labels)\n  # Get the metric results\n  mean_loss=loss_metric.result()\n  mean_accuracy = accuracy_metric.result()\n\n  print('Epoch: ', epoch)\n  print('  loss:     {:.3f}'.format(mean_loss))\n  print('  accuracy: {:.3f}'.format(mean_accuracy))\n```\n\n----------------------------------------\n\nTITLE: Training and Testing SNGP Model in Python\nDESCRIPTION: This function trains an SNGP model on given training data and then tests it on test data. It compiles the model, fits it to the training data, and then computes the posterior mean probability for the test data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndef train_and_test_sngp(train_examples, test_examples):\n  sngp_model = DeepResNetSNGPWithCovReset(**resnet_config)\n\n  sngp_model.compile(**train_config)\n  sngp_model.fit(train_examples, train_labels, verbose=0, **fit_config)\n\n  sngp_logits, sngp_covmat = sngp_model(test_examples, return_covmat=True)\n  sngp_probs = compute_posterior_mean_probability(sngp_logits, sngp_covmat)\n\n  return sngp_probs\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Helper Libraries in Python\nDESCRIPTION: This snippet imports the necessary libraries for the image classification project, including TensorFlow, NumPy, and Matplotlib. It also prints the TensorFlow version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# TensorFlow and tf.keras\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Building a Linear Model in TensorFlow\nDESCRIPTION: Constructs a simple linear model using `tf.layers.Dense` with one unit. The model is applied to the input data, creating a tensor of predicted values for subsequent processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_21\n\nLANGUAGE: Python\nCODE:\n```\nlinear_model = tf.layers.Dense(units=1)\n\ny_pred = linear_model(x)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Object Tracking in TensorFlow Checkpoints\nDESCRIPTION: This code shows how TensorFlow's Checkpoint system tracks variables and objects in lists and dictionaries. It creates variables, assigns them to attributes, saves the checkpoint, and then restores a specific variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nsave = tf.train.Checkpoint()\nsave.listed = [tf.Variable(1.)]\nsave.listed.append(tf.Variable(2.))\nsave.mapped = {'one': save.listed[0]}\nsave.mapped['two'] = save.listed[1]\nsave_path = save.save('./tf_list_example')\n\nrestore = tf.train.Checkpoint()\nv2 = tf.Variable(0.)\nassert 0. == v2.numpy()  # Not restored yet\nrestore.mapped = {'two': v2}\nrestore.restore(save_path)\nassert 2. == v2.numpy()\n```\n\n----------------------------------------\n\nTITLE: Configuring TF_CONFIG for Multi-Worker Training\nDESCRIPTION: Sets up the TF_CONFIG environment variable to specify the cluster configuration for distributed training. This is then removed for local execution in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport json\nimport os\n\ntf_config = {\n    'cluster': {\n        'chief': ['localhost:11111'],\n        'worker': ['localhost:12345', 'localhost:23456', 'localhost:21212'],\n        'ps': ['localhost:12121', 'localhost:13131'],\n    },\n    'task': {'type': 'chief', 'index': 0}\n}\n\nos.environ['TF_CONFIG'] = json.dumps(tf_config)\n\ndel os.environ['TF_CONFIG']\n```\n\n----------------------------------------\n\nTITLE: Creating a probability model with Softmax layer in TensorFlow\nDESCRIPTION: Converts the model's linear outputs (logits) to probability distributions by adding a Softmax layer. This makes the predictions more interpretable as confidence scores for each class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprobability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])\n```\n\n----------------------------------------\n\nTITLE: Executing the Training Loop\nDESCRIPTION: Runs the training loop to optimize the model parameters, displaying the progress of loss reduction and parameter updates at each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncurrent_loss = loss(y, model(x))\n\nprint(f\"Starting:\")\nprint(\"    \", report(model, current_loss))\n\ntraining_loop(model, x, y)\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Loop for JAX Model\nDESCRIPTION: Defines a training function that runs multiple epochs, performs training steps, evaluates the model, and tracks losses and accuracies. It handles the learning rate schedule and prints progress information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef train(model, state, optimizer_state, train_data, epochs, losses, avg_losses, eval_losses, eval_accuracies):\n  p = Progress(STEPS_PER_EPOCH)\n  rng = jax.random.PRNGKey(0)\n  for epoch in range(epochs):\n\n    optimizer_step = optimizer_state[1].count\n\n    for step, (data, labels) in enumerate(train_data):\n      p.step(reset=(step==0))\n      state, optimizer_state, rng, loss = train_step(model, state, optimizer_state, rng, data.numpy(), labels.numpy())\n      losses.append(loss)\n    avg_loss = np.mean(losses[-step:])\n    avg_losses.append(avg_loss)\n\n    other_state, params = state.pop('params')\n    eval_loss, _ = model.loss(params, other_state, rng, all_test_data.numpy(), all_test_labels.numpy(), train=False)\n    eval_losses.append(eval_loss)\n    eval_accuracy = model.accuracy(state, all_test_data.numpy(), all_test_labels.numpy())\n    eval_accuracies.append(eval_accuracy)\n\n    print(\"\\nEpoch\", epoch, \"train loss:\", avg_loss, \"eval loss:\", eval_loss, \"eval accuracy\", eval_accuracy, \"lr:\", jlr_decay(optimizer_step))\n\n  return state, optimizer_state\n```\n\n----------------------------------------\n\nTITLE: Getting the most likely class from a single prediction\nDESCRIPTION: Extracts the most probable class from a single prediction by finding the index with the highest probability value. This identifies which class the model believes the image belongs to with highest confidence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nnp.argmax(predictions_single[0])\n```\n\n----------------------------------------\n\nTITLE: Implementing Optimized Mapping for TensorFlow Dataset Benchmarking\nDESCRIPTION: Creates an optimized TensorFlow data pipeline with separate mapping functions for time-consuming and memory-consuming operations. Uses interleaving, batching, caching, and prefetching for better performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@map_decorator\ndef time_consuming_map(steps, times, values):\n    map_enter = time.perf_counter()\n    time.sleep(0.001 * values.shape[0])  # Time consuming step\n    map_elapsed = time.perf_counter() - map_enter\n\n    return (\n        tf.concat((steps, tf.tile([[[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n    )\n\n\n@map_decorator\ndef memory_consuming_map(steps, times, values):\n    map_enter = time.perf_counter()\n    time.sleep(0.0001 * values.shape[0])  # Memory consuming step\n    map_elapsed = time.perf_counter() - map_enter\n\n    # Use tf.tile to handle batch dimension\n    return (\n        tf.concat((steps, tf.tile([[[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n    )\n\n\noptimized_timeline = timelined_benchmark(\n    tf.data.Dataset.range(2)\n    .interleave(  # Parallelize data reading\n        dataset_generator_fun,\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    .batch(  # Vectorize your mapped function\n        _batch_map_num_items,\n        drop_remainder=True)\n    .map(  # Parallelize map transformation\n        time_consuming_map,\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    .cache()  # Cache data\n    .map(  # Reduce memory usage\n        memory_consuming_map,\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    .prefetch(  # Overlap producer and consumer works\n        tf.data.AUTOTUNE\n    )\n    .unbatch(),\n    5\n)\n```\n\n----------------------------------------\n\nTITLE: Using BackupAndRestore Callback for Fault Tolerance in TensorFlow\nDESCRIPTION: Implementing fault tolerance in multi-worker training using the BackupAndRestore callback. This automatically backs up the model at epoch boundaries and restores training state if a worker is interrupted.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# Multi-worker training with `MultiWorkerMirroredStrategy`\n# and the `BackupAndRestore` callback. The training state \n# is backed up at epoch boundaries by default.\n\ncallbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\nwith strategy.scope():\n  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\nmulti_worker_model.fit(multi_worker_dataset,\n                       epochs=3,\n                       steps_per_epoch=70,\n                       callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Defining Dataset Preparation for Mixed Precision Training\nDESCRIPTION: Prepares training and test datasets from tensor slices with appropriate batch sizes. This example uses a batch size of 8192 which can be efficiently processed when using mixed precision.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\ntrain_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n                 .shuffle(10000).batch(8192))\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(8192)\n```\n\n----------------------------------------\n\nTITLE: Dependencies and Environment Initialization\nDESCRIPTION: Import necessary libraries, create CartPole environment and set random seeds for reproducibility\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport collections\nimport gym\nimport numpy as np\nimport statistics\nimport tensorflow as tf\nimport tqdm\n\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras import layers\nfrom typing import Any, List, Sequence, Tuple\n\n\n# Create the environment\nenv = gym.make(\"CartPole-v1\")\n\n# Set seed for experiment reproducibility\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n# Small epsilon value for stabilizing division operations\neps = np.finfo(np.float32).eps.item()\n```\n\n----------------------------------------\n\nTITLE: Implementing the Call Method for Autoregressive LSTM Prediction\nDESCRIPTION: Defines the call method for the FeedBack model that performs autoregressive multi-step prediction. It initializes with the warmup method, then iteratively feeds predictions back as inputs for subsequent time steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_66\n\nLANGUAGE: python\nCODE:\n```\ndef call(self, inputs, training=None):\n  # Use a TensorArray to capture dynamically unrolled outputs.\n  predictions = []\n  # Initialize the LSTM state.\n  prediction, state = self.warmup(inputs)\n\n  # Insert the first prediction.\n  predictions.append(prediction)\n\n  # Run the rest of the prediction steps.\n  for n in range(1, self.out_steps):\n    # Use the last prediction as input.\n    x = prediction\n    # Execute one lstm step.\n    x, state = self.lstm_cell(x, states=state,\n                              training=training)\n    # Convert the lstm output to a prediction.\n    prediction = self.dense(x)\n    # Add the prediction to the output.\n    predictions.append(prediction)\n\n  # predictions.shape => (time, batch, features)\n  predictions = tf.stack(predictions)\n  # predictions.shape => (batch, time, features)\n  predictions = tf.transpose(predictions, [1, 0, 2])\n  return predictions\n\nFeedBack.call = call\n```\n\n----------------------------------------\n\nTITLE: Plotting Confusion Matrix in Python for TensorFlow Model\nDESCRIPTION: This function creates and plots a confusion matrix using seaborn's heatmap. It also prints out various metrics derived from the confusion matrix, such as true positives, false positives, etc.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef plot_cm(labels, predictions, threshold=0.5):\n  cm = confusion_matrix(labels, predictions > threshold)\n  plt.figure(figsize=(5,5))\n  sns.heatmap(cm, annot=True, fmt=\"d\")\n  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n  plt.ylabel('Actual label')\n  plt.xlabel('Predicted label')\n\n  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n  print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n```\n\n----------------------------------------\n\nTITLE: Initializing TPU for TensorFlow Operations\nDESCRIPTION: Initializes a TPU device by creating a TPU cluster resolver and connecting to it. This is a required step before performing any TPU operations in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\ntf.config.experimental_connect_to_cluster(resolver)\n# This is the TPU initialization code that has to be at the beginning.\ntf.tpu.experimental.initialize_tpu_system(resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\n```\n\n----------------------------------------\n\nTITLE: Configuring Multi-Worker Training with Keras in TensorFlow\nDESCRIPTION: This snippet demonstrates how to set up multi-worker training using Keras in TensorFlow. It includes configuring callbacks for backup and restore functionality, creating a model within a distributed strategy scope, and fitting the model with a multi-worker dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ncallbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup', save_freq=30)]\nwith strategy.scope():\n  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\nmulti_worker_model.fit(multi_worker_dataset,\n                       epochs=3,\n                       steps_per_epoch=70,\n                       callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Working with Multiple Gradient Tapes Simultaneously\nDESCRIPTION: Shows how to use multiple gradient tapes simultaneously, where each tape watches different tensors and calculates gradients independently of each other.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx0 = tf.constant(0.0)\nx1 = tf.constant(0.0)\n\nwith tf.GradientTape() as tape0, tf.GradientTape() as tape1:\n  tape0.watch(x0)\n  tape1.watch(x1)\n\n  y0 = tf.math.sin(x0)\n  y1 = tf.nn.sigmoid(x1)\n\n  y = y0 + y1\n\n  ys = tf.reduce_sum(y)\n```\n\nLANGUAGE: python\nCODE:\n```\ntape0.gradient(ys, x0).numpy()   # cos(x) => 1.0\n```\n\nLANGUAGE: python\nCODE:\n```\ntape1.gradient(ys, x1).numpy()   # sigmoid(x1)*(1-sigmoid(x1)) => 0.25\n```\n\n----------------------------------------\n\nTITLE: Implementing Linear Regression Model with TensorFlow\nDESCRIPTION: This class defines a linear regression model using TensorFlow operations and the @tf.function decorator for improved performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nclass LinearRegression(tf.Module):\n\n  def __init__(self):\n    self.built = False\n\n  @tf.function\n  def __call__(self, x):\n    # Initialize the model parameters on the first call\n    if not self.built:\n      # Randomly generate the weight vector and bias term\n      rand_w = tf.random.uniform(shape=[x.shape[-1], 1])\n      rand_b = tf.random.uniform(shape=[])\n      self.w = tf.Variable(rand_w)\n      self.b = tf.Variable(rand_b)\n      self.built = True\n    y = tf.add(tf.matmul(x, self.w), self.b)\n    return tf.squeeze(y, axis=1)\n\nlin_reg = LinearRegression()\nprediction = lin_reg(x_train_norm[:1])\nprediction_unnorm = norm_y.unnorm(prediction)\nprediction_unnorm.numpy()\n```\n\n----------------------------------------\n\nTITLE: Saving a Complete TensorFlow Model in .keras Format\nDESCRIPTION: Creates, trains, and saves an entire TensorFlow model in the newer .keras format, which is the recommended approach for Keras objects as it provides name-based saving and easier debugging.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Create and train a new model instance.\nmodel = create_model()\nmodel.fit(train_images, train_labels, epochs=5)\n\n# Save the entire model as a `.keras` zip archive.\nmodel.save('my_model.keras')\n```\n\n----------------------------------------\n\nTITLE: Training Fraud Detection Model with TensorFlow and Keras\nDESCRIPTION: This snippet demonstrates how to train the fraud detection model using the defined architecture and callbacks. It loads the initial weights, sets the batch size and number of epochs, and uses early stopping.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = make_model()\nmodel.load_weights(initial_weights)\nbaseline_history = model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[early_stopping()],\n    validation_data=(val_features, val_labels))\n```\n\n----------------------------------------\n\nTITLE: Defining U-Net Model for Image Segmentation\nDESCRIPTION: This code defines the U-Net model architecture using a pretrained MobileNetV2 as the encoder and custom upsampling blocks for the decoder.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nbase_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\nlayer_names = [\n    'block_1_expand_relu',   # 64x64\n    'block_3_expand_relu',   # 32x32\n    'block_6_expand_relu',   # 16x16\n    'block_13_expand_relu',  # 8x8\n    'block_16_project',      # 4x4\n]\nbase_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n\ndown_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n\ndown_stack.trainable = False\n\nup_stack = [\n    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n]\n\ndef unet_model(output_channels:int):\n  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n\n  # Downsampling through the model\n  skips = down_stack(inputs)\n  x = skips[-1]\n  skips = reversed(skips[:-1])\n\n  # Upsampling and establishing the skip connections\n  for up, skip in zip(up_stack, skips):\n    x = up(x)\n    concat = tf.keras.layers.Concatenate()\n    x = concat([x, skip])\n\n  # This is the last layer of the model\n  last = tf.keras.layers.Conv2DTranspose(\n      filters=output_channels, kernel_size=3, strides=2,\n      padding='same')  #64x64 -> 128x128\n\n  x = last(x)\n\n  return tf.keras.Model(inputs=inputs, outputs=x)\n```\n\n----------------------------------------\n\nTITLE: Implementing Linear Model for Time Series Prediction\nDESCRIPTION: Creates a simple linear model using a single Dense layer with no activation function, which applies a learnable linear transformation to the input features to predict the target value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nlinear = tf.keras.Sequential([\n    tf.keras.layers.Dense(units=1)\n])\n```\n\n----------------------------------------\n\nTITLE: Downloading and configuring a feature extractor model from TensorFlow Hub\nDESCRIPTION: Defines URLs for two pre-trained models from TensorFlow Hub (MobileNetV2 and InceptionV3) and selects one to use as a feature extractor for transfer learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\ninception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n\nfeature_extractor_model = mobilenet_v2 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}\n```\n\n----------------------------------------\n\nTITLE: Creating MirroredStrategy for Multi-GPU Training\nDESCRIPTION: Initialize a MirroredStrategy instance for synchronous distributed training on multiple GPUs on a single machine. This strategy uses all available GPUs and NCCL for cross-device communication.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Defining the Training Loop with AutoGraph in TensorFlow\nDESCRIPTION: This code defines the `train` function that performs the in-graph training loop. It initializes the model and optimizer, then iterates through the training and testing datasets. The `fit` and `predict` functions are called within the loop to calculate loss and accuracy.  The losses and accuracies are tracked using `tf.TensorArray` and converted to `tf.Tensor` objects before returning. The `train` function is converted into a TensorFlow graph using `tf.autograph.to_graph` for in-graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef train(train_ds, test_ds, learning_rate, max_steps):\n  m = mlp_model((28 * 28,))\n  opt = tf.train.AdamOptimizer(learning_rate)\n\n  train_losses = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n  test_losses = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n  train_accuracies = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n  test_accuracies = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n\n  # This entire training loop will be run in-graph.\n  i = tf.constant(0)\n  for (train_x, train_y), (test_x, test_y) in tf.data.Dataset.zip((train_ds, test_ds)):\n    step_train_loss, step_train_accuracy = fit(m, train_x, train_y, opt)\n    step_test_loss, step_test_accuracy = predict(m, test_x, test_y)\n    if i % 50 == 0:\n      print('Step', i, 'train loss:', step_train_loss, 'test loss:',\n            step_test_loss, 'train accuracy:', step_train_accuracy,\n            'test accuracy:', step_test_accuracy)\n    train_losses.append(step_train_loss)\n    test_losses.append(step_test_loss)\n    train_accuracies.append(step_train_accuracy)\n    test_accuracies.append(step_test_accuracy)\n\n    i += 1\n    if i >= max_steps:\n      break\n\n  # We've recorded our loss values and accuracies\n  # to a list in a graph with AutoGraph's help.\n  # In order to return the values as a Tensor,\n  # we need to stack them before returning them.\n  return (train_losses.stack(), test_losses.stack(),\n          train_accuracies.stack(), test_accuracies.stack())\n  \ntrain = tf.autograph.to_graph(\n    train,\n    experimental_optional_features=(\n        tf.autograph.experimental.Feature.LISTS,\n        tf.autograph.experimental.Feature.BUILTIN_FUNCTIONS,\n        tf.autograph.experimental.Feature.EQUALITY_OPERATORS,\n        tf.autograph.experimental.Feature.AUTO_CONTROL_DEPS))\n```\n\n----------------------------------------\n\nTITLE: Training Loop with Distributed Dataset in TensorFlow\nDESCRIPTION: This example demonstrates how to use a distributed dataset in a training loop with tf.distribute.MirroredStrategy. It defines a train_step function and iterates over the distributed dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 16\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n\n@tf.function\ndef train_step(inputs):\n  features, labels = inputs\n  return labels - 0.3 * features\n\nfor x in dist_dataset:\n  # train_step trains the model using the dataset elements\n  loss = mirrored_strategy.run(train_step, args=(x,))\n  print(\"Loss is \", loss)\n```\n\n----------------------------------------\n\nTITLE: Plotting Learning Curves for Model Training\nDESCRIPTION: Creates plots to visualize the training and validation accuracy/loss over epochs, which helps analyze model performance and identify potential overfitting or underfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Creating and Saving a Model with Custom Output Names\nDESCRIPTION: Defines a custom tf.Module that returns a dictionary mapping output names to values and saves it with a signature, allowing control over output tensor names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModuleWithOutputName(tf.Module):\n  def __init__(self):\n    super(CustomModuleWithOutputName, self).__init__()\n    self.v = tf.Variable(1.)\n\n  @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n  def __call__(self, x):\n    return {'custom_output_name': x * self.v}\n\nmodule_output = CustomModuleWithOutputName()\ncall_output = module_output.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\nmodule_output_path = os.path.join(tmpdir, 'module_with_output_name')\ntf.saved_model.save(module_output, module_output_path,\n                    signatures={'serving_default': call_output})\n```\n\n----------------------------------------\n\nTITLE: Evaluating and Predicting with a Loaded TensorFlow Model\nDESCRIPTION: Shows how to evaluate accuracy and make predictions with a TensorFlow model that has been loaded from a .keras file, verifying that the model functions correctly after restoration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Evaluate the restored model\nloss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n\nprint(new_model.predict(test_images).shape)\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with tf.function\nDESCRIPTION: Shows how to compute gradients for a function decorated with @tf.function using GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nv = tf.Variable(1.0)\nwith tf.GradientTape() as tape:\n  result = add(v, 1.0)\ntape.gradient(result, v)\n```\n\n----------------------------------------\n\nTITLE: Object Detection Model Loading and Inference\nDESCRIPTION: Functions for loading TensorFlow Hub object detection model and running inference on images. Includes image preprocessing and result handling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/object_detection.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef load_img(path):\n  img = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img, channels=3)\n  return img\n\ndef run_detector(detector, path):\n  img = load_img(path)\n  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n  start_time = time.time()\n  result = detector(converted_img)\n  end_time = time.time()\n  result = {key:value.numpy() for key,value in result.items()}\n  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n  print(\"Inference time: \", end_time-start_time)\n  image_with_boxes = draw_boxes(\n      img.numpy(), result[\"detection_boxes\"],\n      result[\"detection_class_entities\"], result[\"detection_scores\"])\n  display_image(image_with_boxes)\n```\n\n----------------------------------------\n\nTITLE: Testing Feature Extraction with a Batch of Images\nDESCRIPTION: Demonstrates how the base model converts input images into feature representations, showing the shape transformation from input images to feature maps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimage_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)\n```\n\n----------------------------------------\n\nTITLE: Defining DTensor Layouts for Different Sharding Configurations\nDESCRIPTION: These code snippets demonstrate how to create various DTensor Layouts for different tensor sharding configurations across 1D and 2D meshes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlayout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh_1d)\n\nlayout = dtensor.Layout([dtensor.UNSHARDED, 'x'], mesh_1d)\n\nlayout = dtensor.Layout(['y', 'x'], mesh_2d)\n\nlayout = dtensor.Layout([\"x\", dtensor.UNSHARDED], mesh_2d)\n```\n\n----------------------------------------\n\nTITLE: Loading and Using Image Classification SavedModel in Python\nDESCRIPTION: Example showing how to load a TensorFlow Hub image classification model and get class logits from a batch of images. This demonstrates the basic usage pattern for classification models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/images.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nobj = hub.load(\"path/to/model\")  # That's tf.saved_model.load() after download.\nimages = ...  # A batch of images with shape [batch_size, height, width, 3].\nlogits = obj(images)   # A batch with shape [batch_size, num_classes].\n```\n\n----------------------------------------\n\nTITLE: Enabling Mixed Precision Policy in TensorFlow\nDESCRIPTION: Sets the global policy for mixed precision training. 'mixed_float16' is used for NVIDIA GPUs, while 'mixed_bfloat16' is recommended for TPUs and CPUs with AMX instructions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# On TPUs and CPUs, use 'mixed_bfloat16' instead\nmixed_precision.set_global_policy('mixed_float16')\n```\n\n----------------------------------------\n\nTITLE: Visualizing multiple test images with their predictions\nDESCRIPTION: Creates a grid display of multiple test images with their predictions and probability distributions. This allows for a broader view of how the model performs across different examples in the test set.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], test_labels)\nplt.tight_layout()\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Compiling Model\nDESCRIPTION: Configures model training parameters including optimizer, loss function, and metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Creating Image Preprocessing Function for ESRGAN\nDESCRIPTION: Defines a function to preprocess images by loading, handling alpha channels, cropping to compatible dimensions, and converting to the appropriate tensor format required by the ESRGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_image(image_path):\n  \"\"\" Loads image from path and preprocesses to make it model ready\n      Args:\n        image_path: Path to the image file\n  \"\"\"\n  hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n  # If PNG, remove the alpha channel. The model only supports\n  # images with 3 color channels.\n  if hr_image.shape[-1] == 4:\n    hr_image = hr_image[...,:-1]\n  hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n  hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n  hr_image = tf.cast(hr_image, tf.float32)\n  return tf.expand_dims(hr_image, 0)\n```\n\n----------------------------------------\n\nTITLE: Creating Distributed Model and Optimizer for Custom Training\nDESCRIPTION: This snippet shows how to create a Keras model and optimizer within the strategy scope for use in custom training loops.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\nwith mirrored_strategy.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(1, input_shape=(1,),\n                            kernel_regularizer=tf.keras.regularizers.L2(1e-4))])\n  optimizer = tf.keras.optimizers.SGD()\n```\n\n----------------------------------------\n\nTITLE: Loading MoveNet Model from TensorFlow Hub\nDESCRIPTION: Loads different variants of MoveNet models (lightning/thunder) from TF Hub or as TFLite models. Handles model initialization and provides inference function for pose detection. Supports both full models and quantized (int8/float16) TFLite versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = \"movenet_lightning\" #@param [\"movenet_lightning\", \"movenet_thunder\", \"movenet_lightning_f16.tflite\", \"movenet_thunder_f16.tflite\", \"movenet_lightning_int8.tflite\", \"movenet_thunder_int8.tflite\"]\n\nif \"tflite\" in model_name:\n  if \"movenet_lightning_f16\" in model_name:\n    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite\n    input_size = 192\n  elif \"movenet_thunder_f16\" in model_name:\n    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n    input_size = 256\n  elif \"movenet_lightning_int8\" in model_name:\n    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/int8/4?lite-format=tflite\n    input_size = 192\n  elif \"movenet_thunder_int8\" in model_name:\n    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/int8/4?lite-format=tflite\n    input_size = 256\n  else:\n    raise ValueError(\"Unsupported model name: %s\" % model_name)\n\n  # Initialize the TFLite interpreter\n  interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n  interpreter.allocate_tensors()\n\n  def movenet(input_image):\n    input_image = tf.cast(input_image, dtype=tf.uint8)\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    interpreter.set_tensor(input_details[0]['index'], input_image.numpy())\n    interpreter.invoke()\n    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n    return keypoints_with_scores\n\nelse:\n  if \"movenet_lightning\" in model_name:\n    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n    input_size = 192\n  elif \"movenet_thunder\" in model_name:\n    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n    input_size = 256\n  else:\n    raise ValueError(\"Unsupported model name: %s\" % model_name)\n\n  def movenet(input_image):\n    model = module.signatures['serving_default']\n    input_image = tf.cast(input_image, dtype=tf.int32)\n    outputs = model(input_image)\n    keypoints_with_scores = outputs['output_0'].numpy()\n    return keypoints_with_scores\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Interpolation Function for Integrated Gradients\nDESCRIPTION: Defines a function that linearly interpolates between baseline and input images at specified alpha intervals. These interpolated images represent points along the path from baseline to input for gradient calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef interpolate_images(baseline,\n                       image,\n                       alphas):\n  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n  baseline_x = tf.expand_dims(baseline, axis=0)\n  input_x = tf.expand_dims(image, axis=0)\n  delta = input_x - baseline_x\n  images = baseline_x +  alphas_x * delta\n  return images\n```\n\n----------------------------------------\n\nTITLE: Training Loop Implementation\nDESCRIPTION: Implements the main training loop that executes the training steps and handles checkpoint saving.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfor epoch in range(EPOCHS):\n  start = time.time()\n\n  n = 0\n  for image_x, image_y in tf.data.Dataset.zip((train_horses, train_zebras)):\n    train_step(image_x, image_y)\n    if n % 10 == 0:\n      print ('.', end='')\n    n += 1\n\n  clear_output(wait=True)\n  generate_images(generator_g, sample_horse)\n\n  if (epoch + 1) % 5 == 0:\n    ckpt_save_path = ckpt_manager.save()\n    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n\n  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Keras model with model.fit\nDESCRIPTION: Trains the model on the training data for 10 epochs. The model learns to associate images with their corresponding labels by adjusting its weights according to the loss function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(train_images, train_labels, epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Creating TFRecordDataset in TensorFlow\nDESCRIPTION: This snippet creates a TFRecordDataset from the downloaded TFRecord file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])\ndataset\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients for a Keras Layer in TensorFlow\nDESCRIPTION: This example demonstrates how to compute gradients for a Keras layer's trainable variables. It creates a dense layer, performs a forward pass, and calculates gradients of the loss with respect to the layer's trainable variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlayer = tf.keras.layers.Dense(2, activation='relu')\nx = tf.constant([[1., 2., 3.]])\n\nwith tf.GradientTape() as tape:\n  # Forward pass\n  y = layer(x)\n  loss = tf.reduce_mean(y**2)\n\n# Calculate gradients with respect to every trainable variable\ngrad = tape.gradient(loss, layer.trainable_variables)\n\nfor var, g in zip(layer.trainable_variables, grad):\n  print(f'{var.name}, shape: {g.shape}')\n```\n\n----------------------------------------\n\nTITLE: Optimizing Integrated Gradients Computation with tf.function in TensorFlow\nDESCRIPTION: This function is decorated with @tf.function to compile it into a high-performance TensorFlow graph. It computes gradients for a batch of interpolated images, improving efficiency for the Integrated Gradients algorithm.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef one_batch(baseline, image, alpha_batch, target_class_idx):\n    # Generate interpolated inputs between baseline and input.\n    interpolated_path_input_batch = interpolate_images(baseline=baseline,\n                                                       image=image,\n                                                       alphas=alpha_batch)\n\n    # Compute gradients between model outputs and interpolated inputs.\n    gradient_batch = compute_gradients(images=interpolated_path_input_batch,\n                                       target_class_idx=target_class_idx)\n    return gradient_batch\n```\n\n----------------------------------------\n\nTITLE: Configuring Training Dataset Pipeline with Augmentation\nDESCRIPTION: Sets up the complete training dataset pipeline that includes shuffling, augmentation, batching, and prefetching. This optimized pipeline applies the custom augmentation function to each image while maintaining high performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = (\n    train_ds\n    .shuffle(1000)\n    .map(augment, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Metrics for Distributed TensorFlow Training\nDESCRIPTION: This code defines metrics to track test loss and training/test accuracy during distributed training. It uses tf.keras.metrics classes within the strategy scope.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  test_loss = tf.keras.metrics.Mean(name='test_loss')\n\n  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='train_accuracy')\n  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='test_accuracy')\n```\n\n----------------------------------------\n\nTITLE: Custom Training Loop with Gradient Descent in TensorFlow\nDESCRIPTION: This code snippet implements a custom training loop using gradient descent optimization. It defines loss and gradient functions, creates a model and optimizer, and then runs the training loop for 300 iterations, printing the loss every 20 steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# A toy dataset of points around 3 * x + 2\nNUM_EXAMPLES = 2000\ntraining_inputs = tf.random_normal([NUM_EXAMPLES])\nnoise = tf.random_normal([NUM_EXAMPLES])\ntraining_outputs = training_inputs * 3 + 2 + noise\n\n# The loss function to be optimized\ndef loss(model, inputs, targets):\n  error = model(inputs) - targets\n  return tf.reduce_mean(tf.square(error))\n\ndef grad(model, inputs, targets):\n  with tf.GradientTape() as tape:\n    loss_value = loss(model, inputs, targets)\n  return tape.gradient(loss_value, [model.W, model.B])\n\n# Define:\n# 1. A model.\n# 2. Derivatives of a loss function with respect to model parameters.\n# 3. A strategy for updating the variables based on the derivatives.\nmodel = Model()\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n\nprint(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n\n# Training loop\nfor i in range(300):\n  grads = grad(model, training_inputs, training_outputs)\n  optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n                            global_step=tf.train.get_or_create_global_step())\n  if i % 20 == 0:\n    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n\nprint(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\nprint(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))\n```\n\n----------------------------------------\n\nTITLE: Zipping Multiple Datasets Together\nDESCRIPTION: Shows how to combine multiple datasets into a single dataset using the Dataset.zip() method, which pairs elements from each input dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n\ndataset3.element_spec\n```\n\n----------------------------------------\n\nTITLE: Calculating maximum difference between original and reloaded model outputs\nDESCRIPTION: Computes the maximum absolute difference between predictions from the original and reloaded models to verify they are identical or nearly identical.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nabs(reloaded_result_batch - result_batch).max()\n```\n\n----------------------------------------\n\nTITLE: Saving a Keras Model in SavedModel Format\nDESCRIPTION: Saves the pre-trained MobileNet model to disk using the SavedModel format, following the versioning convention used by TensorFlow Serving.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmobilenet_save_path = os.path.join(tmpdir, \"mobilenet/1/\")\ntf.saved_model.save(pretrained_model, mobilenet_save_path)\n```\n\n----------------------------------------\n\nTITLE: Defining an Augmentation Function with Multiple Transformations\nDESCRIPTION: Creates a comprehensive augmentation function that applies padding, random cropping, and random brightness adjustments to images. The function uses stateless random operations with seeds to ensure reproducibility and deterministic behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef augment(image_label, seed):\n  image, label = image_label\n  image, label = resize_and_rescale(image, label)\n  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n  # Make a new seed.\n  new_seed = tf.random.split(seed, num=1)[0, :]\n  # Random crop back to the original size.\n  image = tf.image.stateless_random_crop(\n      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n  # Random brightness.\n  image = tf.image.stateless_random_brightness(\n      image, max_delta=0.5, seed=new_seed)\n  image = tf.clip_by_value(image, 0, 1)\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Decompressing Layers with Compression Penalty in Python\nDESCRIPTION: This function decompresses layers while maintaining a compression penalty. It converts CompressedDense and CompressedConv2D layers to CompressibleDense and CompressibleConv2D respectively, preserving the regularization. This approach is useful for further training with compression penalties.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndef decompress_layer_with_penalty(layer):\n  if isinstance(layer, CompressedDense):\n    return CompressibleDense.copy(layer, regularizer=regularizer)\n  if isinstance(layer, CompressedConv2D):\n    return CompressibleConv2D.copy(layer, regularizer=regularizer)\n  return type(layer).from_config(layer.get_config())\n\ndecompressed_classifier = tf.keras.models.clone_model(\n    compressed_classifier, clone_function=decompress_layer_with_penalty)\n```\n\n----------------------------------------\n\nTITLE: Training Neural Network Model with Validation\nDESCRIPTION: Train the model for 40 epochs using mini-batches of 512 samples. Monitors training and validation performance to track model learning progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=40,\n                    batch_size=512,\n                    validation_data=(x_val, y_val),\n                    verbose=1)\n```\n\n----------------------------------------\n\nTITLE: Saving a TensorFlow Model in SavedModel Format\nDESCRIPTION: Creates and trains a model, then saves it in the SavedModel format, which allows direct use with TFLite/TFServing for inferencing. Creates a directory structure containing the model data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Create and train a new model instance.\nmodel = create_model()\nmodel.fit(train_images, train_labels, epochs=5)\n\n# Save the entire model as a SavedModel.\n!mkdir -p saved_model\ntf.saved_model.save(model, 'saved_model/my_model')\n```\n\n----------------------------------------\n\nTITLE: Creating a Complete Training Loop for Neural Networks\nDESCRIPTION: Function that implements a complete training loop for a neural network, tracking both training and validation metrics across epochs. It iterates through batches of data, applies training and validation steps, and reports performance metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef train_model(mlp, train_data, val_data, loss, acc, optimizer, epochs):\n  # Initialize data structures\n  train_losses, train_accs = [], []\n  val_losses, val_accs = [], []\n\n  # Format training loop and begin training\n  for epoch in range(epochs):\n    batch_losses_train, batch_accs_train = [], []\n    batch_losses_val, batch_accs_val = [], []\n\n    # Iterate over the training data\n    for x_batch, y_batch in train_data:\n      # Compute gradients and update the model's parameters\n      batch_loss, batch_acc = train_step(x_batch, y_batch, loss, acc, mlp, optimizer)\n      # Keep track of batch-level training performance\n      batch_losses_train.append(batch_loss)\n      batch_accs_train.append(batch_acc)\n\n    # Iterate over the validation data\n    for x_batch, y_batch in val_data:\n      batch_loss, batch_acc = val_step(x_batch, y_batch, loss, acc, mlp)\n      batch_losses_val.append(batch_loss)\n      batch_accs_val.append(batch_acc)\n\n    # Keep track of epoch-level model performance\n    train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n    val_loss, val_acc = tf.reduce_mean(batch_losses_val), tf.reduce_mean(batch_accs_val)\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    print(f\"Epoch: {epoch}\")\n    print(f\"Training loss: {train_loss:.3f}, Training accuracy: {train_acc:.3f}\")\n    print(f\"Validation loss: {val_loss:.3f}, Validation accuracy: {val_acc:.3f}\")\n  return train_losses, train_accs, val_losses, val_accs\n```\n\n----------------------------------------\n\nTITLE: Downloading TFRecord Test File\nDESCRIPTION: This snippet downloads a TFRecord test file for the French Street Name Signs (FSNS) dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Video Processing\nDESCRIPTION: Commands to install necessary Python packages: remotezip for accessing ZIP files, tqdm for progress tracking, opencv-python for video processing, and tensorflow_docs for Jupyter notebook visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip install remotezip tqdm opencv-python\n!pip install -q git+https://github.com/tensorflow/docs\n```\n\n----------------------------------------\n\nTITLE: Training U-Net Model with Sample Weights in TensorFlow\nDESCRIPTION: This snippet demonstrates how to train the U-Net model using sample weights to handle class imbalance. It compiles a new model and fits it on the weighted dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nweighted_model = unet_model(OUTPUT_CLASSES)\nweighted_model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'])\n\nweighted_model.fit(\n    train_batches.map(add_sample_weights),\n    epochs=1,\n    steps_per_epoch=10)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions and Visualizing Results with TensorFlow\nDESCRIPTION: This code demonstrates how to use the trained model to make predictions on test images. It visualizes the predictions alongside the actual images, displaying the predicted class names and comparing them with the true labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n# Retrieve a batch of images from the test set\nimage_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', label_batch)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].astype(\"uint8\"))\n  plt.title(class_names[predictions[i]])\n  plt.axis(\"off\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Keras Model\nDESCRIPTION: Defines a custom Keras model called MySequentialModel that inherits from tf.keras.Model and implements a sequential structure of two flexible dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@keras.saving.register_keras_serializable()\nclass MySequentialModel(tf.keras.Model):\n  def __init__(self, name=None, **kwargs):\n    super().__init__(**kwargs)\n\n    self.dense_1 = FlexibleDense(out_features=3)\n    self.dense_2 = FlexibleDense(out_features=2)\n  def call(self, x):\n    x = self.dense_1(x)\n    return self.dense_2(x)\n\nmy_sequential_model = MySequentialModel(name=\"the_model\")\nprint(\"Model results:\", my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))\n```\n\n----------------------------------------\n\nTITLE: Parsing and Resizing Images with TensorFlow\nDESCRIPTION: Function to parse image files and resize them to a fixed shape of 128x128. Converts image to float32 format and extracts labels from the filepath.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_74\n\nLANGUAGE: python\nCODE:\n```\ndef parse_image(filename):\n  parts = tf.strings.split(filename, os.sep)\n  label = parts[-2]\n\n  image = tf.io.read_file(filename)\n  image = tf.io.decode_jpeg(image)\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  image = tf.image.resize(image, [128, 128])\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Visualizing Performance Comparison Between Models\nDESCRIPTION: Creates a bar chart comparing validation and test mean absolute error (MAE) across different model types. The visualization shows the relative performance of various forecasting approaches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_69\n\nLANGUAGE: python\nCODE:\n```\nx = np.arange(len(multi_performance))\nwidth = 0.3\n\nmetric_name = 'mean_absolute_error'\nval_mae = [v[metric_name] for v in multi_val_performance.values()]\ntest_mae = [v[metric_name] for v in multi_performance.values()]\n\nplt.bar(x - 0.17, val_mae, width, label='Validation')\nplt.bar(x + 0.17, test_mae, width, label='Test')\nplt.xticks(ticks=x, labels=multi_performance.keys(),\n           rotation=45)\nplt.ylabel(f'MAE (average over all times and outputs)')\n_ = plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating with TPUStrategy in TensorFlow 2\nDESCRIPTION: Demonstrates how to train and evaluate a model using TPUStrategy with Keras Model.fit in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nmodel.fit(dataset, epochs=5, steps_per_epoch=10)\n\nmodel.evaluate(eval_dataset, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Using Dataset in tf.estimator.Estimator input_fn\nDESCRIPTION: This snippet demonstrates how to use a `Dataset` in the `input_fn` of a `tf.estimator.Estimator`. The framework handles creating an iterator and initializing it. The example also includes parsing `tf.Example` protocol buffers and preprocessing the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef dataset_input_fn():\n  filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\n  dataset = tf.data.TFRecordDataset(filenames)\n\n  # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n  # protocol buffer, and perform any additional per-record preprocessing.\n  def parser(record):\n    keys_to_features = {\n        \"image_data\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n        \"date_time\": tf.FixedLenFeature((), tf.int64, default_value=\"\"),\n        \"label\": tf.FixedLenFeature((), tf.int64,\n                                    default_value=tf.zeros([], dtype=tf.int64)),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n\n    # Perform additional preprocessing on the parsed data.\n    image = tf.image.decode_jpeg(parsed[\"image_data\"])\n    image = tf.reshape(image, [299, 299, 1])\n    label = tf.cast(parsed[\"label\"], tf.int32)\n\n    return {\"image_data\": image, \"date_time\": parsed[\"date_time\"]}, label\n\n  # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n  # tensor for each example.\n  dataset = dataset.map(parser)\n  dataset = dataset.shuffle(buffer_size=10000)\n  dataset = dataset.batch(32)\n  dataset = dataset.repeat(num_epochs)\n\n  # Each element of `dataset` is tuple containing a dictionary of features\n  # (in which each value is a batch of values for that feature), and a batch of\n  # labels.\n  return dataset\n```\n\n----------------------------------------\n\nTITLE: Basic tf.function Usage with Addition Example\nDESCRIPTION: Demonstrates how to define and use a simple function with the @tf.function decorator to add two tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@tf.function  # The decorator converts `add` into a `PolymorphicFunction`.\ndef add(a, b):\n  return a + b\n\nadd(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]\n```\n\n----------------------------------------\n\nTITLE: Executing Distributed Training Loop\nDESCRIPTION: Implements training loop with epoch boundaries and result tracking. Demonstrates scheduling training steps and coordination between workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 4\nsteps_per_epoch = 5\nfor i in range(num_epochs):\n  accuracy.reset_states()\n  for _ in range(steps_per_epoch):\n    coordinator.schedule(step_fn, args=(per_worker_iterator,))\n  coordinator.join()\n  print(\"Finished epoch %d, accuracy is %f.\" % (i, accuracy.result().numpy()))\n```\n\n----------------------------------------\n\nTITLE: Creating Model and Early Stopping Callback in TensorFlow\nDESCRIPTION: This snippet creates the model using the previously defined function and sets up an early stopping callback to prevent overfitting during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model()\n# Create earlystopping callback\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3)\n```\n\n----------------------------------------\n\nTITLE: Training the Transfer Learning Model\nDESCRIPTION: Initiates the training process for the specified number of epochs, using the training dataset and validating on the validation dataset. Returns a history object to track performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data=validation_dataset)\n```\n\n----------------------------------------\n\nTITLE: Testing Single-Worker Model Training\nDESCRIPTION: Training the MNIST model on a single worker to verify the model works correctly before scaling to multiple workers. This establishes a baseline for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport mnist_setup\n\nbatch_size = 64\nsingle_worker_dataset = mnist_setup.mnist_dataset(batch_size)\nsingle_worker_model = mnist_setup.build_and_compile_cnn_model()\nsingle_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)\n```\n\n----------------------------------------\n\nTITLE: Using Multiple GPUs in TensorFlow\nDESCRIPTION: This snippet demonstrates how to run operations across multiple GPUs by creating a loop for device assignment. Each GPU processes its part of the computation, and then results are aggregated on the CPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_gpu.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Creates a graph.\nc = []\nfor d in ['/device:GPU:2', '/device:GPU:3']:\n  with tf.device(d):\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n    c.append(tf.matmul(a, b))\nwith tf.device('/cpu:0'):\n  sum = tf.add_n(c)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint(sess.run(sum))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Session Creation and Usage\nDESCRIPTION: Shows different ways to create and use TensorFlow sessions, including local and remote sessions with configuration options.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n----------------------------------------\n\nTITLE: Compiling and Training Wav2Vec2 Model\nDESCRIPTION: Compiles the Wav2Vec2 model with an optimizer and loss function, then trains it using the prepared datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer, loss=loss_fn)\nhistory = model.fit(train_dataset, validation_data=val_dataset, epochs=3)\nhistory.history\n```\n\n----------------------------------------\n\nTITLE: Setting up Distributed Training Coordination\nDESCRIPTION: Initializes ClusterCoordinator and creates per-worker datasets for distributed training. Sets up coordination between workers for distributed execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ncoordinator = tf.distribute.coordinator.ClusterCoordinator(strategy)\n\n@tf.function\ndef per_worker_dataset_fn():\n  return strategy.distribute_datasets_from_function(dataset_fn)\n\nper_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)\nper_worker_iterator = iter(per_worker_dataset)\n```\n\n----------------------------------------\n\nTITLE: Printing Library Versions for Compatibility Check\nDESCRIPTION: Displays the versions of TensorFlow, TensorFlow Hub, TensorFlow Transform, and Apache Beam being used in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint('TF version: {}'.format(tf.__version__))\nprint('TF-Hub version: {}'.format(hub.__version__))\nprint('TF-Transform version: {}'.format(tft.__version__))\nprint('Apache Beam version: {}'.format(beam.__version__))\n```\n\n----------------------------------------\n\nTITLE: Re-evaluating a TensorFlow Model\nDESCRIPTION: Code to evaluate a TensorFlow model that has been previously restored, printing the accuracy percentage of the model on test data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nloss, acc = model.evaluate(test_images, test_labels, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n```\n\n----------------------------------------\n\nTITLE: Resuming Training from Checkpoint in TensorFlow 2\nDESCRIPTION: Recreating the Keras model and continuing training from the last saved checkpoint using the same BackupAndRestore callback that automatically handles the restoration process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss=loss,\n              metrics=['accuracy'],\n              steps_per_execution=10)\nmodel.fit(x=x_train,\n            y=y_train,\n            epochs=10,\n            steps_per_epoch=100,\n            validation_data=(x_test, y_test),\n            callbacks=[backup_restore_callback])\n```\n\n----------------------------------------\n\nTITLE: Frame Generator Class for Video Processing in Python\nDESCRIPTION: This class creates an iterable object that generates frames and labels from video files. It's designed to feed data into a TensorFlow pipeline for video classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nclass FrameGenerator:\n  def __init__(self, path, n_frames, training = False):\n    \"\"\" Returns a set of frames with their associated label. \n\n      Args:\n        path: Video file paths.\n        n_frames: Number of frames. \n        training: Boolean to determine if training dataset is being created.\n    \"\"\"\n    self.path = path\n    self.n_frames = n_frames\n    self.training = training\n    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n\n  def get_files_and_class_names(self):\n    video_paths = list(self.path.glob('*/*.avi'))\n    classes = [p.parent.name for p in video_paths] \n    return video_paths, classes\n\n  def __call__(self):\n    video_paths, classes = self.get_files_and_class_names()\n\n    pairs = list(zip(video_paths, classes))\n\n    if self.training:\n      random.shuffle(pairs)\n\n    for path, name in pairs:\n      video_frames = frames_from_video_file(path, self.n_frames) \n      label = self.class_ids_for_name[name] # Encode labels\n      yield video_frames, label\n```\n\n----------------------------------------\n\nTITLE: Computing Higher-Order Derivatives with Nested Gradient Tapes\nDESCRIPTION: Demonstrates how to compute higher-order derivatives by nesting gradient tapes, where the outer tape differentiates the result of the inner tape's gradient calculation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(1.0)  # Create a Tensorflow variable initialized to 1.0\n\nwith tf.GradientTape() as t2:\n  with tf.GradientTape() as t1:\n    y = x * x * x\n\n  # Compute the gradient inside the outer `t2` context manager\n  # which means the gradient computation is differentiable as well.\n  dy_dx = t1.gradient(y, x)\nd2y_dx2 = t2.gradient(dy_dx, x)\n\nprint('dy_dx:', dy_dx.numpy())  # 3 * x**2 => 3.0\nprint('d2y_dx2:', d2y_dx2.numpy())  # 6 * x => 6.0\n```\n\n----------------------------------------\n\nTITLE: Visualizing Interpolated Images with Matplotlib\nDESCRIPTION: Creates a visualization of the interpolated images at different alpha values, showing the gradual transition from the black baseline to the full 'Fireboat' image, demonstrating the path used for Integrated Gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfig = plt.figure(figsize=(20, 20))\n\ni = 0\nfor alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n  i += 1\n  plt.subplot(1, len(alphas[0::10]), i)\n  plt.title(f'alpha: {alpha:.1f}')\n  plt.imshow(image)\n  plt.axis('off')\n\nplt.tight_layout();\n```\n\n----------------------------------------\n\nTITLE: Freezing the Convolutional Base for Feature Extraction\nDESCRIPTION: Freezes all layers in the base model to prevent their weights from being updated during training, which is essential for transfer learning's feature extraction phase.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbase_model.trainable = False\n```\n\n----------------------------------------\n\nTITLE: Saving a SavedModel with tf.Module in TensorFlow 2\nDESCRIPTION: This snippet demonstrates how to define a custom model using tf.Module, create a serving function, and save it as a SavedModel in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MyModel(tf.Module):\n  @tf.function\n  def __call__(self, input):\n    return add_two(input)\n\nmodel = MyModel()\n\n@tf.function\ndef serving_default(input):\n  return {'output': model(input)}\n\nsignature_function = serving_default.get_concrete_function(\n    tf.TensorSpec(shape=[], dtype=tf.float32))\ntf.saved_model.save(\n    model, 'tf2-save', signatures={\n        tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_function})\n```\n\n----------------------------------------\n\nTITLE: Download and Extract Flowers Dataset\nDESCRIPTION: Downloads the flowers dataset from TensorFlow's storage and extracts it for processing. The dataset contains multiple categories of flower images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\narchive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\ndata_dir = pathlib.Path(archive).with_suffix('')\n```\n\n----------------------------------------\n\nTITLE: Listing Current Directory Contents in Python\nDESCRIPTION: Lists the contents of the current directory after building the index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n!ls\n```\n\n----------------------------------------\n\nTITLE: Listing Checkpoint Files After Training in TensorFlow\nDESCRIPTION: Lists the checkpoint files in the directory to show the multiple checkpoint files created during training, each with a different epoch number.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nos.listdir(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Untrained Model in TensorFlow\nDESCRIPTION: Creates a new untrained model instance and evaluates its performance on the test dataset to establish a baseline accuracy before loading trained weights.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a basic model instance\nmodel = create_model()\n\n# Evaluate the model\nloss, acc = model.evaluate(test_images, test_labels, verbose=2)\nprint(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))\n```\n\n----------------------------------------\n\nTITLE: Slicing 3D Tensors with tf.slice\nDESCRIPTION: Demonstrates how to use tf.slice with 3D tensors by specifying begin indices and size for each dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nt3 = tf.constant([[[1, 3, 5, 7],\n                   [9, 11, 13, 15]],\n                  [[17, 19, 21, 23],\n                   [25, 27, 29, 31]]\n                  ])\n\nprint(tf.slice(t3,\n               begin=[1, 1, 0],\n               size=[1, 1, 2]))\n```\n\n----------------------------------------\n\nTITLE: Creating Validation and Training Datasets in TensorFlow\nDESCRIPTION: This snippet creates separate validation and training datasets from the packed dataset, using caching to improve performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nvalidate_ds = packed_ds.take(N_VALIDATION).cache()\ntrain_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating LSTM Model\nDESCRIPTION: Compiles, trains, and evaluates the LSTM model using the wide window generator, storing performance metrics for validation and test datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nhistory = compile_and_fit(lstm_model, wide_window)\n\nIPython.display.clear_output()\nval_performance['LSTM'] = lstm_model.evaluate(wide_window.val, return_dict=True)\nperformance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Loading Language Model Components from TensorFlow Hub\nDESCRIPTION: Creates a TensorFlow graph that loads the pre-trained language model, and sets up operations to extract word embeddings, layer activations, and calculate perplexity.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n#@title Load the language model pieces\ng = tf.Graph()\nn_layer = 12\nmodel_dim = 768\n\nwith g.as_default():\n  text = tf.placeholder(dtype=tf.string, shape=(1,))\n\n  # Load the pretrained model from TF-Hub\n  module = hub.Module(hub_module)\n\n  # Get the word embeddings, activations at each layer, negative log likelihood\n  # of the text, and calculate the perplexity.\n  embeddings = module(dict(text=text), signature=\"word_embeddings\", as_dict=True)[\"word_embeddings\"]\n  activations = module(dict(text=text), signature=\"activations\", as_dict=True)[\"activations\"]\n  neg_log_likelihood = module(dict(text=text), signature=\"neg_log_likelihood\", as_dict=True)[\"neg_log_likelihood\"]\n  ppl = tf.exp(tf.reduce_mean(neg_log_likelihood, axis=1))\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Gradient Descent Optimizer\nDESCRIPTION: Defines a custom GradientDescent class that inherits from tf.Module. Includes initialization with a learning rate and a method to apply gradients to variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nclass GradientDescent(tf.Module):\n\n  def __init__(self, learning_rate=1e-3):\n    # Initialize parameters\n    self.learning_rate = learning_rate\n    self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n\n  def apply_gradients(self, grads, vars):\n    # Update variables\n    for grad, var in zip(grads, vars):\n      var.assign_sub(self.learning_rate*grad)\n```\n\n----------------------------------------\n\nTITLE: Finding and Loading the Latest Checkpoint in TensorFlow\nDESCRIPTION: Defines a function to find the latest checkpoint by epoch number and returns its path. Then loads this latest checkpoint to restore the model to its most recent state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef load_latest_checkpoint(checkpoint_dir):\n    latest = max(os.listdir(checkpoint_dir), key=lambda f: int(f.split('-')[1].split('.')[0]))\n    return os.path.join(checkpoint_dir, latest)\n\nlatest = load_latest_checkpoint(checkpoint_dir)\nlatest\n```\n\n----------------------------------------\n\nTITLE: Training and Testing Loop with Distributed Strategy in TensorFlow\nDESCRIPTION: Implements the main training and testing loop using distributed datasets. It iterates over epochs, performs distributed training and testing steps, saves checkpoints, and prints progress information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\nfor epoch in range(EPOCHS):\n  # TRAIN LOOP\n  total_loss = 0.0\n  num_batches = 0\n  for x in train_dist_dataset:\n    total_loss += distributed_train_step(x)\n    num_batches += 1\n  train_loss = total_loss / num_batches\n\n  # TEST LOOP\n  for x in test_dist_dataset:\n    distributed_test_step(x)\n\n  if epoch % 2 == 0:\n    checkpoint.save(checkpoint_prefix)\n\n  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n              \"Test Accuracy: {}\")\n  print(template.format(epoch + 1, train_loss,\n                         train_accuracy.result() * 100, test_loss.result(),\n                         test_accuracy.result() * 100))\n\n  test_loss.reset_states()\n  train_accuracy.reset_states()\n  test_accuracy.reset_states()\n```\n\n----------------------------------------\n\nTITLE: Building a Preprocessing Model\nDESCRIPTION: Creates a Keras model that handles all preprocessing steps by concatenating the preprocessed inputs and defining input-output relationships, then visualizes the model architecture.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npreprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n\ntitanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n\ntf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)\n```\n\n----------------------------------------\n\nTITLE: Working with Random Tensors in TensorFlow Sessions\nDESCRIPTION: Shows how tensor values are consistent within a single session run but can change across different runs. This example uses random uniform values to demonstrate this behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nvec = tf.random_uniform(shape=(3,))\nout1 = vec + 1\nout2 = vec + 2\nprint(sess.run(vec))\nprint(sess.run(vec))\nprint(sess.run((out1, out2)))\n```\n\n----------------------------------------\n\nTITLE: Dataset Preparation with Augmentation\nDESCRIPTION: Function to prepare datasets with resizing, rescaling, and optional augmentation, including performance optimizations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef prepare(ds, shuffle=False, augment=False):\n  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n              num_parallel_calls=AUTOTUNE)\n\n  if shuffle:\n    ds = ds.shuffle(1000)\n\n  ds = ds.batch(batch_size)\n\n  if augment:\n    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n                num_parallel_calls=AUTOTUNE)\n\n  return ds.prefetch(buffer_size=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Initializing MultiWorkerMirroredStrategy in TensorFlow\nDESCRIPTION: Creates an instance of tf.distribute.MultiWorkerMirroredStrategy for distributed training. This strategy must be created before any TensorFlow ops to avoid runtime errors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model Performance on Test Dataset\nDESCRIPTION: This snippet evaluates the fine-tuned model on a test dataset to measure its accuracy on unseen data. It returns the loss and accuracy metrics to show how well the model generalizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nloss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Management Functions for Multi-Worker Training\nDESCRIPTION: These utility functions manage checkpoint saving and restoring in a multi-worker environment. They handle chief worker identification, temporary directory creation, and file path management for distributed checkpointing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom multiprocessing import util\ncheckpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n\ndef _is_chief(task_type, task_id, cluster_spec):\n  return (task_type is None\n          or task_type == 'chief'\n          or (task_type == 'worker'\n              and task_id == 0\n              and \"chief\" not in cluster_spec.as_dict()))\n\ndef _get_temp_dir(dirpath, task_id):\n  base_dirpath = 'workertemp_' + str(task_id)\n  temp_dir = os.path.join(dirpath, base_dirpath)\n  tf.io.gfile.makedirs(temp_dir)\n  return temp_dir\n\ndef write_filepath(filepath, task_type, task_id, cluster_spec):\n  dirpath = os.path.dirname(filepath)\n  base = os.path.basename(filepath)\n  if not _is_chief(task_type, task_id, cluster_spec):\n    dirpath = _get_temp_dir(dirpath, task_id)\n  return os.path.join(dirpath, base)\n```\n\n----------------------------------------\n\nTITLE: Using SavedModel API for Model Persistence\nDESCRIPTION: Shows how to save and load models using the lower-level tf.saved_model API, including distributed inference examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = get_model()  # get a fresh model\nsaved_model_path = '/tmp/tf_save'\ntf.saved_model.save(model, saved_model_path)\n\nDEFAULT_FUNCTION_KEY = 'serving_default'\nloaded = tf.saved_model.load(saved_model_path)\ninference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n```\n\n----------------------------------------\n\nTITLE: Incorrect TF2 Implementation with Cached Learning Rate\nDESCRIPTION: This TensorFlow 2.x code demonstrates the issue where learning rate is only computed once then reused, rather than following the intended schedule because the symbolic tensor is accidentally cached.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nglobal_step = tf.Variable(0)\nlearning_rate = 1.0 / global_step # Wrong! Only computed once!\nopt = tf.keras.optimizers.SGD(learning_rate)\n\ndef train_step(...):\n  ...\n  opt.apply_gradients(...)\n  global_step.assign_add(1)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimization Paths for Momentum Algorithm\nDESCRIPTION: This code visualizes the path of the parameters over a contour plot of the loss function for the momentum optimization algorithm.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nviz_paths(param_map_mtm, x_vals, loss, \"Momentum\")\n```\n\n----------------------------------------\n\nTITLE: Loading MoViNet model from TensorFlow Hub\nDESCRIPTION: Downloads and initializes a pretrained MoViNet A2 base model from TensorFlow Hub for video classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nid = 'a2'\nmode = 'base'\nversion = '3'\nhub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\nmodel = hub.load(hub_url)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Data Pipeline with Prefetch\nDESCRIPTION: Example showing how to create a tf.data pipeline that includes prefetching, demonstrating asynchronous transformation behavior in the profiler.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(10)\ndataset = dataset.map(lambda x: x)\ndataset = dataset.repeat(2)\ndataset = dataset.batch(5)\ndataset = dataset.prefetch(1)\n```\n\n----------------------------------------\n\nTITLE: Training and Testing Step Functions for DTensor Models\nDESCRIPTION: Functions that execute single training and testing steps with DTensor. The training step computes gradients and updates model parameters, while the testing step evaluates model performance. Both functions return loss and accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(model, x_batch, y_batch, loss, metric, optimizer):\n  # Execute a single training step\n  with tf.GradientTape() as tape:\n    y_pred = model(x_batch)\n    batch_loss = loss(y_pred, y_batch)\n  # Compute gradients and update the model's parameters\n  grads = tape.gradient(batch_loss, model.trainable_variables)\n  optimizer.apply_gradients(grads)\n  # Return batch loss and accuracy\n  batch_acc = metric(y_pred, y_batch)\n  return batch_loss, batch_acc\n\n@tf.function\ndef test_step(model, x_batch, y_batch, loss, metric):\n  # Execute a single testing step\n  y_pred = model(x_batch)\n  batch_loss = loss(y_pred, y_batch)\n  batch_acc = metric(y_pred, y_batch)\n  return batch_loss, batch_acc\n```\n\n----------------------------------------\n\nTITLE: Adding Dropout Layers with Keras\nDESCRIPTION: Creates a neural network model with dropout layers using the Keras Sequential API. Dropout layers with a rate of 0.5 are added after each dense layer to prevent overfitting. The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy/binary cross-entropy metrics, and then trained.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndpt_model = keras.models.Sequential([\n    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\ndpt_model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy','binary_crossentropy'])\n\ndpt_model_history = dpt_model.fit(train_data, train_labels,\n                                  epochs=20,\n                                  batch_size=512,\n                                  validation_data=(test_data, test_labels),\n                                  verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Setting Example Layout for DTensor Data Tensors\nDESCRIPTION: Creates layout examples for data tensors that are sharded along the batch dimension across the mesh.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nexample_data_layout = dtensor.Layout(['batch', dtensor.UNSHARDED], mesh)  # or\nexample_data_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic TensorFlow Input Pipeline in Python\nDESCRIPTION: This snippet demonstrates a basic implementation of a TensorFlow input pipeline using the tf.data API. It includes functions for parsing TFExample records, data augmentation, and creating a dataset from TFRecord files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/datasets.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef parse_fn(example):\n  \"Parse TFExample records and perform simple data augmentation.\"\n  example_fmt = {\n    \"image\": tf.FixedLengthFeature((), tf.string, \"\"),\n    \"label\": tf.FixedLengthFeature((), tf.int64, -1)\n  }\n  parsed = tf.parse_single_example(example, example_fmt)\n  image = tf.image.decode_image(parsed[\"image\"])\n  image = _augment_helper(image)  # augments image using slice, reshape, resize_bilinear\n  return image, parsed[\"label\"]\n\ndef input_fn():\n  files = tf.data.Dataset.list_files(\"/path/to/dataset/train-*.tfrecord\")\n  dataset = files.interleave(tf.data.TFRecordDataset)\n  dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size)\n  dataset = dataset.map(map_func=parse_fn)\n  dataset = dataset.batch(batch_size=FLAGS.batch_size)\n  return dataset\n```\n\n----------------------------------------\n\nTITLE: Training Model with Keras fit\nDESCRIPTION: Trains the model using the Keras fit method with the prepared dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = get_model()\ntrain_dataset, eval_dataset = get_data()\nmodel.fit(train_dataset, epochs=2)\n```\n\n----------------------------------------\n\nTITLE: Controlling Variable Watching in tf.GradientTape\nDESCRIPTION: This snippet illustrates how to control which variables are watched by tf.GradientTape. It demonstrates watching specific tensors and disabling automatic watching of variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n  tape.watch(x)\n  y = x**2\n\n# dy = 2x * dx\ndy_dx = tape.gradient(y, x)\nprint(dy_dx.numpy())\n\nx0 = tf.Variable(0.0)\nx1 = tf.Variable(10.0)\n\nwith tf.GradientTape(watch_accessed_variables=False) as tape:\n  tape.watch(x1)\n  y0 = tf.math.sin(x0)\n  y1 = tf.nn.softplus(x1)\n  y = y0 + y1\n  ys = tf.reduce_sum(y)\n\ngrad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n\nprint('dy/dx0:', grad['x0'])\nprint('dy/dx1:', grad['x1'].numpy())\n```\n\n----------------------------------------\n\nTITLE: Using tf.py_function as an Escape Hatch for Python Code\nDESCRIPTION: Shows how to execute Python code on each invocation of a tf.function using tf.py_function, with the caveat that it has limitations for portability and distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n@tf.py_function(Tout=tf.float32)\ndef py_plus(x, y):\n  print('Executing eagerly.')\n  return x + y\n\n@tf.function\ndef tf_wrapper(x, y):\n  print('Tracing.')\n  return py_plus(x, y)\n```\n\n----------------------------------------\n\nTITLE: Implementing Adam Optimizer for DTensor in TensorFlow\nDESCRIPTION: A custom Adam optimizer implementation that's compatible with DTensor. It initializes optimizer parameters and variable slots, and provides a method to apply gradients to update model variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass Adam(tf.Module):\n\n    def __init__(self, model_vars, learning_rate=1e-3, beta_1=0.9, beta_2=0.999, ep=1e-7):\n      # Initialize optimizer parameters and variable slots\n      self.model_vars = model_vars\n      self.beta_1 = beta_1\n      self.beta_2 = beta_2\n      self.learning_rate = learning_rate\n      self.ep = ep\n      self.t = 1.\n      self.v_dvar, self.s_dvar = [], []\n      # Initialize optimizer variable slots\n      for var in model_vars:\n        v = dtensor.DVariable(dtensor.call_with_layout(tf.zeros, var.layout, shape=var.shape))\n        s = dtensor.DVariable(dtensor.call_with_layout(tf.zeros, var.layout, shape=var.shape))\n        self.v_dvar.append(v)\n        self.s_dvar.append(s)\n\n    def apply_gradients(self, grads):\n      # Update the model variables given their gradients\n      for i, (d_var, var) in enumerate(zip(grads, self.model_vars)):\n        self.v_dvar[i].assign(self.beta_1*self.v_dvar[i] + (1-self.beta_1)*d_var)\n        self.s_dvar[i].assign(self.beta_2*self.s_dvar[i] + (1-self.beta_2)*tf.square(d_var))\n        v_dvar_bc = self.v_dvar[i]/(1-(self.beta_1**self.t))\n        s_dvar_bc = self.s_dvar[i]/(1-(self.beta_2**self.t))\n        var.assign_sub(self.learning_rate*(v_dvar_bc/(tf.sqrt(s_dvar_bc) + self.ep)))\n      self.t += 1.\n      return \n```\n\n----------------------------------------\n\nTITLE: Implementing Learning Rate Decay Schedule with InverseTimeDecay in TensorFlow\nDESCRIPTION: Creates a learning rate schedule using InverseTimeDecay that hyperbolically decreases the learning rate over time. This schedule reduces the learning rate to 1/2 of base at 1,000 epochs, 1/3 at 2,000 epochs, and so on.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n  0.001,\n  decay_steps=STEPS_PER_EPOCH*1000,\n  decay_rate=1,\n  staircase=False)\n\ndef get_optimizer():\n  return tf.keras.optimizers.Adam(lr_schedule)\n```\n\n----------------------------------------\n\nTITLE: Plotting Baseline and Dropout Model History\nDESCRIPTION: Compares the training histories of a baseline model and a model with dropout layers using the `plot_history` function. This visualization allows for evaluating the impact of dropout on mitigating overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nplot_history([('baseline', baseline_history),\n              ('dropout', dpt_model_history)])\n```\n\n----------------------------------------\n\nTITLE: Stopping Gradient Flow for Specific Operations with tf.stop_gradient\nDESCRIPTION: Demonstrates using tf.stop_gradient to precisely control gradient flow by preventing gradients from propagating through specific parts of a computation graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\ny = tf.Variable(3.0)\n\nwith tf.GradientTape() as t:\n  y_sq = y**2\n  z = x**2 + tf.stop_gradient(y_sq)\n\ngrad = t.gradient(z, {'x': x, 'y': y})\n\nprint('dz/dx:', grad['x'])  # 2*x => 4\nprint('dz/dy:', grad['y'])\n```\n\n----------------------------------------\n\nTITLE: Restoring from Checkpoint and Continuing Training in TensorFlow\nDESCRIPTION: Restoring a model from the latest checkpoint and continuing distributed training. This demonstrates how to use tf.train.latest_checkpoint to find and restore the most recent checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nlatest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\ncheckpoint.restore(latest_checkpoint)\nmulti_worker_model.fit(multi_worker_dataset, epochs=2, steps_per_epoch=20)\n```\n\n----------------------------------------\n\nTITLE: Loading Universal Encoder Multilingual Q&A Model from TensorFlow Hub\nDESCRIPTION: Loads the Universal Encoder Multilingual Q&A model from TensorFlow Hub, which provides question_encoder and response_encoder signatures for embedding questions and answers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Load model from tensorflow hub\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\", \"https://tfhub.dev/google/universal-sentence-encoder-qa/3\"]\nmodel = hub.load(module_url)\n```\n\n----------------------------------------\n\nTITLE: Normalizing Time Series Data in Python\nDESCRIPTION: This snippet demonstrates how to normalize time series data by subtracting the mean and dividing by the standard deviation of the training set. It applies this normalization to train, validation, and test datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_mean = train_df.mean()\ntrain_std = train_df.std()\n\ntrain_df = (train_df - train_mean) / train_std\nval_df = (val_df - train_mean) / train_std\ntest_df = (test_df - train_mean) / train_std\n```\n\n----------------------------------------\n\nTITLE: Running MoveNet Inference with Cropping Algorithm\nDESCRIPTION: Processes each frame of the input GIF using the MoveNet model, applying the cropping algorithm to focus on the person. It includes visualization of the results and progress tracking.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Load the input image.\nnum_frames, image_height, image_width, _ = image.shape\ncrop_region = init_crop_region(image_height, image_width)\n\noutput_images = []\nbar = display(progress(0, num_frames-1), display_id=True)\nfor frame_idx in range(num_frames):\n  keypoints_with_scores = run_inference(\n      movenet, image[frame_idx, :, :, :], crop_region,\n      crop_size=[input_size, input_size])\n  output_images.append(draw_prediction_on_image(\n      image[frame_idx, :, :, :].numpy().astype(np.int32),\n      keypoints_with_scores, crop_region=None,\n      close_figure=True, output_image_height=300))\n  crop_region = determine_crop_region(\n      keypoints_with_scores, image_height, image_width)\n  bar.update(progress(frame_idx, num_frames-1))\n\n# Prepare gif visualization.\noutput = np.stack(output_images, axis=0)\nto_gif(output, duration=100)\n```\n\n----------------------------------------\n\nTITLE: Complete Deep Dream Implementation with Octaves and Tiling\nDESCRIPTION: Combines octave processing with tiled gradient computation for a complete DeepDream implementation. Handles image preprocessing, multiple octaves, and gradient updates with progress display.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n                                octaves=range(-2,3), octave_scale=1.3):\n  base_shape = tf.shape(img)\n  img = tf.keras.utils.img_to_array(img)\n  img = tf.keras.applications.inception_v3.preprocess_input(img)\n\n  initial_shape = img.shape[:-1]\n  img = tf.image.resize(img, initial_shape)\n  for octave in octaves:\n    # Scale the image based on the octave\n    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n    new_size = tf.cast(new_size, tf.int32)\n    img = tf.image.resize(img, new_size)\n\n    for step in range(steps_per_octave):\n      gradients = get_tiled_gradients(img, new_size)\n      img = img + gradients*step_size\n      img = tf.clip_by_value(img, -1, 1)\n\n      if step % 10 == 0:\n        display.clear_output(wait=True)\n        show(deprocess(img))\n        print (\"Octave {}, Step {}\".format(octave, step))\n    \n  result = deprocess(img)\n  return result\n```\n\n----------------------------------------\n\nTITLE: Implementing CVAE Loss Functions and Training Step\nDESCRIPTION: Defines the loss function based on the Evidence Lower Bound (ELBO) and the training step function for the CVAE. The loss combines reconstruction loss and KL divergence to enable proper learning of the latent space distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.keras.optimizers.Adam(1e-4)\n\n\ndef log_normal_pdf(sample, mean, logvar, raxis=1):\n  log2pi = tf.math.log(2. * np.pi)\n  return tf.reduce_sum(\n      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n      axis=raxis)\n\n\ndef compute_loss(model, x):\n  mean, logvar = model.encode(x)\n  z = model.reparameterize(mean, logvar)\n  x_logit = model.decode(z)\n  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n  logpz = log_normal_pdf(z, 0., 0.)\n  logqz_x = log_normal_pdf(z, mean, logvar)\n  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n\n\n@tf.function\ndef train_step(model, x, optimizer):\n  \"\"\"Executes one training step and returns the loss.\n\n  This function computes the loss and gradients, and uses the latter to\n  update the model's parameters.\n  \"\"\"\n  with tf.GradientTape() as tape:\n    loss = compute_loss(model, x)\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset with Features and Labels\nDESCRIPTION: Demonstrates creating a tf.data.Dataset that pairs feature dictionaries with their corresponding labels for supervised learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ntitanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))\n```\n\n----------------------------------------\n\nTITLE: Using a Dynamic RNN with LSTM Cell in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the custom DynamicRNN class with an LSTM cell. It creates a random input tensor and shows the output shape after processing through the RNN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlstm_cell = tf.keras.layers.LSTMCell(units = 13)\n\nmy_rnn = DynamicRNN(lstm_cell)\noutputs, state = my_rnn(tf.random.normal(shape=[10,20,3]))\nprint(outputs.shape)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing MNIST Images for CVAE Training\nDESCRIPTION: Preprocesses MNIST images by reshaping, normalizing, and binarizing them. The function converts grayscale values to binary (0 or 1) to model each pixel with a Bernoulli distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_images(images):\n  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n  return np.where(images > .5, 1.0, 0.0).astype('float32')\n\ntrain_images = preprocess_images(train_images)\ntest_images = preprocess_images(test_images)\n```\n\n----------------------------------------\n\nTITLE: Preparing MNIST Dataset for Training\nDESCRIPTION: Prepares the MNIST dataset for training by applying scaling, shuffling, and batching operations, then limiting to a specific number of batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ntest_data = mnist_test.map(scale).batch(BATCH_SIZE)\n\nSTEPS_PER_EPOCH = 5\n\ntrain_data = train_data.take(STEPS_PER_EPOCH)\ntest_data = test_data.take(STEPS_PER_EPOCH)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom TensorFlow Module\nDESCRIPTION: Creates a custom tf.Module class that contains a trainable weight variable and a multiply method decorated with tf.function for graph optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nclass MyModule(tf.Module):\n  def __init__(self, value):\n    self.weight = tf.Variable(value)\n\n  @tf.function\n  def multiply(self, x):\n    return x * self.weight\n```\n\n----------------------------------------\n\nTITLE: Building Semantic Vector Indexes\nDESCRIPTION: Creates efficient search indexes for semantic vectors using SimpleNeighbors library, both for individual languages and a combined multilingual index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nnum_index_trees = 40\nlanguage_name_to_index = {}\nembedding_dimensions = len(list(language_to_embeddings.values())[0][0])\nfor language_code, zip_file, news_file, language_name in corpus_metadata:\n  print('\\nAdding {} embeddings to index'.format(language_name))\n  index = SimpleNeighbors(embedding_dimensions, metric='dot')\n\n  for i in trange(len(language_to_sentences[language_code])):\n    index.add_one(language_to_sentences[language_code][i], language_to_embeddings[language_code][i])\n\n  print('Building {} index with {} trees...'.format(language_name, num_index_trees))\n  index.build(n=num_index_trees)\n  language_name_to_index[language_name] = index\n```\n\n----------------------------------------\n\nTITLE: Computing Text Embeddings\nDESCRIPTION: Computes embeddings for all test sentences using the Universal Sentence Encoder model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Compute embeddings.\nar_result = embed_text(arabic_sentences)\nen_result = embed_text(english_sentences)\nes_result = embed_text(spanish_sentences)\nde_result = embed_text(german_sentences)\nfr_result = embed_text(french_sentences)\nit_result = embed_text(italian_sentences)\nja_result = embed_text(japanese_sentences)\nko_result = embed_text(korean_sentences)\nru_result = embed_text(russian_sentences)\nzh_result = embed_text(chinese_sentences)\n\nmultilingual_result = embed_text(multilingual_example)\nmultilingual_in_en_result = embed_text(multilingual_example_in_en)\n```\n\n----------------------------------------\n\nTITLE: Applying Posterior Mean Probability Computation in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the compute_posterior_mean_probability function with the SNGP model's outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nsngp_logits, sngp_covmat = sngp_model(test_examples, return_covmat=True)\nsngp_probs = compute_posterior_mean_probability(sngp_logits, sngp_covmat)\n```\n\n----------------------------------------\n\nTITLE: Distributed Training Epoch Function in TensorFlow\nDESCRIPTION: Defines a tf.function that wraps an entire training epoch. This function iterates over the distributed dataset, performs training steps, and calculates the average loss for the epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\n@tf.function\ndef distributed_train_epoch(dataset):\n  total_loss = 0.0\n  num_batches = 0\n  for x in dataset:\n    per_replica_losses = strategy.run(train_step, args=(x,))\n    total_loss += strategy.reduce(\n      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n    num_batches += 1\n  return total_loss / tf.cast(num_batches, dtype=tf.float32)\n\nfor epoch in range(EPOCHS):\n  train_loss = distributed_train_epoch(train_dist_dataset)\n\n  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n  print(template.format(epoch + 1, train_loss, train_accuracy.result() * 100))\n\n  train_accuracy.reset_states()\n```\n\n----------------------------------------\n\nTITLE: Direct Inline Evaluation with TensorFlow\nDESCRIPTION: Implementation of direct evaluation on small models where the coordinator runs evaluation directly on the distributed model using the evaluation dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\neval_dataset = tf.data.Dataset.from_tensor_slices(\n    feature_and_label_gen(num_examples=16)).map(\n          lambda x: (\n              {\"features\": feature_preprocess_stage(x[\"features\"])},\n              label_preprocess_stage(x[\"label\"])\n          )).batch(8)\n\neval_accuracy = tf.keras.metrics.Accuracy()\n\nfor batch_data, labels in eval_dataset:\n  pred = model(batch_data, training=False)\n  actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n  eval_accuracy.update_state(labels, actual_pred)\n\nprint(\"Evaluation accuracy: %f\" % eval_accuracy.result())\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training and Validation Metrics in TensorFlow\nDESCRIPTION: This code creates a visualization of training and validation accuracy/loss over epochs. It marks the point where fine-tuning began, allowing for comparison between the feature extraction and fine-tuning phases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing Image Dataset for TensorFlow\nDESCRIPTION: This code downloads a dataset of cat and dog images, extracts it, and creates TensorFlow datasets for training and validation using image_dataset_from_directory utility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n                                                            shuffle=True,\n                                                            batch_size=BATCH_SIZE,\n                                                            image_size=IMG_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Creating TPU Distribution Strategy for Parallel Training\nDESCRIPTION: Creates a TPU distribution strategy that enables synchronous distributed training across multiple TPU cores, making efficient use of the TPU hardware.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.TPUStrategy(resolver)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment for SavedModel Example\nDESCRIPTION: Initializes required imports, sets up a temporary directory for saving models, and configures GPU memory growth to prevent memory errors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport tempfile\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\ntmpdir = tempfile.mkdtemp()\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU Memory Growth\nDESCRIPTION: Sets memory growth for available GPU devices to prevent TensorFlow from allocating all available GPU memory at once.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nphysical_devices = tf.config.list_physical_devices('GPU')\nfor device in physical_devices:\n  tf.config.experimental.set_memory_growth(device, True)\n```\n\n----------------------------------------\n\nTITLE: Implementing WindowGenerator Class for Time Series Data in Python\nDESCRIPTION: This class handles the creation of input and label windows for time series data. It manages indexes, offsets, and splitting of features into input-label pairs for various prediction tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass WindowGenerator():\n  def __init__(self, input_width, label_width, shift,\n               train_df=train_df, val_df=val_df, test_df=test_df,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n    self.test_df = test_df\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])\n```\n\n----------------------------------------\n\nTITLE: Implementing Repeat Baseline for Multi-step Prediction\nDESCRIPTION: Creates a simple baseline model that repeats the previous day's values for multi-step prediction, assuming tomorrow will be similar to today.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_57\n\nLANGUAGE: python\nCODE:\n```\nclass RepeatBaseline(tf.keras.Model):\n  def call(self, inputs):\n    return inputs\n```\n\n----------------------------------------\n\nTITLE: Optimizing TPU Training with Multiple Steps Inside tf.function\nDESCRIPTION: Demonstrates how to improve TPU performance by executing multiple training steps within a single tf.function call. This approach reduces overhead by batching multiple steps together, utilizing tf.range which gets converted to tf.while_loop on the TPU worker.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_multiple_steps(iterator, steps):\n  \"\"\"The step function for one training step.\"\"\"\n\n  def step_fn(inputs):\n    \"\"\"The computation to run on each TPU device.\"\"\"\n    images, labels = inputs\n    with tf.GradientTape() as tape:\n      logits = model(images, training=True)\n      per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n          labels, logits, from_logits=True)\n      loss = tf.nn.compute_average_loss(per_example_loss)\n      model_losses = model.losses\n      if model_losses:\n        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n    training_loss.update_state(loss * strategy.num_replicas_in_sync)\n    training_accuracy.update_state(labels, logits)\n\n  for _ in tf.range(steps):\n    strategy.run(step_fn, args=(next(iterator),))\n\n# Convert `steps_per_epoch` to `tf.Tensor` so the `tf.function` won't get\n# retraced if the value changes.\ntrain_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n\nprint('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n      optimizer.iterations.numpy(),\n      round(float(training_loss.result()), 4),\n      round(float(training_accuracy.result()) * 100, 2)))\n```\n\n----------------------------------------\n\nTITLE: Data Packing Functions for DTensor in TensorFlow\nDESCRIPTION: Helper functions for transferring data to devices using DTensor. The first function repacks local tensors to DTensors with specified layouts, while the second function specifically packs training data batches into DTensors sharded along the batch axis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef repack_local_tensor(x, layout):\n  # Repacks a local Tensor-like to a DTensor with layout\n  # This function assumes a single-client application\n  x = tf.convert_to_tensor(x)\n  sharded_dims = []\n\n  # For every sharded dimension, use tf.split to split the along the dimension.\n  # The result is a nested list of split-tensors in queue[0].\n  queue = [x]\n  for axis, dim in enumerate(layout.sharding_specs):\n    if dim == dtensor.UNSHARDED:\n      continue\n    num_splits = layout.shape[axis]\n    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n    sharded_dims.append(dim)\n\n  # Now you can build the list of component tensors by looking up the location in\n  # the nested list of split-tensors created in queue[0].\n  components = []\n  for locations in layout.mesh.local_device_locations():\n    t = queue[0]\n    for dim in sharded_dims:\n      split_index = locations[dim]  # Only valid on single-client mesh.\n      t = t[split_index]\n    components.append(t)\n\n  return dtensor.pack(components, layout)\n\ndef repack_batch(x, y, mesh):\n  # Pack training data batches into DTensors along the batch axis\n  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n  return x, y\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients for Multiple Variables in TensorFlow\nDESCRIPTION: This snippet shows how to compute gradients for multiple variables using tf.GradientTape. It calculates the gradient of a loss function with respect to weights and biases in a simple linear model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nw = tf.Variable(tf.random.normal((3, 2)), name='w')\nb = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\nx = [[1., 2., 3.]]\n\nwith tf.GradientTape(persistent=True) as tape:\n  y = x @ w + b\n  loss = tf.reduce_mean(y**2)\n\n[dl_dw, dl_db] = tape.gradient(loss, [w, b])\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TensorFlow model's accuracy on test data\nDESCRIPTION: Tests the model's performance on previously unseen data to measure how well it generalizes. Returns the loss value and accuracy metric, comparing the model's predictions against the ground truth test labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)\n```\n\n----------------------------------------\n\nTITLE: Creating audio datasets from directory structure with TensorFlow\nDESCRIPTION: This code creates training and validation datasets from the audio files using TensorFlow's audio_dataset_from_directory utility, which automatically loads and labels data based on folder structure. It sets a fixed output sequence length of 16000 samples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n    directory=data_dir,\n    batch_size=64,\n    validation_split=0.2,\n    seed=0,\n    output_sequence_length=16000,\n    subset='both')\n\nlabel_names = np.array(train_ds.class_names)\nprint()\nprint(\"label names:\", label_names)\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard to visualize training metrics\nDESCRIPTION: Starts TensorBoard in a Jupyter environment to visualize training metrics and track model performance across epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n%tensorboard --logdir logs/fit\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Python Side Effects in TensorFlow Functions\nDESCRIPTION: This code snippet shows how calling a function with Python side effects multiple times with different arguments triggers new graph creations. It illustrates the behavior of tf.function when dealing with Python-level operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(a_function_with_python_side_effect(2))\nprint(a_function_with_python_side_effect(3))\n```\n\n----------------------------------------\n\nTITLE: Custom Training Step Function for Multi-Worker Training\nDESCRIPTION: This function defines a custom training step using tf.function for efficiency. It includes forward pass, loss calculation, gradient computation, and metric updates, all designed to work with the distributed strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(iterator):\n  \"\"\"Training step function.\"\"\"\n\n  def step_fn(inputs):\n    \"\"\"Per-Replica step function.\"\"\"\n    x, y = inputs\n    with tf.GradientTape() as tape:\n      predictions = multi_worker_model(x, training=True)\n      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n          from_logits=True,\n          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n      loss = tf.nn.compute_average_loss(per_example_loss)\n      model_losses = multi_worker_model.losses\n      if model_losses:\n        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n\n    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n    optimizer.apply_gradients(\n        zip(grads, multi_worker_model.trainable_variables))\n    train_accuracy.update_state(y, predictions)\n    return loss\n\n  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n  return strategy.reduce(\n      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n```\n\n----------------------------------------\n\nTITLE: Adding Global Average Pooling Layer for Feature Reduction\nDESCRIPTION: Applies global average pooling to reduce the spatial dimensions of features from the base model, converting each feature map to a single value to create a fixed-length feature vector.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)\n```\n\n----------------------------------------\n\nTITLE: Unfreezing Base Model for Fine-Tuning\nDESCRIPTION: Enables fine-tuning by making the base model trainable, which allows updating the weights of the pre-trained model during further training to better adapt to the specific dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nbase_model.trainable = True\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Sharding Options in TensorFlow\nDESCRIPTION: Shows how to configure dataset sharding options for distributed training. In this example, auto-sharding is turned off, which is not recommended for production use but may be useful for debugging.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n\nglobal_batch_size = 64\nmulti_worker_dataset = mnist_setup.mnist_dataset(batch_size=64)\ndataset_no_auto_shard = multi_worker_dataset.with_options(options)\n```\n\n----------------------------------------\n\nTITLE: Instantiating Hyperband Tuner\nDESCRIPTION: Creates an instance of the Hyperband tuner with specified parameters for hyperparameter optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=10,\n                     factor=3,\n                     directory='my_dir',\n                     project_name='intro_to_kt')\n```\n\n----------------------------------------\n\nTITLE: Creating and Training Keras Model for MNIST in TensorFlow 2\nDESCRIPTION: Defines a sequential Keras model for MNIST classification, compiles it with Adam optimizer and sparse categorical crossentropy loss, then trains it with model checkpointing for later evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  return tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10)\n  ])\n\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss=loss,\n              metrics=['accuracy'],\n              steps_per_execution=10,\n              run_eagerly=True)\n\nlog_dir = tempfile.mkdtemp()\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=os.path.join(log_dir, 'ckpt-{epoch}'),\n    save_weights_only=True)\n\nmodel.fit(x=x_train,\n          y=y_train,\n          epochs=1,\n          callbacks=[model_checkpoint])\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Gradients with tf.custom_gradient\nDESCRIPTION: Creates a custom gradient function using the tf.custom_gradient decorator to override the default gradient calculation, specifically to clip gradients using tf.clip_by_norm during backpropagation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Establish an identity operation, but clip during the gradient pass.\n@tf.custom_gradient\ndef clip_gradients(y):\n  def backward(dy):\n    return tf.clip_by_norm(dy, 0.5)\n  return y, backward\n\nv = tf.Variable(2.0)\nwith tf.GradientTape() as t:\n  output = clip_gradients(v * v)\nprint(t.gradient(output, v))  # calls \"backward\", which clips 4 to 2\n```\n\n----------------------------------------\n\nTITLE: Feeding Values to Placeholders in TensorFlow C++\nDESCRIPTION: Demonstrates how to feed values to placeholders when executing a TensorFlow graph. The example creates a placeholder, adds a constant matrix to it, then feeds specific values during execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/cc.md#2025-04-21_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\nScope root = Scope::NewRootScope();\nauto a = Placeholder(root, DT_INT32);\n// [3 3; 3 3]\nauto b = Const(root, 3, {2, 2});\nauto c = Add(root, a, b);\nClientSession session(root);\nstd::vector<Tensor> outputs;\n\n// Feed a <- [1 2; 3 4]\nsession.Run({ {a, { {1, 2}, {3, 4} } } }, {c}, &outputs);\n// outputs[0] == [4 5; 6 7]\n```\n\n----------------------------------------\n\nTITLE: Implementing a Warmup Method for LSTM State Initialization\nDESCRIPTION: Defines a warmup method for the FeedBack model that initializes the LSTM's internal state based on input data. It processes initial inputs through the LSTM layer and returns both a prediction and the LSTM state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_64\n\nLANGUAGE: python\nCODE:\n```\ndef warmup(self, inputs):\n  # inputs.shape => (batch, time, features)\n  # x.shape => (batch, lstm_units)\n  x, *state = self.lstm_rnn(inputs)\n\n  # predictions.shape => (batch, features)\n  prediction = self.dense(x)\n  return prediction, state\n\nFeedBack.warmup = warmup\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Model for Single Feature\nDESCRIPTION: Constructs a simple sequential model with normalization and dense layers for single feature prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nhorsepower_model = tf.keras.Sequential([\n    horsepower_normalizer,\n    layers.Dense(units=1)\n])\n\nhorsepower_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Building a Dense Layer Class in TensorFlow Core\nDESCRIPTION: Implementation of a fully-connected (dense) layer as a TensorFlow Module. This class handles weight initialization using Xavier method, supports customizable activation functions, and infers input dimensions on the first call.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass DenseLayer(tf.Module):\n\n  def __init__(self, out_dim, weight_init=xavier_init, activation=tf.identity):\n    # Initialize the dimensions and activation functions\n    self.out_dim = out_dim\n    self.weight_init = weight_init\n    self.activation = activation\n    self.built = False\n\n  def __call__(self, x):\n    if not self.built:\n      # Infer the input dimension based on first call\n      self.in_dim = x.shape[1]\n      # Initialize the weights and biases\n      self.w = tf.Variable(self.weight_init(shape=(self.in_dim, self.out_dim)))\n      self.b = tf.Variable(tf.zeros(shape=(self.out_dim,)))\n      self.built = True\n    # Compute the forward pass\n    z = tf.add(tf.matmul(x, self.w), self.b)\n    return self.activation(z)\n```\n\n----------------------------------------\n\nTITLE: Performance Optimization with tf.function\nDESCRIPTION: Shows how to use tf.function to compile and optimize TensorFlow NumPy code, demonstrating significant performance improvements through trace compilation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ninputs, labels = create_batch(512)\nprint(\"Eager performance\")\ncompute_gradients(model, inputs, labels)\nprint(timeit.timeit(lambda: compute_gradients(model, inputs, labels),\n                    number=10) * 100, \"ms\")\n\nprint(\"\\ntf.function compiled performance\")\ncompiled_compute_gradients = tf.function(compute_gradients)\ncompiled_compute_gradients(model, inputs, labels)  # warmup\nprint(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),\n                    number=10) * 100, \"ms\")\n```\n\n----------------------------------------\n\nTITLE: Indexing Ragged Tensors in Python\nDESCRIPTION: These examples demonstrate various indexing operations on 2D and 3D ragged tensors, including single element access, slicing, and multi-dimensional indexing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nqueries = tf.ragged.constant(\n    [['Who', 'is', 'George', 'Washington'],\n     ['What', 'is', 'the', 'weather', 'tomorrow'],\n     ['Goodnight']])\n\nprint(queries[1])                   # A single query\nprint(queries[1, 2])                # A single word\nprint(queries[1:])                  # Everything but the first row\nprint(queries[:, :3])               # The first 3 words of each query\nprint(queries[:, -2:])              # The last 2 words of each query\n```\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.ragged.constant([[[1, 2, 3], [4]],\n                         [[5], [], [6]],\n                         [[7]],\n                         [[8, 9], [10]]])\n\nprint(rt[1])                        # Second row (2D RaggedTensor)\nprint(rt[3, 0])                     # First element of fourth row (1D Tensor)\nprint(rt[:, 1:3])                   # Items 1-3 of each row (3D RaggedTensor)\nprint(rt[:, -1:])                   # Last item of each row (3D RaggedTensor)\n```\n\n----------------------------------------\n\nTITLE: Comparing Model Sizes in TensorFlow\nDESCRIPTION: This code calculates and compares the sizes of the original and compressed model weights. It demonstrates the significant size reduction achieved through compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef get_weight_size_in_bytes(weight):\n  if weight.dtype == tf.string:\n    return tf.reduce_sum(tf.strings.length(weight, unit=\"BYTE\"))\n  else:\n    return tf.size(weight) * weight.dtype.size\n\noriginal_size = sum(map(get_weight_size_in_bytes, classifier.weights))\ncompressed_size = sum(map(get_weight_size_in_bytes, compressed_classifier.weights))\n\nprint(f\"Size of original model weights: {original_size} bytes\")\nprint(f\"Size of compressed model weights: {compressed_size} bytes\")\nprint(f\"Compression ratio: {(original_size/compressed_size):0.0f}x\")\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Hub Embedding Pipeline in Python\nDESCRIPTION: Sets up and runs a pipeline to generate embeddings using a TensorFlow Hub model. It includes options for random projection and handles output to a temporary directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\n\noutput_dir = tempfile.mkdtemp()\noriginal_dim = hub.load(model_url)(['']).shape[1]\nrandom_projection_matrix = None\n\nif projected_dim:\n  random_projection_matrix = generate_random_projection_weights(\n      original_dim, projected_dim)\n\nargs = {\n    'job_name': 'hub2emb-{}'.format(datetime.utcnow().strftime('%y%m%d-%H%M%S')),\n    'runner': 'DirectRunner',\n    'batch_size': 1024,\n    'data_dir': 'corpus/*.txt',\n    'output_dir': output_dir,\n    'model_url': model_url,\n    'random_projection_matrix': random_projection_matrix,\n}\n\nprint(\"Pipeline args are set.\")\nargs\n```\n\n----------------------------------------\n\nTITLE: Loading and Normalizing Oxford-IIIT Pet Dataset\nDESCRIPTION: This code loads the Oxford-IIIT Pet Dataset using TensorFlow Datasets and defines functions to normalize the images and masks for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n\ndef normalize(input_image, input_mask):\n  input_image = tf.cast(input_image, tf.float32) / 255.0\n  input_mask -= 1\n  return input_image, input_mask\n\ndef load_image(datapoint):\n  input_image = tf.image.resize(datapoint['image'], (128, 128))\n  input_mask = tf.image.resize(\n    datapoint['segmentation_mask'],\n    (128, 128),\n    method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n  )\n\n  input_image, input_mask = normalize(input_image, input_mask)\n\n  return input_image, input_mask\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor with Multiple Ragged Dimensions in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a ragged tensor with multiple ragged dimensions using nested RaggedTensors. It uses the from_row_splits method to construct the tensor and then prints its shape and number of partitioned dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_56\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=tf.RaggedTensor.from_row_splits(\n        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n        row_splits=[0, 3, 3, 5, 9, 10]),\n    row_splits=[0, 1, 1, 5])\nprint(rt)\nprint(\"Shape: {}\".format(rt.shape))\nprint(\"Number of partitioned dimensions: {}\".format(rt.ragged_rank))\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Training Step Function in TensorFlow\nDESCRIPTION: Defines a training step function that calculates per-example losses, computes average loss, handles regularization losses, and applies gradients to model parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef train_step(inputs):\n  features, labels = inputs\n\n  with tf.GradientTape() as tape:\n    predictions = model(features, training=True)\n    per_example_loss = loss_object(labels, predictions)\n    loss = tf.nn.compute_average_loss(per_example_loss)\n    model_losses = model.losses\n    if model_losses:\n      loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n  return loss\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Function with tf.function Decorator\nDESCRIPTION: Demonstrates how to use the tf.function decorator to convert a Python function into a TensorFlow graph for optimized execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef my_func(x):\n  print('Tracing.\\n')\n  return tf.reduce_sum(x)\n```\n\n----------------------------------------\n\nTITLE: Loading and Testing Converted TensorFlow Model\nDESCRIPTION: Example showing how to reload the saved model and test its functionality with different batch sizes for prediction and accuracy evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nreloaded_model = tf.saved_model.load(\"./\")\n\n# Test if it works and that the batch size is indeed variable.\nx,y = next(iter(train_data.unbatch().batch(13)))\nprint(np.argmax(reloaded_model.predict(x).numpy(), axis=-1))\nx,y = next(iter(train_data.unbatch().batch(20)))\nprint(np.argmax(reloaded_model.predict(x).numpy(), axis=-1))\n\nprint(reloaded_model.accuracy(one_batch, one_batch_labels))\nprint(reloaded_model.accuracy(all_test_data, all_test_labels))\n```\n\n----------------------------------------\n\nTITLE: Optimized CSV Loading with Batched Text Lines\nDESCRIPTION: Implements a more efficient CSV loading technique by reading text lines in batches and then decoding them. This approach leverages the performance advantage of batch decoding in tf.io.decode_csv.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_60\n\nLANGUAGE: python\nCODE:\n```\nfonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\nfonts_lines = fonts_files.interleave(\n    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n    cycle_length=100).batch(BATCH_SIZE)\n\nfonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))\n```\n\n----------------------------------------\n\nTITLE: Obtaining and Using Concrete Functions in TensorFlow\nDESCRIPTION: This snippet demonstrates how to obtain and utilize concrete functions in TensorFlow. It illustrates creating a concrete function from an existing function and how this traced function can be executed. Special attention is given to the handling of function signatures and constraints related to argument types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Obtaining concrete trace\")\ndouble_strings = double.get_concrete_function(tf.constant(\"a\"))\nprint(\"Executing traced function\")\nprint(double_strings(tf.constant(\"a\")))\nprint(double_strings(a=tf.constant(\"b\")))\n```\n\nLANGUAGE: python\nCODE:\n```\n# You can also call get_concrete_function on an InputSpec\ndouble_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))\nprint(double_strings_from_inputspec(tf.constant(\"c\")))\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(double_strings)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(double_strings.function_type)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith assert_raises(tf.errors.InvalidArgumentError):\n  double_strings(tf.constant(1))\n```\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef pow(a, b):\n  return a ** b\n\nsquare = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)\nprint(square)\n```\n\nLANGUAGE: python\nCODE:\n```\nassert square(tf.constant(10.0)) == 100\n\nwith assert_raises(TypeError):\n  square(tf.constant(10.0), b=3)\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU Thread Mode and Count\nDESCRIPTION: This code sets environment variables to control GPU thread usage. It configures private GPU threads to prevent preprocessing operations from monopolizing GPU resources and limits the thread count to reduce kernel launch delay during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ['TF_GPU_THREAD_MODE']='gpu_private'\nos.environ['TF_GPU_THREAD_COUNT']='1'\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Conv1D Model\nDESCRIPTION: Compiles, trains, and evaluates the convolutional model using the configured window generator, storing performance metrics for validation and test datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nhistory = compile_and_fit(conv_model, conv_window)\n\nIPython.display.clear_output()\nval_performance['Conv'] = conv_model.evaluate(conv_window.val, return_dict=True)\nperformance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Launching First TensorFlow Worker Process in Background\nDESCRIPTION: This code launches the first worker process in the background using the Jupyter bash magic. The process runs main.py and redirects output to a log file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\n%%bash --bg\npython main.py &> job_0.log\n```\n\n----------------------------------------\n\nTITLE: Saving Large Models with Proto-splitting\nDESCRIPTION: Demonstrates how to save models that exceed the 2GB protobuf limit using the experimental_image_format option in TensorFlow 2.15+.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ntf.saved_model.save(\n  ...,\n  options=tf.saved_model.SaveOptions(experimental_image_format=True)\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up MirroredStrategy for Distributed Training in Python\nDESCRIPTION: This snippet demonstrates how to create a MirroredStrategy for distributed training and configure a RunConfig with it. This setup allows training to be distributed across multiple GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=strategy)\n```\n\n----------------------------------------\n\nTITLE: Creating and Manipulating TensorFlow NumPy ND Arrays\nDESCRIPTION: Demonstrates creating a TensorFlow NumPy ndarray, displaying its attributes, and showing that it's an alias to tf.Tensor. Also shows common array manipulation methods like transpose and reshape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create an ND array and check out different attributes.\nones = tnp.ones([5, 3], dtype=tnp.float32)\nprint(\"Created ND array with shape = %s, rank = %s, \"\n      \"dtype = %s on device = %s\\n\" % (\n          ones.shape, ones.ndim, ones.dtype, ones.device))\n\n# `ndarray` is just an alias to `tf.Tensor`.\nprint(\"Is `ones` an instance of tf.Tensor: %s\\n\" % isinstance(ones, tf.Tensor))\n\n# Try commonly used member functions.\nprint(\"ndarray.T has shape %s\" % str(ones.T.shape))\nprint(\"narray.reshape(-1) has shape %s\" % ones.reshape(-1).shape)\n```\n\n----------------------------------------\n\nTITLE: Auto-sharding Data Across Workers with TensorFlow\nDESCRIPTION: This snippet demonstrates how to auto-shard data across workers using TensorFlow's distribute_datasets_from_function. It calculates the global batch size based on the number of workers and creates a distributed dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nper_worker_batch_size = 64\nnum_workers = len(tf_config['cluster']['worker'])\nglobal_batch_size = per_worker_batch_size * num_workers\n\nwith strategy.scope():\n  multi_worker_dataset = strategy.distribute_datasets_from_function(\n      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-step Last Baseline Model\nDESCRIPTION: Creates a baseline model for multi-step prediction that repeats the last input timestep for the required number of output steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_56\n\nLANGUAGE: python\nCODE:\n```\nclass MultiStepLastBaseline(tf.keras.Model):\n  def call(self, inputs):\n    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n```\n\n----------------------------------------\n\nTITLE: Creating MultiWorkerMirroredStrategy for Synchronous Distributed Training\nDESCRIPTION: Code to instantiate MultiWorkerMirroredStrategy for synchronous training across multiple workers, each potentially with multiple GPUs. This creates copies of all variables on each device across workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Processing Single Frame with MoViNet Streaming Model\nDESCRIPTION: Demonstrates how to process a single frame using the MoViNet streaming model. It uses the initial state and the first frame of the video as input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ninputs = initial_state.copy()\n\n# Add the batch axis, take the first frme, but keep the frame-axis.\ninputs['image'] = jumpingjack[tf.newaxis, 0:1, ...] \n\n# warmup\nmodel(inputs);\n\nlogits, new_state = model(inputs)\nlogits = logits[0]\nprobs = tf.nn.softmax(logits, axis=-1)\n\nfor label, p in get_top_k(probs):\n  print(f'{label:20s}: {p:.3f}')\n\nprint()\n```\n\n----------------------------------------\n\nTITLE: Loading and Cleaning Auto MPG Dataset for TensorFlow Regression\nDESCRIPTION: Downloads the Auto MPG dataset, loads it into a pandas DataFrame, and performs initial data cleaning by removing rows with missing values and encoding categorical variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n                'Acceleration', 'Model Year', 'Origin']\n\nraw_dataset = pd.read_csv(url, names=column_names,\n                          na_values='?', comment='\\t',\n                          sep=' ', skipinitialspace=True)\n\ndataset = raw_dataset.copy()\ndataset = dataset.dropna()\n\ndataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\ndataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='', dtype=float)\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model to HDF5 File\nDESCRIPTION: Save an entire Keras model to an HDF5 file, preserving weights, architecture, and optimizer configuration. Allows model checkpointing and later restoration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model()\n\nmodel.fit(train_images, train_labels, epochs=5)\n\n# Save entire model to a HDF5 file\nmodel.save('my_model.h5')\n```\n\nLANGUAGE: python\nCODE:\n```\n# Recreate the exact same model, including weights and optimizer.\nnew_model = keras.models.load_model('my_model.h5')\nnew_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Converting TF_CONFIG to JSON String\nDESCRIPTION: Converting the TF_CONFIG dictionary to a JSON string, which is the format required for the TF_CONFIG environment variable used by TensorFlow's distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\njson.dumps(tf_config)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Weather Dataset in Python\nDESCRIPTION: This code downloads a weather dataset, reads it into a pandas DataFrame, and performs initial preprocessing steps including datetime conversion and subsampling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nzip_path = tf.keras.utils.get_file(\n    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n    fname='jena_climate_2009_2016.csv.zip',\n    extract=True)\ncsv_path, _ = os.path.splitext(zip_path)\n\ndf = pd.read_csv(csv_path)\n# Slice [start:stop:step], starting from index 5 take every 6th record.\ndf = df[5::6]\n\ndate_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n```\n\n----------------------------------------\n\nTITLE: Implementing Fast Gradient Sign Method (FGSM) for Adversarial Attack\nDESCRIPTION: Creates a function that generates adversarial perturbations using gradients of the loss with respect to the input image, implementing the core FGSM algorithm.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nloss_object = tf.keras.losses.CategoricalCrossentropy()\n\ndef create_adversarial_pattern(input_image, input_label):\n  with tf.GradientTape() as tape:\n    tape.watch(input_image)\n    prediction = pretrained_model(input_image)\n    loss = loss_object(input_label, prediction)\n\n  # Get the gradients of the loss w.r.t to the input image.\n  gradient = tape.gradient(loss, input_image)\n  # Get the sign of the gradients to create the perturbation\n  signed_grad = tf.sign(gradient)\n  return signed_grad\n```\n\n----------------------------------------\n\nTITLE: Writing Image Data to TFRecord File\nDESCRIPTION: This code demonstrates how to write image data to a TFRecord file. It creates a tf.train.Example message containing image features such as height, width, depth, label, and raw image data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimage_labels = {\n    cat_in_snow : 0,\n    williamsburg_bridge : 1,\n}\n\n# This is an example, just using the cat image.\nimage_string = open(cat_in_snow, 'rb').read()\n\nlabel = image_labels[cat_in_snow]\n\n# Create a dictionary with features that may be relevant.\ndef image_example(image_string, label):\n  image_shape = tf.io.decode_jpeg(image_string).shape\n\n  feature = {\n      'height': _int64_feature(image_shape[0]),\n      'width': _int64_feature(image_shape[1]),\n      'depth': _int64_feature(image_shape[2]),\n      'label': _int64_feature(label),\n      'image_raw': _bytes_feature(image_string),\n  }\n\n  return tf.train.Example(features=tf.train.Features(feature=feature))\n\n# Write the raw image files to `images.tfrecords`.\n# First, process the two images into `tf.train.Example` messages.\n# Then, write to a `.tfrecords` file.\nrecord_file = 'images.tfrecords'\nwith tf.io.TFRecordWriter(record_file) as writer:\n  for filename, label in image_labels.items():\n    image_string = open(filename, 'rb').read()\n    tf_example = image_example(image_string, label)\n    writer.write(tf_example.SerializeToString())\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Augmentation Layers\nDESCRIPTION: Creates a sequential model for data augmentation including random flips and rotations using Keras preprocessing layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata_augmentation = tf.keras.Sequential([\n  layers.RandomFlip(\"horizontal_and_vertical\"),\n  layers.RandomRotation(0.2),\n])\n```\n\n----------------------------------------\n\nTITLE: Implementing Dropout in TensorFlow Keras Model\nDESCRIPTION: This code creates a sequential model with dropout layers added after each Dense layer. The dropout rate is set to 0.5, meaning 50% of the features will be randomly set to zero during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: Python\nCODE:\n```\ndropout_model = tf.keras.Sequential([\n    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(1)\n])\n\nregularizer_histories['dropout'] = compile_and_fit(dropout_model, \"regularizers/dropout\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Compressed Convolutional Layer in TensorFlow\nDESCRIPTION: This class extends CustomConv2D to create a compressed version of a convolutional layer. It compresses the kernel and bias, and decompresses them when accessed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclass CompressedConv2D(CustomConv2D):\n\n  def build(self, input_shape, other=None):\n    assert isinstance(other, CompressibleConv2D)\n    self.input_channels = other.kernel.shape[2]\n    self.kernel_compressed, self.kernel_log_step = compress_latent(\n        other.kernel_latent, other.kernel_log_step, \"kernel\")\n    self.bias_compressed, self.bias_log_step = compress_latent(\n        other.bias_latent, other.bias_log_step, \"bias\")\n    self.built = True\n\n  @property\n  def kernel(self):\n    rdft_shape = (self.input_channels, self.filters,\n                  self.kernel_size, self.kernel_size // 2 + 1, 2)\n    kernel_rdft = decompress_latent(\n        self.kernel_compressed, rdft_shape, self.kernel_log_step)\n    return from_rdft(kernel_rdft, self.kernel_size)\n\n  @property\n  def bias(self):\n    bias_shape = (self.filters,)\n    return decompress_latent(\n        self.bias_compressed, bias_shape, self.bias_log_step)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset from Multiple CSV Files\nDESCRIPTION: This snippet demonstrates how to use make_csv_dataset with a glob pattern to read multiple CSV files in parallel. It sets parameters for batch size, epochs, parallel reading, and shuffling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nfonts_ds = tf.data.experimental.make_csv_dataset(\n    file_pattern = \"fonts/*.csv\",\n    batch_size=10, num_epochs=1,\n    num_parallel_reads=20,\n    shuffle_buffer_size=10000)\n```\n\n----------------------------------------\n\nTITLE: Loading Horse2Zebra Dataset for CycleGAN Training\nDESCRIPTION: Loads the horse2zebra dataset from TensorFlow Datasets and splits it into training and testing sets for horses and zebras. This dataset is used for unpaired image-to-image translation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset, metadata = tfds.load('cycle_gan/horse2zebra',\n                              with_info=True, as_supervised=True)\n\ntrain_horses, train_zebras = dataset['trainA'], dataset['trainB']\ntest_horses, test_zebras = dataset['testA'], dataset['testB']\n```\n\n----------------------------------------\n\nTITLE: Setting up Preprocessing Layers with TensorFlow\nDESCRIPTION: Creates vocabulary lookup layers and preprocessing models for features and labels under Strategy scope. Defines vocabulary lists and builds Keras preprocessing models for string-to-id conversion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfeature_vocab = [\n    \"avenger\", \"ironman\", \"batman\", \"hulk\", \"spiderman\", \"kingkong\", \"wonder_woman\"\n]\nlabel_vocab = [\"yes\", \"no\"]\n\nwith strategy.scope():\n  feature_lookup_layer = tf.keras.layers.StringLookup(\n      vocabulary=feature_vocab,\n      mask_token=None)\n  label_lookup_layer = tf.keras.layers.StringLookup(\n      vocabulary=label_vocab,\n      num_oov_indices=0,\n      mask_token=None)\n\n  raw_feature_input = tf.keras.layers.Input(\n      shape=(3,),\n      dtype=tf.string,\n      name=\"feature\")\n  feature_id_input = feature_lookup_layer(raw_feature_input)\n  feature_preprocess_stage = tf.keras.Model(\n      {\"features\": raw_feature_input},\n      feature_id_input)\n\n  raw_label_input = tf.keras.layers.Input(\n      shape=(1,),\n      dtype=tf.string,\n      name=\"label\")\n  label_id_input = label_lookup_layer(raw_label_input)\n\n  label_preprocess_stage = tf.keras.Model(\n      {\"label\": raw_label_input},\n      label_id_input)\n```\n\n----------------------------------------\n\nTITLE: Defining Image Processing and Visualization Functions\nDESCRIPTION: Defines helper functions for loading, cropping, resizing images and displaying multiple images in a grid. Uses TensorFlow operations for image processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef crop_center(image):\n  \"\"\"Returns a cropped square image.\"\"\"\n  shape = image.shape\n  new_shape = min(shape[1], shape[2])\n  offset_y = max(shape[1] - shape[2], 0) // 2\n  offset_x = max(shape[2] - shape[1], 0) // 2\n  image = tf.image.crop_to_bounding_box(\n      image, offset_y, offset_x, new_shape, new_shape)\n  return image\n\n@functools.lru_cache(maxsize=None)\ndef load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n  \"\"\"Loads and preprocesses images.\"\"\"\n  # Cache image file locally.\n  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n  img = tf.io.decode_image(\n      tf.io.read_file(image_path),\n      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n  img = crop_center(img)\n  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n  return img\n\ndef show_n(images, titles=('',)):\n  n = len(images)\n  image_sizes = [image.shape[1] for image in images]\n  w = (image_sizes[0] * 6) // 320\n  plt.figure(figsize=(w * n, w))\n  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n  for i in range(n):\n    plt.subplot(gs[i])\n    plt.imshow(images[i][0], aspect='equal')\n    plt.axis('off')\n    plt.title(titles[i] if len(titles) > i else '')\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset Pipelines for CVAE\nDESCRIPTION: Creates TensorFlow dataset objects with shuffling and batching for efficient training and testing data pipelines. These datasets will feed the CVAE model during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n                 .shuffle(train_size).batch(batch_size))\ntest_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n                .shuffle(test_size).batch(batch_size))\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets for Video Data in Python\nDESCRIPTION: This snippet shows how to create TensorFlow datasets for training, validation, and test sets using the FrameGenerator class. It defines the output signature and batches the data for processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nn_frames = 10\nbatch_size = 8\n\noutput_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n                    tf.TensorSpec(shape = (), dtype = tf.int16))\n\ntrain_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], n_frames, training=True),\n                                          output_signature = output_signature)\n\n\n# Batch the data\ntrain_ds = train_ds.batch(batch_size)\n\nval_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], n_frames),\n                                        output_signature = output_signature)\nval_ds = val_ds.batch(batch_size)\n\ntest_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], n_frames),\n                                         output_signature = output_signature)\n\ntest_ds = test_ds.batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Building CNN Model for Audio Classification\nDESCRIPTION: Sequential CNN model definition using Keras, including preprocessing layers for resizing and normalization, followed by convolutional and dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmodel = models.Sequential([\n    layers.Input(shape=input_shape),\n    # Downsample the input.\n    layers.Resizing(32, 32),\n    # Normalize.\n    norm_layer,\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.Conv2D(64, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_labels),\n])\n```\n\n----------------------------------------\n\nTITLE: Calculating Class Weights in Python for TensorFlow Model\nDESCRIPTION: This code snippet calculates class weights to handle imbalanced datasets. It adjusts the importance of each class inversely proportional to its frequency in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n```\n\n----------------------------------------\n\nTITLE: Model Compilation and Data Preparation\nDESCRIPTION: Shows model compilation with loss and optimizer setup, along with MNIST dataset preparation and normalization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = keras.Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\nx_train = x_train.reshape(60000, 784).astype('float32') / 255\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Callbacks\nDESCRIPTION: Defines custom callbacks for learning rate scheduling, model checkpointing, and TensorBoard logging\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass PrintLR(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, model.optimizer.learning_rate.numpy()))\n\ncallbacks = [\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n                                       save_weights_only=True),\n    tf.keras.callbacks.LearningRateScheduler(decay),\n    PrintLR()\n]\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard from Command Line\nDESCRIPTION: Shows how to launch TensorBoard from the command line to visualize a saved TensorFlow graph. TensorBoard runs as a web service that displays interactive visualizations in a browser.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntensorboard --logdir .\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Variables\nDESCRIPTION: This code demonstrates how to create TensorFlow variables of different types, including tensors, booleans, and complex numbers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmy_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\nmy_variable = tf.Variable(my_tensor)\n\n# Variables can be all kinds of types, just like tensors\nbool_variable = tf.Variable([False, False, False, True])\ncomplex_variable = tf.Variable([5 + 4j, 6 + 1j])\n```\n\n----------------------------------------\n\nTITLE: Implementing Input Gradient Regularization in TensorFlow\nDESCRIPTION: This code demonstrates input gradient regularization technique. It calculates the gradient of the output with respect to the input, computes its magnitude, and then calculates the gradient of that magnitude with respect to the model parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as t2:\n  # The inner tape only takes the gradient with respect to the input,\n  # not the variables.\n  with tf.GradientTape(watch_accessed_variables=False) as t1:\n    t1.watch(x)\n    y = layer(x)\n    out = tf.reduce_sum(layer(x)**2)\n  # 1. Calculate the input gradient.\n  g1 = t1.gradient(out, x)\n  # 2. Calculate the magnitude of the input gradient.\n  g1_mag = tf.norm(g1)\n\n# 3. Calculate the gradient of the magnitude with respect to the model.\ndg1_mag = t2.gradient(g1_mag, layer.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing with MirroredStrategy using Model.fit API\nDESCRIPTION: Example demonstrating how to integrate preprocessing layers when using TensorFlow's MirroredStrategy with the Keras Model.fit API. The preprocessing layer (IntegerLookup) is created within the strategy scope and applied to the dataset before training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n  # Create the layer(s) under scope.\n  integer_preprocessing_layer = tf.keras.layers.IntegerLookup(vocabulary=FILE_PATH)\n  model = ...\n  model.compile(...)\ndataset = dataset.map(lambda x, y: (integer_preprocessing_layer(x), y))\nmodel.fit(dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Parallel Training Loop with DTensor in Python\nDESCRIPTION: This code snippet demonstrates a training loop for data parallel training using DTensor. It includes epoch tracking, progress reporting, and checkpointing after each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 2\nmanager = start_checkpoint_manager(model)\n\nfor epoch in range(num_epochs):\n  step = 0\n  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()), stateful_metrics=[])\n  metrics = {'epoch': epoch}\n  for x,y in train_data_vec:\n\n    x, y = repack_batch(x, y, mesh)\n\n    metrics.update(train_step(model, x, y, 1e-2))\n\n    pbar.update(step, values=metrics.items(), finalize=False)\n    step += 1\n  manager.save()\n  pbar.update(step, values=metrics.items(), finalize=True)\n```\n\n----------------------------------------\n\nTITLE: Nesting tf.function Definitions\nDESCRIPTION: Demonstrates how tf.functions can be nested within other tf.functions, creating a dense layer that uses the previously defined add function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef dense_layer(x, w, b):\n  return add(tf.matmul(x, w), b)\n\ndense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))\n```\n\n----------------------------------------\n\nTITLE: Building LSTM Music Generation Model in TensorFlow\nDESCRIPTION: Creates a neural network model with an LSTM layer and multiple output heads for pitch, step, and duration prediction. Each output has its own appropriate loss function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ninput_shape = (seq_length, 3)\nlearning_rate = 0.005\n\ninputs = tf.keras.Input(input_shape)\nx = tf.keras.layers.LSTM(128)(inputs)\n\noutputs = {\n  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n  'step': tf.keras.layers.Dense(1, name='step')(x),\n  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n}\n\nmodel = tf.keras.Model(inputs, outputs)\n\nloss = {\n      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n          from_logits=True),\n      'step': mse_with_positive_pressure,\n      'duration': mse_with_positive_pressure,\n}\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\nmodel.compile(loss=loss, optimizer=optimizer)\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Vectorization with tf.vectorized_map\nDESCRIPTION: Demonstrates how to use tf.vectorized_map to compute per-example gradients efficiently, showing how to vectorize operations for better performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef vectorized_per_example_gradients(inputs, labels):\n  def single_example_gradient(arg):\n    inp, label = arg\n    return compute_gradients(model,\n                             tnp.expand_dims(inp, 0),\n                             tnp.expand_dims(label, 0))\n  # Note that a call to `tf.vectorized_map` semantically maps\n  # `single_example_gradient` over each row of `inputs` and `labels`.\n  # The interface is similar to `tf.map_fn`.\n  # The underlying machinery vectorizes away this map loop which gives\n  # nice speedups.\n  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n\nbatch_size = 128\ninputs, labels = create_batch(batch_size)\n\nper_example_gradients = vectorized_per_example_gradients(inputs, labels)\nfor w, p in zip(model.weights, per_example_gradients):\n  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n      w.shape, batch_size, p.shape))\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for MoViNet Transfer Learning\nDESCRIPTION: A pip installation command for required packages including remotezip for handling ZIP files, tqdm for progress tracking, OpenCV for video processing, and tf-models-official for accessing the pre-trained MoViNet models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official\n```\n\n----------------------------------------\n\nTITLE: Image Decoding and Resizing Function\nDESCRIPTION: Creates a function to decode JPEG images and resize them to a specified height and width. This ensures all images have consistent dimensions for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef decode_img(img):\n  # Convert the compressed string to a 3D uint8 tensor\n  img = tf.io.decode_jpeg(img, channels=3)\n  # Resize the image to the desired size\n  return tf.image.resize(img, [img_height, img_width])\n```\n\n----------------------------------------\n\nTITLE: Making predictions with a Keras model using converted RaggedTensors\nDESCRIPTION: Shows how to use the trained Keras model to make predictions on the input data after converting the RaggedTensor to a dense tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nprint(keras_model.predict(hashed_words.to_tensor()))\n```\n\n----------------------------------------\n\nTITLE: Implementing Cross-Entropy Loss Function in TensorFlow\nDESCRIPTION: Function that computes the cross-entropy loss between predicted logits and true labels using sparse operations, which is efficient for multiclass classification problems as it doesn't require one-hot encoding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef cross_entropy_loss(y_pred, y):\n  # Compute cross entropy loss with a sparse operation\n  sparse_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_pred)\n  return tf.reduce_mean(sparse_ce)\n```\n\n----------------------------------------\n\nTITLE: Evaluating the model performance\nDESCRIPTION: Evaluates the trained model's performance using the test dataset to measure accuracy and loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(test_dataset)\n```\n\n----------------------------------------\n\nTITLE: Defining an Input Function for TensorFlow Estimator\nDESCRIPTION: Creates an input_fn that loads the Iris dataset using TensorFlow Datasets, maps the features to match the model's input layer name, and sets up batching and repeating for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef input_fn():\n  split = tfds.Split.TRAIN\n  dataset = tfds.load('iris', split=split, as_supervised=True)\n  dataset = dataset.map(lambda features, labels: ({'dense_input':features}, labels))\n  dataset = dataset.batch(32).repeat()\n  return dataset\n```\n\n----------------------------------------\n\nTITLE: Configuring Training Callbacks in TensorFlow\nDESCRIPTION: Defines a function to create a standard set of callbacks for model training, including EpochDots for reduced logging noise, EarlyStopping to prevent unnecessary training, and TensorBoard for monitoring training progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef get_callbacks(name):\n  return [\n    tfdocs.modeling.EpochDots(),\n    tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n    tf.keras.callbacks.TensorBoard(logdir/name),\n  ]\n```\n\n----------------------------------------\n\nTITLE: Compiling and Training the Image Classification Model\nDESCRIPTION: This code compiles the model with an optimizer, loss function, and metrics, then trains it using the prepared datasets. It specifies the number of epochs for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nepochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Fine-tuning for a SavedModel\nDESCRIPTION: Creates an optimization step function to fine-tune a SavedModel using gradient tape, demonstrating how to access and update variables in the imported model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.keras.optimizers.SGD(0.05)\n\ndef train_step():\n  with tf.GradientTape() as tape:\n    loss = (10. - imported(tf.constant(2.))) ** 2\n  variables = tape.watched_variables()\n  grads = tape.gradient(loss, variables)\n  optimizer.apply_gradients(zip(grads, variables))\n  return loss\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Dataset in TensorFlow\nDESCRIPTION: Creates a dataset that reads records from CSV files with four float columns that may have missing values. The dataset is mapped to stack the items into tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nrecord_defaults = [999,999,999,999]\ndataset = tf.data.experimental.CsvDataset(\"missing.csv\", record_defaults)\ndataset = dataset.map(lambda *items: tf.stack(items))\ndataset\n```\n\n----------------------------------------\n\nTITLE: Training Loop Implementation for DTensor MLP Model\nDESCRIPTION: Complete training loop for a DTensor MLP model. It processes training and testing data over multiple epochs, using the previously defined training and testing step functions, and maintains metrics for performance evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the training loop parameters and structures\nepochs = 3\nbatch_size = 128\ntrain_losses, test_losses = [], []\ntrain_accs, test_accs = [], []\noptimizer = Adam(mlp_model.trainable_variables)\n\n# Format training loop\nfor epoch in range(epochs):\n  batch_losses_train, batch_accs_train = [], []\n  batch_losses_test, batch_accs_test = [], []\n\n  # Iterate through training data\n  for x_batch, y_batch in train_data:\n    x_batch, y_batch = repack_batch(x_batch, y_batch, mesh)\n    batch_loss, batch_acc = train_step(mlp_model, x_batch, y_batch, cross_entropy_loss, accuracy, optimizer)\n   # Keep track of batch-level training performance\n    batch_losses_train.append(batch_loss)\n    batch_accs_train.append(batch_acc)\n\n  # Iterate through testing data\n  for x_batch, y_batch in test_data:\n    x_batch, y_batch = repack_batch(x_batch, y_batch, mesh)\n    batch_loss, batch_acc = test_step(mlp_model, x_batch, y_batch, cross_entropy_loss, accuracy)\n    # Keep track of batch-level testing\n    batch_losses_test.append(batch_loss)\n    batch_accs_test.append(batch_acc)\n\n# Keep track of epoch-level model performance\n  train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n  test_loss, test_acc = tf.reduce_mean(batch_losses_test), tf.reduce_mean(batch_accs_test)\n  train_losses.append(train_loss)\n  train_accs.append(train_acc)\n  test_losses.append(test_loss)\n  test_accs.append(test_acc)\n  print(f\"Epoch: {epoch}\")\n  print(f\"Training loss: {train_loss.numpy():.3f}, Training accuracy: {train_acc.numpy():.3f}\")\n  print(f\"Testing loss: {test_loss.numpy():.3f}, Testing accuracy: {test_acc.numpy():.3f}\")\n```\n\n----------------------------------------\n\nTITLE: Generating Out-of-Domain Data for Uncertainty Testing\nDESCRIPTION: Creates out-of-domain (OOD) examples from a third class that the model never sees during training. This is used to test how well the model recognizes examples far from the training distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef make_ood_data(sample_size=500, means=(2.5, -1.75), vars=(0.01, 0.01)):\n  return np.random.multivariate_normal(\n      means, cov=np.diag(vars), size=sample_size)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training Results with Matplotlib in Python\nDESCRIPTION: This code snippet creates plots of the loss and accuracy on the training and validation sets using Matplotlib. It visualizes the model's performance over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Testing the feature extractor layer output\nDESCRIPTION: Passes an image batch through the feature extractor layer and prints the shape of the output feature vector batch. The MobileNetV2 model outputs a 1280-dimensional feature vector for each image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfeature_batch = feature_extractor_layer(image_batch)\nprint(feature_batch.shape)\n```\n\n----------------------------------------\n\nTITLE: Issues with Python Iterators in tf.function\nDESCRIPTION: Shows how Python iterators don't work as expected in tf.function since they rely on Python runtime state that only advances during tracing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef buggy_consume_next(iterator):\n  tf.print(\"Value:\", next(iterator))\n\niterator = iter([1, 2, 3])\nbuggy_consume_next(iterator)\n# This reuses the first value from the iterator, rather than consuming the next value.\nbuggy_consume_next(iterator)\nbuggy_consume_next(iterator)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing String Features with Categorical Encoding\nDESCRIPTION: Processes string features using StringLookup to convert strings to indices, then applies CategoryEncoding to convert indices to one-hot vectors suitable for model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfor name, input in inputs.items():\n  if input.dtype == tf.float32:\n    continue\n  \n  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n\n  x = lookup(input)\n  x = one_hot(x)\n  preprocessed_inputs.append(x)\n```\n\n----------------------------------------\n\nTITLE: Creating a Compressible MNIST Classifier Model with Custom Layers\nDESCRIPTION: Constructs a sequential model for MNIST classification using the compressible layer implementations. The model architecture mirrors a standard classifier but with added compression capabilities through entropy regularization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef make_mnist_classifier(regularizer):\n  return tf.keras.Sequential([\n      CompressibleConv2D(regularizer, 20, 5, strides=2, name=\"conv_1\"),\n      CompressibleConv2D(regularizer, 50, 5, strides=2, name=\"conv_2\"),\n      tf.keras.layers.Flatten(),\n      CompressibleDense(regularizer, 500, name=\"fc_1\"),\n      CompressibleDense(regularizer, 10, name=\"fc_2\"),\n  ], name=\"classifier\")\n\ncompressible_classifier = make_mnist_classifier(regularizer)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow Dependencies and Imports\nDESCRIPTION: Installs required packages and imports necessary TensorFlow libraries including compatibility modules and decision forests.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install tensorflow_decision_forests\n\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\nimport tensorflow_decision_forests as tfdf\nfrom tensorflow import keras\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Keras Layer\nDESCRIPTION: Shows how to create a custom Keras layer by subclassing `tf.keras.layers.Layer`.  The `MyLayer` class performs a matrix multiplication of the input with a kernel matrix. The `build` method creates the layer's weights, the `call` method defines the forward pass, and `compute_output_shape` defines the output shape. The `get_config` and `from_config` methods are implemented for serialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n```python\nclass MyLayer(layers.Layer):\n\n  def __init__(self, output_dim, **kwargs):\n    self.output_dim = output_dim\n    super(MyLayer, self).__init__(**kwargs)\n\n  def build(self, input_shape):\n    shape = tf.TensorShape((input_shape[1], self.output_dim))\n    # Create a trainable weight variable for this layer.\n    self.kernel = self.add_weight(name='kernel',\n                                  shape=shape,\n                                  initializer='uniform',\n                                  trainable=True)\n    # Make sure to call the `build` method at the end\n    super(MyLayer, self).build(input_shape)\n\n  def call(self, inputs):\n    return tf.matmul(inputs, self.kernel)\n\n  def compute_output_shape(self, input_shape):\n    shape = tf.TensorShape(input_shape).as_list()\n    shape[-1] = self.output_dim\n    return tf.TensorShape(shape)\n\n  def get_config(self):\n    base_config = super(MyLayer, self).get_config()\n    base_config['output_dim'] = self.output_dim\n    return base_config\n\n  @classmethod\n  def from_config(cls, config):\n    return cls(**config)\n```\n```\n\nLANGUAGE: python\nCODE:\n```\n```python\nmodel = tf.keras.Sequential([\n    MyLayer(10),\n    layers.Activation('softmax')])\n\n# The compile step specifies the training configuration\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Trains for 5 epochs.\nmodel.fit(data, labels, batch_size=32, epochs=5)\n```\n```\n\n----------------------------------------\n\nTITLE: Adjusting Image Brightness with tf.image\nDESCRIPTION: Shows how to increase image brightness using tf.image.adjust_brightness. The example applies a positive brightness factor of 0.4 to make the image appear brighter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nbright = tf.image.adjust_brightness(image, 0.4)\nvisualize(image, bright)\n```\n\n----------------------------------------\n\nTITLE: Time Series Windowing Dataset Creation\nDESCRIPTION: Function to create windowed datasets from time series data with configurable window size, shift, and stride parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_77\n\nLANGUAGE: python\nCODE:\n```\ndef make_window_dataset(ds, window_size=5, shift=1, stride=1):\n  windows = ds.window(window_size, shift=shift, stride=stride)\n\n  def sub_to_batch(sub):\n    return sub.batch(window_size, drop_remainder=True)\n\n  windows = windows.flat_map(sub_to_batch)\n  return windows\n```\n\n----------------------------------------\n\nTITLE: Adapting TextVectorization Layer to Training Data in TensorFlow\nDESCRIPTION: Fitting the TextVectorization layer to the training dataset to build a vocabulary index mapping strings to integers. This step processes only training data to avoid information leakage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Make a text-only dataset (without labels), then call adapt\ntrain_text = raw_train_ds.map(lambda x, y: x)\nvectorize_layer.adapt(train_text)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset from Note Features in Python\nDESCRIPTION: Converts the NumPy array of note features into a TensorFlow Dataset, which provides a standardized interface for feeding data to TensorFlow models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nnotes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\nnotes_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Determining Crop Region for MoveNet Inference\nDESCRIPTION: Calculates the optimal crop region for the next frame based on the detected joints from the previous frame. It centers the crop on the midpoint of the hip joints and adjusts the size based on the distances between joints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef determine_crop_region(\n      keypoints, image_height,\n      image_width):\n  \"\"\"Determines the region to crop the image for the model to run inference on.\n\n  The algorithm uses the detected joints from the previous frame to estimate\n  the square region that encloses the full body of the target person and\n  centers at the midpoint of two hip joints. The crop size is determined by\n  the distances between each joints and the center point.\n  When the model is not confident with the four torso joint predictions, the\n  function returns a default crop which is the full image padded to square.\n  \"\"\"\n  target_keypoints = {}\n  for joint in KEYPOINT_DICT.keys():\n    target_keypoints[joint] = [\n      keypoints[0, 0, KEYPOINT_DICT[joint], 0] * image_height,\n      keypoints[0, 0, KEYPOINT_DICT[joint], 1] * image_width\n    ]\n\n  if torso_visible(keypoints):\n    center_y = (target_keypoints['left_hip'][0] +\n                target_keypoints['right_hip'][0]) / 2;\n    center_x = (target_keypoints['left_hip'][1] +\n                target_keypoints['right_hip'][1]) / 2;\n\n    (max_torso_yrange, max_torso_xrange,\n      max_body_yrange, max_body_xrange) = determine_torso_and_body_range(\n          keypoints, target_keypoints, center_y, center_x)\n\n    crop_length_half = np.amax(\n        [max_torso_xrange * 1.9, max_torso_yrange * 1.9,\n          max_body_yrange * 1.2, max_body_xrange * 1.2])\n\n    tmp = np.array(\n        [center_x, image_width - center_x, center_y, image_height - center_y])\n    crop_length_half = np.amin(\n        [crop_length_half, np.amax(tmp)]);\n\n    crop_corner = [center_y - crop_length_half, center_x - crop_length_half];\n\n    if crop_length_half > max(image_width, image_height) / 2:\n      return init_crop_region(image_height, image_width)\n    else:\n      crop_length = crop_length_half * 2;\n      return {\n        'y_min': crop_corner[0] / image_height,\n        'x_min': crop_corner[1] / image_width,\n        'y_max': (crop_corner[0] + crop_length) / image_height,\n        'x_max': (crop_corner[1] + crop_length) / image_width,\n        'height': (crop_corner[0] + crop_length) / image_height -\n            crop_corner[0] / image_height,\n        'width': (crop_corner[1] + crop_length) / image_width -\n            crop_corner[1] / image_width\n      }\n  else:\n    return init_crop_region(image_height, image_width)\n```\n\n----------------------------------------\n\nTITLE: Generating Text with Romeo Prompt in TensorFlow\nDESCRIPTION: Calls the generate_text function with a starting prompt \"ROMEO: \" to generate Shakespeare-like text based on the trained RNN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nprint(generate_text(model, start_string=u\"ROMEO: \"))\n```\n\n----------------------------------------\n\nTITLE: Seeding Random Number Generators in TensorFlow Tests\nDESCRIPTION: Examples of properly seeding different random number generators to ensure test determinism. Shows how to seed Python's random, NumPy's random, and TensorFlow's random number generators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/tests.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Python RNG\nimport random\nrandom.seed(42)\n\n# Numpy RNG\nimport numpy as np\nnp.random.seed(42)\n\n# TF RNG\nfrom tensorflow.python.framework import random_seed\nrandom_seed.set_seed(42)\n```\n\n----------------------------------------\n\nTITLE: Performing Inference with a Trained Text Classification Model in TensorFlow\nDESCRIPTION: This code demonstrates how to use a trained TensorFlow model to make predictions on new text examples. It shows the basic syntax for calling predict() on a model with constant text inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nexamples = tf.constant([\n  \"The movie was great!\",\n  \"The movie was okay.\",\n  \"The movie was terrible...\"\n])\n\nexport_model.predict(examples)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Dependencies\nDESCRIPTION: Importing required TensorFlow and utility libraries for the text generation project\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n\nimport numpy as np\nimport os\nimport time\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Keras Model\nDESCRIPTION: This snippet demonstrates how to use a trained Keras model to make predictions on a test dataset. It uses the `predict` method to generate predictions for each image in the `test_images` array. The output is an array of predictions, where each prediction represents the model's confidence for each class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npredictions = model.predict(test_images)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset with Sparse Tensors\nDESCRIPTION: Demonstrates creating a dataset containing a sparse tensor, which is an efficient representation for tensors that are mostly filled with zeros.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Dataset containing a sparse tensor.\ndataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4]))\n\ndataset4.element_spec\n```\n\n----------------------------------------\n\nTITLE: Defining Class Names for Fashion MNIST Dataset\nDESCRIPTION: This snippet creates a list of class names corresponding to the labels in the Fashion MNIST dataset. These names are used for display purposes when visualizing the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n```\n\n----------------------------------------\n\nTITLE: Kernel Classifier Implementation - TensorFlow Python\nDESCRIPTION: This code replaces the basic LinearClassifier with a KernelLinearClassifier to apply explicit kernel mappings on the input features for better classification of the MNIST dataset. It utilizes the Random Fourier Features technique to enhance the model's ability to classify non-linearly separable data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Specify the feature(s) to be used by the estimator. This is identical to the\n# code used for the LinearClassifier.\nimage_column = tf.contrib.layers.real_valued_column('images', dimension=784)\noptimizer = tf.train.FtrlOptimizer(\n   learning_rate=50.0, l2_regularization_strength=0.001)\n\nkernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(\n  input_dim=784, output_dim=2000, stddev=5.0, name='rffm')\nkernel_mappers = {image_column: [kernel_mapper]}\nestimator = tf.contrib.kernel_methods.KernelLinearClassifier(\n   n_classes=10, optimizer=optimizer, kernel_mappers=kernel_mappers)\n\n# Train.\nstart = time.time()\nestimator.fit(input_fn=train_input_fn, steps=2000)\nend = time.time()\nprint('Elapsed time: {} seconds'.format(end - start))\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Loaded SavedModel\nDESCRIPTION: Performs inference using the loaded SavedModel's serving_default signature and verifies that results match the original model's predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nlabeling = infer(tf.constant(x))[pretrained_model.output_names[0]]\n\ndecoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]\n\nprint(\"Result after saving and loading:\\n\", decoded)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic TensorFlow Variable\nDESCRIPTION: Creates a basic three-dimensional TensorFlow variable with default float32 dtype and glorot uniform initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmy_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n```\n\n----------------------------------------\n\nTITLE: Defining Model with TPU Embeddings\nDESCRIPTION: Creates a Keras model with TPU embeddings using TPUStrategy scope. Configures embedding features, tables, and optimizer with proper compilation settings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.TPUStrategy(cluster_resolver)\nwith strategy.scope():\n  if hasattr(tf.keras.optimizers, \"legacy\"):\n    optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n  else:\n    optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n  dense_input = tf.keras.Input(shape=(2,), dtype=tf.float32, batch_size=global_batch_size)\n  sparse_input = tf.keras.Input(shape=(), dtype=tf.int32, batch_size=global_batch_size)\n  embedded_input = tfrs.layers.embedding.TPUEmbedding(\n      feature_config=tf.tpu.experimental.embedding.FeatureConfig(\n          table=tf.tpu.experimental.embedding.TableConfig(\n              vocabulary_size=10,\n              dim=5,\n              initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=1)),\n          name=\"sparse_input\"),\n      optimizer=optimizer)(sparse_input)\n  input = tf.keras.layers.Concatenate(axis=1)([dense_input, embedded_input])\n  result = tf.keras.layers.Dense(1)(input)\n  model = tf.keras.Model(inputs={\"dense_feature\": dense_input, \"sparse_feature\": sparse_input}, outputs=result)\n  model.compile(optimizer, \"mse\", steps_per_execution=10)\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss in Python\nDESCRIPTION: This function creates a plot of the training and validation loss over epochs. It uses a logarithmic scale on the y-axis to show the wide range of loss values during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef plot_loss(history, label, n):\n  # Use a log scale on y-axis to show the wide range of values.\n  plt.semilogy(history.epoch, history.history['loss'],\n               color=colors[n], label='Train ' + label)\n  plt.semilogy(history.epoch, history.history['val_loss'],\n               color=colors[n], label='Val ' + label,\n               linestyle=\"--\")\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Defining DeepResNet Model in TensorFlow\nDESCRIPTION: Implements a multi-layer residual network (ResNet) with dropout regularization as a baseline deterministic model. The model uses Dense layers for hidden and output layers, with configurable number of layers, hidden units, and dropout rate.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass DeepResNet(tf.keras.Model):\n  \"\"\"Defines a multi-layer residual network.\"\"\"\n  def __init__(self, num_classes, num_layers=3, num_hidden=128,\n               dropout_rate=0.1, **classifier_kwargs):\n    super().__init__()\n    # Defines class meta data.\n    self.num_hidden = num_hidden\n    self.num_layers = num_layers\n    self.dropout_rate = dropout_rate\n    self.classifier_kwargs = classifier_kwargs\n\n    # Defines the hidden layers.\n    self.input_layer = tf.keras.layers.Dense(self.num_hidden, trainable=False)\n    self.dense_layers = [self.make_dense_layer() for _ in range(num_layers)]\n\n    # Defines the output layer.\n    self.classifier = self.make_output_layer(num_classes)\n\n  def call(self, inputs):\n    # Projects the 2d input data to high dimension.\n    hidden = self.input_layer(inputs)\n\n    # Computes the ResNet hidden representations.\n    for i in range(self.num_layers):\n      resid = self.dense_layers[i](hidden)\n      resid = tf.keras.layers.Dropout(self.dropout_rate)(resid)\n      hidden += resid\n\n    return self.classifier(hidden)\n\n  def make_dense_layer(self):\n    \"\"\"Uses the Dense layer as the hidden layer.\"\"\"\n    return tf.keras.layers.Dense(self.num_hidden, activation=\"relu\")\n\n  def make_output_layer(self, num_classes):\n    \"\"\"Uses the Dense layer as the output layer.\"\"\"\n    return tf.keras.layers.Dense(\n        num_classes, **self.classifier_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting a Flower Image Dataset\nDESCRIPTION: Downloads and extracts a flower image dataset using Keras' get_file utility, then converts the path to a pathlib.Path object for easier manipulation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_55\n\nLANGUAGE: python\nCODE:\n```\nflowers_root = tf.keras.utils.get_file(\n    'flower_photos',\n    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n    untar=True)\nflowers_root = pathlib.Path(flowers_root)\n```\n\n----------------------------------------\n\nTITLE: Running Embedding Generation Pipeline in Python\nDESCRIPTION: This code sets up and runs a pipeline to generate embeddings using TensorFlow Hub and random projection. It defines pipeline arguments and executes the pipeline using the run_hub2emb function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\n\noutput_dir = pathlib.Path(tempfile.mkdtemp())\ntemporary_dir = pathlib.Path(tempfile.mkdtemp())\n\ng = tf.Graph()\nwith g.as_default():\n  original_dim = load_module(module_url)(['']).shape[1]\n  random_projection_matrix = None\n\n  if projected_dim:\n    random_projection_matrix = generate_random_projection_weights(\n        original_dim, projected_dim)\n\nargs = {\n    'job_name': 'hub2emb-{}'.format(datetime.utcnow().strftime('%y%m%d-%H%M%S')),\n    'runner': 'DirectRunner',\n    'batch_size': 1024,\n    'data_dir': 'corpus/*.txt',\n    'output_dir': output_dir,\n    'temporary_dir': temporary_dir,\n    'module_url': module_url,\n    'random_projection_matrix': random_projection_matrix,\n}\n\nprint(\"Pipeline args are set.\")\nargs\n```\n\n----------------------------------------\n\nTITLE: Implementing Tensor Repacking for DTensor in Python\nDESCRIPTION: Defines a helper function 'repack_local_tensor' to transfer data from local host memory to DTensor's component tensors on accelerator devices, assuming a single-client application.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef repack_local_tensor(x, layout):\n  \"\"\"Repacks a local Tensor-like to a DTensor with layout.\n\n  This function assumes a single-client application.\n  \"\"\"\n  x = tf.convert_to_tensor(x)\n  sharded_dims = []\n\n  # For every sharded dimension, use tf.split to split the along the dimension.\n  # The result is a nested list of split-tensors in queue[0].\n  queue = [x]\n  for axis, dim in enumerate(layout.sharding_specs):\n    if dim == dtensor.UNSHARDED:\n      continue\n    num_splits = layout.shape[axis]\n    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n    sharded_dims.append(dim)\n\n  # Now we can build the list of component tensors by looking up the location in\n  # the nested list of split-tensors created in queue[0].\n  components = []\n  for locations in layout.mesh.local_device_locations():\n    t = queue[0]\n    for dim in sharded_dims:\n      split_index = locations[dim]  # Only valid on single-client mesh.\n      t = t[split_index]\n    components.append(t)\n\n  return dtensor.pack(components, layout)\n```\n\n----------------------------------------\n\nTITLE: Implementing Softmax Layer with Float32 Output\nDESCRIPTION: Shows how to properly implement a softmax activation layer with float32 dtype to avoid numeric issues at model output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx = layers.Dense(10, name='dense_logits')(x)\noutputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)\nprint('Outputs dtype: %s' % outputs.dtype.name)\n```\n\n----------------------------------------\n\nTITLE: Optimizing TensorFlow Datasets for Training\nDESCRIPTION: Applies the same performance optimizations to datasets loaded from TensorFlow Datasets, ensuring consistent training efficiency across different data sources.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)\ntest_ds = configure_for_performance(test_ds)\n```\n\n----------------------------------------\n\nTITLE: Running GRU Layer in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create and run a GRU (Gated Recurrent Unit) layer in TensorFlow, processing a sequence of inputs all at once and returning both the result and final state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngru = layers.GRU(units=4, return_sequences=True, return_state=True)\n\ninputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n\nresult, state = gru(inputs) # Run it all at once\n```\n\n----------------------------------------\n\nTITLE: Manually Saving and Loading Model Weights in TensorFlow\nDESCRIPTION: Demonstrates how to manually save model weights to a checkpoint file and then load those weights into a new model instance. Creates a directory for checkpoints, saves weights in .h5 format, and evaluates the restored model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Save the weights\nos.mkdir('./checkpoints')\nmodel.save_weights('./checkpoints/my_checkpoint.weights.h5')\n\n# Create a new model instance\nmodel = create_model()\n\n# Restore the weights\nmodel.load_weights('./checkpoints/my_checkpoint.weights.h5')\n\n# Evaluate the model\nloss, acc = model.evaluate(test_images, test_labels, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n```\n\n----------------------------------------\n\nTITLE: Compiling and Training CNN Model\nDESCRIPTION: Configure model training parameters and train the model with validation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_labels, epochs=10, \n                    validation_data=(test_images, test_labels))\n```\n\n----------------------------------------\n\nTITLE: Simple ReLU Implementation with tf.function\nDESCRIPTION: Basic implementation of a ReLU activation function using tf.function for graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef my_relu(x):\n  return tf.maximum(0., x)\n```\n\n----------------------------------------\n\nTITLE: Model Instantiation\nDESCRIPTION: Create instance of ActorCritic model with specified number of actions and hidden units\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nnum_actions = env.action_space.n  # 2\nnum_hidden_units = 128\n\nmodel = ActorCritic(num_actions, num_hidden_units)\n```\n\n----------------------------------------\n\nTITLE: Debugging Keras Models with TFDBG\nDESCRIPTION: Shows how to integrate TFDBG with Keras models by wrapping the backend session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\n\ntf.keras.backend.set_session(tf_debug.LocalCLIDebugWrapperSession(tf.Session()))\n\n# Define your keras model, called \"model\".\n\n# Calls to `fit()`, 'evaluate()` and `predict()` methods will break into the\n# TFDBG CLI.\nmodel.fit(...)\nmodel.evaluate(...)\nmodel.predict(...)\n```\n\n----------------------------------------\n\nTITLE: Implementing Stacked LSTM Cells\nDESCRIPTION: This code snippet details creating multiple layers of LSTM cells to enhance the model's expressiveness. The output of each LSTM layer feeds into the next layer, effectively building a deep LSTM model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef lstm_cell():\n  return tf.contrib.rnn.BasicLSTMCell(lstm_size)\nstacked_lstm = tf.contrib.rnn.MultiRNNCell(\n    [lstm_cell() for _ in range(number_of_layers)])\n\ninitial_state = state = stacked_lstm.zero_state(batch_size, tf.float32)\nfor i in range(num_steps):\n    # The value of state is updated after processing each batch of words.\n    output, state = stacked_lstm(words[:, i], state)\n\n    # The rest of the code.\n    # ...\n\nfinal_state = state\n```\n\n----------------------------------------\n\nTITLE: Caching Dataset in TensorFlow Data Pipeline\nDESCRIPTION: Shows how to cache a dataset after applying time-consuming operations to improve performance in subsequent epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbenchmark(\n    ArtificialDataset()\n    .map(  # Apply time consuming operations before cache\n        mapped_function\n    ).cache(\n    ),\n    5\n)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Replica Device Setter\nDESCRIPTION: Example using tf.train.replica_device_setter for data-parallel distributed training. Shows automatic placement of variables and operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device(tf.train.replica_device_setter(ps_tasks=3)):\n  # tf.Variable objects are, by default, placed on tasks in \"/job:ps\" in a\n  # round-robin fashion.\n  w_0 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n  b_0 = tf.Variable(...)  # placed on \"/job:ps/task:1\"\n  w_1 = tf.Variable(...)  # placed on \"/job:ps/task:2\"\n  b_1 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n\n  input_data = tf.placeholder(tf.float32)     # placed on \"/job:worker\"\n  layer_0 = tf.matmul(input_data, w_0) + b_0  # placed on \"/job:worker\"\n  layer_1 = tf.matmul(layer_0, w_1) + b_1     # placed on \"/job:worker\"\n```\n\n----------------------------------------\n\nTITLE: Configuring DTensor-compatible Metrics and Optimizers in Python\nDESCRIPTION: Demonstrates how to create DTensor-compatible optimizers and metrics by providing the mesh information. This allows internal state variables and tensors to work with variables in the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.keras.dtensor.experimental.optimizers.Adam(0.01, mesh=mesh)\nmetrics = {'accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}\neval_metrics = {'eval_accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow 2 Checkpoint to TensorFlow 1\nDESCRIPTION: This function converts a TensorFlow 2 checkpoint to TensorFlow 1 format. It reads variables from a TF2 checkpoint using tf.train.load_checkpoint, creates new variables, and saves them using the TF1 Saver API. It handles the variable name conversion between TF1 and TF2 formats.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef convert_tf2_to_tf1(checkpoint_path, output_prefix):\n  \"\"\"Converts a TF2 checkpoint to TF1.\n\n  The checkpoint must be saved using a \n  `tf.train.Checkpoint(var_list={name: variable})`\n\n  To load the converted checkpoint with `tf.compat.v1.Saver`:\n  ```\n  saver = tf.compat.v1.train.Saver(var_list={name: variable}) \n\n  # An alternative, if the variable names match the keys:\n  saver = tf.compat.v1.train.Saver(var_list=[variables]) \n  saver.restore(sess, output_path)\n  ```\n  \"\"\"\n  vars = {}\n  reader = tf.train.load_checkpoint(checkpoint_path)\n  dtypes = reader.get_variable_to_dtype_map()\n  for key in dtypes.keys():\n    # Get the \"name\" from the \n    if key.startswith('var_list/'):\n      var_name = key.split('/')[1]\n      # TF2 checkpoint keys use '/', so if they appear in the user-defined name,\n      # they are escaped to '.S'.\n      var_name = var_name.replace('.S', '/')\n      vars[var_name] = tf.Variable(reader.get_tensor(key))\n  \n  return tf1.train.Saver(var_list=vars).save(sess=None, save_path=output_prefix)\n```\n\n----------------------------------------\n\nTITLE: Training MNIST Compression Model in TensorFlow\nDESCRIPTION: This code defines functions to prepare the dataset and train the MNIST compression model. It adds dummy targets for rate and distortion, and then fits the model on the training dataset for 15 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef add_rd_targets(image, label):\n  # Training is unsupervised, so labels aren't necessary here. However, we\n  # need to add \"dummy\" targets for rate and distortion.\n  return image, dict(rate=0., distortion=0.)\n\ndef train_mnist_model(lmbda):\n  trainer = make_mnist_compression_trainer(lmbda)\n  trainer.fit(\n      training_dataset.map(add_rd_targets).batch(128).prefetch(8),\n      epochs=15,\n      validation_data=validation_dataset.map(add_rd_targets).batch(128).cache(),\n      validation_freq=1,\n      verbose=1,\n  )\n  return trainer\n\ntrainer = train_mnist_model(lmbda=2000)\n```\n\n----------------------------------------\n\nTITLE: Training Text Classification Model with TensorFlow\nDESCRIPTION: Training the sentiment analysis model over multiple epochs using the prepared datasets. The model is trained on the training dataset and validated on the validation dataset to monitor performance during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nepochs = 10\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Image Segmentation Predictions in TensorFlow\nDESCRIPTION: This function displays the original image, true mask, and predicted mask for given samples from a dataset or a single sample image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef show_predictions(dataset=None, num=1):\n  if dataset:\n    for image, mask in dataset.take(num):\n      pred_mask = model.predict(image)\n      display([image[0], mask[0], create_mask(pred_mask)])\n  else:\n    display([sample_image, sample_mask,\n             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Matching with User Query in Python\nDESCRIPTION: Executes the full similarity matching process: extracting embeddings for a user query, finding similar items in the index, and displaying the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n#@title { run: \"auto\" }\nquery = \"confronting global challenges\" #@param {type:\"string\"}\n\nprint(\"Generating embedding for the query...\")\n%time query_embedding = extract_embeddings(query)\n\nprint(\"\")\nprint(\"Finding relevant items in the index...\")\n%time items = find_similar_items(query_embedding, 10)\n\nprint(\"\")\nprint(\"Results:\")\nprint(\"=========\")\nfor item in items:\n  print(item)\n```\n\n----------------------------------------\n\nTITLE: Saving and Restoring Variables with Checkpoints in TensorFlow\nDESCRIPTION: This code demonstrates how to use tf.train.Checkpoint to save and restore tf.Variables to and from checkpoints. It shows creating a variable, saving it to a checkpoint, changing its value, and then restoring the original value from the checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(10.)\ncheckpoint = tf.train.Checkpoint(x=x)\n\nx.assign(2.)   # Assign a new value to the variables and save.\ncheckpoint_path = './ckpt/'\ncheckpoint.save('./ckpt/')\n\nx.assign(11.)  # Change the variable after saving.\n\n# Restore values from the checkpoint\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n\nprint(x)  # => 2.0\n```\n\n----------------------------------------\n\nTITLE: Running the In-Graph Training Loop in TensorFlow\nDESCRIPTION: This code sets up and runs the in-graph training loop. It creates a `tf.Graph`, defines the learning rate and maximum steps, sets up the training and testing datasets using the `setup_mnist_data` function, and calls the `train` function. Finally, it initializes the global variables and runs the training loop within a `tf.Session`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  learning_rate = 0.005\n  max_steps=500\n\n  train_ds = setup_mnist_data(True, 50)\n  test_ds = setup_mnist_data(False, 1000)\n  (train_losses, test_losses, train_accuracies,\n   test_accuracies) = train(train_ds, test_ds, learning_rate, max_steps)\n\n  init = tf.global_variables_initializer()\n\nwith tf.Session(graph=g) as sess:\n  sess.run(init)\n  (train_losses, test_losses, train_accuracies,\n   test_accuracies) = sess.run([train_losses, test_losses, train_accuracies,\n                                test_accuracies])\n```\n\n----------------------------------------\n\nTITLE: Defining a Simplified Model Function with Gradient Saturation in Python\nDESCRIPTION: Creates a simplified model function that exhibits gradient saturation beyond a certain input value (0.8), demonstrating why simple gradients can be misleading for feature importance attribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef f(x):\n  \"\"\"A simplified model function.\"\"\"\n  return tf.where(x < 0.8, x, 0.8)\n\ndef interpolated_path(x):\n  \"\"\"A straight line path.\"\"\"\n  return tf.zeros_like(x)\n\nx = tf.linspace(start=0.0, stop=1.0, num=6)\ny = f(x)\n```\n\n----------------------------------------\n\nTITLE: Downloading UCF-101 Subset in Python\nDESCRIPTION: This snippet demonstrates how to download a subset of the UCF-101 dataset using the previously defined helper functions. It specifies the number of classes and splits the data into training, validation, and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nURL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\ndownload_dir = pathlib.Path('./UCF101_subset/')\nsubset_paths = download_ufc_101_subset(URL, \n                        num_classes = 10, \n                        splits = {\"train\": 30, \"val\": 10, \"test\": 10},\n                        download_dir = download_dir)\n```\n\n----------------------------------------\n\nTITLE: Evaluating TensorFlow Classifier Accuracy on Test Data in Python\nDESCRIPTION: This code evaluates the trained classifier's accuracy on the test dataset. It uses an input function for evaluation and prints the test set accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\neval_result = classifier.evaluate(\n    input_fn=lambda: input_fn(test, test_y, training=False))\n\nprint('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n```\n\n----------------------------------------\n\nTITLE: Defining Mean Squared Error Loss Function\nDESCRIPTION: Implements a mean squared error loss function that computes the average squared difference between predicted and target values for a batch of data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# This computes a single loss value for an entire batch\ndef loss(target_y, predicted_y):\n  return tf.reduce_mean(tf.square(target_y - predicted_y))\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Linear Regression Data with Noise\nDESCRIPTION: Creates a synthetic dataset for linear regression by generating x values and corresponding y values with added Gaussian noise. The true model has a weight of 3.0 and bias of 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# The actual line\nTRUE_W = 3.0\nTRUE_B = 2.0\n\nNUM_EXAMPLES = 201\n\n# A vector of random x values\nx = tf.linspace(-2,2, NUM_EXAMPLES)\nx = tf.cast(x, tf.float32)\n\ndef f(x):\n  return x * TRUE_W + TRUE_B\n\n# Generate some noise\nnoise = tf.random.normal(shape=[NUM_EXAMPLES])\n\n# Calculate y\ny = f(x) + noise\n```\n\n----------------------------------------\n\nTITLE: Creating Sequence Dataset for Music Generation in Python\nDESCRIPTION: Transforms the note dataset into sequences for training, where each example consists of a sequence of notes as input and the next note as the label. The function also normalizes pitch values and formats the output for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef create_sequences(\n    dataset: tf.data.Dataset, \n    seq_length: int,\n    vocab_size = 128,\n) -> tf.data.Dataset:\n  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n  seq_length = seq_length+1\n\n  # Take 1 extra for the labels\n  windows = dataset.window(seq_length, shift=1, stride=1,\n                              drop_remainder=True)\n\n  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n  sequences = windows.flat_map(flatten)\n  \n  # Normalize note pitch\n  def scale_pitch(x):\n    x = x/[vocab_size,1.0,1.0]\n    return x\n\n  # Split the labels\n  def split_labels(sequences):\n    inputs = sequences[:-1]\n    labels_dense = sequences[-1]\n    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n\n    return scale_pitch(inputs), labels\n\n  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Extracting Frames from Video Files in Python\nDESCRIPTION: This function extracts a specified number of frames from a video file. It uses OpenCV to read the video, randomly selects a starting point, and formats the frames using the previously defined format_frames function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n  \"\"\"\n    Creates frames from each video file present for each category.\n\n    Args:\n      video_path: File path to the video.\n      n_frames: Number of frames to be created per video file.\n      output_size: Pixel size of the output frame image.\n\n    Return:\n      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n  \"\"\"\n  # Read each video frame by frame\n  result = []\n  src = cv2.VideoCapture(str(video_path))  \n\n  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n\n  need_length = 1 + (n_frames - 1) * frame_step\n\n  if need_length > video_length:\n    start = 0\n  else:\n    max_start = video_length - need_length\n    start = random.randint(0, max_start + 1)\n\n  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n  # ret is a boolean indicating whether read was successful, frame is the image itself\n  ret, frame = src.read()\n  result.append(format_frames(frame, output_size))\n\n  for _ in range(n_frames - 1):\n    for _ in range(frame_step):\n      ret, frame = src.read()\n    if ret:\n      frame = format_frames(frame, output_size)\n      result.append(frame)\n    else:\n      result.append(np.zeros_like(result[0]))\n  src.release()\n  result = np.array(result)[..., [2, 1, 0]]\n\n  return result\n```\n\n----------------------------------------\n\nTITLE: Testing Fully Native TF2 Model\nDESCRIPTION: Tests the fully native TensorFlow 2.0 model with the same random seed and inputs to ensure consistent behavior. This is the final verification step before completing the migration process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nrandom_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\nwith random_tool.scope():\n  tf.keras.utils.set_random_seed(42)\n  layer = FullyNativeModel(10)\n\n  inputs = tf.random.normal(shape=(10, 5, 5, 5))\n  migrated_output = layer(inputs)\n\n  # Grab the regularization loss as well\n  migrated_regularization_loss = tf.math.add_n(layer.losses)\n\nprint(migrated_regularization_loss)\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow Keras Model for Binary Classification\nDESCRIPTION: Configures the model with RMSprop optimizer, binary cross-entropy loss, and accuracy metric for binary classification training\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Constructing and Compiling Keras Model\nDESCRIPTION: Creates a simple Sequential model within the strategy scope and compiles it with SGD optimizer. Includes steps_per_execution parameter for optimization of training performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n\n  model.compile(tf.keras.optimizers.legacy.SGD(), loss=\"mse\", steps_per_execution=10)\n```\n\n----------------------------------------\n\nTITLE: Displaying MIT License in Python\nDESCRIPTION: Contains the MIT License text as a comment block in Python. This license pertains to François Chollet's contributions, likely related to Keras which is used in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title MIT License\n#\n# Copyright (c) 2017 François Chollet\n#\n# Permission is hereby granted, free of charge, to any person obtaining a\n# copy of this software and associated documentation files (the \"Software\"),\n# to deal in the Software without restriction, including without limitation\n# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n# and/or sell copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n```\n\n----------------------------------------\n\nTITLE: Testing the Warmup Method on Example Data\nDESCRIPTION: Demonstrates how to use the warmup method to get an initial prediction and state from the feedback model using an example input from the multi_window dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_65\n\nLANGUAGE: python\nCODE:\n```\nprediction, state = feedback_model.warmup(multi_window.example[0])\nprediction.shape\n```\n\n----------------------------------------\n\nTITLE: Transfer Learning Feature Extractor Setup\nDESCRIPTION: Configure a feature extraction layer from a pre-trained MobileNet model, preparing it for transfer learning on a custom image classification task\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfeature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n\nfeature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n                                         input_shape=(224,224,3))\n\nfeature_extractor_layer.trainable = False\n\nmodel = tf.keras.Sequential([\n  feature_extractor_layer,\n  layers.Dense(image_data.num_classes, activation='softmax')\n])\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Trained U-Net Model in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the trained model to make predictions on test data, visualizing the results for multiple samples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nshow_predictions(test_batches, 3)\n```\n\n----------------------------------------\n\nTITLE: Importing Data Visualization and Analysis Libraries in Python\nDESCRIPTION: Imports pandas, matplotlib, seaborn, and other utility libraries for data analysis and visualization. Sets the default figure size for plots.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport tempfile\nimport os\n# Preset Matplotlib figure sizes.\nmatplotlib.rcParams['figure.figsize'] = [9, 6]\n```\n\n----------------------------------------\n\nTITLE: Creating File Paths for Distributed Model Saving in TensorFlow\nDESCRIPTION: Functions that determine appropriate file paths for saving models in a distributed training environment. The chief worker saves to the primary path while other workers save to temporary directories to avoid contention.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmodel_path = '/tmp/keras-model'\n\ndef _is_chief(task_type, task_id):\n  # Note: there are two possible `TF_CONFIG` configurations.\n  #   1) In addition to `worker` tasks, a `chief` task type is use;\n  #      in this case, this function should be modified to\n  #      `return task_type == 'chief'`.\n  #   2) Only `worker` task type is used; in this case, worker 0 is\n  #      regarded as the chief. The implementation demonstrated here\n  #      is for this case.\n  # For the purpose of this Colab section, the `task_type` is `None` case\n  # is added because it is effectively run with only a single worker.\n  return (task_type == 'worker' and task_id == 0) or task_type is None\n\ndef _get_temp_dir(dirpath, task_id):\n  base_dirpath = 'workertemp_' + str(task_id)\n  temp_dir = os.path.join(dirpath, base_dirpath)\n  tf.io.gfile.makedirs(temp_dir)\n  return temp_dir\n\ndef write_filepath(filepath, task_type, task_id):\n  dirpath = os.path.dirname(filepath)\n  base = os.path.basename(filepath)\n  if not _is_chief(task_type, task_id):\n    dirpath = _get_temp_dir(dirpath, task_id)\n  return os.path.join(dirpath, base)\n\ntask_type, task_id = (strategy.cluster_resolver.task_type,\n                      strategy.cluster_resolver.task_id)\nwrite_model_path = write_filepath(model_path, task_type, task_id)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Gradient Saturation and Integrated Gradients Concept in Matplotlib\nDESCRIPTION: Generates a visualization that compares gradient saturation issues with the Integrated Gradients approach. The left plot shows where gradients saturate, while the right plot illustrates the concept of accumulating gradients along a path from baseline to input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n#@title\nfig = plt.figure(figsize=(12, 5))\nax0 = fig.add_subplot(121)\nax0.plot(x, f(x), marker='o')\nax0.set_title('Gradients saturate over F(x)', fontweight='bold')\nax0.text(0.2, 0.5, 'Gradients > 0 = \\n x is important')\nax0.text(0.7, 0.85, 'Gradients = 0 \\n x not important')\nax0.set_yticks(tf.range(0, 1.5, 0.5))\nax0.set_xticks(tf.range(0, 1.5, 0.5))\nax0.set_ylabel('F(x) - model true class predicted probability')\nax0.set_xlabel('x - (pixel value)')\n\nax1 = fig.add_subplot(122)\nax1.plot(x, f(x), marker='o')\nax1.plot(x, interpolated_path(x), marker='>')\nax1.set_title('IG intuition', fontweight='bold')\nax1.text(0.25, 0.1, 'Accumulate gradients along path')\nax1.set_ylabel('F(x) - model true class predicted probability')\nax1.set_xlabel('x - (pixel value)')\nax1.set_yticks(tf.range(0, 1.5, 0.5))\nax1.set_xticks(tf.range(0, 1.5, 0.5))\nax1.annotate('Baseline', xy=(0.0, 0.0), xytext=(0.0, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.1))\nax1.annotate('Input', xy=(1.0, 0.0), xytext=(0.95, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.1))\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Extracting Specific Indices with tf.gather\nDESCRIPTION: Shows how to use tf.gather to extract elements at specific indices from a tensor along a single axis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.gather(t1,\n                indices=[0, 3, 6]))\n\n# This is similar to doing\n\nt1[::3]\n```\n\n----------------------------------------\n\nTITLE: Writing TensorFlow Summaries to TensorBoard\nDESCRIPTION: This code demonstrates how to use tf.summary to log scalar values with a summary writer. The summaries are written directly to the writer, and the step value must be provided at the call site.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nsummary_writer = tf.summary.create_file_writer('/tmp/summaries')\nwith summary_writer.as_default():\n  tf.summary.scalar('loss', 0.1, step=42)\n```\n\n----------------------------------------\n\nTITLE: Dataset Preprocessing\nDESCRIPTION: Applies vectorization to both training and validation datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = train_ds.map(vectorize_text)\nval_ds = val_ds.map(vectorize_text)\n```\n\n----------------------------------------\n\nTITLE: Creating RandomFeatureGaussianProcess Layer in TensorFlow\nDESCRIPTION: This code creates a RandomFeatureGaussianProcess layer with specified parameters such as units, number of inducing points, and covariance momentum.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ngp_layer = nlp_layers.RandomFeatureGaussianProcess(units=num_classes,\n                                               num_inducing=1024,\n                                               normalize_input=False,\n                                               scale_random_features=True,\n                                               gp_cov_momentum=-1)\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TensorFlow Model Loaded from HDF5\nDESCRIPTION: Demonstrates how to evaluate the accuracy of a TensorFlow model that has been loaded from an HDF5 file, confirming that the model functions correctly after restoration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nloss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n```\n\n----------------------------------------\n\nTITLE: Training Final Model with Optimal Hyperparameters\nDESCRIPTION: Retrains the model using the optimal hyperparameters and number of epochs determined in the previous steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhypermodel = tuner.hypermodel.build(best_hps)\n\n# Retrain the model\nhypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from a CSV File\nDESCRIPTION: Uses tf.data.experimental.make_csv_dataset to create a dataset directly from a CSV file, automatically handling parsing and type inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ntitanic_csv_ds = tf.data.experimental.make_csv_dataset(\n    titanic_file_path,\n    batch_size=5, # Artificially small to make examples easier to show.\n    label_name='survived',\n    num_epochs=1,\n    ignore_errors=True,)\n```\n\n----------------------------------------\n\nTITLE: Applying TF1 Hub Module with Multiple Inputs/Outputs\nDESCRIPTION: Demonstrates how to apply a module with multiple named inputs and outputs using signatures and dictionary format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tf1_hub_module.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\noutputs = m(dict(apples=x1, oranges=x2), signature=\"fruit_to_pet\", as_dict=True)\ny1 = outputs[\"cats\"]\ny2 = outputs[\"dogs\"]\n```\n\n----------------------------------------\n\nTITLE: Counting Trainable Variables in the Model\nDESCRIPTION: Shows how to check the number of trainable variables in the model, which helps verify that only the newly added classification layers are trainable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nlen(model.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Calculating Pitch Offset for Note Conversion in Python\nDESCRIPTION: This code calculates the ideal offset for converting pitch predictions to musical notes. It accounts for possible offsets in freely sung melodies relative to absolute pitch values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nnote_names = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\ndef hz2offset(freq):\n  # This measures the quantization error for a single note.\n  if freq == 0:  # Rests always have zero error.\n    return None\n  # Quantized note.\n  h = round(12 * math.log2(freq / C0))\n  return 12 * math.log2(freq / C0) - h\n\n\n# The ideal offset is the mean quantization error for all the notes\n# (excluding rests):\noffsets = [hz2offset(p) for p in pitch_outputs_and_rests if p != 0]\nprint(\"offsets: \", offsets)\n\nideal_offset = statistics.mean(offsets)\nprint(\"ideal offset: \", ideal_offset)\n```\n\n----------------------------------------\n\nTITLE: Packing features into a single array\nDESCRIPTION: This function takes a dictionary of features and labels and packs the features into a single array using tf.stack. The resulting array has shape (batch_size, num_features). This is used to simplify the model building step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef pack_features_vector(features, labels):\n  \"\"\"Pack the features into a single array.\"\"\"\n  features = tf.stack(list(features.values()), axis=1)\n  return features, labels\n```\n\n----------------------------------------\n\nTITLE: Evaluating Text Classification Model on Test Data with TensorFlow\nDESCRIPTION: Assessing the trained model's performance on the test dataset by calculating loss and accuracy metrics. This provides an unbiased evaluation of how well the model generalizes to new, unseen data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nloss, accuracy = model.evaluate(test_ds)\n\nprint(\"Loss: \", loss)\nprint(\"Accuracy: \", accuracy)\n```\n\n----------------------------------------\n\nTITLE: Implementing LSTM Model for Time Series in TensorFlow\nDESCRIPTION: Creates a sequential model with an LSTM layer for time series prediction. The LSTM layer returns sequences to enable predictions at each time step, followed by a dense layer for final output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nlstm_model = tf.keras.models.Sequential([\n    # Shape [batch, time, features] => [batch, time, lstm_units]\n    tf.keras.layers.LSTM(32, return_sequences=True),\n    # Shape => [batch, time, features]\n    tf.keras.layers.Dense(units=1)\n])\n```\n\n----------------------------------------\n\nTITLE: Converting MIDI to WAV using Timidity in Python\nDESCRIPTION: Uses the Timidity command-line tool to convert the MIDI file back to WAV format for playback. This is particularly useful in environments like Google Colab where direct MIDI playback isn't supported.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n!timidity $converted_audio_file_as_midi -Ow -o $wav_from_created_midi\n```\n\n----------------------------------------\n\nTITLE: Custom Sidecar Evaluation Loop in TensorFlow\nDESCRIPTION: Implementation of a custom sidecar evaluation loop that monitors checkpoints and performs evaluation on the latest model checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_dir = ...\neval_model = ...\neval_data = ...\ncheckpoint = tf.train.Checkpoint(model=eval_model)\n\nfor latest_checkpoint in tf.train.checkpoints_iterator(\n    checkpoint_dir):\n  try:\n    checkpoint.restore(latest_checkpoint).expect_partial()\n  except (tf.errors.OpError,) as e:\n    # checkpoint may be deleted by training when it is about to read it.\n    continue\n\n  # Optionally add callbacks to write summaries.\n  eval_model.evaluate(eval_data)\n\n  # Evaluation finishes when it has evaluated the last epoch.\n  if latest_checkpoint.endswith('-{}'.format(train_epochs)):\n    break\n```\n\n----------------------------------------\n\nTITLE: Converting TF_CONFIG to JSON\nDESCRIPTION: Serializing the tf_config dictionary to a JSON string, which would be used to set the TF_CONFIG environment variable in a real distributed training setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\njson.dumps(tf_config)\n```\n\n----------------------------------------\n\nTITLE: Prediction and Error Visualization\nDESCRIPTION: Generates model predictions on test data and creates scatter and histogram plots to visualize prediction accuracy and error distribution\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ntest_predictions = model.predict(normed_test_data).flatten()\n\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [MPG]')\nplt.ylabel('Predictions [MPG]')\nplt.axis('equal')\nplt.axis('square')\n```\n\n----------------------------------------\n\nTITLE: Transition from TF1.x Sessions to TF2 Functions\nDESCRIPTION: This code snippet demonstrates the transition from using Tensorflow 1.x sessions to Tensorflow 2.x functions. With TF1.x, outputs are computed using `session.run`, whereas in TF2, function invocation resembles a regular Python function call with TensorFlow handling computation internally. Dependencies for running this code include TensorFlow's Python library. The main parameter here is `input`, which is the data fed to the function `f`. The expected output is the result computed by `f`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# TF1.x\noutputs = session.run(f(placeholder), feed_dict={placeholder: input})\n# TF2\noutputs = f(input)\n```\n\n----------------------------------------\n\nTITLE: Defining Prediction Function for Action Recognition\nDESCRIPTION: This function takes a video sample, runs it through the I3D model, and prints the top 5 predicted actions with their probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef predict(sample_video):\n  # Add a batch axis to the sample video.\n  model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n\n  logits = i3d(model_input)['default'][0]\n  probabilities = tf.nn.softmax(logits)\n\n  print(\"Top 5 actions:\")\n  for i in np.argsort(probabilities)[::-1][:5]:\n    print(f\"  {labels[i]:22}: {probabilities[i] * 100:5.2f}%\")\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients of Non-Scalar Outputs in TensorFlow\nDESCRIPTION: This snippet demonstrates how to compute gradients when the output is a non-scalar (vector) with respect to a scalar input using TensorFlow's GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.)\n\nwith tf.GradientTape() as tape:\n  y = x * [3., 4.]\n\nprint(tape.gradient(y, x).numpy())\n```\n\n----------------------------------------\n\nTITLE: Visualizing Trained Model Performance\nDESCRIPTION: Plots the final trained model predictions against the ground truth and data points, and displays the final loss value after training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(x, y, '.', label=\"Data\")\nplt.plot(x, f(x), label=\"Ground truth\")\nplt.plot(x, model(x), label=\"Predictions\")\nplt.legend()\nplt.show()\n\nprint(\"Current loss: %1.6f\" % loss(model(x), y).numpy())\n```\n\n----------------------------------------\n\nTITLE: Using Custom Callbacks with Model.fit in TensorFlow 2\nDESCRIPTION: Demonstrates how to use the custom callbacks with Keras Model.fit in TensorFlow 2. The callbacks are passed to the fit method to log tensors and stop training after a specific number of steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/logging_stop_hook.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\nmodel.compile(optimizer, \"mse\")\n\n# Begin training.\n# The training will stop after 2 steps, and the weights/loss will also be logged.\nmodel.fit(dataset, callbacks=[StopAtStepCallback(stop_step=2),\n                              LoggingTensorCallback(every_n_iter=2)])\n```\n\n----------------------------------------\n\nTITLE: Compiling Transfer Learning Model with Lower Learning Rate\nDESCRIPTION: This snippet demonstrates how to compile a fine-tuning model with a reduced learning rate to avoid overfitting. It uses binary cross-entropy loss and RMSprop optimizer with a learning rate that's 10 times smaller than the base rate.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])\n```\n\n----------------------------------------\n\nTITLE: Defining a Small Neural Network with Two Hidden Layers\nDESCRIPTION: Creates a neural network with two hidden layers of 16 units each using the ELU activation function. This model has more capacity than the tiny model while still being relatively small.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nsmall_model = tf.keras.Sequential([\n    # `input_shape` is only required here so that `.summary` works.\n    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n    layers.Dense(16, activation='elu'),\n    layers.Dense(1)\n])\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Conditional Logic with AutoGraph\nDESCRIPTION: Demonstrates how AutoGraph converts Python control flow into TensorFlow graph operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef simple_relu(x):\n  if tf.greater(x, 0):\n    return x\n  else:\n    return 0\n\n# Using `tf.function` makes `tf_simple_relu` a `PolymorphicFunction` that wraps\n# `simple_relu`.\ntf_simple_relu = tf.function(simple_relu)\n\nprint(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\nprint(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow Hub to Load Pre-trained Text Embeddings in Python\nDESCRIPTION: This snippet demonstrates how to import the tensorflow_hub library, load a pre-trained text embedding model, and generate embeddings for text inputs. It shows the basic pattern of using TensorFlow Hub models within a TensorFlow program.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/overview.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\nembeddings = model([\"The rain in Spain.\", \"falls\",\n                    \"mainly\", \"In the plain!\"])\n\nprint(embeddings.shape)  #(4,128)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Loss Function for Non-negative Values in Python\nDESCRIPTION: Defines a custom loss function based on mean squared error that adds a penalty for negative predictions, ensuring step and duration values are positive.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n  mse = (y_true - y_pred) ** 2\n  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n  return tf.reduce_mean(mse + positive_pressure)\n```\n\n----------------------------------------\n\nTITLE: Model Prediction Testing\nDESCRIPTION: Tests the exported model with sample inputs and prints predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ninputs = [\n    \"This is a fantastic movie.\",\n    \"This is a bad movie.\",\n    \"This movie was so bad that it was good.\",\n    \"I will never say yes to watching this movie.\",\n]\n\npredicted_scores = export_model.predict(inputs)\npredicted_labels = [int(round(x[0])) for x in predicted_scores]\n\nfor input, label in zip(inputs, predicted_labels):\n  print(\"Question: \", input)\n  print(\"Predicted label: \", label)\n```\n\n----------------------------------------\n\nTITLE: Using Keras compile and fit API\nDESCRIPTION: Shows how to use Keras' high-level API for model training instead of custom training loops, with the compile and fit methods.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer=optimizer, loss=loss_fn)\nmodel.fit(dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing LSTM Model for Multi-output Prediction\nDESCRIPTION: Creates an LSTM-based sequential model with 32 units and a dense output layer, configured for processing time series data with multiple features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nlstm_model = tf.keras.models.Sequential([\n    # Shape [batch, time, features] => [batch, time, lstm_units]\n    tf.keras.layers.LSTM(32, return_sequences=True),\n    # Shape => [batch, time, features]\n    tf.keras.layers.Dense(units=num_features)\n])\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data for Training and Evaluation in Python\nDESCRIPTION: This code splits the preprocessed weather dataset into training, validation, and test sets while maintaining the temporal order of the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncolumn_indices = {name: i for i, name in enumerate(df.columns)}\n\nn = len(df)\ntrain_df = df[0:int(n*0.7)]\nval_df = df[int(n*0.7):int(n*0.9)]\ntest_df = df[int(n*0.9):]\n\nnum_features = df.shape[1]\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential model with feature extractor and classification layer\nDESCRIPTION: Creates a Keras Sequential model that combines the pre-trained feature extractor layer with a Dense classification layer. The number of output neurons matches the number of classes in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nnum_classes = len(class_names)\n\nmodel = tf.keras.Sequential([\n  feature_extractor_layer,\n  tf.keras.layers.Dense(num_classes)\n])\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: NumPy and TensorFlow NumPy Interoperability\nDESCRIPTION: Demonstrates how TensorFlow NumPy arrays can be used with standard NumPy functions and vice versa, showing the automatic conversion between the two types through the __array__ interface.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# ND array passed into NumPy function.\nnp_sum = np.sum(tnp.ones([2, 3]))\nprint(\"sum = %s. Class: %s\" % (float(np_sum), np_sum.__class__))\n\n# `np.ndarray` passed into TensorFlow NumPy function.\ntnp_sum = tnp.sum(np.ones([2, 3]))\nprint(\"sum = %s. Class: %s\" % (float(tnp_sum), tnp_sum.__class__))\n```\n\n----------------------------------------\n\nTITLE: Defining and Training CNN Model\nDESCRIPTION: Creates and trains a convolutional neural network model using the augmented dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n```\n\n----------------------------------------\n\nTITLE: Saving and Reloading the Model with Preprocessing\nDESCRIPTION: Demonstrates how to save the complete model with preprocessing included, reload it, and verify that predictions remain consistent before and after reloading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntitanic_model.save('test.keras')\nreloaded = tf.keras.models.load_model('test.keras')\n```\n\nLANGUAGE: python\nCODE:\n```\nfeatures_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n\nbefore = titanic_model(features_dict)\nafter = reloaded(features_dict)\nassert (before-after)<1e-3\nprint(before)\nprint(after)\n```\n\n----------------------------------------\n\nTITLE: Executing YAMNet Model for Sound Classification in Python\nDESCRIPTION: This code runs the YAMNet model on the prepared audio data, obtaining scores, embeddings, and spectrogram. It then identifies the main sound class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Run the model, check the output.\nscores, embeddings, spectrogram = model(waveform)\n\nscores_np = scores.numpy()\nspectrogram_np = spectrogram.numpy()\ninfered_class = class_names[scores_np.mean(axis=0).argmax()]\nprint(f'The main sound is: {infered_class}')\n```\n\n----------------------------------------\n\nTITLE: Defining a Large Neural Network with Four 512-Unit Layers\nDESCRIPTION: Creates a large neural network with four hidden layers of 512 units each using the ELU activation function. This model has excessive capacity to demonstrate overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nlarge_model = tf.keras.Sequential([\n    layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n    layers.Dense(512, activation='elu'),\n    layers.Dense(512, activation='elu'),\n    layers.Dense(512, activation='elu'),\n    layers.Dense(1)\n])\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function in TensorFlow\nDESCRIPTION: Implements a loss function that calculates categorical cross-entropy between model predictions and desired labels. The function takes the model, input features, and labels as parameters and returns the average loss across examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef loss(model, x, y):\n  y_ = model(x)\n  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n\n\nl = loss(model, features, labels)\nprint(\"Loss test: {}\".format(l))\n```\n\n----------------------------------------\n\nTITLE: Implementing Parallel Map in TensorFlow Input Pipeline\nDESCRIPTION: This snippet shows how to use parallel map operations in a TensorFlow input pipeline, which can improve performance for computationally intensive map functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.TFRecordDataset(filename)\ndataset = dataset.map(parse_record, num_parallel_calls=2)\ndataset = dataset.batch(32)\ndataset = dataset.repeat()\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Partial Checkpoint Restoration\nDESCRIPTION: Shows how to restore just a specific variable (the bias) from a checkpoint by creating a minimal object structure that matches the checkpoint's dependency graph for that variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nto_restore = tf.Variable(tf.zeros([5]))\nprint(to_restore.numpy())  # All zeros\nfake_layer = tf.train.Checkpoint(bias=to_restore)\nfake_net = tf.train.Checkpoint(l1=fake_layer)\nnew_root = tf.train.Checkpoint(net=fake_net)\nstatus = new_root.restore(tf.train.latest_checkpoint('./tf_ckpts/'))\nprint(to_restore.numpy())  # This gets the restored value.\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed Training Step Function\nDESCRIPTION: Defines a train_step function that properly scales the loss according to global batch size and runs computations across multiple devices using strategy.run and strategy.reduce to aggregate results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  def train_step(dist_inputs):\n    def step_fn(inputs):\n      images, labels = inputs\n      logits = model(images)\n      cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n          logits=logits, labels=labels)\n      loss = tf.nn.compute_average_loss(cross_entropy, global_batch_size=BATCH_SIZE)\n      train_op = optimizer.minimize(loss)\n      with tf.control_dependencies([train_op]):\n        return tf.identity(loss)\n\n    per_replica_losses = strategy.run(\n        step_fn, args=(dist_inputs,))\n    mean_loss = strategy.reduce(\n        tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n    return mean_loss\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow for Distributed Training\nDESCRIPTION: Import the TensorFlow library to set up the environment for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset with Multiple Components\nDESCRIPTION: Creates a dataset where each element contains a scalar tensor and a vector tensor, both with random uniform values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndataset2 = tf.data.Dataset.from_tensor_slices(\n   (tf.random.uniform([4]),\n    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n\ndataset2\n```\n\n----------------------------------------\n\nTITLE: Training the Tiny Model and Storing its History\nDESCRIPTION: Compiles and trains the tiny model using the previously defined function, then stores its training history in the size_histories dictionary for later comparison and analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nsize_histories['Tiny'] = compile_and_fit(tiny_model, 'sizes/Tiny')\n```\n\n----------------------------------------\n\nTITLE: Exporting the trained model as a SavedModel\nDESCRIPTION: Saves the trained model to disk using the TensorFlow SavedModel format for later reuse. The export path includes a timestamp to create a unique directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nt = time.time()\n\nexport_path = \"/tmp/saved_models/{}\".format(int(t))\nmodel.save(export_path)\n\nexport_path\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Images for Cats vs Dogs Classification in Python\nDESCRIPTION: This function preprocesses images for a cats vs dogs classification task. It casts the image to float32, normalizes pixel values, and resizes the image to 160x160.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nIMG_SIZE = 160  # All images will be resized to 160x160\n\ndef preprocess(image, label):\n  image = tf.cast(image, tf.float32)\n  image = (image/127.5) - 1\n  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Using Categorical Cross Entropy Loss in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the CategoricalCrossentropy loss object to calculate loss between true and predicted values. The loss object is callable and takes y_true and y_pred arguments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ncce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\ncce([[1, 0]], [[-1.0,3.0]]).numpy()\n```\n\n----------------------------------------\n\nTITLE: Retrieving the true label for comparison\nDESCRIPTION: Accesses the actual label from the test dataset to compare with the model's prediction. This allows verification of whether the prediction was correct.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_labels[0]\n```\n\n----------------------------------------\n\nTITLE: Visualizing Output of Custom RandomInvert Layer\nDESCRIPTION: Displays an image processed with the custom RandomInvert layer. This demonstrates how to apply the subclassed layer to an image and visualize the result using Matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n_ = plt.imshow(RandomInvert()(image)[0])\n```\n\n----------------------------------------\n\nTITLE: Implementing Softmax Classification in TensorFlow\nDESCRIPTION: Implements classification logic using softmax probabilities and calculates prediction accuracy using TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprobabilities = tf.nn.softmax(logits)\n\nprediction = tf.argmax(probabilities, 1)\ncorrect_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n```\n\n----------------------------------------\n\nTITLE: Implementing SNGP Model Class in TensorFlow\nDESCRIPTION: This code defines a DeepResNetSNGP class that extends DeepResNet to include spectral normalization and Gaussian process output layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclass DeepResNetSNGP(DeepResNet):\n  def __init__(self, spec_norm_bound=0.9, **kwargs):\n    self.spec_norm_bound = spec_norm_bound\n    super().__init__(**kwargs)\n\n  def make_dense_layer(self):\n    \"\"\"Applies spectral normalization to the hidden layer.\"\"\"\n    dense_layer = super().make_dense_layer()\n    return nlp_layers.SpectralNormalization(\n        dense_layer, norm_multiplier=self.spec_norm_bound)\n\n  def make_output_layer(self, num_classes):\n    \"\"\"Uses Gaussian process as the output layer.\"\"\"\n    return nlp_layers.RandomFeatureGaussianProcess(\n        num_classes,\n        gp_cov_momentum=-1,\n        **self.classifier_kwargs)\n\n  def call(self, inputs, training=False, return_covmat=False):\n    # Gets logits and a covariance matrix from the GP layer.\n    logits, covmat = super().call(inputs)\n\n    # Returns only logits during training.\n    if not training and return_covmat:\n      return logits, covmat\n\n    return logits\n```\n\n----------------------------------------\n\nTITLE: Running Test Function with Constant Folding Enabled\nDESCRIPTION: This code executes the test function with constant folding optimization turned on, measuring and displaying the execution time with optimization for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith options({'constant_folding': True}):\n  print(tf.config.optimizer.get_experimental_options())\n  simple_function = test_function_1()\n  # Trace once\n  x = tf.constant(2.2)\n  simple_function(x)\n  print(\"Constant folded execution:\", timeit.timeit(lambda: simple_function(x), number = 1), \"s\")\n```\n\n----------------------------------------\n\nTITLE: Generating predictions with the reloaded model\nDESCRIPTION: Makes predictions with the reloaded model, extracts class IDs, and maps them to class names to verify the reloaded model works correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nreloaded_predicted_id = tf.math.argmax(reloaded_result_batch, axis=-1)\nreloaded_predicted_label_batch = class_names[reloaded_predicted_id]\nprint(reloaded_predicted_label_batch)\n```\n\n----------------------------------------\n\nTITLE: Debugging Keras Custom Model with Eager Execution\nDESCRIPTION: Example demonstrating how to debug a custom Keras model using eager execution and pdb debugger. Shows implementation of conditional logic in the model's call method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModel(tf.keras.models.Model):\n\n  @tf.function\n  def call(self, input_data):\n    if tf.reduce_mean(input_data) > 0:\n      return input_data\n    else:\n      import pdb\n      pdb.set_trace()\n      return input_data // 2\n\n\ntf.config.run_functions_eagerly(True)\nmodel = CustomModel()\nmodel(tf.constant([-2, -4]))\n```\n\n----------------------------------------\n\nTITLE: Inspecting Dataset Structure with element_spec\nDESCRIPTION: Creates a dataset from random uniform tensors and inspects its structure using the element_spec property, which provides information about the shape and type of each element.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n\ndataset1.element_spec\n```\n\n----------------------------------------\n\nTITLE: Implementing Top-K Predictions Function for Image Classification\nDESCRIPTION: Defines a function to get the top K predicted labels and their probabilities for a given image using the loaded Inception V1 model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef top_k_predictions(img, k=3):\n  image_batch = tf.expand_dims(img, 0)\n  predictions = model(image_batch)\n  probs = tf.nn.softmax(predictions, axis=-1)\n  top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n  top_labels = imagenet_labels[tuple(top_idxs)]\n  return top_labels, top_probs[0]\n```\n\n----------------------------------------\n\nTITLE: Creating CSV Dataset in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a CSV dataset using tf.data.experimental.make_csv_dataset, specifying batch size and label column.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_45\n\nLANGUAGE: python\nCODE:\n```\ntitanic_batches = tf.data.experimental.make_csv_dataset(\n    titanic_file, batch_size=4,\n    label_name=\"survived\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Training Components\nDESCRIPTION: Sets up loss function, optimizer, and metrics for model training and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer = tf.keras.optimizers.Adam()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n```\n\n----------------------------------------\n\nTITLE: Creating an ImageDataGenerator in TensorFlow\nDESCRIPTION: This snippet creates an ImageDataGenerator for data augmentation, specifying rescaling and rotation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nimg_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Available Traces with pretty_printed_concrete_signatures\nDESCRIPTION: Shows how to view all available traces that have been created for a tf.function using the pretty_printed_concrete_signatures method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(double.pretty_printed_concrete_signatures())\n```\n\n----------------------------------------\n\nTITLE: Combining L2 Regularization and Dropout in TensorFlow Keras\nDESCRIPTION: This snippet demonstrates how to combine L2 regularization and dropout in a single model. It applies L2 regularization with a penalty of 0.0001 to each Dense layer and adds a dropout layer with a rate of 0.5 after each Dense layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: Python\nCODE:\n```\ncombined_model = tf.keras.Sequential([\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu', input_shape=(FEATURES,)),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(1)\n])\n\nregularizer_histories['combined'] = compile_and_fit(combined_model, \"regularizers/combined\")\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Flowers Dataset for Augmentation Examples\nDESCRIPTION: Loads the TensorFlow Flowers dataset with train/validation/test splits for demonstrating image augmentation techniques. The data is loaded with supervision information and metadata for later access to class names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n(train_ds, val_ds, test_ds), metadata = tfds.load(\n    'tf_flowers',\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n    with_info=True,\n    as_supervised=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up BigBiGAN Tensors in TensorFlow\nDESCRIPTION: Creates tensors for samples, reconstructions, discriminator scores and loss computations using the BigBiGAN class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbigbigan = BigBiGAN(module)\n\n# Make input placeholders for x (`enc_ph`) and z (`gen_ph`).\nenc_ph = bigbigan.make_encoder_ph()\ngen_ph = bigbigan.make_generator_ph()\n\n# Compute samples G(z) from encoder input z (`gen_ph`).\ngen_samples = bigbigan.generate(gen_ph)\n\n# Compute reconstructions G(E(x)) of encoder input x (`enc_ph`).\nrecon_x = bigbigan.reconstruct_x(enc_ph, upsample=True)\n\n# Compute encoder features used for representation learning evaluations given\n# encoder input x (`enc_ph`).\nenc_features = bigbigan.encode(enc_ph, return_all_features=True)\n\n# Compute discriminator scores for encoder pairs (x, E(x)) given x (`enc_ph`)\n# and generator pairs (G(z), z) given z (`gen_ph`).\ndisc_scores_enc = bigbigan.discriminate(*bigbigan.enc_pairs_for_disc(enc_ph))\ndisc_scores_gen = bigbigan.discriminate(*bigbigan.gen_pairs_for_disc(gen_ph))\n\n# Compute losses.\nlosses = bigbigan.losses(enc_ph, gen_ph)\n```\n\n----------------------------------------\n\nTITLE: Checking Validation Performance Metrics\nDESCRIPTION: Displays the validation performance metrics for all implemented models to enable direct comparison of their effectiveness on the time series task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nval_performance\n```\n\n----------------------------------------\n\nTITLE: Creating a Reusable Model Compilation and Training Function\nDESCRIPTION: Defines a function that handles model compilation and training with standardized settings. It configures the optimizer, loss function, metrics, and implements the fit method with appropriate callbacks and data mappings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef compile_and_fit(model, name, optimizer=None, max_epochs=10000):\n  if optimizer is None:\n    optimizer = get_optimizer()\n  model.compile(optimizer=optimizer,\n                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                metrics=[\n                  tf.keras.metrics.BinaryCrossentropy(\n                      from_logits=True, name='binary_crossentropy'),\n                  'accuracy'])\n\n  model.summary()\n\n  history = model.fit(\n    train_ds.map(lambda x, y: (x, tf.expand_dims(y, axis=-1))),\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs=max_epochs,\n    validation_data=validate_ds.map(lambda x, y: (x, tf.expand_dims(y, axis=-1))),\n    callbacks=get_callbacks(name),\n    verbose=0)\n  return history\n```\n\n----------------------------------------\n\nTITLE: Dereferencing Tensor References in TF2\nDESCRIPTION: Demonstrates how to retrieve the original tensor or variable from a reference using the .deref() method in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nreferenced_var = x.ref().deref()\nassert referenced_var is x\nreferenced_var\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Print Behavior in tf.function Graph Execution in Python\nDESCRIPTION: Illustrates how print statements behave differently in graph execution compared to eager execution when using tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef get_MSE(y_true, y_pred):\n  print(\"Calculating MSE!\")\n  sq_diff = tf.pow(y_true - y_pred, 2)\n  return tf.reduce_mean(sq_diff)\n\nerror = get_MSE(y_true, y_pred)\nerror = get_MSE(y_true, y_pred)\nerror = get_MSE(y_true, y_pred)\n\n# Now, globally set everything to run eagerly to force eager execution.\ntf.config.run_functions_eagerly(True)\n\n# Observe what is printed below.\nerror = get_MSE(y_true, y_pred)\nerror = get_MSE(y_true, y_pred)\nerror = get_MSE(y_true, y_pred)\n\ntf.config.run_functions_eagerly(False)\n```\n\n----------------------------------------\n\nTITLE: Implementing Keras Model with MirroredStrategy\nDESCRIPTION: Demonstrates how to create and compile a simple Keras model within a MirroredStrategy scope for multi-GPU training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\nwith mirrored_strategy.scope():\n  model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n  model.compile(loss='mse', optimizer='sgd')\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing MNIST Dataset for Training\nDESCRIPTION: Loads the MNIST dataset, normalizes pixel values, applies one-hot encoding to labels, and creates TensorFlow data pipelines for training and testing with appropriate batching and shuffling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(x_train, train_labels), (x_test, test_labels) = tf.keras.datasets.mnist.load_data()\n\ntrain_data = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\ntrain_data = train_data.map(lambda x,y: (tf.expand_dims(tf.cast(x, tf.float32)/255.0, axis=-1),\n                                         tf.one_hot(y, depth=10)))\n\nBATCH_SIZE = 256\ntrain_data = train_data.batch(BATCH_SIZE, drop_remainder=True)\ntrain_data = train_data.cache()\ntrain_data = train_data.shuffle(5000, reshuffle_each_iteration=True)\n\ntest_data = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\ntest_data = test_data.map(lambda x,y: (tf.expand_dims(tf.cast(x, tf.float32)/255.0, axis=-1),\n                                         tf.one_hot(y, depth=10)))\ntest_data = test_data.batch(10000)\ntest_data = test_data.cache()\n\n(one_batch, one_batch_labels) = next(iter(train_data)) # just one batch\n(all_test_data, all_test_labels) = next(iter(test_data)) # all in one batch since batch size is 10000\n```\n\n----------------------------------------\n\nTITLE: Checking Processed Headlines Data\nDESCRIPTION: Displays the last few lines of the processed text file to verify the data extraction worked correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n!tail corpus/text.txt\n```\n\n----------------------------------------\n\nTITLE: Running Frame Interpolation on Input Images in Python\nDESCRIPTION: Example code that demonstrates how to use the interpolate_recursively function to generate intermediate frames between two input images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ninput_frames = [image1, image2]\nframes = list(\n    interpolate_recursively(input_frames, times_to_interpolate,\n                                        interpolator))\n```\n\n----------------------------------------\n\nTITLE: Preparing Dataset Batches for Training\nDESCRIPTION: Shuffles and batches a dataset to prepare it for model training, which is essential for stochastic gradient descent optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ntitanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)\n```\n\n----------------------------------------\n\nTITLE: Building a Video Classification Model with TensorFlow\nDESCRIPTION: This code snippet demonstrates how to create and train a video classification model using TensorFlow. It uses a pre-trained EfficientNetB0 as a feature extractor and adds custom layers for video classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nnet = tf.keras.applications.EfficientNetB0(include_top = False)\nnet.trainable = False\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Rescaling(scale=255),\n    tf.keras.layers.TimeDistributed(net),\n    tf.keras.layers.Dense(10),\n    tf.keras.layers.GlobalAveragePooling3D()\n])\n\nmodel.compile(optimizer = 'adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n              metrics=['accuracy'])\n\nmodel.fit(train_ds, \n          epochs = 10,\n          validation_data = val_ds,\n          callbacks = tf.keras.callbacks.EarlyStopping(patience = 2, monitor = 'val_loss'))\n```\n\n----------------------------------------\n\nTITLE: Defining embedding ID column in TF1\nDESCRIPTION: This code snippet defines an embedding ID column using `tf1.feature_column.categorical_column_with_identity`. It creates a categorical feature column that maps integer inputs to categorical IDs. The `key` parameter is set to `\"sparse_feature\"`, indicating that the input features are integer-valued, and `num_buckets` is set to 10, representing the vocabulary size for the embedding table.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nembedding_id_column = (\n      tf1.feature_column.categorical_column_with_identity(\n          key=\"sparse_feature\", num_buckets=10))\n```\n\n----------------------------------------\n\nTITLE: Evaluating MoViNet Model on Test Set in TensorFlow\nDESCRIPTION: This snippet shows how to evaluate the trained MoViNet model on the test dataset using the evaluate method, returning the results as a dictionary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(test_ds, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: License Definition in Python\nDESCRIPTION: License declaration for the TensorFlow documentation under Apache License 2.0, included as a Python comment block.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Compiling the model with optimizer and loss function\nDESCRIPTION: Configures the model for training by specifying the optimizer, loss function, and metrics. Also sets up TensorBoard logging callbacks to track training progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n  optimizer=tf.keras.optimizers.Adam(),\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])\n\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n    log_dir=log_dir,\n    histogram_freq=1) # Enable histogram computation for every epoch.\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Models with Checkpoints in TensorFlow\nDESCRIPTION: This snippet shows how to use tf.train.Checkpoint to save and load entire models, including the optimizer state and global step. It demonstrates creating a model and optimizer, saving them to a checkpoint, and then restoring them.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport tempfile\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(10)\n])\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001)\ncheckpoint_dir = tempfile.mkdtemp()\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\nroot = tf.train.Checkpoint(optimizer=optimizer,\n                           model=model,\n                           optimizer_step=tf.train.get_or_create_global_step())\n\nroot.save(checkpoint_prefix)\nroot.restore(tf.train.latest_checkpoint(checkpoint_dir))\n```\n\n----------------------------------------\n\nTITLE: Setting Up License Information in Python\nDESCRIPTION: A code block containing the Apache License 2.0 information as a Python comment. This serves as the license header for the tutorial file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Custom Gradients in SavedModel\nDESCRIPTION: Demonstrates how to save and load a model with custom gradients using tf.saved_model with the experimental_custom_gradients option, which preserves the custom gradient behavior after loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass MyModule(tf.Module):\n\n  @tf.function(input_signature=[tf.TensorSpec(None)])\n  def call_custom_grad(self, x):\n    return clip_gradients(x)\n\nmodel = MyModule()\n```\n\nLANGUAGE: python\nCODE:\n```\ntf.saved_model.save(\n    model,\n    'saved_model',\n    options=tf.saved_model.SaveOptions(experimental_custom_gradients=True))\n\n# The loaded gradients will be the same as the above example.\nv = tf.Variable(2.0)\nloaded = tf.saved_model.load('saved_model')\nwith tf.GradientTape() as t:\n  output = loaded.call_custom_grad(v * v)\nprint(t.gradient(output, v))\n```\n\n----------------------------------------\n\nTITLE: Converting Logits to Probabilities\nDESCRIPTION: Applies softmax function to convert model logits into probability distributions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntf.nn.softmax(predictions).numpy()\n```\n\n----------------------------------------\n\nTITLE: Using DumpingDebugWrapperSession for TensorFlow Debugging\nDESCRIPTION: This Python code snippet wraps a standard TensorFlow session with `DumpingDebugWrapperSession` to generate filesystem dumps for analysis. The watch_fn function parameter allows customization of tensor watching. Dependencies include TensorFlow and tfdbg.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python import debug as tf_debug\n\nsess = tf_debug.DumpingDebugWrapperSession(\n    sess, \"/shared/storage/location/tfdbg_dumps_1/\", watch_fn=my_watch_fn)\n```\n\n----------------------------------------\n\nTITLE: Implementing Token Generation Function in TensorFlow\nDESCRIPTION: Defines a function that performs one step of text generation by feeding token inputs and memory states to the language model and obtaining output probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n#@title Construct the per-token generation graph\ndef feedforward_step(module, inputs, mems):\n  \"\"\"Generate one step.\"\"\"\n  # Set up the input dict for one step of generation\n  inputs = tf.dtypes.cast(inputs, tf.int64)\n  generation_input_dict = dict(input_tokens=inputs)\n  mems_dict = {\"mem_{}\".format(i): mems[i] for i in range(n_layer)}\n  generation_input_dict.update(mems_dict)\n\n  # Generate the tokens from the language model\n  generation_outputs = module(generation_input_dict, signature=\"prediction\", as_dict=True)\n\n  # Get the probabilities and the inputs for the next steps\n  probs = generation_outputs[\"probs\"]\n  new_mems = [generation_outputs[\"new_mem_{}\".format(i)] for i in range(n_layer)]\n\n  return probs, new_mems\n\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Multi-Step Dense Model\nDESCRIPTION: Compiles, trains, and evaluates the multi-step dense model using the configured window generator, storing performance metrics for validation and test datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nhistory = compile_and_fit(multi_step_dense, conv_window)\n\nIPython.display.clear_output()\nval_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val, return_dict=True)\nperformance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing 1D Convolutional Neural Network for Time Series\nDESCRIPTION: Creates a sequential model using Conv1D for time series prediction. This model can process multiple time steps to make predictions while maintaining flexibility with input sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nconv_model = tf.keras.Sequential([\n    tf.keras.layers.Conv1D(filters=32,\n                           kernel_size=(CONV_WIDTH,),\n                           activation='relu'),\n    tf.keras.layers.Dense(units=32, activation='relu'),\n    tf.keras.layers.Dense(units=1),\n])\n```\n\n----------------------------------------\n\nTITLE: Restoring Checkpoints and Evaluating Model in TensorFlow\nDESCRIPTION: Demonstrates how to restore a model from a checkpoint and evaluate its accuracy. This code creates a new model, optimizer, and dataset, then restores the latest checkpoint and performs evaluation steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\neval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='eval_accuracy')\n\nnew_model = create_model()\nnew_optimizer = tf.keras.optimizers.Adam()\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n\n@tf.function\ndef eval_step(images, labels):\n  predictions = new_model(images, training=False)\n  eval_accuracy(labels, predictions)\n\ncheckpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n\nfor images, labels in test_dataset:\n  eval_step(images, labels)\n\nprint('Accuracy after restoring the saved model without strategy: {}'.format(\n    eval_accuracy.result() * 100))\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Preprocessing for CSV Data in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the Normalization layer in Keras to preprocess numeric data from a CSV file before feeding it into a TensorFlow model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nnormalize = layers.Normalization()\nnormalize.adapt(abalone_features)\n\nnorm_abalone_model = tf.keras.Sequential([\n  normalize,\n  layers.Dense(64, activation='relu'),\n  layers.Dense(1)\n])\n\nnorm_abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n                           optimizer = tf.keras.optimizers.Adam())\n\nnorm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Training a Model with the Custom Dataset\nDESCRIPTION: Fits the model using the manually created dataset for training and validation. This demonstrates using a custom tf.data pipeline with model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)\n```\n\n----------------------------------------\n\nTITLE: Performing Object Detection Inference\nDESCRIPTION: This code performs object detection inference on the loaded image using the selected TensorFlow Hub model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# running inference\nresults = hub_model(image_np)\n\n# different object detection models have additional results\n# all of them are explained in the documentation\nresult = {key:value.numpy() for key,value in results.items()}\nprint(result.keys())\n```\n\n----------------------------------------\n\nTITLE: Setting Up Training Parameters\nDESCRIPTION: Defines constants for the input pipeline including buffer size, batch sizes (per replica and global), and the number of training epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = len(train_images)\n\nBATCH_SIZE_PER_REPLICA = 64\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\nEPOCHS = 10\n```\n\n----------------------------------------\n\nTITLE: Resampling Audio Waveform for YAMNet Input in Python\nDESCRIPTION: This function ensures the audio sample rate is 16kHz, which is required for the YAMNet model. It resamples the waveform if necessary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef ensure_sample_rate(original_sample_rate, waveform,\n                       desired_sample_rate=16000):\n  \"\"\"Resample waveform if required.\"\"\"\n  if original_sample_rate != desired_sample_rate:\n    desired_length = int(round(float(len(waveform)) /\n                               original_sample_rate * desired_sample_rate))\n    waveform = scipy.signal.resample(waveform, desired_length)\n  return desired_sample_rate, waveform\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST dataset from .npz file\nDESCRIPTION: Downloads and loads the MNIST dataset from a remote .npz file using TensorFlow's utility function. The data is extracted into training and testing examples and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nDATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n\npath = tf.keras.utils.get_file('mnist.npz', DATA_URL)\nwith np.load(path) as data:\n  train_examples = data['x_train']\n  train_labels = data['y_train']\n  test_examples = data['x_test']\n  test_labels = data['y_test']\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Images using MobileNetV2 preprocess_input in TensorFlow\nDESCRIPTION: Uses the built-in preprocessing function from MobileNetV2 to rescale pixel values from [0, 255] to [-1, 1], which is the expected input range for the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n```\n\n----------------------------------------\n\nTITLE: Randomly Changing Image Contrast with Stateless Operations\nDESCRIPTION: Shows how to apply random contrast changes using tf.image.stateless_random_contrast. Multiple examples with different seeds demonstrate how the operation produces consistent outputs for the same seed values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(3):\n  seed = (i, 0)  # tuple of size (2,)\n  stateless_random_contrast = tf.image.stateless_random_contrast(\n      image, lower=0.1, upper=0.9, seed=seed)\n  visualize(image, stateless_random_contrast)\n```\n\n----------------------------------------\n\nTITLE: Processing Input Tensors for Handwriting Recognition in TensorFlow\nDESCRIPTION: This snippet demonstrates how to obtain input features from a features dictionary, create a tensor for input sequence lengths, and reshape the ink data into a dense tensor. It also handles optional target data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nshapes = features[\"shape\"]\nlengths = tf.squeeze(\n    tf.slice(shapes, begin=[0, 0], size=[params[\"batch_size\"], 1]))\ninks = tf.reshape(\n    tf.sparse_tensor_to_dense(features[\"ink\"]),\n    [params[\"batch_size\"], -1, 3])\nif targets is not None:\n  targets = tf.squeeze(targets)\n```\n\n----------------------------------------\n\nTITLE: Creating Artificial Dataset Class in TensorFlow\nDESCRIPTION: Implementation of a custom dataset class that inherits from tf.data.Dataset to simulate data loading delays.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass ArtificialDataset(tf.data.Dataset):\n    def _generator(num_samples):\n        # Opening the file\n        time.sleep(0.03)\n        \n        for sample_idx in range(num_samples):\n            # Reading data (line, record) from the file\n            time.sleep(0.015)\n            \n            yield (sample_idx,)\n    \n    def __new__(cls, num_samples=3):\n        return tf.data.Dataset.from_generator(\n            cls._generator,\n            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n            args=(num_samples,)\n        )\n```\n\n----------------------------------------\n\nTITLE: Saving Generator in MirroredStrategy with Checkpoint\nDESCRIPTION: Creates a random number generator within a distribution strategy scope and prepares to checkpoint its state, ensuring each replica has its own deterministic random stream.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfilename = \"./checkpoint\"\nstrat = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat.scope():\n  g = tf.random.Generator.from_seed(1)\n  cp = tf.train.Checkpoint(my_generator=g)\n  print(strat.run(lambda: g.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Training Loop with tf.GradientTape in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a custom training loop with a sequential model, implementing the three standard steps: iterating over data batches, collecting gradients with tf.GradientTape, and applying weight updates with an optimizer. It also handles regularization losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, 3, activation='relu',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n                           input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10)\n])\n\noptimizer = tf.keras.optimizers.Adam(0.001)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n@tf.function\ndef train_step(inputs, labels):\n  with tf.GradientTape() as tape:\n    predictions = model(inputs, training=True)\n    regularization_loss=tf.math.add_n(model.losses)\n    pred_loss=loss_fn(labels, predictions)\n    total_loss=pred_loss + regularization_loss\n\n  gradients = tape.gradient(total_loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\nfor epoch in range(NUM_EPOCHS):\n  for inputs, labels in train_data:\n    train_step(inputs, labels)\n  print(\"Finished epoch\", epoch)\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow and Required Libraries for Integrated Gradients\nDESCRIPTION: Imports necessary libraries including TensorFlow, TensorFlow Hub, matplotlib, and numpy for implementing Integrated Gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pylab as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function and Trainer for MNIST Compression in TensorFlow\nDESCRIPTION: This snippet defines a pass-through loss function and creates a function to make an MNIST compression trainer. The trainer is compiled with an Adam optimizer and uses the rate-distortion Lagrangian as the loss function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef pass_through_loss(_, x):\n  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n  return x\n\ndef make_mnist_compression_trainer(lmbda, latent_dims=50):\n  trainer = MNISTCompressionTrainer(latent_dims)\n  trainer.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    # Just pass through rate and distortion as losses/metrics.\n    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n    loss_weights=dict(rate=1., distortion=lmbda),\n  )\n  return trainer\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Text Standardization Function in Python for TensorFlow\nDESCRIPTION: A custom standardization function that preprocesses text by converting to lowercase, removing HTML tags like <br />, and stripping punctuation. This function is designed to be used with TensorFlow's TextVectorization layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef custom_standardization(input_data):\n  lowercase = tf.strings.lower(input_data)\n  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n  return tf.strings.regex_replace(stripped_html,\n                                  '[%s]' % re.escape(string.punctuation),\n                                  '')\n```\n\n----------------------------------------\n\nTITLE: Generating Multilingual Text with TensorFlow\nDESCRIPTION: This code generates text based on a given seed using a pre-trained model. It runs the model within a TensorFlow session and retrieves various outputs including embeddings, log likelihood, perplexity, activations, token IDs, and the generated text.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nwith session.as_default():\n  results = session.run([embeddings, neg_log_likelihood, ppl, activations, token_ids, generated_text], feed_dict={text: [seed]})\n  embeddings_result, neg_log_likelihood_result, ppl_result, activations_result, token_ids_result, generated_text_result = results\n  generated_text_output = generated_text_result[0].decode('utf-8')\n\nprint(generated_text_output)\n```\n\n----------------------------------------\n\nTITLE: Text Vectorization Layer Setup\nDESCRIPTION: Creates and configures a TextVectorization layer for preprocessing text data with specified vocabulary size and sequence length.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nvectorize_layer = TextVectorization(\n    max_tokens=VOCAB_SIZE,\n    output_mode='int',\n    output_sequence_length=MAX_SEQUENCE_LENGTH)\n\ntrain_text = train_ds.map(lambda text, labels: text)\nvectorize_layer.adapt(train_text)\n```\n\n----------------------------------------\n\nTITLE: Creating Vector and Matrix Feature Columns\nDESCRIPTION: Demonstrates creating numeric feature columns for vector and matrix inputs with specific shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Represent a 10-element vector in which each cell contains a tf.float32.\nvector_feature_column = tf.feature_column.numeric_column(key=\"Bowling\",\n                                                         shape=10)\n\n# Represent a 10x5 matrix in which each cell contains a tf.float32.\nmatrix_feature_column = tf.feature_column.numeric_column(key=\"MyMatrix\",\n                                                         shape=[10,5])\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Step Function\nDESCRIPTION: Defines the training step using tf.GradientTape for automatic differentiation and gradient-based optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(images, labels):\n  with tf.GradientTape() as tape:\n    predictions = model(images, training=True)\n    loss = loss_object(labels, predictions)\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n  train_loss(loss)\n  train_accuracy(labels, predictions)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Keras Model with BackupAndRestore Callback\nDESCRIPTION: Defining and compiling a Keras model for MNIST classification and configuring the BackupAndRestore callback to enable fault tolerance at epoch boundaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  return tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10)\n  ])\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss=loss,\n              metrics=['accuracy'])\nlog_dir = tempfile.mkdtemp()\nbackup_restore_callback = tf.keras.callbacks.BackupAndRestore(\n    backup_dir = log_dir)\n```\n\n----------------------------------------\n\nTITLE: Complete Image Processing Pipeline Function\nDESCRIPTION: Combines label extraction and image processing into a single function that converts a file path to an (image, label) pair. This function is used with Dataset.map().\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef process_path(file_path):\n  label = get_label(file_path)\n  # Load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n```\n\n----------------------------------------\n\nTITLE: Loading Mixed Data Types from CSV for TensorFlow Processing\nDESCRIPTION: This code loads the Titanic dataset, which contains mixed data types, into a pandas DataFrame and separates features and labels, demonstrating how to handle more complex CSV data in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntitanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\ntitanic.head()\n\ntitanic_features = titanic.copy()\ntitanic_labels = titanic_features.pop('survived')\n```\n\n----------------------------------------\n\nTITLE: Listing TensorFlow Devices\nDESCRIPTION: Shows how to list available physical and logical devices in TensorFlow, and how to get a GPU device if available or fall back to CPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nprint(\"All logical devices:\", tf.config.list_logical_devices())\nprint(\"All physical devices:\", tf.config.list_physical_devices())\n\n# Try to get the GPU device. If unavailable, fallback to CPU.\ntry:\n  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\nexcept IndexError:\n  device = \"/device:CPU:0\"\n```\n\n----------------------------------------\n\nTITLE: TPU CrossShardOptimizer Implementation\nDESCRIPTION: Shows how to wrap the optimizer for TPU compatibility using CrossShardOptimizer while maintaining local training capability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\nif FLAGS.use_tpu:\n  optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n```\n\n----------------------------------------\n\nTITLE: Training Converted Model in TensorFlow\nDESCRIPTION: Implementation of training loop for continuing model training in TensorFlow after JAX conversion, including optimizer setup, gradient calculation, and progress tracking.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.keras.optimizers.Adam(learning_rate=tflr_decay)\n\n# Set the iteration step for the learning rate to resume from where it left off in JAX.\noptimizer.iterations.assign(len(eval_losses)*STEPS_PER_EPOCH)\n\np = Progress(STEPS_PER_EPOCH)\n\nfor epoch in range(JAX_EPOCHS, JAX_EPOCHS+TF_EPOCHS):\n\n  # This is where the learning rate schedule state is stored in the optimizer state.\n  optimizer_step = optimizer.iterations\n\n  for step, (data, labels) in enumerate(train_data):\n    p.step(reset=(step==0))\n    with tf.GradientTape() as tape:\n      #loss = reloaded_model.loss(data, labels, True)\n      loss = reloaded_model.train_loss(data, labels)\n      grads = tape.gradient(loss, reloaded_model.vars)\n      optimizer.apply_gradients(zip(grads, reloaded_model.vars))\n      losses.append(loss)\n  avg_loss = np.mean(losses[-step:])\n  avg_losses.append(avg_loss)\n\n  eval_loss = reloaded_model.eval_loss(all_test_data.numpy(), all_test_labels.numpy()).numpy()\n  eval_losses.append(eval_loss)\n  eval_accuracy = reloaded_model.accuracy(all_test_data.numpy(), all_test_labels.numpy()).numpy()\n  eval_accuracies.append(eval_accuracy)\n\n  print(\"\\nEpoch\", epoch, \"train loss:\", avg_loss, \"eval loss:\", eval_loss, \"eval accuracy\", eval_accuracy, \"lr:\", tflr_decay(optimizer.iterations).numpy())\n```\n\n----------------------------------------\n\nTITLE: CPU-Based Preprocessing Setup in TensorFlow\nDESCRIPTION: This Python snippet shows how to place preprocessing operations on a CPU using 'tf.device()' context manager, which frees up GPU resources for model training. The suggested setup is useful for optimizing input pipelines in TensorFlow workflows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device('/cpu:0'):\n  # function to get and process images or data.\n  distorted_inputs = load_and_distort_images()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Text-to-Video Retrieval in Python\nDESCRIPTION: This snippet imports necessary libraries including TensorFlow, TensorFlow Hub, NumPy, OpenCV, and IPython display for text-to-video retrieval tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q opencv-python\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_hub as hub\n\nimport numpy as np\nimport cv2\nfrom IPython import display\nimport math\n```\n\n----------------------------------------\n\nTITLE: Running a Function on All TPU Cores with Distribution Strategy\nDESCRIPTION: Demonstrates how to use the TPU strategy's run method to execute a matrix multiplication function across all TPU cores simultaneously with the same inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef matmul_fn(x, y):\n  z = tf.matmul(x, y)\n  return z\n\nz = strategy.run(matmul_fn, args=(a, b))\nprint(z)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating MNIST Model\nDESCRIPTION: Trains the model on the training data for 5 epochs and evaluates performance on the test dataset to measure accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/_index.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(x_train, y_train, epochs=5)\n\nmodel.evaluate(x_test,  y_test, verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Checking Version in Python\nDESCRIPTION: This snippet imports TensorFlow and prints its version to verify the installation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Instantiating a DNNClassifier Estimator\nDESCRIPTION: Creates a Deep Neural Network classifier with specified hidden layers and output classes for the Iris classification problem.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    # Two hidden layers of 30 and 10 nodes respectively.\n    hidden_units=[30, 10],\n    # The model must choose between 3 classes.\n    n_classes=3)\n```\n\n----------------------------------------\n\nTITLE: Initializing TextVectorization Layer for Binary Mode in TensorFlow\nDESCRIPTION: Creates a TextVectorization layer with binary output mode and a maximum vocabulary size of 10000 tokens.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nVOCAB_SIZE = 10000\n\nbinary_vectorize_layer = TextVectorization(\n    max_tokens=VOCAB_SIZE,\n    output_mode='binary')\n```\n\n----------------------------------------\n\nTITLE: Converting an Image to Grayscale with tf.image\nDESCRIPTION: Shows how to convert a color image to grayscale using tf.image.rgb_to_grayscale. The example includes visualization with a color bar to illustrate the grayscale intensity values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ngrayscaled = tf.image.rgb_to_grayscale(image)\nvisualize(image, tf.squeeze(grayscaled))\n_ = plt.colorbar()\n```\n\n----------------------------------------\n\nTITLE: Initializing Model Bias for Imbalanced Dataset in Python\nDESCRIPTION: This snippet demonstrates how to set the correct initial bias for the output layer to account for class imbalance. It calculates the bias based on the ratio of positive to negative samples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ninitial_bias = np.log([pos/neg])\ninitial_bias\n```\n\n----------------------------------------\n\nTITLE: Setting Up Sequence Parameters and Creating Dataset in Python\nDESCRIPTION: Configures the sequence length and vocabulary size, then calls the create_sequences function to prepare the dataset for training the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nseq_length = 25\nvocab_size = 128\nseq_ds = create_sequences(notes_ds, seq_length, vocab_size)\nseq_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Linear Time Series Model\nDESCRIPTION: Trains the linear model using the compile_and_fit utility function and evaluates its performance on validation and test datasets, storing results for comparison with the baseline model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nhistory = compile_and_fit(linear, single_step_window)\n\nval_performance['Linear'] = linear.evaluate(single_step_window.val, return_dict=True)\nperformance['Linear'] = linear.evaluate(single_step_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Optimizing Performance with Multi-step Function in TensorFlow\nDESCRIPTION: Shows how to pack multiple training steps into a single tf.function to improve performance when using ParameterServerStrategy with a custom training loop.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nsteps_per_invocation = 10\n\n@tf.function\ndef step_fn(iterator):\n  for _ in range(steps_per_invocation):\n    features, labels = next(iterator)\n    def replica_fn(features, labels):\n      ...\n\n    strategy.run(replica_fn, args=(features, labels))\n```\n\n----------------------------------------\n\nTITLE: Using Transformer Encoder Preprocessor with Keras Layers\nDESCRIPTION: Shows how to integrate the tokenization and packing steps of a Transformer encoder preprocessor into a Keras model using KerasLayer wrappers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntokenize = hub.KerasLayer(preprocessor.tokenize)\ntokenized_hypotheses = tokenize(text_hypotheses)\ntokenized_premises = tokenize(text_premises)\n\nbert_pack_inputs = hub.KerasLayer(\n    preprocessor.bert_pack_inputs,\n    arguments=dict(seq_length=seq_length))  # Optional argument.\nencoder_inputs = bert_pack_inputs([tokenized_premises, tokenized_hypotheses])\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Variables\nDESCRIPTION: Demonstrates creating a TensorFlow Variable to store mutable state with initial values set to zeros.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nvar = tf.Variable([0.0, 0.0, 0.0])\n```\n\n----------------------------------------\n\nTITLE: Creating Ragged Tensors with tf.ragged.constant\nDESCRIPTION: Shows how to create ragged tensors directly from nested Python lists using tf.ragged.constant, with examples of sentence and paragraph structures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsentences = tf.ragged.constant([\n    [\"Let's\", \"build\", \"some\", \"ragged\", \"tensors\", \"!\"],\n    [\"We\", \"can\", \"use\", \"tf.ragged.constant\", \".\"]])\nprint(sentences)\n```\n\nLANGUAGE: python\nCODE:\n```\nparagraphs = tf.ragged.constant([\n    [['I', 'have', 'a', 'cat'], ['His', 'name', 'is', 'Mat']],\n    [['Do', 'you', 'want', 'to', 'come', 'visit'], [\"I'm\", 'free', 'tomorrow']],\n])\nprint(paragraphs)\n```\n\n----------------------------------------\n\nTITLE: Mapping the pack_features_vector function to the dataset\nDESCRIPTION: This snippet applies the pack_features_vector function to each element in the training dataset using the tf.data.Dataset.map method. This transforms the dataset to contain feature arrays instead of feature dictionaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = train_dataset.map(pack_features_vector)\n```\n\n----------------------------------------\n\nTITLE: Saving a TensorFlow Model in HDF5 Format\nDESCRIPTION: Creates, trains, and saves a TensorFlow model in the legacy HDF5 (.h5) format, which stores the model architecture, weights, training configuration, and optimizer state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# Create and train a new model instance.\nmodel = create_model()\nmodel.fit(train_images, train_labels, epochs=5)\n\n# Save the entire model to a HDF5 file.\n# The '.h5' extension indicates that the model should be saved to HDF5.\nmodel.save('my_model.h5')\n```\n\n----------------------------------------\n\nTITLE: Loading MoViNet Streaming Model from TensorFlow Hub\nDESCRIPTION: Loads the streaming version of a MoViNet model from TensorFlow Hub. It specifies the model ID, mode, version, and constructs the hub URL.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%%time\nid = 'a2'\nmode = 'stream'\nversion = '3'\nhub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\nmodel = hub.load(hub_url)\n```\n\n----------------------------------------\n\nTITLE: Computing Jacobian for Tensor Source in TensorFlow\nDESCRIPTION: This code calculates the Jacobian of a dense layer's output with respect to its kernel. It demonstrates how the shape of the Jacobian relates to the shapes of the input and output tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.normal([7, 5])\nlayer = tf.keras.layers.Dense(10, activation=tf.nn.relu)\n\nwith tf.GradientTape(persistent=True) as tape:\n  y = layer(x)\n\nj = tape.jacobian(y, layer.kernel)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Building MoViNet Model in TensorFlow\nDESCRIPTION: This snippet shows how to download a pre-trained MoViNet model, build a classifier using the model, and load pre-trained weights. It uses the 'a0' configuration and sets up the model for fine-tuning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel_id = 'a0'\nresolution = 224\n\ntf.keras.backend.clear_session()\n\nbackbone = movinet.Movinet(model_id=model_id)\nbackbone.trainable = False\n\n# Set num_classes=600 to load the pre-trained weights from the original model\nmodel = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\nmodel.build([None, None, None, None, 3])\n\n# Load pre-trained weights\n!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n!tar -xvf movinet_a0_base.tar.gz\n\ncheckpoint_dir = f'movinet_{model_id}_base'\ncheckpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\ncheckpoint = tf.train.Checkpoint(model=model)\nstatus = checkpoint.restore(checkpoint_path)\nstatus.assert_existing_objects_matched()\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Jitter for Image Augmentation\nDESCRIPTION: Creates a function to apply random jittering to images, which includes resizing to 286x286, random cropping to 256x256, and random horizontal flipping. This helps prevent overfitting in the CycleGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef random_jitter(image):\n  # resizing to 286 x 286 x 3\n  image = tf.image.resize(image, [286, 286],\n                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n  # randomly cropping to 256 x 256 x 3\n  image = random_crop(image)\n\n  # random mirroring\n  image = tf.image.random_flip_left_right(image)\n\n  return image\n```\n\n----------------------------------------\n\nTITLE: Creating a Sharded Input Function for MNIST Dataset\nDESCRIPTION: Defines an input function that loads the MNIST dataset and applies appropriate preprocessing. The function shards the data across workers to ensure each worker processes a distinct portion of the dataset for model convergence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = 10000\nBATCH_SIZE = 64\n\ndef input_fn(mode, input_context=None):\n  datasets, info = tfds.load(name='mnist',\n                                with_info=True,\n                                as_supervised=True)\n  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else\n                   datasets['test'])\n\n  def scale(image, label):\n    image = tf.cast(image, tf.float32)\n    image /= 255\n    return image, label\n\n  if input_context:\n    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\n                                        input_context.input_pipeline_id)\n  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Creating Distributed Keras Model with MirroredStrategy\nDESCRIPTION: This snippet demonstrates how to create a simple Keras model within the scope of a MirroredStrategy for distributed training on multiple GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\nwith mirrored_strategy.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(1, input_shape=(1,),\n                            kernel_regularizer=tf.keras.regularizers.L2(1e-4))])\n  model.compile(loss='mse', optimizer='sgd')\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pattern 1: Accidental State Accumulation in TensorFlow 2.x\nDESCRIPTION: This code snippet shows a problematic pattern where training loss accumulates across steps because a global list is never cleared, causing the optimizer to minimize an ever-increasing sum of losses across all training steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# initialize all objects\nmodel = Model()\noptimizer = ...\n\ndef train_step(...)\n  ...\n  model(...)\n  total_loss = tf.reduce_sum(all_losses) # global list is never cleared,\n  # Accidentally accumulates sum loss across all training steps\n  optimizer.minimize(total_loss)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Model with Strategy Scope in Python\nDESCRIPTION: This snippet shows how to load a saved TensorFlow model within a Strategy.scope, compile it, and evaluate its performance on a dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  replicated_model = tf.keras.models.load_model(path)\n  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                           optimizer=tf.keras.optimizers.Adam(),\n                           metrics=['accuracy'])\n\n  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n```\n\n----------------------------------------\n\nTITLE: Calculating Regularization Loss in Custom Training Loop\nDESCRIPTION: This snippet shows how to calculate the regularization loss in a custom training loop when using L2 regularization. It demonstrates adding the regularization losses to the model's main loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: Python\nCODE:\n```\nresult = l2_model(features)\nregularization_loss=tf.add_n(l2_model.losses)\n```\n\n----------------------------------------\n\nTITLE: Implementing Loss, Predictions, and Optimizer for Handwriting Recognition in TensorFlow\nDESCRIPTION: This snippet demonstrates how to calculate the loss, create a training operation, and generate predictions for the model. It uses cross-entropy loss and the Adam optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\ncross_entropy = tf.reduce_mean(\n    tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets, logits=logits))\n# Add the optimizer.\ntrain_op = tf.contrib.layers.optimize_loss(\n    loss=cross_entropy,\n    global_step=tf.train.get_global_step(),\n    learning_rate=params.learning_rate,\n    optimizer=\"Adam\",\n    # some gradient clipping stabilizes training in the beginning.\n    clip_gradients=params.gradient_clipping_norm,\n    summaries=[\"learning_rate\", \"loss\", \"gradients\", \"gradient_norm\"])\npredictions = tf.argmax(logits, axis=1)\nreturn model_fn_lib.ModelFnOps(\n    mode=mode,\n    predictions={\"logits\": logits,\n                 \"predictions\": predictions},\n    loss=cross_entropy,\n    train_op=train_op,\n    eval_metric_ops={\"accuracy\": tf.metrics.accuracy(targets, predictions)})\n```\n\n----------------------------------------\n\nTITLE: Implementing Linear Multi-Step Forecasting with TensorFlow in Python\nDESCRIPTION: Creates a simple linear model that predicts multiple future time steps based on the last input time step. The model extracts the final time step from the input, applies a linear projection to predict all output steps, and reshapes the result to the desired output format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_58\n\nLANGUAGE: python\nCODE:\n```\nmulti_linear_model = tf.keras.Sequential([\n    # Take the last time-step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_linear_model, multi_window)\n\nIPython.display.clear_output()\nmulti_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val, return_dict=True)\nmulti_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0, return_dict=True)\nmulti_window.plot(multi_linear_model)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Helper Libraries\nDESCRIPTION: Imports the necessary libraries for the tutorial, including TensorFlow, NumPy, and OS for file operations, then prints the TensorFlow version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import TensorFlow\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport os\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Disabling GPU Visibility for Simulating Multiple Workers\nDESCRIPTION: Setting the CUDA_VISIBLE_DEVICES environment variable to -1 to disable GPU access, ensuring workers don't conflict when running on the same machine for this tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Evaluation Mode in TensorFlow Custom Estimator\nDESCRIPTION: This code demonstrates how to implement the evaluation mode in a custom Estimator. It computes accuracy metrics and returns them along with the loss in an EstimatorSpec object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Compute evaluation metrics.\naccuracy = tf.metrics.accuracy(labels=labels,\n                               predictions=predicted_classes,\n                               name='acc_op')\nmetrics = {'accuracy': accuracy}\ntf.summary.scalar('accuracy', accuracy[1])\n\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(\n        mode, loss=loss, eval_metric_ops=metrics)\n```\n\n----------------------------------------\n\nTITLE: Encoding sparse columns with vocabulary list\nDESCRIPTION: This snippet demonstrates how to create a `FeatureColumn` for a categorical feature with a known vocabulary list using `tf.feature_column.categorical_column_with_vocabulary_list`. This function automatically converts categorical values into vectors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\neye_color = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"eye_color\", vocabulary_list=[\"blue\", \"brown\", \"green\"])\n```\n\n----------------------------------------\n\nTITLE: Building Neural Network Model with Keras in Python\nDESCRIPTION: This snippet defines the architecture of the neural network using Keras Sequential API. It includes a Flatten layer and two Dense layers, with the final layer having 10 outputs for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10)\n])\n```\n\n----------------------------------------\n\nTITLE: Setting up Data and Model with MirroredStrategy\nDESCRIPTION: Defines functions to load MNIST dataset and create a CNN model using tf.distribute.MirroredStrategy for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndef get_data():\n  datasets = tfds.load(name='mnist', as_supervised=True)\n  mnist_train, mnist_test = datasets['train'], datasets['test']\n\n  BUFFER_SIZE = 10000\n\n  BATCH_SIZE_PER_REPLICA = 64\n  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n\n  def scale(image, label):\n    image = tf.cast(image, tf.float32)\n    image /= 255\n\n    return image, label\n\n  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n\n  return train_dataset, eval_dataset\n\ndef get_model():\n  with mirrored_strategy.scope():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(10)\n    ])\n\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  optimizer=tf.keras.optimizers.Adam(),\n                  metrics=[tf.metrics.SparseCategoricalAccuracy()])\n    return model\n```\n\n----------------------------------------\n\nTITLE: Creating TypeSpec for ExtensionType in Python\nDESCRIPTION: Shows two ways to create TypeSpec objects for ExtensionType instances: explicitly or using tf.type_spec_from_value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nspec1 = Player.Spec(name=tf.TensorSpec([], tf.float32), attributes={})\nspec2 = tf.type_spec_from_value(anne)\n```\n\n----------------------------------------\n\nTITLE: Defining Feature Columns for TensorFlow Estimator\nDESCRIPTION: Creates three feature columns for a TensorFlow Estimator: a numeric column for age, a categorical column with vocabulary list for class, and a categorical column with hash bucket for embark_town.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nage = tf.feature_column.numeric_column('age')\ncls = tf.feature_column.categorical_column_with_vocabulary_list('class', ['First', 'Second', 'Third']) \nembark = tf.feature_column.categorical_column_with_hash_bucket('embark_town', 32)\n```\n\n----------------------------------------\n\nTITLE: Fetching Image Data for TFRecord Storage (Python)\nDESCRIPTION: Downloads images to local files using tf.keras.utils.get_file, enabling the integration of external image data into TFRecord datasets for processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ncat_in_snow  = tf.keras.utils.get_file('320px-Felis_catus-cat_on_snow.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\nwilliamsburg_bridge = tf.keras.utils.get_file('194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')\n```\n\n----------------------------------------\n\nTITLE: Creating CSV File with Missing Values\nDESCRIPTION: This snippet creates a CSV file with missing values to demonstrate handling of incomplete data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_50\n\nLANGUAGE: python\nCODE:\n```\n%%writefile missing.csv\n1,2,3,4\n,2,3,4\n1,,3,4\n1,2,,4\n1,2,3,\n,,,\n```\n\n----------------------------------------\n\nTITLE: Implementing make_dataset Method for WindowGenerator Class in TensorFlow\nDESCRIPTION: Creates a tf.data.Dataset from time series data using tf.keras.utils.timeseries_dataset_from_array. The method converts DataFrame data into a dataset of input-label window pairs and applies the split_window method to separate inputs and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef make_dataset(self, data):\n  data = np.array(data, dtype=np.float32)\n  ds = tf.keras.utils.timeseries_dataset_from_array(\n      data=data,\n      targets=None,\n      sequence_length=self.total_window_size,\n      sequence_stride=1,\n      shuffle=True,\n      batch_size=32,)\n\n  ds = ds.map(self.split_window)\n\n  return ds\n\nWindowGenerator.make_dataset = make_dataset\n```\n\n----------------------------------------\n\nTITLE: Setting Up Optimizer and Global Step Counter\nDESCRIPTION: Initializes a Gradient Descent optimizer with a specified learning rate and creates a global step counter to track training progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n\nglobal_step = tf.Variable(0)\n```\n\n----------------------------------------\n\nTITLE: Compressing and Decompressing Model Parameters in TensorFlow\nDESCRIPTION: These functions compress and decompress model parameters using TensorFlow Compression's PowerLawEntropyModel. They convert weights to binary strings and store quantization step sizes at half precision.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef compress_latent(latent, log_step, name):\n  em = tfc.PowerLawEntropyModel(latent.shape.rank)\n  compressed = em.compress(latent / tf.exp(log_step))\n  compressed = tf.Variable(compressed, name=f\"{name}_compressed\")\n  log_step = tf.cast(log_step, tf.float16)\n  log_step = tf.Variable(log_step, name=f\"{name}_log_step\")\n  return compressed, log_step\n\ndef decompress_latent(compressed, shape, log_step):\n  latent = tfc.PowerLawEntropyModel(len(shape)).decompress(compressed, shape)\n  step = tf.exp(tf.cast(log_step, latent.dtype))\n  return latent * step\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model Accuracy on Test Dataset with TensorFlow\nDESCRIPTION: Calculates model accuracy by evaluating predictions against actual labels across the test dataset. Uses tf.keras.metrics.Accuracy to track the accuracy metric across all test examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ntest_accuracy = tf.keras.metrics.Accuracy()\n\nfor (x, y) in test_dataset:\n  logits = model(x)\n  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n  test_accuracy(prediction, y)\n\nprint(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))\n```\n\n----------------------------------------\n\nTITLE: Training a Gradient Boosted Trees Model with TensorFlow Decision Forests\nDESCRIPTION: This snippet shows how to create and train a Gradient Boosted Trees model using TensorFlow Decision Forests in TensorFlow 2. It uses default hyperparameters and trains on the previously prepared dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Use the default hyper-parameters of the model.\ngbt_model = tfdf.keras.GradientBoostedTreesModel()\ngbt_model.fit(train_dataset)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Data for TensorFlow Decision Forests Models\nDESCRIPTION: This snippet demonstrates how to load Titanic dataset CSV files into pandas DataFrames and convert them to TensorFlow datasets for use with Decision Forests models. It shows that Decision Forests can handle various feature types without preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataframe = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\neval_dataframe = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n\n# Convert the Pandas Dataframes into TensorFlow datasets.\ntrain_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(train_dataframe, label=\"survived\")\neval_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(eval_dataframe, label=\"survived\")\n```\n\n----------------------------------------\n\nTITLE: Building ANNOY Index for Embeddings in Python\nDESCRIPTION: This function builds an ANNOY (Approximate Nearest Neighbors Oh Yeah) index for the generated embeddings. It reads embedding files, adds items to the index, builds the index with specified parameters, and saves the index and mapping to disk.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef build_index(embedding_files_pattern, index_filename, vector_length, \n    metric='angular', num_trees=100):\n  '''Builds an ANNOY index'''\n\n  annoy_index = annoy.AnnoyIndex(vector_length, metric=metric)\n  # Mapping between the item and its identifier in the index\n  mapping = {}\n\n  embed_files = tf.gfile.Glob(embedding_files_pattern)\n  print('Found {} embedding file(s).'.format(len(embed_files)))\n\n  item_counter = 0\n  for f, embed_file in enumerate(embed_files):\n    print('Loading embeddings in file {} of {}...'.format(\n      f+1, len(embed_files)))\n    record_iterator = tf.io.tf_record_iterator(\n      path=embed_file)\n\n    for string_record in record_iterator:\n      example = tf.train.Example()\n      example.ParseFromString(string_record)\n      text = example.features.feature['text'].bytes_list.value[0].decode(\"utf-8\")\n      mapping[item_counter] = text\n      embedding = np.array(\n        example.features.feature['embedding'].float_list.value)\n      annoy_index.add_item(item_counter, embedding)\n      item_counter += 1\n      if item_counter % 100000 == 0:\n        print('{} items loaded to the index'.format(item_counter))\n\n  print('A total of {} items added to the index'.format(item_counter))\n\n  print('Building the index with {} trees...'.format(num_trees))\n  annoy_index.build(n_trees=num_trees)\n  print('Index is successfully built.')\n  \n  print('Saving index to disk...')\n  annoy_index.save(index_filename)\n  print('Index is saved to disk.')\n  print(\"Index file size: {} GB\".format(\n    round(os.path.getsize(index_filename) / float(1024 ** 3), 2)))\n  annoy_index.unload()\n\n  print('Saving mapping to disk...')\n  with open(index_filename + '.mapping', 'wb') as handle:\n    pickle.dump(mapping, handle, protocol=pickle.HIGHEST_PROTOCOL)\n  print('Mapping is saved to disk.')\n  print(\"Mapping file size: {} MB\".format(\n    round(os.path.getsize(index_filename + '.mapping') / float(1024 ** 2), 2)))\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets for Video Processing\nDESCRIPTION: This code creates training and test datasets from the downloaded video files using TensorFlow's Dataset API. It defines the batch size, number of frames to extract per video, and output specifications for the data generator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 8\nnum_frames = 8\n\noutput_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n                    tf.TensorSpec(shape = (), dtype = tf.int16))\n\ntrain_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], num_frames, training = True),\n                                          output_signature = output_signature)\ntrain_ds = train_ds.batch(batch_size)\n\ntest_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], num_frames),\n                                         output_signature = output_signature)\ntest_ds = test_ds.batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Transforming Datasets with TensorFlow in Python\nDESCRIPTION: Applies map, shuffle, and batch transformations to TensorFlow datasets, demonstrating how to preprocess and structure data efficiently for machine learning models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n\nds_file = ds_file.batch(2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Synthesis Transform Network in Python\nDESCRIPTION: Creates the decoder (synthesis) transform network using dense and transposed convolution layers to convert latent representations back into images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_synthesis_transform():\n  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n  return tf.keras.Sequential([\n      tf.keras.layers.Dense(\n          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n      tf.keras.layers.Dense(\n          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n      tf.keras.layers.Reshape((7, 7, 50)),\n      tf.keras.layers.Conv2DTranspose(\n          20, 5, use_bias=True, strides=2, padding=\"same\",\n          activation=\"leaky_relu\", name=\"conv_1\"),\n      tf.keras.layers.Conv2DTranspose(\n          1, 5, use_bias=True, strides=2, padding=\"same\",\n          activation=\"leaky_relu\", name=\"conv_2\"),\n  ], name=\"synthesis_transform\")\n```\n\n----------------------------------------\n\nTITLE: Embedding Input Words for LSTM\nDESCRIPTION: This snippet shows how to convert word IDs into dense representations using TensorFlow's embedding lookup. It is a key step to allow the LSTM to efficiently process the input words based on learned word embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# embedding_matrix is a tensor of shape [vocabulary_size, embedding size]\nword_embeddings = tf.nn.embedding_lookup(embedding_matrix, word_ids)\n```\n\n----------------------------------------\n\nTITLE: RNN Model Structure Definition in Python\nDESCRIPTION: Outline of the model definition process for the drawing classifier, showing how input tensors are processed through convolutional layers, bidirectional LSTM layers, and finally classified with a softmax layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ninks, lengths, targets = _get_input_tensors(features, targets)\nconvolved = _add_conv_layers(inks)\nfinal_state = _add_rnn_layers(convolved, lengths)\nlogits =_add_fc_layers(final_state)\n```\n\n----------------------------------------\n\nTITLE: Configuring Window Generator for Multi-Step Time Series Prediction\nDESCRIPTION: Creates a WindowGenerator that produces batches of three-hour inputs and one-hour labels for multi-step time series forecasting. The configuration specifies input width, label width, and shift parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nCONV_WIDTH = 3\nconv_window = WindowGenerator(\n    input_width=CONV_WIDTH,\n    label_width=1,\n    shift=1,\n    label_columns=['T (degC)'])\n\nconv_window\n```\n\n----------------------------------------\n\nTITLE: Creating a 1D ConvNet Model Function in TensorFlow\nDESCRIPTION: Defines a function to create a 1D Convolutional Neural Network model with optional vectorization layer, embedding, dropout, and dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef create_model(vocab_size, num_labels, vectorizer=None):\n  my_layers =[]\n  if vectorizer is not None:\n    my_layers = [vectorizer]\n\n  my_layers.extend([\n      layers.Embedding(vocab_size, 64, mask_zero=True),\n      layers.Dropout(0.5),\n      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n      layers.GlobalMaxPooling1D(),\n      layers.Dense(num_labels)\n  ])\n\n  model = tf.keras.Sequential(my_layers)\n  return model\n```\n\n----------------------------------------\n\nTITLE: Creating Categorical Identity Column\nDESCRIPTION: Demonstrates how to create a categorical identity column for handling integer features with a specified number of buckets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create categorical output for an integer feature named \"my_feature_b\",\n# The values of my_feature_b must be >= 0 and < num_buckets\nidentity_feature_column = tf.feature_column.categorical_column_with_identity(\n    key='my_feature_b',\n    num_buckets=4) # Values [0, 4)\n\n# In order for the preceding call to work, the input_fn() must return\n# a dictionary containing 'my_feature_b' as a key. Furthermore, the values\n# assigned to 'my_feature_b' must belong to the set [0, 4).\ndef input_fn():\n    ...\n    return ({ 'my_feature_a':[7, 9, 5, 2], 'my_feature_b':[3, 1, 2, 2] },\n            [Label_values])\n```\n\n----------------------------------------\n\nTITLE: Processing a TensorFlow Dataset\nDESCRIPTION: This snippet shows how to process the created dataset by repeating, batching, and taking a limited number of elements. It then prints the resulting batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfor count_batch in ds_counter.repeat().batch(10).take(10):\n  print(count_batch.numpy())\n```\n\n----------------------------------------\n\nTITLE: Deep Ensemble Inference in Python\nDESCRIPTION: This code performs inference using a deep ensemble. It collects logits from all ensemble members, computes softmax probabilities, and then averages them to get the final ensemble prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n# Deep ensemble inference\nensemble_logit_samples = [model(test_examples) for model in resnet_ensemble]\nensemble_prob_samples = [tf.nn.softmax(logits, axis=-1)[:, 0] for logits in ensemble_logit_samples]\nensemble_probs = tf.reduce_mean(ensemble_prob_samples, axis=0)\n```\n\n----------------------------------------\n\nTITLE: Episode Runner for Training Data Collection\nDESCRIPTION: Runs a single episode using the provided model to collect training data including action probabilities, values and rewards. Handles state management and model inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef run_episode(\n    initial_state: tf.Tensor,\n    model: tf.keras.Model,\n    max_steps: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n  \"\"\"Runs a single episode to collect training data.\"\"\"\n\n  action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n  values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n  rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n\n  initial_state_shape = initial_state.shape\n  state = initial_state\n\n  for t in tf.range(max_steps):\n    # Convert state into a batched tensor (batch size = 1)\n    state = tf.expand_dims(state, 0)\n\n    # Run the model and to get action probabilities and critic value\n    action_logits_t, value = model(state)\n\n    # Sample next action from the action probability distribution\n    action = tf.random.categorical(action_logits_t, 1)[0, 0]\n    action_probs_t = tf.nn.softmax(action_logits_t)\n\n    # Store critic values\n    values = values.write(t, tf.squeeze(value))\n\n    # Store log probability of the action chosen\n    action_probs = action_probs.write(t, action_probs_t[0, action])\n\n    # Apply action to the environment to get next state and reward\n    state, reward, done = env_step(action)\n    state.set_shape(initial_state_shape)\n\n    # Store reward\n    rewards = rewards.write(t, reward)\n\n    if tf.cast(done, tf.bool):\n      break\n\n  action_probs = action_probs.stack()\n  values = values.stack()\n  rewards = rewards.stack()\n\n  return action_probs, values, rewards\n```\n\n----------------------------------------\n\nTITLE: Compiling and Evaluating Restored SavedModel\nDESCRIPTION: Recompile the restored SavedModel and evaluate its performance, demonstrating model restoration and validation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nnew_model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=['accuracy'])\n\n# Evaluate the restored model.\nloss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n```\n\n----------------------------------------\n\nTITLE: Defining Training and Validation Datasets with Feedable Iterator\nDESCRIPTION: Demonstrates how to create feedable iterators for training and validation datasets with identical structure. Shows alternating between datasets using string handles.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntraining_dataset = tf.data.Dataset.range(100).map(\n    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()\nvalidation_dataset = tf.data.Dataset.range(50)\n\nhandle = tf.placeholder(tf.string, shape=[])\niterator = tf.data.Iterator.from_string_handle(\n    handle, training_dataset.output_types, training_dataset.output_shapes)\nnext_element = iterator.get_next()\n\ntraining_iterator = training_dataset.make_one_shot_iterator()\nvalidation_iterator = validation_dataset.make_initializable_iterator()\n\ntraining_handle = sess.run(training_iterator.string_handle())\nvalidation_handle = sess.run(validation_iterator.string_handle())\n\nwhile True:\n  for _ in range(200):\n    sess.run(next_element, feed_dict={handle: training_handle})\n\n  sess.run(validation_iterator.initializer)\n  for _ in range(50):\n    sess.run(next_element, feed_dict={handle: validation_handle})\n```\n\n----------------------------------------\n\nTITLE: Creating Signatures with Input Signature in TensorFlow 2\nDESCRIPTION: Creates a SavedModel signature by specifying an input signature decorator for a tf.function. This approach defines the expected input types and shapes upfront, then saves the model with the named signature.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Option 1: Specify an input signature.\n@tf.function(input_signature=[...])\ndef fn(...):\n  ...\n  return outputs\n\ntf.saved_model.save(model, path, signatures={\n    'name': fn\n})\n```\n\n----------------------------------------\n\nTITLE: Predicting on a Single Image Batch\nDESCRIPTION: This snippet predicts the class probabilities for a single image that has been reshaped into a batch of size 1. It uses the trained `model` to make the prediction and stores the result in `predictions_single`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\npredictions_single = model.predict(img)\n\nprint(predictions_single)\n```\n\n----------------------------------------\n\nTITLE: Caching CSV Dataset with Dataset.cache() Method\nDESCRIPTION: This snippet demonstrates how to use Dataset.cache() to improve iteration performance by storing the parsed data in memory after the first epoch. Note that cache() disables any shuffles earlier in the pipeline, so shuffle() is added back after caching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n%%time\ncaching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n\nfor i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n  if i % 40 == 0:\n    print('.', end='')\nprint()\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from File Paths with tf.data\nDESCRIPTION: Initializes a tf.data.Dataset from file paths and applies shuffling. This is part of creating a custom image loading pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlist_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n```\n\n----------------------------------------\n\nTITLE: Basic License Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license declaration for TensorFlow code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Counting Downloaded Videos\nDESCRIPTION: Counts and displays the total number of videos downloaded across all data splits (train, validation, test) to verify the download process completed correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nvideo_count_train = len(list(download_dir.glob('train/*/*.avi')))\nvideo_count_val = len(list(download_dir.glob('val/*/*.avi')))\nvideo_count_test = len(list(download_dir.glob('test/*/*.avi')))\nvideo_total = video_count_train + video_count_val + video_count_test\nprint(f\"Total videos: {video_total}\")\n```\n\n----------------------------------------\n\nTITLE: Applying Integrated Gradients to Fireboat Image Classification in TensorFlow\nDESCRIPTION: This code snippet applies the Integrated Gradients algorithm to a 'Fireboat' image, using 240 steps for approximation. It demonstrates how to use the integrated_gradients function with specific parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nig_attributions = integrated_gradients(baseline=baseline,\n                                       image=img_name_tensors['Fireboat'],\n                                       target_class_idx=555,\n                                       m_steps=240)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Gradient Disconnection Due to Variable Replacement in TensorFlow\nDESCRIPTION: This snippet shows how replacing a Variable with a Tensor inadvertently disconnects the gradient in subsequent iterations of a loop.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\n\nfor epoch in range(2):\n  with tf.GradientTape() as tape:\n    y = x+1\n\n  print(type(x).__name__, \":\", tape.gradient(y, x))\n  x = x + 1   # This should be `x.assign_add(1)`\n```\n\n----------------------------------------\n\nTITLE: Loading a TensorFlow Model from .keras Format\nDESCRIPTION: Demonstrates how to load a TensorFlow model that was saved in the .keras format, displaying the model summary to verify the architecture was properly restored.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nnew_model = tf.keras.models.load_model('my_model.keras')\n\n# Show the model architecture\nnew_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies and Version Check\nDESCRIPTION: Importing required libraries and checking versions of TensorFlow, TF Hub, and GPU availability\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nimport tf_keras as keras\n\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n```\n\n----------------------------------------\n\nTITLE: Loading Text Embedding Models in Distributed Training with TensorFlow\nDESCRIPTION: Demonstrates how to properly load a text embedding model within a distribution strategy scope to ensure variables are created correctly for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n  with strategy.scope():\n    ...\n    model = hub.load(\"path/to/model\")\n    ...\n```\n\n----------------------------------------\n\nTITLE: Loading a SavedModel in C++\nDESCRIPTION: Shows how to load a SavedModel in C++ using the SavedModelBundle API, specifying session options, run options, and model tags.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: C++\nCODE:\n```\nconst string export_dir = ...\nSavedModelBundle bundle;\n...\nLoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n               &bundle);\n```\n\n----------------------------------------\n\nTITLE: Creating Training Dataset Function\nDESCRIPTION: Defines dataset function that applies preprocessing layers and batching. Transforms raw data into preprocessed format suitable for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef dataset_fn(_):\n  raw_dataset = tf.data.Dataset.from_tensor_slices(examples)\n\n  train_dataset = raw_dataset.map(\n      lambda x: (\n          {\"features\": feature_preprocess_stage(x[\"features\"])},\n          label_preprocess_stage(x[\"label\"])\n      )).shuffle(200).batch(32).repeat()\n  return train_dataset\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Performance with a Confusion Matrix\nDESCRIPTION: Creates a function to generate and display a confusion matrix using sklearn and seaborn. The matrix shows the relationship between predicted and actual digits, helping identify common misclassification patterns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nimport sklearn.metrics as sk_metrics\n\ndef show_confusion_matrix(test_labels, test_classes):\n  # Compute confusion matrix and normalize\n  plt.figure(figsize=(10,10))\n  confusion = sk_metrics.confusion_matrix(test_labels.numpy(), \n                                          test_classes.numpy())\n  confusion_normalized = confusion / confusion.sum(axis=1, keepdims=True)\n  axis_labels = range(10)\n  ax = sns.heatmap(\n      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n      cmap='Blues', annot=True, fmt='.4f', square=True)\n  plt.title(\"Confusion matrix\")\n  plt.ylabel(\"True label\")\n  plt.xlabel(\"Predicted label\")\n\nshow_confusion_matrix(y_test, test_classes)\n```\n\n----------------------------------------\n\nTITLE: Defining a Feedback Model Class using TensorFlow LSTM for Time Series Forecasting\nDESCRIPTION: Creates a FeedBack model class that implements an autoregressive LSTM model for multi-step time series forecasting. The model uses LSTMCell for step-by-step predictions and includes a dense layer for output conversion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_62\n\nLANGUAGE: python\nCODE:\n```\nclass FeedBack(tf.keras.Model):\n  def __init__(self, units, out_steps):\n    super().__init__()\n    self.out_steps = out_steps\n    self.units = units\n    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n    self.dense = tf.keras.layers.Dense(num_features)\n```\n\n----------------------------------------\n\nTITLE: Custom Vocabulary Table Implementation\nDESCRIPTION: Creates a custom vocabulary table layer that maps tokens to integer indices with support for OOV tokens.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nclass MyVocabTable(tf.keras.layers.Layer):\n  def __init__(self, vocab):\n    super().__init__()\n    self.keys = [''] + vocab\n    self.values = range(len(self.keys))\n\n    self.init = tf.lookup.KeyValueTensorInitializer(\n        self.keys, self.values, key_dtype=tf.string, value_dtype=tf.int64)\n\n    num_oov_buckets = 1\n\n    self.table = tf.lookup.StaticVocabularyTable(self.init, num_oov_buckets)\n\n  def call(self, x):\n    result = self.table.lookup(x)\n    return result\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients using tf.GradientTape in TensorFlow\nDESCRIPTION: This example demonstrates how to use tf.GradientTape to compute the gradient of y=x^2 with respect to x. It shows the basic usage of GradientTape for automatic differentiation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(3.0)\n\nwith tf.GradientTape() as tape:\n  y = x**2\n\n# dy = 2x * dx\ndy_dx = tape.gradient(y, x)\ndy_dx.numpy()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Language Pair Similarities in Python\nDESCRIPTION: Functions to visualize semantic similarities between sentence pairs in different language combinations using the Universal Sentence Encoder.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nvisualize_similarity(en_result, es_result, english_sentences, spanish_sentences, 'English-Spanish Similarity')\n\nvisualize_similarity(en_result, it_result, english_sentences, italian_sentences, 'English-Italian Similarity')\n\nvisualize_similarity(it_result, es_result, italian_sentences, spanish_sentences, 'Italian-Spanish Similarity')\n\nvisualize_similarity(en_result, zh_result, english_sentences, chinese_sentences, 'English-Chinese Similarity')\n\nvisualize_similarity(en_result, ko_result, english_sentences, korean_sentences, 'English-Korean Similarity')\n\nvisualize_similarity(zh_result, ko_result, chinese_sentences, korean_sentences, 'Chinese-Korean Similarity')\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Speech Recognition Model\nDESCRIPTION: This snippet shows the expected output format when running the speech recognition model on an audio file. It displays the top three predicted labels with their corresponding confidence scores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nleft (score = 0.81477)\nright (score = 0.14139)\n_unknown_ (score = 0.03808)\n```\n\n----------------------------------------\n\nTITLE: Creating Validation Dataset for TensorFlow Image Classification\nDESCRIPTION: This snippet creates a validation dataset using the image_dataset_from_directory utility, with the same batch size and image dimensions as the training dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n                                                                 shuffle=True,\n                                                                 batch_size=BATCH_SIZE,\n                                                                 image_size=IMG_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Parsing TFRecord Example in TensorFlow\nDESCRIPTION: This snippet demonstrates how to parse a TFRecord example from the dataset and access a specific feature.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nraw_example = next(iter(dataset))\nparsed = tf.train.Example.FromString(raw_example.numpy())\n\nparsed.features.feature['image/text']\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Entire Keras Model (HDF5)\nDESCRIPTION: Demonstrates how to save and load an entire Keras model to a single HDF5 file using `model.save()` and `tf.keras.models.load_model()`. This includes the model's architecture, weights, and optimizer configuration, allowing you to resume training from the exact same state. The model is first created, compiled, and trained, then saved to 'my_model.h5', and finally loaded back.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Create a trivial model\nmodel = tf.keras.Sequential([\n  layers.Dense(64, activation='relu', input_shape=(32,)),\n  layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(data, labels, batch_size=32, epochs=5)\n\n\n# Save entire model to a HDF5 file\nmodel.save('my_model.h5')\n\n# Recreate the exact same model, including weights and optimizer.\nmodel = tf.keras.models.load_model('my_model.h5')\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Virtual CPUs for DTensor\nDESCRIPTION: Function to configure virtual CPU devices for DTensor testing and development\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef configure_virtual_cpus(ncpu):\n  phy_devices = tf.config.list_physical_devices('CPU')\n  tf.config.set_logical_device_configuration(phy_devices[0], [\n        tf.config.LogicalDeviceConfiguration(),\n    ] * ncpu)\n\nconfigure_virtual_cpus(8)\nDEVICES = [f'CPU:{i}' for i in range(8)]\n\ntf.config.list_logical_devices('CPU')\n```\n\n----------------------------------------\n\nTITLE: Accessing Dataset Elements Using Iterator\nDESCRIPTION: Demonstrates how to explicitly create a Python iterator from a dataset and access its elements using the next() function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nit = iter(dataset)\n\nprint(next(it).numpy())\n```\n\n----------------------------------------\n\nTITLE: Implementing Xavier Weight Initialization in TensorFlow\nDESCRIPTION: Function that implements the Xavier (or Glorot) initialization method for neural network weights. It creates a uniform distribution based on input and output dimensions to maintain proper signal variance through the network.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef xavier_init(shape):\n  # Computes the xavier initialization values for a weight matrix\n  in_dim, out_dim = shape\n  xavier_lim = tf.sqrt(6.)/tf.sqrt(tf.cast(in_dim + out_dim, tf.float32))\n  weight_vals = tf.random.uniform(shape=(in_dim, out_dim), \n                                  minval=-xavier_lim, maxval=xavier_lim, seed=22)\n  return weight_vals\n```\n\n----------------------------------------\n\nTITLE: Implementing Fully Native Keras Layers Model in TensorFlow 2\nDESCRIPTION: This code shows the final step in migrating to a fully native TensorFlow 2 model using only Keras layers. It demonstrates how to structure the model without relying on any TensorFlow 1.x compatible layers or variable scopes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nclass FullyNativeKerasLayersModel(tf.keras.layers.Layer):\n\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.conv_1 = tf.keras.layers.Conv2D(\n          3, 3,\n          kernel_regularizer=\"l2\")\n    self.conv_2 = tf.keras.layers.Conv2D(\n          4, 4,\n          kernel_regularizer=\"l2\")\n    self.conv_3 = tf.keras.layers.Conv2D(\n          5, 5,\n          kernel_regularizer=\"l2\")\n\n\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = self.conv_1(inputs)\n      out = self.conv_2(out)\n      out = self.conv_3(out)\n      return out\n\nlayer = FullyNativeKerasLayersModel()\nlayer(tf.ones(shape=(10, 10, 10, 10)))\n[v.name for v in layer.weights]\n```\n\n----------------------------------------\n\nTITLE: Creating JAX Model and Optax Optimizer\nDESCRIPTION: Initializes the ConvModel, creates the optimizer using Optax with a learning rate decay schedule, and sets up lists for tracking training progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel = ConvModel()\nstate = model.init({'params':jax.random.PRNGKey(0), 'dropout':jax.random.PRNGKey(0)}, one_batch, train=True)\n\noptimizer = optax.adam(learning_rate=jlr_decay)\noptimizer_state = optimizer.init(state['params'])\n\nlosses=[]\navg_losses=[]\neval_losses=[]\neval_accuracies=[]\n```\n\n----------------------------------------\n\nTITLE: Adding Dense Layers to CNN\nDESCRIPTION: Add classification layers including flatten and dense layers for final prediction\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))\n```\n\n----------------------------------------\n\nTITLE: Using tf.data.Iterator Correctly in tf.function\nDESCRIPTION: Demonstrates the proper way to use TensorFlow's specialized tf.data.Iterator with tf.function to correctly consume items from a dataset on each call.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef good_consume_next(iterator):\n  # This is ok, iterator is a tf.data.Iterator\n  tf.print(\"Value:\", next(iterator))\n\nds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\niterator = iter(ds)\ngood_consume_next(iterator)\ngood_consume_next(iterator)\ngood_consume_next(iterator)\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients of Multiple Targets as a Dictionary in TensorFlow\nDESCRIPTION: This snippet shows how to compute gradients of multiple targets stored in a dictionary with respect to a single source variable using TensorFlow's GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\nwith tf.GradientTape() as tape:\n  y0 = x**2\n  y1 = 1 / x\n\nprint(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())\n```\n\n----------------------------------------\n\nTITLE: Initializing a MLP Model for Digit Classification\nDESCRIPTION: Code snippet that initializes a Multi-Layer Perceptron with two hidden layers (700 and 500 neurons) and an output layer of 10 neurons for digit classification, using ReLU activation functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nhidden_layer_1_size = 700\nhidden_layer_2_size = 500\noutput_size = 10\n\nmlp_model = MLP([\n    DenseLayer(out_dim=hidden_layer_1_size, activation=tf.nn.relu),\n    DenseLayer(out_dim=hidden_layer_2_size, activation=tf.nn.relu),\n    DenseLayer(out_dim=output_size)])\n```\n\n----------------------------------------\n\nTITLE: Loading and Using a Reusable SavedModel in Python\nDESCRIPTION: This snippet demonstrates how to load a SavedModel from TensorFlow Hub and use it as part of a larger TensorFlow model. It shows the basic usage of the hub.load() function and how to invoke the loaded model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nobj = hub.load(\"path/to/model\")  # That's tf.saved_model.load() after download.\noutputs = obj(inputs, training=False)  # Invokes the tf.function obj.__call__.\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom SessionRunHook with TensorFlow 1 - Python\nDESCRIPTION: This snippet shows the creation of a custom SessionRunHook that logs the number of examples processed per second during training in TensorFlow 1. It includes the definitions for input function and model function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/sessionrunhook_callback.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices(\n      (features, labels)).batch(1).repeat(100)\n\n\ndef _model_fn(features, labels, mode):\n  logits = tf1.layers.Dense(1)(features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\nLANGUAGE: python\nCODE:\n```\nclass LoggerHook(tf1.train.SessionRunHook):\n  \"\"\"Logs loss and runtime.\"\"\"\n\n  def begin(self):\n    self._step = -1\n    self._start_time = time.time()\n    self.log_frequency = 10\n\n  def before_run(self, run_context):\n    self._step += 1\n\n  def after_run(self, run_context, run_values):\n    if self._step % self.log_frequency == 0:\n      current_time = time.time()\n      duration = current_time - self._start_time\n      self._start_time = current_time\n      examples_per_sec = self.log_frequency / duration\n      print('Time:', datetime.now(), ', Step #:', self._step,\n            ', Examples per second:', examples_per_sec)\n\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\n\n# Begin training.\nestimator.train(_input_fn, hooks=[LoggerHook()])\n```\n\n----------------------------------------\n\nTITLE: Applying Image Processing to Datasets\nDESCRIPTION: Uses the process_path function to transform file paths into (image, label) pairs with parallel processing for better performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\ntrain_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Time Feature Engineering for Weather Data in Python\nDESCRIPTION: This code snippet creates cyclical time features (sine and cosine) for day and year to capture time-based patterns in the weather data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntimestamp_s = date_time.map(pd.Timestamp.timestamp)\n\nday = 24*60*60\nyear = (365.2425)*day\n\ndf['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\ndf['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\ndf['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\ndf['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained MobileNetV2 Classifier from TensorFlow Hub\nDESCRIPTION: This code loads a pre-trained MobileNetV2 image classification model from TensorFlow Hub and wraps it as a Keras layer. It sets up the model to accept input images of size 224x224 pixels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nmobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\ninception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n\nclassifier_model = mobilenet_v2 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}\n\nIMAGE_SHAPE = (224, 224)\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n])\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Auto MPG Dataset in Python\nDESCRIPTION: This code loads the Auto MPG dataset from UCI Machine Learning Repository, drops missing values, and converts it to a TensorFlow tensor. It then splits the data into training and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n                'Acceleration', 'Model Year', 'Origin']\n\ndataset = pd.read_csv(url, names=column_names, na_values='?', comment='\\t',\n                          sep=' ', skipinitialspace=True)\n\ndataset = dataset.dropna()\ndataset_tf = tf.convert_to_tensor(dataset, dtype=tf.float32)\ndataset.tail()\n\ndataset_shuffled = tf.random.shuffle(dataset_tf, seed=22)\ntrain_data, test_data = dataset_shuffled[100:], dataset_shuffled[:100]\nx_train, y_train = train_data[:, 1:], train_data[:, 0]\nx_test, y_test = test_data[:, 1:], test_data[:, 0]\n```\n\n----------------------------------------\n\nTITLE: Python Counter Causing Unexpected Behavior in tf.function\nDESCRIPTION: Shows a common pitfall where a Python integer counter used to guard variable updates is captured at trace time, causing unexpected increments in a TensorFlow variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = tf.Variable(0)\n    self.counter = 0\n\n  @tf.function\n  def __call__(self):\n    if self.counter == 0:\n      # A python side-effect\n      self.counter += 1\n      self.v.assign_add(1)\n\n    return self.v\n\nm = Model()\nfor n in range(3):\n  print(m().numpy()) # prints 1, 2, 3\n```\n\n----------------------------------------\n\nTITLE: Handling Control Flow in Gradient Computation with TensorFlow\nDESCRIPTION: This snippet shows how control flow (if statement) affects gradient computation in TensorFlow, demonstrating that gradients are only connected to the executed branch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(1.0)\n\nv0 = tf.Variable(2.0)\nv1 = tf.Variable(2.0)\n\nwith tf.GradientTape(persistent=True) as tape:\n  tape.watch(x)\n  if x > 0.0:\n    result = v0\n  else:\n    result = v1**2 \n\ndv0, dv1 = tape.gradient(result, [v0, v1])\n\nprint(dv0)\nprint(dv1)\n```\n\n----------------------------------------\n\nTITLE: Initializing Dictionary for Storing Training Histories\nDESCRIPTION: Creates an empty dictionary to store the training histories of different model sizes. This will be used for comparing model performance across different architectures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nsize_histories = {}\n```\n\n----------------------------------------\n\nTITLE: Plotting ROC Curves with Baseline and Weighted Models\nDESCRIPTION: Visualizes Receiver Operating Characteristic (ROC) curves comparing baseline and weighted model performance on train and test data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nplot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n\nplot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\nplot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n\n\nplt.legend(loc='lower right');\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Device Placement with CPU and GPU\nDESCRIPTION: Demonstrates pinning operations to specific devices (CPU/GPU) using tf.device context manager. Shows basic image processing and matrix multiplication operations across devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nweights = tf.random_normal(...)\n\nwith tf.device(\"/device:CPU:0\"):\n  # Operations created in this context will be pinned to the CPU.\n  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n\nwith tf.device(\"/device:GPU:0\"):\n  # Operations created in this context will be pinned to the GPU.\n  result = tf.matmul(weights, img)\n```\n\n----------------------------------------\n\nTITLE: Training the Compressible MNIST Classifier Model\nDESCRIPTION: Trains the compressible classifier on MNIST data and displays the resulting accuracy. The model is trained with entropy regularization to optimize the trade-off between accuracy and compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\npenalized_accuracy = train_model(\n    compressible_classifier, training_dataset, validation_dataset)\n\nprint(f\"Accuracy: {penalized_accuracy:0.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Word Embeddings in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create word embeddings in TensorFlow by initializing an embedding variable and using tf.nn.embedding_lookup to map word IDs to embedding vectors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/embedding.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nword_embeddings = tf.get_variable(\"word_embeddings\",\n    [vocabulary_size, embedding_size])\nembedded_word_ids = tf.nn.embedding_lookup(word_embeddings, word_ids)\n```\n\n----------------------------------------\n\nTITLE: Linear Estimator Example\nDESCRIPTION: This code shows how to instantiate, train, and evaluate a linear estimator using `tf.estimator.LinearClassifier`. It defines the feature columns, trains the model, and then evaluates the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ne = tf.estimator.LinearClassifier(\n    feature_columns=[\n        native_country, education, occupation, workclass, marital_status,\n        race, age_buckets, education_x_occupation,\n        age_buckets_x_race_x_occupation],\n    model_dir=YOUR_MODEL_DIRECTORY)\ne.train(input_fn=input_fn_train, steps=200)\n# Evaluate for one step (one pass through the test data).\nresults = e.evaluate(input_fn=input_fn_test)\n\n# Print the stats for the evaluation.\nfor key in sorted(results):\n    print(\"%s: %s\" % (key, results[key]))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Checkpoints\nDESCRIPTION: Configures checkpoint management for saving and restoring model states during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_path = \"./checkpoints/train\"\n\nckpt = tf.train.Checkpoint(generator_g=generator_g,\n                           generator_f=generator_f,\n                           discriminator_x=discriminator_x,\n                           discriminator_y=discriminator_y,\n                           generator_g_optimizer=generator_g_optimizer,\n                           generator_f_optimizer=generator_f_optimizer,\n                           discriminator_x_optimizer=discriminator_x_optimizer,\n                           discriminator_y_optimizer=discriminator_y_optimizer)\n\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\nif ckpt_manager.latest_checkpoint:\n  ckpt.restore(ckpt_manager.latest_checkpoint)\n  print ('Latest checkpoint restored!!')\n```\n\n----------------------------------------\n\nTITLE: Iterating Through a CSV Dataset with Selected Columns\nDESCRIPTION: Shows how to iterate through a CSV dataset that has specific columns selected and print each line as a numpy array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nfor line in dataset:\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Serving Integration Example\nDESCRIPTION: Shows how to create wrapper methods for TensorFlow Serving compatibility by decomposing extension type values into raw tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModuleWrapper(tf.Module):\n  def __init__(self, variable_value):\n    super().__init__()\n    self.v = tf.Variable(variable_value)\n\n  @tf.function\n  def var_weighted_mean(self, x: MaskedTensor):\n    \"\"\"Mean value of unmasked values in x, weighted by self.v.\"\"\"\n    x = MaskedTensor(x.values * self.v, x.mask)\n    return (tf.reduce_sum(x.with_default(0)) /\n            tf.reduce_sum(tf.cast(x.mask, x.dtype)))\n\n  @tf.function()\n  def var_weighted_mean_wrapper(self, x_values, x_mask):\n    \"\"\"Raw tensor wrapper for var_weighted_mean.\"\"\"\n    return self.var_weighted_mean(MaskedTensor(x_values, x_mask))\n\nmodule = CustomModuleWrapper([3., 2., 8., 5.])\n\nmodule.var_weighted_mean_wrapper.get_concrete_function(\n    tf.TensorSpec(None, tf.float32), tf.TensorSpec(None, tf.bool))\ncustom_module_path = tempfile.mkdtemp()\ntf.saved_model.save(module, custom_module_path)\nimported_model = tf.saved_model.load(custom_module_path)\nx = MaskedTensor([1., 2., 3., 4.], [False, True, False, True])\nimported_model.var_weighted_mean_wrapper(x.values, x.mask)\n```\n\n----------------------------------------\n\nTITLE: Installing clang-format for C++ Style Checking\nDESCRIPTION: Command to install clang-format on Ubuntu 16+ systems for checking C/C++ code formatting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ apt-get install -y clang-format\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Data Utilities in Python with TensorFlow\nDESCRIPTION: This comprehensive code snippet defines utility functions for downloading, extracting, and processing video data from the UCF-101 dataset. It includes functions for listing files, extracting class information, downloading from zip files, and converting videos to frame sequences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title \n\ndef list_files_per_class(zip_url):\n  \"\"\"\n    List the files in each class of the dataset given the zip URL.\n\n    Args:\n      zip_url: URL from which the files can be unzipped. \n\n    Return:\n      files: List of files in each of the classes.\n  \"\"\"\n  files = []\n  with rz.RemoteZip(URL) as zip:\n    for zip_info in zip.infolist():\n      files.append(zip_info.filename)\n  return files\n\ndef get_class(fname):\n  \"\"\"\n    Retrieve the name of the class given a filename.\n\n    Args:\n      fname: Name of the file in the UCF101 dataset.\n\n    Return:\n      Class that the file belongs to.\n  \"\"\"\n  return fname.split('_')[-3]\n\ndef get_files_per_class(files):\n  \"\"\"\n    Retrieve the files that belong to each class. \n\n    Args:\n      files: List of files in the dataset.\n\n    Return:\n      Dictionary of class names (key) and files (values).\n  \"\"\"\n  files_for_class = collections.defaultdict(list)\n  for fname in files:\n    class_name = get_class(fname)\n    files_for_class[class_name].append(fname)\n  return files_for_class\n\ndef download_from_zip(zip_url, to_dir, file_names):\n  \"\"\"\n    Download the contents of the zip file from the zip URL.\n\n    Args:\n      zip_url: Zip URL containing data.\n      to_dir: Directory to download data to.\n      file_names: Names of files to download.\n  \"\"\"\n  with rz.RemoteZip(zip_url) as zip:\n    for fn in tqdm.tqdm(file_names):\n      class_name = get_class(fn)\n      zip.extract(fn, str(to_dir / class_name))\n      unzipped_file = to_dir / class_name / fn\n\n      fn = pathlib.Path(fn).parts[-1]\n      output_file = to_dir / class_name / fn\n      unzipped_file.rename(output_file,)\n\ndef split_class_lists(files_for_class, count):\n  \"\"\"\n    Returns the list of files belonging to a subset of data as well as the remainder of\n    files that need to be downloaded.\n\n    Args:\n      files_for_class: Files belonging to a particular class of data.\n      count: Number of files to download.\n\n    Return:\n      split_files: Files belonging to the subset of data.\n      remainder: Dictionary of the remainder of files that need to be downloaded.\n  \"\"\"\n  split_files = []\n  remainder = {}\n  for cls in files_for_class:\n    split_files.extend(files_for_class[cls][:count])\n    remainder[cls] = files_for_class[cls][count:]\n  return split_files, remainder\n\ndef download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n  \"\"\"\n    Download a subset of the UFC101 dataset and split them into various parts, such as\n    training, validation, and test. \n\n    Args:\n      zip_url: Zip URL containing data.\n      num_classes: Number of labels.\n      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n              (value is number of files per split).\n      download_dir: Directory to download data to.\n\n    Return:\n      dir: Posix path of the resulting directories containing the splits of data.\n  \"\"\"\n  files = list_files_per_class(zip_url)\n  for f in files:\n    tokens = f.split('/')\n    if len(tokens) <= 2:\n      files.remove(f) # Remove that item from the list if it does not have a filename\n\n  files_for_class = get_files_per_class(files)\n\n  classes = list(files_for_class.keys())[:num_classes]\n\n  for cls in classes:\n    new_files_for_class = files_for_class[cls]\n    random.shuffle(new_files_for_class)\n    files_for_class[cls] = new_files_for_class\n\n  # Only use the number of classes you want in the dictionary\n  files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n\n  dirs = {}\n  for split_name, split_count in splits.items():\n    print(split_name, \":\")\n    split_dir = download_dir / split_name\n    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n    download_from_zip(zip_url, split_dir, split_files)\n    dirs[split_name] = split_dir\n\n  return dirs\n\ndef format_frames(frame, output_size):\n  \"\"\"\n    Pad and resize an image from a video.\n\n    Args:\n      frame: Image that needs to resized and padded. \n      output_size: Pixel size of the output frame image.\n\n    Return:\n      Formatted frame with padding of specified output size.\n  \"\"\"\n  frame = tf.image.convert_image_dtype(frame, tf.float32)\n  frame = tf.image.resize_with_pad(frame, *output_size)\n  return frame\n\ndef frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n  \"\"\"\n    Creates frames from each video file present for each category.\n\n    Args:\n      video_path: File path to the video.\n      n_frames: Number of frames to be created per video file.\n      output_size: Pixel size of the output frame image.\n\n    Return:\n      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n  \"\"\"\n  # Read each video frame by frame\n  result = []\n  src = cv2.VideoCapture(str(video_path))  \n\n  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n\n  need_length = 1 + (n_frames - 1) * frame_step\n\n  if need_length > video_length:\n    start = 0\n  else:\n    max_start = video_length - need_length\n    start = random.randint(0, max_start + 1)\n\n  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n  # ret is a boolean indicating whether read was successful, frame is the image itself\n  ret, frame = src.read()\n  result.append(format_frames(frame, output_size))\n\n  for _ in range(n_frames - 1):\n    for _ in range(frame_step):\n      ret, frame = src.read()\n    if ret:\n      frame = format_frames(frame, output_size)\n      result.append(frame)\n    else:\n      result.append(np.zeros_like(result[0]))\n  src.release()\n  result = np.array(result)[..., [2, 1, 0]]\n\n  return result\n\nclass FrameGenerator:\n  def __init__(self, path, n_frames, training = False):\n    \"\"\" Returns a set of frames with their associated label. \n\n      Args:\n        path: Video file paths.\n        n_frames: Number of frames. \n        training: Boolean to determine if training dataset is being created.\n    \"\"\"\n    self.path = path\n    self.n_frames = n_frames\n    self.training = training\n    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n\n  def get_files_and_class_names(self):\n    video_paths = list(self.path.glob('*/*.avi'))\n    classes = [p.parent.name for p in video_paths] \n    return video_paths, classes\n\n  def __call__(self):\n    video_paths, classes = self.get_files_and_class_names()\n\n    pairs = list(zip(video_paths, classes))\n\n    if self.training:\n      random.shuffle(pairs)\n\n    for path, name in pairs:\n      video_frames = frames_from_video_file(path, self.n_frames) \n      label = self.class_ids_for_name[name] # Encode labels\n      yield video_frames, label\n```\n\n----------------------------------------\n\nTITLE: Saving a Model with a Default Signature\nDESCRIPTION: Demonstrates how to save a tf.Module with a single signature using the signatures parameter, which becomes the 'serving_default' signature.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nmodule_with_signature_path = os.path.join(tmpdir, 'module_with_signature')\ncall = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\ntf.saved_model.save(module, module_with_signature_path, signatures=call)\n```\n\n----------------------------------------\n\nTITLE: Visualizing semantic similarity between example sentences\nDESCRIPTION: Demonstrates semantic similarity visualization by creating a heatmap of similarities between different sets of topically related sentences about smartphones, weather, food, and age questions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmessages = [\n    # Smartphones\n    \"I like my phone\",\n    \"My phone is not good.\",\n    \"Your cellphone looks great.\",\n\n    # Weather\n    \"Will it snow tomorrow?\",\n    \"Recently a lot of hurricanes have hit the US\",\n    \"Global warming is real\",\n\n    # Food and health\n    \"An apple a day, keeps the doctors away\",\n    \"Eating strawberries is healthy\",\n    \"Is paleo better than keto?\",\n\n    # Asking about age\n    \"How old are you?\",\n    \"what is your age?\",\n]\n\n\nwith tf.Session() as session:\n  session.run(tf.global_variables_initializer())\n  session.run(tf.tables_initializer())\n  run_and_plot(session, input_placeholder, messages)\n```\n\n----------------------------------------\n\nTITLE: Processing MoViNet classification results\nDESCRIPTION: Defines a function to process the model's output logits, converting them to probabilities and returning the top-k predictions with their labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n  \"\"\"Outputs the top k model labels and probabilities on the given video.\n\n  Args:\n    probs: probability tensor of shape (num_frames, num_classes) that represents\n      the probability of each class on each frame.\n    k: the number of top predictions to select.\n    label_map: a list of labels to map logit indices to label strings.\n\n  Returns:\n    a tuple of the top-k labels and probabilities.\n  \"\"\"\n  # Sort predictions to find top_k\n  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n  # collect the labels of top_k predictions\n  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n  # decode lablels\n  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n  # top_k probabilities of the predictions\n  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n  return tuple(zip(top_labels, top_probs))\n```\n\n----------------------------------------\n\nTITLE: Plotting Confusion Matrix for Video Classification in Python\nDESCRIPTION: This function creates and plots a confusion matrix for action recognition. It takes actual and predicted labels, class labels, and dataset type as inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef plot_confusion_matrix(actual, predicted, labels, ds_type):\n  cm = tf.math.confusion_matrix(actual, predicted)\n  ax = sns.heatmap(cm, annot=True, fmt='g')\n  sns.set(rc={'figure.figsize':(12, 12)})\n  sns.set(font_scale=1.4)\n  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n  ax.set_xlabel('Predicted Action')\n  ax.set_ylabel('Actual Action')\n  plt.xticks(rotation=90)\n  plt.yticks(rotation=0)\n  ax.xaxis.set_ticklabels(labels)\n  ax.yaxis.set_ticklabels(labels)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Required Libraries for TPU Usage\nDESCRIPTION: Imports the necessary Python libraries for TPU operations, including TensorFlow and TensorFlow Datasets for loading training data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport os\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Generating Text Embeddings with TensorFlow Hub Model\nDESCRIPTION: Defines a function to generate embeddings for input text using a TensorFlow Hub model. It optionally applies random projection to reduce embedding dimensionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nembed_fn = None\n\ndef generate_embeddings(text, model_url, random_projection_matrix=None):\n  # Beam will run this function in different processes that need to\n  # import hub and load embed_fn (if not previously loaded)\n  global embed_fn\n  if embed_fn is None:\n    embed_fn = hub.load(model_url)\n  embedding = embed_fn(text).numpy()\n  if random_projection_matrix is not None:\n    embedding = embedding.dot(random_projection_matrix)\n  return text, embedding\n```\n\n----------------------------------------\n\nTITLE: Implementing ResNet Main Branch\nDESCRIPTION: Custom layer implementing the main computational branch of a ResNet residual block using (2+1)D convolutions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass ResidualMain(keras.layers.Layer):\n  \"\"\"\n    Residual block of the model with convolution, layer normalization, and the\n    activation function, ReLU.\n  \"\"\"\n  def __init__(self, filters, kernel_size):\n    super().__init__()\n    self.seq = keras.Sequential([\n        Conv2Plus1D(filters=filters,\n                    kernel_size=kernel_size,\n                    padding='same'),\n        layers.LayerNormalization(),\n        layers.ReLU(),\n        Conv2Plus1D(filters=filters, \n                    kernel_size=kernel_size,\n                    padding='same'),\n        layers.LayerNormalization()\n    ])\n    \n  def call(self, x):\n    return self.seq(x)\n```\n\n----------------------------------------\n\nTITLE: Registering a ZeroOut Custom Operation in TensorFlow C++\nDESCRIPTION: This snippet demonstrates how to register a custom operation named ZeroOut that takes an int32 tensor as input and outputs a modified version. The registration includes defining input/output types and a shape function that ensures the output tensor has the same shape as the input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\")\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n```\n\n----------------------------------------\n\nTITLE: Using tf.distribute.Strategy for Multi-GPU Training in TensorFlow\nDESCRIPTION: This code snippet shows how to use tf.distribute.Strategy to implement data parallelism across multiple GPUs. It creates a mirrored strategy and builds a simple Keras model within its scope, allowing automatic distribution of the model across available GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\ngpus = tf.config.list_logical_devices('GPU')\nstrategy = tf.distribute.MirroredStrategy(gpus)\nwith strategy.scope():\n  inputs = tf.keras.layers.Input(shape=(1,))\n  predictions = tf.keras.layers.Dense(1)(inputs)\n  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n  model.compile(loss='mse',\n                optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))\n```\n\n----------------------------------------\n\nTITLE: Interpolating Frames Using Recursive Midpoint Method in Python\nDESCRIPTION: A function that applies recursive midpoint interpolation to a list of frames, generating smoothly interpolated frames between each pair of consecutive input frames.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef interpolate_recursively(\n    frames: List[np.ndarray], num_recursions: int,\n    interpolator: Interpolator) -> Iterable[np.ndarray]:\n  \"\"\"Generates interpolated frames by repeatedly interpolating the midpoint.\n\n  Args:\n    frames: List of input frames. Expected shape (H, W, 3). The colors should be\n      in the range[0, 1] and in gamma space.\n    num_recursions: Number of times to do recursive midpoint\n      interpolation.\n    interpolator: The frame interpolation model to use.\n\n  Yields:\n    The interpolated frames (including the inputs).\n  \"\"\"\n  n = len(frames)\n  for i in range(1, n):\n    yield from _recursive_generator(frames[i - 1], frames[i],\n                                    times_to_interpolate, interpolator)\n  # Separately yield the final frame.\n  yield frames[-1]\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow\nDESCRIPTION: Importing the TensorFlow library for use in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Tracing Behavior with Different Input Types\nDESCRIPTION: Demonstrates how tf.function traces and retraces based on input types, showing the tracing process with different tensor types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef double(a):\n  print(\"Tracing with\", a)\n  return a + a\n\nprint(double(tf.constant(1)))\nprint()\nprint(double(tf.constant(1.1)))\nprint()\nprint(double(tf.constant(\"a\")))\nprint()\n\n```\n\n----------------------------------------\n\nTITLE: Getting Probabilities for Test Examples\nDESCRIPTION: Generates probability predictions for first 5 test examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprobability_model(x_test[:5])\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow Model with Adam Optimizer\nDESCRIPTION: Configures the model compilation settings, including the optimizer, loss function, and evaluation metrics. Uses sparse categorical crossentropy loss which is appropriate for integer class labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer=tf.train.AdamOptimizer(),\n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=[\"accuracy\"])\n```\n\n----------------------------------------\n\nTITLE: Normalizing Audio Data for YAMNet Input in Python\nDESCRIPTION: This snippet normalizes the audio data to values between -1.0 and 1.0, which is required for the YAMNet model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwaveform = wav_data / tf.int16.max\n```\n\n----------------------------------------\n\nTITLE: Plotting Training Loss History in Python\nDESCRIPTION: Visualizes the loss curve during training to analyze model convergence and identify potential issues.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(history.epoch, history.history['loss'], label='total loss')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Using make_template with Variable Tracking in TensorFlow\nDESCRIPTION: Example demonstrating how to use tf.compat.v1.make_template within a Keras layer while properly tracking variables and regularization losses. Shows template reuse patterns and scope management.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass CompatV1TemplateScaleByY(tf.keras.layers.Layer):\n\n  def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n    def my_op(x, scalar_name):\n      var1 = tf.compat.v1.get_variable(scalar_name,\n                            shape=[],\n                            regularizer=tf.compat.v1.keras.regularizers.L2(),\n                            initializer=tf.compat.v1.constant_initializer(1.5))\n      return x * var1\n    self.scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op, scalar_name='y')\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    with tf.compat.v1.variable_scope('layer'):\n      # Using a scope ensures the `scale_by_y` name will not be incremented\n      # for each instantiation of the layer.\n      return self.scale_by_y(inputs)\n\nlayer = CompatV1TemplateScaleByY()\n\nout = layer(tf.ones(shape=(2, 3)))\nprint(\"weights:\", layer.weights)\nprint(\"regularization loss:\", layer.losses)\nprint(\"output:\", out)\n```\n\n----------------------------------------\n\nTITLE: Defining Mapped Function for Data Transformation in Python\nDESCRIPTION: Defines a mapped function that simulates time-consuming pre-processing by adding a sleep delay. This function is used to demonstrate parallelization of data transformation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef mapped_function(s):\n    # Do some hard pre-processing\n    tf.py_function(lambda: time.sleep(0.03), [], ())\n    return s\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies and Setting Up Environment for TensorFlow Hub Q&A Model\nDESCRIPTION: Installs required packages and imports necessary libraries for working with the Universal Encoder Multilingual Q&A model and SQuAD dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n#@title Setup Environment\n# Install the latest Tensorflow version.\n!pip install -q \"tensorflow-text==2.11.*\"\n!pip install -q simpleneighbors[annoy]\n!pip install -q nltk\n!pip install -q tqdm\n```\n\nLANGUAGE: python\nCODE:\n```\n#@title Setup common imports and functions\nimport json\nimport nltk\nimport os\nimport pprint\nimport random\nimport simpleneighbors\nimport urllib\nfrom IPython.display import HTML, display\nfrom tqdm.notebook import tqdm\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_hub as hub\nfrom tensorflow_text import SentencepieceTokenizer\n\nnltk.download('punkt')\n\n# Additional helper functions defined here...\n```\n\n----------------------------------------\n\nTITLE: Using a Specific GPU in TensorFlow\nDESCRIPTION: This snippet illustrates how to specify which GPU TensorFlow should use with `with tf.device`. If the specified GPU is unavailable, it raises an `InvalidArgumentError`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_gpu.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Creates a graph.\nwith tf.device('/device:GPU:2'):\n  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  c = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint(sess.run(c))\n```\n\n----------------------------------------\n\nTITLE: Profiling Custom Training Loops with Trace API in Python\nDESCRIPTION: Instrument a custom training loop with the tf.profiler.experimental.Trace API to mark step boundaries for the Profiler. This method enables step-based performance analysis and improves trace viewer output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfor step in range(NUM_STEPS):\n    with tf.profiler.experimental.Trace('train', step_num=step, _r=1):\n        train_data = next(dataset)\n        train_step(train_data)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dataset with Counter for Deterministic Augmentation\nDESCRIPTION: Creates a counter object and pairs it with the training dataset to provide unique, deterministic seeds for random augmentations. This approach ensures that each image receives different random transformations across epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Create a `Counter` object and `Dataset.zip` it together with the training set.\ncounter = tf.data.experimental.Counter()\ntrain_ds = tf.data.Dataset.zip((train_datasets, (counter, counter)))\n```\n\n----------------------------------------\n\nTITLE: Controlling Float Type Preferences in TensorFlow NumPy\nDESCRIPTION: Shows how to control whether TensorFlow NumPy prefers float32 or float64 when converting float literals to tensors, using the prefer_float32 parameter of experimental_enable_numpy_behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(prefer_float32=True)\nprint(\"When prefer_float32 is True:\")\nprint(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\nprint(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n\ntnp.experimental_enable_numpy_behavior(prefer_float32=False)\nprint(\"When prefer_float32 is False:\")\nprint(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\nprint(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n```\n\n----------------------------------------\n\nTITLE: Reloading the SavedModel from disk\nDESCRIPTION: Loads the saved model back from disk using tf.keras.models.load_model to verify it can be properly reused.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nreloaded = tf.keras.models.load_model(export_path)\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Search with User Query in Python\nDESCRIPTION: This code allows users to enter a query, generates its embedding, finds similar items in the index, and displays the results. It demonstrates the end-to-end process of semantic similarity search.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n#@title { run: \"auto\" }\nquery = \"confronting global challenges\" #@param {type:\"string\"}\nprint(\"Generating embedding for the query...\")\n%time query_embedding = extract_embeddings(query)\n\nprint(\"\")\nprint(\"Finding relevant items in the index...\")\n%time items = find_similar_items(query_embedding, 10)\n\nprint(\"\")\nprint(\"Results:\")\nprint(\"=========\")\nfor item in items:\n  print(item)\n```\n\n----------------------------------------\n\nTITLE: Loading IMDB Dataset\nDESCRIPTION: Loading and splitting the IMDB reviews dataset into training, validation, and test sets\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_data, validation_data, test_data = tfds.load(\n    name=\"imdb_reviews\", \n    split=('train[:60%]', 'train[60%:]', 'test'),\n    as_supervised=True)\n```\n\n----------------------------------------\n\nTITLE: Feature Engineering for Wind Data in Python\nDESCRIPTION: This code performs feature engineering on wind data, converting wind direction and velocity to x and y components for better model interpretation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwv = df.pop('wv (m/s)')\nmax_wv = df.pop('max. wv (m/s)')\n\n# Convert to radians.\nwd_rad = df.pop('wd (deg)')*np.pi / 180\n\n# Calculate the wind x and y components.\ndf['Wx'] = wv*np.cos(wd_rad)\ndf['Wy'] = wv*np.sin(wd_rad)\n\n# Calculate the max wind x and y components.\ndf['max Wx'] = max_wv*np.cos(wd_rad)\ndf['max Wy'] = max_wv*np.sin(wd_rad)\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Dataset Factory Function\nDESCRIPTION: Defines a function that creates a CSV dataset from a given file path. This function will be used with interleave to process multiple CSV files concurrently.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_55\n\nLANGUAGE: python\nCODE:\n```\ndef make_font_csv_ds(path):\n  return tf.data.experimental.CsvDataset(\n    path, \n    record_defaults=font_column_types, \n    header=True)\n```\n\n----------------------------------------\n\nTITLE: Getting Actual and Predicted Labels for Confusion Matrix in TensorFlow\nDESCRIPTION: This function extracts actual ground truth values and predicted values from a dataset for creating a confusion matrix. It processes the dataset and model predictions to return actual and predicted labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef get_actual_predicted_labels(dataset):\n  \"\"\"\n    Create a list of actual ground truth values and the predictions from the model.\n\n    Args:\n      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n\n    Return:\n      Ground truth and predicted values for a particular dataset.\n  \"\"\"\n  actual = [labels for _, labels in dataset.unbatch()]\n  predicted = model.predict(dataset)\n\n  actual = tf.stack(actual, axis=0)\n  predicted = tf.concat(predicted, axis=0)\n  predicted = tf.argmax(predicted, axis=1)\n\n  return actual, predicted\n```\n\n----------------------------------------\n\nTITLE: Separating Positive and Negative Features\nDESCRIPTION: Splits the training features and labels into positive and negative classes for oversampling preparation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\npos_features = train_features[bool_train_labels]\nneg_features = train_features[~bool_train_labels]\n\npos_labels = train_labels[bool_train_labels]\nneg_labels = train_labels[~bool_train_labels]\n```\n\n----------------------------------------\n\nTITLE: Creating Generators in MirroredStrategy Scope\nDESCRIPTION: Creates a random number generator inside a MirroredStrategy scope where each replica gets an independent stream of random numbers while maintaining deterministic behavior based on the seed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nstrat = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat.scope():\n  g = tf.random.Generator.from_seed(1)\n  print(strat.run(lambda: g.normal([])))\n  print(strat.run(lambda: g.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Cleaning Wind Velocity Data in Python\nDESCRIPTION: This code snippet identifies and replaces erroneous wind velocity values in the dataset with zeros.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwv = df['wv (m/s)']\nbad_wv = wv == -9999.0\nwv[bad_wv] = 0.0\n\nmax_wv = df['max. wv (m/s)']\nbad_max_wv = max_wv == -9999.0\nmax_wv[bad_max_wv] = 0.0\n\n# The above inplace edits are reflected in the DataFrame.\ndf['wv (m/s)'].min()\n```\n\n----------------------------------------\n\nTITLE: Defining Helper Functions for Image Processing in TensorFlow\nDESCRIPTION: Defines helper functions for loading, preprocessing, and displaying images. Includes functions to load images from URLs, reshape and normalize image data, and display images using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Helper functions for loading image (hidden)\n\noriginal_image_cache = {}\n\ndef preprocess_image(image):\n  image = np.array(image)\n  # reshape into shape [batch_size, height, width, num_channels]\n  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n  return image\n\ndef load_image_from_url(img_url):\n  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n  user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n  response = requests.get(img_url, headers=user_agent)\n  image = Image.open(BytesIO(response.content))\n  image = preprocess_image(image)\n  return image\n\ndef load_image(image_url, image_size=256, dynamic_size=False, max_dynamic_size=512):\n  \"\"\"Loads and preprocesses images.\"\"\"\n  # Cache image file locally.\n  if image_url in original_image_cache:\n    img = original_image_cache[image_url]\n  elif image_url.startswith('https://'):\n    img = load_image_from_url(image_url)\n  else:\n    fd = tf.io.gfile.GFile(image_url, 'rb')\n    img = preprocess_image(Image.open(fd))\n  original_image_cache[image_url] = img\n  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n  img_raw = img\n  if tf.reduce_max(img) > 1.0:\n    img = img / 255.\n  if len(img.shape) == 3:\n    img = tf.stack([img, img, img], axis=-1)\n  if not dynamic_size:\n    img = tf.image.resize_with_pad(img, image_size, image_size)\n  elif img.shape[1] > max_dynamic_size or img.shape[2] > max_dynamic_size:\n    img = tf.image.resize_with_pad(img, max_dynamic_size, max_dynamic_size)\n  return img, img_raw\n\ndef show_image(image, title=''):\n  image_size = image.shape[1]\n  w = (image_size * 6) // 320\n  plt.figure(figsize=(w, w))\n  plt.imshow(image[0], aspect='equal')\n  plt.axis('off')\n  plt.title(title)\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Converting Video Frames to GIF in Python\nDESCRIPTION: This function takes a set of video frames and converts them into a GIF animation. It uses the imageio library to save the frames as a GIF file and returns an embedded version of the file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef to_gif(images):\n  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n  imageio.mimsave('./animation.gif', converted_images, fps=10)\n  return embed.embed_file('./animation.gif')\n```\n\n----------------------------------------\n\nTITLE: Creating Valid Ragged Tensors with Consistent Types and Ranks\nDESCRIPTION: Shows examples of valid ragged tensor creation with consistent types and ranks, as well as error cases when attempting to mix types or nesting depths.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]))  # ok: type=string, rank=2\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.ragged.constant([[[1, 2], [3]], [[4, 5]]]))        # ok: type=int32, rank=3\n```\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  tf.ragged.constant([[\"one\", \"two\"], [3, 4]])              # bad: multiple types\nexcept ValueError as exception:\n  print(exception)\n```\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  tf.ragged.constant([\"A\", [\"B\", \"C\"]])                     # bad: multiple nesting depths\nexcept ValueError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Numeric Type Constraint\nDESCRIPTION: Demonstrates registering an op with the numbertype constraint that restricts the attribute to numeric types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_17\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"NumberType\")\n    .Attr(\"t: numbertype\");\n```\n\n----------------------------------------\n\nTITLE: Saving Model Weights Using Keras API\nDESCRIPTION: Demonstrates how to save a model's weights to a checkpoint file using the Keras built-in save_weights method, which creates a TensorFlow checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nnet.save_weights('easy_checkpoint')\n```\n\n----------------------------------------\n\nTITLE: TF-Hub Module Loading Function\nDESCRIPTION: Creates a helper function to load a TensorFlow Hub module and prepare an embedding function that transforms sentences into embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef load_module(module_url):\n  embed_module = hub.Module(module_url)\n  placeholder = tf.placeholder(dtype=tf.string)\n  embed = embed_module(placeholder)\n  session = tf.Session()\n  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n  print('TF-Hub module is loaded.')\n\n  def _embeddings_fn(sentences):\n    computed_embeddings = session.run(\n        embed, feed_dict={placeholder: sentences})\n    return computed_embeddings\n\n  return _embeddings_fn\n```\n\n----------------------------------------\n\nTITLE: Downloading and extracting the mini Speech Commands dataset\nDESCRIPTION: This code downloads and extracts the mini Speech Commands dataset using TensorFlow's get_file utility, saving it to a local directory for use in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nDATASET_PATH = 'data/mini_speech_commands'\n\ndata_dir = pathlib.Path(DATASET_PATH)\nif not data_dir.exists():\n  tf.keras.utils.get_file(\n      'mini_speech_commands.zip',\n      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n      extract=True,\n      cache_dir='.', cache_subdir='data')\n```\n\n----------------------------------------\n\nTITLE: Saving a Custom Module as a SavedModel\nDESCRIPTION: Instantiates a custom tf.Module, traces its call method with a constant input, and saves it to disk as a SavedModel without explicit signatures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodule_no_signatures_path = os.path.join(tmpdir, 'module_no_signatures')\nmodule(tf.constant(0.))\nprint('Saving model...')\ntf.saved_model.save(module, module_no_signatures_path)\n```\n\n----------------------------------------\n\nTITLE: Preparing Training and Validation Datasets - Python\nDESCRIPTION: This snippet creates directories for training and validation datasets of cats and dogs and prints out the number of images in each directory. This step is essential for organizing data before model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\n\n# Directory with our training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nprint ('Total training cat images:', len(os.listdir(train_cats_dir)))\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nprint ('Total training dog images:', len(os.listdir(train_dogs_dir)))\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nprint ('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nprint ('Total validation dog images:', len(os.listdir(validation_dogs_dir)))\n```\n\n----------------------------------------\n\nTITLE: Using Image Classification SavedModel with Keras\nDESCRIPTION: Example showing how to use a TensorFlow Hub image classification model with the Keras API. This demonstrates integration with Keras for image classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/images.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlogits = hub.KerasLayer(\"path/to/model\")(images)\n```\n\n----------------------------------------\n\nTITLE: Generating Model Predictions in Python with TensorFlow\nDESCRIPTION: This code snippet generates predictions for the training and test datasets using the trained model. It uses the model's predict method with a specified batch size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntrain_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Using Text Embedding Models with KerasLayer in TensorFlow Hub\nDESCRIPTION: Shows how to integrate a text embedding model into a Keras model using the hub.KerasLayer wrapper, which handles variable tracking and training mode automatically.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nembeddings = hub.KerasLayer(\"path/to/model\", trainable=...)(text_input)\n```\n\n----------------------------------------\n\nTITLE: Implementing Dataset Benchmark Function\nDESCRIPTION: Function to measure dataset iteration performance with simulated training steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef benchmark(dataset, num_epochs=2):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for sample in dataset:\n            # Performing a training step\n            time.sleep(0.01)\n    print(\"Execution time:\", time.perf_counter() - start_time)\n```\n\n----------------------------------------\n\nTITLE: Defining a Python Generator for Counting\nDESCRIPTION: This snippet defines a Python generator function that yields numbers up to a specified stop value. It demonstrates a basic generator that can be used with tf.data.Dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef count(stop):\n  i = 0\n  while i<stop:\n    yield i\n    i += 1\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset for Training\nDESCRIPTION: Prepares the training data using TensorFlow's Dataset API, including shuffling and batching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices((x, y))\ndataset = dataset.shuffle(buffer_size=x.shape[0]).batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Neural Network Module\nDESCRIPTION: Implements a sequential model using two dense layers with tf.Module as the base class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass SequentialModule(tf.Module):\n  def __init__(self, name=None):\n    super().__init__(name=name)\n\n    self.dense_1 = Dense(in_features=3, out_features=3)\n    self.dense_2 = Dense(in_features=3, out_features=2)\n\n  def __call__(self, x):\n    x = self.dense_1(x)\n    return self.dense_2(x)\n```\n\n----------------------------------------\n\nTITLE: Sampling Mode Profiling with gRPC Server in Python\nDESCRIPTION: Start a gRPC server for on-demand profiling and capture a profile using the TensorBoard profile plugin. This method allows for remote profiling and can be used with distributed training setups.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Start a profiler server before your model runs.\ntf.profiler.experimental.server.start(6009)\n# (Model code goes here).\n#  Send a request to the profiler server to collect a trace of your model.\ntf.profiler.experimental.client.trace('grpc://localhost:6009',\n                                      'gs://your_tb_logdir', 2000)\n```\n\n----------------------------------------\n\nTITLE: Profiling with tf.profiler Function API in Python\nDESCRIPTION: Use the tf.profiler Function API to start and stop profiling programmatically. This method allows for more granular control over when profiling occurs during model execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntf.profiler.experimental.start('logdir')\n# Train the model here\ntf.profiler.experimental.stop()\n```\n\n----------------------------------------\n\nTITLE: Defining Multilingual Test Sentences\nDESCRIPTION: Creates parallel sets of sentences in multiple languages for testing cross-lingual similarity, including Arabic, Chinese, English, French, German, Italian, Japanese, Korean, Russian and Spanish.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Some texts of different lengths in different languages.\narabic_sentences = ['كلب', 'الجراء لطيفة.', 'أستمتع بالمشي لمسافات طويلة على طول الشاطئ مع كلبي.']\nchinese_sentences = ['狗', '小狗很好。', '我喜欢和我的狗一起沿着海滩散步。']\nenglish_sentences = ['dog', 'Puppies are nice.', 'I enjoy taking long walks along the beach with my dog.']\nfrench_sentences = ['chien', 'Les chiots sont gentils.', 'J\\'aime faire de longues promenades sur la plage avec mon chien.']\ngerman_sentences = ['Hund', 'Welpen sind nett.', 'Ich genieße lange Spaziergänge am Strand entlang mit meinem Hund.']\nitalian_sentences = ['cane', 'I cuccioli sono carini.', 'Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.']\njapanese_sentences = ['犬', '子犬はいいです', '私は犬と一緒にビーチを散歩するのが好きです']\nkorean_sentences = ['개', '강아지가 좋다.', '나는 나의 개와 해변을 따라 길게 산책하는 것을 즐긴다.']\nrussian_sentences = ['собака', 'Милые щенки.', 'Мне нравится подолгу гулять по пляжу со своей собакой.']\nspanish_sentences = ['perro', 'Los cachorros son agradables.', 'Disfruto de dar largos paseos por la playa con mi perro.']\n\n# Multilingual example\nmultilingual_example = [\"Willkommen zu einfachen, aber\", \"verrassend krachtige\", \"multilingüe\", \"compréhension du language naturel\", \"модели.\", \"大家是什么意思\" , \"보다 중요한\", \".اللغة التي يتحدثونها\"]\nmultilingual_example_in_en =  [\"Welcome to simple yet\", \"surprisingly powerful\", \"multilingual\", \"natural language understanding\", \"models.\", \"What people mean\", \"matters more than\", \"the language they speak.\"]\n```\n\n----------------------------------------\n\nTITLE: Preparing MNIST Dataset for Training in TensorFlow\nDESCRIPTION: Demonstrates how to load and preprocess the MNIST dataset using TensorFlow's data API. This prepares the data for training a model in eager execution mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Fetch and format the mnist data\n(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n\ndataset = tf.data.Dataset.from_tensor_slices(\n  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n   tf.cast(mnist_labels,tf.int64)))\ndataset = dataset.shuffle(1000).batch(32)\n```\n\n----------------------------------------\n\nTITLE: Creating While Loops with AutoGraph\nDESCRIPTION: Shows how a Python while loop is converted to a TensorFlow while_loop operation, implementing a function that squares a number until it exceeds a threshold.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef square_until_stop(x, y):\n  while x < y:\n    x = x * x\n  return x\n\nwith tf.Graph().as_default():\n  with tf.Session() as sess:\n    print(sess.run(square_until_stop(tf.constant(4), tf.constant(100))))\n```\n\n----------------------------------------\n\nTITLE: Randomly Changing Image Brightness with Stateless Operations\nDESCRIPTION: Demonstrates the use of tf.image.stateless_random_brightness for deterministic random brightness adjustments. The example shows how different seed values produce different brightness changes while maintaining reproducibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(3):\n  seed = (i, 0)  # tuple of size (2,)\n  stateless_random_brightness = tf.image.stateless_random_brightness(\n      image, max_delta=0.95, seed=seed)\n  visualize(image, stateless_random_brightness)\n```\n\n----------------------------------------\n\nTITLE: Initializing MobileNetV2 for Transfer Learning in TensorFlow\nDESCRIPTION: Sets up a pre-trained MobileNetV2 model with frozen weights for transfer learning. The model expects input images of size 192x192 with 3 color channels and excludes the top classification layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\nmobile_net.trainable=False\n```\n\n----------------------------------------\n\nTITLE: Ordering Distributed Dataset Outputs with MirroredStrategy\nDESCRIPTION: Demonstrates how to maintain proper ordering of outputs when processing data across multiple workers using tf.distribute.MirroredStrategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\ndataset_size = 24\nbatch_size = 6\ndataset = tf.data.Dataset.range(dataset_size).enumerate().batch(batch_size)\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n\ndef predict(index, inputs):\n  outputs = 2 * inputs\n  return index, outputs\n\nresult = {}\nfor index, inputs in dist_dataset:\n  output_index, outputs = mirrored_strategy.run(predict, args=(index, inputs))\n  indices = list(mirrored_strategy.experimental_local_results(output_index))\n  rindices = []\n  for a in indices:\n    rindices.extend(a.numpy())\n  outputs = list(mirrored_strategy.experimental_local_results(outputs))\n  routputs = []\n  for a in outputs:\n    routputs.extend(a.numpy())\n  for i, value in zip(rindices, routputs):\n    result[i] = value\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Slicing Sparse Tensors in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to slice sparse tensors using tf.sparse.slice. It extracts specific portions from the previously created sparse patterns and converts them to dense tensors for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nsparse_slice_A = tf.sparse.slice(sparse_pattern_A, start = [0,0], size = [8,5])\nsparse_slice_B = tf.sparse.slice(sparse_pattern_B, start = [0,5], size = [8,6])\nsparse_slice_C = tf.sparse.slice(sparse_pattern_C, start = [0,10], size = [8,6])\nprint(tf.sparse.to_dense(sparse_slice_A))\nprint(tf.sparse.to_dense(sparse_slice_B))\nprint(tf.sparse.to_dense(sparse_slice_C))\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset from TensorFlow Datasets\nDESCRIPTION: Download and load the MNIST dataset using TensorFlow Datasets, splitting it into train and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndatasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\nmnist_train, mnist_test = datasets['train'], datasets['test']\n```\n\n----------------------------------------\n\nTITLE: Making Predictions on New Unlabeled Data with TensorFlow\nDESCRIPTION: Demonstrates how to use a trained model to make predictions on new, unlabeled examples. Includes probability calculation using softmax and mapping predictions to class names for Iris species classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\npredict_dataset = tf.convert_to_tensor([\n    [5.1, 3.3, 1.7, 0.5,],\n    [5.9, 3.0, 4.2, 1.5,],\n    [6.9, 3.1, 5.4, 2.1]\n])\n\npredictions = model(predict_dataset)\n\nfor i, logits in enumerate(predictions):\n  class_idx = tf.argmax(logits).numpy()\n  p = tf.nn.softmax(logits)[class_idx]\n  name = class_names[class_idx]\n  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tensor Filter in TensorFlow Debugger\nDESCRIPTION: Defines a custom filter callable that detects zero-valued scalar tensors and adds it to the debugging session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef my_filter_callable(datum, tensor):\n  # A filter that detects zero-valued scalars.\n  return len(tensor.shape) == 0 and tensor == 0.0\n\nsess.add_tensor_filter('my_filter', my_filter_callable)\n```\n\n----------------------------------------\n\nTITLE: Running STS Benchmark Evaluation\nDESCRIPTION: Implements the evaluation of sentence embeddings using the STS Benchmark, calculating Pearson correlation with human judgments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsts_data = sts_dev #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\n\ndef run_sts_benchmark(batch):\n  sts_encode1 = tf.nn.l2_normalize(embed(tf.constant(batch['sent_1'].tolist())), axis=1)\n  sts_encode2 = tf.nn.l2_normalize(embed(tf.constant(batch['sent_2'].tolist())), axis=1)\n  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n  clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n  scores = 1.0 - tf.acos(clip_cosine_similarities) / math.pi\n  \"\"\"Returns the similarity scores\"\"\"\n  return scores\n\ndev_scores = sts_data['sim'].tolist()\nscores = []\nfor batch in np.array_split(sts_data, 10):\n  scores.extend(run_sts_benchmark(batch))\n\npearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\nprint('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n    pearson_correlation[0], pearson_correlation[1]))\n```\n\n----------------------------------------\n\nTITLE: Retrieving label names for specific indices\nDESCRIPTION: This code demonstrates how to access the text labels corresponding to specific numeric label indices in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nlabel_names[[1,1,3,0]]\n```\n\n----------------------------------------\n\nTITLE: Distributed Model Training with ParameterServerStrategy in TensorFlow\nDESCRIPTION: This code shows how to use ParameterServerStrategy for distributed training. It includes dataset preparation, model definition, compilation, and training using the Keras API within the strategy's scope.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(\n      (features, labels)).shuffle(10).repeat().batch(64)\n\neval_dataset = tf.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).repeat().batch(1)\n\nwith strategy.scope():\n  model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\n  optimizer = tf.keras.optimizers.legacy.Adagrad(learning_rate=0.05)\n  model.compile(optimizer, \"mse\")\n\nmodel.fit(dataset, epochs=5, steps_per_epoch=10)\n```\n\n----------------------------------------\n\nTITLE: Checking prediction shape\nDESCRIPTION: Prints the shape of the predictions output from the model, which should have dimensions of batch size x number of classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npredictions.shape\n```\n\n----------------------------------------\n\nTITLE: Implementing Adam Optimizer in TensorFlow Core\nDESCRIPTION: Custom implementation of the Adam optimizer that maintains exponentially moving averages of gradients and squared gradients, with bias correction, for efficient model parameter updates during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass Adam:\n\n    def __init__(self, learning_rate=1e-3, beta_1=0.9, beta_2=0.999, ep=1e-7):\n      # Initialize optimizer parameters and variable slots\n      self.beta_1 = beta_1\n      self.beta_2 = beta_2\n      self.learning_rate = learning_rate\n      self.ep = ep\n      self.t = 1.\n      self.v_dvar, self.s_dvar = [], []\n      self.built = False\n      \n    def apply_gradients(self, grads, vars):\n      # Initialize variables on the first call\n      if not self.built:\n        for var in vars:\n          v = tf.Variable(tf.zeros(shape=var.shape))\n          s = tf.Variable(tf.zeros(shape=var.shape))\n          self.v_dvar.append(v)\n          self.s_dvar.append(s)\n        self.built = True\n      # Update the model variables given their gradients\n      for i, (d_var, var) in enumerate(zip(grads, vars)):\n        self.v_dvar[i].assign(self.beta_1*self.v_dvar[i] + (1-self.beta_1)*d_var)\n        self.s_dvar[i].assign(self.beta_2*self.s_dvar[i] + (1-self.beta_2)*tf.square(d_var))\n        v_dvar_bc = self.v_dvar[i]/(1-(self.beta_1**self.t))\n        s_dvar_bc = self.s_dvar[i]/(1-(self.beta_2**self.t))\n        var.assign_sub(self.learning_rate*(v_dvar_bc/(tf.sqrt(s_dvar_bc) + self.ep)))\n      self.t += 1.\n      return \n```\n\n----------------------------------------\n\nTITLE: Creating a Fully Replicated Rank-2 DTensor in TensorFlow\nDESCRIPTION: Example of creating a 3x2 rank-2 DTensor that is fully replicated across all devices in a two-dimensional mesh. Each device holds an identical copy of the complete tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfully_replicated_dtensor = dtensor_from_array(\n    tf.reshape(tf.range(6), (3, 2)),\n    layout=dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh))\n# Or, layout=tensor.Layout.fully_replicated(mesh, rank=2)\n\nfor component_tensor in dtensor.unpack(fully_replicated_dtensor):\n  print(\"Device:\", component_tensor.device, \",\", component_tensor)\n```\n\n----------------------------------------\n\nTITLE: Printing Performance Metrics for All Models\nDESCRIPTION: Outputs the mean absolute error for each model in the multi_performance dictionary, allowing for direct numerical comparison between different forecasting approaches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_70\n\nLANGUAGE: python\nCODE:\n```\nfor name, value in multi_performance.items():\n  print(f'{name:8s}: {value[metric_name]:0.4f}')\n```\n\n----------------------------------------\n\nTITLE: Using Ragged Tensors with tf.function in Python\nDESCRIPTION: This example shows how to use ragged tensors with @tf.function-decorated functions. The make_palindrome function works with both ragged and non-ragged tensors, demonstrating the flexibility of tf.function with ragged tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef make_palindrome(x, axis):\n  return tf.concat([x, tf.reverse(x, [axis])], axis)\n```\n\nLANGUAGE: python\nCODE:\n```\nmake_palindrome(tf.constant([[1, 2], [3, 4], [5, 6]]), axis=1)\n```\n\nLANGUAGE: python\nCODE:\n```\nmake_palindrome(tf.ragged.constant([[1, 2], [3], [4, 5, 6]]), axis=1)\n```\n\n----------------------------------------\n\nTITLE: Calculating Torso and Body Range for MoveNet\nDESCRIPTION: Computes the maximum distance from each keypoint to the center location for both full body and torso keypoints. This information is used to determine the crop size for the next frame.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef determine_torso_and_body_range(\n    keypoints, target_keypoints, center_y, center_x):\n  \"\"\"Calculates the maximum distance from each keypoints to the center location.\n\n  The function returns the maximum distances from the two sets of keypoints:\n  full 17 keypoints and 4 torso keypoints. The returned information will be\n  used to determine the crop size. See determineCropRegion for more detail.\n  \"\"\"\n  torso_joints = ['left_shoulder', 'right_shoulder', 'left_hip', 'right_hip']\n  max_torso_yrange = 0.0\n  max_torso_xrange = 0.0\n  for joint in torso_joints:\n    dist_y = abs(center_y - target_keypoints[joint][0])\n    dist_x = abs(center_x - target_keypoints[joint][1])\n    if dist_y > max_torso_yrange:\n      max_torso_yrange = dist_y\n    if dist_x > max_torso_xrange:\n      max_torso_xrange = dist_x\n\n  max_body_yrange = 0.0\n  max_body_xrange = 0.0\n  for joint in KEYPOINT_DICT.keys():\n    if keypoints[0, 0, KEYPOINT_DICT[joint], 2] < MIN_CROP_KEYPOINT_SCORE:\n      continue\n    dist_y = abs(center_y - target_keypoints[joint][0]);\n    dist_x = abs(center_x - target_keypoints[joint][1]);\n    if dist_y > max_body_yrange:\n      max_body_yrange = dist_y\n\n    if dist_x > max_body_xrange:\n      max_body_xrange = dist_x\n\n  return [max_torso_yrange, max_torso_xrange, max_body_yrange, max_body_xrange]\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Function for NumPy and TensorFlow NumPy in Python\nDESCRIPTION: This function benchmarks a given function 'f' on a set of inputs. It measures execution time and supports optional GPU synchronization for accurate GPU timing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef benchmark(f, inputs, number=30, force_gpu_sync=False):\n  \"\"\"Utility to benchmark `f` on each value in `inputs`.\"\"\"\n  times = []\n  for inp in inputs:\n    def _g():\n      if force_gpu_sync:\n        one = tnp.asarray(1)\n      f(inp)\n      if force_gpu_sync:\n        with tf.device(\"CPU:0\"):\n          tnp.copy(one)  # Force a sync for GPU case\n\n    _g()  # warmup\n    t = timeit.timeit(_g, number=number)\n    times.append(t * 1000. / number)\n  return times\n```\n\n----------------------------------------\n\nTITLE: Using Common Shape Functions in C++\nDESCRIPTION: Example of using predefined shape functions from TensorFlow's common_shape_fns.h to implement shape inference for the ZeroOut operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_42\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\")\n    .SetShapeFn(::tensorflow::shape_inference::UnchangedShape);\n```\n\n----------------------------------------\n\nTITLE: Using Unknown Dimensions for Flexible TensorFlow Function Tracing\nDESCRIPTION: Shows how to use None as a wildcard dimension in the input signature to allow tf.function to handle variably-sized inputs without retracing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\ndef g(x):\n  print('Tracing with', x)\n  return x\n\n# No retrace!\nprint(g(tf.constant([1, 2, 3])))\nprint(g(tf.constant([1, 2, 3, 4, 5])))\n\n```\n\n----------------------------------------\n\nTITLE: Slicing with Negative Indices in TensorFlow\nDESCRIPTION: Demonstrates slicing from the end of a tensor using negative indices in Python-style notation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(t1[-3:])\n```\n\n----------------------------------------\n\nTITLE: Evaluating Keras Model with NumPy Data and Dataset\nDESCRIPTION: Demonstrates how to evaluate a Keras model using both NumPy data and a `tf.data.Dataset`. It shows the usage of the `model.evaluate` method with different input types and parameters. The `batch_size` parameter controls the number of samples per batch, and the `steps` parameter specifies the number of batches to process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n```python\ndata = np.random.random((1000, 32))\nlabels = random_one_hot_labels((1000, 10))\n\nmodel.evaluate(data, labels, batch_size=32)\n\nmodel.evaluate(dataset, steps=30)\n```\n```\n\n----------------------------------------\n\nTITLE: Using Metrics in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to use tf.metrics in TensorFlow. It creates a Mean metric object, updates it with new data, and retrieves the result. This shows how metrics can be used to track statistics during model training or evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nm = tf.keras.metrics.Mean(\"loss\")\nm(0)\nm(5)\nm.result()  # => 2.5\nm([8, 9])\nm.result()  # => 5.5\n```\n\n----------------------------------------\n\nTITLE: Converting Between Tensor Types in Python\nDESCRIPTION: This set of examples shows how to convert between RaggedTensors, regular Tensors, and SparseTensors using various conversion methods provided by the RaggedTensor class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nragged_sentences = tf.ragged.constant([\n    ['Hi'], ['Welcome', 'to', 'the', 'fair'], ['Have', 'fun']])\n\n# RaggedTensor -> Tensor\nprint(ragged_sentences.to_tensor(default_value='', shape=[None, 10]))\n\n# Tensor -> RaggedTensor\nx = [[1, 3, -1, -1], [2, -1, -1, -1], [4, 5, 8, 9]]\nprint(tf.RaggedTensor.from_tensor(x, padding=-1))\n\n#RaggedTensor -> SparseTensor\nprint(ragged_sentences.to_sparse())\n\n# SparseTensor -> RaggedTensor\nst = tf.SparseTensor(indices=[[0, 0], [2, 0], [2, 1]],\n                     values=['a', 'b', 'c'],\n                     dense_shape=[3, 3])\nprint(tf.RaggedTensor.from_sparse(st))\n```\n\n----------------------------------------\n\nTITLE: Iterating Through Dimensions in TF2 Style\nDESCRIPTION: Demonstrates the simplified approach in TensorFlow 2.0 for iterating through dimensions, where dimensions are directly accessible as integers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfor value in shape:\n  print(value)\n```\n\n----------------------------------------\n\nTITLE: Loading ESRGAN TensorFlow Hub Model\nDESCRIPTION: Loads the ESRGAN model from TensorFlow Hub using the specified model URL.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = hub.load(SAVED_MODEL_PATH)\n```\n\n----------------------------------------\n\nTITLE: Plotting Multi-Step Dense Model Predictions\nDESCRIPTION: Visualizes the predictions of the multi-step dense model against actual data using the configured window generator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nconv_window.plot(multi_step_dense)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training Metrics for Citation Intent Classifier\nDESCRIPTION: This code creates plots to visualize the training metrics (accuracy, precision, recall, and loss) over time using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nglobal_steps = [x['global_step'] for x in metrics]\nfig, axes = plt.subplots(ncols=2, figsize=(20,8))\n\nfor axes_index, metric_names in enumerate([['accuracy', 'precision', 'recall'],\n                                            ['loss']]):\n  for metric_name in metric_names:\n    axes[axes_index].plot(global_steps, [x[metric_name] for x in metrics], label=metric_name)\n  axes[axes_index].legend()\n  axes[axes_index].set_xlabel(\"Global Step\")\n```\n\n----------------------------------------\n\nTITLE: Implementing CVAE Model Architecture in TensorFlow\nDESCRIPTION: Defines the Convolutional Variational Autoencoder (CVAE) class with encoder and decoder networks using TensorFlow Keras. The encoder outputs mean and log-variance parameters for the latent space, while the decoder reconstructs images from latent vectors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass CVAE(tf.keras.Model):\n  \"\"\"Convolutional variational autoencoder.\"\"\"\n\n  def __init__(self, latent_dim):\n    super(CVAE, self).__init__()\n    self.latent_dim = latent_dim\n    self.encoder = tf.keras.Sequential(\n        [\n            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n            tf.keras.layers.Conv2D(\n                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n            tf.keras.layers.Conv2D(\n                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n            tf.keras.layers.Flatten(),\n            # No activation\n            tf.keras.layers.Dense(latent_dim + latent_dim),\n        ]\n    )\n\n    self.decoder = tf.keras.Sequential(\n        [\n            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n            tf.keras.layers.Conv2DTranspose(\n                filters=64, kernel_size=3, strides=2, padding='same',\n                activation='relu'),\n            tf.keras.layers.Conv2DTranspose(\n                filters=32, kernel_size=3, strides=2, padding='same',\n                activation='relu'),\n            # No activation\n            tf.keras.layers.Conv2DTranspose(\n                filters=1, kernel_size=3, strides=1, padding='same'),\n        ]\n    )\n\n  @tf.function\n  def sample(self, eps=None):\n    if eps is None:\n      eps = tf.random.normal(shape=(100, self.latent_dim))\n    return self.decode(eps, apply_sigmoid=True)\n\n  def encode(self, x):\n    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n    return mean, logvar\n\n  def reparameterize(self, mean, logvar):\n    eps = tf.random.normal(shape=mean.shape)\n    return eps * tf.exp(logvar * .5) + mean\n\n  def decode(self, z, apply_sigmoid=False):\n    logits = self.decoder(z)\n    if apply_sigmoid:\n      probs = tf.sigmoid(logits)\n      return probs\n    return logits\n```\n\n----------------------------------------\n\nTITLE: Creating an Export Module Class in TensorFlow\nDESCRIPTION: Defines an ExportModule class that encapsulates a model with preprocessing and postprocessing functions. It uses tf.function with input signature for deployment optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nclass ExportModule(tf.Module):\n  def __init__(self, model, preprocess, class_pred):\n    # Initialize pre and postprocessing functions\n    self.model = model\n    self.preprocess = preprocess\n    self.class_pred = class_pred\n\n  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None, None, None], dtype=tf.uint8)]) \n  def __call__(self, x):\n    # Run the ExportModule for new data points\n    x = self.preprocess(x)\n    y = self.model(x)\n    y = self.class_pred(y)\n    return y \n```\n\n----------------------------------------\n\nTITLE: Creating Rank 0 Tensors in TensorFlow\nDESCRIPTION: Demonstrates creation of scalar (rank 0) tensors with different data types including string, integer, float, and complex numbers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmammal = tf.Variable(\"Elephant\", tf.string)\nignition = tf.Variable(451, tf.int16)\nfloating = tf.Variable(3.14159265359, tf.float64)\nits_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)\n```\n\n----------------------------------------\n\nTITLE: Implementing Residual Wrapper for Time Series Models\nDESCRIPTION: Creates a residual wrapper class that adds residual connections to any given model, helping with model convergence and performance in time series prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_55\n\nLANGUAGE: python\nCODE:\n```\nclass ResidualWrapper(tf.keras.Model):\n  def __init__(self, model):\n    super().__init__()\n    self.model = model\n\n  def call(self, inputs, *args, **kwargs):\n    delta = self.model(inputs, *args, **kwargs)\n\n    # The prediction for each time step is the input\n    # from the previous time step plus the delta\n    # calculated by the model.\n    return inputs + delta\n```\n\n----------------------------------------\n\nTITLE: Creating Audio Loading Function\nDESCRIPTION: Defines a function to load WAV files, convert them to float tensors, and resample to 16 kHz single-channel audio as required by YAMNet.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Utility functions for loading audio files and making sure the sample rate is correct.\n\n@tf.function\ndef load_wav_16k_mono(filename):\n    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n    file_contents = tf.io.read_file(filename)\n    wav, sample_rate = tf.audio.decode_wav(\n          file_contents,\n          desired_channels=1)\n    wav = tf.squeeze(wav, axis=-1)\n    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    return wav\n```\n\n----------------------------------------\n\nTITLE: Creating and Distributing Datasets\nDESCRIPTION: Creates TensorFlow datasets from the input images and labels, then distributes them across devices using the MirroredStrategy's experimental_distribute_dataset method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n\ntrain_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\ntest_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing Dense Neural Network for Time Series in TensorFlow\nDESCRIPTION: Creates a sequential dense neural network with multiple layers for time series prediction. The model consists of two hidden layers with 64 units each and ReLU activation, followed by a single output unit.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ndense = tf.keras.Sequential([\n    tf.keras.layers.Dense(units=64, activation='relu'),\n    tf.keras.layers.Dense(units=64, activation='relu'),\n    tf.keras.layers.Dense(units=1)\n])\n\nhistory = compile_and_fit(dense, single_step_window)\n\nval_performance['Dense'] = dense.evaluate(single_step_window.val, return_dict=True)\nperformance['Dense'] = dense.evaluate(single_step_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Instantiating the Feedback LSTM Model with Specific Parameters\nDESCRIPTION: Creates an instance of the FeedBack model with 32 LSTM units and a specific number of output steps defined by the OUT_STEPS variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_63\n\nLANGUAGE: python\nCODE:\n```\nfeedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients of Non-Scalar Targets in TensorFlow\nDESCRIPTION: This snippet demonstrates how to compute gradients of multiple targets with respect to a single source variable using TensorFlow's GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\nwith tf.GradientTape(persistent=True) as tape:\n  y0 = x**2\n  y1 = 1 / x\n\nprint(tape.gradient(y0, x).numpy())\nprint(tape.gradient(y1, x).numpy())\n```\n\n----------------------------------------\n\nTITLE: Restoring Distributed Generator State from Checkpoint\nDESCRIPTION: Restores a random generator's state within a distribution strategy context, allowing each replica to resume its deterministic random sequence from the saved point.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nwith strat.scope():\n  cp.restore(filename)\n  print(\"RNG stream from restoring point:\")\n  print(strat.run(lambda: g.normal([])))\n  print(strat.run(lambda: g.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Creating Advanced Checkpoint Callbacks in TensorFlow\nDESCRIPTION: Configures a more advanced checkpoint callback that saves the model weights every 5 epochs with unique filenames that include the epoch number. It also creates a new directory for these checkpoints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Include the epoch in the file name (uses `str.format`)\ncheckpoint_path = \"training_2/cp-{epoch:04d}.weights.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nos.mkdir(checkpoint_dir)\n\nbatch_size = 32\n\n# Calculate the number of batches per epoch\nimport math\nn_batches = len(train_images) / batch_size\nn_batches = math.ceil(n_batches)    # round up the number of batches to the nearest whole integer\n\n# Create a callback that saves the model's weights every 5 epochs\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_path,\n    verbose=1,\n    save_weights_only=True,\n    save_freq=5*n_batches)\n\n# Create a new model instance\nmodel = create_model()\n\n# Save the weights using the `checkpoint_path` format\nmodel.save_weights(checkpoint_path.format(epoch=0))\n\n# Train the model with the new callback\nmodel.fit(train_images,\n          train_labels,\n          epochs=50,\n          batch_size=batch_size,\n          callbacks=[cp_callback],\n          validation_data=(test_images, test_labels),\n          verbose=0)\n```\n\n----------------------------------------\n\nTITLE: Applying Text Vectorization to Datasets in TensorFlow\nDESCRIPTION: Processing the raw training, validation, and test datasets through the vectorize_text function to convert all text data into integer sequences for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = raw_train_ds.map(vectorize_text)\nval_ds = raw_val_ds.map(vectorize_text)\ntest_ds = raw_test_ds.map(vectorize_text)\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub Module for Style Transfer\nDESCRIPTION: Loads the pre-trained TensorFlow Hub module for arbitrary image stylization. The module takes content and style images as input and produces a stylized output image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Load TF Hub module.\n\nhub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\nhub_module = hub.load(hub_handle)\n```\n\n----------------------------------------\n\nTITLE: Using BackupAndRestore with Step-Based Saving in TensorFlow\nDESCRIPTION: Partially shown example of using BackupAndRestore callback with step-based backup frequency. This feature, available in tf-nightly and TensorFlow 2.10+, allows backing up the model every specified number of batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n# The training state is backed up at every 30 steps because `save_freq` is set\n```\n\n----------------------------------------\n\nTITLE: Displaying ResNet Block Summary\nDESCRIPTION: Uses the summary method to display a comprehensive overview of the ResNet block, including layer details and parameter counts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nblock.summary()\n```\n\n----------------------------------------\n\nTITLE: Writing TFRecord File in Python\nDESCRIPTION: This snippet demonstrates how to write observations to a TFRecord file using tf.io.TFRecordWriter. It converts each observation to a tf.train.Example message and writes it to the file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfilename = 'test.tfrecord'\n\n# Write the `tf.train.Example` observations to the file.\nwith tf.io.TFRecordWriter(filename) as writer:\n  for i in range(n_observations):\n    example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n    writer.write(example.numpy())\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Baseline Image in Matplotlib\nDESCRIPTION: Displays the black baseline image (all zeros) that will be used as the starting point for Integrated Gradients calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.imshow(baseline)\nplt.title(\"Baseline\")\nplt.axis('off')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Creating a Context Manager for Optimizer Options in TensorFlow\nDESCRIPTION: This code defines a context manager that allows temporarily changing TensorFlow optimizer options and restoring the original options afterward. It's used to demonstrate different optimizer settings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@contextlib.contextmanager\ndef options(options):\n  old_opts = tf.config.optimizer.get_experimental_options()\n  tf.config.optimizer.set_experimental_options(options)\n  try:\n    yield\n  finally:\n    tf.config.optimizer.set_experimental_options(old_opts)\n```\n\n----------------------------------------\n\nTITLE: Running Inference with a TensorFlow Lite Model in Python\nDESCRIPTION: This code snippet demonstrates how to load a TensorFlow Lite model, get its signature runner, and use it to make predictions on new data. It also compares the results with the original model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nTF_MODEL_FILE_PATH = 'model.tflite' # The default path to the saved TensorFlow Lite model\n\ninterpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)\n\nclassify_lite = interpreter.get_signature_runner('serving_default')\n\npredictions_lite = classify_lite(sequential_1_input=img_array)['outputs']\nscore_lite = tf.nn.softmax(predictions_lite)\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite))\n)\n\nprint(np.max(np.abs(predictions - predictions_lite)))\n```\n\n----------------------------------------\n\nTITLE: Image Loading and Preprocessing for Inception V1 Model\nDESCRIPTION: Defines a function to read, decode, and preprocess images for input into the Inception V1 model. It resizes images to 224x224 pixels and converts them to float32 format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef read_image(file_name):\n  image = tf.io.read_file(file_name)\n  image = tf.io.decode_jpeg(image, channels=3)\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n  return image\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies for TensorFlow Migration Example\nDESCRIPTION: Imports necessary libraries including TensorFlow, TensorFlow compat.v1, and TensorFlow Datasets to demonstrate early stopping migration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Testing the Complete FeedBack Model Output Shape\nDESCRIPTION: Verifies the output shape of the FeedBack model when run on example data, confirming the dimensions match the expected (batch, time, features) format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_67\n\nLANGUAGE: python\nCODE:\n```\nprint('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Sample code showing the Apache 2.0 license header that applies to the TensorFlow documentation. This is a standard header included in TensorFlow documentation files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Initializing Data Normalization for Single Feature\nDESCRIPTION: Creates and adapts a normalization layer for the Horsepower feature using TensorFlow Keras layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nhorsepower = np.array(train_features['Horsepower'])\n\nhorsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\nhorsepower_normalizer.adapt(horsepower)\n```\n\n----------------------------------------\n\nTITLE: Loading WAV Files in TensorFlow Dataset\nDESCRIPTION: Defines a mapping function to load WAV files into the TensorFlow dataset pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef load_wav_for_map(filename, label, fold):\n  return load_wav_16k_mono(filename), label, fold\n\nmain_ds = main_ds.map(load_wav_for_map)\nmain_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow datasets from NumPy arrays\nDESCRIPTION: Converts NumPy arrays to TensorFlow datasets using tf.data.Dataset.from_tensor_slices(). This creates datasets containing pairs of examples and their corresponding labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n```\n\n----------------------------------------\n\nTITLE: Splitting and Preparing Training Datasets\nDESCRIPTION: Splits the dataset into train, validation and test sets based on folds, and prepares them for training with caching and batching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ncached_ds = main_ds.cache()\ntrain_ds = cached_ds.filter(lambda embedding, label, fold: fold < 4)\nval_ds = cached_ds.filter(lambda embedding, label, fold: fold == 4)\ntest_ds = cached_ds.filter(lambda embedding, label, fold: fold == 5)\n\nremove_fold_column = lambda embedding, label, fold: (embedding, label)\n\ntrain_ds = train_ds.map(remove_fold_column)\nval_ds = val_ds.map(remove_fold_column)\ntest_ds = test_ds.map(remove_fold_column)\n\ntrain_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Reading CSV File with Pandas in Python\nDESCRIPTION: This snippet demonstrates how to read the Titanic CSV file using pandas and display the first few rows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.read_csv(titanic_file)\ndf.head()\n```\n\n----------------------------------------\n\nTITLE: Implementing TensorFlow API Dispatchers for MaskedTensor\nDESCRIPTION: Defines dispatch decorators to override default behavior of TensorFlow APIs for MaskedTensor operations, including unary and binary elementwise operations and matrix multiplication.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\n@tf.experimental.dispatch_for_unary_elementwise_apis(MaskedTensor)\ndef unary_elementwise_op_handler(op, x):\n return MaskedTensor(op(x.values), x.mask)\n\n@tf.experimental.dispatch_for_binary_elementwise_apis(\n    Union[MaskedTensor, tf.Tensor],\n    Union[MaskedTensor, tf.Tensor])\ndef binary_elementwise_op_handler(op, x, y):\n  x = convert_to_masked_tensor(x)\n  y = convert_to_masked_tensor(y)\n  return MaskedTensor(op(x.values, y.values), x.mask & y.mask)\n\n@tf.experimental.dispatch_for_api(tf.matmul)\ndef masked_matmul(a: MaskedTensor, b,\n                  transpose_a=False, transpose_b=False,\n                  adjoint_a=False, adjoint_b=False,\n                  a_is_sparse=False, b_is_sparse=False,\n                  output_type=None,\n                  grad_a=False, grad_b=False,\n                  name=None,\n                  ):\n  if isinstance(a, MaskedTensor):\n    a = a.with_default(0)\n  if isinstance(b, MaskedTensor):\n    b = b.with_default(0)\n  return tf.matmul(a, b, transpose_a, transpose_b, adjoint_a,\n                   adjoint_b, a_is_sparse, b_is_sparse,\n                   output_type)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating the FeedBack LSTM Model\nDESCRIPTION: Compiles, trains, and evaluates the FeedBack model on validation and test datasets. After training, it stores performance metrics in the multi_val_performance and multi_performance dictionaries and plots predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_68\n\nLANGUAGE: python\nCODE:\n```\nhistory = compile_and_fit(feedback_model, multi_window)\n\nIPython.display.clear_output()\n\nmulti_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val, return_dict=True)\nmulti_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0, return_dict=True)\nmulti_window.plot(feedback_model)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for MoveNet Pose Detection\nDESCRIPTION: Imports required Python libraries including TensorFlow, TensorFlow Hub, numpy, OpenCV, matplotlib, and imageio for pose detection and visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow_docs.vis import embed\nimport numpy as np\nimport cv2\n\n# Import matplotlib libraries\nfrom matplotlib import pyplot as plt\nfrom matplotlib.collections import LineCollection\nimport matplotlib.patches as patches\n\n# Some modules to display an animation using imageio.\nimport imageio\nfrom IPython.display import HTML, display\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor using row_splits in TensorFlow\nDESCRIPTION: Demonstrates the basic internal encoding of RaggedTensor by creating a ragged tensor from flat values and row_splits. The row_splits indicate how the values are divided into rows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=[3, 1, 4, 1, 5, 9, 2],\n    row_splits=[0, 4, 4, 6, 7])\nprint(rt)\n```\n\n----------------------------------------\n\nTITLE: Configuring TF_CONFIG Environment Variable for Multi-Worker Training\nDESCRIPTION: Shows how to set up the TF_CONFIG environment variable as a JSON string to specify cluster configuration for distributed training across multiple workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"TF_CONFIG\"] = json.dumps({\n    \"cluster\": {\n        \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n        \"ps\": [\"host4:port\", \"host5:port\"]\n    },\n   \"task\": {\"type\": \"worker\", \"index\": 1}\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Datasets for Performance\nDESCRIPTION: This code snippet shows how to optimize the TensorFlow datasets for performance. It applies caching, shuffling, and prefetching to improve data loading efficiency during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n\ntrain_ds = train_ds.batch(2)\nval_ds = val_ds.batch(2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradient Descent with Momentum in TensorFlow\nDESCRIPTION: This class implements the momentum optimization algorithm using TensorFlow. It initializes the learning rate and momentum parameters, and provides a method to apply gradients to variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Momentum(tf.Module):\n\n  def __init__(self, learning_rate=1e-3, momentum=0.7):\n    # Initialize parameters\n    self.learning_rate = learning_rate\n    self.momentum = momentum\n    self.change = 0.\n    self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n\n  def apply_gradients(self, grads, vars):\n    # Update variables \n    for grad, var in zip(grads, vars):\n      curr_change = self.learning_rate*grad + self.momentum*self.change\n      var.assign_sub(curr_change)\n      self.change = curr_change\n```\n\n----------------------------------------\n\nTITLE: Copyright and License Declaration in Python\nDESCRIPTION: Copyright declaration and Apache 2.0 license information for the TensorFlow Hub Authors, formatted as a Python comment block.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Copyright 2022 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Examining a single prediction from TensorFlow model\nDESCRIPTION: Inspects the prediction for the first image in the test dataset. The output is an array of 10 probability values representing the model's confidence for each class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npredictions[0]\n```\n\n----------------------------------------\n\nTITLE: Inspecting Sequence Dataset Format in Python\nDESCRIPTION: Examines the first batch of the sequence dataset to understand the shape and content of the input features and target labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfor seq, target in seq_ds.take(1):\n  print('sequence shape:', seq.shape)\n  print('sequence elements (first 10):', seq[0: 10])\n  print()\n  print('target:', target)\n```\n\n----------------------------------------\n\nTITLE: Creating Numeric Feature Columns in TensorFlow\nDESCRIPTION: Code that creates numeric feature columns for each input feature in the training data, which specify how the model should use each feature.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Feature columns describe how to use the input.\nmy_feature_columns = []\nfor key in train_x.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from File Paths in TensorFlow\nDESCRIPTION: Creates a tf.data.Dataset from file paths using list_files, then takes and prints the first 5 file paths from the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_57\n\nLANGUAGE: python\nCODE:\n```\nlist_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))\n\nfor f in list_ds.take(5):\n  print(f.numpy())\n```\n\n----------------------------------------\n\nTITLE: Creating Dense Neural Network for Multi-output Prediction\nDESCRIPTION: Implements a sequential dense neural network with two hidden layers of 64 units each and ReLU activation, followed by an output layer matching the number of features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_53\n\nLANGUAGE: python\nCODE:\n```\ndense = tf.keras.Sequential([\n    tf.keras.layers.Dense(units=64, activation='relu'),\n    tf.keras.layers.Dense(units=64, activation='relu'),\n    tf.keras.layers.Dense(units=num_features)\n])\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Type-Specific ZeroOut Ops in C++\nDESCRIPTION: Demonstrates separate implementations of ZeroOut op for int32 and float types. Each class handles tensor input/output and implements the zeroing logic for its specific type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_30\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nclass ZeroOutInt32Op : public OpKernel {\n  // as before\n};\n\nclass ZeroOutFloatOp : public OpKernel {\n public:\n  explicit ZeroOutFloatOp(OpKernelConstruction* context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<float>();\n\n    // Create an output tensor\n    Tensor* output = NULL;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_tensor.shape(), &output));\n    auto output_flat = output->template flat<float>();\n\n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the first input value\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<int32>(\"T\"),\n    ZeroOutInt32Op);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<float>(\"T\"),\n    ZeroOutFloatOp);\n```\n\n----------------------------------------\n\nTITLE: Running Sentence Similarity Benchmark Evaluation\nDESCRIPTION: Executes the similarity benchmark using TensorFlow session and computes Pearson correlation coefficient between predicted and actual similarity scores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef run_sts_benchmark(session):\n  \"\"\"Returns the similarity scores\"\"\"\n  scores = session.run(\n      sim_scores,\n      feed_dict={\n          sts_input1.values: values1,\n          sts_input1.indices:  indices1,\n          sts_input1.dense_shape:  dense_shape1,\n          sts_input2.values:  values2,\n          sts_input2.indices:  indices2,\n          sts_input2.dense_shape:  dense_shape2,\n      })\n  return scores\n\n\nwith tf.Session() as session:\n  session.run(tf.global_variables_initializer())\n  session.run(tf.tables_initializer())\n  scores = run_sts_benchmark(session)\n\npearson_correlation = scipy.stats.pearsonr(scores, similarity_scores)\nprint('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n    pearson_correlation[0], pearson_correlation[1]))\n```\n\n----------------------------------------\n\nTITLE: Incremental Variable Updates\nDESCRIPTION: Demonstrates how to incrementally update Variable values using the assign_add method, which adds the given values to the existing ones.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nvar.assign_add([1, 1, 1])\n```\n\n----------------------------------------\n\nTITLE: Testing Tensor Value Immutability in ExtensionType in Python\nDESCRIPTION: Demonstrates that tensor values within an ExtensionType are also immutable and cannot be modified.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  mt.mask[0] = False\nexcept TypeError as e:\n  print(f\"Got expected TypeError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Demonstrating WeakTensor Type Deferral\nDESCRIPTION: Example showing how a WeakTensor (a tensor without an explicitly specified dtype) defers to the dtype of a stronger-typed tensor in an operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntf.constant(1.2) + tf.constant(3.1, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.3>\n```\n\n----------------------------------------\n\nTITLE: Creating Function to Select Subset of Classes\nDESCRIPTION: Defines a function that creates a dictionary containing a specified number of files per class for a subset of classes, useful for creating balanced class distributions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef select_subset_of_classes(files_for_class, classes, files_per_class):\n  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n\n    Args:\n      files_for_class: Dictionary of class names (key) and files (values).\n      classes: List of classes.\n      files_per_class: Number of files per class of interest.\n\n    Returns:\n      Dictionary with class as key and list of specified number of video files in that class.\n  \"\"\"\n  files_subset = dict()\n\n  for class_name in classes:\n    class_files = files_for_class[class_name]\n    files_subset[class_name] = class_files[:files_per_class]\n\n  return files_subset\n```\n\n----------------------------------------\n\nTITLE: Evaluating ESRGAN Performance with PSNR Metric\nDESCRIPTION: Visualizes the super resolution result and calculates the Peak Signal-to-Noise Ratio (PSNR) metric to quantitatively evaluate the enhancement quality compared to the original image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n# Calculating PSNR wrt Original Image\npsnr = tf.image.psnr(\n    tf.clip_by_value(fake_image, 0, 255),\n    tf.clip_by_value(hr_image, 0, 255), max_val=255)\nprint(\"PSNR Achieved: %f\" % psnr)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for FILM Frame Interpolation\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, TensorFlow Hub, NumPy, and mediapy for image and video processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport requests\nimport numpy as np\n\nfrom typing import Generator, Iterable, List, Optional\nimport mediapy as media\n```\n\n----------------------------------------\n\nTITLE: Exporting a TensorFlow 1 Estimator as a SavedModel\nDESCRIPTION: This snippet demonstrates how to export a TensorFlow 1 Estimator as a SavedModel. It defines a model function, creates an Estimator, trains it for one step, and exports it as a SavedModel with a serving input function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef model_fn(features, labels, mode):\n  output = add_two(features['input'])\n  step = tf1.train.get_global_step()\n  return tf.estimator.EstimatorSpec(\n      mode,\n      predictions=output,\n      train_op=step.assign_add(1),\n      loss=tf.constant(0.),\n      export_outputs={\n          tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: \\\n          tf.estimator.export.PredictOutput({'output': output})})\nest = tf.estimator.Estimator(model_fn, 'estimator-checkpoints')\n\n# Train for one step to create a checkpoint.\ndef train_fn():\n  return tf.data.Dataset.from_tensors({'input': 3.})\nest.train(train_fn, steps=1)\n\n# This utility function `build_raw_serving_input_receiver_fn` takes in raw\n# tensor features and builds an \"input serving receiver function\", which\n# creates placeholder inputs to the model.\nserving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\n    {'input': tf.constant(3.)})  # Pass in a dummy input batch.\nestimator_path = est.export_saved_model('exported-estimator', serving_input_fn)\n\n# Estimator's export_saved_model creates a time stamped directory. Move this\n# to a set path so it can be inspected with `saved_model_cli` in the cell below.\n!rm -rf estimator-model\nimport shutil\nshutil.move(estimator_path, 'estimator-model')\n```\n\n----------------------------------------\n\nTITLE: Saving MetaGraphDef in TensorFlow 1\nDESCRIPTION: This snippet shows how to create a simple computation graph, initialize variables, and save it as a MetaGraphDef in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  x = tf1.placeholder(tf.float32, shape=[], name='x')\n  v = tf.Variable(3.0, name='v')\n  y = tf.multiply(x, v, name='y')\n  with tf1.Session() as sess:\n    sess.run(v.initializer)\n    print(sess.run(y, feed_dict={x: 5}))\n    s = tf1.train.Saver()\n    s.export_meta_graph('multiply.pb', as_text=True)\n    s.save(sess, 'multiply_values.ckpt')\n```\n\n----------------------------------------\n\nTITLE: Concatenating RaggedTensors in TensorFlow\nDESCRIPTION: Shows how to concatenate ragged tensors along an axis, which joins each row to form a single row with the combined length.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nragged_x = tf.ragged.constant([[\"John\"], [\"a\", \"big\", \"dog\"], [\"my\", \"cat\"]])\nragged_y = tf.ragged.constant([[\"fell\", \"asleep\"], [\"barked\"], [\"is\", \"fuzzy\"]])\nprint(tf.concat([ragged_x, ragged_y], axis=1))\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with GradientTape in TensorFlow\nDESCRIPTION: Demonstrates how to use tf.GradientTape to compute the gradient of a sum-and-square operation with respect to the input tensor. Shows basic gradient tracking and computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nx = tf.ones((2, 2))\n\nwith tf.GradientTape() as t:\n  t.watch(x)\n  y = tf.reduce_sum(x)\n  z = tf.multiply(y, y)\n\n# Derivative of z with respect to the original input tensor x\ndz_dx = t.gradient(z, x)\nfor i in [0, 1]:\n  for j in [0, 1]:\n    assert dz_dx[i][j].numpy() == 8.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Wide Convolutional Window Generator\nDESCRIPTION: Creates a specialized WindowGenerator that accounts for the convolutional kernel width to ensure label and prediction lengths match when using wider input windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nLABEL_WIDTH = 24\nINPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\nwide_conv_window = WindowGenerator(\n    input_width=INPUT_WIDTH,\n    label_width=LABEL_WIDTH,\n    shift=1,\n    label_columns=['T (degC)'])\n\nwide_conv_window\n```\n\n----------------------------------------\n\nTITLE: Implementing Integral Approximation for Integrated Gradients in TensorFlow\nDESCRIPTION: This function implements the integral approximation step of the Integrated Gradients algorithm using the trapezoidal rule. It takes gradients as input and returns the approximated integral.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef integral_approximation(gradients):\n  # riemann_trapezoidal\n  grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n  integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n  return integrated_gradients\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients for Image Classification in TensorFlow\nDESCRIPTION: This function computes gradients of the model's predictions with respect to input images using TensorFlow's GradientTape. It takes images and a target class index as input and returns the gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef compute_gradients(images, target_class_idx):\n  with tf.GradientTape() as tape:\n    tape.watch(images)\n    logits = model(images)\n    probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n  return tape.gradient(probs, images)\n```\n\n----------------------------------------\n\nTITLE: Inspecting the Loaded Dataset\nDESCRIPTION: Displays the first few rows of the training dataset to verify the data structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain.head()\n```\n\n----------------------------------------\n\nTITLE: Image Processing and Visualization Functions\nDESCRIPTION: Helper functions for downloading, resizing images and visualizing detection results. Includes functions for drawing bounding boxes and displaying detection scores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/object_detection.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef display_image(image):\n  fig = plt.figure(figsize=(20, 15))\n  plt.grid(False)\n  plt.imshow(image)\n\ndef download_and_resize_image(url, new_width=256, new_height=256, display=False):\n  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n  response = urlopen(url)\n  image_data = response.read()\n  image_data = BytesIO(image_data)\n  pil_image = Image.open(image_data)\n  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.LANCZOS)\n  pil_image_rgb = pil_image.convert(\"RGB\")\n  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n  print(\"Image downloaded to %s.\" % filename)\n  if display:\n    display_image(pil_image)\n  return filename\n```\n\n----------------------------------------\n\nTITLE: Building Model with Mixed Precision Layers\nDESCRIPTION: Constructs a neural network model using Dense layers that will use mixed precision based on the global policy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ninputs = keras.Input(shape=(784,), name='digits')\nif tf.config.list_physical_devices('GPU'):\n  print('The model will run with 4096 units on a GPU')\n  num_units = 4096\nelse:\n  # Use fewer units on CPUs so the model finishes in a reasonable amount of time\n  print('The model will run with 64 units on a CPU')\n  num_units = 64\ndense1 = layers.Dense(num_units, activation='relu', name='dense_1')\nx = dense1(inputs)\ndense2 = layers.Dense(num_units, activation='relu', name='dense_2')\nx = dense2(x)\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Crosses\nDESCRIPTION: This code demonstrates how to create a feature cross, combining two features into a single feature. The `crossed_column()` method is used to combine 'sport' and 'city' into 'sport_x_city'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsport_x_city = tf.feature_column.crossed_column(\n    [\"sport\", \"city\"], hash_bucket_size=int(1e4))\n```\n\n----------------------------------------\n\nTITLE: Zipping Multiple Datasets\nDESCRIPTION: Combines two separate datasets into one dataset using the zip operation and displays the resulting dataset object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n\ndataset3\n```\n\n----------------------------------------\n\nTITLE: Creating Computational Convenience Functions in Python\nDESCRIPTION: Defines several helper functions: 'make_kernel' transforms a 2D array into a convolution kernel; 'simple_conv' performs a simplified 2D convolution operation; and 'laplace' computes the 2D Laplacian of an array using convolution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef make_kernel(a):\n  \"\"\"Transform a 2D array into a convolution kernel\"\"\"\n  a = np.asarray(a)\n  a = a.reshape(list(a.shape) + [1,1])\n  return tf.constant(a, dtype=1)\n\n\ndef simple_conv(x, k):\n  \"\"\"A simplified 2D convolution operation\"\"\"\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\n  return y[0, :, :, 0]\n\n\ndef laplace(x):\n  \"\"\"Compute the 2D laplacian of an array\"\"\"\n  laplace_k = make_kernel([[0.5, 1.0, 0.5,\n                           [1.0, -6., 1.0],\n                           [0.5, 1.0, 0.5]])\n  return simple_conv(x, laplace_k)\n\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Conversion Functions for tf.train.Example\nDESCRIPTION: Defines utility functions to convert standard Python/TensorFlow types into tf.train.Feature compatible formats for bytes, float and int64 data types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n```\n\n----------------------------------------\n\nTITLE: Creating a CNN Model for MNIST Classification on TPU\nDESCRIPTION: Defines a sequential Keras model with convolutional layers for MNIST image classification. The model uses L2 regularization on all layers to demonstrate regularization loss handling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  regularizer = tf.keras.regularizers.L2(1e-5)\n  return tf.keras.Sequential(\n      [tf.keras.layers.Conv2D(256, 3, input_shape=(28, 28, 1),\n                              activation='relu',\n                              kernel_regularizer=regularizer),\n       tf.keras.layers.Conv2D(256, 3,\n                              activation='relu',\n                              kernel_regularizer=regularizer),\n       tf.keras.layers.Flatten(),\n       tf.keras.layers.Dense(256,\n                             activation='relu',\n                             kernel_regularizer=regularizer),\n       tf.keras.layers.Dense(128,\n                             activation='relu',\n                             kernel_regularizer=regularizer),\n       tf.keras.layers.Dense(10,\n                             kernel_regularizer=regularizer)])\n```\n\n----------------------------------------\n\nTITLE: Loading and Using TensorFlow Hub Encoder in Python\nDESCRIPTION: Demonstrates how to load a TensorFlow Hub encoder and use it to process encoder inputs. This snippet shows the basic usage pattern for the encoder.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nencoder = hub.load(\"path/to/encoder\")\nencoder_outputs = encoder(encoder_inputs)\n```\n\n----------------------------------------\n\nTITLE: Simple Batching in TensorFlow Dataset API\nDESCRIPTION: Demonstrates batching with tf.data by creating two range datasets, zipping them together, and then batching them in groups of 4 elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_60\n\nLANGUAGE: python\nCODE:\n```\ninc_dataset = tf.data.Dataset.range(100)\ndec_dataset = tf.data.Dataset.range(0, -100, -1)\ndataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\nbatched_dataset = dataset.batch(4)\n\nfor batch in batched_dataset.take(4):\n  print([arr.numpy() for arr in batch])\n```\n\n----------------------------------------\n\nTITLE: Adding Current Directory to Python Path\nDESCRIPTION: Ensuring the current directory is in the Python path to allow importing files that will be created with %%writefile later in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif '.' not in sys.path:\n  sys.path.insert(0, '.')\n```\n\n----------------------------------------\n\nTITLE: Handling Numeric Stability in Output Layer\nDESCRIPTION: Demonstrates the correct way to handle the output layer for numeric stability when using mixed precision.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# INCORRECT: softmax and model output will be float16, when it should be float32\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\nprint('Outputs dtype: %s' % outputs.dtype.name)\n```\n\n----------------------------------------\n\nTITLE: Converting Arrays to DTensors in TensorFlow\nDESCRIPTION: Helper function that creates a DTensor from an array or tensor by first replicating it across all devices in a mesh, then sharding it according to a specified layout. This function is useful for quick prototyping in single-client environments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef dtensor_from_array(arr, layout, shape=None, dtype=None):\n  \"\"\"Convert a DTensor from something that looks like an array or Tensor.\n\n  This function is convenient for quick doodling DTensors from a known,\n  unsharded data object in a single-client environment. This is not the\n  most efficient way of creating a DTensor, but it will do for this\n  tutorial.\n  \"\"\"\n  if shape is not None or dtype is not None:\n    arr = tf.constant(arr, shape=shape, dtype=dtype)\n\n  # replicate the input to the mesh\n  a = dtensor.copy_to_mesh(arr,\n          layout=dtensor.Layout.replicated(layout.mesh, rank=layout.rank))\n  # shard the copy to the desirable layout\n  return dtensor.relayout(a, layout=layout)\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset with TensorFlow Datasets\nDESCRIPTION: Loads the MNIST dataset from TensorFlow Datasets and splits it into training, validation, and testing sets with a batch size of 128.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_data, val_data, test_data = tfds.load(\"mnist\", \n                                            split=['train[10000:]', 'train[0:10000]', 'test'],\n                                            batch_size=128, as_supervised=True)\n```\n\n----------------------------------------\n\nTITLE: Applying Gradients with Optimizer\nDESCRIPTION: Demonstrates how to calculate the loss and gradients for input data, then apply those gradients to update model parameters using the optimizer. The code also prints the loss before and after optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nloss_value, grads = grad(model, features, labels)\n\nprint(\"Step: {}, Initial Loss: {}\".format(global_step.numpy(),\n                                          loss_value.numpy()))\n\noptimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n\nprint(\"Step: {},         Loss: {}\".format(global_step.numpy(),\n                                          loss(model, features, labels).numpy()))\n```\n\n----------------------------------------\n\nTITLE: Defining Feature Conversion Functions for tf.Example in Python\nDESCRIPTION: These functions convert scalar values to tf.train.Feature types compatible with tf.Example. They handle bytes, float, and int64 conversions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n```\n\n----------------------------------------\n\nTITLE: Printing Dataset Examples\nDESCRIPTION: Demonstrates how to iterate through and print examples from the validation dataset, showing reviews and their corresponding labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfor review_batch, label_batch in val_ds.take(1):\n  for i in range(5):\n    print(\"Review: \", review_batch[i].numpy())\n    print(\"Label: \", label_batch[i].numpy())\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Dense Layer with DTensor Support\nDESCRIPTION: Custom Dense layer implementation that supports DTensor sharding through layout specifications for weights and biases\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Dense(tf.Module):\n\n  def __init__(self, input_size, output_size,\n               init_seed, weight_layout, activation=None):\n    super().__init__()\n\n    random_normal_initializer = tf.function(tf.random.stateless_normal)\n\n    self.weight = dtensor.DVariable(\n        dtensor.call_with_layout(\n            random_normal_initializer, weight_layout,\n            shape=[input_size, output_size],\n            seed=init_seed\n            ))\n    if activation is None:\n      activation = lambda x:x\n    self.activation = activation\n    \n    # bias is sharded the same way as the last axis of weight.\n    bias_layout = weight_layout.delete([0])\n\n    self.bias = dtensor.DVariable(\n        dtensor.call_with_layout(tf.zeros, bias_layout, [output_size]))\n\n  def __call__(self, x):\n    y = tf.matmul(x, self.weight) + self.bias\n    y = self.activation(y)\n\n    return y\n```\n\n----------------------------------------\n\nTITLE: Apache Beam Pipeline for Embedding Generation\nDESCRIPTION: Defines an Apache Beam pipeline that reads text data, generates embeddings using a TensorFlow Hub module, and writes the results to TFRecord files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef run_hub2emb(args):\n  '''Runs the embedding generation pipeline'''\n\n  options = beam.options.pipeline_options.PipelineOptions(**args)\n  args = namedtuple(\"options\", args.keys())(*args.values())\n\n  raw_metadata = create_metadata()\n  converter = tft.coders.CsvCoder(\n      column_names=['text'], schema=raw_metadata.schema)\n\n  with beam.Pipeline(args.runner, options=options) as pipeline:\n    with tft_beam.Context(args.temporary_dir):\n      # Read the sentences from the input file\n      sentences = ( \n          pipeline\n          | 'Read sentences from files' >> beam.io.ReadFromText(\n              file_pattern=args.data_dir)\n          | 'Convert to dictionary' >> beam.Map(converter.decode)\n      )\n\n      sentences_dataset = (sentences, raw_metadata)\n      preprocess_fn = make_preprocess_fn(args.module_url, args.random_projection_matrix)\n      # Generate the embeddings for the sentence using the TF-Hub module\n      embeddings_dataset, _ = (\n          sentences_dataset\n          | 'Extract embeddings' >> tft_beam.AnalyzeAndTransformDataset(preprocess_fn)\n      )\n\n      embeddings, transformed_metadata = embeddings_dataset\n      # Write the embeddings to TFRecords files\n      embeddings | 'Write embeddings to TFRecords' >> beam.io.tfrecordio.WriteToTFRecord(\n          file_path_prefix='{}/emb'.format(args.output_dir),\n          file_name_suffix='.tfrecords',\n          coder=tft.coders.ExampleProtoCoder(transformed_metadata.schema))\n```\n\n----------------------------------------\n\nTITLE: Using Preprocessor and Encoder with KerasLayer in TensorFlow\nDESCRIPTION: Demonstrates how to integrate a preprocessor and encoder into a Keras model using hub.KerasLayer wrappers, simplifying the handling of variables and training modes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nencoder_inputs = hub.KerasLayer(\"path/to/preprocessor\")(text_input)\nencoder_outputs = hub.KerasLayer(\"path/to/encoder\", trainable=True)(encoder_inputs)\nembeddings = encoder_outputs[\"default\"]\n```\n\n----------------------------------------\n\nTITLE: Visualizing model predictions with Matplotlib\nDESCRIPTION: Creates a grid of images with their predicted labels to visually inspect model predictions. Displays 30 images with their predicted class names as titles.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(10,9))\nplt.subplots_adjust(hspace=0.5)\n\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(predicted_label_batch[n].title())\n  plt.axis('off')\n_ = plt.suptitle(\"Model predictions\")\n```\n\n----------------------------------------\n\nTITLE: Using Strategy in Optimizer or Library Code\nDESCRIPTION: Example of using the currently active strategy in library code to perform operations like reduction. This approach allows writing distribution-aware libraries that work regardless of the active strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# In optimizer or other library code\n# Get currently active strategy\nstrategy = tf.distribute.get_strategy()\nstrategy.reduce(\"SUM\", 1., axis=None)  # reduce some values\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets with Preprocessing Applied\nDESCRIPTION: Prepares the training and testing datasets by applying the preprocessing functions, caching, shuffling, and batching. This optimizes the data pipeline for training the CycleGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrain_horses = train_horses.cache().map(\n    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\n\ntrain_zebras = train_zebras.cache().map(\n    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\n\ntest_horses = test_horses.map(\n    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\n\ntest_zebras = test_zebras.map(\n    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Random Image Rotation using SciPy and TensorFlow\nDESCRIPTION: Implementation of random image rotation using scipy.ndimage through tf.py_function. Rotates images randomly between -30 and 30 degrees.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_75\n\nLANGUAGE: python\nCODE:\n```\n@tf.py_function(Tout=tf.float32)\ndef random_rotate_image(image):\n  image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n  return image\n```\n\n----------------------------------------\n\nTITLE: Displaying Model Summary\nDESCRIPTION: Prints a summary of the complete model architecture showing all layers, their output shapes, and trainable parameter counts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Listing available speech commands in the dataset\nDESCRIPTION: This code lists all the speech command categories available in the dataset by reading the directory names, excluding non-data files like README.md.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncommands = np.array(tf.io.gfile.listdir(str(data_dir)))\ncommands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\nprint('Commands:', commands)\n```\n\n----------------------------------------\n\nTITLE: Rebuilding Model for Text Generation with Batch Size 1 in TensorFlow\nDESCRIPTION: Creates a new model instance with batch size 1 for text generation, loads weights from the latest checkpoint, and builds the model with a flexible sequence length.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmodel = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n\nmodel.build(tf.TensorShape([1, None]))\n```\n\n----------------------------------------\n\nTITLE: Creating Main Function to Download UCF101 Subset\nDESCRIPTION: Defines a comprehensive function that handles the entire process of downloading a subset of the UCF101 dataset and splitting it into training, validation, and test sets with specified sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef download_ucf_101_subset(zip_url, num_classes, splits, download_dir):\n  \"\"\" Download a subset of the UCF101 dataset and split them into various parts, such as\n    training, validation, and test.\n\n    Args:\n      zip_url: A URL with a ZIP file with the data.\n      num_classes: Number of labels.\n      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n              (value is number of files per split).\n      download_dir: Directory to download data to.\n\n    Return:\n      Mapping of the directories containing the subsections of data.\n  \"\"\"\n  files = list_files_from_zip_url(zip_url)\n  for f in files:\n    path = os.path.normpath(f)\n    tokens = path.split(os.sep)\n    if len(tokens) <= 2:\n      files.remove(f) # Remove that item from the list if it does not have a filename\n  \n  files_for_class = get_files_per_class(files)\n\n  classes = list(files_for_class.keys())[:num_classes]\n\n  for cls in classes:\n    random.shuffle(files_for_class[cls])\n    \n  # Only use the number of classes you want in the dictionary\n  files_for_class = {x: files_for_class[x] for x in classes}\n\n  dirs = {}\n  for split_name, split_count in splits.items():\n    print(split_name, \":\")\n    split_dir = download_dir / split_name\n    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n    download_from_zip(zip_url, split_dir, split_files)\n    dirs[split_name] = split_dir\n\n  return dirs\n```\n\n----------------------------------------\n\nTITLE: Specifying Input Signature for tf.function with RaggedTensorSpec in Python\nDESCRIPTION: This snippet demonstrates how to explicitly specify the input_signature for a tf.function using tf.RaggedTensorSpec. It defines a function to calculate max and min values of a ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    input_signature=[tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32)])\ndef max_and_min(rt):\n  return (tf.math.reduce_max(rt, axis=-1), tf.math.reduce_min(rt, axis=-1))\n\nmax_and_min(tf.ragged.constant([[1, 2], [3], [4, 5, 6]]))\n```\n\n----------------------------------------\n\nTITLE: Loading a SavedModel and Examining Signatures\nDESCRIPTION: Loads the previously saved model using tf.saved_model.load and examines the available signature keys, which typically includes 'serving_default'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nloaded = tf.saved_model.load(mobilenet_save_path)\nprint(list(loaded.signatures.keys()))  # [\"serving_default\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Equality Operator for MaskedTensor in TensorFlow\nDESCRIPTION: Demonstrates how to override the __eq__ operator for MaskedTensor extension type to ignore masked elements when comparing for equality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  def __repr__(self):\n    return masked_tensor_str(self.values, self.mask)\n\n  def __eq__(self, other):\n    result = tf.math.equal(self.values, other.values)\n    result = result | ~(self.mask & other.mask)\n    return tf.reduce_all(result)\n\nx = MaskedTensor([1, 2, 3, 4], [True, True, False, True])\ny = MaskedTensor([5, 2, 0, 4], [False, True, False, True])\nprint(x == y)\n```\n\n----------------------------------------\n\nTITLE: Loading and Using a Saved TensorFlow Model\nDESCRIPTION: Shows how to load a previously saved model from disk using tf.saved_model.load and execute its methods with new inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nreloaded = tf.saved_model.load(save_path)\nreloaded.multiply(tf.constant([1, 2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Implementing GPU Kernel in CUDA\nDESCRIPTION: This snippet demonstrates the CUDA implementation of the 'Example' operation, including the CUDA kernel and GPU functor specialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_5\n\nLANGUAGE: CUDA\nCODE:\n```\n#ifdef GOOGLE_CUDA\n#define EIGEN_USE_GPU\n#include \"kernel_example.h\"\n#include \"tensorflow/core/util/gpu_kernel_helper.h\"\n\nusing namespace tensorflow;\n\nusing GPUDevice = Eigen::GpuDevice;\n\n// Define the CUDA kernel.\ntemplate <typename T>\n__global__ void ExampleCudaKernel(const int size, const T* in, T* out) {\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < size;\n       i += blockDim.x * gridDim.x) {\n    out[i] = 2 * __ldg(in + i);\n  }\n}\n\n// Define the GPU implementation that launches the CUDA kernel.\ntemplate <typename T>\nvoid ExampleFunctor<GPUDevice, T>::operator()(\n    const GPUDevice& d, int size, const T* in, T* out) {\n  // Launch the cuda kernel.\n  //\n  // See core/util/gpu_kernel_helper.h for example of computing\n  // block count and thread_per_block count.\n  int block_count = 1024;\n  int thread_per_block = 20;\n  ExampleCudaKernel<T>\n      <<<block_count, thread_per_block, 0, d.stream()>>>(size, in, out);\n}\n\n// Explicitly instantiate functors for the types of OpKernels registered.\ntemplate struct ExampleFunctor<GPUDevice, float>;\ntemplate struct ExampleFunctor<GPUDevice, int32>;\n\n#endif  // GOOGLE_CUDA\n```\n\n----------------------------------------\n\nTITLE: Downloading a Test Audio File\nDESCRIPTION: Downloads a sample WAV file (cat meow sound) to test the YAMNet model's inference capabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntesting_wav_file_name = tf.keras.utils.get_file('miaow_16k.wav',\n                                                'https://storage.googleapis.com/audioset/miaow_16k.wav',\n                                                cache_dir='./',\n                                                cache_subdir='test_data')\n\nprint(testing_wav_file_name)\n```\n\n----------------------------------------\n\nTITLE: Configuring Language Model and Generation Parameters\nDESCRIPTION: Sets up the language model configuration including which pre-trained model to use from TensorFlow Hub and the maximum length of text to generate.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title { run: \"auto\" }\nlanguage = \"en\" #@param [\"en\", \"ar\", \"zh-cn\", \"zh-tw\", \"nl\", \"fr\", \"de\", \"it\", \"ja\", \"ko\", \"pl\", \"pt\", \"ru\", \"es\", \"th\", \"tr\", \"bg\", \"ca\", \"cs\", \"da\", \"el\", \"et\", \"fa\", \"fi\", \"he\", \"hi\", \"hr\", \"hu\", \"id\", \"lt\", \"lv\", \"ms\", \"no\", \"ro\", \"sk\", \"sl\", \"sr\", \"sv\", \"tl\", \"uk\", \"vi\", \"multilingual-64k\", \"multilingual-128k\"]\nhub_module = \"https://tfhub.dev/google/wiki40b-lm-{}/1\".format(language)\nmax_gen_len = 20 #@param\n\nprint(\"Using the {} model to generate sequences of max length {}.\".format(hub_module, max_gen_len))\n\n```\n\n----------------------------------------\n\nTITLE: Preparing Training Dataset Pipeline\nDESCRIPTION: Sets up the training dataset pipeline with normalization, caching, shuffling, batching, and prefetching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 128\n\nds_train = ds_train.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_train = ds_train.cache()\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\nds_train = ds_train.batch(batch_size)\nds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Restoring Generator State to Different MirroredStrategy\nDESCRIPTION: Transfers a random generator's state from a 2-replica strategy to a 3-replica strategy while maintaining the deterministic sequence for overlapping replicas.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nstrat2 = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\", \"cpu:2\"])\nwith strat2.scope():\n  g2 = tf.random.Generator.from_seed(1)\n  cp2 = tf.train.Checkpoint(my_generator=g2)\n  cp2.restore(filename)\n  print(\"RNG stream from restoring point:\")\n  print(strat2.run(lambda: g2.normal([])))\n  print(strat2.run(lambda: g2.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Models with SavedModel\nDESCRIPTION: Demonstrates how to save and load models that use MaskedTensor using SavedModel functionality, including both Keras and custom models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nmasked_tensor_model_path = tempfile.mkdtemp()\ntf.saved_model.save(masked_tensor_model, masked_tensor_model_path)\nimported_model = tf.saved_model.load(masked_tensor_model_path)\nimported_model(a)\n```\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModule(tf.Module):\n  def __init__(self, variable_value):\n    super().__init__()\n    self.v = tf.Variable(variable_value)\n\n  @tf.function\n  def grow(self, x: MaskedTensor):\n    \"\"\"Increase values in `x` by multiplying them by `self.v`.\"\"\"\n    return MaskedTensor(x.values * self.v, x.mask)\n\nmodule = CustomModule(100.0)\n\nmodule.grow.get_concrete_function(MaskedTensor.Spec(shape=None,\n                                                    dtype=tf.float32))\ncustom_module_path = tempfile.mkdtemp()\ntf.saved_model.save(module, custom_module_path)\nimported_model = tf.saved_model.load(custom_module_path)\nimported_model.grow(MaskedTensor([1., 2, 3], [False, True, False]))\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Required Libraries for Image Classification\nDESCRIPTION: This snippet imports the necessary libraries for the image classification tutorial, including TensorFlow, Keras, NumPy, and Matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n```\n\n----------------------------------------\n\nTITLE: Initializing Window Generator for Multi-output Prediction\nDESCRIPTION: Sets up WindowGenerator instances for single-step and wide window predictions, configuring input width, label width and shift parameters for time series data processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nsingle_step_window = WindowGenerator(\n    # `WindowGenerator` returns all features as labels if you\n    # don't set the `label_columns` argument.\n    input_width=1, label_width=1, shift=1)\n\nwide_window = WindowGenerator(\n    input_width=24, label_width=24, shift=1)\n\nfor example_inputs, example_labels in wide_window.train.take(1):\n  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n```\n\n----------------------------------------\n\nTITLE: Plotting MSE Loss over Training Epochs with Matplotlib\nDESCRIPTION: Creates a plot using Matplotlib to visualize the changes in Mean Squared Error (MSE) loss over training epochs for both training and testing datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmatplotlib.rcParams['figure.figsize'] = [9, 6]\n\nplt.plot(range(epochs), train_losses, label = \"Training loss\")\nplt.plot(range(epochs), test_losses, label = \"Testing loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Mean squared error loss\")\nplt.legend()\nplt.title(\"MSE loss vs training iterations\");\n```\n\n----------------------------------------\n\nTITLE: Extracting Class Names from Directory Structure\nDESCRIPTION: Uses Python's pathlib to extract class names from the directory structure. This approach leverages the file organization to determine class labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\nprint(class_names)\n```\n\n----------------------------------------\n\nTITLE: Environment Setup and Package Installation\nDESCRIPTION: Installation of required packages including gym and pyglet for the CartPole environment\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install gym[classic_control]\n!pip install pyglet\n```\n\n----------------------------------------\n\nTITLE: Embedding Weights using Keras Dense Layers in Python\nDESCRIPTION: This snippet replicates embedding functionality using Keras layers without a combiner option. Requires `tensorflow` with `tf.keras.layers`. The weights are normalized before creating a sparse weight vector and embedding them using linear transformations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nids = tf.constant([[5, 11, 5, 17, 17]])\nweights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n\nweights = weights / tf.reduce_sum(weights, axis=-1, keepdims=True)\n\ncount_layer = tf.keras.layers.CategoryEncoding(\n    num_tokens=20, output_mode='count', sparse=True)\nembedding_layer = tf.keras.layers.Dense(4, use_bias=False)\nembedding_layer(count_layer(ids, count_weights=weights))\n```\n\n----------------------------------------\n\nTITLE: Enhancing Low Resolution Image with ESRGAN\nDESCRIPTION: Processes the low-resolution image with the ESRGAN model to generate a super-resolution version and measures the processing time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nstart = time.time()\nfake_image = model(lr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n```\n\n----------------------------------------\n\nTITLE: Preprocessing with ParameterServerStrategy using Model.fit API\nDESCRIPTION: Example showing how to use preprocessing layers with ParameterServerStrategy using Model.fit API. This approach requires using a DatasetCreator to handle distributed dataset creation, with the StringLookup preprocessing layer applied within the dataset function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.experimental.ParameterServerStrategy(\n    cluster_resolver,\n    variable_partitioner=variable_partitioner)\n\nwith strategy.scope():\n  preprocessing_layer = tf.keras.layers.StringLookup(vocabulary=FILE_PATH)\n  model = ...\n  model.compile(...)\n\ndef dataset_fn(input_context):\n  ...\n  dataset = dataset.map(preprocessing_layer)\n  ...\n  return dataset\n\ndataset_creator = tf.keras.utils.experimental.DatasetCreator(dataset_fn)\nmodel.fit(dataset_creator, epochs=5, steps_per_epoch=20, callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Processed Dataset Elements\nDESCRIPTION: Examines the shape of images and their corresponding labels in the processed dataset to verify the pipeline is working correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfor image, label in train_ds.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())\n```\n\n----------------------------------------\n\nTITLE: Computing Higher-Order Gradients with Nested GradientTapes in TensorFlow\nDESCRIPTION: Demonstrates how to compute higher-order derivatives by nesting GradientTape contexts. This example computes both the first and second derivatives of a cubic function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(1.0)  # Create a Tensorflow variable initialized to 1.0\n\nwith tf.GradientTape() as t:\n  with tf.GradientTape() as t2:\n    y = x * x * x\n  # Compute the gradient inside the 't' context manager\n  # which means the gradient computation is differentiable as well.\n  dy_dx = t2.gradient(y, x)\nd2y_dx2 = t.gradient(dy_dx, x)\n\nassert dy_dx.numpy() == 3.0\nassert d2y_dx2.numpy() == 6.0\n```\n\n----------------------------------------\n\nTITLE: Setting up License Information in Python\nDESCRIPTION: A code block defining the Apache License 2.0 as a Python comment block, which specifies the licensing terms for the tutorial code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Image Generation Utility\nDESCRIPTION: Implements a helper function to generate and display images during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef generate_images(model, test_input):\n  prediction = model(test_input)\n    \n  plt.figure(figsize=(12, 12))\n\n  display_list = [test_input[0], prediction[0]]\n  title = ['Input Image', 'Predicted Image']\n\n  for i in range(2):\n    plt.subplot(1, 2, i+1)\n    plt.title(title[i])\n    plt.imshow(display_list[i] * 0.5 + 0.5)\n    plt.axis('off')\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Optimizing Memory Usage in TensorFlow Data Pipeline\nDESCRIPTION: Shows a technique to optimize memory usage by splitting the mapping function into time-consuming and memory-consuming parts, caching the result of the time-consuming part.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n```\n\n----------------------------------------\n\nTITLE: Notes to MIDI Conversion Function\nDESCRIPTION: Function to convert note data back into a MIDI file format with customizable instrument and velocity settings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef notes_to_midi(\n  notes: pd.DataFrame,\n  out_file: str, \n  instrument_name: str,\n  velocity: int = 100,  # note loudness\n) -> pretty_midi.PrettyMIDI:\n\n  pm = pretty_midi.PrettyMIDI()\n  instrument = pretty_midi.Instrument(\n      program=pretty_midi.instrument_name_to_program(\n          instrument_name))\n\n  prev_start = 0\n  for i, note in notes.iterrows():\n    start = float(prev_start + note['step'])\n    end = float(start + note['duration'])\n    note = pretty_midi.Note(\n        velocity=velocity,\n        pitch=int(note['pitch']),\n        start=start,\n        end=end,\n    )\n    instrument.notes.append(note)\n    prev_start = start\n\n  pm.instruments.append(instrument)\n  pm.write(out_file)\n  return pm\n```\n\n----------------------------------------\n\nTITLE: Building Text Generation Graph with TensorFlow\nDESCRIPTION: Constructs a statically unrolled computational graph for generating text of a specified maximum length, including tokenization, token generation, and detokenization steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#@title Build the statically unrolled graph for `max_gen_len` tokens\nwith g.as_default():\n  # Tokenization with the sentencepiece model.\n  token_ids = module(dict(text=text), signature=\"tokenization\", as_dict=True)[\"token_ids\"]\n  inputs_np = token_ids\n  # Generate text by statically unrolling the computational graph\n  mems_np = [np.zeros([1, 0, model_dim], dtype=np.float32) for _ in range(n_layer)]\n\n  # Generate up to `max_gen_len` tokens\n  sampled_ids = []\n  for step in range(max_gen_len):\n    probs, mems_np = feedforward_step(module, inputs_np, mems_np)\n    sampled_id = tf.random.categorical(tf.math.log(probs[0]), num_samples=1, dtype=tf.int32)\n    sampled_id = tf.squeeze(sampled_id)\n    sampled_ids.append(sampled_id)\n    inputs_np = tf.reshape(sampled_id, [1, 1])\n\n  # Transform the ids into text\n  sampled_ids = tf.expand_dims(sampled_ids, axis=0)\n  generated_text = module(dict(token_ids=sampled_ids), signature=\"detokenization\", as_dict=True)[\"text\"]\n\n  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Columns\nDESCRIPTION: Defining categorical and numeric feature columns for the model using TensorFlow's feature column API\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nCATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n                       'embark_town', 'alone']\nNUMERIC_COLUMNS = ['age', 'fare']\n\nfeature_columns = []\nfor feature_name in CATEGORICAL_COLUMNS:\n  vocabulary = dftrain[feature_name].unique()\n  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n\nfor feature_name in NUMERIC_COLUMNS:\n  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n```\n\n----------------------------------------\n\nTITLE: Copying ND Arrays Between Devices\nDESCRIPTION: Shows how to explicitly copy TensorFlow NumPy arrays between devices using tnp.copy within a device context, demonstrating cross-device data movement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device(\"/device:CPU:0\"):\n  prediction_cpu = tnp.copy(prediction)\nprint(prediction.device)\nprint(prediction_cpu.device)\n```\n\n----------------------------------------\n\nTITLE: Registering a ZeroOut Custom Operation in TensorFlow\nDESCRIPTION: This code registers a new custom operation called 'ZeroOut' that takes an int32 tensor input and produces an int32 tensor output with the same shape. It includes a shape inference function to ensure output maintains the input tensor's shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\")\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model\nDESCRIPTION: Evaluates model performance on test dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(x_test,  y_test, verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Registering a TensorFlow Op with Attributes in C++\nDESCRIPTION: C++ code for registering a TensorFlow operation with custom attributes. This example registers a 'ZeroOut' op with an integer attribute named 'preserve_index' that controls which element to preserve.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_12\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"preserve_index: int\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\");\n```\n\n----------------------------------------\n\nTITLE: Retrieving and Displaying a Sample Image from Dataset\nDESCRIPTION: Extracts a single image and label from the training dataset for demonstration purposes. The code displays the image with its label name to provide context for the augmentation examples that follow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimage, label = next(iter(train_ds))\n_ = plt.imshow(image)\n_ = plt.title(get_label_name(label))\n```\n\n----------------------------------------\n\nTITLE: Initializing Feature Column Tables\nDESCRIPTION: Initializes both global variables and table lookup for feature columns. This is necessary to manage categorical data within a TensorFlow session. Both initializers must be run before using the feature column inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\nvar_init = tf.global_variables_initializer()\ntable_init = tf.tables_initializer()\nsess = tf.Session()\nsess.run((var_init, table_init))\n```\n\n----------------------------------------\n\nTITLE: Model Training Execution\nDESCRIPTION: Trains the model for 50 epochs using the prepared training and validation datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(x = train_ds,\n                    epochs = 50, \n                    validation_data = val_ds)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset Pipeline\nDESCRIPTION: Creates batched and shuffled tf.data.Dataset objects for efficient training and testing data pipelines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    (x_train, y_train)).shuffle(10000).batch(32)\n\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n```\n\n----------------------------------------\n\nTITLE: Training Keras Model with Fit Method in Python\nDESCRIPTION: This snippet demonstrates how to train a Keras model using the fit method. It specifies the input data, number of epochs, and batch size for training. The code also prints the shape of the input data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprint(x.shape[0])\nkeras_model.fit(x, y, epochs=10, batch_size=1000)\n```\n\n----------------------------------------\n\nTITLE: Enabling Device Placement Logging in TensorFlow\nDESCRIPTION: Sets up TensorFlow to log device placement information for operations and tensors. This helps in identifying which devices (CPU/GPU) are being used for different parts of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu_performance_analysis.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\n```\n\n----------------------------------------\n\nTITLE: Creating Image Preprocessing Pipeline\nDESCRIPTION: Defines a sequential model for image resizing and pixel value rescaling using Keras preprocessing layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nIMG_SIZE = 180\n\nresize_and_rescale = tf.keras.Sequential([\n  layers.Resizing(IMG_SIZE, IMG_SIZE),\n  layers.Rescaling(1./255)\n])\n```\n\n----------------------------------------\n\nTITLE: Processing File Paths to Extract Labels in TensorFlow\nDESCRIPTION: Defines a function to process file paths by reading the file content and extracting the label from the path, then applies it to a dataset using map.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_58\n\nLANGUAGE: python\nCODE:\n```\ndef process_path(file_path):\n  label = tf.strings.split(file_path, os.sep)[-2]\n  return tf.io.read_file(file_path), label\n\nlabeled_ds = list_ds.map(process_path)\n```\n\n----------------------------------------\n\nTITLE: Computing Element-wise Gradients in TensorFlow\nDESCRIPTION: This snippet shows how to compute element-wise gradients for the sigmoid function over a range of input values using TensorFlow's GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linspace(-10.0, 10.0, 200+1)\n\nwith tf.GradientTape() as tape:\n  tape.watch(x)\n  y = tf.nn.sigmoid(x)\n\ndy_dx = tape.gradient(y, x)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Training Loop with Checkpoints in TensorFlow 2\nDESCRIPTION: Implements a custom training loop that loads the last checkpoint at the start of each epoch after the first one. Includes gradient computation, optimization steps, and checkpoint saving after each training step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfor epoch in range(epochs):\n  if epoch > 0:\n      tf.train.load_checkpoint(save_path)\n  print(f\"\\nStart of epoch {epoch}\")\n\n  for step in range(steps_per_epoch):\n    with tf.GradientTape() as tape:\n\n      logits = model(x_train, training=True)\n      loss_value = loss_fn(y_train, logits)\n\n      grads = tape.gradient(loss_value, model.trainable_weights)\n      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n\n    save_path = checkpoint_manager.save()\n    print(f\"Checkpoint saved to {save_path}\")\n    print(f\"Training loss at step {step}: {loss_value}\")\n```\n\n----------------------------------------\n\nTITLE: Executing Custom Training Loop on TPU\nDESCRIPTION: Implements a training loop using the previously defined train_step function. The loop iterates through epochs and steps, executing the training function and printing training metrics after each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsteps_per_eval = 10000 // batch_size\n\ntrain_iterator = iter(train_dataset)\nfor epoch in range(5):\n  print('Epoch: {}/5'.format(epoch))\n\n  for step in range(steps_per_epoch):\n    train_step(train_iterator)\n  print('Current step: {}, training loss: {}, training accuracy: {}%'.format(\n      optimizer.iterations.numpy(),\n      round(float(training_loss.result()), 4),\n      round(float(training_accuracy.result()) * 100, 2)))\n  training_loss.reset_states()\n  training_accuracy.reset_states()\n```\n\n----------------------------------------\n\nTITLE: Evaluating Distributed Model in TensorFlow\nDESCRIPTION: This snippet demonstrates how to evaluate a distributed model trained with ParameterServerStrategy using the Keras API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(eval_dataset, steps=10, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Cycle Consistency Loss\nDESCRIPTION: Calculates the cycle consistency loss which ensures that cycled images are similar to the original input images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef calc_cycle_loss(real_image, cycled_image):\n  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n  \n  return LAMBDA * loss1\n```\n\n----------------------------------------\n\nTITLE: Implementing Checkpoint Management in TensorFlow Custom Training Loop\nDESCRIPTION: Code demonstrates how to implement checkpointing in a custom training loop to handle parameter server or coordinator failures. It saves model variables periodically and restores from the latest checkpoint before training starts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_manager = tf.train.CheckpointManager(\n    tf.train.Checkpoint(model=model, optimizer=optimizer),\n    checkpoint_dir,\n    max_to_keep=3)\nif checkpoint_manager.latest_checkpoint:\n  checkpoint = checkpoint_manager.checkpoint\n  checkpoint.restore(\n      checkpoint_manager.latest_checkpoint).assert_existing_objects_matched()\n\nglobal_steps = int(optimizer.iterations.numpy())\nstarting_epoch = global_steps // steps_per_epoch\n\nfor _ in range(starting_epoch, num_epochs):\n  for _ in range(steps_per_epoch):\n    coordinator.schedule(step_fn, args=(per_worker_iterator,))\n  coordinator.join()\n  checkpoint_manager.save()\n```\n\n----------------------------------------\n\nTITLE: Inspecting Trainable Variables of Custom Layer\nDESCRIPTION: Prints the names of all trainable variables in the custom layer to verify that the layer was built correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint([var.name for var in layer.trainable_variables])\n```\n\n----------------------------------------\n\nTITLE: Complete Feature Columns Training Example in TensorFlow 1 in Python\nDESCRIPTION: This snippet demonstrates a complete training example using feature columns in TensorFlow 1. Dependencies are `tensorflow` and feature columns APIs. It covers data preparation, model definition, training, and prediction with structured feature transformations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfeatures = {\n    'type': [0, 1, 1],\n    'size': ['small', 'small', 'medium'],\n    'weight': [2.7, 1.8, 1.6],\n}\nlabels = [1, 1, 0]\npredict_features = {'type': [0], 'size': ['foo'], 'weight': [-0.7]}\n\nvocab = ['small', 'medium', 'large']\none_hot_dims = 3\nembedding_dims = 4\nweight_mean = 2.0\nweight_variance = 1.0\n\ncategorical_col = tf1.feature_column.categorical_column_with_identity(\n    'type', num_buckets=one_hot_dims)\nindicator_col = tf1.feature_column.indicator_column(categorical_col)\n\nvocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n    'size', vocabulary_list=vocab, num_oov_buckets=1)\nembedding_col = tf1.feature_column.embedding_column(vocab_col, embedding_dims)\n\nnormalizer_fn = lambda x: (x - weight_mean) / math.sqrt(weight_variance)\nnumeric_col = tf1.feature_column.numeric_column(\n    'weight', normalizer_fn=normalizer_fn)\n\nestimator = tf1.estimator.DNNClassifier(\n    feature_columns=[indicator_col, embedding_col, numeric_col],\n    hidden_units=[1])\n\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n\nestimator.train(_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Loading Sample Images for Classification and Integrated Gradients\nDESCRIPTION: Downloads and processes two sample images (a fireboat and a giant panda) to demonstrate image classification and Integrated Gradients visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimg_url = {\n    'Fireboat': 'http://storage.googleapis.com/download.tensorflow.org/example_images/San_Francisco_fireboat_showing_off.jpg',\n    'Giant Panda': 'http://storage.googleapis.com/download.tensorflow.org/example_images/Giant_Panda_2.jpeg',\n}\n\nimg_paths = {name: tf.keras.utils.get_file(name, url) for (name, url) in img_url.items()}\nimg_name_tensors = {name: read_image(img_path) for (name, img_path) in img_paths.items()}\n```\n\n----------------------------------------\n\nTITLE: Running Classifier on Batch of Images and Visualizing Results\nDESCRIPTION: This snippet demonstrates how to use the pre-trained classifier on a batch of images from the custom dataset. It then visualizes the predictions by displaying the images along with their predicted class names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nresult_batch = classifier.predict(train_ds)\n\npredicted_class_names = imagenet_labels[tf.math.argmax(result_batch, axis=-1)]\n\nplt.figure(figsize=(10,9))\nplt.subplots_adjust(hspace=0.5)\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(predicted_class_names[n])\n  plt.axis('off')\n_ = plt.suptitle(\"ImageNet predictions\")\n```\n\n----------------------------------------\n\nTITLE: Downloading and Exploring Stack Overflow Dataset in TensorFlow\nDESCRIPTION: This code downloads the Stack Overflow dataset, extracts it, and explores its directory structure. It demonstrates how to use tf.keras.utils.get_file for dataset retrieval and pathlib for file system operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndata_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n\ndataset_dir = utils.get_file(\n    origin=data_url,\n    untar=True,\n    cache_dir='stack_overflow',\n    cache_subdir='')\n\ndataset_dir = pathlib.Path(dataset_dir).parent\n\nlist(dataset_dir.iterdir())\n\ntrain_dir = dataset_dir/'train'\nlist(train_dir.iterdir())\n\nsample_file = train_dir/'python/1755.txt'\n\nwith open(sample_file) as f:\n  print(f.read())\n```\n\n----------------------------------------\n\nTITLE: Inspecting MobileNet Trainable Variables\nDESCRIPTION: Shows how to examine trainable variables in a loaded MobileNet model, accessing the trainable_variables attribute to display information about the first few variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nloaded = tf.saved_model.load(mobilenet_save_path)\nprint(\"MobileNet has {} trainable variables: {}, ...\".format(\n          len(loaded.trainable_variables),\n          \", \".join([v.name for v in loaded.trainable_variables[:5]])))\n```\n\n----------------------------------------\n\nTITLE: Loading and Splitting TensorFlow Flowers Dataset\nDESCRIPTION: Downloads and splits the tf_flowers dataset into training, validation and test sets using TensorFlow Datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n(train_ds, val_ds, test_ds), metadata = tfds.load(\n    'tf_flowers',\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n    with_info=True,\n    as_supervised=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Plotting Confusion Matrix for MoViNet Model in TensorFlow\nDESCRIPTION: This code gets the actual and predicted labels from the test dataset and uses them to create and plot the confusion matrix for the MoViNet model's performance evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nactual, predicted = get_actual_predicted_labels(test_ds)\nplot_confusion_matrix(actual, predicted, label_names, 'test')\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential Model in Keras\nDESCRIPTION: This code demonstrates how to create a simple fully-connected neural network using the Sequential model in Keras. It adds three Dense layers with different configurations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential()\n# Adds a densely-connected layer with 64 units to the model:\nmodel.add(layers.Dense(64, activation='relu'))\n# Add another:\nmodel.add(layers.Dense(64, activation='relu'))\n# Add a softmax layer with 10 output units:\nmodel.add(layers.Dense(10, activation='softmax'))\n```\n\n----------------------------------------\n\nTITLE: Accessing Training History in TensorFlow Keras Model\nDESCRIPTION: Retrieving the training history dictionary from the History object returned by model.fit(). This contains metrics tracked during training for both training and validation phases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nhistory_dict = history.history\nhistory_dict.keys()\n```\n\n----------------------------------------\n\nTITLE: Basic Tensor Operations: Scalar Multiplication\nDESCRIPTION: Demonstrates scalar multiplication of a tensor by a constant value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n5 * x\n```\n\n----------------------------------------\n\nTITLE: Defining a tf.function with ExtensionType Parameters in Python\nDESCRIPTION: Shows how to define a tf.function that accepts an ExtensionType parameter, with tracing behavior based on TypeSpec.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef anonymize_player(player):\n  print(\"<<TRACING>>\")\n  return Player(\"<anonymous>\", player.attributes)\n```\n\n----------------------------------------\n\nTITLE: Debugging in tf.function with TensorFlow\nDESCRIPTION: This snippet provides debugging tips for working with tf.function in TensorFlow, stressing the importance of eager mode for debugging and ways to print and track intermediate values. It describes techniques for facilitating the debugging process using TensorFlow's configuration and debugging utilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_17\n\n\n\n----------------------------------------\n\nTITLE: Training a Model with Sharded Data using DTensor API in Python\nDESCRIPTION: Illustrates how to shard data from the input pipeline on the batch dimension and train a model with fully replicated weights. The example shows a training loop for 3 epochs, including progress tracking and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 3\n\nimage_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=4)\nlabel_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n\nfor epoch in range(num_epochs):\n  print(\"============================\") \n  print(\"Epoch: \", epoch)\n  for metric in metrics.values():\n    metric.reset_state()\n  step = 0\n  results = {}\n  pbar = tf.keras.utils.Progbar(target=None, stateful_metrics=[])\n  for input in ds_train:\n    images, labels = input[0], input[1]\n    images, labels = pack_dtensor_inputs(\n        images, labels, image_layout, label_layout)\n\n    results.update(train_step(model, images, labels, optimizer, metrics))\n    for metric_name, metric in metrics.items():\n      results[metric_name] = metric.result()\n\n    pbar.update(step, values=results.items(), finalize=False)\n    step += 1\n  pbar.update(step, values=results.items(), finalize=True)\n\n  for metric in eval_metrics.values():\n    metric.reset_state()\n  for input in ds_test:\n    images, labels = input[0], input[1]\n    images, labels = pack_dtensor_inputs(\n        images, labels, image_layout, label_layout)\n    results.update(eval_step(model, images, labels, eval_metrics))\n\n  for metric_name, metric in eval_metrics.items():\n    results[metric_name] = metric.result()\n  \n  for metric_name, metric in results.items():\n    print(f\"{metric_name}: {metric.numpy()}\")\n```\n\n----------------------------------------\n\nTITLE: Create TensorFlow Dataset from Directory\nDESCRIPTION: Configures and creates training and validation datasets from image directory using Keras utilities with specified batch size and image dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\nimg_height = 180\nimg_width = 180\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets\nDESCRIPTION: Creating datasets from tensors and files using tf.data.Dataset API\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n\n# Create a CSV file\nimport tempfile\n_, filename = tempfile.mkstemp()\n\nwith open(filename, 'w') as f:\n  f.write(\"\"\"Line 1\nLine 2\nLine 3\n  \"\"\")\n\nds_file = tf.data.TextLineDataset(filename)\n```\n\n----------------------------------------\n\nTITLE: Configuring Distribution Strategy\nDESCRIPTION: Creates MirroredStrategy for distributed training across multiple GPUs on a single machine\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n```\n\n----------------------------------------\n\nTITLE: Creating and Iterating Over a Basic TensorFlow Dataset\nDESCRIPTION: Demonstrates how to create a simple tf.data.Dataset, define a training step function, and iterate over the dataset in a non-distributed setting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 16\n# Create a tf.data.Dataset object.\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n\n@tf.function\ndef train_step(inputs):\n  features, labels = inputs\n  return labels - 0.3 * features\n\n# Iterate over the dataset using the for..in construct.\nfor inputs in dataset:\n  print(train_step(inputs))\n```\n\n----------------------------------------\n\nTITLE: Loading a TensorFlow SavedModel\nDESCRIPTION: Demonstrates how to load a TensorFlow model that was saved in the SavedModel format using the tf.saved_model.load function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nsaved_model = tf.saved_model.load('saved_model/my_model')\nsaved_model\n```\n\n----------------------------------------\n\nTITLE: Custom Tokenizer Implementation\nDESCRIPTION: Implements a custom tokenizer class using TensorFlow Text's UnicodeScriptTokenizer for text preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass MyTokenizer(tf.keras.layers.Layer):\n  def __init__(self):\n    super().__init__()\n    self.tokenizer = tf_text.UnicodeScriptTokenizer()\n\n  def call(self, text):\n    lower_case = tf_text.case_fold_utf8(text)\n    result = self.tokenizer.tokenize(lower_case)\n    if isinstance(result, tf.RaggedTensor):\n      result = result.to_tensor()\n    return result\n```\n\n----------------------------------------\n\nTITLE: Implementing Integrated Gradients Algorithm for Image Classification in TensorFlow\nDESCRIPTION: This function implements the full Integrated Gradients algorithm. It generates interpolated images, computes gradients, approximates the integral, and scales the result. It uses batching for efficiency and can handle large numbers of steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef integrated_gradients(baseline,\n                         image,\n                         target_class_idx,\n                         m_steps=50,\n                         batch_size=32):\n  # Generate alphas.\n  alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n\n  # Collect gradients.    \n  gradient_batches = []\n    \n  # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n  for alpha in tf.range(0, len(alphas), batch_size):\n    from_ = alpha\n    to = tf.minimum(from_ + batch_size, len(alphas))\n    alpha_batch = alphas[from_:to]\n\n    gradient_batch = one_batch(baseline, image, alpha_batch, target_class_idx)\n    gradient_batches.append(gradient_batch)\n      \n  # Concatenate path gradients together row-wise into single tensor.\n  total_gradients = tf.concat(gradient_batches, axis=0)\n\n  # Integral approximation through averaging gradients.\n  avg_gradients = integral_approximation(gradients=total_gradients)\n\n  # Scale integrated gradients with respect to input.\n  integrated_gradients = (image - baseline) * avg_gradients\n\n  return integrated_gradients\n```\n\n----------------------------------------\n\nTITLE: Setting Python Environment Variables for TensorFlow Build on Windows\nDESCRIPTION: Commands to configure Python-related environment variables to avoid common build issues. These set the appropriate paths for Python executable, libraries, and directories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nset PATH=path/to/python;%PATH% # [e.g. (C:/Python311)]\nset PATH=path/to/python/Scripts;%PATH% # [e.g. (C:/Python311/Scripts)] \nset PYTHON_BIN_PATH=path/to/python_virtualenv/Scripts/python.exe \nset PYTHON_LIB_PATH=path/to/python virtualenv/lib/site-packages \nset PYTHON_DIRECTORY=path/to/python_virtualenv/Scripts \n```\n\n----------------------------------------\n\nTITLE: Saving Initial Model Weights\nDESCRIPTION: Retrieves initial model weights for potential model reset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ninitial_weights = model.get_weights()\n```\n\n----------------------------------------\n\nTITLE: Creating DTensor Input Packing Utility\nDESCRIPTION: Defines a function to pack regular tensors into DTensors with appropriate layouts for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef pack_dtensor_inputs(images, labels, image_layout, label_layout):\n  num_local_devices = image_layout.mesh.num_local_devices()\n  images = tf.split(images, num_local_devices)\n  labels = tf.split(labels, num_local_devices)\n  images = dtensor.pack(images, image_layout)\n  labels = dtensor.pack(labels, label_layout)\n  return  images, labels\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Dependencies\nDESCRIPTION: Import necessary TensorFlow modules and matplotlib for visualization\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Plotting Time Series Window Configuration\nDESCRIPTION: Visualizes the window configuration for time series prediction, displaying how 3 hours of inputs are used to predict 1 hour into the future.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nconv_window.plot()\nplt.suptitle(\"Given 3 hours of inputs, predict 1 hour into the future.\")\n```\n\n----------------------------------------\n\nTITLE: Selecting Subset of Classes\nDESCRIPTION: Applies the select_subset_of_classes function to create a subset of the dataset with the specified number of classes and files per class, then displays the selected class names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfiles_subset = select_subset_of_classes(files_for_class, classes[:NUM_CLASSES], FILES_PER_CLASS)\nlist(files_subset.keys())\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Type Promotion in TensorFlow NumPy\nDESCRIPTION: Shows how TensorFlow NumPy handles type promotion for operations between arrays of different data types, following NumPy promotion rules rather than TensorFlow's stricter type handling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Type promotion for operations\")\nvalues = [tnp.asarray(1, dtype=d) for d in\n          (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\nfor i, v1 in enumerate(values):\n  for v2 in values[i + 1:]:\n    print(\"%s + %s => %s\" %\n          (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))\n```\n\n----------------------------------------\n\nTITLE: Processing Multiple Epochs with repeat() After batch() in TensorFlow\nDESCRIPTION: Demonstrates creating batches first and then repeating them for multiple epochs, which ensures clear epoch boundaries with consistent batch sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_65\n\nLANGUAGE: python\nCODE:\n```\ntitanic_batches = titanic_lines.batch(128).repeat(3)\n\nplot_batch_sizes(titanic_batches)\n```\n\n----------------------------------------\n\nTITLE: Processing Image Dataset in TensorFlow\nDESCRIPTION: This snippet demonstrates how to iterate over the image dataset and print the shapes of images and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nfor images, labels in ds.take(1):\n  print('images.shape: ', images.shape)\n  print('labels.shape: ', labels.shape)\n```\n\n----------------------------------------\n\nTITLE: Saving TensorFlow Model to Keras Archive in Python\nDESCRIPTION: This snippet demonstrates how to save a TensorFlow model to a .keras zip archive using the Model.save method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npath = 'my_model.keras'\n```\n\nLANGUAGE: python\nCODE:\n```\nmodel.save(path)\n```\n\n----------------------------------------\n\nTITLE: Model Training Step Function\nDESCRIPTION: Executes a single training step including running an episode, calculating returns and losses, and applying gradients. Optimized with tf.function for performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(\n    initial_state: tf.Tensor,\n    model: tf.keras.Model,\n    optimizer: tf.keras.optimizers.Optimizer,\n    gamma: float,\n    max_steps_per_episode: int) -> tf.Tensor:\n  \"\"\"Runs a model training step.\"\"\"\n\n  with tf.GradientTape() as tape:\n\n    # Run the model for one episode to collect training data\n    action_probs, values, rewards = run_episode(\n        initial_state, model, max_steps_per_episode)\n\n    # Calculate the expected returns\n    returns = get_expected_return(rewards, gamma)\n\n    # Convert training data to appropriate TF tensor shapes\n    action_probs, values, returns = [\n        tf.expand_dims(x, 1) for x in [action_probs, values, returns]]\n\n    # Calculate the loss values to update our network\n    loss = compute_loss(action_probs, values, returns)\n\n  # Compute the gradients from the loss\n  grads = tape.gradient(loss, model.trainable_variables)\n\n  # Apply the gradients to the model's parameters\n  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n  episode_reward = tf.math.reduce_sum(rewards)\n\n  return episode_reward\n```\n\n----------------------------------------\n\nTITLE: Preparing Input Data for FILM Model\nDESCRIPTION: Loads two images, prepares the time parameter, and creates the input dictionary for the FILM model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimage_1_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/one.png?raw=true\"\nimage_2_url = \"https://github.com/google-research/frame-interpolation/blob/main/photos/two.png?raw=true\"\n\ntime = np.array([0.5], dtype=np.float32)\n\nimage1 = load_image(image_1_url)\nimage2 = load_image(image_2_url)\n\ninput = {\n    'time': np.expand_dims(time, axis=0),\n     'x0': np.expand_dims(image1, axis=0),\n     'x1': np.expand_dims(image2, axis=0)\n}\nmid_frame = model(input)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Deferred Restoration in TensorFlow\nDESCRIPTION: This snippet shows how TensorFlow's Checkpoint system defers restores for variables that don't yet exist. It creates a variable, prints its initial zero value, assigns it to a layer, and then prints the restored value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndeferred_restore = tf.Variable(tf.zeros([1, 5]))\nprint(deferred_restore.numpy())  # Not restored; still zeros\nfake_layer.kernel = deferred_restore\nprint(deferred_restore.numpy())  # Restored\n```\n\n----------------------------------------\n\nTITLE: Visualizing Learning Rate Schedule Over Epochs\nDESCRIPTION: Plots the learning rate over training epochs to visualize how the InverseTimeDecay schedule affects learning rate. This helps understand the hyperbolic decrease pattern during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nstep = np.linspace(0,100000)\nlr = lr_schedule(step)\nplt.figure(figsize = (8,6))\nplt.plot(step/STEPS_PER_EPOCH, lr)\nplt.ylim([0,max(plt.ylim())])\nplt.xlabel('Epoch')\n_ = plt.ylabel('Learning Rate')\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Keras Callback for Epoch-Based Interruption\nDESCRIPTION: Defining a custom Keras callback that artificially raises a RuntimeError at a specified epoch to simulate training failure in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass InterruptAtEpoch(tf.keras.callbacks.Callback):\n  # A callback for artificially interrupting training.\n  def __init__(self, interrupting_epoch=3):\n    self.interrupting_epoch = interrupting_epoch\n\n  def on_epoch_end(self, epoch, log=None):\n    if epoch == self.interrupting_epoch:\n      raise RuntimeError('Interruption')\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Images for Model Input\nDESCRIPTION: These functions handle image loading, decoding, resizing, and normalization for model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_image(image):\n  image = tf.image.decode_jpeg(image, channels=3)\n  image = tf.image.resize(image, [192, 192])\n  image /= 255.0  # normalize to [0,1] range\n\n  return image\n```\n\nLANGUAGE: python\nCODE:\n```\ndef load_and_preprocess_image(path):\n  image = tf.read_file(path)\n  return preprocess_image(image)\n```\n\n----------------------------------------\n\nTITLE: Iterating Through Dimensions in TF1.x Style\nDESCRIPTION: Shows how to iterate through dimensions of a TensorShape in TensorFlow 1.x, where each dimension is an object requiring the .value attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfor dim in shape:\n    value = dim.value\n    print(value)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Server Setup\nDESCRIPTION: Implementation of TensorFlow server setup for worker and parameter server roles in distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"GRPC_FAIL_FAST\"] = \"use_caller\"\n\nserver = tf.distribute.Server(\n    cluster_resolver.cluster_spec(),\n    job_name=cluster_resolver.task_type,\n    task_index=cluster_resolver.task_id,\n    protocol=cluster_resolver.rpc_layer or \"grpc\",\n    start=True)\nserver.join()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow and NumPy Compatibility in Python\nDESCRIPTION: Converts between TensorFlow Tensors and NumPy ndarrays showing automatic and explicit conversions. It ensures integrated use of NumPy and TensorFlow data structures flexibly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\n\nndarray = np.ones([3, 3])\n\nprint(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\ntensor = tf.multiply(ndarray, 42)\nprint(tensor)\n\n\nprint(\"And NumPy operations convert Tensors to numpy arrays automatically\")\nprint(np.add(tensor, 1))\n\nprint(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\nprint(tensor.numpy())\n```\n\n----------------------------------------\n\nTITLE: Conditionally Selecting Distribution Strategy Based on Available Hardware\nDESCRIPTION: Example showing how to conditionally select a strategy based on available hardware. Uses MirroredStrategy if GPUs are available, otherwise falls back to the Default Strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  strategy = tf.distribute.MirroredStrategy()\nelse:  # Use the Default Strategy\n  strategy = tf.distribute.get_strategy()\n\nwith strategy.scope():\n  # Do something interesting\n  print(tf.Variable(1.))\n```\n\n----------------------------------------\n\nTITLE: Creating Low-Level CSV Dataset in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a low-level CSV dataset using tf.data.experimental.CsvDataset, specifying column types manually.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_49\n\nLANGUAGE: python\nCODE:\n```\ntitanic_types  = [tf.int32, tf.string, tf.float32, tf.int32, tf.int32, tf.float32, tf.string, tf.string, tf.string, tf.string]\ndataset = tf.data.experimental.CsvDataset(titanic_file, titanic_types , header=True)\n\nfor line in dataset.take(10):\n  print([item.numpy() for item in line])\n```\n\n----------------------------------------\n\nTITLE: Processing CSV Dataset in TensorFlow\nDESCRIPTION: This snippet shows how to iterate over the CSV dataset and print feature and label batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_46\n\nLANGUAGE: python\nCODE:\n```\nfor feature_batch, label_batch in titanic_batches.take(1):\n  print(\"'survived': {}\".format(label_batch))\n  print(\"features:\")\n  for key, value in feature_batch.items():\n    print(\"  {!r:20s}: {}\".format(key, value))\n```\n\n----------------------------------------\n\nTITLE: Installing pylint for TensorFlow Python Style Checking\nDESCRIPTION: Command to install pylint package using pip for checking Python code against TensorFlow style guidelines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install pylint\n```\n\n----------------------------------------\n\nTITLE: Creating Sheet Music Score with music21 in Python\nDESCRIPTION: This code uses the music21 library to create a sheet music score from the quantized notes and rests. It sets the tempo based on the best predictions per note and adds each note or rest to the score.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Creating the sheet music score.\nsc = music21.stream.Score()\n# Adjust the speed to match the actual singing.\nbpm = 60 * 60 / best_predictions_per_note\nprint ('bpm: ', bpm)\na = music21.tempo.MetronomeMark(number=bpm)\nsc.insert(0,a)\n\nfor snote in best_notes_and_rests:   \n    d = 'half'\n    if snote == 'Rest':      \n      sc.append(music21.note.Rest(type=d))\n    else:\n      sc.append(music21.note.Note(snote, type=d))\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset Pipeline Example\nDESCRIPTION: Example showing how to create a TensorFlow dataset pipeline with range, map, repeat and batch transformations. Used to demonstrate how iterator long names are generated in tf.data analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(10).map(lambda x: x).repeat(2).batch(5)\n```\n\n----------------------------------------\n\nTITLE: Showing Available SignatureDef Keys with SavedModel CLI\nDESCRIPTION: Command using SavedModel CLI to display all available SignatureDef keys within a specific MetaGraphDef tag-set. This helps users identify the different entry points or functions available in the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n```\n\n----------------------------------------\n\nTITLE: Showing Available MetaGraphDef Tag-Sets with SavedModel CLI\nDESCRIPTION: Command using SavedModel CLI to display all available MetaGraphDef tag-sets in a SavedModel. This helps users identify the different versions or configurations stored in the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir /tmp/saved_model_dir\n```\n\n----------------------------------------\n\nTITLE: Creating a test dataset by sharding the validation dataset\nDESCRIPTION: This code splits the validation dataset into two equal parts using the shard method, creating separate validation and test datasets for proper model evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntest_ds = val_ds.shard(num_shards=2, index=0)\nval_ds = val_ds.shard(num_shards=2, index=1)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Data Distribution (Python)\nDESCRIPTION: This snippet employs seaborn to create a pair plot of selected features from the training dataset to visually investigate the relationships and distributions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Importing Loss Functions for Regression in TensorFlow\nDESCRIPTION: This snippet shows how to import common loss functions used for regression problems in TensorFlow. It includes Mean Squared Error (MSE) and Mean Absolute Error (MAE).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.losses.MeanSquaredError\n```\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.losses.MeanAbsoluteError\n```\n\n----------------------------------------\n\nTITLE: Downloading and Reading Audio File for YAMNet Analysis in Python\nDESCRIPTION: This code downloads a WAV file, reads it using scipy, ensures the correct sample rate, and displays basic audio information. It also allows listening to the audio.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# wav_file_name = 'speech_whistling2.wav'\nwav_file_name = 'miaow_16k.wav'\nsample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\nsample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n\n# Show some basic information about the audio.\nduration = len(wav_data)/sample_rate\nprint(f'Sample rate: {sample_rate} Hz')\nprint(f'Total duration: {duration:.2f}s')\nprint(f'Size of the input: {len(wav_data)}')\n\n# Listening to the wav file.\nAudio(wav_data, rate=sample_rate)\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Linear Model\nDESCRIPTION: This snippet defines a simple linear model with weights and biases as TensorFlow variables. The model outputs predictions based on the input and the current weight and bias values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Model(object):\n  def __init__(self):\n    self.W = tf.Variable(5.0)\n    self.b = tf.Variable(0.0)\n\n  def __call__(self, x):\n    return self.W * x + self.b\n\nmodel = Model()\nassert model(3.0).numpy() == 15.0\n```\n\n----------------------------------------\n\nTITLE: Training Decompressed Classifier and Comparing Accuracy in Python\nDESCRIPTION: This code trains the decompressed classifier for one epoch and compares its accuracy with the original compressed classifier. It demonstrates how to use the decompressed model for further training and highlights the potential drop in validation accuracy due to lack of regularization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndecompressed_accuracy = train_model(\n    decompressed_classifier, training_dataset, validation_dataset, epochs=1)\n\nprint(f\"Accuracy of the compressed classifier: {compressed_accuracy:0.4f}\")\nprint(f\"Accuracy of the decompressed classifier after one more epoch of training: {decompressed_accuracy:0.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Monte Carlo Dropout Sampling in Python\nDESCRIPTION: This function performs Monte Carlo dropout sampling on test examples. It enables dropout during inference to generate multiple forward passes with different dropout masks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ndef mc_dropout_sampling(test_examples):\n  # Enable dropout during inference.\n  return resnet_model(test_examples, training=True)\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow Model to TensorFlow Lite with Optimization Options\nDESCRIPTION: Converts the saved model to TensorFlow Lite format with configurable optimization settings including weight quantization and activation quantization using a calibration dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n#@title Optimization settings\noptimize_lite_model = False  #@param {type:\"boolean\"}\n#@markdown Setting a value greater than zero enables quantization of neural network activations. A few dozen is already a useful amount.\nnum_calibration_examples = 60  #@param {type:\"slider\", min:0, max:1000, step:1}\nrepresentative_dataset = None\nif optimize_lite_model and num_calibration_examples:\n  # Use a bounded number of training examples without labels for calibration.\n  # TFLiteConverter expects a list of input tensors, each with batch size 1.\n  representative_dataset = lambda: itertools.islice(\n      ([image[None, ...]] for batch, _ in train_ds for image in batch),\n      num_calibration_examples)\n\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\nif optimize_lite_model:\n  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n  if representative_dataset:  # This is optional, see above.\n    converter.representative_dataset = representative_dataset\nlite_model_content = converter.convert()\n\nwith open(f\"/tmp/lite_flowers_model_{model_name}.tflite\", \"wb\") as f:\n  f.write(lite_model_content)\nprint(\"Wrote %sTFLite model of %d bytes.\" %\n      (\"optimized \" if optimize_lite_model else \"\", len(lite_model_content)))\n```\n\n----------------------------------------\n\nTITLE: Model Training Configuration\nDESCRIPTION: Configures the model training parameters including optimizer, loss function, and metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n              optimizer = keras.optimizers.Adam(learning_rate = 0.0001), \n              metrics = ['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Generating Basic Histogram Data with Moving Mean in Python\nDESCRIPTION: Creates histogram summaries containing normally distributed data where the mean increases over time. Uses tf.random_normal to generate the distribution and tf.summary.histogram to record the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensorboard_histograms.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nk = tf.placeholder(tf.float32)\n\n# Make a normal distribution, with a shifting mean\nmean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n# Record that distribution into a histogram summary\ntf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n\n# Setup a session and summary writer\nsess = tf.Session()\nwriter = tf.summary.FileWriter(\"/tmp/histogram_example\")\n\nsummaries = tf.summary.merge_all()\n\n# Setup a loop and write the summaries to disk\nN = 400\nfor step in range(N):\n  k_val = step/float(N)\n  summ = sess.run(summaries, feed_dict={k: k_val})\n  writer.add_summary(summ, global_step=step)\n```\n\n----------------------------------------\n\nTITLE: Normalizing Data with TensorFlow Module\nDESCRIPTION: This class implements data normalization using TensorFlow operations, allowing for standardization and unstandardization of input features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nclass Normalize(tf.Module):\n  def __init__(self, x):\n    # Initialize the mean and standard deviation for normalization\n    self.mean = tf.math.reduce_mean(x, axis=0)\n    self.std = tf.math.reduce_std(x, axis=0)\n\n  def norm(self, x):\n    # Normalize the input\n    return (x - self.mean)/self.std\n\n  def unnorm(self, x):\n    # Unnormalize the input\n    return (x * self.std) + self.mean\n\nnorm_x = Normalize(x_train_ohe)\nnorm_y = Normalize(y_train)\nx_train_norm, y_train_norm = norm_x.norm(x_train_ohe), norm_y.norm(y_train)\nx_test_norm, y_test_norm = norm_x.norm(x_test_ohe), norm_y.norm(y_test)\n```\n\n----------------------------------------\n\nTITLE: Using Converted Layer in Keras Functional Model in Python\nDESCRIPTION: This snippet demonstrates how to use the converted layer directly in Keras functional model construction. It creates a model using tf.keras.Input and the CompatV1LayerModel, then shows how to access model weights and losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ninputs = tf.keras.Input(shape=(5, 5, 5))\noutputs = CompatV1LayerModel(10)(inputs)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nx = tf.random.normal(shape=(8, 5, 5, 5))\nmodel(x)\n\n# Access the model variables and regularization losses\nmodel.weights\nmodel.losses\n```\n\n----------------------------------------\n\nTITLE: Creating a Bigger Model with Keras\nDESCRIPTION: Defines a larger neural network model using Keras Sequential API. The model consists of two dense layers with 512 units each and a ReLU activation function, followed by an output dense layer with sigmoid activation for binary classification. It compiles the model with the Adam optimizer, binary cross-entropy loss, and accuracy/binary cross-entropy metrics, and then prints a summary of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nbigger_model = keras.models.Sequential([\n    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(512, activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nbigger_model.compile(optimizer='adam',\n                     loss='binary_crossentropy',\n                     metrics=['accuracy','binary_crossentropy'])\n\nbigger_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic CSV Dataset with TensorFlow\nDESCRIPTION: Creates a simple CSV dataset using TensorFlow's experimental CsvDataset which reads files sequentially. It specifies column types and indicates that the files have headers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nsimple_font_ds = tf.data.experimental.CsvDataset(\n    font_csvs, \n    record_defaults=font_column_types, \n    header=True)\n```\n\n----------------------------------------\n\nTITLE: Converting RGB to Grayscale in TensorFlow Python\nDESCRIPTION: Illustrates the use of tf.image.rgb_to_grayscale function to convert an RGB image to grayscale. This is another utility from the tf.image module for image processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntf.image.rgb_to_grayscale\n```\n\n----------------------------------------\n\nTITLE: Loading and Labeling Text Datasets\nDESCRIPTION: Loads text files using TextLineDataset and applies labels to create labeled datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nlabeled_data_sets = []\n\nfor i, file_name in enumerate(FILE_NAMES):\n  lines_dataset = tf.data.TextLineDataset(str(parent_dir/file_name))\n  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n  labeled_data_sets.append(labeled_dataset)\n```\n\n----------------------------------------\n\nTITLE: Converting Keras Model to Estimator\nDESCRIPTION: Demonstrates the API call to convert a Keras model into a TensorFlow Estimator for distributed training purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.estimator.model_to_estimator\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset\nDESCRIPTION: Downloads MNIST dataset using TensorFlow Datasets and sets up data pipeline with normalization and batching\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n\nmnist_train, mnist_test = datasets['train'], datasets['test']\n\ndef scale(image, label):\n  image = tf.cast(image, tf.float32)\n  image /= 255\n  return image, label\n\ntrain_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\neval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Installing Audio Dependencies\nDESCRIPTION: System level installation of timidity and libsndfile1 for audio processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!sudo apt-get install -q -y timidity libsndfile1\n```\n\n----------------------------------------\n\nTITLE: Visualizing Attributions for Fireboat Image Classification in Python\nDESCRIPTION: This code snippet demonstrates how to use the plot_img_attributions function to visualize Integrated Gradients attributions for a 'Fireboat' image. It uses specific parameters for steps, color map, and overlay alpha to highlight the model's focus on water cannons and spouts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n_ = plot_img_attributions(image=img_name_tensors['Fireboat'],\n                          baseline=baseline,\n                          target_class_idx=555,\n                          m_steps=240,\n                          cmap=plt.cm.inferno,\n                          overlay_alpha=0.4)\n```\n\n----------------------------------------\n\nTITLE: Adding Values to Existing Tensor with tf.tensor_scatter_nd_add\nDESCRIPTION: Demonstrates how to add values at specific indices of an existing tensor using tf.tensor_scatter_nd_add.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nt11 = tf.constant([[2, 7, 0],\n                   [9, 0, 1],\n                   [0, 3, 8]])\n\n# Convert the tensor into a magic square by inserting numbers at appropriate indices\n\nt12 = tf.tensor_scatter_nd_add(t11,\n                               indices=[[0, 2], [1, 1], [2, 0]],\n                               updates=[6, 5, 4])\n\nprint(t12)\n```\n\n----------------------------------------\n\nTITLE: Image Flipping in TensorFlow Python\nDESCRIPTION: Shows how to use tf.image.flip_left_right function to flip an image horizontally. This is part of the tf.image module for image processing operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntf.image.flip_left_right\n```\n\n----------------------------------------\n\nTITLE: Timing Optimized CSV Dataset Processing\nDESCRIPTION: Times the processing of 20 batches from the optimized CSV dataset to demonstrate the performance improvement. This approach is significantly faster than the standard method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_61\n\nLANGUAGE: python\nCODE:\n```\n%%time\nfor i,batch in enumerate(fonts_fast.take(20)):\n  print('.',end='')\n\nprint()\n```\n\n----------------------------------------\n\nTITLE: Implementing Optimized TensorFlow Data Pipeline\nDESCRIPTION: Example showing the recommended order of operations for input pipeline optimization with tf.data, including file sharding, shuffling, and parsing operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nd = tf.data.Dataset.list_files(pattern, shuffle=False)\nd = d.shard(num_workers, worker_index)\nd = d.repeat(num_epochs)\nd = d.shuffle(shuffle_buffer_size)\nd = d.interleave(tf.data.TFRecordDataset,\n                 cycle_length=num_readers, block_length=1)\nd = d.map(parser_fn, num_parallel_calls=num_map_threads)\n```\n\n----------------------------------------\n\nTITLE: Setting Embedding Dimension for Text Classification Model in TensorFlow\nDESCRIPTION: Defining the embedding dimension parameter which determines the size of the dense vector representations for each word in the vocabulary of the text classification model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nembedding_dim = 16\n```\n\n----------------------------------------\n\nTITLE: Loading TensorBoard Extension and Viewing Training Logs\nDESCRIPTION: Loads the TensorBoard notebook extension and opens an embedded TensorBoard viewer to visualize and compare the training metrics for different model sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Load the TensorBoard notebook extension\n%load_ext tensorboard\n\n# Open an embedded TensorBoard viewer\n%tensorboard --logdir {logdir}/sizes\n```\n\n----------------------------------------\n\nTITLE: Showing Available Tag-Sets in SavedModel\nDESCRIPTION: Demonstrates how to use the 'show' command to display all available tag-sets in a SavedModel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir /tmp/saved_model_dir\nThe given SavedModel contains the following tag-sets:\nserve\nserve, gpu\n```\n\n----------------------------------------\n\nTITLE: Computing Element-wise Minimum with tf.tensor_scatter_nd_min\nDESCRIPTION: Demonstrates how to take the element-wise minimum between original tensor values and update values at specified indices using tf.tensor_scatter_nd_min.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nt14 = tf.constant([[-2, -7, 0],\n                   [-9, 0, 1],\n                   [0, -3, -8]])\n\nt15 = tf.tensor_scatter_nd_min(t14,\n                               indices=[[0, 2], [1, 1], [2, 0]],\n                               updates=[-6, -5, -4])\n\nprint(t15)\n```\n\n----------------------------------------\n\nTITLE: Creating Training Dataset from MIDI Files in Python\nDESCRIPTION: Extracts notes from a specified number of MIDI files and combines them into a single pandas DataFrame for training. This is the first step in preparing data for a music generation model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nnum_files = 5\nall_notes = []\nfor f in filenames[:num_files]:\n  notes = midi_to_notes(f)\n  all_notes.append(notes)\n\nall_notes = pd.concat(all_notes)\n```\n\n----------------------------------------\n\nTITLE: Saving JAX Model for Inference using TensorFlow SavedModel\nDESCRIPTION: Demonstrates how to save a JAX model for inference using TensorFlow SavedModel format. It wraps the JAX state in tf.Variables, converts the predict function, and saves the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nx, y = next(iter(train_data.unbatch().batch(13)))\n\nm = tf.Module()\nstate_vars = tf.nest.map_structure(tf.Variable, state)\nm.vars = tf.nest.flatten(state_vars)\npredict_fn = jax2tf.convert(model.predict, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\"])\n@tf.function(autograph=False, input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\ndef predict(data):\n    return predict_fn(state_vars, data)\nm.predict = predict\ntf.saved_model.save(m, \"./\")\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow Model with Binary Cross-Entropy Loss and Adam Optimizer\nDESCRIPTION: This snippet shows how to compile a TensorFlow model for binary classification. It uses the Adam optimizer and binary cross-entropy loss function. The model's performance is measured using binary accuracy with a threshold of 0.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n```\n\n----------------------------------------\n\nTITLE: Creating Lambda Layer for Random Image Inversion in TensorFlow\nDESCRIPTION: Creates a Lambda layer wrapper for the random inversion function. This approach provides a concise way to integrate custom augmentation into Keras models, returning a layer that can be applied to images with a specified inversion probability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef random_invert(factor=0.5):\n  return layers.Lambda(lambda x: random_invert_img(x, factor))\n\nrandom_invert = random_invert()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Text Processing in TensorFlow\nDESCRIPTION: This snippet imports the necessary TensorFlow, Keras, and other utility libraries required for text processing and dataset handling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport collections\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.layers import TextVectorization\n\nimport tensorflow_datasets as tfds\nimport tensorflow_text as tf_text\n```\n\n----------------------------------------\n\nTITLE: Broadcasting 2D Tensor with 2D RaggedTensor\nDESCRIPTION: Shows broadcasting between a 2D tensor with shape [3, 1] and a 2D ragged tensor with 3 rows, where the tensor values are broadcast across the ragged dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_49\n\nLANGUAGE: python\nCODE:\n```\n# x         (2d ragged):  3 x (num_rows)\n# y         (2d tensor):  3 x          1\n# Result    (2d ragged):  3 x (num_rows)\nx = tf.ragged.constant(\n   [[10, 87, 12],\n    [19, 53],\n    [12, 32]])\ny = [[1000], [2000], [3000]]\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Configuring Virtual CPUs for DTensor in TensorFlow\nDESCRIPTION: This snippet imports TensorFlow and DTensor, configures virtual CPUs, and sets up device lists for demonstration purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nfrom tensorflow.experimental import dtensor\n\nprint('TensorFlow version:', tf.__version__)\n\ndef configure_virtual_cpus(ncpu):\n  phy_devices = tf.config.list_physical_devices('CPU')\n  tf.config.set_logical_device_configuration(phy_devices[0], [\n        tf.config.LogicalDeviceConfiguration(),\n    ] * ncpu)\n\nconfigure_virtual_cpus(6)\nDEVICES = [f'CPU:{i}' for i in range(6)]\n\ntf.config.list_logical_devices('CPU')\n```\n\n----------------------------------------\n\nTITLE: Creating For Loops with TensorArray in AutoGraph\nDESCRIPTION: Demonstrates how AutoGraph handles Python for loops by converting them to TensorFlow operations, showing a function that squares each number in an array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=tf.autograph.experimental.Feature.LISTS)\ndef squares(nums):\n\n  result = tf.TensorArray(tf.int64, size=0, dynamic_size=True)\n  \n  for num in nums:\n    result.append(num * num)\n\n  return result.stack()\n\nwith tf.Graph().as_default():\n  with tf.Session() as sess:\n    print(sess.run(squares(tf.constant(np.arange(10)))))\n```\n\n----------------------------------------\n\nTITLE: Plotting Predictions and Uncertainty for SNGP in Python\nDESCRIPTION: This function plots normalized class probabilities and predictive uncertainties for a given model. It creates two subplots: one for class probability and another for predictive uncertainty.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef plot_predictions(pred_probs, model_name=\"\"):\n  \"\"\"Plot normalized class probabilities and predictive uncertainties.\"\"\"\n  # Compute predictive uncertainty.\n  uncertainty = pred_probs * (1. - pred_probs)\n\n  # Initialize the plot axes.\n  fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n\n  # Plots the class probability.\n  pcm_0 = plot_uncertainty_surface(pred_probs, ax=axs[0])\n  # Plots the predictive uncertainty.\n  pcm_1 = plot_uncertainty_surface(uncertainty, ax=axs[1])\n\n  # Adds color bars and titles.\n  fig.colorbar(pcm_0, ax=axs[0])\n  fig.colorbar(pcm_1, ax=axs[1])\n\n  axs[0].set_title(f\"Class Probability, {model_name}\")\n  axs[1].set_title(f\"(Normalized) Predictive Uncertainty, {model_name}\")\n\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Shuffle-then-Repeat Pattern in TensorFlow\nDESCRIPTION: Demonstrates the shuffle-then-repeat pattern which shows all elements of one epoch before moving to the next, and examines indices near the epoch boundary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_69\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.zip((counter, lines))\nshuffled = dataset.shuffle(buffer_size=100).batch(10).repeat(2)\n\nprint(\"Here are the item ID's near the epoch boundary:\\n\")\nfor n, line_batch in shuffled.skip(60).take(5):\n  print(n.numpy())\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Augmentation with Keras in Python\nDESCRIPTION: This code snippet creates a data augmentation pipeline using Keras preprocessing layers. It applies random flips, rotations, and zooms to the input images to increase the diversity of the training data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndata_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                  img_width,\n                                  3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Image Preprocessing Functions for Testing\nDESCRIPTION: Defines a function to preprocess test images by applying normalization without random jittering. This ensures consistent evaluation of the CycleGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_image_test(image, label):\n  image = normalize(image)\n  return image\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Fashion MNIST Dataset\nDESCRIPTION: Loads the Fashion MNIST dataset and normalizes the pixel values for training and testing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n```\n\nLANGUAGE: python\nCODE:\n```\n# Normalize pixel values between 0 and 1\nimg_train = img_train.astype('float32') / 255.0\nimg_test = img_test.astype('float32') / 255.0\n```\n\n----------------------------------------\n\nTITLE: Implementing Training and Validation Step Functions\nDESCRIPTION: Functions for performing single training and validation steps in a neural network training loop. The training step computes gradients and updates model parameters, while the validation step evaluates model performance without updates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef train_step(x_batch, y_batch, loss, acc, model, optimizer):\n  # Update the model state given a batch of data\n  with tf.GradientTape() as tape:\n    y_pred = model(x_batch)\n    batch_loss = loss(y_pred, y_batch)\n  batch_acc = acc(y_pred, y_batch)\n  grads = tape.gradient(batch_loss, model.variables)\n  optimizer.apply_gradients(grads, model.variables)\n  return batch_loss, batch_acc\n\ndef val_step(x_batch, y_batch, loss, acc, model):\n  # Evaluate the model on given a batch of validation data\n  y_pred = model(x_batch)\n  batch_loss = loss(y_pred, y_batch)\n  batch_acc = acc(y_pred, y_batch)\n  return batch_loss, batch_acc\n```\n\n----------------------------------------\n\nTITLE: Defining a TF1.x-style Dense Layer Function in Python\nDESCRIPTION: This code defines a dense layer function using TensorFlow 1.x-style variable creation with tf.compat.v1.get_variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef dense(self, inputs, units):\n  out = inputs\n  with tf.compat.v1.variable_scope(\"dense\"):\n    # The weights are created with a `regularizer`,\n    kernel = tf.compat.v1.get_variable(\n        shape=[out.shape[-1], units],\n        regularizer=tf.keras.regularizers.L2(),\n        initializer=tf.compat.v1.initializers.glorot_normal,\n        name=\"kernel\")\n    bias = tf.compat.v1.get_variable(\n        shape=[units,],\n        initializer=tf.compat.v1.initializers.zeros,\n        name=\"bias\")\n    out = tf.linalg.matmul(out, kernel)\n    out = tf.compat.v1.nn.bias_add(out, bias)\n  return out\n```\n\n----------------------------------------\n\nTITLE: Processing GRU Input in Two Parts with State Passing\nDESCRIPTION: This code shows how to process a GRU input sequence in two parts, demonstrating state passing to continue computation where it left off. It also verifies that the results match processing the entire sequence at once.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfirst_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\nsecond_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n\nprint(np.allclose(result[:, :5,:], first_half))\nprint(np.allclose(result[:, 5:,:], second_half))\n```\n\n----------------------------------------\n\nTITLE: Defining Video Loading and Visualization Functions in Python\nDESCRIPTION: This snippet defines utility functions for loading videos using OpenCV, cropping and resizing frames, and displaying videos and retrieval results. It includes functions for center-cropping frames, loading videos from URLs, and creating HTML for result visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef crop_center_square(frame):\n  y, x = frame.shape[0:2]\n  min_dim = min(y, x)\n  start_x = (x // 2) - (min_dim // 2)\n  start_y = (y // 2) - (min_dim // 2)\n  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n\n\ndef load_video(video_url, max_frames=32, resize=(224, 224)):\n  path = tf.keras.utils.get_file(os.path.basename(video_url)[-128:], video_url)\n  cap = cv2.VideoCapture(path)\n  frames = []\n  try:\n    while True:\n      ret, frame = cap.read()\n      if not ret:\n        break\n      frame = crop_center_square(frame)\n      frame = cv2.resize(frame, resize)\n      frame = frame[:, :, [2, 1, 0]]\n      frames.append(frame)\n\n      if len(frames) == max_frames:\n        break\n  finally:\n    cap.release()\n  frames = np.array(frames)\n  if len(frames) < max_frames:\n    n_repeat = int(math.ceil(max_frames / float(len(frames))))\n    frames = frames.repeat(n_repeat, axis=0)\n  frames = frames[:max_frames]\n  return frames / 255.0\n\ndef display_video(urls):\n    html = '<table>'\n    html += '<tr><th>Video 1</th><th>Video 2</th><th>Video 3</th></tr><tr>'\n    for url in urls:\n        html += '<td>'\n        html += '<img src=\"{}\" height=\"224\">'.format(url)\n        html += '</td>'\n    html += '</tr></table>'\n    return display.HTML(html)\n\ndef display_query_and_results_video(query, urls, scores):\n  \"\"\"Display a text query and the top result videos and scores.\"\"\"\n  sorted_ix = np.argsort(-scores)\n  html = ''\n  html += '<h2>Input query: <i>{}</i> </h2><div>'.format(query)\n  html += 'Results: <div>'\n  html += '<table>'\n  html += '<tr><th>Rank #1, Score:{:.2f}</th>'.format(scores[sorted_ix[0]])\n  html += '<th>Rank #2, Score:{:.2f}</th>'.format(scores[sorted_ix[1]])\n  html += '<th>Rank #3, Score:{:.2f}</th></tr><tr>'.format(scores[sorted_ix[2]])\n  for i, idx in enumerate(sorted_ix):\n    url = urls[sorted_ix[i]];\n    html += '<td>'\n    html += '<img src=\"{}\" height=\"224\">'.format(url)\n    html += '</td>'\n  html += '</tr></table>'\n  return html\n```\n\n----------------------------------------\n\nTITLE: Adding Sparse Tensors in TensorFlow\nDESCRIPTION: This code demonstrates the addition of two sparse tensors using tf.sparse.add. It creates two sparse tensors with the same dense shape and adds them element-wise, preserving the sparse representation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nst_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n                       values=[31, 2], \n                       dense_shape=[4, 10])\n\nst_b = tf.sparse.SparseTensor(indices=[[0, 2], [3, 0]],\n                       values=[56, 38],\n                       dense_shape=[4, 10])\n\nst_sum = tf.sparse.add(st_a, st_b)\n\nprint(pprint_sparse_tensor(st_sum))\n```\n\n----------------------------------------\n\nTITLE: Slicing 2D Tensors with Range Indices\nDESCRIPTION: Shows how to slice a 2D tensor using row and column range indices to extract a specific submatrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nt2 = tf.constant([[0, 1, 2, 3, 4],\n                  [5, 6, 7, 8, 9],\n                  [10, 11, 12, 13, 14],\n                  [15, 16, 17, 18, 19]])\n\nprint(t2[:-1, 1:3])\n```\n\n----------------------------------------\n\nTITLE: Setting Up ParameterServerStrategy with ClusterCoordinator\nDESCRIPTION: Code to create ParameterServerStrategy and ClusterCoordinator for parameter server training. This approach uses a central coordinator to manage workers and parameter servers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.experimental.ParameterServerStrategy(\n    tf.distribute.cluster_resolver.TFConfigClusterResolver(),\n    variable_partitioner=variable_partitioner)\ncoordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(\n    strategy)\n```\n\n----------------------------------------\n\nTITLE: Initialize CentralStorageStrategy\nDESCRIPTION: Creates a CentralStorageStrategy instance for synchronized training with variables on CPU\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncentral_storage_strategy = tf.distribute.experimental.CentralStorageStrategy()\n```\n\n----------------------------------------\n\nTITLE: Creating and Using an Explicit Iterator with TensorFlow Distributed Dataset\nDESCRIPTION: This snippet demonstrates how to create and use an explicit iterator for a distributed dataset to iterate for a fixed number of steps. It shows how to use both next() and get_next() methods to retrieve elements during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 10\nsteps_per_epoch = 5\nfor epoch in range(num_epochs):\n  dist_iterator = iter(dist_dataset)\n  for step in range(steps_per_epoch):\n    # train_step trains the model using the dataset elements\n    loss = mirrored_strategy.run(train_step, args=(next(dist_iterator),))\n    # which is the same as\n    # loss = mirrored_strategy.run(train_step, args=(dist_iterator.get_next(),))\n    print(\"Loss is \", loss)\n```\n\n----------------------------------------\n\nTITLE: Setting Random Seeds for Reproducibility\nDESCRIPTION: Initialize random seeds for TensorFlow and NumPy to ensure reproducible results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n# Sampling rate for audio playback\n_SAMPLING_RATE = 16000\n```\n\n----------------------------------------\n\nTITLE: Creating a 1-Dimensional DTensor Mesh\nDESCRIPTION: This code creates a 1-dimensional mesh using 6 CPU devices along a mesh dimension 'x'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmesh_1d = dtensor.create_mesh([('x', 6)], devices=DEVICES)\nprint(mesh_1d)\n```\n\n----------------------------------------\n\nTITLE: Creating Segmentation Mask from Model Predictions in TensorFlow\nDESCRIPTION: This function takes the predicted mask from the model and creates a final segmentation mask by selecting the class with the highest probability for each pixel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef create_mask(pred_mask):\n  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n  pred_mask = pred_mask[..., tf.newaxis]\n  return pred_mask[0]\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Time-Based Early Stopping Callback in TF2\nDESCRIPTION: Implements a custom Keras callback that stops training after a specified maximum time. This demonstrates how to create custom early stopping logic in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass LimitTrainingTime(tf.keras.callbacks.Callback):\n  def __init__(self, max_time_s):\n    super().__init__()\n    self.max_time_s = max_time_s\n    self.start_time = None\n\n  def on_train_begin(self, logs):\n    self.start_time = time.time()\n\n  def on_train_batch_end(self, batch, logs):\n    now = time.time()\n    if now - self.start_time >  self.max_time_s:\n      self.model.stop_training = True\n```\n\n----------------------------------------\n\nTITLE: Iterating over Parsed Dataset to Display Features (Python)\nDESCRIPTION: Demonstrates iterating over a parsed dataset to output feature entries, useful for validating data parsing correctness.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfor parsed_record in parsed_dataset.take(10):\n  print(repr(parsed_record))\n```\n\n----------------------------------------\n\nTITLE: Summing Weights with Keras CategoryEncoding in Python\nDESCRIPTION: This snippet sums weights per category using Keras's `CategoryEncoding`. Requires `tensorflow` with `tf.keras.layers`. Inputs include categorical ids and associated weights, with the output as a dense tensor of summed counts per category.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nids = tf.constant([[5, 11, 5, 17, 17]])\nweights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n\ncount_layer = tf.keras.layers.CategoryEncoding(\n    num_tokens=20, output_mode='count', sparse=True)\ntf.sparse.to_dense(count_layer(ids, count_weights=weights))\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow Object Detection Dependencies\nDESCRIPTION: Imports required libraries and dependencies for running object detection using TensorFlow Hub models. Includes setup for image processing, visualization and GPU checking.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/object_detection.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\nimport time\n\nprint(tf.__version__)\nprint(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n```\n\n----------------------------------------\n\nTITLE: Setting Up Training Callbacks in TensorFlow\nDESCRIPTION: Configures callbacks for saving model checkpoints during training and implementing early stopping to prevent overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath='./training_checkpoints/ckpt_{epoch}',\n        save_weights_only=True),\n    tf.keras.callbacks.EarlyStopping(\n        monitor='loss',\n        patience=5,\n        verbose=1,\n        restore_best_weights=True),\n]\n```\n\n----------------------------------------\n\nTITLE: Verifying Shape Consistency with Wide Windows\nDESCRIPTION: Demonstrates that the baseline model can handle different window sizes without code changes by checking the input and output shapes, which is possible because the model processes each time step independently.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', wide_window.example[0].shape)\nprint('Output shape:', baseline(wide_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Visualizing audio waveforms with matplotlib\nDESCRIPTION: This code creates a grid of plots showing the waveforms of several audio samples from the dataset, with their corresponding command labels as titles, to visualize the audio patterns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(16, 10))\nrows = 3\ncols = 3\nn = rows * cols\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  audio_signal = example_audio[i]\n  plt.plot(audio_signal)\n  plt.title(label_names[example_labels[i]])\n  plt.yticks(np.arange(-1.2, 1.2, 0.2))\n  plt.ylim([-1.1, 1.1])\n```\n\n----------------------------------------\n\nTITLE: Building Neural Network Model\nDESCRIPTION: Constructs model architecture with embedding and dense layers under Strategy scope. Includes optimizer and metric definitions for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model_input = tf.keras.layers.Input(\n      shape=(3,), dtype=tf.int64, name=\"model_input\")\n\n  emb_layer = tf.keras.layers.Embedding(\n      input_dim=len(feature_lookup_layer.get_vocabulary()), output_dim=16384)\n  emb_output = tf.reduce_mean(emb_layer(model_input), axis=1)\n  dense_output = tf.keras.layers.Dense(\n      units=1, activation=\"sigmoid\",\n      kernel_regularizer=tf.keras.regularizers.L2(1e-4),\n  )(emb_output)\n  model = tf.keras.Model({\"features\": model_input}, dense_output)\n\n  optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.1)\n  accuracy = tf.keras.metrics.Accuracy()\n```\n\n----------------------------------------\n\nTITLE: Installing and Loading WER Metric in Python\nDESCRIPTION: This snippet installs the 'datasets' library and loads the Word Error Rate (WER) metric for evaluating speech recognition performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n!pip3 install -q datasets\n\nfrom datasets import load_metric\nmetric = load_metric(\"wer\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Parser Function for TFRecord Image Data\nDESCRIPTION: Creates a function that parses a single TensorFlow Example protocol buffer using the previously defined image feature description dictionary. This function is used to extract structured data from serialized examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef _parse_image_function(example_proto):\n  # Parse the input tf.train.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\nparsed_image_dataset = raw_image_dataset.map(_parse_image_function)\nparsed_image_dataset\n```\n\n----------------------------------------\n\nTITLE: Loading FILM Model from TensorFlow Hub\nDESCRIPTION: Loads the FILM model from TensorFlow Hub using the provided model handle URL.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmodel = hub.load(\"https://tfhub.dev/google/film/1\")\n```\n\n----------------------------------------\n\nTITLE: Loading Generator Module from SavedModel\nDESCRIPTION: Loads a previously saved module containing a random number generator from SavedModel format, showing that the generator state is preserved and continues from the saved point.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimported = tf.saved_model.load(filename)\nprint(\"RNG stream from loading point:\")\nprint(\"state:\", imported.state())\nprint(imported())\nprint(\"state:\", imported.state())\nprint(imported())\nprint(\"state:\", imported.state())\n```\n\n----------------------------------------\n\nTITLE: Running the Custom Estimator Python Example\nDESCRIPTION: Command to execute the custom_estimator.py example script that implements a custom Estimator for the Iris problem.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython custom_estimator.py\n```\n\n----------------------------------------\n\nTITLE: Visualizing Gradient Saturation for Image Classification in TensorFlow\nDESCRIPTION: This code snippet creates two plots: one showing the model's predicted probability for the target class over alpha, and another showing the average pixel gradients (normalized) over alpha. It helps visualize gradient saturation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\npred = model(interpolated_images)\npred_proba = tf.nn.softmax(pred, axis=-1)[:, 555]\n\nplt.figure(figsize=(10, 4))\nax1 = plt.subplot(1, 2, 1)\nax1.plot(alphas, pred_proba)\nax1.set_title('Target class predicted probability over alpha')\nax1.set_ylabel('model p(target class)')\nax1.set_xlabel('alpha')\nax1.set_ylim([0, 1])\n\nax2 = plt.subplot(1, 2, 2)\naverage_grads = tf.reduce_mean(path_gradients, axis=[1, 2, 3])\naverage_grads_norm = (average_grads-tf.math.reduce_min(average_grads))/(tf.math.reduce_max(average_grads)-tf.reduce_min(average_grads))\nax2.plot(alphas, average_grads_norm)\nax2.set_title('Average pixel gradients (normalized) over alpha')\nax2.set_ylabel('Average pixel gradients')\nax2.set_xlabel('alpha')\nax2.set_ylim([0, 1]);\n```\n\n----------------------------------------\n\nTITLE: Checking Trainable Variables Count in TensorFlow Model\nDESCRIPTION: This snippet counts the number of trainable variables in the model, which helps verify how many parameters will be updated during fine-tuning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nlen(model.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Implementing a CPU Kernel for the ZeroOut Operation in TensorFlow C++\nDESCRIPTION: This code implements the kernel for the ZeroOut operation that sets all elements of an int32 tensor to zero except for the first element. The implementation extends the OpKernel class and overrides the Compute method, which handles the tensor manipulation logic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output_flat = output_tensor->flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n    for (int i = 1; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Defining visualization function for image predictions in TensorFlow\nDESCRIPTION: Creates a helper function to display test images along with prediction information. The function highlights correct predictions in blue and incorrect ones in red, showing the predicted class, confidence percentage, and actual class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef plot_image(i, predictions_array, true_label, img):\n  true_label, img = true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  true_label = true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')\n```\n\n----------------------------------------\n\nTITLE: Defining a custom Keras model with custom training step in TensorFlow 2\nDESCRIPTION: Creates a custom Keras model by subclassing tf.keras.Sequential and overriding the train_step method to implement a custom training loop using tf.GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nclass CustomModel(tf.keras.Sequential):\n  \"\"\"A custom sequential model that overrides `Model.train_step`.\"\"\"\n\n  def train_step(self, data):\n    batch_data, labels = data\n\n    with tf.GradientTape() as tape:\n      predictions = self(batch_data, training=True)\n      # Compute the loss value (the loss function is configured\n      # in `Model.compile`).\n      loss = self.compiled_loss(labels, predictions)\n\n    # Compute the gradients of the parameters with respect to the loss.\n    gradients = tape.gradient(loss, self.trainable_variables)\n    # Perform gradient descent by updating the weights/parameters.\n    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n    # Update the metrics (includes the metric that tracks the loss).\n    self.compiled_metrics.update_state(labels, predictions)\n    # Return a dict mapping metric names to the current values.\n    return {m.name: m.result() for m in self.metrics}\n```\n\n----------------------------------------\n\nTITLE: Generating Interpolated Frames\nDESCRIPTION: Generates intermediate frames using the loaded model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfilled_frames = module(input_frames)['default'] / 255.0\n```\n\n----------------------------------------\n\nTITLE: Displaying RaggedTensor shape information in TensorFlow\nDESCRIPTION: Shows how to create a RaggedTensor and display its shape attribute, which returns a TensorShape with None for ragged dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).shape\n```\n\n----------------------------------------\n\nTITLE: Creating Helper Function for Visualizing Semantic Similarity\nDESCRIPTION: Defines a function to plot a similarity matrix using cosine similarity between sentence embeddings. The visualization helps identify semantic relationships between the sample sentences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n#@title Helper functions\n\ndef plot_similarity(features, labels):\n  \"\"\"Plot a similarity matrix of the embeddings.\"\"\"\n  cos_sim = pairwise.cosine_similarity(features)\n  sns.set(font_scale=1.2)\n  cbar_kws=dict(use_gridspec=False, location=\"left\")\n  g = sns.heatmap(\n      cos_sim, xticklabels=labels, yticklabels=labels,\n      vmin=0, vmax=1, cmap=\"Blues\", cbar_kws=cbar_kws)\n  g.tick_params(labelright=True, labelleft=False)\n  g.set_yticklabels(labels, rotation=0)\n  g.set_title(\"Semantic Textual Similarity\")\n```\n\n----------------------------------------\n\nTITLE: Accessing tf.functions in TensorFlow 2 SavedModel\nDESCRIPTION: This snippet shows how to access and call tf.functions that are attached to a model saved with TensorFlow 2 API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nloaded = tf.saved_model.load('tf2-save')\nprint('restored __call__:', loaded.__call__)\nprint('output with input 5.', loaded(5))\n```\n\n----------------------------------------\n\nTITLE: Training Loop for CVAE Model in Python\nDESCRIPTION: Implements the main training loop for the CVAE model. It iterates through epochs, performs training steps, computes loss on the test set, and generates images at each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\ngenerate_and_save_images(model, 0, test_sample)\n\nfor epoch in range(1, epochs + 1):\n  start_time = time.time()\n  for train_x in train_dataset:\n    train_step(model, train_x, optimizer)\n  end_time = time.time()\n\n  loss = tf.keras.metrics.Mean()\n  for test_x in test_dataset:\n    loss(compute_loss(model, test_x))\n  elbo = -loss.result()\n  display.clear_output(wait=False)\n  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n        .format(epoch, elbo, end_time - start_time))\n  generate_and_save_images(model, epoch, test_sample)\n```\n\n----------------------------------------\n\nTITLE: Creating a CNN Model with Dropout in TensorFlow\nDESCRIPTION: This code snippet defines a Convolutional Neural Network (CNN) model using TensorFlow's Keras API. It includes data augmentation, convolutional layers, max pooling, dropout for regularization, and dense layers for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = Sequential([\n  data_augmentation,\n  layers.Rescaling(1./255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes, name=\"outputs\")\n])\n```\n\n----------------------------------------\n\nTITLE: Evaluating TensorFlow Model Metrics in Python\nDESCRIPTION: This code snippet evaluates the model on the test dataset and prints out the results for each metric. It then plots the confusion matrix using the previously defined function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbaseline_results = model.evaluate(test_features, test_labels,\n                                  batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, baseline_results):\n  print(name, ': ', value)\nprint()\n\nplot_cm(test_labels, test_predictions_baseline)\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Step for DTensor MLP in Python\nDESCRIPTION: Defines a training step function using a custom training loop with Stochastic Gradient Descent optimizer. The function handles forward pass, backward gradient pass, and variable updates for the MLP model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(model, x, y, learning_rate=tf.constant(1e-4)):\n  with tf.GradientTape() as tape:\n    logits = model(x)\n    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n    # global loss (scalar).\n    loss = tf.reduce_sum(\n        tf.nn.sparse_softmax_cross_entropy_with_logits(\n            logits=logits, labels=y))\n  parameters = model.trainable_variables\n  gradients = tape.gradient(loss, parameters)\n  for parameter, parameter_gradient in zip(parameters, gradients):\n    parameter.assign_sub(learning_rate * parameter_gradient)\n\n  # Define some metrics\n  accuracy = 1.0 - tf.reduce_sum(tf.cast(tf.argmax(logits, axis=-1, output_type=tf.int64) != y, tf.float32)) / x.shape[0]\n  loss_per_sample = loss / len(x)\n  return {'loss': loss_per_sample, 'accuracy': accuracy}\n```\n\n----------------------------------------\n\nTITLE: Saving a Keras Model as SavedModel in TensorFlow 2\nDESCRIPTION: This snippet shows how to create a Keras model, define a serving function, and save it as a SavedModel using the Keras API in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ninp = tf.keras.Input(3)\nout = add_two(inp)\nmodel = tf.keras.Model(inputs=inp, outputs=out)\n\n@tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.float32)])\ndef serving_default(input):\n  return {'output': model(input)}\n\nmodel.save('keras-model', save_format='tf', signatures={\n        tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: serving_default})\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Loop with Checkpointing\nDESCRIPTION: Defines a function that trains the model for multiple steps, restores from the latest checkpoint if available, and periodically saves new checkpoints using the CheckpointManager.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef train_and_checkpoint(net, manager):\n  ckpt.restore(manager.latest_checkpoint)\n  if manager.latest_checkpoint:\n    print(\"Restored from {}\".format(manager.latest_checkpoint))\n  else:\n    print(\"Initializing from scratch.\")\n\n  for _ in range(50):\n    example = next(iterator)\n    loss = train_step(net, example, opt)\n    ckpt.step.assign_add(1)\n    if int(ckpt.step) % 10 == 0:\n      save_path = manager.save()\n      print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n      print(\"loss {:1.2f}\".format(loss.numpy()))\n```\n\n----------------------------------------\n\nTITLE: Creating Low Resolution Image for ESRGAN Comparison\nDESCRIPTION: Downscales the high-resolution image to create a low-resolution version for demonstrating super resolution enhancement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nlr_image = downscale_image(tf.squeeze(hr_image))\n```\n\n----------------------------------------\n\nTITLE: Summing Weighted Categorical Data with Feature Columns in Python\nDESCRIPTION: This snippet demonstrates how to sum weights per category using TensorFlow's feature columns. Dependencies include `tensorflow` and `tf.feature_column` APIs. Inputs are categorical identifiers and weights for each category occurrence, and the output is an indicator column representing the summed category weights.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nids = tf.constant([[5, 11, 5, 17, 17]])\nweights = tf.constant([[0.5, 1.5, 0.7, 1.8, 0.2]])\n\ncategorical_col = tf1.feature_column.categorical_column_with_identity(\n    'ids', num_buckets=20)\nweighted_categorical_col = tf1.feature_column.weighted_categorical_column(\n    categorical_col, 'weights')\nindicator_col = tf1.feature_column.indicator_column(weighted_categorical_col)\ncall_feature_columns(indicator_col, {'ids': ids, 'weights': weights})\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Text Feature Vector Module in TensorFlow Hub\nDESCRIPTION: Demonstrates how to use a text embedding module from TensorFlow Hub to convert text strings into vector representations. The module accepts a batch of strings and returns a tensor of embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/text.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n  embed = hub.Module(\"path/to/module\")\n  representations = embed([\n      \"A long sentence.\",\n      \"single-word\",\n      \"http://example.com\"])\n```\n\n----------------------------------------\n\nTITLE: Splitting and Normalizing Data for TensorFlow Regression Model\nDESCRIPTION: Splits the dataset into training and test sets, separates features from labels, and applies normalization to the feature data using TensorFlow's Normalization layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ntrain_dataset = dataset.sample(frac=0.8, random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\ntrain_features = train_dataset.copy()\ntest_features = test_dataset.copy()\n\ntrain_labels = train_features.pop('MPG')\ntest_labels = test_features.pop('MPG')\n\nnormalizer = tf.keras.layers.Normalization(axis=-1)\nnormalizer.adapt(np.array(train_features))\n\nfirst = np.array(train_features[:1])\n\nwith np.printoptions(precision=2, suppress=True):\n  print('First example:', first)\n  print()\n  print('Normalized:', normalizer(first).numpy())\n```\n\n----------------------------------------\n\nTITLE: Predicting with Keras Model using NumPy Data\nDESCRIPTION: Shows how to use the `model.predict` method to generate predictions from a Keras model using NumPy data. The `batch_size` parameter defines the number of samples processed in each batch. The predicted output is a NumPy array, and its shape is printed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n```python\nresult = model.predict(data, batch_size=32)\nprint(result.shape)\n```\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Nightly Build\nDESCRIPTION: Command to install the nightly build of TensorFlow, which is required to use the new type promotion features described in this guide.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q tf_nightly\n```\n\n----------------------------------------\n\nTITLE: Executing Embedding Generation Pipeline in Python\nDESCRIPTION: This code snippet cleans up previous output, runs the embedding generation pipeline, and displays the execution time. It uses the run_hub2emb function to generate embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n!rm -r {output_dir}\n!rm -r {temporary_dir}\n\nprint(\"Running pipeline...\")\n%time run_hub2emb(args)\nprint(\"Pipeline is done.\")\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Saving with TensorFlow 2 Keras Callback\nDESCRIPTION: Shows how to use tf.keras.callbacks.ModelCheckpoint with the Keras Model.fit API in TensorFlow 2 to save checkpoints during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  return tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation='softmax')\n  ])\n\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'],\n              steps_per_execution=10)\n\nlog_dir = tempfile.mkdtemp()\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=log_dir)\n\nmodel.fit(x=x_train,\n          y=y_train,\n          epochs=10,\n          validation_data=(x_test, y_test),\n          callbacks=[model_checkpoint_callback])\n```\n\nLANGUAGE: python\nCODE:\n```\n%ls {model_checkpoint_callback.filepath}\n```\n\n----------------------------------------\n\nTITLE: Initializing Model, Optimizer, and Checkpoint for Distributed TensorFlow Training\nDESCRIPTION: This snippet shows how to create a model, optimizer, and checkpoint within the strategy scope for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# A model, an optimizer, and a checkpoint must be created under `strategy.scope`.\nwith strategy.scope():\n  model = create_model()\n\n  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n```\n\n----------------------------------------\n\nTITLE: Export Model Creation\nDESCRIPTION: Creates and compiles an export model that includes the vectorization layer and sigmoid activation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nexport_model = tf.keras.Sequential(\n    [vectorize_layer, model,\n     layers.Activation('sigmoid')])\n\nexport_model.compile(\n    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n    optimizer='adam',\n    metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning TF2 SavedModel in TensorFlow 2 using hub.KerasLayer\nDESCRIPTION: Shows how to load a TF2 SavedModel as a trainable Keras layer for fine-tuning in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nm =  hub.KerasLayer(handle, trainable=True)\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Augmentation for TensorFlow Image Classification\nDESCRIPTION: This code defines a data augmentation sequence using Keras layers for random flipping and rotation of images to increase sample diversity and reduce overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip('horizontal'),\n  tf.keras.layers.RandomRotation(0.2),\n])\n```\n\n----------------------------------------\n\nTITLE: Creating Image Tensors from Flattened CSV Features\nDESCRIPTION: This function parses column names that represent pixel positions (r{row}c{column}) and rebuilds the original 20x20 images from the flattened data. It returns a dictionary with the reconstructed image tensor and any other features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nimport re\n\ndef make_images(features):\n  image = [None]*400\n  new_feats = {}\n\n  for name, value in features.items():\n    match = re.match('r(\\d+)c(\\d+)', name)\n    if match:\n      image[int(match.group(1))*20+int(match.group(2))] = value\n    else:\n      new_feats[name] = value\n\n  image = tf.stack(image, axis=0)\n  image = tf.reshape(image, [20, 20, -1])\n  new_feats['image'] = image\n\n  return new_feats\n```\n\n----------------------------------------\n\nTITLE: Visualizing another prediction example with matplotlib\nDESCRIPTION: Shows the prediction visualization for a different test image (index 12) to examine the model's performance on another example. Uses the same visualization functions to display both the image and its prediction distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ni = 12\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  test_labels)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: TF2: Using Keras Metrics with tf.keras.Model\nDESCRIPTION: Example of using TF2's Keras metrics API with a Keras model. Creates datasets, defines a model, and compiles it with accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\neval_dataset = tf.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\ninputs = tf.keras.Input((2,))\nlogits = tf.keras.layers.Dense(2)(inputs)\npredictions = tf.math.argmax(input=logits, axis=1)\nmodel = tf.keras.models.Model(inputs, predictions)\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n\nmodel.compile(optimizer, loss='mse', metrics=[tf.keras.metrics.Accuracy()])\n```\n\n----------------------------------------\n\nTITLE: Enforcing Input Signature for TensorFlow Function\nDESCRIPTION: Demonstrates how to use input_signature to constrain a tf.function to a specific input type, preventing retracing for incompatible inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\ndef next_collatz(x):\n  print(\"Tracing with\", x)\n  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n\nprint(next_collatz(tf.constant([1, 2])))\n# You specified a 1-D tensor in the input signature, so this should fail.\nwith assert_raises(TypeError):\n  next_collatz(tf.constant([[1, 2], [3, 4]]))\n\n# You specified an int32 dtype in the input signature, so this should fail.\nwith assert_raises(TypeError):\n  next_collatz(tf.constant([1.0, 2.0]))\n\n```\n\n----------------------------------------\n\nTITLE: Input Handling with Keras\nDESCRIPTION: Shows how to handle dictionary input using Keras Input layers and create a model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ninputs = {\n  'foo': tf.keras.Input(shape=()),\n  'bar': tf.keras.Input(shape=()),\n  'baz': tf.keras.Input(shape=()),\n}\noutputs = tf.keras.layers.Concatenate()(inputs.values())\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel(input_dict)\n```\n\n----------------------------------------\n\nTITLE: Applying Softmax Activation\nDESCRIPTION: Shows how to apply the softmax function to a tensor along the last dimension for normalization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntf.nn.softmax(x, axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Loading Keras SavedModel in TensorFlow 2\nDESCRIPTION: This snippet demonstrates how to load a SavedModel saved with Keras back into a Keras Model object and use it for prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nloaded_model = tf.keras.models.load_model('keras-model')\nloaded_model.predict_on_batch(tf.constant([1, 3, 4]))\n```\n\n----------------------------------------\n\nTITLE: Implementing Adaptive Moment Estimation (Adam) in TensorFlow\nDESCRIPTION: This class implements the Adam optimization algorithm using TensorFlow. It initializes the Adam parameters and provides a method to apply gradients to variables with bias correction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass Adam(tf.Module):\n  \n    def __init__(self, learning_rate=1e-3, beta_1=0.9, beta_2=0.999, ep=1e-7):\n      # Initialize the Adam parameters\n      self.beta_1 = beta_1\n      self.beta_2 = beta_2\n      self.learning_rate = learning_rate\n      self.ep = ep\n      self.t = 1.\n      self.v_dvar, self.s_dvar = [], []\n      self.title = f\"Adam: learning rate={self.learning_rate}\"\n      self.built = False\n\n    def apply_gradients(self, grads, vars):\n      # Set up moment and RMSprop slots for each variable on the first call\n      if not self.built:\n        for var in vars:\n          v = tf.Variable(tf.zeros(shape=var.shape))\n          s = tf.Variable(tf.zeros(shape=var.shape))\n          self.v_dvar.append(v)\n          self.s_dvar.append(s)\n        self.built = True\n      # Perform Adam updates\n      for i, (d_var, var) in enumerate(zip(grads, vars)):\n        # Moment calculation\n        self.v_dvar[i] = self.beta_1*self.v_dvar[i] + (1-self.beta_1)*d_var\n        # RMSprop calculation\n        self.s_dvar[i] = self.beta_2*self.s_dvar[i] + (1-self.beta_2)*tf.square(d_var)\n        # Bias correction\n        v_dvar_bc = self.v_dvar[i]/(1-(self.beta_1**self.t))\n        s_dvar_bc = self.s_dvar[i]/(1-(self.beta_2**self.t))\n        # Update model variables\n        var.assign_sub(self.learning_rate*(v_dvar_bc/(tf.sqrt(s_dvar_bc) + self.ep)))\n      # Increment the iteration counter\n      self.t += 1.\n```\n\n----------------------------------------\n\nTITLE: Converting Waveform to Spectrogram using STFT in TensorFlow\nDESCRIPTION: Function to convert audio waveforms into spectrograms using Short-time Fourier transform. Adds a channels dimension for CNN compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef get_spectrogram(waveform):\n  # Convert the waveform to a spectrogram via a STFT.\n  spectrogram = tf.signal.stft(\n      waveform, frame_length=255, frame_step=128)\n  # Obtain the magnitude of the STFT.\n  spectrogram = tf.abs(spectrogram)\n  # Add a `channels` dimension, so that the spectrogram can be used\n  # as image-like input data with convolution layers (which expect\n  # shape (`batch_size`, `height`, `width`, `channels`).\n  spectrogram = spectrogram[..., tf.newaxis]\n  return spectrogram\n```\n\n----------------------------------------\n\nTITLE: Creating Base Model from Pre-trained MobileNetV2\nDESCRIPTION: Instantiates a MobileNetV2 model pre-loaded with ImageNet weights as a feature extractor. The include_top=False parameter removes the classification layers, making it suitable for transfer learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Create the base model from the pre-trained model MobileNet V2\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n```\n\n----------------------------------------\n\nTITLE: Downloading Text Files for TensorFlow Dataset\nDESCRIPTION: This snippet downloads multiple text files to be used in creating a text dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\ndirectory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\nfile_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n\nfile_paths = [\n    tf.keras.utils.get_file(file_name, directory_url + file_name)\n    for file_name in file_names\n]\n```\n\n----------------------------------------\n\nTITLE: DeepDream Image Processing Functions\nDESCRIPTION: Utility functions for downloading, processing, and displaying images used in the DeepDream implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef download(url, max_dim=None):\n  name = url.split('/')[-1]\n  image_path = tf.keras.utils.get_file(name, origin=url)\n  img = PIL.Image.open(image_path)\n  if max_dim:\n    img.thumbnail((max_dim, max_dim))\n  return np.array(img)\n\ndef deprocess(img):\n  img = 255*(img + 1.0)/2.0\n  return tf.cast(img, tf.uint8)\n\ndef show(img):\n  display.display(PIL.Image.fromarray(np.array(img)))\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Random Generator\nDESCRIPTION: Creates a tf.random.Generator object with an initial seed value for random number generation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: Python\nCODE:\n```\n# Create a generator.\nrng = tf.random.Generator.from_seed(123, alg='philox')\n```\n\n----------------------------------------\n\nTITLE: Downloading the Titanic CSV File\nDESCRIPTION: Downloads the Titanic dataset CSV file using tf.keras.utils.get_file, which handles caching and retrieval of remote files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ntitanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n```\n\n----------------------------------------\n\nTITLE: Batch Image Detection Implementation\nDESCRIPTION: Functions for processing multiple images in sequence, including timing measurements for each detection operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/object_detection.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef detect_img(image_url):\n  start_time = time.time()\n  image_path = download_and_resize_image(image_url, 640, 480)\n  run_detector(detector, image_path)\n  end_time = time.time()\n  print(\"Inference time:\",end_time-start_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Binary Cross-Entropy Loss for Distributed Training in TensorFlow\nDESCRIPTION: Sets up a loss object with reduction set to NONE, allowing tf.nn.compute_average_loss to handle the reduction later in the distributed training context.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Sets `reduction=NONE` to leave it to tf.nn.compute_average_loss() below.\nloss_object = tf.keras.losses.BinaryCrossentropy(\n  from_logits=True,\n  reduction=tf.keras.losses.Reduction.NONE)\n```\n\n----------------------------------------\n\nTITLE: Getting Dynamic Shape of RaggedTensors in TensorFlow\nDESCRIPTION: Shows how to retrieve the dynamic shape of a RaggedTensor using tf.shape, which returns a DynamicRaggedShape object that can represent variable-length dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.ragged.constant([[1], [2, 3, 4], [], [5, 6]])\nrt_shape = tf.shape(rt)\nprint(rt_shape)\n```\n\n----------------------------------------\n\nTITLE: Balancing Multiple Loss Components with Loss Weights in TensorFlow\nDESCRIPTION: Recompiles the model with weighted loss components to balance the influence of pitch, step, and duration predictions during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n    loss=loss,\n    loss_weights={\n        'pitch': 0.05,\n        'step': 1.0,\n        'duration':1.0,\n    },\n    optimizer=optimizer,\n)\n```\n\n----------------------------------------\n\nTITLE: Calculating Initial Loss\nDESCRIPTION: Computes loss on first training example before training begins.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nloss_fn(y_train[:1], predictions).numpy()\n```\n\n----------------------------------------\n\nTITLE: Recording Control Flow with GradientTape in TensorFlow\nDESCRIPTION: Shows how GradientTape naturally handles Python control flow structures like if statements and loops when recording operations for gradient computation, by defining and testing a function with conditional logic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef f(x, y):\n  output = 1.0\n  for i in range(y):\n    if i > 1 and i < 5:\n      output = tf.multiply(output, x)\n  return output\n\ndef grad(x, y):\n  with tf.GradientTape() as t:\n    t.watch(x)\n    out = f(x, y)\n  return t.gradient(out, x)\n\nx = tf.convert_to_tensor(2.0)\n\nassert grad(x, 6).numpy() == 12.0\nassert grad(x, 5).numpy() == 12.0\nassert grad(x, 4).numpy() == 4.0\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Related Libraries for CycleGAN\nDESCRIPTION: Imports necessary libraries including TensorFlow, TensorFlow datasets, and custom pix2pix models for implementing CycleGAN. Also imports visualization and utility libraries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_datasets as tfds\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\nAUTOTUNE = tf.data.AUTOTUNE\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a TensorFlow Model\nDESCRIPTION: This code generates predictions for validation data and converts the probability outputs to class labels using numpy's argmax function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ny_pred = model.predict(validation_data)\n```\n\nLANGUAGE: python\nCODE:\n```\ny_pred = np.argmax(y_pred, axis=1)\n```\n\n----------------------------------------\n\nTITLE: Creating CNN Model with Distributed Strategy Scope\nDESCRIPTION: Defines a CNN model for Fashion MNIST classification using tf.keras.Sequential API within the strategy scope, which ensures variables are created on the appropriate devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu',\n                             input_shape=(28, 28, 1)),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')\n    ])\n  optimizer = tf.train.GradientDescentOptimizer(0.001)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Training Progress Callback in Keras\nDESCRIPTION: Implements a custom Keras callback to print progress during model training by displaying a dot for each completed epoch\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Performance Comparison\nDESCRIPTION: Creates a bar chart comparing mean absolute error performance metrics across all models for both validation and test datasets, enabling visual performance comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nx = np.arange(len(performance))\nwidth = 0.3\nmetric_name = 'mean_absolute_error'\nval_mae = [v[metric_name] for v in val_performance.values()]\ntest_mae = [v[metric_name] for v in performance.values()]\n\nplt.ylabel('mean_absolute_error [T (degC), normalized]')\nplt.bar(x - 0.17, val_mae, width, label='Validation')\nplt.bar(x + 0.17, test_mae, width, label='Test')\nplt.xticks(ticks=x, labels=performance.keys(),\n           rotation=45)\n_ = plt.legend()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Model Wrapper for JAX Models\nDESCRIPTION: Class implementing a TensorFlow Module that wraps JAX model functionality, handling state management, predictions, loss calculations, and accuracy metrics with support for variable batch sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass TFModel(tf.Module):\n  def __init__(self, state, model):\n    super().__init__()\n\n    # Special care needed for the train=True/False parameter in the loss\n    @jax.jit\n    def loss_with_train_bool(state, rng, data, labels, train):\n      other_state, params = state.pop('params')\n      loss, batch_stats = jax.lax.cond(train,\n                                       lambda state, data, labels: model.loss(params, other_state, rng, data, labels, train=True),\n                                       lambda state, data, labels: model.loss(params, other_state, rng, data, labels, train=False),\n                                       state, data, labels)\n      # must use JAX to split the RNG, therefore, must do it in a @jax.jit function\n      new_rng, _ = jax.random.split(rng)\n      return loss, batch_stats, new_rng\n\n    self.state_vars = tf.nest.map_structure(tf.Variable, state)\n    self.vars = tf.nest.flatten(self.state_vars)\n    self.jax_rng = tf.Variable(jax.random.PRNGKey(0))\n\n    self.loss_fn = jax2tf.convert(loss_with_train_bool, polymorphic_shapes=[\"...\", \"...\", \"(b, 28, 28, 1)\", \"(b, 10)\", \"...\"])\n    self.accuracy_fn = jax2tf.convert(model.accuracy, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\", \"(b, 10)\"])\n    self.predict_fn = jax2tf.convert(model.predict, polymorphic_shapes=[\"...\", \"(b, 28, 28, 1)\"])\n\n  # Must specify TensorSpec manually for variable batch size to work\n  @tf.function(autograph=False, input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\n  def predict(self, data):\n    # Make sure the TfModel.predict function implicitly use self.state_vars and not the JAX state directly\n    # otherwise, all model weights would be embedded in the TF graph as constants.\n    return self.predict_fn(self.state_vars, data)\n\n  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n               autograph=False)\n  def train_loss(self, data, labels):\n      loss, batch_stats, new_rng = self.loss_fn(self.state_vars, self.jax_rng, data, labels, True)\n      # update batch norm stats\n      flat_vars = tf.nest.flatten(self.state_vars['batch_stats'])\n      flat_values = tf.nest.flatten(batch_stats['batch_stats'])\n      for var, val in zip(flat_vars, flat_values):\n        var.assign(val)\n      # update RNG\n      self.jax_rng.assign(new_rng)\n      return loss\n\n  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n               autograph=False)\n  def eval_loss(self, data, labels):\n      loss, batch_stats, new_rng = self.loss_fn(self.state_vars, self.jax_rng, data, labels, False)\n      return loss\n\n  @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32),\n                                tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n               autograph=False)\n  def accuracy(self, data, labels):\n    return self.accuracy_fn(self.state_vars, data, labels)\n```\n\n----------------------------------------\n\nTITLE: Accumulating Results with Keras Metrics\nDESCRIPTION: Showing how Keras metrics maintain state across multiple update calls, accumulating results over time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\naccuracy.update_state(y_true=[0, 0, 1, 1], y_pred=[0, 0, 0, 0])\naccuracy.update_state(y_true=[0, 0, 1, 1], y_pred=[1, 1, 0, 0])\naccuracy.result().numpy()\n```\n\n----------------------------------------\n\nTITLE: Enabling New Type Promotion Mode in TensorFlow-NumPy\nDESCRIPTION: This snippet shows how to enable the new dtype conversion mode for TensorFlow-NumPy operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n```\n\n----------------------------------------\n\nTITLE: Examining LSTM Model Metrics\nDESCRIPTION: Retrieves and displays the metrics used for evaluating the LSTM model's performance on the time series prediction task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_47\n\nLANGUAGE: python\nCODE:\n```\ncm = lstm_model.metrics[1]\ncm.metrics\n```\n\n----------------------------------------\n\nTITLE: Displaying Model Architecture Summary\nDESCRIPTION: Prints a summary of the model architecture including layer information, parameter counts, and shapes. This provides a comprehensive overview of the model structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Applying Image Transformation to Font Dataset\nDESCRIPTION: This snippet applies the make_images function to each batch in the dataset using the map transformation, converting the flattened CSV data into structured image tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nfonts_image_ds = fonts_ds.map(make_images)\n\nfor features in fonts_image_ds.take(1):\n  break\n```\n\n----------------------------------------\n\nTITLE: Training History Visualization Function\nDESCRIPTION: Creates visualization plots to analyze model performance across training epochs, showing mean absolute and squared errors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [MPG]')\n  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n           label = 'Val Error')\n  plt.ylim([0,5])\n  plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Implementing DTensor-Aware Dense Layer for MLP\nDESCRIPTION: Creates a dense layer module that supports DTensor. It uses dtensor.call_with_layout for initializing DTensor variables and implements the forward pass with DTensor operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass DenseLayer(tf.Module):\n\n  def __init__(self, in_dim, out_dim, weight_layout, activation=tf.identity):\n    super().__init__()\n    # Initialize dimensions and the activation function\n    self.in_dim, self.out_dim = in_dim, out_dim\n    self.activation = activation\n\n    # Initialize the DTensor weights using the Xavier scheme\n    uniform_initializer = tf.function(tf.random.stateless_uniform)\n    xavier_lim = tf.sqrt(6.)/tf.sqrt(tf.cast(self.in_dim + self.out_dim, tf.float32))\n    self.w = dtensor.DVariable(\n      dtensor.call_with_layout(\n          uniform_initializer, weight_layout,\n          shape=(self.in_dim, self.out_dim), seed=(22, 23),\n          minval=-xavier_lim, maxval=xavier_lim))\n        \n    # Initialize the bias with the zeros\n    bias_layout = weight_layout.delete([0])\n    self.b = dtensor.DVariable(\n      dtensor.call_with_layout(tf.zeros, bias_layout, shape=[out_dim]))\n\n  def __call__(self, x):\n    # Compute the forward pass\n    z = tf.add(tf.matmul(x, self.w), self.b)\n    return self.activation(z)\n```\n\n----------------------------------------\n\nTITLE: Writing Generator State to Checkpoint\nDESCRIPTION: Saves the current state of the random number generator to a checkpoint file and demonstrates that the generator continues to produce its sequence after saving.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ncp.write(filename)\nprint(\"RNG stream from saving point:\")\nprint(g.normal([]))\nprint(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Using Forward References in TensorFlow Extension Types\nDESCRIPTION: Shows how to use string-based forward references for types that haven't been fully defined yet in extension type definitions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nclass Node(tf.experimental.ExtensionType):\n  value: tf.Tensor\n  children: Tuple[\"Node\", ...] = ()\n\nNode(3, [Node(5), Node(2)])\n```\n\n----------------------------------------\n\nTITLE: Generating Feature Maps with MobileNetV2\nDESCRIPTION: Processes a batch of images through the MobileNet model to produce feature maps. The output shape shows the spatial dimensions of the feature maps before final classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfeature_map_batch = mobile_net(image_batch)\nprint(feature_map_batch.shape)\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow 1 train_and_evaluate\nDESCRIPTION: Executes the TensorFlow 1 train_and_evaluate function with the classifier, training specification, and evaluation specification to train and evaluate the model synchronously.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntf1.estimator.train_and_evaluate(estimator=classifier,\n                                train_spec=train_spec,\n                                eval_spec=eval_spec)\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow 1 SavedModel to TFLite Model in TF2\nDESCRIPTION: This example demonstrates how to convert a TensorFlow 1 SavedModel to a TFLite model using the TensorFlow 2 converter API. It shows the simplified conversion process with fewer flags compared to the TF1 approach.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tflite.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Convert TF1 SavedModel to a TFLite model.\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=SAVED_MODEL_DIR)\nconverter.optimizations = {tf.lite.Optimize.DEFAULT}\ntflite_model = converter.convert()\n```\n\n----------------------------------------\n\nTITLE: Subclassed Model Definition and Saving Attempt\nDESCRIPTION: This snippet defines a subclassed TensorFlow model and attempts to save it before training. It demonstrates a common pitfall where saving fails due to the lack of concrete functions, which are typically generated during the first call or training of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass SubclassedModel(tf.keras.Model):\n  \"\"\"Example model defined by subclassing `tf.keras.Model`.\"\"\"\n\n  output_name = 'output_layer'\n\n  def __init__(self):\n    super(SubclassedModel, self).__init__()\n    self._dense_layer = tf.keras.layers.Dense(\n        5, dtype=tf.dtypes.float32, name=self.output_name)\n\n  def call(self, inputs):\n    return self._dense_layer(inputs)\n\nmy_model = SubclassedModel()\ntry:\n  my_model.save(saved_model_path)\nexcept ValueError as e:\n  print(f'{type(e).__name__}: ', *e.args)\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Saving Function for ESRGAN Results\nDESCRIPTION: Creates a function to save processed tensor images to disk by clipping values to valid range, converting to appropriate format, and saving as JPEG files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef save_image(image, filename):\n  \"\"\"\n    Saves unscaled Tensor Images.\n    Args:\n      image: 3D image tensor. [height, width, channels]\n      filename: Name of the file to save.\n  \"\"\"\n  if not isinstance(image, Image.Image):\n    image = tf.clip_by_value(image, 0, 255)\n    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n  image.save(\"%s.jpg\" % filename)\n  print(\"Saved as %s.jpg\" % filename)\n```\n\n----------------------------------------\n\nTITLE: Listing SavedModel Directory Contents\nDESCRIPTION: Uses shell command to list the contents of the SavedModel directory, showing files and subdirectories like saved_model.pb and variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n!ls {mobilenet_save_path}\n```\n\n----------------------------------------\n\nTITLE: Reading TFRecord File in Python\nDESCRIPTION: This code shows how to read a TFRecord file using tf.data.TFRecordDataset and parse the Example protos into a dictionary of NumPy arrays without using TensorFlow ops.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [filename]\nraw_dataset = tf.data.TFRecordDataset(filenames)\nraw_dataset\n\nfor raw_record in raw_dataset.take(1):\n  example = tf.train.Example()\n  example.ParseFromString(raw_record.numpy())\n  print(example)\n\nresult = {}\n# example.features.feature is the dictionary\nfor key, feature in example.features.feature.items():\n  # The values are the Feature objects which contain a `kind` which contains:\n  # one of three fields: bytes_list, float_list, int64_list\n\n  kind = feature.WhichOneof('kind')\n  result[key] = np.array(getattr(feature, kind).value)\n\nresult\n```\n\n----------------------------------------\n\nTITLE: Analyze Debug Data Offline using tfdbg\nDESCRIPTION: This snippet provides a bash command to analyze dumped TensorFlow debug data offline. The offline_analyzer binary inspects data in the specified dump directory. Ensure that the dump location has been correctly specified in previous debug steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython -m tensorflow.python.debug.cli.offline_analyzer \\\n    --dump_dir=/shared/storage/location/tfdbg_dumps_1\n```\n\n----------------------------------------\n\nTITLE: Displaying Tensor Values from MaskedTensor in Python\nDESCRIPTION: Demonstrates how to access and print the values field of a MaskedTensor instance, which is automatically converted to a Tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(mt.values)\n```\n\n----------------------------------------\n\nTITLE: Subtracting Values from Existing Tensor with tf.tensor_scatter_nd_sub\nDESCRIPTION: Shows how to subtract values at specific indices of an existing tensor using tf.tensor_scatter_nd_sub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Convert the tensor into an identity matrix\n\nt13 = tf.tensor_scatter_nd_sub(t11,\n                               indices=[[0, 0], [0, 1], [1, 0], [1, 1], [1, 2], [2, 1], [2, 2]],\n                               updates=[1, 7, 9, -1, 1, 3, 7])\n\nprint(t13)\n```\n\n----------------------------------------\n\nTITLE: Extending SNGP Model with Covariance Reset in TensorFlow\nDESCRIPTION: This code extends the DeepResNetSNGP class to include the ResetCovarianceCallback in its fit method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nclass DeepResNetSNGPWithCovReset(DeepResNetSNGP):\n  def fit(self, *args, **kwargs):\n    \"\"\"Adds ResetCovarianceCallback to model callbacks.\"\"\"\n    kwargs[\"callbacks\"] = list(kwargs.get(\"callbacks\", []))\n    kwargs[\"callbacks\"].append(ResetCovarianceCallback())\n\n    return super().fit(*args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Training Low Latency Convolutional Model in TensorFlow\nDESCRIPTION: Command for training a low-latency CNN model based on 'cnn-one-fstride4' topology. Uses 11 million FLOPs with similar parameter count to standard conv model but faster execution. Includes two-phase training with different learning rates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npython tensorflow/examples/speech_commands/train \\\n--model_architecture=low_latency_conv \\\n--how_many_training_steps=20000,6000 \\\n--learning_rate=0.01,0.001\n```\n\n----------------------------------------\n\nTITLE: Configuring and Instantiating ResNet Model\nDESCRIPTION: Sets up a six-layer ResNet with 128 hidden units and creates an instance of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresnet_config = dict(num_classes=2, num_layers=6, num_hidden=128)\n```\n\nLANGUAGE: python\nCODE:\n```\nresnet_model = DeepResNet(**resnet_config)\n```\n\nLANGUAGE: python\nCODE:\n```\nresnet_model.build((None, 2))\nresnet_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained Model from TF Hub\nDESCRIPTION: Loading the pre-trained Wav2Vec2 model using TensorFlow Hub's KerasLayer\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npretrained_layer = hub.KerasLayer(\"https://tfhub.dev/vasudevgupta7/wav2vec2/1\", trainable=True)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimization Paths for Adam Algorithm\nDESCRIPTION: This code visualizes the path of the parameters over a contour plot of the loss function for the Adam optimization algorithm.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nviz_paths(param_map_adam, x_vals, loss, \"Adam\")\n```\n\n----------------------------------------\n\nTITLE: Concatenating and Shuffling Balanced Dataset\nDESCRIPTION: Combines resampled positive features with negative features and randomly shuffles the combined dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nresampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_features.shape\n```\n\n----------------------------------------\n\nTITLE: Listing Flower Dataset Class Directories\nDESCRIPTION: Loops through the root directory of the flower dataset to print the names of each class directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_56\n\nLANGUAGE: python\nCODE:\n```\nfor item in flowers_root.glob(\"*\"):\n  print(item.name)\n```\n\n----------------------------------------\n\nTITLE: Training Distributed Keras Model with NumPy Arrays\nDESCRIPTION: This snippet demonstrates training a distributed Keras model using NumPy arrays as input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\n\ninputs, targets = np.ones((100, 1)), np.ones((100, 1))\nmodel.fit(inputs, targets, epochs=2, batch_size=10)\n```\n\n----------------------------------------\n\nTITLE: Actor-Critic Loss Computer\nDESCRIPTION: Calculates the combined Actor-Critic loss using action probabilities, values and returns. Uses Huber loss for the critic component.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhuber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n\ndef compute_loss(\n    action_probs: tf.Tensor,\n    values: tf.Tensor,\n    returns: tf.Tensor) -> tf.Tensor:\n  \"\"\"Computes the combined Actor-Critic loss.\"\"\"\n\n  advantage = returns - values\n\n  action_log_probs = tf.math.log(action_probs)\n  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n\n  critic_loss = huber_loss(values, returns)\n\n  return actor_loss + critic_loss\n```\n\n----------------------------------------\n\nTITLE: Plotting Training History for Video Classification Model in Python\nDESCRIPTION: This function creates plots of loss and accuracy on training and validation sets. It takes the model history as input and generates a figure with two subplots for loss and accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef plot_history(history):\n  \"\"\"\n    Plotting training and validation learning curves.\n\n    Args:\n      history: model history with all the metric measures\n  \"\"\"\n  fig, (ax1, ax2) = plt.subplots(2)\n\n  fig.set_size_inches(18.5, 10.5)\n\n  # Plot loss\n  ax1.set_title('Loss')\n  ax1.plot(history.history['loss'], label = 'train')\n  ax1.plot(history.history['val_loss'], label = 'test')\n  ax1.set_ylabel('Loss')\n  \n  # Determine upper bound of y-axis\n  max_loss = max(history.history['loss'] + history.history['val_loss'])\n\n  ax1.set_ylim([0, np.ceil(max_loss)])\n  ax1.set_xlabel('Epoch')\n  ax1.legend(['Train', 'Validation']) \n\n  # Plot accuracy\n  ax2.set_title('Accuracy')\n  ax2.plot(history.history['accuracy'],  label = 'train')\n  ax2.plot(history.history['val_accuracy'], label = 'test')\n  ax2.set_ylabel('Accuracy')\n  ax2.set_ylim([0, 1])\n  ax2.set_xlabel('Epoch')\n  ax2.legend(['Train', 'Validation'])\n\n  plt.show()\n\nplot_history(history)\n```\n\n----------------------------------------\n\nTITLE: Setting up license and copyright information for TensorFlow Hub\nDESCRIPTION: Copyright notice and license information for the TensorFlow Hub Authors, establishing the Apache License 2.0 terms for the code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n```\n\n----------------------------------------\n\nTITLE: Extracting Elements from Multiple Axes with tf.gather_nd\nDESCRIPTION: Shows how to use tf.gather_nd to extract elements from specified indices across multiple dimensions of a tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nt4 = tf.constant([[0, 5],\n                  [1, 6],\n                  [2, 7],\n                  [3, 8],\n                  [4, 9]])\n\nprint(tf.gather_nd(t4,\n                   indices=[[2], [3], [0]]))\n```\n\n----------------------------------------\n\nTITLE: Performance Comparison Between Eager and tf.function\nDESCRIPTION: Compares execution time between eager mode and tf.function for a convolutional layer, showing that performance benefits depend on the operations being performed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport timeit\nconv_layer = tf.keras.layers.Conv2D(100, 3)\n\n@tf.function\ndef conv_fn(image):\n  return conv_layer(image)\n\nimage = tf.zeros([1, 200, 200, 100])\n# Warm up\nconv_layer(image); conv_fn(image)\nprint(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\nprint(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\nprint(\"Note how there's not much difference in performance for convolutions\")\n\n```\n\n----------------------------------------\n\nTITLE: Creating helper function for dataset display in TensorFlow\nDESCRIPTION: Defines a utility function to print the contents of a tf.data.Dataset where each element is a dictionary, making it easier to visualize dataset contents.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Helper function used to print datasets in the examples below.\ndef print_dictionary_dataset(dataset):\n  for i, element in enumerate(dataset):\n    print(\"Element {}:\".format(i))\n    for (feature_name, feature_value) in element.items():\n      print('{:>14} = {}'.format(feature_name, feature_value))\n```\n\n----------------------------------------\n\nTITLE: Configuring Batch Size and Learning Rate for Distributed Training\nDESCRIPTION: Shows how to calculate global batch size based on number of replicas and adjust learning rates accordingly for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nBATCH_SIZE_PER_REPLICA = 5\nglobal_batch_size = (BATCH_SIZE_PER_REPLICA *\n                     mirrored_strategy.num_replicas_in_sync)\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100)\ndataset = dataset.batch(global_batch_size)\n\nLEARNING_RATES_BY_BATCH_SIZE = {5: 0.1, 10: 0.15}\nlearning_rate = LEARNING_RATES_BY_BATCH_SIZE[global_batch_size]\n```\n\n----------------------------------------\n\nTITLE: Building a sequential neural network model for MNIST\nDESCRIPTION: Creates a simple sequential neural network with one hidden layer for classifying MNIST digits. The model includes a flattening layer to convert 28x28 images to 1D vectors, followed by dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10)\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['sparse_categorical_accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset for DTensor Training\nDESCRIPTION: Loads the MNIST dataset using TensorFlow Datasets for training and testing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n(ds_train, ds_test), ds_info = tfds.load(\n    'mnist',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Implicit Tensor Conversion in Functions\nDESCRIPTION: Demonstrates how TensorFlow functions like tf.reduce_sum automatically convert compatible Python objects to tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntf.reduce_sum([1,2,3])\n```\n\n----------------------------------------\n\nTITLE: Applying LayoutMap to a Subclassed Model in Python with DTensor API\nDESCRIPTION: Demonstrates how to create a LayoutMap and apply it to a subclassed model, specifying layouts for model weights without modifying the existing model code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nlayout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n\nlayout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\nlayout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n\nwith layout_map.scope():\n  subclassed_model = SubclassedModel()\n\ndtensor_input = dtensor.copy_to_mesh(tf.zeros((16, 16)), layout=unsharded_layout_2d)\n# Trigger the weights creation for subclass model\nsubclassed_model(dtensor_input)\n\nprint(subclassed_model.feature.kernel.layout)\n```\n\n----------------------------------------\n\nTITLE: Plotting Accuracy Metrics for DTensor Model Evaluation\nDESCRIPTION: Example usage of the plot_metrics function to visualize the accuracy during training and testing. This shows how model accuracy progresses over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplot_metrics(train_accs, test_accs, \"Accuracy\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating Video Classification Model on Test Dataset in Python\nDESCRIPTION: This code snippet uses Keras Model.evaluate to get the loss and accuracy on the test dataset. It returns the evaluation results as a dictionary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(test_ds, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Dataset for tf.Example in Python\nDESCRIPTION: This code generates a sample dataset with boolean, integer, string, and float features for use in creating tf.Example messages.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nn_observations = int(1e4)\n\nfeature0 = np.random.choice([False, True], n_observations)\n\nfeature1 = np.random.randint(0, 5, n_observations)\n\nstrings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\nfeature2 = strings[feature1]\n\nfeature3 = np.random.randn(n_observations)\n```\n\n----------------------------------------\n\nTITLE: Disabling Eager Execution for TensorFlow Estimator\nDESCRIPTION: Disables TensorFlow's eager execution mode which is necessary for multi-worker training with Estimators to avoid serialization issues with thread locks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.disable_eager_execution()\n```\n\n----------------------------------------\n\nTITLE: Rotating an Image by 90 Degrees with tf.image\nDESCRIPTION: Shows how to rotate an image by 90 degrees clockwise using tf.image.rot90. The transformation is applied to the original image and the result is displayed for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nrotated = tf.image.rot90(image)\nvisualize(image, rotated)\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow 1 Frozen GraphDef to TFLite Model in TF2\nDESCRIPTION: This example illustrates the process of converting a TensorFlow 1 frozen GraphDef to a TFLite model using TensorFlow 2. It first converts the frozen GraphDef to a TF1 SavedModel, then uses the TF2 converter to create a TFLite model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tflite.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n## Convert TF1 frozen Graph to TF1 SavedModel.\n\n# Load the graph as a v1.GraphDef\nimport pathlib\ngdef = tf.compat.v1.GraphDef()\ngdef.ParseFromString(pathlib.Path(GRAPH_DEF_MODEL_PATH).read_bytes())\n\n# Convert the GraphDef to a tf.Graph\nwith tf.Graph().as_default() as g:\n  tf.graph_util.import_graph_def(gdef, name=\"\")\n\n# Look up the input and output tensors.\ninput_tensor = g.get_tensor_by_name('input:0') \noutput_tensor = g.get_tensor_by_name('MobilenetV1/Predictions/Softmax:0')\n\n# Save the graph as a TF1 Savedmodel\nremove_dir('saved_model_3/')\nwith tf.compat.v1.Session(graph=g) as s:\n  tf.compat.v1.saved_model.simple_save(\n      session=s,\n      export_dir='saved_model_3/',\n      inputs={'input':input_tensor},\n      outputs={'output':output_tensor})\n\n# Convert TF1 SavedModel to a TFLite model.\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_3/')\nconverter.optimizations = {tf.lite.Optimize.DEFAULT}\ntflite_model = converter.convert()\n```\n\n----------------------------------------\n\nTITLE: Parsing CSV Lines with Proper Types using tf.io.decode_csv\nDESCRIPTION: This snippet demonstrates using tf.io.decode_csv with proper type specifications. It parses the Titanic data with the correct data types and displays the resulting feature types and shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nfeatures = tf.io.decode_csv(lines, record_defaults=titanic_types) \n\nfor f in features:\n  print(f\"type: {f.dtype.name}, shape: {f.shape}\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Time-Measured Custom Dataset in TensorFlow\nDESCRIPTION: Implements a custom TensorFlow dataset class that tracks the time spent in each processing step. The dataset provides samples with timing information for 'Open' and 'Read' operations, along with instance, epoch, and sample indices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass TimeMeasuredDataset(tf.data.Dataset):\n    # OUTPUT: (steps, timings, counters)\n    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n    \n    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n    \n    def _generator(instance_idx, num_samples):\n        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n        \n        # Opening the file\n        open_enter = time.perf_counter()\n        time.sleep(0.03)\n        open_elapsed = time.perf_counter() - open_enter\n        \n        for sample_idx in range(num_samples):\n            # Reading data (line, record) from the file\n            read_enter = time.perf_counter()\n            time.sleep(0.015)\n            read_elapsed = time.perf_counter() - read_enter\n            \n            yield (\n                [(\"Open\",), (\"Read\",)],\n                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n            )\n            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n            \n    \n    def __new__(cls, num_samples=3):\n        return tf.data.Dataset.from_generator(\n            cls._generator,\n            output_types=cls.OUTPUT_TYPES,\n            output_shapes=cls.OUTPUT_SHAPES,\n            args=(next(cls._INSTANCES_COUNTER), num_samples)\n        )\n```\n\n----------------------------------------\n\nTITLE: Importing required libraries for sentence encoding\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, TensorFlow Hub, SentencePiece, and visualization libraries to work with the Universal Sentence Encoder Lite model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom absl import logging\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\nimport sentencepiece as spm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport re\nimport seaborn as sns\n```\n\n----------------------------------------\n\nTITLE: Mapping Parse Function over Dataset (Python)\nDESCRIPTION: Applies a parsing function to convert serialized examples into structured tensors, preparing data for modeling or further processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nparsed_dataset = raw_dataset.map(_parse_function)\nparsed_dataset\n```\n\n----------------------------------------\n\nTITLE: Running Fine-tuning Training Loop\nDESCRIPTION: Executes a training loop using the previously defined train_step function, showing how loss decreases and variable values approach the optimal value over iterations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfor _ in range(10):\n  # \"v\" approaches 5, \"loss\" approaches 0\n  print(\"loss={:.2f} v={:.2f}\".format(train_step(), imported.v.numpy()))\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Gradient Disconnection Due to Non-TensorFlow Calculations\nDESCRIPTION: This snippet shows how performing calculations outside of TensorFlow (using NumPy) can lead to disconnected gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable([[1.0, 2.0],\n                 [3.0, 4.0]], dtype=tf.float32)\n\nwith tf.GradientTape() as tape:\n  x2 = x**2\n\n  # This step is calculated with NumPy\n  y = np.mean(x2, axis=0)\n\n  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n  # using `tf.convert_to_tensor`.\n  y = tf.reduce_mean(y, axis=0)\n\nprint(tape.gradient(y, x))\n```\n\n----------------------------------------\n\nTITLE: Loading and processing a GIF for MoViNet classification\nDESCRIPTION: Defines a function to load a GIF file, resize it, and convert it to a TensorFlow tensor suitable for input to the MoViNet model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef load_gif(file_path, image_size=(224, 224)):\n  \"\"\"Loads a gif file into a TF tensor.\n\n  Use images resized to match what's expected by your model.\n  The model pages say the \"A2\" models expect 224 x 224 images at 5 fps\n\n  Args:\n    file_path: path to the location of a gif file.\n    image_size: a tuple of target size.\n\n  Returns:\n    a video of the gif file\n  \"\"\"\n  # Load a gif file, convert it to a TF tensor\n  raw = tf.io.read_file(file_path)\n  video = tf.io.decode_gif(raw)\n  # Resize the video\n  video = tf.image.resize(video, image_size)\n  # change dtype to a float32\n  # Hub models always want images normalized to [0,1]\n  # ref: https://www.tensorflow.org/hub/common_signatures/images#input\n  video = tf.cast(video, tf.float32) / 255.\n  return video\n```\n\n----------------------------------------\n\nTITLE: Inspecting a Batch from the CSV Dataset\nDESCRIPTION: Examines the contents of a batch from the CSV dataset, showing how feature names are automatically used as dictionary keys and values are properly formatted.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfor batch, label in titanic_csv_ds.take(1):\n  for key, value in batch.items():\n    print(f\"{key:20s}: {value}\")\n  print()\n  print(f\"{'label':20s}: {label})\n```\n\n----------------------------------------\n\nTITLE: Encoding Final Results\nDESCRIPTION: Converts the segmented character codepoints back into UTF-8 encoded strings for display.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimization Paths\nDESCRIPTION: Defines a function to visualize the paths of parameters over a contour plot of the loss function for different learning rates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\ndef viz_paths(param_map, x_vals, loss_fn, title, max_iters=2000):\n  # Creating a controur plot of the loss function\n  t_vals = tf.range(1., max_iters + 100.)\n  t_grid, x_grid = tf.meshgrid(t_vals, x_vals)\n  loss_grid = tf.math.log(loss_fn(x_grid))\n  plt.pcolormesh(t_vals, x_vals, loss_grid, vmin=0, shading='nearest')\n  colors = ['r', 'w', 'c']\n  # Plotting the parameter paths over the contour plot\n  for i, learning_rate in enumerate(param_map):\n    param_path = param_map[learning_rate]\n    if len(param_path) > 0:\n      x_star = param_path[-1]\n      plt.plot(t_vals[:len(param_path)], param_path, c=colors[i])\n      plt.plot(len(param_path), x_star, marker='o', c=colors[i], \n              label = f\"x*: learning rate={learning_rate}\")\n  plt.xlabel(\"Iterations\")\n  plt.ylabel(\"Parameter value\")\n  plt.legend()\n  plt.title(f\"{title} parameter paths\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Single-Step WindowGenerator for Time Series Prediction\nDESCRIPTION: Creates a WindowGenerator instance specifically configured for single-step prediction, with input and label width of 1 and a shift of a single time step, focusing on the temperature column for prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nsingle_step_window = WindowGenerator(\n    input_width=1, label_width=1, shift=1,\n    label_columns=['T (degC)'])\nsingle_step_window\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Model\nDESCRIPTION: Generates predictions using the model on a single training example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npredictions = model(x_train[:1]).numpy()\npredictions\n```\n\n----------------------------------------\n\nTITLE: Visualizing 2D Latent Space of CVAE in Python\nDESCRIPTION: Implements a function to plot a 2D manifold of digits from the latent space, showcasing the continuous distribution of different digit classes across the latent space.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\ndef plot_latent_images(model, n, digit_size=28):\n  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n\n  norm = tfp.distributions.Normal(0, 1)\n  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n  image_width = digit_size*n\n  image_height = image_width\n  image = np.zeros((image_height, image_width))\n\n  for i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n      z = np.array([[xi, yi]])\n      x_decoded = model.sample(z)\n      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n      image[i * digit_size: (i + 1) * digit_size,\n            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n\n  plt.figure(figsize=(10, 10))\n  plt.imshow(image, cmap='Greys_r')\n  plt.axis('Off')\n  plt.show()\n```\n\nLANGUAGE: Python\nCODE:\n```\nplot_latent_images(model, 20)\n```\n\n----------------------------------------\n\nTITLE: Using Factory Methods Instead of Custom Constructor in Python\nDESCRIPTION: Demonstrates an alternative approach to customizing object creation using factory methods instead of overriding the constructor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nclass Toy(tf.experimental.ExtensionType):\n  name: str\n  price: tf.Tensor\n\n  @staticmethod\n  def new_toy_with_discount(name, price, discount):\n    return Toy(name, price * (1 - discount))\n\nprint(Toy.new_toy_with_discount(\"ball\", 5.0, discount=0.2))\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow with GPU Support\nDESCRIPTION: Pip command to install TensorFlow with CUDA GPU support for deep learning and machine learning tasks\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\npip install tensorflow[and-cuda]\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom TensorFlow Dataset in Python\nDESCRIPTION: This Python snippet demonstrates how to define a custom dataset in TensorFlow. It involves creating a Python class 'MyReaderDataset' that extends 'tf.data.Dataset'. The 'my_reader_dataset_op.so' shared object library is loaded to provide custom operations. This snippet requires a compiled TensorFlow shared library and TensorFlow API to construct the dataset graph node and define the output types, shapes, and classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/formats.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Assumes the file is in the current working directory.\nmy_reader_dataset_module = tf.load_op_library(\"./my_reader_dataset_op.so\")\n\nclass MyReaderDataset(tf.data.Dataset):\n\n  def __init__(self):\n    super(MyReaderDataset, self).__init__()\n    # Create any input attrs or tensors as members of this class.\n\n  def _as_variant_tensor(self):\n    # Actually construct the graph node for the dataset op.\n    #\n    # This method will be invoked when you create an iterator on this dataset\n    # or a dataset derived from it.\n    return my_reader_dataset_module.my_reader_dataset()\n\n  # The following properties define the structure of each element: a scalar\n  # `tf.string` tensor. Change these properties to match the `output_dtypes()`\n  # and `output_shapes()` methods of `MyReaderDataset::Dataset` if you modify\n  # the structure of each element.\n  @property\n  def output_types(self):\n    return tf.string\n\n  @property\n  def output_shapes(self):\n    return tf.TensorShape([])\n\n  @property\n  def output_classes(self):\n    return tf.Tensor\n\nif __name__ == \"__main__\":\n  # Create a MyReaderDataset and print its elements.\n  with tf.Session() as sess:\n    iterator = MyReaderDataset().make_one_shot_iterator()\n    next_element = iterator.get_next()\n    try:\n      while True:\n        print(sess.run(next_element))  # Prints \"MyReader!\" ten times.\n    except tf.errors.OutOfRangeError:\n      pass\n\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing an Image for Inference\nDESCRIPTION: Downloads a sample image using Keras utilities, opens it with PIL, and normalizes pixel values by dividing by 255.0 for model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimg_file = tf.keras.utils.get_file(origin=\"https://tensorflow.org/images/bedroom_hrnet_tutorial.jpg\")\nimg = np.array(Image.open(img_file))/255.0\n```\n\n----------------------------------------\n\nTITLE: Spectrogram Plotting Function\nDESCRIPTION: Function to create and display spectrogram visualization of audio data using librosa.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nMAX_ABS_INT16 = 32768.0\n\ndef plot_stft(x, sample_rate, show_black_and_white=False):\n  x_stft = np.abs(librosa.stft(x, n_fft=2048))\n  fig, ax = plt.subplots()\n  fig.set_size_inches(20, 10)\n  x_stft_db = librosa.amplitude_to_db(x_stft, ref=np.max)\n  if(show_black_and_white):\n    librosadisplay.specshow(data=x_stft_db, y_axis='log', \n                             sr=sample_rate, cmap='gray_r')\n  else:\n    librosadisplay.specshow(data=x_stft_db, y_axis='log', sr=sample_rate)\n\n  plt.colorbar(format='%+2.0f dB')\n```\n\n----------------------------------------\n\nTITLE: Configuring TextVectorization Layer in TensorFlow for Text Processing\nDESCRIPTION: Setting up a TextVectorization layer to standardize, tokenize, and vectorize text data. This layer converts text inputs into integer sequences with a defined maximum vocabulary size and sequence length.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmax_features = 10000\nsequence_length = 250\n\nvectorize_layer = layers.TextVectorization(\n    standardize=custom_standardization,\n    max_tokens=max_features,\n    output_mode='int',\n    output_sequence_length=sequence_length)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Image Dataset from Directory in Python\nDESCRIPTION: Demonstrates how to use tf.keras.utils.image_dataset_from_directory to generate a tf.data.Dataset from a directory of images on disk. This is a high-level utility for image preprocessing in Keras.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.utils.image_dataset_from_directory\n```\n\n----------------------------------------\n\nTITLE: Displaying Interpolated Video Frames in Python\nDESCRIPTION: Code that shows how to display the interpolated frames as a video using media.show_video, with a specified frame rate (fps) of 30.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(f'video with {len(frames)} frames')\nmedia.show_video(frames, fps=30, title='FILM interpolated video')\n```\n\n----------------------------------------\n\nTITLE: Defining Image Labels for TFRecord Processing (Python)\nDESCRIPTION: Associates label IDs with image files, a preparatory step for categorizing image data in TFRecords through metadata.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nimage_labels = {\n    cat_in_snow : 0,\n    williamsburg_bridge : 1,\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Keras Model with Input and Output\nDESCRIPTION: Creates a TensorFlow Keras model by specifying the input and output tensors, then demonstrates inferencing with the model using NumPy arrays.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncalc = tf.keras.Model(inputs=input, outputs=result)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(calc(np.array([1])).numpy())\nprint(calc(np.array([2])).numpy())\n```\n\n----------------------------------------\n\nTITLE: Checking for Missing Values (Python)\nDESCRIPTION: This snippet checks the dataset for missing values by summing the null entries across all columns, aiding in data cleaning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndataset.isna().sum()\n```\n\n----------------------------------------\n\nTITLE: Using SidecarEvaluator for TensorFlow 2 Model Evaluation\nDESCRIPTION: Prepares test data as a TensorFlow dataset and uses SidecarEvaluator to evaluate the trained Keras model using checkpoints saved during training, simulating a separate evaluation process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndata = tf.data.Dataset.from_tensor_slices((x_test, y_test))\ndata = data.batch(64)\n\ntf.keras.utils.SidecarEvaluator(\n    model=model,\n    data=data,\n    checkpoint_dir=log_dir,\n    max_evaluations=1\n).start()\n```\n\n----------------------------------------\n\nTITLE: Registering a CPU Kernel Builder for ZeroOut Operation in TensorFlow\nDESCRIPTION: This snippet shows how to register the ZeroOut kernel implementation with the TensorFlow system for CPU devices. The registration associates the operation name with the specific kernel implementation and device constraints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\n```\n\n----------------------------------------\n\nTITLE: Executing TensorFlow Session with Placeholder Inputs\nDESCRIPTION: This code snippet demonstrates creating a TensorFlow session, defining a placeholder, and running computations with various input values. The placeholder 'x' allows dynamic input by feeding different values at runtime. It requires TensorFlow installed and configured. The snippet also handles exceptions when values are not correctly fed to placeholders.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# and a computation that depends on it.\nx = tf.placeholder(tf.float32, shape=[3])\ny = tf.square(x)\n\nwith tf.Session() as sess:\n  # Feeding a value changes the result that is returned when you evaluate `y`.\n  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n\n  # Raises `tf.errors.InvalidArgumentError`, because you must feed a value for\n  # a `tf.placeholder()` when evaluating a tensor that depends on it.\n  sess.run(y)\n\n  # Raises `ValueError`, because the shape of `37.0` does not match the shape\n  # of placeholder `x`.\n  sess.run(y, {x: 37.0})\n```\n\n----------------------------------------\n\nTITLE: Creating MNIST Codec and Compressing Images in TensorFlow\nDESCRIPTION: This code creates a compressor and decompressor for MNIST images, compresses a batch of images to strings, and then decompresses them back to images. It also prints information about the compressed representation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef make_mnist_codec(trainer, **kwargs):\n  # The entropy model must be created with `compression=True` and the same\n  # instance must be shared between compressor and decompressor.\n  entropy_model = tfc.ContinuousBatchedEntropyModel(\n      trainer.prior, coding_rank=1, compression=True, **kwargs)\n  compressor = MNISTCompressor(trainer.analysis_transform, entropy_model)\n  decompressor = MNISTDecompressor(entropy_model, trainer.synthesis_transform)\n  return compressor, decompressor\n\ncompressor, decompressor = make_mnist_codec(trainer)\n\n(originals, _), = validation_dataset.batch(16).skip(3).take(1)\n\nstrings, entropies = compressor(originals)\n\nprint(f\"String representation of first digit in hexadecimal: 0x{strings[0].numpy().hex()}\")\nprint(f\"Number of bits actually needed to represent it: {entropies[0]:0.2f}\")\n\nreconstructions = decompressor(strings)\n```\n\n----------------------------------------\n\nTITLE: Configuring TPU RunConfig\nDESCRIPTION: Demonstrates how to create a complete TPU RunConfig setup that can switch between local and Cloud TPU execution, including project configuration and cluster resolution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\nimport subprocess\n\nclass FLAGS(object):\n  use_tpu=False\n  tpu_name=None\n  # Use a local temporary path for the `model_dir`\n  model_dir = tempfile.mkdtemp()\n  # Number of training steps to run on the Cloud TPU before returning control.\n  iterations = 50\n  # A single Cloud TPU has 8 shards.\n  num_shards = 8\n\nif FLAGS.use_tpu:\n    my_project_name = subprocess.check_output([\n        'gcloud','config','get-value','project'])\n    my_zone = subprocess.check_output([\n        'gcloud','config','get-value','compute/zone'])\n    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n            tpu=[FLAGS.tpu_name],\n            zone=my_zone,\n            project=my_project_name)\n    master = tpu_cluster_resolver.get_master()\nelse:\n    master = ''\n\nmy_tpu_run_config = tf.estimator.tpu.RunConfig(\n    master=master,\n    evaluation_master=master,\n    model_dir=FLAGS.model_dir,\n    session_config=tf.ConfigProto(\n        allow_soft_placement=True, log_device_placement=True),\n    tpu_config=tf.estimator.tpu.TPUConfig(FLAGS.iterations,\n                                          FLAGS.num_shards),\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset with Multiple Components\nDESCRIPTION: Creates a dataset where each element is a tuple containing two tensors of different shapes, demonstrating how to combine multiple tensors in a single dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndataset2 = tf.data.Dataset.from_tensor_slices(\n   (tf.random.uniform([4]),\n    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n\ndataset2.element_spec\n```\n\n----------------------------------------\n\nTITLE: Creating and Training Keras Model with MaskedTensor\nDESCRIPTION: Shows how to construct and train a Keras Sequential model that accepts MaskedTensor inputs using standard Dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\ninput_spec = MaskedTensor.Spec([None, 2], tf.float32)\n\nmasked_tensor_model = tf.keras.Sequential([\n    tf.keras.layers.Input(type_spec=input_spec),\n    tf.keras.layers.Dense(16, activation=\"relu\"),\n    tf.keras.layers.Dense(1)])\nmasked_tensor_model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n```\n\nLANGUAGE: python\nCODE:\n```\na = MaskedTensor([[1., 2], [3, 4], [5, 6]],\n                  [[True, False], [False, True], [True, True]])\nmasked_tensor_model.fit(a, tf.constant([[1], [0], [1]]), epochs=3)\nprint(masked_tensor_model(a))\n```\n\n----------------------------------------\n\nTITLE: Loading and Inspecting TensorFlow Checkpoints\nDESCRIPTION: This code demonstrates how to use tf.train.load_checkpoint to create a CheckpointReader object, which provides low-level access to checkpoint contents. It shows how to retrieve shape and dtype information for variables in the checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nreader = tf.train.load_checkpoint('./tf_ckpts/')\nshape_from_key = reader.get_variable_to_shape_map()\ndtype_from_key = reader.get_variable_to_dtype_map()\n\nsorted(shape_from_key.keys())\n```\n\n----------------------------------------\n\nTITLE: Expected Return Calculator\nDESCRIPTION: Computes expected returns for each timestep using discount factor gamma. Includes optional standardization of returns for training stability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef get_expected_return(\n    rewards: tf.Tensor,\n    gamma: float,\n    standardize: bool = True) -> tf.Tensor:\n  \"\"\"Compute expected returns per timestep.\"\"\"\n\n  n = tf.shape(rewards)[0]\n  returns = tf.TensorArray(dtype=tf.float32, size=n)\n\n  # Start from the end of `rewards` and accumulate reward sums\n  # into the `returns` array\n  rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n  discounted_sum = tf.constant(0.0)\n  discounted_sum_shape = discounted_sum.shape\n  for i in tf.range(n):\n    reward = rewards[i]\n    discounted_sum = reward + gamma * discounted_sum\n    discounted_sum.set_shape(discounted_sum_shape)\n    returns = returns.write(i, discounted_sum)\n  returns = returns.stack()[::-1]\n\n  if standardize:\n    returns = ((returns - tf.math.reduce_mean(returns)) /\n               (tf.math.reduce_std(returns) + eps))\n\n  return returns\n```\n\n----------------------------------------\n\nTITLE: One-hot Encoding String Data with Keras\nDESCRIPTION: Shows how to one-hot encode string data using a vocabulary with Keras StringLookup layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nstring_lookup_layer = tf.keras.layers.StringLookup(\n    vocabulary=['small', 'medium', 'large'],\n    num_oov_indices=0,\n    output_mode='one_hot')\nstring_lookup_layer(['small', 'medium', 'large'])\n```\n\n----------------------------------------\n\nTITLE: Training with TensorFlow Metrics and Summary Logging\nDESCRIPTION: This snippet shows how to use tf.keras.metrics to aggregate data during training and testing, and logging the results as summaries for visualization in TensorBoard. It demonstrates separating train and test summaries into different directories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef train(model, optimizer, dataset, log_freq=10):\n  avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n  for images, labels in dataset:\n    loss = train_step(model, optimizer, images, labels)\n    avg_loss.update_state(loss)\n    if tf.equal(optimizer.iterations % log_freq, 0):\n      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n      avg_loss.reset_states()\n\ndef test(model, test_x, test_y, step_num):\n  # training=False is only needed if there are layers with different\n  # behavior during training versus inference (e.g. Dropout).\n  loss = loss_fn(model(test_x, training=False), test_y)\n  tf.summary.scalar('loss', loss, step=step_num)\n\ntrain_summary_writer = tf.summary.create_file_writer('/tmp/summaries/train')\ntest_summary_writer = tf.summary.create_file_writer('/tmp/summaries/test')\n\nwith train_summary_writer.as_default():\n  train(model, optimizer, dataset)\n\nwith test_summary_writer.as_default():\n  test(model, test_x, test_y, optimizer.iterations)\n```\n\n----------------------------------------\n\nTITLE: Complete Multi-Worker Training Implementation with TensorFlow\nDESCRIPTION: This comprehensive script combines all the elements of multi-worker training, including strategy definition, data sharding, model building, custom training loop, and checkpoint management. It's designed to be run on each worker in a distributed training setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n%%writefile main.py\n#@title File: `main.py`\nimport os\nimport json\nimport tensorflow as tf\nimport mnist\nfrom multiprocessing import util\n\nper_worker_batch_size = 64\ntf_config = json.loads(os.environ['TF_CONFIG'])\nnum_workers = len(tf_config['cluster']['worker'])\nglobal_batch_size = per_worker_batch_size * num_workers\n\nnum_epochs = 3\nnum_steps_per_epoch=70\n\n# Checkpoint saving and restoring\ndef _is_chief(task_type, task_id, cluster_spec):\n  return (task_type is None\n          or task_type == 'chief'\n          or (task_type == 'worker'\n              and task_id == 0\n              and 'chief' not in cluster_spec.as_dict()))\n\ndef _get_temp_dir(dirpath, task_id):\n  base_dirpath = 'workertemp_' + str(task_id)\n  temp_dir = os.path.join(dirpath, base_dirpath)\n  tf.io.gfile.makedirs(temp_dir)\n  return temp_dir\n\ndef write_filepath(filepath, task_type, task_id, cluster_spec):\n  dirpath = os.path.dirname(filepath)\n  base = os.path.basename(filepath)\n  if not _is_chief(task_type, task_id, cluster_spec):\n    dirpath = _get_temp_dir(dirpath, task_id)\n  return os.path.join(dirpath, base)\n\ncheckpoint_dir = os.path.join(util.get_temp_dir(), 'ckpt')\n\n# Define Strategy\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n\nwith strategy.scope():\n  # Model building/compiling need to be within `tf.distribute.Strategy.scope`.\n  multi_worker_model = mnist.build_cnn_model()\n\n  multi_worker_dataset = strategy.distribute_datasets_from_function(\n      lambda input_context: mnist.dataset_fn(global_batch_size, input_context))\n  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='train_accuracy')\n\n@tf.function\ndef train_step(iterator):\n  \"\"\"Training step function.\"\"\"\n\n  def step_fn(inputs):\n    \"\"\"Per-Replica step function.\"\"\"\n    x, y = inputs\n    with tf.GradientTape() as tape:\n      predictions = multi_worker_model(x, training=True)\n      per_example_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n          from_logits=True,\n          reduction=tf.keras.losses.Reduction.NONE)(y, predictions)\n      loss = tf.nn.compute_average_loss(per_example_loss)\n      model_losses = multi_worker_model.losses\n      if model_losses:\n        loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n\n    grads = tape.gradient(loss, multi_worker_model.trainable_variables)\n    optimizer.apply_gradients(\n        zip(grads, multi_worker_model.trainable_variables))\n    train_accuracy.update_state(y, predictions)\n\n    return loss\n\n  per_replica_losses = strategy.run(step_fn, args=(next(iterator),))\n  return strategy.reduce(\n      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n\nepoch = tf.Variable(\n    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\nstep_in_epoch = tf.Variable(\n    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n    name='step_in_epoch')\n\ntask_type, task_id, cluster_spec = (strategy.cluster_resolver.task_type,\n                                    strategy.cluster_resolver.task_id,\n                                    strategy.cluster_resolver.cluster_spec())\n\ncheckpoint = tf.train.Checkpoint(\n    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n\nwrite_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n                                      cluster_spec)\ncheckpoint_manager = tf.train.CheckpointManager(\n    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)\n\n# Restoring the checkpoint\nlatest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\nif latest_checkpoint:\n  checkpoint.restore(latest_checkpoint)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Keras Model Accuracy\nDESCRIPTION: This snippet evaluates the accuracy of a trained Keras model on a test dataset. It uses the `evaluate` method to calculate the loss and accuracy. The `test_images` and `test_labels` represent the test dataset, and the `verbose` parameter controls the level of output during evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('Test accuracy:', test_acc)\n```\n\n----------------------------------------\n\nTITLE: Constructing DynamicRaggedShape with Row Partitions\nDESCRIPTION: Demonstrates direct construction of a DynamicRaggedShape using row partitions and an inner shape, which specifies how dimensions are partitioned.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_46\n\nLANGUAGE: python\nCODE:\n```\ntf.experimental.DynamicRaggedShape(\n    row_partitions=[tf.experimental.RowPartition.from_row_lengths([5, 3, 2])],\n    inner_shape=[10, 8])\n```\n\n----------------------------------------\n\nTITLE: Comparing Predictions with Ground Truth Labels\nDESCRIPTION: Stacks and displays the actual labels and model predictions side by side for comparison using tf.stack.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ntf.stack([y,prediction],axis=1)\n```\n\n----------------------------------------\n\nTITLE: Optimizing TensorFlow Dataset Performance with Caching and Prefetching\nDESCRIPTION: Configuring datasets with caching and prefetching to improve training performance. These operations ensure data isn't a bottleneck during model training by keeping processed data in memory and overlapping data preprocessing with model execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Creating a Label Extraction Function\nDESCRIPTION: Defines a function to extract class labels from file paths. It converts file paths to one-hot encodings based on directory names and returns an integer label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef get_label(file_path):\n  # Convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  # The second to last is the class-directory\n  one_hot = parts[-2] == class_names\n  # Integer encode the label\n  return tf.argmax(one_hot)\n```\n\n----------------------------------------\n\nTITLE: Preparing True Labels for Performance Comparison in TensorFlow\nDESCRIPTION: This code extracts the true labels for the validation data from the 'labels' array, starting from the index after the training data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ny_true = np.array(labels[train_size:])\n```\n\n----------------------------------------\n\nTITLE: Generating Quadratic Data with Noise in TensorFlow\nDESCRIPTION: Creates a dataset following a quadratic curve with added random noise using TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linspace(-2, 2, 201)\nx = tf.cast(x, tf.float32)\n\ndef f(x):\n  y = x**2 + 2*x - 5\n  return y\n\ny = f(x) + tf.random.normal(shape=[201])\n\nplt.plot(x.numpy(), y.numpy(), '.', label='Data')\nplt.plot(x, f(x), label='Ground truth')\nplt.legend();\n```\n\n----------------------------------------\n\nTITLE: Creating Simple Linear Model with Keras in Python\nDESCRIPTION: This class defines a simple linear model using Keras. It has a single dense layer with 5 units.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass Net(tf.keras.Model):\n  \"\"\"A simple linear model.\"\"\"\n\n  def __init__(self):\n    super(Net, self).__init__()\n    self.l1 = tf.keras.layers.Dense(5)\n\n  def call(self, x):\n    return self.l1(x)\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Download and Resize Function\nDESCRIPTION: Function to download images from URLs and resize them to specified dimensions using PIL\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef download_and_resize(name, url, new_width=256, new_height=256):\n  path = tf.keras.utils.get_file(url.split('/')[-1], url)\n  image = Image.open(path)\n  image = ImageOps.fit(image, (new_width, new_height), Image.LANCZOS)\n  return image\n```\n\n----------------------------------------\n\nTITLE: Resetting Gradient Tape Recording with reset Method\nDESCRIPTION: Shows how to completely reset a gradient tape during execution using the reset method, which discards all previously recorded operations and starts fresh.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\ny = tf.Variable(3.0)\nreset = True\n\nwith tf.GradientTape() as t:\n  y_sq = y * y\n  if reset:\n    # Throw out all the tape recorded so far.\n    t.reset()\n  z = x * x + y_sq\n\ngrad = t.gradient(z, {'x': x, 'y': y})\n\nprint('dz/dx:', grad['x'])  # 2*x => 4\nprint('dz/dy:', grad['y'])\n```\n\n----------------------------------------\n\nTITLE: Implementing Graph-Enabled Sequential Module\nDESCRIPTION: Creates a sequential module with the __call__ method decorated with @tf.function for graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MySequentialModule(tf.Module):\n  def __init__(self, name=None):\n    super().__init__(name=name)\n\n    self.dense_1 = Dense(in_features=3, out_features=3)\n    self.dense_2 = Dense(in_features=3, out_features=2)\n\n  @tf.function\n  def __call__(self, x):\n    x = self.dense_1(x)\n    return self.dense_2(x)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Vocabulary in TextVectorization Layer with TensorFlow\nDESCRIPTION: Accessing the vocabulary created by the TextVectorization layer to see word-to-integer mappings. This code prints examples of token mappings and the total vocabulary size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\nprint(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\nprint('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))\n```\n\n----------------------------------------\n\nTITLE: Evaluating Initial Model Performance\nDESCRIPTION: Evaluates the untrained model's performance on the validation dataset to establish a baseline for comparison after training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ninitial_epochs = 10\n\nloss0, accuracy0 = model.evaluate(validation_dataset)\n```\n\n----------------------------------------\n\nTITLE: Concatenating and converting sparse tensors in TensorFlow\nDESCRIPTION: Demonstrates how to convert ragged tensors to sparse tensors, concatenate them, and then convert back to dense format with a placeholder for missing values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nsparse_x = ragged_x.to_sparse()\nsparse_y = ragged_y.to_sparse()\nsparse_result = tf.sparse.concat(sp_inputs=[sparse_x, sparse_y], axis=1)\nprint(tf.sparse.to_dense(sparse_result, ''))\n```\n\n----------------------------------------\n\nTITLE: Define and Compile CNN Model\nDESCRIPTION: Creates a sequential CNN model with multiple convolution and pooling layers, followed by dense layers. Includes image rescaling and compilation with Adam optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nnum_classes = 5\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Loading Text Dataset from Directory in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use tf.keras.utils.text_dataset_from_directory to load a text dataset from a directory structure. It creates training, validation, and test datasets with specified batch sizes and splits.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nbatch_size = 32\nseed = 42\n\nraw_train_ds = utils.text_dataset_from_directory(\n    train_dir,\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='training',\n    seed=seed)\n\nraw_val_ds = utils.text_dataset_from_directory(\n    train_dir,\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='validation',\n    seed=seed)\n\ntest_dir = dataset_dir/'test'\n\nraw_test_ds = utils.text_dataset_from_directory(\n    test_dir,\n    batch_size=batch_size)\n```\n\n----------------------------------------\n\nTITLE: Processing and Inferencing Speech Sample in TensorFlow\nDESCRIPTION: This code reads a speech sample, pads it, normalizes it using a Wav2Vec2Processor, and performs inference using the loaded model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nspeech, _ = sf.read(\"SA2.wav\")\nspeech = np.pad(speech, (0, AUDIO_MAXLEN - len(speech)))\nspeech = tf.expand_dims(processor(tf.constant(speech)), 0)\n\noutputs = finetuned_model(speech)\noutputs\n```\n\n----------------------------------------\n\nTITLE: Loading Universal Sentence Encoder Model\nDESCRIPTION: Loads the pre-trained Multilingual Universal Sentence Encoder model from TensorFlow Hub and defines an embedding function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodule_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3' #@param ['https://tfhub.dev/google/universal-sentence-encoder-multilingual/3', 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3']\n\nmodel = hub.load(module_url)\n\ndef embed_text(input):\n  return model(input)\n```\n\n----------------------------------------\n\nTITLE: Re-tracing tf.function with Different Input Types\nDESCRIPTION: Shows how tf.function will re-trace when given inputs with different data types, creating a new specialized graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([10.0, 9.1, 8.2], dtype=tf.float32)\nmy_func(x)\n```\n\n----------------------------------------\n\nTITLE: Printing Predictions and Probabilities for Iris Species Classification in Python\nDESCRIPTION: This code iterates through the predictions made by the classifier, extracting the predicted class and its probability for each input. It then prints these results along with the expected species.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfor pred_dict, expec in zip(predictions, expected):\n    class_id = pred_dict['class_ids'][0]\n    probability = pred_dict['probabilities'][class_id]\n\n    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n        SPECIES[class_id], 100 * probability, expec))\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Step for DTensor Model\nDESCRIPTION: Defines a custom training step function that handles gradient computation and application with DTensor-aware loss reduction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(model, x, y, optimizer, metrics):\n  with tf.GradientTape() as tape:\n    logits = model(x, training=True)\n    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n    # global loss (scalar).\n    loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n        y, logits, from_logits=True))\n    \n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n  for metric in metrics.values():\n    metric.update_state(y_true=y, y_pred=logits)\n\n  loss_per_sample = loss / len(x)\n  results = {'loss': loss_per_sample}\n  return results\n```\n\n----------------------------------------\n\nTITLE: Flipping an Image Horizontally with tf.image\nDESCRIPTION: Demonstrates horizontal flipping of an image using tf.image.flip_left_right. This basic transformation reverses the image along the horizontal axis and displays the result alongside the original for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nflipped = tf.image.flip_left_right(image)\nvisualize(image, flipped)\n```\n\n----------------------------------------\n\nTITLE: Implementing CompressibleDense Layer with Entropy Regularization\nDESCRIPTION: Extends a custom dense layer with functionality for entropy regularization and quantization. It tracks separate latent representations of weights, applies quantization with trainable step sizes, and adds regularization losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass CompressibleDense(CustomDense):\n\n  def __init__(self, regularizer, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.regularizer = regularizer\n\n  def build(self, input_shape, other=None):\n    \"\"\"Instantiates weights, optionally initializing them from `other`.\"\"\"    \n    super().build(input_shape, other=other)\n    if other is not None and hasattr(other, \"kernel_log_step\"):\n      kernel_log_step = other.kernel_log_step\n      bias_log_step = other.bias_log_step\n    else:\n      kernel_log_step = bias_log_step = -4.\n    self.kernel_log_step = tf.Variable(\n        tf.cast(kernel_log_step, self.variable_dtype), name=\"kernel_log_step\")\n    self.bias_log_step = tf.Variable(\n        tf.cast(bias_log_step, self.variable_dtype), name=\"bias_log_step\")\n    self.add_loss(lambda: self.regularizer(\n        self.kernel_latent / tf.exp(self.kernel_log_step)))\n    self.add_loss(lambda: self.regularizer(\n        self.bias_latent / tf.exp(self.bias_log_step)))\n\n  @property\n  def kernel(self):\n    return quantize(self.kernel_latent, self.kernel_log_step)\n\n  @kernel.setter\n  def kernel(self, kernel):\n    self.kernel_latent = tf.Variable(kernel, name=\"kernel_latent\")\n\n  @property\n  def bias(self):\n    return quantize(self.bias_latent, self.bias_log_step)\n\n  @bias.setter\n  def bias(self, bias):\n    self.bias_latent = tf.Variable(bias, name=\"bias_latent\")\n```\n\n----------------------------------------\n\nTITLE: Loading YAMNet Model from TensorFlow Hub in Python\nDESCRIPTION: This code loads the YAMNet model from TensorFlow Hub. The model is used for audio event classification across 521 classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Load the model.\nmodel = hub.load('https://tfhub.dev/google/yamnet/1')\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Dataset from Tensor Slices\nDESCRIPTION: Demonstrates creating a basic tf.data.Dataset from a list of integers using from_tensor_slices. This is a fundamental method to create datasets from in-memory data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\ndataset\n```\n\n----------------------------------------\n\nTITLE: Implementing Naive Mapping for TensorFlow Dataset Benchmarking\nDESCRIPTION: Creates a mapping function and dataset pipeline for the naive approach to processing datasets. The map function adds simulated computational and memory operations without optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n@map_decorator\ndef naive_map(steps, times, values):\n    map_enter = time.perf_counter()\n    time.sleep(0.001)  # Time consuming step\n    time.sleep(0.0001)  # Memory consuming step\n    map_elapsed = time.perf_counter() - map_enter\n\n    return (\n        tf.concat((steps, [[\"Map\"]]), axis=0),\n        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n        tf.concat((values, [values[-1]]), axis=0)\n    )\n\nnaive_timeline = timelined_benchmark(\n    tf.data.Dataset.range(2)\n    .flat_map(dataset_generator_fun)\n    .map(naive_map)\n    .batch(_batch_map_num_items, drop_remainder=True)\n    .unbatch(),\n    5\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Frame Interpolator Class for FILM Model\nDESCRIPTION: Implements a custom Interpolator class that wraps the FILM model for efficient frame interpolation, including padding and alignment operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef _pad_to_align(x, align):\n  assert np.ndim(x) == 4\n  assert align > 0, 'align must be a positive number.'\n\n  height, width = x.shape[-3:-1]\n  height_to_pad = (align - height % align) if height % align != 0 else 0\n  width_to_pad = (align - width % align) if width % align != 0 else 0\n\n  bbox_to_pad = {\n      'offset_height': height_to_pad // 2,\n      'offset_width': width_to_pad // 2,\n      'target_height': height + height_to_pad,\n      'target_width': width + width_to_pad\n  }\n  padded_x = tf.image.pad_to_bounding_box(x, **bbox_to_pad)\n  bbox_to_crop = {\n      'offset_height': height_to_pad // 2,\n      'offset_width': width_to_pad // 2,\n      'target_height': height,\n      'target_width': width\n  }\n  return padded_x, bbox_to_crop\n\n\nclass Interpolator:\n  def __init__(self, align: int = 64) -> None:\n    self._model = hub.load(\"https://tfhub.dev/google/film/1\")\n    self._align = align\n\n  def __call__(self, x0: np.ndarray, x1: np.ndarray,\n               dt: np.ndarray) -> np.ndarray:\n    if self._align is not None:\n      x0, bbox_to_crop = _pad_to_align(x0, self._align)\n      x1, _ = _pad_to_align(x1, self._align)\n\n    inputs = {'x0': x0, 'x1': x1, 'time': dt[..., np.newaxis]}\n    result = self._model(inputs, training=False)\n    image = result['image']\n\n    if self._align is not None:\n      image = tf.image.crop_to_bounding_box(image, **bbox_to_crop)\n    return image.numpy()\n```\n\n----------------------------------------\n\nTITLE: Analyzing On-Disk Model Sizes with ZIP Compression in TensorFlow\nDESCRIPTION: This code saves the models to disk, applies ZIP compression, and compares the resulting file sizes. It shows that EPR compression provides benefits even after applying additional lossless compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport shutil\n\ndef get_disk_size(model, path):\n  model.save(path)\n  zip_path = shutil.make_archive(path, \"zip\", path)\n  return os.path.getsize(zip_path)\n\noriginal_zip_size = get_disk_size(classifier, \"/tmp/classifier\")\ncompressed_zip_size = get_disk_size(\n    compressed_classifier, \"/tmp/compressed_classifier\")\n\nprint(f\"Original on-disk size (ZIP compressed): {original_zip_size} bytes\")\nprint(f\"Compressed on-disk size (ZIP compressed): {compressed_zip_size} bytes\")\nprint(f\"Compression ratio: {(original_zip_size/compressed_zip_size):0.0f}x\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Audio Sample\nDESCRIPTION: Downloads and processes a sample bird audio file for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!curl -O  \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Turdus_merula_2.ogg\"\n\nturdus_merula = \"Turdus_merula_2.ogg\"\naudio, sample_rate = librosa.load(turdus_merula)\nsample_rate, wav_data_turdus = ensure_sample_rate(audio, sample_rate)\nAudio(wav_data_turdus, rate=sample_rate)\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset for CVAE Training\nDESCRIPTION: Loads the MNIST digit dataset using TensorFlow's built-in datasets module. The dataset consists of 28x28 pixel grayscale images of handwritten digits.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n```\n\n----------------------------------------\n\nTITLE: Applying Random Transformations to Images in TensorFlow Python\nDESCRIPTION: Illustrates the use of tf.image.stateless_random* functions for applying random transformations to images. These are useful for data augmentation in machine learning pipelines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntf.image.stateless_random*\n```\n\n----------------------------------------\n\nTITLE: Parsing Protocol Buffer Messages in TensorFlow\nDESCRIPTION: Defines a function to parse tf.train.Example protocol buffer messages from a TFRecord file. The parsed features are transformed into tensors representing an image and its label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\ndef _parse_function(example_proto):\n  features = {\"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n              \"label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n  parsed_features = tf.parse_single_example(example_proto, features)\n  return parsed_features[\"image\"], parsed_features[\"label\"]\n\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(_parse_function)\n```\n\n----------------------------------------\n\nTITLE: Broadcasting 2D tensor with 2D RaggedTensor in TensorFlow\nDESCRIPTION: Shows how to add a 2D tensor with shape 3x1 to a 2D ragged tensor with 3 rows, where the tensor value is broadcast across each row of the ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# x         (2d ragged):  3 x (num_rows)\n# y         (2d tensor):  3 x          1\n# Result    (2d ragged):  3 x (num_rows)\nx = tf.ragged.constant(\n   [[10, 87, 12],\n    [19, 53],\n    [12, 32]])\ny = [[1000], [2000], [3000]]\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Predicting Image Class with Pre-trained Model\nDESCRIPTION: This snippet demonstrates how to use the pre-trained classifier to predict the class of a single image. It loads an image of Grace Hopper, preprocesses it, and runs it through the model to get a prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ngrace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\ngrace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\ngrace_hopper = np.array(grace_hopper)/255.0\nresult = classifier.predict(grace_hopper[np.newaxis, ...])\npredicted_class = tf.math.argmax(result[0], axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Generating Streaming Test Audio Data - Bash\nDESCRIPTION: Command to generate a 10-minute WAV file with test words spoken every three seconds, along with ground truth labels for testing streaming accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nbazel run tensorflow/examples/speech_commands:generate_streaming_test_wav\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for TensorFlow Style Transfer\nDESCRIPTION: Imports necessary libraries including TensorFlow, TensorFlow Hub, and visualization packages. Prints version information and checks GPU availability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport functools\nimport os\n\nfrom matplotlib import gridspec\nimport matplotlib.pylab as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nprint(\"TF Version: \", tf.__version__)\nprint(\"TF Hub version: \", hub.__version__)\nprint(\"Eager mode enabled: \", tf.executing_eagerly())\nprint(\"GPU available: \", tf.config.list_physical_devices('GPU'))\n```\n\n----------------------------------------\n\nTITLE: Implementing Nested Control Flow with AutoGraph\nDESCRIPTION: Demonstrates nested conditionals in a function that finds the nearest odd square of a number, showing how AutoGraph handles complex control flow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=tf.autograph.experimental.Feature.EQUALITY_OPERATORS)\ndef nearest_odd_square(x):\n  if x > 0:\n    x = x * x\n    if x % 2 == 0:\n      x = x + 1\n  return x\n\nwith tf.Graph().as_default():\n  with tf.Session() as sess:\n    print(sess.run(nearest_odd_square(tf.constant(4))))\n    print(sess.run(nearest_odd_square(tf.constant(5))))\n    print(sess.run(nearest_odd_square(tf.constant(6))))\n```\n\n----------------------------------------\n\nTITLE: Loading TF Hub Models in Colab with TPU via Local Redirection\nDESCRIPTION: Loads a TensorFlow Hub model with special options to redirect reads through the Colab host when using TPU. This workaround allows TPU workers to access model data even when they don't have direct access to the cached files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/caching.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nload_options =\ntf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\nreloaded_model = hub.load(\"https://tfhub.dev/...\", options=load_options)\n```\n\n----------------------------------------\n\nTITLE: Compiling Custom Op Using System Compiler in Bash\nDESCRIPTION: This snippet provides bash commands to compile the custom operation using the system compiler for a TensorFlow binary installation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\nTF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\ng++ -std=c++14 -shared zero_out.cc -o zero_out.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2\n```\n\n----------------------------------------\n\nTITLE: Building ResNet Model Architecture\nDESCRIPTION: Constructs the complete (2+1)D ResNet model using Keras functional API with multiple residual blocks and downsampling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ninput_shape = (None, 10, HEIGHT, WIDTH, 3)\ninput = layers.Input(shape=(input_shape[1:]))\nx = input\n\nx = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.ReLU()(x)\nx = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n\n# Block 1\nx = add_residual_block(x, 16, (3, 3, 3))\nx = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n\n# Block 2\nx = add_residual_block(x, 32, (3, 3, 3))\nx = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n\n# Block 3\nx = add_residual_block(x, 64, (3, 3, 3))\nx = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n\n# Block 4\nx = add_residual_block(x, 128, (3, 3, 3))\n\nx = layers.GlobalAveragePooling3D()(x)\nx = layers.Flatten()(x)\nx = layers.Dense(10)(x)\n\nmodel = keras.Model(input, x)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for BERT Model Usage\nDESCRIPTION: Imports necessary libraries including seaborn for visualization, sklearn for metrics, TensorFlow, TensorFlow Hub, and TensorFlow Text for preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport seaborn as sns\nfrom sklearn.metrics import pairwise\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text  # Imports TF ops for preprocessing.\n```\n\n----------------------------------------\n\nTITLE: Testing the Input Function with Dataset Visualization\nDESCRIPTION: Tests the input function by taking one batch from the dataset and printing the features and labels to verify the data structure before training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfor features_batch, labels_batch in input_fn().take(1):\n  print(features_batch)\n  print(labels_batch)\n```\n\n----------------------------------------\n\nTITLE: Setting Bazel Build Option to Avoid Package Creation Issues\nDESCRIPTION: Special Bazel build option flag to avoid issues with package creation as referenced in tensorflow issue #22390.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n--define=no_tensorflow_py_deps=true\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Creation and Management for Multi-Worker Training\nDESCRIPTION: This snippet creates a tf.train.Checkpoint to track the model and training progress variables. It also sets up a tf.train.CheckpointManager to manage checkpoint saving and retention in a distributed environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nepoch = tf.Variable(\n    initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\nstep_in_epoch = tf.Variable(\n    initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n    name='step_in_epoch')\ntask_type, task_id = (strategy.cluster_resolver.task_type,\n                      strategy.cluster_resolver.task_id)\n# Normally, you don't need to manually instantiate a `ClusterSpec`, but in this\n# illustrative example you did not set `'TF_CONFIG'` before initializing the\n# strategy. Check out the next section for \"real-world\" usage.\ncluster_spec = tf.train.ClusterSpec(tf_config['cluster'])\n\ncheckpoint = tf.train.Checkpoint(\n    model=multi_worker_model, epoch=epoch, step_in_epoch=step_in_epoch)\n\nwrite_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id,\n                                      cluster_spec)\ncheckpoint_manager = tf.train.CheckpointManager(\n    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)\n```\n\n----------------------------------------\n\nTITLE: Assertion Tests for Nearly Fully Native Model\nDESCRIPTION: Verifies that the nearly fully native model's outputs and regularization losses match the original model's behavior, confirming that the further migration steps haven't altered model functionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Verify that the regularization loss and output both match\nnp.testing.assert_allclose(original_regularization_loss.numpy(), migrated_regularization_loss.numpy())\nnp.testing.assert_allclose(original_output.numpy(), migrated_output.numpy())\n```\n\n----------------------------------------\n\nTITLE: Basic TensorFlow Operations with Eager Execution\nDESCRIPTION: Demonstrates basic tensor operations using eager execution. It shows matrix multiplication, addition, and interaction with NumPy arrays.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nx = [[2.]]\nm = tf.matmul(x, x)\nprint(\"hello, {}\".format(m))\n\na = tf.constant([[1, 2],\n                 [3, 4]])\nprint(a)\n\n# Broadcasting support\nb = tf.add(a, 1)\nprint(b)\n\n# Operator overloading is supported\nprint(a * b)\n\n# Use NumPy values\nimport numpy as np\n\nc = np.multiply(a, b)\nprint(c)\n\n# Obtain numpy value from a tensor:\nprint(a.numpy())\n# => [[1 2]\n#     [3 4]]\n```\n\n----------------------------------------\n\nTITLE: MaskedTensor Example Implementation\nDESCRIPTION: Example showing MaskedTensor extension type implementation with a replace_mask method\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  def replace_mask(self, new_mask):\n      self.values.shape.assert_is_compatible_with(new_mask.shape)\n      return MaskedTensor(self.values, new_mask)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Checking GPU Availability\nDESCRIPTION: This snippet imports TensorFlow and prints the number of available GPUs using tf.config.list_physical_devices('GPU').\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard from Command Line\nDESCRIPTION: Command to start TensorBoard by specifying the log directory path where model data is stored. The server will start and be accessible at http://localhost:6006.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n# Replace PATH with the actual path passed as model_dir\ntensorboard --logdir=PATH\n```\n\n----------------------------------------\n\nTITLE: Training SNGP Model in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create, compile, and fit the SNGP model using Keras API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nsngp_model = DeepResNetSNGPWithCovReset(**resnet_config)\nsngp_model.compile(**train_config)\nsngp_model.fit(train_examples, train_labels, **fit_config)\n```\n\n----------------------------------------\n\nTITLE: Building Custom Layers in TensorFlow with Eager Execution\nDESCRIPTION: Defines a custom layer by subclassing tf.keras.layers.Layer. This example shows how to create trainable variables and define the forward pass in a custom layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MySimpleLayer(tf.keras.layers.Layer):\n  def __init__(self, output_units):\n    super(MySimpleLayer, self).__init__()\n    self.output_units = output_units\n\n  def build(self, input_shape):\n    # The build method gets called the first time your layer is used.\n    # Creating variables on build() allows you to make their shape depend\n    # on the input shape and hence removes the need for the user to specify\n    # full shapes. It is possible to create variables during __init__() if\n    # you already know their full shapes.\n    self.kernel = self.add_variable(\n      \"kernel\", [input_shape[-1], self.output_units])\n\n  def call(self, input):\n    # Override call() instead of __call__ so we can perform some bookkeeping.\n    return tf.matmul(input, self.kernel)\n```\n\n----------------------------------------\n\nTITLE: Implementing Shape Function with Specific Output Shape in C++\nDESCRIPTION: This snippet shows how to implement a shape function that sets a specific output shape (n, 3) based on the input shape (n, ...) in C++. It demonstrates using dimension manipulation functions from InferenceContext.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_53\n\nLANGUAGE: c++\nCODE:\n```\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    c->set_output(0, c->Matrix(c->Dim(c->input(0), 0), 3));\n    return Status::OK();\n});\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow with GPU Support in Docker\nDESCRIPTION: Example of running a TensorFlow operation using GPU support in a Docker container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu \\\n   python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Distribution Strategy with Generators\nDESCRIPTION: Example of using random number generators with TensorFlow distribution strategies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ng = tf.random.Generator.from_seed(1)\nstrat = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat.scope():\n  def f():\n    print(g.normal([]))\n  results = strat.run(f)\n```\n\n----------------------------------------\n\nTITLE: Generating and Displaying Adversarial Examples with Different Epsilon Values\nDESCRIPTION: Creates adversarial examples using different epsilon values (perturbation strengths) and displays them with their predictions to show how increasing epsilon affects misclassification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nepsilons = [0, 0.01, 0.1, 0.15]\ndescriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n                for eps in epsilons]\n\nfor i, eps in enumerate(epsilons):\n  adv_x = image + eps*perturbations\n  adv_x = tf.clip_by_value(adv_x, -1, 1)\n  display_images(adv_x, descriptions[i])\n```\n\n----------------------------------------\n\nTITLE: Tracing TensorFlow Model Execution for TensorBoard Visualization\nDESCRIPTION: Sets up logging, creates a new model instance, and traces its execution for visualization in TensorBoard.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nstamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = \"logs/func/%s\" % stamp\nwriter = tf.summary.create_file_writer(logdir)\n\nnew_model = MySequentialModule()\n\ntf.summary.trace_on(graph=True)\ntf.profiler.experimental.start(logdir)\nz = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\nwith writer.as_default():\n  tf.summary.trace_export(\n      name=\"my_func_trace\",\n      step=0,\n      profiler_outdir=logdir)\n```\n\n----------------------------------------\n\nTITLE: Creating a Mapping Function Decorator for TensorFlow Eager Execution\nDESCRIPTION: Implements a decorator for mapping functions that wraps them in a tf.py_function to enable execution in eager mode, preventing auto-graph compilation. This is important for functions that need to perform timing measurements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef map_decorator(func):\n    def wrapper(steps, times, values):\n        # Use a tf.py_function to prevent auto-graph from compiling the method\n        return tf.py_function(\n            func,\n            inp=(steps, times, values),\n            Tout=(steps.dtype, times.dtype, values.dtype)\n        )\n    return wrapper\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequential Model\nDESCRIPTION: Demonstrates how to use tf.keras.Sequential to create a model by stacking layers in sequence for a cleaner implementation when layers are called one after another.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmy_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n                                                    input_shape=(\n                                                        None, None, 3)),\n                             tf.keras.layers.BatchNormalization(),\n                             tf.keras.layers.Conv2D(2, 1,\n                                                    padding='same'),\n                             tf.keras.layers.BatchNormalization(),\n                             tf.keras.layers.Conv2D(3, (1, 1)),\n                             tf.keras.layers.BatchNormalization()])\nmy_seq(tf.zeros([1, 2, 3, 3]))\n```\n\n----------------------------------------\n\nTITLE: Casting Model Outputs to Float32\nDESCRIPTION: Demonstrates how to cast model outputs to float32 using a linear activation layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\noutputs = layers.Activation('linear', dtype='float32')(outputs)\n```\n\n----------------------------------------\n\nTITLE: Creating CycleGAN Generator and Discriminator Models\nDESCRIPTION: Initializes the generator and discriminator models for the CycleGAN architecture using modified UNet generators with instance normalization. Two generators and two discriminators are created for the bidirectional translation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nOUTPUT_CHANNELS = 3\n\ngenerator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\ngenerator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n\ndiscriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\ndiscriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)\n```\n\n----------------------------------------\n\nTITLE: Performing Image Super Resolution with ESRGAN\nDESCRIPTION: Applies the ESRGAN model to the input image to generate a super-resolution version and measures the processing time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nstart = time.time()\nfake_image = model(hr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n```\n\n----------------------------------------\n\nTITLE: Preprocessing audio data by removing extra channel dimension\nDESCRIPTION: This code defines and applies a preprocessing function that removes the extra channel dimension from the audio data using tf.squeeze, as the dataset contains only single-channel audio.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef squeeze(audio, labels):\n  audio = tf.squeeze(audio, axis=-1)\n  return audio, labels\n\ntrain_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\nval_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for Speech Recognition Model Visualization\nDESCRIPTION: Command to start TensorBoard pointing to the training logs directory, allowing visualization of training metrics, confusion matrices, and other model performance data through a web interface.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntensorboard --logdir /tmp/retrain_logs\n```\n\n----------------------------------------\n\nTITLE: Comparing Shuffle-Repeat vs Repeat-Shuffle Patterns\nDESCRIPTION: Calculates and plots the mean item IDs for both shuffle-then-repeat and repeat-then-shuffle patterns to compare how they handle epoch boundaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_72\n\nLANGUAGE: python\nCODE:\n```\nrepeat_shuffle = [n.numpy().mean() for n, line_batch in shuffled]\n\nplt.plot(shuffle_repeat, label=\"shuffle().repeat()\")\nplt.plot(repeat_shuffle, label=\"repeat().shuffle()\")\nplt.ylabel(\"Mean item ID\")\nplt.legend()\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow Model with Class Weights in Python\nDESCRIPTION: This code snippet demonstrates how to train a TensorFlow model using class weights. It uses the previously calculated class weights to handle imbalanced datasets during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nweighted_model = make_model()\nweighted_model.load_weights(initial_weights)\n\nweighted_history = weighted_model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[early_stopping()],\n    validation_data=(val_features, val_labels),\n    # The class weights go here\n    class_weight=class_weight)\n```\n\n----------------------------------------\n\nTITLE: Creating Categorical Feature Column with Vocabulary List in TensorFlow\nDESCRIPTION: Creates a categorical feature column by mapping input to elements in a predefined vocabulary list. Used for small vocabulary sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(\n    key=feature_name_from_input_fn,\n    vocabulary_list=[\"kitchenware\", \"electronics\", \"sports\"])\n```\n\n----------------------------------------\n\nTITLE: Defining Mean Squared Error Function with tf.function in Python\nDESCRIPTION: Shows how to define a Mean Squared Error function using tf.function decorator, and demonstrates the difference between graph and eager execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef get_MSE(y_true, y_pred):\n  sq_diff = tf.pow(y_true - y_pred, 2)\n  return tf.reduce_mean(sq_diff)\n\ny_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\ny_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\nprint(y_true)\nprint(y_pred)\n\nget_MSE(y_true, y_pred)\n\ntf.config.run_functions_eagerly(True)\n\nget_MSE(y_true, y_pred)\n\n# Don't forget to set it back when you are done.\ntf.config.run_functions_eagerly(False)\n```\n\n----------------------------------------\n\nTITLE: Creating Test Step Function for Mixed Precision Model Evaluation\nDESCRIPTION: Defines a test step function that generates predictions from the model for evaluation purposes. The function is decorated with tf.function for improved performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef test_step(x):\n  return model(x, training=False)\n```\n\n----------------------------------------\n\nTITLE: Call to tf.function with Different TypeSpec in Python\nDESCRIPTION: Demonstrates that a tf.function is retraced when called with an ExtensionType that has a different TypeSpec.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Function gets traced (new TypeSpec: keys for attributes changed):\nanonymize_player(Player(\"Chuck\", {\"height\": 11.0, \"jump\": 5.3}))\n```\n\n----------------------------------------\n\nTITLE: Debugging TensorFlow Estimators\nDESCRIPTION: Demonstrates how to debug TensorFlow Estimator methods using LocalCLIDebugHook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python import debug as tf_debug\n\n# Create a LocalCLIDebugHook and use it as a monitor when calling fit().\nhooks = [tf_debug.LocalCLIDebugHook()]\n\n# To debug `train`:\nclassifier.train(input_fn,\n                 steps=1000,\n                 hooks=hooks)\n```\n\n----------------------------------------\n\nTITLE: Compiling and Training a TensorFlow Model in Python\nDESCRIPTION: This code snippet compiles the model with Adam optimizer and Sparse Categorical Crossentropy loss, then trains it on the training dataset for a specified number of epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nepochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub Model and Warmup in Python\nDESCRIPTION: This snippet loads the selected model from TensorFlow Hub and performs a warmup inference with random input to optimize subsequent calls.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclassifier = hub.load(model_handle)\n\ninput_shape = image.shape\nwarmup_input = tf.random.uniform(input_shape, 0, 1.0)\n%time warmup_logits = classifier(warmup_input).numpy()\n```\n\n----------------------------------------\n\nTITLE: Reshaping Tensors in TensorFlow\nDESCRIPTION: Demonstrates various ways to reshape tensors while maintaining the total number of elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nrank_three_tensor = tf.ones([3, 4, 5])\nmatrix = tf.reshape(rank_three_tensor, [6, 10])\nmatrixB = tf.reshape(matrix, [3, -1])\nmatrixAlt = tf.reshape(matrixB, [4, 3, -1])\nyet_another = tf.reshape(matrixAlt, [13, 2, -1])  # ERROR!\n```\n\n----------------------------------------\n\nTITLE: Implementing Class Function for Rejection Resampling in TensorFlow\nDESCRIPTION: Defines a class function that extracts labels from feature-label pairs for use with tf.data.Dataset.rejection_resample()\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_78\n\nLANGUAGE: python\nCODE:\n```\ndef class_func(features, label):\n  return label\n```\n\n----------------------------------------\n\nTITLE: Defining Hypermodel for Image Classification\nDESCRIPTION: Creates a model builder function that defines the architecture and hyperparameters to be tuned for the image classification task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef model_builder(hp):\n  model = keras.Sequential()\n  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n\n  # Tune the number of units in the first Dense layer\n  # Choose an optimal value between 32-512\n  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n  model.add(keras.layers.Dense(10))\n\n  # Tune the learning rate for the optimizer\n  # Choose an optimal value from 0.01, 0.001, or 0.0001\n  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n\n  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n\n  return model\n```\n\n----------------------------------------\n\nTITLE: Running the Language Model Code\nDESCRIPTION: This snippet provides the shell commands necessary to run the language modeling script in TensorFlow after setting up the environment. It covers the process of navigating to the working directory and executing the training script with specified parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd models/tutorials/rnn/ptb\npython ptb_word_lm.py --data_path=$HOME/simple-examples/data/ --model=small\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for YAMNet Sound Classification in Python\nDESCRIPTION: This snippet imports necessary libraries for audio processing, machine learning, and visualization using TensorFlow, TensorFlow Hub, NumPy, and Matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport csv\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nfrom scipy.io import wavfile\n```\n\n----------------------------------------\n\nTITLE: Calculating Character Lengths\nDESCRIPTION: This snippet illustrates how to determine the byte and character length of a UTF-8 encoded string using TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Note that the final character takes up 4 bytes in UTF8.\nthanks = u'Thanks 😊'.encode('UTF-8')\nnum_bytes = tf.strings.length(thanks).numpy()\nnum_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\nprint('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))\n```\n\n----------------------------------------\n\nTITLE: Implementing Timelined Benchmark for TensorFlow Datasets\nDESCRIPTION: Creates a function that iterates through a time-measured dataset for a specified number of epochs, accumulating timing information for dataset operations and simulated training steps. Returns a dictionary of timing metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef timelined_benchmark(dataset, num_epochs=2):\n    # Initialize accumulators\n    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n    \n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        epoch_enter = time.perf_counter()\n        for (steps, times, values) in dataset:\n            # Record dataset preparation informations\n            steps_acc = tf.concat((steps_acc, steps), axis=0)\n            times_acc = tf.concat((times_acc, times), axis=0)\n            values_acc = tf.concat((values_acc, values), axis=0)\n            \n            # Simulate training time\n            train_enter = time.perf_counter()\n            time.sleep(0.01)\n            train_elapsed = time.perf_counter() - train_enter\n            \n            # Record training informations\n            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n        \n        epoch_elapsed = time.perf_counter() - epoch_enter\n        # Record epoch informations\n        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n        time.sleep(0.001)\n    \n    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}\n```\n\n----------------------------------------\n\nTITLE: Converting variable-length tensors to RaggedTensors in tf.data\nDESCRIPTION: Shows how to use dense_to_ragged_batch transformation to convert variable-length dense tensors into RaggedTensors when batching in a tf.data pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nnon_ragged_dataset = tf.data.Dataset.from_tensor_slices([1, 5, 3, 2, 8])\nnon_ragged_dataset = non_ragged_dataset.map(tf.range)\nbatched_non_ragged_dataset = non_ragged_dataset.apply(\n    tf.data.experimental.dense_to_ragged_batch(2))\nfor element in batched_non_ragged_dataset:\n  print(element)\n```\n\n----------------------------------------\n\nTITLE: Transforming Sparse Tensors with Dataset.map in TensorFlow\nDESCRIPTION: This snippet demonstrates how to transform sparse tensors in a dataset using the Dataset.map method. It applies a multiplication operation to each element in the dataset and prints the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntransform_dataset = dataset.map(lambda x: x*2)\nfor i in transform_dataset:\n  print(pprint_sparse_tensor(i))\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained MobileNet Image Classifier\nDESCRIPTION: Download a pre-trained MobileNet image classification model from TensorFlow Hub and configure it as a Keras sequential model for image prediction\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclassifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\"\n\nIMAGE_SHAPE = (224, 224)\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n])\n```\n\n----------------------------------------\n\nTITLE: Exporting TensorFlow Audio Classification Model with Preprocessing\nDESCRIPTION: This code defines an ExportModel class that wraps a TensorFlow audio classification model and includes preprocessing steps. It accepts either a filename or waveform data, applies preprocessing, and returns predictions with class IDs and names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass ExportModel(tf.Module):\n  def __init__(self, model):\n    self.model = model\n\n    # Accept either a string-filename or a batch of waveforms.\n    # You could add additional signatures for a single wave, or a ragged-batch. \n    self.__call__.get_concrete_function(\n        x=tf.TensorSpec(shape=(), dtype=tf.string))\n    self.__call__.get_concrete_function(\n       x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n\n\n  @tf.function\n  def __call__(self, x):\n    # If they pass a string, load the file and decode it. \n    if x.dtype == tf.string:\n      x = tf.io.read_file(x)\n      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n      x = tf.squeeze(x, axis=-1)\n      x = x[tf.newaxis, :]\n    \n    x = get_spectrogram(x)  \n    result = self.model(x, training=False)\n    \n    class_ids = tf.argmax(result, axis=-1)\n    class_names = tf.gather(label_names, class_ids)\n    return {'predictions':result,\n            'class_ids': class_ids,\n            'class_names': class_names}\n```\n\n----------------------------------------\n\nTITLE: Training a Simple Linear Model - TensorFlow Python\nDESCRIPTION: This code snippet constructs and trains a linear model using TensorFlow's Estimators API. It creates a LinearClassifier with 784-dimensional input features derived from the MNIST dataset, fits the model on training data, and evaluates its performance on validation data, reporting metrics such as accuracy and loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\n# Specify the feature(s) to be used by the estimator.\nimage_column = tf.contrib.layers.real_valued_column('images', dimension=784)\nestimator = tf.contrib.learn.LinearClassifier(feature_columns=[image_column], n_classes=10)\n\n# Train.\nstart = time.time()\nestimator.fit(input_fn=train_input_fn, steps=2000)\nend = time.time()\nprint('Elapsed time: {} seconds'.format(end - start))\n\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics)\n```\n\n----------------------------------------\n\nTITLE: Separating Features and Labels from CSV Data for TensorFlow Model Training\nDESCRIPTION: This snippet shows how to separate features and labels from a pandas DataFrame, preparing the data for training a TensorFlow model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nabalone_features = abalone_train.copy()\nabalone_labels = abalone_features.pop('Age')\n\nabalone_features = np.array(abalone_features)\nabalone_features\n```\n\n----------------------------------------\n\nTITLE: Defining a Tiny Neural Network Model with TensorFlow\nDESCRIPTION: Creates a small sequential neural network with one hidden layer of 16 units using the ELU activation function. This serves as a baseline model for comparison with larger architectures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntiny_model = tf.keras.Sequential([\n    layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n    layers.Dense(1)\n])\n```\n\n----------------------------------------\n\nTITLE: Preparing Feature Columns in TensorFlow\nDESCRIPTION: Demonstrates using TensorFlow's feature columns for input preprocessing. It uses both numeric and categorical columns, the latter transformed via `indicator_column` for dense representation. Outputs the constructed input layer ready for computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\nfeatures = {\n    'sales' : [[5], [10], [8], [9]],\n    'department': ['sports', 'sports', 'gardening', 'gardening']}\n\ndepartment_column = tf.feature_column.categorical_column_with_vocabulary_list(\n        'department', ['sports', 'gardening'])\ndepartment_column = tf.feature_column.indicator_column(department_column)\n\ncolumns = [\n    tf.feature_column.numeric_column('sales'),\n    department_column\n]\n\ninputs = tf.feature_column.input_layer(features, columns)\n```\n\n----------------------------------------\n\nTITLE: Accessing Keras Training History Keys\nDESCRIPTION: This code demonstrates how to access the keys in the history dictionary after training a Keras model, which contain the metrics that were tracked during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nhistory.history.keys()\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel CLI on Keras SavedModel\nDESCRIPTION: This command demonstrates how to use the saved_model_cli to run inference on a SavedModel saved with Keras in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n!saved_model_cli run --dir keras-model --tag_set serve \\\n --signature_def serving_default --input_exprs input=10\n```\n\n----------------------------------------\n\nTITLE: Plotting LSTM Model Predictions\nDESCRIPTION: Visualizes the LSTM model's predictions using the wide window generator, showing how the recurrent architecture captures temporal patterns in the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_46\n\nLANGUAGE: python\nCODE:\n```\nwide_window.plot(lstm_model)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Epoch-based File Shuffling\nDESCRIPTION: Shows how the list_files dataset automatically shuffles filenames between epochs. This is useful for training models to prevent order-based biases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nprint('Epoch 1:')\nfor f in list(font_files)[:5]:\n  print(\"    \", f.numpy())\nprint('    ...')\nprint()\n\nprint('Epoch 2:')\nfor f in list(font_files)[:5]:\n  print(\"    \", f.numpy())\nprint('    ...')\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Fashion MNIST Dataset\nDESCRIPTION: Loads the Fashion MNIST dataset, reshapes the images to include a channel dimension, normalizes pixel values to the [0,1] range, and converts labels to int64 type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n# Adding a dimension to the array -> new shape == (28, 28, 1)\n# We are doing this because the first layer in our model is a convolutional\n# layer and it requires a 4D input (batch_size, height, width, channels).\n# batch_size dimension will be added later on.\ntrain_images = train_images[..., None]\ntest_images = test_images[..., None]\n\n# Getting the images in [0, 1] range.\ntrain_images = train_images / np.float32(255)\ntest_images = test_images / np.float32(255)\n\ntrain_labels = train_labels.astype('int64')\ntest_labels = test_labels.astype('int64')\n```\n\n----------------------------------------\n\nTITLE: Preprocessing MNIST Data for Neural Network Training\nDESCRIPTION: Defines a preprocessing function that reshapes the 2D images to 1D vectors and rescales pixel values from [0,255] to [0,1]. Applies this preprocessing to training and validation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess(x, y):\n  # Reshaping the data\n  x = tf.reshape(x, shape=[-1, 784])\n  # Rescaling the data\n  x = x/255\n  return x, y\n\ntrain_data, val_data = train_data.map(preprocess), val_data.map(preprocess)\n```\n\n----------------------------------------\n\nTITLE: Defining a Complete Model with Preprocessing\nDESCRIPTION: Creates a function to build a complete model that combines the preprocessing head with a neural network body, then compiles it with appropriate loss and optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef titanic_model(preprocessing_head, inputs):\n  body = tf.keras.Sequential([\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  preprocessed_inputs = preprocessing_head(inputs)\n  result = body(preprocessed_inputs)\n  model = tf.keras.Model(inputs, result)\n\n  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                optimizer=tf.keras.optimizers.Adam())\n  return model\n\ntitanic_model = titanic_model(titanic_preprocessing, inputs)\n```\n\n----------------------------------------\n\nTITLE: Checking Input/Output Shapes of Multi-Step Dense Model\nDESCRIPTION: Verifies the input and output shapes of the multi-step dense model to ensure compatibility with the window generator's data format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', conv_window.example[0].shape)\nprint('Output shape:', multi_step_dense(conv_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Compiling a Binary Classification Model in TensorFlow with Adam Optimizer\nDESCRIPTION: Configures a TensorFlow model for binary classification using the Adam optimizer and binary cross-entropy loss function. This setup is appropriate for binary classification problems where the model outputs logits.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Checking Uninitialized Variables\nDESCRIPTION: Reports which variables have not been initialized in the session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(session.run(tf.report_uninitialized_variables()))\n```\n\n----------------------------------------\n\nTITLE: Handling Errors when Indexing Ragged Dimensions\nDESCRIPTION: Demonstrates the error that occurs when attempting to index a ragged dimension in a DynamicRaggedShape, since ragged dimensions don't have a single size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  rt_shape[1]\nexcept ValueError as e:\n  print(\"Got expected ValueError:\", e)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Tracing Behavior in tf.function in Python\nDESCRIPTION: Shows how to identify when a tf.function is tracing by adding a print statement to its code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef a_function_with_python_side_effect(x):\n  print(\"Tracing!\") # An eager-only side effect.\n  return x * x + tf.constant(2)\n\n# This is traced the first time.\nprint(a_function_with_python_side_effect(tf.constant(2)))\n# The second time through, you won't see the side effect.\nprint(a_function_with_python_side_effect(tf.constant(3)))\n\n# This retraces each time the Python argument changes,\n# as a Python argument could be an epoch count or other\n```\n\n----------------------------------------\n\nTITLE: Saving DTensor Model with SavedModel in Python\nDESCRIPTION: This snippet demonstrates how to save a DTensor model using SavedModel. It creates a simple mesh, sets up the model, and defines a function signature for saving.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"world\", 1)], devices=DEVICES[:1])\nmlp = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh), \n           dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)])\n\nmanager = start_checkpoint_manager(mlp)\n\nmodel_for_saving = tf.keras.Sequential([\n  text_vectorization,\n  mlp\n])\n\n@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\ndef run(inputs):\n  return {'result': model_for_saving(inputs)}\n\ntf.saved_model.save(\n    model_for_saving, \"/tmp/saved_model\",\n    signatures=run)\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Pastry ExtensionType with tf.function\nDESCRIPTION: Example of creating a Pastry ExtensionType and using it with tf.function decorator for improved performance\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nclass Pastry(tf.experimental.ExtensionType):\n  sweetness: tf.Tensor  # 2d embedding that encodes sweetness\n  chewiness: tf.Tensor  # 2d embedding that encodes chewiness\n\n@tf.function\ndef combine_pastry_features(x: Pastry):\n  return (x.sweetness + x.chewiness) / 2\n\ncookie = Pastry(sweetness=[1.2, 0.4], chewiness=[0.8, 0.2])\ncombine_pastry_features(cookie)\n```\n\n----------------------------------------\n\nTITLE: Creating Input Function for TensorFlow Datasets in Python\nDESCRIPTION: This function creates an input pipeline using TensorFlow Datasets. It loads the cats vs dogs dataset, applies preprocessing, shuffles, and batches the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef train_input_fn(batch_size):\n  data = tfds.load('cats_vs_dogs', as_supervised=True)\n  train_data = data['train']\n  train_data = train_data.map(preprocess).shuffle(500).batch(batch_size)\n  return train_data\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Dependencies in Python\nDESCRIPTION: This snippet imports TensorFlow and other necessary dependencies for the guide.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as v1\nimport sys\nimport numpy as np\n\nfrom contextlib import contextmanager\n```\n\n----------------------------------------\n\nTITLE: Killing Background Scripts in Jupyter Notebook\nDESCRIPTION: This Jupyter magic command terminates any previously running background scripts to ensure a clean environment before launching new worker processes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# first kill any previous runs\n%killbgscripts\n```\n\n----------------------------------------\n\nTITLE: Running pylint on TensorFlow Python Files\nDESCRIPTION: Command to check a specific Python file against the TensorFlow pylint rules using a custom pylintrc file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pylint --rcfile=tensorflow/tools/ci_build/pylintrc tensorflow/python/keras/losses.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Direct Remote Model Loading in Shell\nDESCRIPTION: Sets an environment variable to instruct TensorFlow Hub to read models directly from remote storage instead of downloading them locally. This is useful in environments with limited disk space but good internet connectivity.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/caching.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nos.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\"\n```\n\n----------------------------------------\n\nTITLE: Training Distributed Keras Model with Dataset\nDESCRIPTION: This code shows how to train a distributed Keras model using a tf.data.Dataset and the fit method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(10)\nmodel.fit(dataset, epochs=2)\nmodel.evaluate(dataset)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Dependencies\nDESCRIPTION: Imports required libraries including TensorFlow, Keras, NumPy and Matplotlib for building and visualizing the neural network.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# TensorFlow and tf.keras\nimport tensorflow.compat.v1 as tf\nfrom tensorflow import keras\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Exporting and Loading a TensorFlow Model\nDESCRIPTION: Demonstrates how to export a trained TensorFlow model and load it back for inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nbinary_model.export('bin.tf')\n\nloaded = tf.saved_model.load('bin.tf')\n\nbinary_model.predict(['How do you sort a list?'])\n\nloaded.serve(tf.constant(['How do you sort a list?'])).numpy()\n```\n\n----------------------------------------\n\nTITLE: Interoperability Between TensorFlow Tensor and ND Array\nDESCRIPTION: Shows the seamless interoperability between tf.Tensor and TensorFlow NumPy arrays, demonstrating that ND array is an alias to tf.Tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([1, 2])\nprint(x)\n\n# `asarray` and `convert_to_tensor` here are no-ops.\ntnp_x = tnp.asarray(x)\nprint(tnp_x)\nprint(tf.convert_to_tensor(tnp_x))\n\n# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\nprint(x.numpy(), x.numpy().__class__)\n```\n\n----------------------------------------\n\nTITLE: Correct TF1 Model Loading in TF2\nDESCRIPTION: Proper way to load and use TF1 Hub model in TF2 using signatures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_issues.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nembed = hub.load('https://tfhub.dev/google/nnlm-en-dim128/1')\nembed.signatures['default'](['my text', 'batch'])\n```\n\n----------------------------------------\n\nTITLE: Loading BigGAN Generator Module\nDESCRIPTION: Initializes the BigGAN generator from TensorFlow Hub and sets up input placeholders\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntf.reset_default_graph()\nprint('Loading BigGAN module from:', module_path)\nmodule = hub.Module(module_path)\ninputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n          for k, v in module.get_input_info_dict().items()}\noutput = module(inputs)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op Return Value Example\nDESCRIPTION: Shows how to document the return value of a TensorFlow operation using the recommended arrow syntax\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_style.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# 'input' is a tensor of shape [2, 3, 5]\ntf.expand_dims(input, 0)  # ⇒ [1, 2, 3, 5]\n```\n\n----------------------------------------\n\nTITLE: Generating TensorFlow 2 Reference Docs\nDESCRIPTION: This code block demonstrates the steps to generate TensorFlow 2 reference documentation using the generate2.py script.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/tensorflow/tensorflow tensorflow\ncd tensorflow/tensorflow/tools/docs\npip install tensorflow\npython generate2.py --output_dir=/tmp/out\n```\n\n----------------------------------------\n\nTITLE: Complete Keras Model Definition and Training\nDESCRIPTION: Demonstrates a complete workflow for defining a Keras Sequential model with regularization, compiling it with appropriate loss and metrics, and training it on a dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, 3, activation='relu',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n                           input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10)\n])\n\n# Model is the full model w/o custom layers\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(train_data, epochs=NUM_EPOCHS)\nloss, acc = model.evaluate(test_data)\n\nprint(\"Loss {}, Accuracy {}\".format(loss, acc))\n```\n\n----------------------------------------\n\nTITLE: Training Distributed Keras Estimator in Python\nDESCRIPTION: This snippet shows how to train the previously created Keras Estimator using the input function. It specifies the number of steps for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nkeras_estimator.train(input_fn=input_fn, steps=10)\n```\n\n----------------------------------------\n\nTITLE: Debugging Remote TensorFlow Sessions in Python\nDESCRIPTION: This code snippet shows how to configure a run options object with tfdbg's watch_graph method to dump intermediate tensors in a shared location for debugging. Dependencies include TensorFlow and tfdbg, and the debug data requires a shared storage location. Different directories should be specified for different Session.run() calls.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python import debug as tf_debug\n\nrun_options = tf.RunOptions()\ntf_debug.watch_graph(\n      run_options,\n      session.graph,\n      debug_urls=[\"file:///shared/storage/location/tfdbg_dumps_1\"])\nsession.run(fetches, feed_dict=feeds, options=run_options)\n```\n\n----------------------------------------\n\nTITLE: Loading Example Data\nDESCRIPTION: Loads and preprocesses test video data from the BAIR dataset\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# @title Load some example data (BAIR).\nbatch_size = 16\n\n# If unable to download the dataset automatically due to \"not enough disk space\", please download manually to Google Drive and\n# load using tf.data.TFRecordDataset.\nds = builder.as_dataset(split=\"test\")\ntest_videos = ds.batch(batch_size)\nfirst_batch = next(iter(test_videos))\ninput_frames = first_batch['image_aux1'][:, ::15]\ninput_frames = tf.cast(input_frames, tf.float32)\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Crop for Image Augmentation\nDESCRIPTION: Defines a function to randomly crop images to the specified height and width. This is part of the random jittering process used in image augmentation for CycleGAN training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef random_crop(image):\n  cropped_image = tf.image.random_crop(\n      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n\n  return cropped_image\n```\n\n----------------------------------------\n\nTITLE: Defining a Training Step for Distributed Training in Python\nDESCRIPTION: This code snippet defines a single training step using tf.GradientTape for computing gradients. It encapsulates the training logic within a function, which can then be executed in a distributed context using the MirroredStrategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef train_step(dist_inputs):\n  def step_fn(inputs):\n    features, labels = inputs\n    logits = model(features)\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n        logits=logits, labels=labels)\n    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\n    train_op = optimizer.minimize(loss)\n    with tf.control_dependencies([train_op]):\n      return tf.identity(loss)\n\n  per_replica_losses = mirrored_strategy.run(\n      step_fn, args=(dist_inputs,))\n  mean_loss = mirrored_strategy.reduce(\n      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n  return mean_loss\n```\n\n----------------------------------------\n\nTITLE: Batching Sparse Tensors with Dataset.batch in TensorFlow\nDESCRIPTION: This snippet demonstrates how to batch sparse tensors using the Dataset.batch method. It combines consecutive elements into a single element and prints the resulting batched sparse tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nbatched_dataset = dataset.batch(2)\nfor element in batched_dataset:\n  print (pprint_sparse_tensor(element))\n```\n\n----------------------------------------\n\nTITLE: Building Keras Model with Functional API\nDESCRIPTION: Demonstrates how to build a Keras model using the Functional API. The code defines the input layer, several dense layers with ReLU activation, and a final dense layer with softmax activation for predictions. The model is then instantiated with the input and output tensors, compiled with an optimizer, loss function, and metrics, and finally trained using the `fit` method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n```python\ninputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor\n\n# A layer instance is callable on a tensor, and returns a tensor.\nx = layers.Dense(64, activation='relu')(inputs)\nx = layers.Dense(64, activation='relu')(x)\npredictions = layers.Dense(10, activation='softmax')(x)\n```\n```\n\nLANGUAGE: python\nCODE:\n```\n```python\nmodel = tf.keras.Model(inputs=inputs, outputs=predictions)\n\n# The compile step specifies the training configuration.\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Trains for 5 epochs\nmodel.fit(data, labels, batch_size=32, epochs=5)\n```\n```\n\n----------------------------------------\n\nTITLE: Batching with Drop Remainder for Fixed Shape in TensorFlow\nDESCRIPTION: Shows how to use drop_remainder=True with the batch operation to ensure full shape propagation by dropping the last batch if it's not full.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_61\n\nLANGUAGE: python\nCODE:\n```\nbatched_dataset = dataset.batch(7, drop_remainder=True)\nbatched_dataset\n```\n\n----------------------------------------\n\nTITLE: One-hot Encoding with Feature Columns\nDESCRIPTION: Demonstrates one-hot encoding of integer inputs using feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncategorical_col = tf1.feature_column.categorical_column_with_identity(\n    'type', num_buckets=3)\nindicator_col = tf1.feature_column.indicator_column(categorical_col)\ncall_feature_columns(indicator_col, {'type': [0, 1, 2]})\n```\n\n----------------------------------------\n\nTITLE: Plotting Training Metrics in Python with TensorFlow\nDESCRIPTION: This function plots training and validation metrics (loss, precision-recall curve, precision, and recall) over epochs. It uses matplotlib to create subplots for each metric.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef plot_metrics(history):\n  metrics = ['loss', 'prc', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Feature Columns\nDESCRIPTION: Importing TensorFlow modules for feature column handling and main TensorFlow functionality\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v2.feature_column as fc\n\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Configuring Virtual CPUs for DTensor\nDESCRIPTION: Sets up 8 virtual CPUs for distributed training experiments using DTensor. This allows simulation of multiple devices even on a single physical CPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef configure_virtual_cpus(ncpu):\n  phy_devices = tf.config.list_physical_devices('CPU')\n  tf.config.set_logical_device_configuration(phy_devices[0], [\n        tf.config.LogicalDeviceConfiguration(),\n    ] * ncpu)\n\nconfigure_virtual_cpus(8)\n\nDEVICES = [f'CPU:{i}' for i in range(8)]\ndevices = tf.config.list_logical_devices('CPU')\ndevice_names = [d.name for d in devices]\ndevice_names\n```\n\n----------------------------------------\n\nTITLE: Creating MNIST Dataset and Model Definition Module\nDESCRIPTION: Writing a Python file with functions to prepare the MNIST dataset and define a CNN model. The file includes functions for dataset sharding and batch processing required for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%%writefile mnist.py\n\nimport os\nimport tensorflow as tf\nimport numpy as np\n\ndef mnist_dataset(batch_size):\n  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n  # The `x` arrays are in uint8 and have values in the range [0, 255].\n  # You need to convert them to float32 with values in the range [0, 1]\n  x_train = x_train / np.float32(255)\n  y_train = y_train.astype(np.int64)\n  train_dataset = tf.data.Dataset.from_tensor_slices(\n      (x_train, y_train)).shuffle(60000)\n  return train_dataset\n\ndef dataset_fn(global_batch_size, input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  dataset = mnist_dataset(batch_size)\n  dataset = dataset.shard(input_context.num_input_pipelines,\n                          input_context.input_pipeline_id)\n  dataset = dataset.batch(batch_size)\n  return dataset\n\ndef build_cnn_model():\n  regularizer = tf.keras.regularizers.L2(1e-5)\n  return tf.keras.Sequential([\n      tf.keras.Input(shape=(28, 28)),\n      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n      tf.keras.layers.Conv2D(32, 3,\n                             activation='relu',\n                             kernel_regularizer=regularizer),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(128,\n                            activation='relu',\n                            kernel_regularizer=regularizer),\n      tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n  ])\n```\n\n----------------------------------------\n\nTITLE: Casting Tensor Data Types in TensorFlow\nDESCRIPTION: Shows how to cast tensors from one data type to another using tf.cast.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfloat_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss in TensorFlow with Matplotlib\nDESCRIPTION: This code creates a plot comparing the training and validation loss over epochs using Matplotlib. It extracts the relevant data from the history dictionary and visualizes the learning progress of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Defining Fast Dataset and Benchmark Function in Python\nDESCRIPTION: Creates a simple dataset using tf.data.Dataset.range and defines a benchmark function to measure execution time. Also defines a simple increment function for mapping.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfast_dataset = tf.data.Dataset.range(10000)\n\ndef fast_benchmark(dataset, num_epochs=2):\n    start_time = time.perf_counter()\n    for _ in tf.data.Dataset.range(num_epochs):\n        for _ in dataset:\n            pass\n    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n    \ndef increment(x):\n    return x+1\n```\n\n----------------------------------------\n\nTITLE: Defining Model and Training Components in TensorFlow\nDESCRIPTION: Sets up a simple sequential model with dense layers, along with optimizer, loss function, and metrics for both training and validation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10)\n])\n\noptimizer = tf.keras.optimizers.Adam(0.005)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ntrain_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\ntrain_loss_metric = tf.keras.metrics.SparseCategoricalCrossentropy()\nval_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\nval_loss_metric = tf.keras.metrics.SparseCategoricalCrossentropy()\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Up Virtual Devices\nDESCRIPTION: Imports TensorFlow and sets up multiple virtual CPU devices for simulating distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport os\n\nprint(tf.__version__)\n\n# Simulate multiple CPUs with virtual devices\nN_VIRTUAL_DEVICES = 2\nphysical_devices = tf.config.list_physical_devices(\"CPU\")\ntf.config.set_logical_device_configuration(\n    physical_devices[0], [tf.config.LogicalDeviceConfiguration() for _ in range(N_VIRTUAL_DEVICES)])\n\nprint(\"Available devices:\")\nfor i, device in enumerate(tf.config.list_logical_devices()):\n  print(\"%d) %s\" % (i, device))\n```\n\n----------------------------------------\n\nTITLE: Measuring Performance Improvement with tf.function in Python\nDESCRIPTION: Demonstrates how to measure the performance difference between eager execution and graph execution using tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n\ndef power(x, y):\n  result = tf.eye(10, dtype=tf.dtypes.int32)\n  for _ in range(y):\n    result = tf.matmul(x, result)\n  return result\n\nprint(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")\n\npower_as_graph = tf.function(power)\nprint(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000), \"seconds\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Network ExtensionType\nDESCRIPTION: Initial implementation of a Network class extending ExtensionType to track work and bandwidth between nodes. This version is not batchable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nclass Network(tf.experimental.ExtensionType):  # This version is not batchable.\n  work: tf.Tensor       # work[n] = work left to do at node n\n  bandwidth: tf.Tensor  # bandwidth[n1, n2] = bandwidth from n1->n2\n\nnet1 = Network([5., 3, 8], [[0., 2, 0], [2, 0, 3], [0, 3, 0]])\nnet2 = Network([3., 4, 2], [[0., 2, 2], [2, 0, 2], [2, 2, 0]])\n```\n\n----------------------------------------\n\nTITLE: Making predictions with a TensorFlow model\nDESCRIPTION: Uses the trained model with softmax layer to generate predictions for all test images. Returns probability distributions across all classes for each image in the test set.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npredictions = probability_model.predict(test_images)\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Models Repository\nDESCRIPTION: This snippet clones the TensorFlow models repository, which contains the Object Detection API code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n!git clone --depth 1 https://github.com/tensorflow/models\n```\n\n----------------------------------------\n\nTITLE: Creating Image Data Generators for Training and Validation - Python\nDESCRIPTION: This snippet sets up ImageDataGenerator objects for the training and validation datasets to perform image rescaling and augmentation. It is a foundational step to prepare data for fitting the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimage_size = 160 # All images will be resized to 160x160\nbatch_size = 32\n\n# Rescale all images by 1./255 and apply image augmentation\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n                rescale=1./255)\n\nvalidation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n                train_dir,  # Source directory for the training images\n                target_size=(image_size, image_size),\n                batch_size=batch_size,\n                # Since we use binary_crossentropy loss, we need binary labels\n                class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n                validation_dir, # Source directory for the validation images\n                target_size=(image_size, image_size),\n                batch_size=batch_size,\n                class_mode='binary')\n```\n\n----------------------------------------\n\nTITLE: Building Dense Neural Network for Multi-Step Forecasting in TensorFlow\nDESCRIPTION: Implements a dense neural network model for multi-step time series forecasting. The model extracts the last time step from the input sequence, applies a dense layer with ReLU activation to increase model capacity, then projects to the output dimensions with a final dense layer and reshapes to the desired output format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_59\n\nLANGUAGE: python\nCODE:\n```\nmulti_dense_model = tf.keras.Sequential([\n    # Take the last time step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, dense_units]\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_dense_model, multi_window)\n\nIPython.display.clear_output()\nmulti_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val, return_dict=True)\nmulti_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0, return_dict=True)\nmulti_window.plot(multi_dense_model)\n```\n\n----------------------------------------\n\nTITLE: Making a prediction on a single image with TensorFlow\nDESCRIPTION: Uses the probability model to generate predictions for a single image. Returns probability distributions for each class, showing the model's confidence in its classification of this specific image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\npredictions_single = probability_model.predict(img)\n\nprint(predictions_single)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing CIFAR10 Dataset\nDESCRIPTION: Load CIFAR10 dataset and normalize pixel values between 0 and 1\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\n```\n\n----------------------------------------\n\nTITLE: Applying Gaussian Process Layer to Input in TensorFlow\nDESCRIPTION: This snippet demonstrates how to apply the GP layer to an input tensor, returning logits and covariance matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nembedding = tf.random.normal(shape=(batch_size, input_dim))\n\nlogits, covmat = gp_layer(embedding)\n```\n\n----------------------------------------\n\nTITLE: Creating Data Preprocessing Function for MNIST\nDESCRIPTION: Defines a scaling function to preprocess MNIST images by casting to float32 and normalizing pixel values to a 0-1 range.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = 10 # Use a much larger value for real code\nBATCH_SIZE = 64\nNUM_EPOCHS = 5\n\n\ndef scale(image, label):\n  image = tf.cast(image, tf.float32)\n  image /= 255\n\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Implementing Loss Plot Function\nDESCRIPTION: Defines a utility function to visualize training and validation loss over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef plot_loss(history):\n  plt.plot(history.history['loss'], label='loss')\n  plt.plot(history.history['val_loss'], label='val_loss')\n  plt.ylim([0, 10])\n  plt.xlabel('Epoch')\n  plt.ylabel('Error [MPG]')\n  plt.legend()\n  plt.grid(True)\n```\n\n----------------------------------------\n\nTITLE: Compiling Text Classification Model with Binary Cross-Entropy Loss in TensorFlow\nDESCRIPTION: Configuring the model with binary cross-entropy loss function, Adam optimizer, and binary accuracy metric for binary text classification. These settings are appropriate for a sentiment analysis task with positive/negative outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(loss=losses.BinaryCrossentropy(),\n              optimizer='adam',\n              metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])\n```\n\n----------------------------------------\n\nTITLE: Running MoveNet Inference on Cropped Image\nDESCRIPTION: Executes the MoveNet model inference on the cropped image region and updates the keypoint coordinates to the original image coordinate system. It handles the preprocessing and postprocessing of the model input and output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef run_inference(movenet, image, crop_region, crop_size):\n  \"\"\"Runs model inference on the cropped region.\n\n  The function runs the model inference on the cropped region and updates the\n  model output to the original image coordinate system.\n  \"\"\"\n  image_height, image_width, _ = image.shape\n  input_image = crop_and_resize(\n    tf.expand_dims(image, axis=0), crop_region, crop_size=crop_size)\n  # Run model inference.\n  keypoints_with_scores = movenet(input_image)\n  # Update the coordinates.\n  for idx in range(17):\n    keypoints_with_scores[0, 0, idx, 0] = (\n        crop_region['y_min'] * image_height +\n        crop_region['height'] * image_height *\n        keypoints_with_scores[0, 0, idx, 0]) / image_height\n    keypoints_with_scores[0, 0, idx, 1] = (\n        crop_region['x_min'] * image_width +\n        crop_region['width'] * image_width *\n        keypoints_with_scores[0, 0, idx, 1]) / image_width\n  return keypoints_with_scores\n```\n\n----------------------------------------\n\nTITLE: Loading Universal Sentence Encoder-Lite from TensorFlow Hub\nDESCRIPTION: Loads the Universal Sentence Encoder-Lite model from TensorFlow Hub and sets up the input placeholder for sparse tensor inputs required by the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodule = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\")\n```\n\nLANGUAGE: python\nCODE:\n```\ninput_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None])\nencodings = module(\n    inputs=dict(\n        values=input_placeholder.values,\n        indices=input_placeholder.indices,\n        dense_shape=input_placeholder.dense_shape))\n```\n\n----------------------------------------\n\nTITLE: Adding Prefetch Transformation for Pipelining in TensorFlow\nDESCRIPTION: This code snippet shows how to add the prefetch transformation to a TensorFlow dataset pipeline. This optimization helps to overlap data preprocessing with model execution, reducing idle time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/datasets.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndataset = dataset.batch(batch_size=FLAGS.batch_size)\ndataset = dataset.prefetch(buffer_size=FLAGS.prefetch_buffer_size)\nreturn dataset\n```\n\n----------------------------------------\n\nTITLE: Implementing CNN-based Multi-Step Time Series Forecasting in TensorFlow\nDESCRIPTION: Creates a convolutional neural network model for multi-step time series forecasting. The model uses the last CONV_WIDTH time steps from the input, applies a 1D convolution to capture temporal patterns, followed by a dense projection and reshaping to the desired output format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_60\n\nLANGUAGE: python\nCODE:\n```\nCONV_WIDTH = 3\nmulti_conv_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n    # Shape => [batch, 1, conv_units]\n    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n    # Shape => [batch, 1,  out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_conv_model, multi_window)\n\nIPython.display.clear_output()\n\nmulti_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val, return_dict=True)\nmulti_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0, return_dict=True)\nmulti_window.plot(multi_conv_model)\n```\n\n----------------------------------------\n\nTITLE: Initializing Dictionary for Regularization Experiment Histories\nDESCRIPTION: Creates a dictionary to store training histories for regularization experiments and initializes it with the tiny model history as a baseline for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nregularizer_histories = {}\nregularizer_histories['Tiny'] = size_histories['Tiny']\n```\n\n----------------------------------------\n\nTITLE: Examining TensorFlow 2.x Checkpoint object in Python\nDESCRIPTION: Creates a Checkpoint object and prints its structure to understand how variable paths are generated in TF2 checkpoints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(0.)\nb = tf.Variable(0.)\nc = tf.Variable(0.)\nroot = ckpt = tf.train.Checkpoint(variables=[a, b, c])\nprint(\"root type =\", type(root).__name__)\nprint(\"root.variables =\", root.variables)\nprint(\"root.variables[0] =\", root.variables[0])\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Repacking for Model Parallel Training with DTensor in Python\nDESCRIPTION: This function repacks the input batch for model parallel training. It applies appropriate layouts to the input tensors, sharding along the batch dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef repack_batch(x, y, mesh):\n  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n  return x, y\n```\n\n----------------------------------------\n\nTITLE: Running Mandelbrot Set Computation and Visualization in TensorFlow\nDESCRIPTION: This snippet executes the Mandelbrot set computation for 200 iterations and then displays the resulting fractal using the previously defined DisplayFractal function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/mandelbrot.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(200): step.run()\n\nDisplayFractal(ns.eval())\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Step Dense Model for Time Series in TensorFlow\nDESCRIPTION: Creates a sequential model that flattens multiple time steps, processes them through dense layers, and reshapes the output. The model can process multiple input time steps to produce a single prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nmulti_step_dense = tf.keras.Sequential([\n    # Shape: (time, features) => (time*features)\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=32, activation='relu'),\n    tf.keras.layers.Dense(units=32, activation='relu'),\n    tf.keras.layers.Dense(units=1),\n    # Add back the time dimension.\n    # Shape: (outputs) => (1, outputs)\n    tf.keras.layers.Reshape([1, -1]),\n])\n```\n\n----------------------------------------\n\nTITLE: Creating Training Utility Function for Time Series Models\nDESCRIPTION: Implements a compile_and_fit function that standardizes the model training process across multiple models, including early stopping to prevent overfitting and consistent metrics for performance comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nMAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=2):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n\n  history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n  return history\n```\n\n----------------------------------------\n\nTITLE: Custom Dense Layer Implementation\nDESCRIPTION: Demonstrates implementing a custom dense layer by extending tf.keras.Layer\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MyDenseLayer(tf.keras.layers.Layer):\n  def __init__(self, num_outputs):\n    super(MyDenseLayer, self).__init__()\n    self.num_outputs = num_outputs\n\n  def build(self, input_shape):\n    self.kernel = self.add_variable(\"kernel\",\n                                    shape=[int(input_shape[-1]),\n                                           self.num_outputs])\n\n  def call(self, input):\n    return tf.matmul(input, self.kernel)\n\nlayer = MyDenseLayer(10)\nprint(layer(tf.zeros([10, 5])))\nprint(layer.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Implementing Prediction Mode in TensorFlow Custom Estimator\nDESCRIPTION: This code snippet demonstrates how to implement the prediction mode in a custom Estimator. It computes predicted classes, probabilities, and logits, and returns them in an EstimatorSpec object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Compute predictions.\npredicted_classes = tf.argmax(logits, 1)\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\n        'class_ids': predicted_classes[:, tf.newaxis],\n        'probabilities': tf.nn.softmax(logits),\n        'logits': logits,\n    }\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n```\n\n----------------------------------------\n\nTITLE: Loading SavedModel in Python\nDESCRIPTION: This Python code shows how to load a SavedModel into a session, which involves specifying session, tags, and export directory. It restores graph definitions and variables based on the specified MetaGraphDef. Necessary Python dependencies include TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nexport_dir = ...\n...\nwith tf.Session(graph=tf.Graph()) as sess:\n  tf.saved_model.loader.load(sess, [tag_constants.TRAINING], export_dir)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Defining Sample Sentences for BERT Analysis\nDESCRIPTION: Creates a list of sample sentences from different domains to demonstrate BERT's embedding capabilities. The sentences cover topics like music, people, plants, and astronomy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsentences = [\n  \"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\",\n  \"The album went straight to number one on the Norwegian album chart, and sold to double platinum.\",\n  \"Among the singles released from the album were the songs \\\"Be My Lover\\\" and \\\"Hard To Stay Awake\\\".\",\n  \"Riccardo Zegna is an Italian jazz musician.\",\n  \"Rajko Maksimović is a composer, writer, and music pedagogue.\",\n  \"One of the most significant Serbian composers of our time, Maksimović has been and remains active in creating works for different ensembles.\",\n  \"Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum\",\n  \"A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.\",\n  \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\",\n]\n```\n\n----------------------------------------\n\nTITLE: Generating and checking model predictions\nDESCRIPTION: Makes predictions on an image batch, extracts the predicted class IDs, and maps them to class names to verify model output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\npredicted_batch = model.predict(image_batch)\npredicted_id = tf.math.argmax(predicted_batch, axis=-1)\npredicted_label_batch = class_names[predicted_id]\nprint(predicted_label_batch)\n```\n\n----------------------------------------\n\nTITLE: Optimizer Creation Function\nDESCRIPTION: Creates an FTRL optimizer with exponential decay for both TF1 and TF2 versions of the models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef create_sample_optimizer(tf_version):\n  if tf_version == 'tf1':\n    optimizer = lambda: tf.keras.optimizers.legacy.Ftrl(\n        l1_regularization_strength=0.001,\n        learning_rate=tf1.train.exponential_decay(\n            learning_rate=0.1,\n            global_step=tf1.train.get_global_step(),\n            decay_steps=10000,\n            decay_rate=0.9))\n  elif tf_version == 'tf2':\n    optimizer = tf.keras.optimizers.legacy.Ftrl(\n        l1_regularization_strength=0.001,\n        learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(\n            initial_learning_rate=0.1, decay_steps=10000, decay_rate=0.9))\n  return optimizer\n```\n\n----------------------------------------\n\nTITLE: Selecting Model and Determining Image Size in Python\nDESCRIPTION: This snippet selects a model handle based on the model name and determines the image size for preprocessing. It handles both fixed and dynamic image sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel_handle = model_handle_map[model_name]\n\nprint(f\"Selected model: {model_name} : {model_handle}\")\n\n\nmax_dynamic_size = 512\nif model_name in model_image_size_map:\n  image_size = model_image_size_map[model_name]\n  dynamic_size = False\n  print(f\"Images will be converted to {image_size}x{image_size}\")\nelse:\n  dynamic_size = True\n  print(f\"Images will be capped to a max size of {max_dynamic_size}x{max_dynamic_size}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Frame Interpolation Parameters in Python\nDESCRIPTION: Code snippet that sets up the parameters for frame interpolation, including the number of recursive interpolations and creating an instance of the Interpolator class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntimes_to_interpolate = 6\ninterpolator = Interpolator()\n```\n\n----------------------------------------\n\nTITLE: Inspecting SavedModel with saved_model_cli\nDESCRIPTION: Uses the saved_model_cli tool to display detailed information about the saved model, including available MetaGraphDefs and signatures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n!saved_model_cli show --dir {mobilenet_save_path} --tag_set serve\n```\n\n----------------------------------------\n\nTITLE: Creating Input Function\nDESCRIPTION: Defining an input function to convert data into TensorFlow Dataset format for model training\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n  def input_function():\n    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n    if shuffle:\n      ds = ds.shuffle(1000)\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    return ds\n  return input_function\n\ntrain_input_fn = make_input_fn(dftrain, y_train)\neval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n```\n\n----------------------------------------\n\nTITLE: Plotting Keras Model Training Progress\nDESCRIPTION: Visualizes the training progress of the Keras model by plotting the loss over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(history.history['loss'])\nplt.xlabel('Epoch')\nplt.ylim([0, max(plt.ylim())])\nplt.ylabel('Loss [Mean Squared Error]')\nplt.title('Keras training progress');\n```\n\n----------------------------------------\n\nTITLE: Explicit Device Placement in TensorFlow with Python\nDESCRIPTION: Enables time-based execution of matrix multiplication on specific devices (CPU and GPU) using TensorFlow, explicitly managing where operations run.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport time\n\ndef time_matmul(x):\n  start = time.time()\n  for loop in range(10):\n    tf.matmul(x, x)\n\n  result = time.time()-start\n\n  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n\n\n# Force execution on CPU\nprint(\"On CPU:\")\nwith tf.device(\"CPU:0\"):\n  x = tf.random_uniform([1000, 1000])\n  assert x.device.endswith(\"CPU:0\")\n  time_matmul(x)\n\n# Force execution on GPU #0 if available\nif tf.config.list_physical_devices('GPU'):\n  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n    x = tf.random_uniform([1000, 1000])\n    assert x.device.endswith(\"GPU:0\")\n    time_matmul(x)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Lite Interpreter for Model Inference\nDESCRIPTION: Sets up a TensorFlow Lite interpreter with the converted model and defines a helper function to simplify making predictions with numpy arrays.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ninterpreter = tf.lite.Interpreter(model_content=lite_model_content)\n# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\ndef lite_model(images):\n  interpreter.allocate_tensors()\n  interpreter.set_tensor(interpreter.get_input_details()[0]['index'], images)\n  interpreter.invoke()\n  return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n```\n\n----------------------------------------\n\nTITLE: Executing TensorFlow Model with Session\nDESCRIPTION: Executes the computation graph using `sess.run()` to obtain the output of a model. Specified input data is fed to placeholders, and the output tensor's result is printed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\nprint(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))\n```\n\n----------------------------------------\n\nTITLE: Creating Adam Optimizer for Custom Training in TensorFlow\nDESCRIPTION: Instantiates an Adam optimizer to be used in a custom training loop with gradient tape for the text generation model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.AdamOptimizer()\n```\n\n----------------------------------------\n\nTITLE: Creating Image Caption Function\nDESCRIPTION: This function creates captions for images based on their attribution information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport IPython.display as display\n\ndef caption_image(image_path):\n    image_rel = pathlib.Path(image_path).relative_to(data_root)\n    return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow Hub pip package\nDESCRIPTION: Bazel commands to build the TensorFlow Hub pip package and create the wheel file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nbazel build tensorflow_hub/pip_package:build_pip_package\n```\n\nLANGUAGE: shell\nCODE:\n```\nbazel-bin/tensorflow_hub/pip_package/build_pip_package \\\n/tmp/tensorflow_hub_pkg\n```\n\n----------------------------------------\n\nTITLE: Adding L2 Weight Regularization with Keras\nDESCRIPTION: Creates a neural network model with L2 weight regularization using the Keras Sequential API. L2 regularization is applied to both dense layers using `keras.regularizers.l2(0.001)`. The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy metrics.  The model is then trained using the `fit` method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nl2_model = keras.models.Sequential([\n    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n                       activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n                       activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nl2_model.compile(optimizer='adam',\n                 loss='binary_crossentropy',\n                 metrics=['accuracy', 'binary_crossentropy'])\n\nl2_model_history = l2_model.fit(train_data, train_labels,\n                                epochs=20,\n                                batch_size=512,\n                                validation_data=(test_data, test_labels),\n                                verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Loading Model Weights and Evaluating in TensorFlow\nDESCRIPTION: Loads the saved weights from a checkpoint into the model and re-evaluates performance to demonstrate the improvement from the trained weights.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Loads the weights\nmodel.load_weights(checkpoint_path)\n\n# Re-evaluate the model\nloss, acc = model.evaluate(test_images, test_labels, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n```\n\n----------------------------------------\n\nTITLE: Generating Spectrogram from WAV File\nDESCRIPTION: This command uses the wav_to_spectrogram tool to convert a WAV file into a spectrogram image. It specifies the input WAV file and the output image file path.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbazel run tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram -- \\\n--input_wav=/tmp/speech_dataset/happy/ab00c4b2_nohash_0.wav \\\n--output_image=/tmp/spectrogram.png\n```\n\n----------------------------------------\n\nTITLE: Accessing Ragged Tensor Elements with Python-style Indexing\nDESCRIPTION: Demonstrates accessing specific slices of a ragged tensor using Python-style indexing to retrieve rows and column ranges.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[0])       # First row\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[:, :2])   # First two values in each row.\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[:, -2:])  # Last two values in each row.\n```\n\n----------------------------------------\n\nTITLE: Importing Python Libraries for Video Classification\nDESCRIPTION: Imports all necessary Python libraries for the video classification task, including utilities for data handling, visualization, video processing, and deep learning frameworks TensorFlow and Keras.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tqdm\nimport random\nimport pathlib\nimport itertools\nimport collections\n\nimport cv2\nimport einops\nimport numpy as np\nimport remotezip as rz\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Type List Constraint\nDESCRIPTION: Shows how to register an op with a constraint on a list of types with minimum length.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_22\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"TypeListExample\")\n    .Attr(\"a: list({int32, float}) >= 3\");\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU Memory for TensorFlow and JAX Coexistence\nDESCRIPTION: Sets environment variables and GPU memory growth settings to allow TensorFlow and JAX to share GPU memory efficiently without pre-allocating all available memory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Needed for TensorFlow and JAX to coexist in GPU memory.\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = \"false\"\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized.\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Custom Training Batch Statistics Callback\nDESCRIPTION: Create a custom Keras callback to track batch-level loss and accuracy during model training, enabling granular performance monitoring\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass CollectBatchStats(tf.keras.callbacks.Callback):\n  def __init__(self):\n    self.batch_losses = []\n    self.batch_acc = []\n\n  def on_train_batch_end(self, batch, logs=None):\n    self.batch_losses.append(logs['loss'])\n    self.batch_acc.append(logs['acc'])\n    self.model.reset_metrics()\n```\n\n----------------------------------------\n\nTITLE: Identifying Non-trainable Variables in MobileNet\nDESCRIPTION: Identifies and displays non-trainable variables in a loaded MobileNet model by comparing variable IDs between the full variables list and trainable_variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntrainable_variable_ids = {id(v) for v in loaded.trainable_variables}\nnon_trainable_variables = [v for v in loaded.variables\n                           if id(v) not in trainable_variable_ids]\nprint(\"MobileNet also has {} non-trainable variables: {}, ...\".format(\n          len(non_trainable_variables),\n          \", \".join([v.name for v in non_trainable_variables[:3]])))\n```\n\n----------------------------------------\n\nTITLE: Showing TensorInfo for a Specific SignatureDef\nDESCRIPTION: Demonstrates how to display all inputs and outputs TensorInfo for a specific SignatureDef using the 'show' command.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir \\\n/tmp/saved_model_dir --tag_set serve --signature_def serving_default\nThe given SavedModel SignatureDef contains the following input(s):\n  inputs['x'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: x:0\nThe given SavedModel SignatureDef contains the following output(s):\n  outputs['y'] tensor_info:\n      dtype: DT_FLOAT\n      shape: (-1, 1)\n      name: y:0\nMethod name is: tensorflow/serving/predict\n```\n\n----------------------------------------\n\nTITLE: Adjusting Image Saturation with tf.image\nDESCRIPTION: Demonstrates saturation adjustment by increasing color intensity using tf.image.adjust_saturation. The example applies a saturation factor of 3 to enhance the color vividness in the image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nsaturated = tf.image.adjust_saturation(image, 3)\nvisualize(image, saturated)\n```\n\n----------------------------------------\n\nTITLE: Building a Text Generation Model with RNN in TensorFlow\nDESCRIPTION: Creates a sequential model for text generation with an embedding layer, a GRU recurrent layer, and a dense output layer. The model architecture is designed to predict the next character in a sequence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n  model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                              batch_input_shape=[batch_size, None]),\n    rnn(rnn_units,\n        return_sequences=True,\n        recurrent_initializer='glorot_uniform',\n        stateful=True),\n    tf.keras.layers.Dense(vocab_size)\n  ])\n  return model\n```\n\n----------------------------------------\n\nTITLE: Device-Specific Generator Creation\nDESCRIPTION: Example of creating a device-specific random number generator to avoid cross-device copy overhead.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device(\"cpu\"):\n  g = tf.random.get_global_generator().split(1)[0]  \n  print(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Model Training Function and Classifier Training\nDESCRIPTION: Defines a function to train models and then trains the MNIST classifier. The function compiles the model with Adam optimizer and sparse categorical crossentropy loss, and returns validation accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef train_model(model, training_data, validation_data, **kwargs):\n  model.compile(\n      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n      # Uncomment this to ease debugging:\n      # run_eagerly=True,\n  )\n  kwargs.setdefault(\"epochs\", 5)\n  kwargs.setdefault(\"verbose\", 1)\n  log = model.fit(\n      training_data.batch(128).prefetch(8),\n      validation_data=validation_data.batch(128).cache(),\n      validation_freq=1,\n      **kwargs,\n  )\n  return log.history[\"val_sparse_categorical_accuracy\"][-1]\n\nclassifier_accuracy = train_model(\n    classifier, training_dataset, validation_dataset)\n\nprint(f\"Accuracy: {classifier_accuracy:0.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Plotting Loss Metrics for DTensor Model Evaluation\nDESCRIPTION: Example usage of the plot_metrics function to visualize the cross entropy loss during training and testing. This shows how model loss changes over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nplot_metrics(train_losses, test_losses, \"Cross entropy loss\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Object Detection Results\nDESCRIPTION: This code visualizes the object detection results by drawing bounding boxes, labels, and scores on the input image. It also handles keypoint visualization if available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nlabel_id_offset = 0\nimage_np_with_detections = image_np.copy()\n\n# Use keypoints if available in detections\nkeypoints, keypoint_scores = None, None\nif 'detection_keypoints' in result:\n  keypoints = result['detection_keypoints'][0]\n  keypoint_scores = result['detection_keypoint_scores'][0]\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset).astype(int),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.30,\n      agnostic_mode=False,\n      keypoints=keypoints,\n      keypoint_scores=keypoint_scores,\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_detections[0])\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Implementing Functional-Style Compat Model in TensorFlow 2\nDESCRIPTION: This snippet demonstrates how to create a model using TensorFlow 1.x compatible layers within a TensorFlow 2 Keras layer. It uses the @tf.compat.v1.keras.utils.track_tf1_style_variables decorator to maintain compatibility with TF1 checkpoints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nclass FunctionalStyleCompatModel(tf.keras.layers.Layer):\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = tf.compat.v1.layers.conv2d(\n          inputs, 3, 3,\n          kernel_regularizer=\"l2\")\n      out = tf.compat.v1.layers.conv2d(\n          out, 4, 4,\n          kernel_regularizer=\"l2\")\n      out = tf.compat.v1.layers.conv2d(\n          out, 5, 5,\n          kernel_regularizer=\"l2\")\n      return out\n\nlayer = FunctionalStyleCompatModel()\nlayer(tf.ones(shape=(10, 10, 10, 10)))\n[v.name for v in layer.weights]\n```\n\n----------------------------------------\n\nTITLE: Graph Inspection and AutoGraph Code Generation\nDESCRIPTION: Shows how to inspect the generated AutoGraph code and raw graph definition.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# This is the graph-generating output of AutoGraph.\nprint(tf.autograph.to_code(simple_relu))\n\n# This is the graph itself.\nprint(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())\n```\n\n----------------------------------------\n\nTITLE: Printing Model Performance Metrics\nDESCRIPTION: Iterates through all models' performance metrics and prints their mean absolute error values on the test dataset for direct numeric comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_50\n\nLANGUAGE: python\nCODE:\n```\nfor name, value in performance.items():\n  print(f'{name:12s}: {value[metric_name]:0.4f}')\n```\n\n----------------------------------------\n\nTITLE: Text Vectorization Function\nDESCRIPTION: Defines a helper function to vectorize text inputs and maintain their labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef vectorize_text(text, label):\n  text = tf.expand_dims(text, -1)\n  return vectorize_layer(text), label\n```\n\n----------------------------------------\n\nTITLE: Implementing a ResNet Identity Block\nDESCRIPTION: Creates a custom ResNet identity block by extending tf.keras.Model and composing multiple layers including convolutions and batch normalization layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass ResnetIdentityBlock(tf.keras.Model):\n  def __init__(self, kernel_size, filters):\n    super(ResnetIdentityBlock, self).__init__(name='')\n    filters1, filters2, filters3 = filters\n\n    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n    self.bn2a = tf.keras.layers.BatchNormalization()\n\n    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n    self.bn2b = tf.keras.layers.BatchNormalization()\n\n    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n    self.bn2c = tf.keras.layers.BatchNormalization()\n\n  def call(self, input_tensor, training=False):\n    x = self.conv2a(input_tensor)\n    x = self.bn2a(x, training=training)\n    x = tf.nn.relu(x)\n\n    x = self.conv2b(x)\n    x = self.bn2b(x, training=training)\n    x = tf.nn.relu(x)\n\n    x = self.conv2c(x)\n    x = self.bn2c(x, training=training)\n\n    x += input_tensor\n    return tf.nn.relu(x)\n\n\nblock = ResnetIdentityBlock(1, [1, 2, 3])\n```\n\n----------------------------------------\n\nTITLE: Saving Trained Wav2Vec2 Model\nDESCRIPTION: Saves the trained Wav2Vec2 model for later inference, excluding the optimizer state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nsave_dir = \"finetuned-wav2vec2\"\nmodel.save(save_dir, include_optimizer=False)\n```\n\n----------------------------------------\n\nTITLE: Building a Custom Layer\nDESCRIPTION: Shows how calling a layer with inputs triggers the build method, which initializes the layer's weights based on input shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it.\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating a Random Forest Model with TensorFlow Decision Forests\nDESCRIPTION: This snippet shows how to create, train, compile, and evaluate a Random Forest model using TensorFlow Decision Forests. Random Forest models are noted for their resistance to overfitting compared to other decision tree models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Train a Random Forest model\nrf_model = tfdf.keras.RandomForestModel()\nrf_model.fit(train_dataset)\n\n# Evaluate the Random Forest model\nrf_model.compile(metrics=['accuracy'])\nrf_evaluation = rf_model.evaluate(eval_dataset, return_dict=True)\nprint(rf_evaluation)\n```\n\n----------------------------------------\n\nTITLE: Configuring Spatial Parallel Training with DTensor in Python\nDESCRIPTION: This code sets up a model for spatial parallel training using DTensor. It creates a 3D mesh including a feature dimension and configures the model with appropriate layouts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"batch\", 2), (\"feature\", 2), (\"model\", 2)], devices=DEVICES)\nmodel = MLP([dtensor.Layout([\"feature\", \"model\"], mesh), \n             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Trace Type in TensorFlow\nDESCRIPTION: This snippet defines a custom trace type class 'FruitTraceType' inheriting from TensorFlow's experimental TraceType. It is utilized to determine subtype relationships and obtain placeholder values, useful in sophisticated type-based tracing scenarios with the TensorFlow library. Dependencies include the experimental module from TensorFlow and defined classes representing fruits.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass FruitTraceType(tf.types.experimental.TraceType):\n  def __init__(self, fruit):\n    self.fruit_type = type(fruit)\n    self.fruit_value = fruit\n\n  def is_subtype_of(self, other):\n      # True if self subtypes `other` and `other`'s type matches FruitTraceType.\n      return (type(other) is FruitTraceType and\n              self.fruit_type is other.fruit_type)\n\n  def most_specific_common_supertype(self, others):\n      # `self` is the specific common supertype if all input types match it.\n      return self if all(self == other for other in others) else None\n\n  def placeholder_value(self, placeholder_context=None):\n      # Use the fruit itself instead of the type for correct tracing.\n      return self.fruit_value\n\n  def __eq__(self, other):\n    return type(other) is FruitTraceType and self.fruit_type == other.fruit_type\n\n  def __hash__(self):\n    return hash(self.fruit_type)\n\nclass FruitWithTraceType:\n\n  def __tf_tracing_type__(self, context):\n    return FruitTraceType(self)\n\nclass AppleWithTraceType(FruitWithTraceType):\n  flavor = tf.constant([1, 2])\n\nclass MangoWithTraceType(FruitWithTraceType):\n  flavor = tf.constant([3, 4])\n\n# Now if you try calling it again:\nget_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Traces a new concrete function\nget_mixed_flavor(AppleWithTraceType(), MangoWithTraceType()) # Re-uses the traced concrete function\n```\n\n----------------------------------------\n\nTITLE: Constructing Ragged Tensors with from_row_splits\nDESCRIPTION: Demonstrates creating a ragged tensor by specifying the indices where each row starts and ends using the from_row_splits factory method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_row_splits(\n    values=[3, 1, 4, 1, 5, 9, 2],\n    row_splits=[0, 4, 4, 6, 7]))\n```\n\n----------------------------------------\n\nTITLE: TF_CONFIG Setup for Worker in TensorFlow\nDESCRIPTION: Example of setting up TF_CONFIG environment variable for a worker node in a distributed training setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"TF_CONFIG\"] = json.dumps({\n    \"cluster\": {\n        \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n        \"ps\": [\"host4:port\", \"host5:port\"],\n        \"chief\": [\"host6:port\"]\n    },\n    \"task\": {\"type\": \"worker\", \"index\": 1}\n})\n```\n\n----------------------------------------\n\nTITLE: Compiling Model with Binary Cross-Entropy Loss\nDESCRIPTION: Configures the model training process by setting the optimizer, loss function, and evaluation metrics. Uses binary cross-entropy loss and accuracy metrics appropriate for binary classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nbase_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])\n```\n\n----------------------------------------\n\nTITLE: Conditional Check in TensorFlow Op Kernel (C++)\nDESCRIPTION: This code snippet demonstrates how to perform conditional checks within a TensorFlow OpKernel's Compute method. It uses the `OP_REQUIRES` macro to validate that the input tensor is a vector. If the condition fails, an `InvalidArgument` status is returned, stopping execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_8\n\nLANGUAGE: c++\nCODE:\n```\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_tensor.shape()),\n                errors::InvalidArgument(\"ZeroOut expects a 1-D vector.\"));\n    // ...\n  }\n```\n\n----------------------------------------\n\nTITLE: Displaying an Image with its Label Name\nDESCRIPTION: Retrieves an image from the dataset and displays it with its corresponding label name converted from an integer using metadata.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nget_label_name = metadata.features['label'].int2str\n\nimage, label = next(iter(train_ds))\n_ = plt.imshow(image)\n_ = plt.title(get_label_name(label))\n```\n\n----------------------------------------\n\nTITLE: Automatic Retracing Reduction in TensorFlow Functions\nDESCRIPTION: Demonstrates the use of reduce_retracing parameter to automatically generalize input types and reduce unnecessary retracing in tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(reduce_retracing=True)\ndef g(x):\n  print('Tracing with', x)\n  return x\n\n# Traces once.\nprint(g(tf.constant([1, 2, 3])))\n\n# Traces again, but more generalized this time.\nprint(g(tf.constant([1, 2, 3, 4, 5])))\n\n# No more tracing!\nprint(g(tf.constant([1, 2, 3, 4, 5, 6, 7])))\nprint(g(tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9])))\n\n```\n\n----------------------------------------\n\nTITLE: Checking Keras Input layer documentation\nDESCRIPTION: Uses the Python help system to display information about the tf.keras.Input class to learn about its parameters and usage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.Input?\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset Metadata for TensorFlow Transform\nDESCRIPTION: Creates metadata that describes the schema of the input data for TensorFlow Transform.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef create_metadata():\n  '''Creates metadata for the raw data'''\n  from tensorflow_transform.tf_metadata import dataset_metadata\n  from tensorflow_transform.tf_metadata import schema_utils\n  feature_spec = {'text': tf.FixedLenFeature([], dtype=tf.string)}\n  schema = schema_utils.schema_from_feature_spec(feature_spec)\n  metadata = dataset_metadata.DatasetMetadata(schema)\n  return metadata\n```\n\n----------------------------------------\n\nTITLE: Basic Shape Function in C++\nDESCRIPTION: Simple shape function implementation for the ZeroOut operation that copies the input shape to the output shape using TensorFlow's shape inference system.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_41\n\nLANGUAGE: c++\nCODE:\n```\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n```\n\n----------------------------------------\n\nTITLE: Setting GPU Memory Limit in TensorFlow\nDESCRIPTION: This code shows how to set a hard limit on the total memory to allocate on the GPU using tf.config.set_logical_device_configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n  try:\n    tf.config.set_logical_device_configuration(\n        gpus[0],\n        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Dataset with Column Selection\nDESCRIPTION: Creates a dataset that reads from CSV files with headers, extracting float data from specific columns (2 and 4) using the select_cols parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_53\n\nLANGUAGE: python\nCODE:\n```\n# Creates a dataset that reads all of the records from two CSV files with\n# headers, extracting float data from columns 2 and 4.\nrecord_defaults = [999, 999] # Only provide defaults for the selected columns\ndataset = tf.data.experimental.CsvDataset(\"missing.csv\", record_defaults, select_cols=[1, 3])\ndataset = dataset.map(lambda *items: tf.stack(items))\ndataset\n```\n\n----------------------------------------\n\nTITLE: Using Persistent GradientTape in TensorFlow\nDESCRIPTION: Demonstrates the creation of a persistent GradientTape that allows multiple calls to the gradient() method on the same recorded computation. Shows how to compute different gradients from the same tape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(3.0)\nwith tf.GradientTape(persistent=True) as t:\n  t.watch(x)\n  y = x * x\n  z = y * y\ndz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\ndy_dx = t.gradient(y, x)  # 6.0\ndel t  # Drop the reference to the tape\n```\n\n----------------------------------------\n\nTITLE: Naming TensorFlow Variables\nDESCRIPTION: This snippet shows how to assign names to TensorFlow variables and demonstrates that variables with the same name are still distinct objects.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create a and b; they will have the same name but will be backed by\n# different tensors.\na = tf.Variable(my_tensor, name=\"Mark\")\n# A new variable with the same name, but different value\n# Note that the scalar add is broadcast\nb = tf.Variable(my_tensor + 1, name=\"Mark\")\n\n# These are elementwise-unequal, despite having the same name\nprint(a == b)\n```\n\n----------------------------------------\n\nTITLE: Converting RaggedTensor to dense tensor in TensorFlow\nDESCRIPTION: Demonstrates how to convert a RaggedTensor to a regular dense tensor using the to_tensor() method, which is useful for integrating with Keras.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nhashed_words.to_tensor()\n```\n\n----------------------------------------\n\nTITLE: Using CsvDataset for Basic CSV Parsing\nDESCRIPTION: This code demonstrates the tf.data.experimental.CsvDataset class for reading CSV files. This lower-level API provides minimal CSV interface without automatic type inference or other conveniences of make_csv_dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_46\n\nLANGUAGE: python\nCODE:\n```\nsimple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n\nfor example in simple_titanic.take(1):\n  print([e.numpy() for e in example])\n```\n\n----------------------------------------\n\nTITLE: Loading Fashion MNIST Dataset\nDESCRIPTION: Loads the Fashion MNIST dataset using Keras, which contains training and test sets of clothing images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfashion_mnist = keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies for JAX and TensorFlow\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, JAX, Flax, Optax, and visualization tools needed for building, converting, and training models across both frameworks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport numpy as np\nimport jax\nimport jax.numpy as jnp\nimport flax\nimport optax\nimport os\nfrom matplotlib import pyplot as plt\nfrom jax.experimental import jax2tf\nfrom threading import Lock # Only used in the visualization utility.\nfrom functools import partial\n```\n\n----------------------------------------\n\nTITLE: Using Text Embedding Models with Direct Text Inputs in TensorFlow Hub\nDESCRIPTION: Demonstrates how to load a text embedding model from TensorFlow Hub and use it to generate embeddings from text inputs. This is the simplest approach but may not support TPU fine-tuning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nobj = hub.load(\"path/to/model\")\ntext_input = [\"A long sentence.\",\n              \"single-word\",\n              \"http://example.com\"]\nembeddings = obj(text_input)\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TensorFlow Model and Printing Metrics\nDESCRIPTION: Evaluates a trained TensorFlow model on test data in batches of 512 samples. The code then iterates through the model's metrics (loss and accuracy) and prints their values with formatted output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = model.evaluate(test_data.batch(512), verbose=2)\n\nfor name, value in zip(model.metrics_names, results):\n  print(\"%s: %.3f\" % (name, value))\n```\n\n----------------------------------------\n\nTITLE: Reading and Processing Text Data\nDESCRIPTION: Reading the downloaded text file and performing initial text processing\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Read, then decode for py2 compat.\ntext = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n# length of text is the number of characters in it\nprint ('Length of text: {} characters'.format(len(text)))\n```\n\n----------------------------------------\n\nTITLE: Using Overloaded Operators with Ragged Tensors in Python\nDESCRIPTION: This snippet demonstrates the use of overloaded operators with ragged tensors. It shows element-wise addition of two ragged tensors and broadcasting a scalar to a ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nx = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\ny = tf.ragged.constant([[1, 1], [2], [3, 3, 3]])\nprint(x + y)\n```\n\nLANGUAGE: python\nCODE:\n```\nx = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\nprint(x + 3)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Dependencies\nDESCRIPTION: Basic import statements for TensorFlow and TensorFlow Datasets required for the TensorFlow 2 examples in the guide.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Using Ragged Tensors with Concrete Functions in Python\nDESCRIPTION: This example shows how to use ragged tensors with concrete functions. It defines an increment function and demonstrates getting and using a concrete function with a ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef increment(x):\n  return x + 1\n\nrt = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\ncf = increment.get_concrete_function(rt)\nprint(cf(rt))\n```\n\n----------------------------------------\n\nTITLE: Creating and Training Estimator with MirroredStrategy in Python\nDESCRIPTION: This snippet demonstrates how to create an Estimator with MirroredStrategy for distributed training and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(\n    train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\nregressor = tf.estimator.LinearRegressor(\n    feature_columns=[tf.feature_column.numeric_column('feats')],\n    optimizer='SGD',\n    config=config)\n\ndef input_fn():\n  dataset = tf.data.Dataset.from_tensors(({{\"feats\":[1.]}}, [1.]))\n  return dataset.repeat(1000).batch(10)\nregressor.train(input_fn=input_fn, steps=10)\nregressor.evaluate(input_fn=input_fn, steps=10)\n```\n\n----------------------------------------\n\nTITLE: Saving and Reloading TensorFlow Audio Classification Model\nDESCRIPTION: This code shows how to save the exported model and reload it, ensuring that the reloaded model produces identical output to the original.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ntf.saved_model.save(export, \"saved\")\nimported = tf.saved_model.load(\"saved\")\nimported(waveform[tf.newaxis, :])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Naive Timeline in TensorFlow Benchmark\nDESCRIPTION: Calls the draw_timeline function to create a visualization of the naive pipeline's execution timeline with a width of 15 units.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndraw_timeline(naive_timeline, \"Naive\", 15)\n```\n\n----------------------------------------\n\nTITLE: Tensor Shape and Datatype Example\nDESCRIPTION: Demonstration of tensor matrix multiplication and accessing tensor properties\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linalg.matmul([[1]], [[2, 3]])\nprint(x)\nprint(x.shape)\nprint(x.dtype)\n```\n\n----------------------------------------\n\nTITLE: Unpacking Nested Dataset Elements\nDESCRIPTION: Demonstrates how to iterate through a dataset with nested elements, unpacking the structure and accessing individual components.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfor a, (b,c) in dataset3:\n  print('shapes: {a.shape}, {b.shape}, {c.shape}'.format(a=a, b=b, c=c))\n```\n\n----------------------------------------\n\nTITLE: Loading MetaGraphDef in TensorFlow 1\nDESCRIPTION: This snippet demonstrates how to load a saved MetaGraphDef and restore variable values using TensorFlow 1 APIs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  meta = tf1.train.import_meta_graph('multiply.pb')\n  x = g.get_tensor_by_name('x:0')\n  y = g.get_tensor_by_name('y:0')\n  with tf1.Session() as sess:\n    meta.restore(sess, 'multiply_values.ckpt')\n    print(sess.run(y, feed_dict={x: 5}))\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Session\nDESCRIPTION: Creates and initializes a TensorFlow session for running the BigBiGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and Setting Random Seed\nDESCRIPTION: Imports TensorFlow, prints the version, and sets a random seed for reproducible results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nprint(tf.__version__)\n# set random seed for reproducible results \ntf.random.set_seed(22)\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Images in Python\nDESCRIPTION: Defines functions to display individual generated images and create an animated GIF of all saved images throughout the training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n\nplt.imshow(display_image(epoch))\nplt.axis('off')  # Display images\n```\n\nLANGUAGE: Python\nCODE:\n```\nanim_file = 'cvae.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)\n```\n\n----------------------------------------\n\nTITLE: Implementing Validation in ExtensionType in Python\nDESCRIPTION: Demonstrates how to override the __validate__ method in an ExtensionType class to perform validation checks on fields after construction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  \"\"\"A tensor paired with a boolean mask, indicating which values are valid.\"\"\"\n  values: tf.Tensor\n  mask: tf.Tensor\n  def __validate__(self):\n    self.values.shape.assert_is_compatible_with(self.mask.shape)\n    assert self.mask.dtype.is_bool, 'mask.dtype must be bool'\n```\n\n----------------------------------------\n\nTITLE: Packing Component Tensors into a DTensor in TensorFlow\nDESCRIPTION: Example of the inverse operation to unpacking - using dtensor.pack() to create a DTensor from multiple component tensors. This function automatically handles copying tensors to their respective devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npacked_dtensor = dtensor.pack(\n    [[0, 1], [0, 1], [0, 1],\n     [0, 1], [0, 1], [0, 1]],\n     layout=layout\n)\nprint(packed_dtensor)\n```\n\n----------------------------------------\n\nTITLE: Initializing TPU Strategy in TensorFlow\nDESCRIPTION: Sets up TPU-based distributed training by creating a TPUClusterResolver, initializing the TPU system, and creating a TPUStrategy instance. Required for running TensorFlow on TPU hardware.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.tpu.experimental.initialize_tpu_system(resolver)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow 1 Model Formats for TFLite Conversion Examples\nDESCRIPTION: This code creates various TensorFlow 1 model formats including a SavedModel, a Keras model, and a frozen GraphDef. These models will be used in subsequent examples to demonstrate TFLite conversion in TF2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tflite.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create a TF1 SavedModel\nSAVED_MODEL_DIR = \"tf_saved_model/\"\nremove_dir(SAVED_MODEL_DIR)\nwith tf1.Graph().as_default() as g:\n  with tf1.Session() as sess:\n    input = tf1.placeholder(tf.float32, shape=(3,), name='input')\n    output = input + 2\n    tf1.saved_model.simple_save(\n        sess, SAVED_MODEL_DIR,\n        inputs={'input': input}, \n        outputs={'output': output})\nprint(\"TF1 SavedModel path: \", SAVED_MODEL_DIR)\n\n# Create a TF1 Keras model\nKERAS_MODEL_PATH = 'tf_keras_model.h5'\nmodel = tf1.keras.models.Sequential([\n    tf1.keras.layers.InputLayer(input_shape=(128, 128, 3,), name='input'),\n    tf1.keras.layers.Dense(units=16, input_shape=(128, 128, 3,), activation='relu'),\n    tf1.keras.layers.Dense(units=1, name='output')\n])\nmodel.save(KERAS_MODEL_PATH, save_format='h5')\nprint(\"TF1 Keras Model path: \", KERAS_MODEL_PATH)\n\n# Create a TF1 frozen GraphDef model\nGRAPH_DEF_MODEL_PATH = tf.keras.utils.get_file(\n    'mobilenet_v1_0.25_128',\n    origin='https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.25_128_frozen.tgz',\n    untar=True,\n) + '/frozen_graph.pb'\n\nprint(\"TF1 frozen GraphDef path: \", GRAPH_DEF_MODEL_PATH)\n```\n\n----------------------------------------\n\nTITLE: Pulling TensorFlow Docker Images\nDESCRIPTION: Commands to download various TensorFlow Docker images, including stable releases, nightly builds, and GPU-enabled versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull tensorflow/tensorflow                     # latest stable release\ndocker pull tensorflow/tensorflow:devel-gpu           # nightly dev release w/ GPU support\ndocker pull tensorflow/tensorflow:latest-gpu-jupyter  # latest release w/ GPU support and Jupyter\n```\n\n----------------------------------------\n\nTITLE: Creating and Inspecting Basic Datasets in TensorFlow\nDESCRIPTION: Demonstrates how to create datasets from tensors and inspect their output types and shapes. Shows examples of creating datasets with different structures including single tensors, tuples, and nested structures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))\nprint(dataset1.output_types)  # ==> \"tf.float32\"\nprint(dataset1.output_shapes)  # ==> \"(10,)\"\n\ndataset2 = tf.data.Dataset.from_tensor_slices(\n   (tf.random_uniform([4]),\n    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))\nprint(dataset2.output_types)  # ==> \"(tf.float32, tf.int32)\"\nprint(dataset2.output_shapes)  # ==> \"((), (100,))\"\n\ndataset3 = tf.data.Dataset.zip((dataset1, dataset2))\nprint(dataset3.output_types)  # ==> (tf.float32, (tf.float32, tf.int32))\nprint(dataset3.output_shapes)  # ==> \"(10, ((), (100,)))\"\n```\n\n----------------------------------------\n\nTITLE: Creating Numeric Feature Column in TensorFlow\nDESCRIPTION: Demonstrates how to create a basic numeric feature column with default float32 data type for handling numerical input values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Defaults to a tf.float32 scalar.\nnumeric_feature_column = tf.feature_column.numeric_column(key=\"SepalLength\")\n```\n\n----------------------------------------\n\nTITLE: Converting a Keras MobileNetV2 Model to TensorFlow Estimator\nDESCRIPTION: Creates a Keras sequential model with MobileNetV2 as the base model, GlobalAveragePooling2D, and a Dense layer, which can be converted to an Estimator using tf.keras.estimator.model_to_estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nkeras_mobilenet_v2 = tf.keras.applications.MobileNetV2(\n    input_shape=(160, 160, 3), include_top=False)\nkeras_mobilenet_v2.trainable = False\n\nestimator_model = tf.keras.Sequential([\n    keras_mobilenet_v2,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(1)\n])\n```\n\n----------------------------------------\n\nTITLE: Examining First Batch After Shuffling in TensorFlow\nDESCRIPTION: Retrieves and prints the indices from the first batch of a shuffled dataset to observe the shuffling effect with a buffer size of 100.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_68\n\nLANGUAGE: python\nCODE:\n```\nn,line_batch = next(iter(dataset))\nprint(n.numpy())\n```\n\n----------------------------------------\n\nTITLE: Evaluating Speech Recognition Model on Validation Dataset\nDESCRIPTION: This snippet runs the evaluation on the validation dataset, decoding predictions and references, and adding them to the WER metric for computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom tqdm.auto import tqdm\n\nfor speech, labels in tqdm(val_dataset, total=num_val_batches):\n    predictions  = eval_fwd(speech)\n    predictions = [tokenizer.decode(pred) for pred in predictions.numpy().tolist()]\n    references = [tokenizer.decode(label, group_tokens=False) for label in labels.numpy().tolist()]\n    metric.add_batch(references=references, predictions=predictions)\n```\n\n----------------------------------------\n\nTITLE: Applying Element-wise Operations on Sparse Tensors in TensorFlow\nDESCRIPTION: This code shows how to perform element-wise operations on non-zero values in sparse tensors using tf.sparse.map_values. It adds 5 to all non-zero values in the sparse tensor st2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nst2_plus_5 = tf.sparse.map_values(tf.add, st2, 5)\nprint(tf.sparse.to_dense(st2_plus_5))\n```\n\n----------------------------------------\n\nTITLE: Defining CNN Model Architecture\nDESCRIPTION: Creates and compiles a CNN model using Keras Sequential API within distribution strategy scope\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10)\n  ])\n\n  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Implementing Iterator Checkpointing in TensorFlow\nDESCRIPTION: Shows how to save and restore dataset iterator state using tf.train.Checkpoint\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_81\n\nLANGUAGE: python\nCODE:\n```\nrange_ds = tf.data.Dataset.range(20)\n\niterator = iter(range_ds)\nckpt = tf.train.Checkpoint(step=tf.Variable(0), iterator=iterator)\nmanager = tf.train.CheckpointManager(ckpt, '/tmp/my_ckpt', max_to_keep=3)\n\nprint([next(iterator).numpy() for _ in range(5)])\n\nsave_path = manager.save()\n\nprint([next(iterator).numpy() for _ in range(5)])\n\nckpt.restore(manager.latest_checkpoint)\n\nprint([next(iterator).numpy() for _ in range(5)])\n```\n\n----------------------------------------\n\nTITLE: Converting Dense Tensor to Sparse Tensor in TensorFlow\nDESCRIPTION: This code snippet demonstrates the conversion of a dense tensor to a sparse tensor using tf.sparse.from_dense. It creates a sparse representation of a 3x4 matrix with specific non-zero values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nst2 = tf.sparse.from_dense([[1, 0, 0, 8], [0, 0, 0, 0], [0, 0, 3, 0]])\nprint(pprint_sparse_tensor(st2))\n```\n\n----------------------------------------\n\nTITLE: Handling Unknown Rank TensorShape in TF2\nDESCRIPTION: Shows how to safely access dimension methods when working with shapes of unknown rank in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nshape = tf.TensorShape(None)\n\nif shape:\n  dim = shape.dims[i]\n  dim.is_compatible_with(other_dim) # or any other dimension method\n```\n\n----------------------------------------\n\nTITLE: Implementing Test Step Function\nDESCRIPTION: Defines the test step function for model evaluation during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef test_step(images, labels):\n  predictions = model(images, training=False)\n  t_loss = loss_object(labels, predictions)\n\n  test_loss(t_loss)\n  test_accuracy(labels, predictions)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Required Libraries\nDESCRIPTION: Imports essential libraries for the tutorial, including TensorFlow and Pandas for data manipulation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Device Placement in TensorFlow\nDESCRIPTION: Shows how to specify device placement for TensorFlow operations using device specifications. Demonstrates the format for device specifications including job name, task index, and device type/index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Operations created outside either context will run on the \"best possible\"\n# device. For example, if you have a GPU and a CPU available, and the operation\n```\n\n----------------------------------------\n\nTITLE: Compiling Model with Optimizer Configuration\nDESCRIPTION: Configures the model training process by setting the optimizer and loss function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nhorsepower_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n    loss='mean_absolute_error')\n```\n\n----------------------------------------\n\nTITLE: Training the Model with Dictionary Features\nDESCRIPTION: Trains the model by passing the dictionary of features as x and the labels as y, leveraging the integrated preprocessing pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntitanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Batching a TensorFlow Dataset containing RaggedTensors\nDESCRIPTION: Shows how to combine consecutive elements in a dataset containing RaggedTensors into batches using the Dataset.batch method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nbatched_dataset = dataset.batch(2)\nprint_dictionary_dataset(batched_dataset)\n```\n\n----------------------------------------\n\nTITLE: Creating a Hybrid Sharded/Replicated DTensor in TensorFlow\nDESCRIPTION: Example showing how to create a 3x2 DTensor with a hybrid layout - sharded along the first axis (mesh dimension 'x') but replicated along the second axis. This demonstrates partial sharding strategies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nhybrid_sharded_dtensor = dtensor_from_array(\n    tf.reshape(tf.range(6), (3, 2)),\n    layout=dtensor.Layout(['x', dtensor.UNSHARDED], mesh))\n\nfor component_tensor in dtensor.unpack(hybrid_sharded_dtensor):\n  print(\"Device:\", component_tensor.device, \",\", component_tensor)\n```\n\n----------------------------------------\n\nTITLE: Defining Data Processing and Model Functions for TF1 Estimator\nDESCRIPTION: Sets up functions for MNIST data normalization, input pipeline creation, and model definition to be used with tf.estimator.Estimator in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef normalize_img(image, label):\n  return tf.cast(image, tf.float32) / 255., label\n\ndef _input_fn():\n  ds_train = tfds.load(\n    name='mnist',\n    split='train',\n    shuffle_files=True,\n    as_supervised=True)\n\n  ds_train = ds_train.map(\n      normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n  ds_train = ds_train.batch(128)\n  ds_train = ds_train.repeat(100)\n  return ds_train\n\ndef _eval_input_fn():\n  ds_test = tfds.load(\n    name='mnist',\n    split='test',\n    shuffle_files=True,\n    as_supervised=True)\n  ds_test = ds_test.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n  ds_test = ds_test.batch(128)\n  return ds_test\n\ndef _model_fn(features, labels, mode):\n  flatten = tf1.layers.Flatten()(features)\n  features = tf1.layers.Dense(128, 'relu')(flatten)\n  logits = tf1.layers.Dense(10)(features)\n\n  loss = tf1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.005)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n\n  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset Input Function\nDESCRIPTION: Defines a reusable input function that converts features and labels into a TensorFlow Dataset with appropriate batching and shuffling for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef input_fn(features, labels, training=True, batch_size=256):\n    \"\"\"An input function for training or evaluating\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle and repeat if you are in training mode.\n    if training:\n        dataset = dataset.shuffle(1000).repeat()\n    \n    return dataset.batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Implementing Identity Loss\nDESCRIPTION: Calculates the identity loss which ensures that if an image of the target domain is provided to the generator, it should output the same image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef identity_loss(real_image, same_image):\n  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n  return LAMBDA * 0.5 * loss\n```\n\n----------------------------------------\n\nTITLE: Embedding Lookup for Skip-gram Model in Python\nDESCRIPTION: Retrieves the embedding vectors for each input word in the batch using tf.nn.embedding_lookup, which pulls rows from the embedding matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nembed = tf.nn.embedding_lookup(embeddings, train_inputs)\n```\n\n----------------------------------------\n\nTITLE: Defining Early Stopping Callback for Model Training in Python\nDESCRIPTION: This snippet defines a function that returns an EarlyStopping callback. It monitors the validation precision-recall curve (PRC) and stops training if it doesn't improve for 10 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nEPOCHS = 100\nBATCH_SIZE = 2048\n\ndef early_stopping():\n return tf.keras.callbacks.EarlyStopping(\n    monitor='val_prc',\n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Stack Overflow Dataset in Text Classification Exercise\nDESCRIPTION: Illustrates the directory structure of the Stack Overflow dataset used in the multi-class classification exercise. Shows how the data is organized by programming language tags in separate folders.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: text\nCODE:\n```\ntrain/\n...python/\n......0.txt\n......1.txt\n...javascript/\n......0.txt\n......1.txt\n...csharp/\n......0.txt\n......1.txt\n...java/\n......0.txt\n......1.txt\n```\n\n----------------------------------------\n\nTITLE: Creating Data Parallel Mesh and Model in Python\nDESCRIPTION: Sets up a data parallel mesh with a single 'batch' dimension and creates an MLP model with fully replicated (unsharded) layouts for data parallel training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\n\nmodel = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),\n             dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),])\n```\n\n----------------------------------------\n\nTITLE: Instantiating TF1 Hub Module\nDESCRIPTION: Creates a hub.Module object from a path to import a TF1 Hub format model into a TensorFlow program.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tf1_hub_module.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nm = hub.Module(\"path/to/a/module_dir\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Number of Available Devices\nDESCRIPTION: Prints the number of devices (replicas) that will be used for synchronous training with the MirroredStrategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from RaggedTensors\nDESCRIPTION: Demonstrates how to build a tf.data.Dataset from RaggedTensors using the Dataset.from_tensor_slices method, which is similar to creating datasets from regular tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(feature_tensors)\nprint_dictionary_dataset(dataset)\n```\n\n----------------------------------------\n\nTITLE: Loading IMDB Dataset\nDESCRIPTION: Downloads and loads the IMDB dataset with a vocabulary limited to the top 10,000 most frequent words\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimdb = keras.datasets.imdb\n\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for CSV Data Processing in TensorFlow\nDESCRIPTION: This snippet imports the necessary libraries for working with CSV data in TensorFlow, including pandas for data manipulation, numpy for numerical operations, and TensorFlow with Keras layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport numpy as np\n\n# Make numpy values easier to read.\nnp.set_printoptions(precision=3, suppress=True)\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Trained Model\nDESCRIPTION: Code to generate predictions for new data using the trained classifier.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Generate predictions from the model\nexpected = ['Setosa', 'Versicolor', 'Virginica']\npredict_x = {\n    'SepalLength': [5.1, 5.9, 6.9],\n    'SepalWidth': [3.3, 3.0, 3.1],\n    'PetalLength': [1.7, 4.2, 5.4],\n    'PetalWidth': [0.5, 1.5, 2.1],\n}\n\npredictions = classifier.predict(\n    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n                                            batch_size=args.batch_size))\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Text and Speech Data\nDESCRIPTION: Defines functions to preprocess text and speech data using the Wav2Vec2Processor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom wav2vec2 import Wav2Vec2Processor\ntokenizer = Wav2Vec2Processor(is_tokenizer=True)\nprocessor = Wav2Vec2Processor(is_tokenizer=False)\n\ndef preprocess_text(text):\n  label = tokenizer(text)\n  return tf.constant(label, dtype=tf.int32)\n\ndef preprocess_speech(audio):\n  audio = tf.constant(audio, dtype=tf.float32)\n  return processor(tf.transpose(audio))\n```\n\n----------------------------------------\n\nTITLE: Measuring Matrix Multiplication Performance in TensorFlow\nDESCRIPTION: This code snippet defines a function to measure the time taken for matrix multiplication operations in TensorFlow. It demonstrates how to control device placement (CPU/GPU) and includes considerations for accurate timing in GPU computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\ndef measure(x, steps):\n  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n  tf.matmul(x, x)\n  start = time.time()\n  for i in range(steps):\n    x = tf.matmul(x, x)\n  # tf.matmul can return before completing the matrix multiplication\n  # (e.g., can return after enqueing the operation on a CUDA stream).\n  # The x.numpy() call below will ensure that all enqueued operations\n  # have completed (and will also copy the result to host memory,\n  # so we're including a little more than just the matmul operation\n  # time).\n  _ = x.numpy()\n  end = time.time()\n  return end - start\n\nshape = (1000, 1000)\nsteps = 200\nprint(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n\n# Run on CPU:\nwith tf.device(\"/cpu:0\"):\n  print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n```\n\n----------------------------------------\n\nTITLE: Performing Operations on TensorFlow Variables\nDESCRIPTION: This snippet shows various operations that can be performed on TensorFlow variables, including shape and dtype inspection, conversion to NumPy arrays, and tensor operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Shape: \", my_variable.shape)\nprint(\"DType: \", my_variable.dtype)\nprint(\"As NumPy: \", my_variable.numpy())\n\nprint(\"A variable:\", my_variable)\nprint(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\nprint(\"\\nIndex of highest value:\", tf.math.argmax(my_variable))\n\n# This creates a new tensor; it does not reshape the variable.\nprint(\"\\nCopying and reshaping: \", tf.reshape(my_variable, [1,4]))\n```\n\n----------------------------------------\n\nTITLE: Using the TF1 to TF2 Checkpoint Conversion Function\nDESCRIPTION: This code demonstrates how to use the convert_tf1_to_tf2 function to convert a TensorFlow 1 checkpoint to TensorFlow 2 format and then load the converted checkpoint. It prints the checkpoint content before and after conversion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Make sure to run the snippet in `Save a TF1 checkpoint in TF2`.\nprint_checkpoint('tf1-ckpt-saved-in-eager')\nconverted_path = convert_tf1_to_tf2('tf1-ckpt-saved-in-eager', \n                                     'converted-tf1-to-tf2')\nprint(\"\\n[Converted]\")\nprint_checkpoint(converted_path)\n\n# Try loading the converted checkpoint.\na = tf.Variable(0.)\nb = tf.Variable(0.)\nc = tf.Variable(0.)\nckpt = tf.train.Checkpoint(vars={'a': a, 'b': b, 'scoped/c': c})\nckpt.restore(converted_path).assert_consumed()\nprint(\"\\nRestored [a, b, c]: \", [a.numpy(), b.numpy(), c.numpy()])\n```\n\n----------------------------------------\n\nTITLE: Implementing CPU OpKernel and Registration in C++\nDESCRIPTION: Main implementation file containing CPU kernel specialization, OpKernel definition, and kernel registration for both CPU and GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_4\n\nLANGUAGE: c++\nCODE:\n```\n// kernel_example.cc\n#include \"kernel_example.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nusing CPUDevice = Eigen::ThreadPoolDevice;\nusing GPUDevice = Eigen::GpuDevice;\n\n// CPU specialization of actual computation.\ntemplate <typename T>\nstruct ExampleFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, int size, const T* in, T* out) {\n    for (int i = 0; i < size; ++i) {\n      out[i] = 2 * in[i];\n    }\n  }\n};\n\n// OpKernel definition.\n// template parameter <T> is the datatype of the tensors.\ntemplate <typename Device, typename T>\nclass ExampleOp : public OpKernel {\n public:\n  explicit ExampleOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n\n    // Do the computation.\n    OP_REQUIRES(context, input_tensor.NumElements() <= tensorflow::kint32max,\n                errors::InvalidArgument(\"Too many elements in tensor\"));\n    ExampleFunctor<Device, T>()()\n        context->eigen_device<Device>(),\n        static_cast<int>(input_tensor.NumElements()),\n        input_tensor.flat<T>().data(),\n        output_tensor->flat<T>().data());\n  }\n};\n\n// Register the CPU kernels.\n#define REGISTER_CPU(T)                                          \\\n  REGISTER_KERNEL_BUILDER(                                       \\\n      Name(\"Example\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      ExampleOp<CPUDevice, T>);\nREGISTER_CPU(float);\nREGISTER_CPU(int32);\n\n// Register the GPU kernels.\n#ifdef GOOGLE_CUDA\n#define REGISTER_GPU(T)                                          \\\n  /* Declare explicit instantiations in kernel_example.cu.cc. */ \\\n  extern template ExampleFunctor<GPUDevice, T>;                  \\\n  REGISTER_KERNEL_BUILDER(                                       \\\n      Name(\"Example\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n      ExampleOp<GPUDevice, T>);\nREGISTER_GPU(float);\nREGISTER_GPU(int32);\n#endif  // GOOGLE_CUDA\n```\n\n----------------------------------------\n\nTITLE: Initializing TextVectorization Layer for Integer Mode in TensorFlow\nDESCRIPTION: Creates a TextVectorization layer with integer output mode, maximum vocabulary size of 10000 tokens, and a maximum sequence length of 250.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nMAX_SEQUENCE_LENGTH = 250\n\nint_vectorize_layer = TextVectorization(\n    max_tokens=VOCAB_SIZE,\n    output_mode='int',\n    output_sequence_length=MAX_SEQUENCE_LENGTH)\n```\n\n----------------------------------------\n\nTITLE: Plotting Semantic Similarity\nDESCRIPTION: Defines functions to plot semantic similarity between sentences using a heatmap visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef plot_similarity(labels, features, rotation):\n  corr = np.inner(features, features)\n  sns.set(font_scale=1.2)\n  g = sns.heatmap(\n      corr,\n      xticklabels=labels,\n      yticklabels=labels,\n      vmin=0,\n      vmax=1,\n      cmap=\"YlOrRd\")\n  g.set_xticklabels(labels, rotation=rotation)\n  g.set_title(\"Semantic Textual Similarity\")\n\ndef run_and_plot(messages_):\n  message_embeddings_ = embed(messages_)\n  plot_similarity(messages_, message_embeddings_, 90)\n```\n\n----------------------------------------\n\nTITLE: Implementing CompressibleConv2D Layer with Fourier Domain Reparameterization\nDESCRIPTION: Extends a custom convolutional layer with Fourier domain reparameterization. It stores kernels in the Fourier domain, applies per-frequency quantization with trainable step sizes, and adds regularization losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nclass CompressibleConv2D(CustomConv2D):\n\n  def __init__(self, regularizer, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.regularizer = regularizer\n\n  def build(self, input_shape, other=None):\n    \"\"\"Instantiates weights, optionally initializing them from `other`.\"\"\"    \n    super().build(input_shape, other=other)\n    if other is not None and hasattr(other, \"kernel_log_step\"):\n      kernel_log_step = other.kernel_log_step\n      bias_log_step = other.bias_log_step\n    else:\n      kernel_log_step = tf.fill(self.kernel_latent.shape[2:], -4.)\n      bias_log_step = -4.\n    self.kernel_log_step = tf.Variable(\n        tf.cast(kernel_log_step, self.variable_dtype), name=\"kernel_log_step\")\n    self.bias_log_step = tf.Variable(\n        tf.cast(bias_log_step, self.variable_dtype), name=\"bias_log_step\")\n    self.add_loss(lambda: self.regularizer(\n        self.kernel_latent / tf.exp(self.kernel_log_step)))\n    self.add_loss(lambda: self.regularizer(\n        self.bias_latent / tf.exp(self.bias_log_step)))\n\n  @property\n  def kernel(self):\n    kernel_rdft = quantize(self.kernel_latent, self.kernel_log_step)\n    return from_rdft(kernel_rdft, self.kernel_size)\n\n  @kernel.setter\n  def kernel(self, kernel):\n    kernel_rdft = to_rdft(kernel, self.kernel_size)\n    self.kernel_latent = tf.Variable(kernel_rdft, name=\"kernel_latent\")\n\n  @property\n  def bias(self):\n    return quantize(self.bias_latent, self.bias_log_step)\n\n  @bias.setter\n  def bias(self, bias):\n    self.bias_latent = tf.Variable(bias, name=\"bias_latent\")\n```\n\n----------------------------------------\n\nTITLE: Writing TFRecord File with tf.python_io (Python)\nDESCRIPTION: Uses tf.python_io to write structured examples to a TFRecord file, suitable for creating datasets in TFRecord format with protocol buffer messages.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Write the `tf.Example` observations to the file.\nwith tf.python_io.TFRecordWriter(filename) as writer:\n  for i in range(n_observations):\n    example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n    writer.write(example)\n```\n\n----------------------------------------\n\nTITLE: Saving a TensorFlow 1 graph as a SavedModel using SavedModelBuilder\nDESCRIPTION: This snippet demonstrates how to save a TensorFlow 1 graph as a SavedModel using the SavedModelBuilder API. It creates a simple graph that adds 2 to an input, defines a signature, and saves the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nremove_dir(\"saved-model-builder\")\n\nwith tf.Graph().as_default() as g:\n  with tf1.Session() as sess:\n    input = tf1.placeholder(tf.float32, shape=[])\n    output = add_two(input)\n    print(\"add two output: \", sess.run(output, {input: 3.}))\n\n    # Save with SavedModelBuilder\n    builder = tf1.saved_model.Builder('saved-model-builder')\n    sig_def = tf1.saved_model.predict_signature_def(\n        inputs={'input': input},\n        outputs={'output': output})\n    builder.add_meta_graph_and_variables(\n        sess, tags=[\"serve\"], signature_def_map={\n            tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: sig_def\n    })\n    builder.save()\n```\n\n----------------------------------------\n\nTITLE: Using CompatV1BatchNorm in Keras Model with Training Modes in Python\nDESCRIPTION: This snippet demonstrates how to use the CompatV1BatchNorm layer in a Keras model, showing how the 'training' argument affects the behavior of batch normalization in both inference and training modes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Constructing model\")\ninputs = tf.keras.Input(shape=(5, 5, 5))\noutputs = CompatV1BatchNorm()(inputs)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(\"Calling model in inference mode\")\nx = tf.random.normal(shape=(8, 5, 5, 5))\nmodel(x, training=False)\n\nprint(\"Moving average variables before training: \",\n      {var.name: var.read_value() for var in model.non_trainable_variables})\n\nprint(\"calling model in training mode\")\nmodel(x, training=True)\n\nprint(\"Moving average variables after training: \",\n      {var.name: var.read_value() for var in model.non_trainable_variables})\n```\n\n----------------------------------------\n\nTITLE: Training the Medium Model and Storing its History\nDESCRIPTION: Compiles and trains the medium model with three 64-unit hidden layers, then stores its training history for comparison with other architectures in the experiment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nsize_histories['Medium']  = compile_and_fit(medium_model, \"sizes/Medium\")\n```\n\n----------------------------------------\n\nTITLE: Testing the Preprocessing Model\nDESCRIPTION: Demonstrates how to use the preprocessing model on a single example by converting feature dictionary values to arrays and passing them through the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfeatures_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\ntitanic_preprocessing(features_dict)\n```\n\n----------------------------------------\n\nTITLE: Embedding GIF Visualization in TensorFlow Documentation\nDESCRIPTION: Code to embed the generated GIF animation of the model's performance in the documentation. It utilizes TensorFlow documentation visualization tools to display the animation inline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_docs.vis.embed as embed\nembed.embed_file(image_file)\n```\n\n----------------------------------------\n\nTITLE: Setting Static Shape in TensorFlow\nDESCRIPTION: This snippet demonstrates setting a predefined static shape to a tensor after shape inference has failed. It uses the `tf.set_shape` method to override dynamic shape inference results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx = tf.zeros(tf.constant([1,2,3])+1)\nx.shape\n\nTensorShape([Dimension(None), Dimension(None), Dimension(None)])\n\nx.set_shape([2,3,4])\n```\n\n----------------------------------------\n\nTITLE: Generated Python Interface for StringToNumber Op\nDESCRIPTION: Example of the automatically generated Python function signature for the StringToNumber op.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ndef string_to_number(string_tensor, out_type=None, name=None):\n  \"\"\"Converts each string in the input Tensor to the specified numeric type.\n\n  Args:\n    string_tensor: A `Tensor` of type `string`.\n    out_type: An optional `tf.DType` from: `tf.float32, tf.int32`.\n      Defaults to `tf.float32`.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor` of type `out_type`.\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating CentralStorageStrategy for CPU Variables with GPU Operations\nDESCRIPTION: Code to instantiate CentralStorageStrategy, which places variables on CPU and replicates operations across all local GPUs. Updates to replicas are aggregated before being applied to variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncentral_storage_strategy = tf.distribute.experimental.CentralStorageStrategy()\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub Model\nDESCRIPTION: Loads the bird vocalization classifier model from TensorFlow Hub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmodel_handle = \"https://tfhub.dev/google/bird-vocalization-classifier/1\"\nmodel = hub.load(model_handle)\n```\n\n----------------------------------------\n\nTITLE: Using BackupAndRestore with Epoch-Based Saving in TensorFlow\nDESCRIPTION: Implementing BackupAndRestore callback with explicit epoch-based backup frequency. This configuration ensures the model is backed up after every training epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# The training state is backed up at epoch boundaries because `save_freq` is\n# set to `epoch`.\n\ncallbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\nwith strategy.scope():\n  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\nmulti_worker_model.fit(multi_worker_dataset,\n                       epochs=3,\n                       steps_per_epoch=70,\n                       callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Building Custom Op with Bazel\nDESCRIPTION: Bazel build configuration for compiling custom TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\n\ntf_custom_op_library(\n    name = \"zero_out.so\",\n    srcs = [\"zero_out.cc\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Global Variables Initialization\nDESCRIPTION: Initializes all global variables in a TensorFlow session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nsession.run(tf.global_variables_initializer())\n# Now all variables are initialized.\n```\n\n----------------------------------------\n\nTITLE: Consuming Values from an Iterator with Error Handling\nDESCRIPTION: Shows how to consume values from a dataset iterator with proper error handling for end-of-dataset scenarios using try-except blocks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(5)\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\n\nresult = tf.add(next_element, next_element)\n\nsess.run(iterator.initializer)\nprint(sess.run(result))  # ==> \"0\"\nprint(sess.run(result))  # ==> \"2\"\nprint(sess.run(result))  # ==> \"4\"\nprint(sess.run(result))  # ==> \"6\"\nprint(sess.run(result))  # ==> \"8\"\ntry:\n  sess.run(result)\nexcept tf.errors.OutOfRangeError:\n  print(\"End of dataset\")\n```\n\n----------------------------------------\n\nTITLE: Converting Assert Statements with AutoGraph\nDESCRIPTION: Shows how Python assert statements are automatically converted to tf.Assert operations in the graph. This example checks for non-zero inputs before calculating the inverse.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=(\n        tf.autograph.experimental.Feature.ASSERT_STATEMENTS,\n        tf.autograph.experimental.Feature.EQUALITY_OPERATORS))\ndef inverse(x):\n  assert x != 0.0, 'Do not pass zero!'\n  return 1.0 / x\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n  try:\n    print(sess.run(inverse(tf.constant(0.0))))\n  except tf.errors.InvalidArgumentError as e:\n    print('Got error message:\\n    %s' % e.message)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Files in a tf.data.Dataset\nDESCRIPTION: Displays the first five file paths from the dataset to verify content. Useful for debugging and understanding the dataset structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfor f in list_ds.take(5):\n  print(f.numpy())\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Estimator in Python\nDESCRIPTION: Example of calling the train method on a TensorFlow Estimator to train a model with a specified input function and number of steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# `input_fn` is the function created in Step 1\nestimator.train(input_fn=my_training_set, steps=2000)\n```\n\n----------------------------------------\n\nTITLE: Loading FLAC Audio Files\nDESCRIPTION: Defines a function to read FLAC audio files and ensure they have the required sample rate of 16000 Hz.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport soundfile as sf\n\nREQUIRED_SAMPLE_RATE = 16000\n\ndef read_flac_file(file_path):\n  with open(file_path, \"rb\") as f:\n      audio, sample_rate = sf.read(f)\n  if sample_rate != REQUIRED_SAMPLE_RATE:\n      raise ValueError(\n          f\"sample rate (={sample_rate}) of your files must be {REQUIRED_SAMPLE_RATE}\"\n      )\n  file_id = os.path.split(file_path)[-1][:-len(\".flac\")]\n  return {file_id: audio}\n```\n\n----------------------------------------\n\nTITLE: Tiled Gradient Computation Class for Deep Dream\nDESCRIPTION: Implements a TensorFlow module for computing gradients on image tiles to handle large images efficiently. Includes random rolling and gradient normalization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass TiledGradients(tf.Module):\n  def __init__(self, model):\n    self.model = model\n\n  @tf.function(\n      input_signature=(\n        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n        tf.TensorSpec(shape=[2], dtype=tf.int32),\n        tf.TensorSpec(shape=[], dtype=tf.int32),)\n  )\n  def __call__(self, img, img_size, tile_size=512):\n    shift, img_rolled = random_roll(img, tile_size)\n\n    # Initialize the image gradients to zero.\n    gradients = tf.zeros_like(img_rolled)\n    \n    # Skip the last tile, unless there's only one tile.\n    xs = tf.range(0, img_size[1], tile_size)[:-1]\n    if not tf.cast(len(xs), bool):\n      xs = tf.constant([0])\n    ys = tf.range(0, img_size[0], tile_size)[:-1]\n    if not tf.cast(len(ys), bool):\n      ys = tf.constant([0])\n\n    for x in xs:\n      for y in ys:\n        # Calculate the gradients for this tile.\n        with tf.GradientTape() as tape:\n          # This needs gradients relative to `img_rolled`.\n          # `GradientTape` only watches `tf.Variable`s by default.\n          tape.watch(img_rolled)\n\n          # Extract a tile out of the image.\n          img_tile = img_rolled[y:y+tile_size, x:x+tile_size]\n          loss = calc_loss(img_tile, self.model)\n\n        # Update the image gradients for this tile.\n        gradients = gradients + tape.gradient(loss, img_rolled)\n\n    # Undo the random shift applied to the image and its gradients.\n    gradients = tf.roll(gradients, shift=-shift, axis=[0,1])\n\n    # Normalize the gradients.\n    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n\n    return gradients\n```\n\n----------------------------------------\n\nTITLE: Loading Titanic Dataset\nDESCRIPTION: Loading training and evaluation datasets from TensorFlow's storage and preparing target variables\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\ndfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\ny_train = dftrain.pop('survived')\ny_eval = dfeval.pop('survived')\n```\n\n----------------------------------------\n\nTITLE: Reading Tensor from Image File in TensorFlow\nDESCRIPTION: This C++ function reads an image file, decodes the image, resizes it to the expected dimensions, and scales pixel values according to specified mean and std parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_5\n\nLANGUAGE: C++\nCODE:\n```\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector<Tensor>* out_tensors) {\n  tensorflow::GraphDefBuilder b;\n```\n\n----------------------------------------\n\nTITLE: Nesting Keras Layers in TF1.x-style Variables with get_or_create_layer in Python\nDESCRIPTION: This code demonstrates how to nest Keras layers within a model using TF1.x-style variable tracking. It uses tf.compat.v1.keras.utils.get_or_create_layer to ensure proper reuse and tracking of nested layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass NestedModel(tf.keras.Model):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n\n  def build_model(self):\n    inp = tf.keras.Input(shape=(5, 5))\n    dense_layer = tf.keras.layers.Dense(\n        10, name=\"dense\", kernel_regularizer=\"l2\",\n        kernel_initializer=tf.compat.v1.ones_initializer())\n    model = tf.keras.Model(inputs=inp, outputs=dense_layer(inp))\n    return model\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    # Get or create a nested model without assigning it as an explicit property\n    model = tf.compat.v1.keras.utils.get_or_create_layer(\n        \"dense_model\", self.build_model)\n    return model(inputs)\n\nlayer = NestedModel(10)\nlayer(tf.ones(shape=(5,5)))\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom __repr__ for ExtensionType in Python\nDESCRIPTION: Shows how to override the default __repr__ method in an ExtensionType class to provide a custom string representation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  \"\"\"A tensor paired with a boolean mask, indicating which values are valid.\"\"\"\n  values: tf.Tensor\n  mask: tf.Tensor       # shape=values.shape; false for invalid values.\n\n  def __repr__(self):\n    return masked_tensor_str(self.values, self.mask)\n\ndef masked_tensor_str(values, mask):\n  if isinstance(values, tf.Tensor):\n    if hasattr(values, 'numpy') and hasattr(mask, 'numpy'):\n      return f'<MaskedTensor {masked_tensor_str(values.numpy(), mask.numpy())}>' \n    else:\n      return f'MaskedTensor(values={values}, mask={mask})'\n  if len(values.shape) == 1:\n    items = [repr(v) if m else '_' for (v, m) in zip(values, mask)]\n  else:\n    items = [masked_tensor_str(v, m) for (v, m) in zip(values, mask)]\n  return '[%s]' % ', '.join(items)\n\nmt = MaskedTensor(values=[[1, 2, 3], [4, 5, 6]],\n                  mask=[[True, True, False], [True, False, True]])\nprint(mt)\n```\n\n----------------------------------------\n\nTITLE: Creating CSV Dataset with Selected Columns in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a CSV dataset with only selected columns using tf.data.experimental.make_csv_dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_47\n\nLANGUAGE: python\nCODE:\n```\ntitanic_batches = tf.data.experimental.make_csv_dataset(\n    titanic_file, batch_size=4,\n    label_name=\"survived\", select_columns=['class', 'fare', 'survived'])\n```\n\n----------------------------------------\n\nTITLE: Comparing predictions between original and reloaded models\nDESCRIPTION: Makes predictions using both the original and reloaded models to verify they produce the same outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nresult_batch = model.predict(image_batch)\nreloaded_result_batch = reloaded.predict(image_batch)\n```\n\n----------------------------------------\n\nTITLE: Training Decompressed Classifier with Penalty and Comparing Accuracy in Python\nDESCRIPTION: This snippet trains the decompressed classifier with compression penalty for one epoch and compares its accuracy with the original compressed classifier. It demonstrates how maintaining regularization during further training can improve model accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ndecompressed_accuracy = train_model(\n    decompressed_classifier, training_dataset, validation_dataset, epochs=1)\n\nprint(f\"Accuracy of the compressed classifier: {compressed_accuracy:0.4f}\")\nprint(f\"Accuracy of the decompressed classifier after one more epoch of training: {decompressed_accuracy:0.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Reading TFRecord File via tf.python_io (Python)\nDESCRIPTION: Illustrates reading TFRecord file using tf.python_io to process TF.Example messages, useful for verifying stored data or converting to another format like NumPy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nrecord_iterator = tf.python_io.tf_record_iterator(path=filename)\n\nfor string_record in record_iterator:\n  example = tf.train.Example()\n  example.ParseFromString(string_record)\n\n  print(example)\n\n  # Exit after 1 iteration as this is purely demonstrative.\n  break\n```\n\n----------------------------------------\n\nTITLE: Model Configuration Setup\nDESCRIPTION: Defining core model parameters including vocabulary size and embedding dimensions\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembedding_dim = 256\n```\n\n----------------------------------------\n\nTITLE: Loading Kinetics 600 labels for MoViNet classification\nDESCRIPTION: Downloads and processes the label list for the Kinetics 600 dataset, which contains 600 human action classes used by the MoViNet model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlabels_path = tf.keras.utils.get_file(\n    fname='labels.txt',\n    origin='https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt'\n)\nlabels_path = pathlib.Path(labels_path)\n\nlines = labels_path.read_text().splitlines()\nKINETICS_600_LABELS = np.array([line.strip() for line in lines])\nKINETICS_600_LABELS[:20]\n```\n\n----------------------------------------\n\nTITLE: Training MoViNet Model in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to train the compiled MoViNet model using the fit method. It specifies the training and validation datasets, number of epochs, and validation frequency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresults = model.fit(train_ds,\n                    validation_data=test_ds,\n                    epochs=num_epochs,\n                    validation_freq=1,\n                    verbose=1)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Linear Model using tf.Module\nDESCRIPTION: Creates a custom linear regression model by subclassing tf.Module. The model initializes weight and bias variables and implements the forward pass computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyModel(tf.Module):\n  def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n    # Initialize the weights to `5.0` and the bias to `0.0`\n    # In practice, these should be randomly initialized\n    self.w = tf.Variable(5.0)\n    self.b = tf.Variable(0.0)\n\n  def __call__(self, x):\n    return self.w * x + self.b\n\nmodel = MyModel()\n\n# List the variables tf.modules's built-in variable aggregation.\nprint(\"Variables:\", model.variables)\n\n# Verify the model works\nassert model(3.0).numpy() == 15.0\n```\n\n----------------------------------------\n\nTITLE: Creating In-Process Cluster for TensorFlow Parameter Server Training\nDESCRIPTION: This function sets up an in-process cluster for demonstration purposes, creating TensorFlow servers for workers and parameter servers. It returns a SimpleClusterResolver object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndef create_in_process_cluster(num_workers, num_ps):\n  \"\"\"Creates and starts local servers and returns the cluster_resolver.\"\"\"\n  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]\n  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]\n\n  cluster_dict = {}\n  cluster_dict[\"worker\"] = [\"localhost:%s\" % port for port in worker_ports]\n  if num_ps > 0:\n    cluster_dict[\"ps\"] = [\"localhost:%s\" % port for port in ps_ports]\n\n  cluster_spec = tf.train.ClusterSpec(cluster_dict)\n\n  # Workers need some inter_ops threads to work properly.\n  worker_config = tf.compat.v1.ConfigProto()\n  if multiprocessing.cpu_count() < num_workers + 1:\n    worker_config.inter_op_parallelism_threads = num_workers + 1\n\n  for i in range(num_workers):\n    tf.distribute.Server(\n        cluster_spec,\n        job_name=\"worker\",\n        task_index=i,\n        config=worker_config,\n        protocol=\"grpc\")\n\n  for i in range(num_ps):\n    tf.distribute.Server(\n        cluster_spec,\n        job_name=\"ps\",\n        task_index=i,\n        protocol=\"grpc\")\n\n  cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(\n      cluster_spec, rpc_layer=\"grpc\")\n  return cluster_resolver\n\n# Set the environment variable to allow reporting worker and ps failure to the\n# coordinator. This is a workaround and won't be necessary in the future.\nos.environ[\"GRPC_FAIL_FAST\"] = \"use_caller\"\n\nNUM_WORKERS = 3\nNUM_PS = 2\ncluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)\n```\n\n----------------------------------------\n\nTITLE: NumPy-based Dataset Balancing\nDESCRIPTION: Implements manual dataset balancing using NumPy by randomly sampling from positive examples to match negative example count.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[choices]\nres_pos_labels = pos_labels[choices]\n\nres_pos_features.shape\n```\n\n----------------------------------------\n\nTITLE: Loading SavedModel in TensorFlow 2\nDESCRIPTION: This function demonstrates how to load a SavedModel in TensorFlow 2 using tf.saved_model.load and run inference using the loaded model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef load_tf2(path, input):\n  print('Loading from', path)\n  loaded = tf.saved_model.load(path)\n  out = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY](\n      tf.constant(input))['output']\n  print('  Output with input', input, ': ', out)\n\nload_tf2('saved-model-builder', 5.)\nload_tf2('simple-save', 5.)\nload_tf2('estimator-model', [5.])  # Estimator's input must be batched.\nload_tf2('tf2-save', 5.)\nload_tf2('keras-model', 5.)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Training Results\nDESCRIPTION: This snippet plots the training results to visualize how the weights and bias evolve over the training epochs. It's an essential step to verify that the model is learning appropriately.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(epochs, Ws, 'r',\n         epochs, bs, 'b')\nplt.plot([TRUE_W] * len(epochs), 'r--',\n         [TRUE_b] * len(epochs), 'b--')\nplt.legend(['W', 'b', 'true W', 'true_b'])\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Inspecting CSV Dataset Features\nDESCRIPTION: This code examines the first batch of the font dataset, displaying the first 15 features to understand the structure of the data. The CSV files have images flattened into a single row with column names formatted as r{row}c{column}.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nfor features in fonts_ds.take(1):\n  for i, (name, value) in enumerate(features.items()):\n    if i>15:\n      break\n    print(f\"{name:20s}: {value}\")\nprint('...')\nprint(f\"[total: {len(features)} features]\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorBoard Logs Directory in Python\nDESCRIPTION: This snippet creates a temporary directory for TensorBoard logs and removes any existing logs in that directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nlogdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\nshutil.rmtree(logdir, ignore_errors=True)\n```\n\n----------------------------------------\n\nTITLE: Passing Inputs Using Python Expressions\nDESCRIPTION: Demonstrates how to pass inputs to the 'run' command using Python expressions, including numpy functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n`<input_key>=[[1],[2],[3]]`\n```\n\nLANGUAGE: python\nCODE:\n```\n`<input_key>=np.ones((32,32,3))`\n```\n\n----------------------------------------\n\nTITLE: Starting an Interactive TensorFlow Session in Python\nDESCRIPTION: Initiates an interactive TensorFlow session, providing an environment that allows for easier manipulation of tensors during simulations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsess = tf.InteractiveSession()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Quantization with Straight-Through Gradients\nDESCRIPTION: Defines a quantization function that uses straight-through gradient estimation to make the quantization operation differentiable during training. This allows the network to learn optimal quantization parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef quantize(latent, log_step):\n  step = tf.exp(log_step)\n  return tfc.round_st(latent / step) * step\n```\n\n----------------------------------------\n\nTITLE: Configuring Thread Pools for CPU Optimization in TensorFlow\nDESCRIPTION: Code snippet demonstrating how to configure intra_op and inter_op parallelism threads to optimize CPU performance in TensorFlow. This configuration is passed to the tf.Session via tf.ConfigProto.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nconfig = tf.ConfigProto()\nconfig.intra_op_parallelism_threads = 44\nconfig.inter_op_parallelism_threads = 44\ntf.Session(config=config)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from NumPy Arrays\nDESCRIPTION: Demonstrates how to normalize image data and create a dataset from the images and labels using from_tensor_slices, which is useful for smaller datasets that fit in memory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimages, labels = train\nimages = images/255\n\ndataset = tf.data.Dataset.from_tensor_slices((images, labels))\ndataset\n```\n\n----------------------------------------\n\nTITLE: Multi-Worker Training with tf.estimator in TensorFlow 1\nDESCRIPTION: Demonstrates the workflow for multi-worker training in TF1 using tf.estimator.Estimator, TrainSpec, EvalSpec, and train_and_evaluate API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n\ndef _eval_input_fn():\n  return tf1.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\ndef _model_fn(features, labels, mode):\n  logits = tf1.layers.Dense(1)(features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\ntrain_spec = tf1.estimator.TrainSpec(input_fn=_input_fn)\neval_spec = tf1.estimator.EvalSpec(input_fn=_eval_input_fn)\ntf1.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n```\n\n----------------------------------------\n\nTITLE: Using tf.gather with Non-Sequential Indices\nDESCRIPTION: Demonstrates gathering arbitrary elements from a tensor by specifying non-sequential indices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nalphabet = tf.constant(list('abcdefghijklmnopqrstuvwxyz'))\n\nprint(tf.gather(alphabet,\n                indices=[2, 0, 19, 18]))\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple MLP Model in TensorFlow/Keras\nDESCRIPTION: This code defines a multi-layer perceptron (MLP) model using Keras. The model consists of two dense layers with ReLU activation, followed by a final dense layer with softmax activation. The `input_shape` parameter determines the input dimensions for the first layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef mlp_model(input_shape):\n  model = tf.keras.Sequential((\n      tf.keras.layers.Dense(100, activation='relu', input_shape=input_shape),\n      tf.keras.layers.Dense(100, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')))\n  model.build()\n  return model\n```\n\n----------------------------------------\n\nTITLE: Testing Stochastic Depth Model in Train and Test Modes in TensorFlow\nDESCRIPTION: This snippet tests the `StochasticNetworkDepth` model in both training and testing modes by explicitly setting the learning phase. It demonstrates the effect of stochastic depth by printing the number of layers executed in each mode, which should differ. It uses a `tf.Session` to execute the graph and inspect the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Use an explicit session here so we can set the train/test switch, and\n# inspect the layer count returned by `call`\nwith tf.Session(graph=g) as sess:\n  init.run()\n\n  for phase, name in enumerate(['test','train']):\n    K.set_learning_phase(phase)\n    result, count = model(tf.convert_to_tensor(train_batch, dtype=tf.float32))\n\n    result1, count1 = sess.run((result, count))\n    result2, count2 = sess.run((result, count))\n\n    delta = (result1 - result2)\n    print(name, \"sum abs delta: \", abs(delta).mean())\n    print(\"    layers 1st call: \", count1)\n    print(\"    layers 2nd call: \", count2)\n    print()\n```\n\n----------------------------------------\n\nTITLE: Finding the class with highest prediction probability using NumPy\nDESCRIPTION: Uses NumPy's argmax function to identify which class has the highest predicted probability. Returns the index of the maximum value, which corresponds to the predicted class label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nnp.argmax(predictions[0])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Gradient Disconnection with Integer Types in TensorFlow\nDESCRIPTION: This snippet shows that gradients cannot be computed through integer types in TensorFlow, resulting in None gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(10)\n\nwith tf.GradientTape() as g:\n  g.watch(x)\n  y = x * x\n\nprint(g.gradient(y, x))\n```\n\n----------------------------------------\n\nTITLE: Creating a Resize and Rescale Utility Function\nDESCRIPTION: Defines a utility function that prepares images for model training by converting to float32, resizing to a standard size, and rescaling pixel values to the range [0,1]. This function provides consistent preprocessing for all dataset images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef resize_and_rescale(image, label):\n  image = tf.cast(image, tf.float32)\n  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n  image = (image / 255.0)\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow Model with Validation Data\nDESCRIPTION: This snippet demonstrates how to train a TensorFlow model using the fit method. It specifies the number of epochs, batch size, and includes validation data. The training history is stored for later analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=40,\n                    batch_size=512,\n                    validation_data=(x_val, y_val),\n                    verbose=1)\n```\n\n----------------------------------------\n\nTITLE: Creating a Text Vectorization Function for TensorFlow Datasets\nDESCRIPTION: A helper function that processes text inputs through the TextVectorization layer. It expands the input dimension and returns both the vectorized text and its corresponding label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef vectorize_text(text, label):\n  text = tf.expand_dims(text, -1)\n  return vectorize_layer(text), label\n```\n\n----------------------------------------\n\nTITLE: Defining Mean Squared Error Loss Function in TensorFlow\nDESCRIPTION: This function implements the Mean Squared Error loss function using TensorFlow operations for evaluating the linear regression model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\ndef mse_loss(y_pred, y):\n  return tf.reduce_mean(tf.square(y_pred - y))\n```\n\n----------------------------------------\n\nTITLE: Data Preparation for Titanic Dataset\nDESCRIPTION: Loads and preprocesses the Titanic dataset by converting categorical variables to numerical values and splitting features and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nx_train = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\nx_eval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\nx_train['sex'].replace(('male', 'female'), (0, 1), inplace=True)\nx_eval['sex'].replace(('male', 'female'), (0, 1), inplace=True)\n\nx_train['alone'].replace(('n', 'y'), (0, 1), inplace=True)\nx_eval['alone'].replace(('n', 'y'), (0, 1), inplace=True)\n\nx_train['class'].replace(('First', 'Second', 'Third'), (1, 2, 3), inplace=True)\nx_eval['class'].replace(('First', 'Second', 'Third'), (1, 2, 3), inplace=True)\n\nx_train.drop(['embark_town', 'deck'], axis=1, inplace=True)\nx_eval.drop(['embark_town', 'deck'], axis=1, inplace=True)\n\ny_train = x_train.pop('survived')\ny_eval = x_eval.pop('survived')\n```\n\n----------------------------------------\n\nTITLE: Training Low Latency SVDF Model in TensorFlow\nDESCRIPTION: Command for training a low-latency SVDF model with optimized execution using only 750K parameters and FLOPs. Uses a two-phase training approach with longer training duration but similar overall training time due to reduced computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npython tensorflow/examples/speech_commands/train \\\n--model_architecture=low_latency_svdf \\\n--how_many_training_steps=100000,35000 \\\n--learning_rate=0.01,0.005\n```\n\n----------------------------------------\n\nTITLE: Running Test Function with Debug Stripper Enabled\nDESCRIPTION: This code executes the debug test function with debug stripper optimization turned on, demonstrating how it strips out debugging operations and prevents errors from being raised.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith options({'debug_stripper': True}):\n  test_func2 = test_function_2()\n  p1 = tf.constant(float('inf'))\n  try:\n    test_func2(p1)\n  except tf.errors.InvalidArgumentError as e:\n    traceback.print_exc(limit=2)\n```\n\n----------------------------------------\n\nTITLE: Creating an ExtensionType with Nested Data Structures in Python\nDESCRIPTION: Demonstrates how to create an ExtensionType class with nested data structures, including a mapping of string keys to tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclass Player(tf.experimental.ExtensionType):\n  name: tf.Tensor\n  attributes: Mapping[str, tf.Tensor]\n\nanne = Player(\"Anne\", {\"height\": 8.3, \"speed\": 28.1})\nanne_spec = tf.type_spec_from_value(anne)\nprint(anne_spec.name)  # Records `dtype` and `shape`, but not the string value.\nprint(anne_spec.attributes)  # Records keys and TensorSpecs for values.\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset from Array using TensorFlow (Python)\nDESCRIPTION: Creates a dataset from a single input array using the tf.data.Dataset.from_tensor_slices method, which generates a dataset of scalars.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntf.data.Dataset.from_tensor_slices(feature1)\n```\n\n----------------------------------------\n\nTITLE: Displaying TensorFlow Import Error from Source Directory (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when trying to import TensorFlow from its source directory, which is not the correct way to use TensorFlow unless using Bazel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>Error importing tensorflow. Unless you are using bazel, you should\n  not try to import tensorflow from its source directory; please exit the\n  tensorflow source tree, and relaunch your python interpreter from\n  there.</pre>\n```\n\n----------------------------------------\n\nTITLE: Applying SpectralNormalization in TensorFlow\nDESCRIPTION: Demonstrates how to apply SpectralNormalization wrapper to a Dense layer in TensorFlow. This regularizes the hidden weight by guiding its spectral norm toward a target value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndense = tf.keras.layers.Dense(units=10)\ndense = nlp_layers.SpectralNormalization(dense, norm_multiplier=0.9)\n```\n\n----------------------------------------\n\nTITLE: Import Dependencies for TensorFlow Image Processing\nDESCRIPTION: Imports required libraries including TensorFlow, NumPy, PIL, and TensorFlow Datasets for image processing tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Creating Generator in First MirroredStrategy for Transfer\nDESCRIPTION: Initializes a distribution strategy with two replicas and creates a random generator within it that will be saved for later transfer to a different strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfilename = \"./checkpoint\"\nstrat1 = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat1.scope():\n  g1 = tf.random.Generator.from_seed(1)\n  cp1 = tf.train.Checkpoint(my_generator=g1)\n  print(strat1.run(lambda: g1.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset with TensorFlow Datasets\nDESCRIPTION: Demonstrates how to load the MNIST dataset using TensorFlow Datasets (tfds) and split it into training and testing sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\nmnist_train, mnist_test = datasets['train'], datasets['test']\n```\n\n----------------------------------------\n\nTITLE: Implementing BigBiGAN Class in Python\nDESCRIPTION: Defines a wrapper class for BigBiGAN that provides convenient access to generator, encoder and discriminator functions. Includes methods for image generation, encoding, reconstruction and loss computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass BigBiGAN(object):\n\n  def __init__(self, module):\n    \"\"\"Initialize a BigBiGAN from the given TF Hub module.\"\"\"\n    self._module = module\n\n  def generate(self, z, upsample=False):\n    \"\"\"Run a batch of latents z through the generator to generate images.\n\n    Args:\n      z: A batch of 120D Gaussian latents, shape [N, 120].\n\n    Returns: a batch of generated RGB images, shape [N, 128, 128, 3], range\n      [-1, 1].\n    \"\"\"\n    outputs = self._module(z, signature='generate', as_dict=True)\n    return outputs['upsampled' if upsample else 'default']\n\n  def make_generator_ph(self):\n    \"\"\"Creates a tf.placeholder with the dtype & shape of generator inputs.\"\"\"\n    info = self._module.get_input_info_dict('generate')['z']\n    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n\n  def gen_pairs_for_disc(self, z):\n    \"\"\"Compute generator input pairs (G(z), z) for discriminator, given z.\n\n    Args:\n      z: A batch of latents (120D standard Gaussians), shape [N, 120].\n\n    Returns: a tuple (G(z), z) of discriminator inputs.\n    \"\"\"\n    # Downsample 256x256 image x for 128x128 discriminator input.\n    x = self.generate(z)\n    return x, z\n\n  def encode(self, x, return_all_features=False):\n    \"\"\"Run a batch of images x through the encoder.\n\n    Args:\n      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n        [-1, 1].\n      return_all_features: If True, return all features computed by the encoder.\n        Otherwise (default) just return a sample z_hat.\n\n    Returns: the sample z_hat of shape [N, 120] (or a dict of all features if\n      return_all_features).\n    \"\"\"\n    outputs = self._module(x, signature='encode', as_dict=True)\n    return outputs if return_all_features else outputs['z_sample']\n\n  def make_encoder_ph(self):\n    \"\"\"Creates a tf.placeholder with the dtype & shape of encoder inputs.\"\"\"\n    info = self._module.get_input_info_dict('encode')['x']\n    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n\n  def enc_pairs_for_disc(self, x):\n    \"\"\"Compute encoder input pairs (x, E(x)) for discriminator, given x.\n\n    Args:\n      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n        [-1, 1].\n\n    Returns: a tuple (downsample(x), E(x)) of discriminator inputs.\n    \"\"\"\n    # Downsample 256x256 image x for 128x128 discriminator input.\n    x_down = tf.nn.avg_pool(x, ksize=2, strides=2, padding='SAME')\n    z = self.encode(x)\n    return x_down, z\n\n  def discriminate(self, x, z):\n    \"\"\"Compute the discriminator scores for pairs of data (x, z).\n\n    (x, z) must be batches with the same leading batch dimension, and joint\n      scores are computed on corresponding pairs x[i] and z[i].\n\n    Args:\n      x: A batch of data (128x128 RGB images), shape [N, 128, 128, 3], range\n        [-1, 1].\n      z: A batch of latents (120D standard Gaussians), shape [N, 120].\n\n    Returns:\n      A dict of scores:\n        score_xz: the joint scores for the (x, z) pairs.\n        score_x: the unary scores for x only.\n        score_z: the unary scores for z only.\n    \"\"\"\n    inputs = dict(x=x, z=z)\n    return self._module(inputs, signature='discriminate', as_dict=True)\n\n  def reconstruct_x(self, x, use_sample=True, upsample=False):\n    \"\"\"Compute BigBiGAN reconstructions of images x via G(E(x)).\n\n    Args:\n      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n        [-1, 1].\n      use_sample: takes a sample z_hat ~ E(x). Otherwise, deterministically\n        use the mean. (Though a sample z_hat may be far from the mean z,\n        typically the resulting recons G(z_hat) and G(z) are very\n        similar.\n      upsample: if set, upsample the reconstruction to the input resolution\n        (256x256). Otherwise return the raw lower resolution generator output\n        (128x128).\n\n    Returns: a batch of recons G(E(x)), shape [N, 256, 256, 3] if\n      `upsample`, otherwise [N, 128, 128, 3].\n    \"\"\"\n    if use_sample:\n      z = self.encode(x)\n    else:\n      z = self.encode(x, return_all_features=True)['z_mean']\n    recons = self.generate(z, upsample=upsample)\n    return recons\n\n  def losses(self, x, z):\n    \"\"\"Compute per-module BigBiGAN losses given data & latent sample batches.\n\n    Args:\n      x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n        [-1, 1].\n      z: A batch of latents (120D standard Gaussians), shape [M, 120].\n\n    For the original BigBiGAN losses, pass batches of size N=M=2048, with z's\n    sampled from a 120D standard Gaussian (e.g., np.random.randn(2048, 120)),\n    and x's sampled from the ImageNet (ILSVRC2012) training set with the\n    \"ResNet-style\" preprocessing from:\n\n        https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_preprocessing.py\n\n    Returns:\n      A dict of per-module losses:\n        disc: loss for the discriminator.\n        enc: loss for the encoder.\n        gen: loss for the generator.\n    \"\"\"\n    # Compute discriminator scores on (x, E(x)) pairs.\n    # Downsample 256x256 image x for 128x128 discriminator input.\n    scores_enc_x_dict = self.discriminate(*self.enc_pairs_for_disc(x))\n    scores_enc_x = tf.concat([scores_enc_x_dict['score_xz'],\n                              scores_enc_x_dict['score_x'],\n                              scores_enc_x_dict['score_z']], axis=0)\n\n    # Compute discriminator scores on (G(z), z) pairs.\n    scores_gen_z_dict = self.discriminate(*self.gen_pairs_for_disc(z))\n    scores_gen_z = tf.concat([scores_gen_z_dict['score_xz'],\n                              scores_gen_z_dict['score_x'],\n                              scores_gen_z_dict['score_z']], axis=0)\n\n    disc_loss_enc_x = tf.reduce_mean(tf.nn.relu(1. - scores_enc_x))\n    disc_loss_gen_z = tf.reduce_mean(tf.nn.relu(1. + scores_gen_z))\n    disc_loss = disc_loss_enc_x + disc_loss_gen_z\n\n    enc_loss = tf.reduce_mean(scores_enc_x)\n    gen_loss = tf.reduce_mean(-scores_gen_z)\n\n    return dict(disc=disc_loss, enc=enc_loss, gen=gen_loss)\n```\n\n----------------------------------------\n\nTITLE: Loading TF1 Checkpoint in TensorFlow 2.x\nDESCRIPTION: This snippet demonstrates how to load a TensorFlow 1.x style checkpoint in TensorFlow 2.x eager execution mode. It creates variables, initializes them to zero, and then restores their values from a previously saved TF1 checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(0., name='a')\nb = tf.Variable(0., name='b')\nwith tf.name_scope('scoped'):\n  c = tf.Variable(0., name='c')\nprint(\"Initialized [a, b, c]: \", [a.numpy(), b.numpy(), c.numpy()])\nsaver = tf1.train.Saver(var_list=[a, b, c])\nsaver.restore(sess=None, save_path='tf1-ckpt-saved-in-eager')\nprint(\"Restored [a, b, c]: \", [a.numpy(), b.numpy(), c.numpy()])\n```\n\n----------------------------------------\n\nTITLE: Training a Model with a TensorFlow Dataset\nDESCRIPTION: Shows how to train a model using a tf.data.Dataset instead of separate features and labels, which can be more efficient for large datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ntitanic_model.fit(titanic_batches, epochs=5)\n```\n\n----------------------------------------\n\nTITLE: Adapting TextVectorization Layers to Training Data in TensorFlow\nDESCRIPTION: Fits the state of the TextVectorization layers to the training dataset by building an index of strings to integers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_text = raw_train_ds.map(lambda text, labels: text)\nbinary_vectorize_layer.adapt(train_text)\nint_vectorize_layer.adapt(train_text)\n```\n\n----------------------------------------\n\nTITLE: Adding Classification Head to Base Model - Python\nDESCRIPTION: This snippet adds a classification head on top of the frozen MobileNet V2 base model to adapt it for the specific task of binary classification (cats vs dogs).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  base_model,\n  keras.layers.GlobalAveragePooling2D(),\n  keras.layers.Dense(1, activation='sigmoid')\n])\n```\n\n----------------------------------------\n\nTITLE: Creating OneDeviceStrategy for Single-Device Computation\nDESCRIPTION: Code to create OneDeviceStrategy which places all variables and computation on a single specified device. This is useful for testing distribution code on a single device.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n```\n\n----------------------------------------\n\nTITLE: Concatenating and Slicing Sparse Tensors in TensorFlow\nDESCRIPTION: This code demonstrates concatenation of multiple sparse tensors using tf.sparse.concat and slicing of the resulting sparse tensor using tf.sparse.slice. It creates three sparse patterns and combines them along the second axis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsparse_pattern_A = tf.sparse.SparseTensor(indices = [[2,4], [3,3], [3,4], [4,3], [4,4], [5,4]],\n                         values = [1,1,1,1,1,1],\n                         dense_shape = [8,5])\nsparse_pattern_B = tf.sparse.SparseTensor(indices = [[0,2], [1,1], [1,3], [2,0], [2,4], [2,5], [3,5], \n                                              [4,5], [5,0], [5,4], [5,5], [6,1], [6,3], [7,2]],\n                         values = [1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n                         dense_shape = [8,6])\nsparse_pattern_C = tf.sparse.SparseTensor(indices = [[3,0], [4,0]],\n                         values = [1,1],\n                         dense_shape = [8,6])\n\nsparse_patterns_list = [sparse_pattern_A, sparse_pattern_B, sparse_pattern_C]\nsparse_pattern = tf.sparse.concat(axis=1, sp_inputs=sparse_patterns_list)\nprint(tf.sparse.to_dense(sparse_pattern))\n```\n\n----------------------------------------\n\nTITLE: Initializing Random Input and Dense Layer in TensorFlow\nDESCRIPTION: This snippet creates a random input tensor and initializes a dense layer with ReLU activation. These will be used in subsequent gradient calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.normal([7, 5])\n\nlayer = tf.keras.layers.Dense(10, activation=tf.nn.relu)\n```\n\n----------------------------------------\n\nTITLE: Simple Neural Network Model Using TensorFlow NumPy\nDESCRIPTION: Implements a simple neural network model with ReLU activation and linear projection using TensorFlow NumPy operations, demonstrating how to use TensorFlow NumPy for machine learning applications.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass Model(object):\n  \"\"\"Model with a dense and a linear layer.\"\"\"\n\n  def __init__(self):\n    self.weights = None\n\n  def predict(self, inputs):\n    if self.weights is None:\n      size = inputs.shape[1]\n      # Note that type `tnp.float32` is used for performance.\n      stddev = tnp.sqrt(size).astype(tnp.float32)\n      w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n      bias = tnp.random.randn(64).astype(tnp.float32)\n      w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8\n      self.weights = (w1, bias, w2)\n    else:\n      w1, bias, w2 = self.weights\n    y = tnp.matmul(inputs, w1) + bias\n    y = tnp.maximum(y, 0)  # Relu\n    return tnp.matmul(y, w2)  # Linear projection\n\nmodel = Model()\n# Create input data and compute predictions.\nprint(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))\n```\n\n----------------------------------------\n\nTITLE: Defining TF_CONFIG for Multi-worker Training\nDESCRIPTION: Creating a tf_config dictionary that specifies the cluster configuration with two workers on localhost, with the current worker being the first worker (index 0).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntf_config = {\n    'cluster': {\n        'worker': ['localhost:12345', 'localhost:23456']\n    },\n    'task': {'type': 'worker', 'index': 0}\n}\n```\n\n----------------------------------------\n\nTITLE: Compiling U-Net Model for Multiclass Segmentation in TensorFlow\nDESCRIPTION: This snippet compiles a U-Net model for multiclass image segmentation using Adam optimizer and SparseCategoricalCrossentropy loss. It sets up the model for training on scalar integer labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nOUTPUT_CLASSES = 3\n\nmodel = unet_model(output_channels=OUTPUT_CLASSES)\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Model Architecture\nDESCRIPTION: Creates a custom model class using Keras Model subclassing API with convolutional and dense layers for image classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyModel(Model):\n  def __init__(self):\n    super().__init__()\n    self.conv1 = Conv2D(32, 3, activation='relu')\n    self.flatten = Flatten()\n    self.d1 = Dense(128, activation='relu')\n    self.d2 = Dense(10)\n\n  def call(self, x):\n    x = self.conv1(x)\n    x = self.flatten(x)\n    x = self.d1(x)\n    return self.d2(x)\n\n# Create an instance of the model\nmodel = MyModel()\n```\n\n----------------------------------------\n\nTITLE: Downloading the Auto MPG Dataset (Python)\nDESCRIPTION: This snippet uses the Keras utility function to download the Auto MPG dataset from the UCI Machine Learning Repository and save it locally for further processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\ndataset_path\n```\n\n----------------------------------------\n\nTITLE: Installing and testing TensorFlow Hub pip package\nDESCRIPTION: Commands to install the built TensorFlow Hub pip package and test the import.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npip install /tmp/tensorflow_hub_pkg/*.whl\n```\n\nLANGUAGE: shell\nCODE:\n```\ncd ..  # exit the directory to avoid confusion\n```\n\nLANGUAGE: python\nCODE:\n```\npython -c \"import tensorflow_hub as hub\"\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor with Uniform Non-Inner Dimensions in TensorFlow\nDESCRIPTION: This example shows how to create a ragged tensor with uniform non-inner dimensions using the from_uniform_row_length method. It partitions rows with a uniform row length and prints the tensor's information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_61\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_uniform_row_length(\n    values=tf.RaggedTensor.from_row_splits(\n        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n        row_splits=[0, 3, 5, 9, 10]),\n    uniform_row_length=2)\nprint(rt)\nprint(\"Shape: {}\".format(rt.shape))\nprint(\"Number of partitioned dimensions: {}\".format(rt.ragged_rank))\n```\n\n----------------------------------------\n\nTITLE: Examining and Freezing Base Model Layers in TensorFlow\nDESCRIPTION: This code checks the number of layers in the base model and freezes layers up to a specific index to prepare for fine-tuning. It prevents earlier layers from being updated during training while allowing later layers to be fine-tuned.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable = False\n```\n\n----------------------------------------\n\nTITLE: Constructing Ragged Tensors with from_value_rowids\nDESCRIPTION: Demonstrates how to create a ragged tensor by specifying which row each value belongs to using the from_value_rowids factory method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_value_rowids(\n    values=[3, 1, 4, 1, 5, 9, 2],\n    value_rowids=[0, 0, 0, 0, 2, 2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Model Training\nDESCRIPTION: Trains the model on the prepared datasets for 3 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=3)\n```\n\n----------------------------------------\n\nTITLE: Building LSTM-based Multi-Step Time Series Forecasting in TensorFlow\nDESCRIPTION: Implements a recurrent neural network model using LSTM for multi-step time series forecasting. The model uses an LSTM layer to accumulate state over the input window, followed by a dense projection and reshaping. This model is designed for single-shot prediction of multiple future time steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_61\n\nLANGUAGE: python\nCODE:\n```\nmulti_lstm_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, lstm_units].\n    # Adding more `lstm_units` just overfits more quickly.\n    tf.keras.layers.LSTM(32, return_sequences=False),\n    # Shape => [batch, out_steps*features].\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features].\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_lstm_model, multi_window)\n\nIPython.display.clear_output()\n\nmulti_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val, return_dict=True)\nmulti_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0, return_dict=True)\nmulti_window.plot(multi_lstm_model)\n```\n\n----------------------------------------\n\nTITLE: Creating Distributed Tensors with DTensor Layout\nDESCRIPTION: Shows how to create distributed tensors using DTensor's call_with_layout function for both single-op and multi-op scenarios.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 3), (\"y\", 2)], devices=DEVICES)\nones = dtensor.call_with_layout(tf.ones, dtensor.Layout(['x', 'y'], mesh), shape=(6, 4))\nprint(ones)\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Model without Strategy Scope in Python\nDESCRIPTION: This code loads a saved TensorFlow model without using a Strategy.scope, compiles it, and evaluates its performance on a dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nunreplicated_model = tf.keras.models.load_model(path)\n\nunreplicated_model.compile(\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=['accuracy'])\n\neval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n\nprint('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n```\n\n----------------------------------------\n\nTITLE: Retrieving Tensor Values from TensorFlow Checkpoint\nDESCRIPTION: This code snippet demonstrates how to use the get_tensor method of a CheckpointReader to retrieve the actual value of a variable from a TensorFlow checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nreader.get_tensor(key)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a TensorFlow Estimator Model\nDESCRIPTION: Uses the trained Estimator model to make predictions on the training data and prints the first prediction's key-value pairs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfor pred in model.predict(train_input_fn):\n  for key, value in pred.items():\n    print(key, \":\", value)\n  break\n```\n\n----------------------------------------\n\nTITLE: One-hot Encoding String Data with Feature Columns\nDESCRIPTION: Demonstrates one-hot encoding of string data using a vocabulary with feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nvocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n    'sizes',\n    vocabulary_list=['small', 'medium', 'large'],\n    num_oov_buckets=0)\nindicator_col = tf1.feature_column.indicator_column(vocab_col)\ncall_feature_columns(indicator_col, {'sizes': ['small', 'medium', 'large']})\n```\n\n----------------------------------------\n\nTITLE: Preparing Dataset and Model for TF2 Keras Implementation\nDESCRIPTION: Sets up the MNIST dataset and defines a simple Keras Sequential model for TensorFlow 2 early stopping examples. Includes data loading, normalization, and model compilation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(ds_train, ds_test), ds_info = tfds.load(\n    'mnist',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n\nds_train = ds_train.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_train = ds_train.batch(128)\n\nds_test = ds_test.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_test = ds_test.batch(128)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10)\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(0.005),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Dependencies\nDESCRIPTION: Imports required TensorFlow modules and prints the version. Includes core TensorFlow import and Keras layer components needed for building the neural network.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\n\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras import Model\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing MNIST Dataset\nDESCRIPTION: Loads the MNIST dataset, normalizes pixel values, and adds a channels dimension for CNN processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Add a channels dimension\nx_train = x_train[..., tf.newaxis].astype(\"float32\")\nx_test = x_test[..., tf.newaxis].astype(\"float32\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom TensorFlow Module\nDESCRIPTION: Defines a custom tf.Module class with a tf.Variable attribute and tf.function-decorated methods for inference and variable mutation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModule(tf.Module):\n\n  def __init__(self):\n    super(CustomModule, self).__init__()\n    self.v = tf.Variable(1.)\n\n  @tf.function\n  def __call__(self, x):\n    print('Tracing with', x)\n    return x * self.v\n\n  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n  def mutate(self, new_v):\n    self.v.assign(new_v)\n\nmodule = CustomModule()\n```\n\n----------------------------------------\n\nTITLE: One-hot Encoding with Keras Preprocessing\nDESCRIPTION: Shows how to perform one-hot encoding using Keras CategoryEncoding layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\none_hot_layer = tf.keras.layers.CategoryEncoding(\n    num_tokens=3, output_mode='one_hot')\none_hot_layer([0, 1, 2])\n```\n\n----------------------------------------\n\nTITLE: Installing Seaborn for Data Visualization in Python\nDESCRIPTION: Installs the seaborn library silently using pip. Seaborn is used for creating statistical visualizations like countplots.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Use seaborn for countplot.\n!pip install -q seaborn\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Architecture with Plot\nDESCRIPTION: Creates a visual representation of the model architecture with layer shapes using Keras utility function, providing a graphical overview of the model structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.utils.plot_model(model, show_shapes=True)\n```\n\n----------------------------------------\n\nTITLE: Maximizing L2 Cache Fetch Granularity for NVIDIA GPUs\nDESCRIPTION: This snippet configures the GPU's L2 cache fetch granularity to 128 bytes for improved performance. It uses the CUDA Runtime API through ctypes to set and verify the device limit before the training loop.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport ctypes\n\n_libcudart = ctypes.CDLL('libcudart.so')\n# Set device limit on the current device\n# cudaLimitMaxL2FetchGranularity = 0x05\npValue = ctypes.cast((ctypes.c_int*1)(), ctypes.POINTER(ctypes.c_int))\n_libcudart.cudaDeviceSetLimit(ctypes.c_int(0x05), ctypes.c_int(128))\n_libcudart.cudaDeviceGetLimit(pValue, ctypes.c_int(0x05))\nassert pValue.contents.value == 128\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Type Promotion Restrictions in 'safe' Mode\nDESCRIPTION: Example showing that mixing int32 and float32 types is not allowed in 'safe' mode, resulting in a TypeError to prevent potential precision loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# This promotion is not allowed in SAFE mode.\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\na = tf.constant(10, dtype = tf.int32)\nb = tf.constant(5.0, dtype = tf.float32)\ntry:\n  a + b\nexcept TypeError as e:\n   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode.\n```\n\n----------------------------------------\n\nTITLE: Setting up imports and utility functions for SavedModel migration\nDESCRIPTION: This snippet sets up the necessary imports and defines utility functions for removing directories and adding two to an input. It prepares the environment for demonstrating SavedModel migration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\nimport shutil\n\ndef remove_dir(path):\n  try:\n    shutil.rmtree(path)\n  except:\n    pass\n\ndef add_two(input):\n  return input + 2\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Performance in TensorFlow\nDESCRIPTION: This snippet configures the datasets for optimal performance using buffered prefetching to load images from disk without blocking I/O operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Getting Tensor Rank in TensorFlow\nDESCRIPTION: Shows how to determine the rank of a tensor using tf.rank method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nr = tf.rank(my_image)\n# After the graph runs, r will hold the value 4.\n```\n\n----------------------------------------\n\nTITLE: Using Python State\nDESCRIPTION: This snippet demonstrates how to use mutable states in Python by creating a tensor of zeros and modifying it. This highlights the difference between immutable tensors and mutable Python variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nx = tf.zeros([10, 10])\nx += 2  # This is equivalent to x = x + 2, which does not mutate the original\nprint(x)\n```\n\n----------------------------------------\n\nTITLE: Testing Custom TensorFlow Operations in Python\nDESCRIPTION: A Python test case for verifying that a custom 'zero_out' operation works correctly. The test loads the custom op library and validates that the operation zeroes out all elements of an array except the first one.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nclass ZeroOutTest(tf.test.TestCase):\n  def testZeroOut(self):\n    zero_out_module = tf.load_op_library('./zero_out.so')\n    with self.test_session():\n      result = zero_out_module.zero_out([5, 4, 3, 2, 1])\n      self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])\n\nif __name__ == \"__main__\":\n  tf.test.main()\n```\n\n----------------------------------------\n\nTITLE: Mapping Dataset Transformation in TensorFlow\nDESCRIPTION: Demonstrates basic dataset mapping operation to parse lines from a CSV file. The code shows how to apply a _parse_line function to transform string data into feature-label pairs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nds = ds.map(_parse_line)\nprint(ds)\n```\n\n----------------------------------------\n\nTITLE: Displaying Original Image with Classification Results\nDESCRIPTION: Visualizes the original image with its predicted class and confidence score before applying any adversarial perturbations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nplt.figure()\nplt.imshow(image[0] * 0.5 + 0.5)  # To change [-1, 1] to [0,1]\n_, image_class, class_confidence = get_imagenet_label(image_probs)\nplt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Using Custom Filesystem in C++\nDESCRIPTION: This snippet demonstrates how to use a custom filesystem implementation in TensorFlow C++ code to create a new writable file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_3\n\nLANGUAGE: C++\nCODE:\n```\nstring filename = \"foobar://path/to/file.txt\";\nstd::unique_ptr<WritableFile> file;\n\n// Calls FooBarFileSystem::NewWritableFile to return\n// a WritableFile class, which happens to be the FooBarFileSystem's\n// WritableFile implementation.\nTF_RETURN_IF_ERROR(env->NewWritableFile(filename, &file));\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential Model (Python)\nDESCRIPTION: This snippet defines a function to create a Sequential Keras model with two hidden layers for regression predictions, including compiling with specified loss and optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef build_model():\n  model = keras.Sequential([\n    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation=tf.nn.relu),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mean_squared_error',\n                optimizer=optimizer,\n                metrics=['mean_absolute_error', 'mean_squared_error'])\n  return model\n```\n\n----------------------------------------\n\nTITLE: Parsing CSV Lines for Estimator Input in Python\nDESCRIPTION: This function parses a single line of a CSV file into features and label, creating the dictionary format required by Estimators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n# Metadata describing the text columns\nCOLUMNS = ['SepalLength', 'SepalWidth',\n           'PetalLength', 'PetalWidth',\n           'label']\nFIELD_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0]]\ndef _parse_line(line):\n    # Decode the line into its fields\n    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n\n    # Pack the result into a dictionary\n    features = dict(zip(COLUMNS,fields))\n\n    # Separate the label from the features\n    label = features.pop('label')\n\n    return features, label\n```\n\n----------------------------------------\n\nTITLE: Splitting Unicode Strings into Characters\nDESCRIPTION: This snippet demonstrates how to split a Unicode string into its individual characters using TensorFlow's unicode_split operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_split(thanks, 'UTF-8').numpy()\n```\n\n----------------------------------------\n\nTITLE: Define Sequential Neural Network Model\nDESCRIPTION: Creating a simple sequential model with dense layers for MNIST classification\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Returns a short sequential model\ndef create_model():\n  model = tf.keras.models.Sequential([\n    keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n  ])\n\n  model.compile(optimizer=tf.keras.optimizers.Adam(),\n                loss=tf.keras.losses.sparse_categorical_crossentropy,\n                metrics=['accuracy'])\n\n  return model\n\n\n# Create a basic model instance\nmodel = create_model()\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Implementing Example Serialization Function\nDESCRIPTION: Creates a function that converts feature values into a serialized tf.train.Example message suitable for writing to TFRecord files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@tf.py_function(Tout=tf.string)\ndef serialize_example(feature0, feature1, feature2, feature3):\n  \"\"\"\n  Creates a tf.train.Example message ready to be written to a file.\n  \"\"\"\n  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n  # data type.\n  feature = {\n      'feature0': _int64_feature(feature0),\n      'feature1': _int64_feature(feature1),\n      'feature2': _bytes_feature(feature2),\n      'feature3': _float_feature(feature3),\n  }\n\n  # Create a Features message using tf.train.Example.\n\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()\n```\n\n----------------------------------------\n\nTITLE: Saving TensorFlow 1.x checkpoint in Python\nDESCRIPTION: Creates variables using TF1 API and saves them to a checkpoint using tf.compat.v1.train.Saver.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                       initializer=tf1.zeros_initializer())\n  b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                       initializer=tf1.zeros_initializer())\n  c = tf1.get_variable('scoped/c', shape=[], dtype=tf.float32, \n                       initializer=tf1.zeros_initializer())\n  with tf1.Session() as sess:\n    saver = tf1.train.Saver()\n    sess.run(a.assign(1))\n    sess.run(b.assign(2))\n    sess.run(c.assign(3))\n    saver.save(sess, 'tf1-ckpt')\n\nprint_checkpoint('tf1-ckpt')\n```\n\n----------------------------------------\n\nTITLE: Building tf.data.Dataset Pipeline\nDESCRIPTION: This code creates a tf.data.Dataset pipeline for efficient training, including shuffling, batching, and prefetching operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nBATCH_SIZE = 32\n\n# Setting a shuffle buffer size as large as the dataset ensures that the data is\n# completely shuffled.\nds = image_label_ds.shuffle(buffer_size=image_count)\nds = ds.repeat()\nds = ds.batch(BATCH_SIZE)\n# `prefetch` lets the dataset fetch batches, in the background while the model is training.\nds = ds.prefetch(buffer_size=AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Shape from a List of Unicode Strings\nDESCRIPTION: This code creates a TensorFlow constant from a list of Unicode strings and retrieves its shape, demonstrating how TensorFlow handles Unicode strings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntf.constant([u\"You're\", u\"welcome!\"]).shape\n```\n\n----------------------------------------\n\nTITLE: Basic Git Commands for TensorFlow Contribution Workflow\nDESCRIPTION: Essential Git commands for setting up a local development environment, creating branches, committing changes, and pushing code to GitHub for TensorFlow contributions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ git clone git@github.com:your-user-name/project-name.git\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git checkout -b new-branch-name\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git add -A\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git commit -m \"commit message here\"\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git push origin branch-name\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset of CSV Filenames\nDESCRIPTION: Creates a TensorFlow dataset that contains the filenames of all CSV files in the 'fonts' directory. This is the first step for interleaving multiple files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_53\n\nLANGUAGE: python\nCODE:\n```\nfont_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n```\n\n----------------------------------------\n\nTITLE: Data Preprocessing and Normalization\nDESCRIPTION: Normalizes the image data by scaling pixel values from 0-255 to 0-1 range for better model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_images = train_images / 255.0\n\ntest_images = test_images / 255.0\n```\n\n----------------------------------------\n\nTITLE: Using Symbolic Tensors in TensorFlow's Functional API\nDESCRIPTION: This snippet demonstrates the use of symbolic tensors in TensorFlow's Functional API, which is useful for building more complex preprocessing pipelines for CSV data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Create a symbolic input\ninput = tf.keras.Input(shape=(), dtype=tf.float32)\n\n# Perform a calculation using the input\nresult = 2*input + 1\n```\n\n----------------------------------------\n\nTITLE: Applying LayoutMap to Functional and Sequential Models in Python with DTensor API\nDESCRIPTION: Shows how to use LayoutMap with Keras Functional and Sequential models, demonstrating the difference in key naming conventions compared to subclassed models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nlayout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n\nlayout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\nlayout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith layout_map.scope():\n  inputs = tf.keras.Input((16,), batch_size=16)\n  x = tf.keras.layers.Dense(16, name='feature')(inputs)\n  x = tf.keras.layers.Dropout(0.1)(x)\n  output = tf.keras.layers.Dense(32, name='feature_2')(x)\n  model = tf.keras.Model(inputs, output)\n\nprint(model.layers[1].kernel.layout)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith layout_map.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(16, name='feature', input_shape=(16,)),\n      tf.keras.layers.Dropout(0.1),\n      tf.keras.layers.Dense(32, name='feature_2')\n  ])\n\nprint(model.layers[2].kernel.layout)\n```\n\n----------------------------------------\n\nTITLE: Assigning New Values to Variables\nDESCRIPTION: Shows how to completely replace the values in a TensorFlow Variable using the assign method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nvar.assign([1, 2, 3])\n```\n\n----------------------------------------\n\nTITLE: Training the model using TPUEstimator in TF1\nDESCRIPTION: This code snippet calls `TPUEstimator.train` to begin training the model. It uses the `_input_fn` to provide the training data and trains for a specified number of steps (in this case, 1 step).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nestimator.train(_input_fn, steps=1)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Generated Videos\nDESCRIPTION: Creates visualization of the generated video sequences including start, interpolated, and end frames\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Show sequences of generated video frames.\n\n# Concatenate start/end frames and the generated filled frames for the new videos.\ngenerated_videos = np.concatenate([input_frames[:, :1] / 255.0, filled_frames, input_frames[:, 1:] / 255.0], axis=1)\n\nfor video_id in range(4):\n  fig = plt.figure(figsize=(10 * 2, 2))\n  for frame_id in range(1, 16):\n    ax = fig.add_axes([frame_id * 1 / 16., 0, (frame_id + 1) * 1 / 16., 1],\n                      xmargin=0, ymargin=0)\n    ax.imshow(generated_videos[video_id, frame_id])\n    ax.axis('off')\n```\n\n----------------------------------------\n\nTITLE: Creating Typed Record Defaults for CSV Parsing\nDESCRIPTION: This code creates a list of default values with appropriate types for each column in the Titanic dataset. These will be used to specify the expected data types when parsing the CSV.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\ntitanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\ntitanic_types\n```\n\n----------------------------------------\n\nTITLE: Data Visualization\nDESCRIPTION: Plotting the first multi-hot encoded vector to visualize the data distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(train_data[0])\n```\n\n----------------------------------------\n\nTITLE: Defining a Function to Pack Dataset Rows in TensorFlow\nDESCRIPTION: This function repacks a list of scalars into a (feature_vector, label) pair for use in the TensorFlow dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\ndef pack_row(*row):\n  label = row[0]\n  features = tf.stack(row[1:],1)\n  return features, label\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Script from Host in Container\nDESCRIPTION: Example of mounting a host directory and running a TensorFlow script within a Docker container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm -v $PWD:/tmp -w /tmp tensorflow/tensorflow python ./script.py\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow Variables for Mutable Object Attributes\nDESCRIPTION: This snippet shows how to use tf.Variables as object attributes to allow for mutation without requiring retracing of the tf.function. It demonstrates that changes to the Variable values are reflected in subsequent function calls.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nclass BetterModel:\n\n  def __init__(self):\n    self.bias = tf.Variable(0.)\n    self.weight = tf.Variable(2.)\n\n@tf.function\ndef evaluate(model, x):\n  return model.weight * x + model.bias\n\nbetter_model = BetterModel()\nprint(evaluate(better_model, x))\n\nprint(\"Adding bias!\")\nbetter_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5\nprint(evaluate(better_model, x))  # This works!\n```\n\n----------------------------------------\n\nTITLE: Inspecting a TensorFlow SavedModel Directory Structure\nDESCRIPTION: Shell commands to list the directories and files created when saving a TensorFlow model in SavedModel format, showing the assets folder, saved_model.pb file, and variables folder.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# my_model directory\n!ls saved_model\n\n# Contains an assets folder, saved_model.pb, and variables folder.\n!ls saved_model/my_model\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Session for Multilingual Text Generation\nDESCRIPTION: This snippet sets up a TensorFlow session and initializes the necessary operations for text generation. It uses a pre-defined graph and initialization operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nwith tf.Session(graph=g).as_default() as session:\n  session.run(init_op)\n```\n\n----------------------------------------\n\nTITLE: Plotting Training History with Logarithmic Scale\nDESCRIPTION: Visualizes all model training histories with a logarithmic x-axis scale to better compare convergence rates and overfitting patterns across different model sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nplotter.plot(size_histories)\na = plt.xscale('log')\nplt.xlim([5, max(plt.xlim())])\nplt.ylim([0.5, 0.7])\nplt.xlabel(\"Epochs [Log Scale]\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic TensorFlow Module\nDESCRIPTION: Creates a simple TensorFlow module that operates on scalar tensors with trainable and non-trainable variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass SimpleModule(tf.Module):\n  def __init__(self, name=None):\n    super().__init__(name=name)\n    self.a_variable = tf.Variable(5.0, name=\"train_me\")\n    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n  def __call__(self, x):\n    return self.a_variable * x + self.non_trainable_variable\n\nsimple_module = SimpleModule(name=\"simple\")\n\nsimple_module(tf.constant(5.0))\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from a Compressed CSV File\nDESCRIPTION: Creates a tf.data.Dataset from a gzipped CSV file by specifying the compression_type parameter, allowing direct reading without manual decompression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ntraffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n    traffic_volume_csv_gz,\n    batch_size=256,\n    label_name='traffic_volume',\n    num_epochs=1,\n    compression_type=\"GZIP\")\n\nfor batch, label in traffic_volume_csv_gz_ds.take(1):\n  for key, value in batch.items():\n    print(f\"{key:20s}: {value[:5]}\")\n  print()\n  print(f\"{'label':20s}: {label[:5]})\n```\n\n----------------------------------------\n\nTITLE: Getting Dynamic Shape of Tensors in TensorFlow\nDESCRIPTION: Demonstrates how to retrieve the dynamic shape of regular tensors using tf.shape, which returns the shape as a 1D integer Tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([['a', 'b'], ['c', 'd'], ['e', 'f']])\ntf.shape(x)\n```\n\n----------------------------------------\n\nTITLE: Array Indexing in TensorFlow NumPy\nDESCRIPTION: Shows various types of indexing supported by TensorFlow NumPy, including basic indexing with slices, boolean indexing, and advanced indexing with arrays as indices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nx = tnp.arange(24).reshape(2, 3, 4)\n\nprint(\"Basic indexing\")\nprint(x[1, tnp.newaxis, 1:3, ...], \"\\n\")\n\nprint(\"Boolean indexing\")\nprint(x[:, (True, False, True)], \"\\n\")\n\nprint(\"Advanced indexing\")\nprint(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Up Data\nDESCRIPTION: Imports TensorFlow and creates sample data for demonstration purposes. Also installs the portpicker utility needed for the examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n!pip install portpicker\n\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\nfeatures = [[1., 1.5], [2., 2.5], [3., 3.5]]\nlabels = [[0.3], [0.5], [0.7]]\neval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\neval_labels = [[0.8], [0.9], [1.]]\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset with Feature-Label Pairs in Python\nDESCRIPTION: This snippet demonstrates how to create a tf.data.Dataset containing pairs of feature dictionaries and labels, which is the format expected by Estimators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Convert the inputs to a Dataset.\ndataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\nprint(dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing Batchable Network ExtensionType\nDESCRIPTION: Enhanced version of Network class that supports batching by extending BatchableExtensionType. Includes shape tracking and initialization logic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nclass Network(tf.experimental.BatchableExtensionType):\n  shape: tf.TensorShape  # batch shape. A single network has shape=[].\n  work: tf.Tensor        # work[*shape, n] = work left to do at node n\n  bandwidth: tf.Tensor   # bandwidth[*shape, n1, n2] = bandwidth from n1->n2\n\n  def __init__(self, work, bandwidth):\n    self.work = tf.convert_to_tensor(work)\n    self.bandwidth = tf.convert_to_tensor(bandwidth)\n    work_batch_shape = self.work.shape[:-1]\n    bandwidth_batch_shape = self.bandwidth.shape[:-2]\n    self.shape = work_batch_shape.merge_with(bandwidth_batch_shape)\n\n  def __repr__(self):\n    return network_repr(self)\n```\n\n----------------------------------------\n\nTITLE: Listing Dataset Files\nDESCRIPTION: Lists the contents of the data directory to verify the downloaded files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nls ./data/train/\n```\n\n----------------------------------------\n\nTITLE: Loading SavedModel in C++\nDESCRIPTION: The C++ snippet describes loading a SavedModel using the TensorFlow C++ API. It involves the `LoadSavedModel` function, requiring session options, run options, export direction, and tags. To compile, ensure TensorFlow's C++ API is available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_8\n\nLANGUAGE: c++\nCODE:\n```\nconst string export_dir = ...\nSavedModelBundle bundle;\n...\nLoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n               &bundle);\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Examples Package for CycleGAN Implementation\nDESCRIPTION: Installs the tensorflow_examples package from GitHub to access the generator and discriminator models needed for CycleGAN implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install git+https://github.com/tensorflow/examples.git\n```\n\n----------------------------------------\n\nTITLE: Simple Batching in TensorFlow Dataset\nDESCRIPTION: Shows how to perform simple batching of datasets using TensorFlow's Dataset.batch(). Two datasets are zipped and batched together, producing batches of size 4 as output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_19\n\nLANGUAGE: Python\nCODE:\n```\ninc_dataset = tf.data.Dataset.range(100)\ndec_dataset = tf.data.Dataset.range(0, -100, -1)\ndataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\nbatched_dataset = dataset.batch(4)\n\niterator = batched_dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\nprint(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\nprint(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])\n```\n\n----------------------------------------\n\nTITLE: Creating Covariance Reset Callback in TensorFlow\nDESCRIPTION: This snippet defines a Keras callback to reset the covariance matrix at the beginning of each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nclass ResetCovarianceCallback(tf.keras.callbacks.Callback):\n\n  def on_epoch_begin(self, epoch, logs=None):\n    \"\"\"Resets covariance matrix at the beginning of the epoch.\"\"\"\n    if epoch > 0:\n      self.model.classifier.reset_covariance_matrix()\n```\n\n----------------------------------------\n\nTITLE: Implementing Loss and Gradient Functions\nDESCRIPTION: Defines functions to calculate loss and gradients for custom training loop implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef loss(model, x, y):\n  \"\"\"Calculates the loss given an example (x, y)\"\"\"\n  logits = model(x)\n  return logits, tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n\ndef grad(model, x, y):\n  \"\"\"Calculates the loss and the gradients given an example (x, y)\"\"\"\n  logits, loss_value = loss(model, x, y)\n  return logits, loss_value, tf.gradients(loss_value, model.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Expanding Image Dimensions\nDESCRIPTION: This snippet expands the dimensions of a single image to create a batch of size 1.  It uses `np.expand_dims` to add a new dimension at the beginning of the image array, effectively wrapping the image in a batch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Add the image to a batch where it's the only member.\nimg = (np.expand_dims(img,0))\n\nprint(img.shape)\n```\n\n----------------------------------------\n\nTITLE: Building and Running Local TensorFlow Model Server with Bash\nDESCRIPTION: Instructions on compiling and starting a TensorFlow model server for local deployment using TensorFlow Serving. Requires TensorFlow Serving to be installed and a predefined export directory for the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_12\n\nLANGUAGE: Shell\nCODE:\n```\nbazel build //tensorflow_serving/model_servers:tensorflow_model_server\nbazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_base_path=$export_dir_base\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Gradient Stopping at Stateful Objects in TensorFlow\nDESCRIPTION: This snippet shows how stateful objects like Variables stop gradient propagation beyond their current state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nx0 = tf.Variable(3.0)\nx1 = tf.Variable(0.0)\n\nwith tf.GradientTape() as tape:\n  # Update x1 = x1 + x0.\n  x1.assign_add(x0)\n  # The tape starts recording from x1.\n  y = x1**2   # y = (x1 + x0)**2\n\n# This doesn't work.\nprint(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x0)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Embedding Extraction in Python\nDESCRIPTION: This code loads the TensorFlow Hub module and the random projection matrix (if available) to prepare for embedding extraction from queries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Load the TF-Hub module\nprint(\"Loading the TF-Hub module...\")\ng = tf.Graph()\nwith g.as_default():\n  embed_fn = load_module(module_url)\nprint(\"TF-Hub module is loaded.\")\n\nrandom_projection_matrix = None\nif os.path.exists('random_projection_matrix'):\n  print(\"Loading random projection matrix...\")\n  with open('random_projection_matrix', 'rb') as handle:\n    random_projection_matrix = pickle.load(handle)\n  print('random projection matrix is loaded.')\n\ndef extract_embeddings(query):\n  '''Generates the embedding for the query'''\n  query_embedding =  embed_fn([query])[0]\n  if random_projection_matrix is not None:\n    query_embedding = query_embedding.dot(random_projection_matrix)\n  return query_embedding\n```\n\n----------------------------------------\n\nTITLE: Loading Custom Filesystem in Python\nDESCRIPTION: This snippet shows how to dynamically load a custom filesystem implementation in Python using the tf.load_file_system_library function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ntf.load_file_system_library(file_system_library)\n```\n\n----------------------------------------\n\nTITLE: Loading and Parsing Serialized Tensors from TFRecord\nDESCRIPTION: Reads serialized tensor data from a TFRecord file and parses it back into the original tensor format. This includes reshaping to the expected image dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nds = tf.data.TFRecordDataset('images.tfrec')\n\ndef parse(x):\n  result = tf.parse_tensor(x, out_type=tf.float32)\n  result = tf.reshape(result, [192, 192, 3])\n  return result\n\nds = ds.map(parse, num_parallel_calls=AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Creating Side-by-Side Comparison of ESRGAN Results\nDESCRIPTION: Creates a side-by-side comparison visualization showing the original high-resolution image, the downscaled low-resolution image, and the ESRGAN-enhanced super-resolution result. Saves the comparison figure and displays the PSNR metric.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nplt.rcParams['figure.figsize'] = [15, 10]\nfig, axes = plt.subplots(1, 3)\nfig.tight_layout()\nplt.subplot(131)\nplot_image(tf.squeeze(hr_image), title=\"Original\")\nplt.subplot(132)\nfig.tight_layout()\nplot_image(tf.squeeze(lr_image), \"x4 Bicubic\")\nplt.subplot(133)\nfig.tight_layout()\nplot_image(tf.squeeze(fake_image), \"Super Resolution\")\nplt.savefig(\"ESRGAN_DIV2K.jpg\", bbox_inches=\"tight\")\nprint(\"PSNR: %f\" % psnr)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic TensorFlow Data Pipeline\nDESCRIPTION: Example showing how to create a basic tf.data pipeline with range, map, repeat, and batch transformations to demonstrate profiler event naming.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(10)\ndataset = dataset.map(lambda x: x)\ndataset = dataset.repeat(2)\ndataset = dataset.batch(5)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Time Series Forecasting in Python\nDESCRIPTION: This code snippet imports necessary libraries for data manipulation, visualization, and machine learning using TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport datetime\n\nimport IPython\nimport IPython.display\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\n\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False\n```\n\n----------------------------------------\n\nTITLE: Using Converted Layer in Keras Functional Model in Python\nDESCRIPTION: This snippet shows how to use the converted TF1.x-style layer in a Keras functional model construction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ninputs = tf.keras.Input(shape=(20))\noutputs = DenseLayer(10)(inputs)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nx = tf.random.normal(shape=(8, 20))\nmodel(x)\n\n# Access the model variables and regularization losses\nmodel.weights\nmodel.losses\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function for Distributed Training in TensorFlow\nDESCRIPTION: This snippet demonstrates how to define a loss function for distributed training using tf.distribute.Strategy. It uses SparseCategoricalCrossentropy loss and handles both prediction and regularization losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  # Set reduction to `NONE` so you can do the reduction yourself.\n  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True,\n      reduction=tf.keras.losses.Reduction.NONE)\n  def compute_loss(labels, predictions, model_losses):\n    per_example_loss = loss_object(labels, predictions)\n    loss = tf.nn.compute_average_loss(per_example_loss)\n    if model_losses:\n      loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n    return loss\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Hub and ANN Search\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, TensorFlow Hub, Apache Beam, ANNOY, and scikit-learn for text embedding generation and approximate nearest neighbor search.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport sys\nimport pickle\nfrom collections import namedtuple\nfrom datetime import datetime\nimport numpy as np\nimport apache_beam as beam\nfrom apache_beam.transforms import util\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport annoy\nfrom sklearn.random_projection import gaussian_random_matrix\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model with Balanced Loss Weights in TensorFlow\nDESCRIPTION: Checks the model's performance after applying loss weights to verify the balance between different loss components.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(train_ds, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Temporarily Suspending Gradient Recording with stop_recording\nDESCRIPTION: Demonstrates how to temporarily stop recording gradients during a calculation using the stop_recording method of GradientTape, which is useful for excluding complex operations from gradient computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.0)\ny = tf.Variable(3.0)\n\nwith tf.GradientTape() as t:\n  x_sq = x * x\n  with t.stop_recording():\n    y_sq = y * y\n  z = x_sq + y_sq\n\ngrad = t.gradient(z, {'x': x, 'y': y})\n\nprint('dz/dx:', grad['x'])  # 2*x => 4\nprint('dz/dy:', grad['y'])\n```\n\n----------------------------------------\n\nTITLE: Broadcasting 2D Tensor with 3D RaggedTensor\nDESCRIPTION: Demonstrates broadcasting between a 2D tensor with shape [1, 1] and a 3D ragged tensor, showing how values are broadcast across both uniform and ragged dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_50\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged):  2 x (r1) x 2\n# y      (2d ragged):         1 x 1\n# Result (3d ragged):  2 x (r1) x 2\nx = tf.ragged.constant(\n    [[[1, 2], [3, 4], [5, 6]],\n     [[7, 8]]],\n    ragged_rank=1)\ny = tf.constant([[10]])\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Gathering Matrix Elements as a Flat List with tf.gather_nd\nDESCRIPTION: Demonstrates using tf.gather_nd to extract multiple elements from a 3D tensor into a single matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Return one matrix\n\nprint(tf.gather_nd(t5,\n                   indices=[[0, 0], [0, 2], [1, 0], [1, 2]]))\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow with CLANG on Windows\nDESCRIPTION: Command to build TensorFlow using the CLANG compiler on Windows with Python 3.11. It generates a CPU wheel package using Bazel build system.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nbazel build --config=win_clang --repo_env=TF_PYTHON_VERSION=3.11 //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu\n```\n\n----------------------------------------\n\nTITLE: Registering GPU Kernel with Host Memory Specification in C++\nDESCRIPTION: Example of registering a GPU kernel for the 'Pad' operation with a specification that the 'paddings' input should be kept in host (CPU) memory. This is a common pattern for operations where some inputs need to be accessed on the CPU even when the main computation runs on GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_46\n\nLANGUAGE: c++\nCODE:\n```\n#define REGISTER_GPU_KERNEL(T)                         \\\n  REGISTER_KERNEL_BUILDER(Name(\"Pad\")                  \\\n                              .Device(DEVICE_GPU)      \\\n                              .TypeConstraint<T>(\"T\")  \\\n                              .HostMemory(\"paddings\"), \\\n                          PadOp<GPUDevice, T>)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Dense Layers\nDESCRIPTION: Demonstrates how to create Dense layers with different configurations, including specifying output dimensions and input shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# In the tf.keras.layers package, layers are objects. To construct a layer,\n# simply construct the object. Most layers take as a first argument the number\n# of output dimensions / channels.\nlayer = tf.keras.layers.Dense(100)\n# The number of input dimensions is often unnecessary, as it can be inferred\n# the first time the layer is used, but it can be provided if you want to\n# specify it manually, which is useful in some complex models.\nlayer = tf.keras.layers.Dense(10, input_shape=(None, 5))\n```\n\n----------------------------------------\n\nTITLE: Visualizing ResNet Model Predictions and Uncertainty\nDESCRIPTION: Computes and visualizes the class probabilities and predictive uncertainty of the ResNet model on test examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresnet_logits = resnet_model(test_examples)\nresnet_probs = tf.nn.softmax(resnet_logits, axis=-1)[:, 0]  # Take the probability for class 0.\n```\n\nLANGUAGE: python\nCODE:\n```\n_, ax = plt.subplots(figsize=(7, 5.5))\n\npcm = plot_uncertainty_surface(resnet_probs, ax=ax)\n\nplt.colorbar(pcm, ax=ax)\nplt.title(\"Class Probability, Deterministic Model\")\n\nplt.show()\n```\n\nLANGUAGE: python\nCODE:\n```\nresnet_uncertainty = resnet_probs * (1 - resnet_probs)\n```\n\nLANGUAGE: python\nCODE:\n```\n_, ax = plt.subplots(figsize=(7, 5.5))\n\npcm = plot_uncertainty_surface(resnet_uncertainty, ax=ax)\n\nplt.colorbar(pcm, ax=ax)\nplt.title(\"Predictive Uncertainty, Deterministic Model\")\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset from Pandas DataFrame\nDESCRIPTION: This snippet shows how to create a TensorFlow Dataset from a pandas DataFrame using from_tensor_slices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\ntitanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\n\nfor feature_batch in titanic_slices.take(1):\n  for key, value in feature_batch.items():\n    print(\"  {!r:20s}: {}\".format(key, value))\n```\n\n----------------------------------------\n\nTITLE: Enabling GPU Memory Growth in TensorFlow\nDESCRIPTION: This snippet demonstrates how to enable GPU memory growth, which allows TensorFlow to allocate GPU memory as needed rather than claiming all available memory at once.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Generating Sample Dataset Features\nDESCRIPTION: Creates a sample dataset with 10,000 observations containing boolean, integer, string and float features for demonstration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# The number of observations in the dataset.\nn_observations = int(1e4)\n\n# Boolean feature, encoded as False or True.\nfeature0 = np.random.choice([False, True], n_observations)\n\n# Integer feature, random from 0 to 4.\nfeature1 = np.random.randint(0, 5, n_observations)\n\n# String feature.\nstrings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\nfeature2 = strings[feature1]\n\n# Float feature, from a standard normal distribution.\nfeature3 = np.random.randn(n_observations)\n```\n\n----------------------------------------\n\nTITLE: Configuring Validation Dataset Pipeline\nDESCRIPTION: Sets up the validation dataset pipeline with only resizing and rescaling operations. The validation data is not augmented to provide an accurate assessment of model performance on unmodified data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nval_ds = (\n    val_ds\n    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Default Attribute\nDESCRIPTION: Demonstrates registering an op with a default value for an attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_23\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"AttrDefaultExample\")\n    .Attr(\"i: int = 0\");\n```\n\n----------------------------------------\n\nTITLE: Generating and Displaying Video Plot with TensorFlow\nDESCRIPTION: Creates a plot visualization of streaming predictions and displays it as a video. The first snippet generates the plot from probability and video data, while the second displays the resulting video at 3 FPS. Can optionally output in GIF format by setting codec='gif'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Generate a plot and output to a video tensor\nplot_video = plot_streaming_top_preds(probs, video, video_fps=8.)\n```\n\nLANGUAGE: python\nCODE:\n```\n# For gif format, set codec='gif'\nmedia.show_video(plot_video, fps=3)\n```\n\n----------------------------------------\n\nTITLE: Implementing Partially Native Keras Layers Model in TensorFlow 2\nDESCRIPTION: This code shows how to create a model that uses a mix of native Keras layers and TensorFlow 1.x compatible layers. It demonstrates how to preserve variable names for remaining compat.v1.layers by recording variable scopes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ndef record_scope(scope_name):\n  \"\"\"Record a variable_scope to make sure future ones get incremented.\"\"\"\n  with tf.compat.v1.variable_scope(scope_name):\n    pass\n\nclass PartiallyNativeKerasLayersModel(tf.keras.layers.Layer):\n\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.conv_1 = tf.keras.layers.Conv2D(\n          3, 3,\n          kernel_regularizer=\"l2\")\n    self.conv_2 = tf.keras.layers.Conv2D(\n          4, 4,\n          kernel_regularizer=\"l2\")\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = self.conv_1(inputs)\n      record_scope('conv2d') # Only needed if follow-on compat.v1.layers do not pass a `name` arg\n      out = self.conv_2(out)\n      record_scope('conv2d_1') # Only needed if follow-on compat.v1.layers do not pass a `name` arg\n      out = tf.compat.v1.layers.conv2d(\n          out, 5, 5,\n          kernel_regularizer=\"l2\")\n      return out\n\nlayer = PartiallyNativeKerasLayersModel()\nlayer(tf.ones(shape=(10, 10, 10, 10)))\n[v.name for v in layer.weights]\n```\n\n----------------------------------------\n\nTITLE: Creating Input Function for TensorFlow Dataset in Python\nDESCRIPTION: This function creates a TensorFlow Dataset from random data. It generates random input features and binary labels, converts them to a dataset, and applies repeat and batch operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef input_fn():\n  x = np.random.random((1024, 10))\n  y = np.random.randint(2, size=(1024, 1))\n  x = tf.cast(x, tf.float32)\n  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n  dataset = dataset.repeat(10)\n  dataset = dataset.batch(32)\n  return dataset\n```\n\n----------------------------------------\n\nTITLE: Loading Validation Dataset with TensorFlow\nDESCRIPTION: Loads the IMDB reviews validation dataset using TensorFlow Datasets (tfds) with specific split and batch configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nval_ds = tfds.load(\n    'imdb_reviews',\n    split='train[80%:]',\n    batch_size=BATCH_SIZE,\n    shuffle_files=True,\n    as_supervised=True)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Horse Images with Random Jitter\nDESCRIPTION: Creates a plot to visualize a sample horse image before and after applying random jitter. This helps understand the image augmentation process used in CycleGAN training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(121)\nplt.title('Horse')\nplt.imshow(sample_horse[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Horse with random jitter')\nplt.imshow(random_jitter(sample_horse[0]) * 0.5 + 0.5)\n```\n\n----------------------------------------\n\nTITLE: Examining Vectorized Text Data in TensorFlow\nDESCRIPTION: Retrieving and displaying a batch of data from the dataset to visualize how raw text is transformed into vectors. This code shows the original review, its label, and the vectorized representation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# retrieve a batch (of 32 reviews and labels) from the dataset\ntext_batch, label_batch = next(iter(raw_train_ds))\nfirst_review, first_label = text_batch[0], label_batch[0]\nprint(\"Review\", first_review)\nprint(\"Label\", raw_train_ds.class_names[first_label])\nprint(\"Vectorized review\", vectorize_text(first_review, first_label))\n```\n\n----------------------------------------\n\nTITLE: Defining a Loss Function\nDESCRIPTION: This snippet implements a loss function using the L2 norm. The loss function is designed to quantify the difference between the predicted and actual outputs, which is essential for training the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef loss(predicted_y, desired_y):\n  return tf.reduce_mean(tf.square(predicted_y - desired_y))\n```\n\n----------------------------------------\n\nTITLE: Dependent Variable Initialization\nDESCRIPTION: Creates a variable whose initial value depends on another variable using initialized_value().\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Compressed Model Performance in TensorFlow\nDESCRIPTION: This snippet compiles and evaluates the compressed classifier, comparing its accuracy to the original model. It demonstrates that the compression maintains model performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ncompressed_classifier.compile(metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n_, compressed_accuracy = compressed_classifier.evaluate(validation_dataset.batch(128))\n\nprint(f\"Accuracy of the compressible classifier: {penalized_accuracy:0.4f}\")\nprint(f\"Accuracy of the compressed classifier: {compressed_accuracy:0.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Input Validation in TensorFlow C++ Op\nDESCRIPTION: C++ code snippet demonstrating how to add input validation to a TensorFlow custom operation. This example checks that the input tensor is a vector (1D) and returns an error if the validation fails.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_11\n\nLANGUAGE: c++\nCODE:\n```\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_tensor.shape()),\n                errors::InvalidArgument(\"ZeroOut expects a 1-D vector.\"));\n    // ...\n  }\n```\n\n----------------------------------------\n\nTITLE: Training the model with transfer learning\nDESCRIPTION: Trains the model using the fit method with training and validation datasets. Training runs for 10 epochs with TensorBoard callback for logging metrics and progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nNUM_EPOCHS = 10\n\nhistory = model.fit(train_ds,\n                    validation_data=val_ds,\n                    epochs=NUM_EPOCHS,\n                    callbacks=tensorboard_callback)\n```\n\n----------------------------------------\n\nTITLE: Implementing Baseline Model for Time Series Prediction in TensorFlow\nDESCRIPTION: Creates a baseline model class that simply returns the current value as the prediction for the next time step. This serves as a performance benchmark for more complex models and works by forwarding the input at the specified label index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass Baseline(tf.keras.Model):\n  def __init__(self, label_index=None):\n    super().__init__()\n    self.label_index = label_index\n\n  def call(self, inputs):\n    if self.label_index is None:\n      return inputs\n    result = inputs[:, :, self.label_index]\n    return result[:, :, tf.newaxis]\n```\n\n----------------------------------------\n\nTITLE: Dataset Caching with tf.init_scope\nDESCRIPTION: Solution showing how to properly cache datasets in tf.function using tf.init_scope to lift operations outside the function-building graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.datasets = {}\n    self.iterators = {}\n\n  @tf.function\n  def __call__(self, key):\n    if key not in self.datasets:\n      # Lifts ops out of function-building graphs\n      with tf.init_scope():\n        self.datasets[key] = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n        self.iterators[key] = iter(self.datasets[key])\n    return self.iterators[key]\n\nm = Model()\nfor _ in range(3):\n  print(next(m('a')))\n```\n\n----------------------------------------\n\nTITLE: First Execution of a tf.function\nDESCRIPTION: Shows the first call to a tf.function, which will trace the computation to create a graph and execute it with the given input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([1, 2, 3])\nmy_func(x)\n```\n\n----------------------------------------\n\nTITLE: Implementing Discriminator and Generator Loss\nDESCRIPTION: Defines the loss functions for both discriminator and generator components of CycleGAN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef discriminator_loss(real, generated):\n  real_loss = loss_obj(tf.ones_like(real), real)\n\n  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n\n  total_disc_loss = real_loss + generated_loss\n\n  return total_disc_loss * 0.5\n\ndef generator_loss(generated):\n  return loss_obj(tf.ones_like(generated), generated)\n```\n\n----------------------------------------\n\nTITLE: Initializing Preprocessed Inputs Collection\nDESCRIPTION: Creates a list to collect all preprocessed inputs, starting with the normalized numeric features, which will be concatenated later in the pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npreprocessed_inputs = [all_numeric_inputs]\n```\n\n----------------------------------------\n\nTITLE: Creating and Compiling Keras Model with Dataset\nDESCRIPTION: Sets up a simple Keras Sequential model and prepares a dataset for training\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_83\n\nLANGUAGE: python\nCODE:\n```\nfmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\nfmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(10)\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Using AutoGraph for Control Flow in TensorFlow\nDESCRIPTION: The snippet demonstrates how AutoGraph transforms Python control flow constructs like loops and conditionals into TensorFlow-compatible operations. By default, AutoGraph is enabled in tf.function, and it allows more natural Python code to be written while ensuring compatibility with TensorFlow execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f(x):\n  while tf.reduce_sum(x) > 1:\n    tf.print(x)\n    x = tf.tanh(x)\n  return x\n\nf(tf.random.uniform([5]))\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.autograph.to_code(f.python_function))\n```\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef fizzbuzz(n):\n  for i in tf.range(1, n + 1):\n    print('Tracing for loop')\n    if i % 15 == 0:\n      print('Tracing fizzbuzz branch')\n      tf.print('fizzbuzz')\n    elif i % 3 == 0:\n      print('Tracing fizz branch')\n      tf.print('fizz')\n    elif i % 5 == 0:\n      print('Tracing buzz branch')\n      tf.print('buzz')\n    else:\n      print('Tracing default branch')\n      tf.print(i)\n\nfizzbuzz(tf.constant(5))\nfizzbuzz(tf.constant(20))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Copyright and License Headers for TensorFlow Hub\nDESCRIPTION: Standard copyright and licensing information for the TensorFlow Hub Authors, provided under the Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n```\n\n----------------------------------------\n\nTITLE: Implementing a TensorFlow Input Function for Training\nDESCRIPTION: A function that creates a TensorFlow Dataset from input features and labels, applying shuffling, repeating, and batching operations for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n```\n\n----------------------------------------\n\nTITLE: Initializing License and Copyright Header\nDESCRIPTION: Standard Apache 2.0 license header for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Implementing Template-Based Kernel for Polymorphic Ops in TensorFlow\nDESCRIPTION: Shows how to use C++ templates to implement a single kernel class that works with multiple data types, reducing code duplication in polymorphic ops.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_27\n\nLANGUAGE: c++\nCODE:\n```\ntemplate <typename T>\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n  \n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<T>();\n    \n    // Create an output tensor\n    Tensor* output = NULL;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_tensor.shape(), &output));\n    auto output_flat = output->template flat<T>();\n    \n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n    \n    // Preserve the first input value\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n\n// Note that TypeConstraint<int32>(\"T\") means that attr \"T\" (defined\n// in the op registration above) must be \"int32\" to use this template\n// instantiation.\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<int32>(\"T\"),\n    ZeroOutOp<int32>);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<float>(\"T\"),\n    ZeroOutOp<float>);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<double>(\"T\"),\n    ZeroOutOp<double>);\n```\n\n----------------------------------------\n\nTITLE: Creating ExtensionType with Custom Field Values in Python\nDESCRIPTION: Shows how to create an instance of the Pencil ExtensionType with custom values for specific fields while using defaults for others.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nPencil(length=0.5, color=\"blue\")\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow Classifier for Iris Dataset in Python\nDESCRIPTION: This snippet demonstrates how to train a TensorFlow classifier using an input function. It uses a lambda function to wrap the input_fn and specifies the number of training steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclassifier.train(\n    input_fn=lambda: input_fn(train, train_y, training=True),\n    steps=5000)\n```\n\n----------------------------------------\n\nTITLE: Preparing a single image for batch prediction in TensorFlow\nDESCRIPTION: Adds a batch dimension to a single image to make it compatible with the model's prediction method. TensorFlow models expect inputs in batches, so even for a single image, it needs to be wrapped in a batch of size 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Add the image to a batch where it's the only member.\nimg = (np.expand_dims(img,0))\n\nprint(img.shape)\n```\n\n----------------------------------------\n\nTITLE: Creating a Ragged Tensor from Row Splits\nDESCRIPTION: Demonstrates how to construct a ragged tensor using tf.RaggedTensor.from_row_splits by specifying the index where each row starts and ends.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_row_splits(\n    values=[3, 1, 4, 1, 5, 9, 2, 6],\n    row_splits=[0, 4, 4, 7, 8]))\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Regression Tutorial\nDESCRIPTION: Imports necessary Python libraries including matplotlib, numpy, pandas, seaborn, and tensorflow for data manipulation, visualization, and machine learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Make NumPy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)\n\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Random Audio Sample\nDESCRIPTION: Selects a random audio sample, displays its transcription, and provides an audio player for listening.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Audio\nimport random\n\nfile_id = random.choice([f[:-len(\".flac\")] for f in flac_files])\nflac_file_path, txt_file_path = os.path.join(data_dir, f\"{file_id}.flac\"), os.path.join(data_dir, \"2428-83705.trans.txt\")\n\nprint(\"Text Transcription:\", read_txt_file(txt_file_path)[file_id], \"\\nAudio:\")\nAudio(filename=flac_file_path)\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Model with Gradient Descent\nDESCRIPTION: Sets up a training operation using `tf.train.GradientDescentOptimizer` to minimize the loss function. This involves backpropagating errors and updating model parameters to reduce loss over iterations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_23\n\nLANGUAGE: Python\nCODE:\n```\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\nfor i in range(100):\n  _, loss_value = sess.run((train, loss))\n  print(loss_value)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Handwriting Recognition Model using TensorFlow Estimator API\nDESCRIPTION: This snippet shows how to set up training and evaluation of the model using TensorFlow's Estimator and Experiment APIs. It configures the estimator, input functions, and training parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nestimator = tf.estimator.Estimator(\n      model_fn=model_fn,\n      model_dir=output_dir,\n      config=config,\n      params=model_params)\n  # Train the model.\n  tf.contrib.learn.Experiment(\n      estimator=estimator,\n      train_input_fn=get_input_fn(\n          mode=tf.contrib.learn.ModeKeys.TRAIN,\n          tfrecord_pattern=FLAGS.training_data,\n          batch_size=FLAGS.batch_size),\n      train_steps=FLAGS.steps,\n      eval_input_fn=get_input_fn(\n          mode=tf.contrib.learn.ModeKeys.EVAL,\n          tfrecord_pattern=FLAGS.eval_data,\n          batch_size=FLAGS.batch_size),\n      min_eval_frequency=1000)\n```\n\n----------------------------------------\n\nTITLE: Handling Non-Deterministic Output in TensorFlow DocTest\nDESCRIPTION: This snippet demonstrates how to use ellipsis (...) to handle non-deterministic output in DocTest for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> x = tf.random.normal((1,))\n>>> print(x)\n<tf.Tensor: shape=(1,), dtype=float32, numpy=..., dtype=float32)>\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training and Validation Metrics with Matplotlib in TensorFlow\nDESCRIPTION: Plots the training and validation loss and accuracy metrics over time to visualize model performance and check for overfitting or underfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nplt.figure()\nplt.ylabel(\"Loss (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,2])\nplt.plot(hist[\"loss\"])\nplt.plot(hist[\"val_loss\"])\n\nplt.figure()\nplt.ylabel(\"Accuracy (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(hist[\"accuracy\"])\nplt.plot(hist[\"val_accuracy\"])\n```\n\n----------------------------------------\n\nTITLE: Serving SavedModel in TensorFlow Serving\nDESCRIPTION: This configuration snippet illustrates how to run a TensorFlow Model Server to serve a SavedModel. The command uses flags for `port`, `model_name`, and `model_base_path`. Model files need to be organized in a structure following versioning in subdirectories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntensorflow_model_server --port=port-numbers --model_name=your-model-name --model_base_path=your_model_base_path\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Session and Distributing Strategy Configuration in Python\nDESCRIPTION: This snippet initializes a TensorFlow session with a specific configuration, and prepares dataset iterators for training and testing. It sets up a distribution strategy's environment, and manages variables needed for training and testing accuracy and loss computations. The strategy and datasets are utilized within a custom training loop where 'run_train()' and 'run_test()' functions are invoked for each epoch. Required dependencies include 'tensorflow', 'strategy' object, and valid training and testing data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  training_loss_result = training_loss.result()\n  training_accuracy_result = training_accuracy.result()\n  test_loss_result = test_loss.result()\n  test_accuracy_result = test_accuracy.result()\n  \n  config = tf.ConfigProto()\n  config.allow_soft_placement = True\n  cluster_spec = resolver.cluster_spec()\n  if cluster_spec:\n    config.cluster_def.CopyFrom(cluster_spec.as_cluster_def())\n\n  print('Starting training...')\n\n  # Do all the computations inside a Session (as opposed to doing eager mode)\n  with tf.Session(target=resolver.master(), config=config) as session:\n    all_variables = (\n        tf.global_variables() + training_loss.variables +\n        training_accuracy.variables + test_loss.variables +\n        test_accuracy.variables)\n    \n    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE, drop_remainder=True)\n    train_iterator = strategy.make_dataset_iterator(train_dataset)\n\n    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE, drop_remainder=True)\n    test_iterator = strategy.make_dataset_iterator(test_dataset)\n    \n    train_iterator_init = train_iterator.initializer\n    test_iterator_init = test_iterator.initializer\n\n    session.run([v.initializer for v in all_variables])\n    \n    dist_train = strategy.experimental_run(train_step, train_iterator).values\n    dist_test = strategy.experimental_run(test_step, test_iterator).values\n\n    # Custom training loop\n    for epoch in range(0, NUM_EPOCHS):\n      print('Starting epoch {}'.format(epoch))\n\n      run_train()\n\n      run_test()\n```\n\n----------------------------------------\n\nTITLE: Data Distribution Analysis in Python\nDESCRIPTION: Creates visualizations to compare distributions of positive and negative examples across different features using Seaborn's jointplot.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npos_df = pd.DataFrame(train_features[ bool_train_labels], columns=train_df.columns)\nneg_df = pd.DataFrame(train_features[~bool_train_labels], columns=train_df.columns)\n\nsns.jointplot(x=pos_df['V5'], y=pos_df['V6'],\n              kind='hex', xlim=(-5,5), ylim=(-5,5))\nplt.suptitle(\"Positive distribution\")\n\nsns.jointplot(x=neg_df['V5'], y=neg_df['V6'],\n              kind='hex', xlim=(-5,5), ylim=(-5,5))\n_ = plt.suptitle(\"Negative distribution\")\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Error: Incompatible Uniform Dimensions\nDESCRIPTION: Demonstrates a broadcasting error that occurs when two ragged tensors have incompatible uniform dimensions at the end of their shapes (2 vs 3).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_54\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged): 3 x (r1) x 2\n# y      (3d ragged): 3 x (r1) x 3  # trailing dimensions do not match\nx = tf.ragged.constant([[[1, 2], [3, 4], [5, 6]],\n                        [[7, 8], [9, 10]]])\ny = tf.ragged.constant([[[1, 2, 0], [3, 4, 0], [5, 6, 0]],\n                        [[7, 8, 0], [9, 10, 0]]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Inception Graph Output in TensorFlow C++\nDESCRIPTION: This function analyzes the output of an Inception graph to retrieve the highest scores and their positions in the tensor, which correspond to categories. It constructs a TopK operation to sort the results and return the highest-scoring labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_9\n\nLANGUAGE: C++\nCODE:\n```\n// Analyzes the output of the Inception graph to retrieve the highest scores and\n// their positions in the tensor, which correspond to categories.\nStatus GetTopLabels(const std::vector<Tensor>& outputs, int how_many_labels,\n                  Tensor* indices, Tensor* scores) {\n  tensorflow::GraphDefBuilder b;\n  string output_name = \"top_k\";\n  tensorflow::ops::TopK(tensorflow::ops::Const(outputs[0], b.opts()),\n                      how_many_labels, b.opts().WithName(output_name));\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensors.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(b.ToGraphDef(&graph));\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  // The TopK node returns two outputs, the scores and their original indices,\n  // so we have to append :0 and :1 to specify them both.\n  std::vector<Tensor> out_tensors;\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name + \":0\", output_name + \":1\"},\n                                {}, &out_tensors));\n  *scores = out_tensors[0];\n  *indices = out_tensors[1];\n  return Status::OK();\n```\n\n----------------------------------------\n\nTITLE: Converting tf.compat.v1.layers Model to Keras Layer in Python\nDESCRIPTION: This snippet demonstrates how to convert a model built with tf.compat.v1.layers into a Keras layer. It uses the tf.compat.v1.keras.utils.track_tf1_style_variables decorator to handle variable tracking and scoping.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass CompatV1LayerModel(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    with tf.compat.v1.variable_scope('model'):\n      out = tf.compat.v1.layers.conv2d(\n          inputs, 3, 3,\n          kernel_regularizer=\"l2\")\n      out = tf.compat.v1.layers.flatten(out)\n      out = tf.compat.v1.layers.dense(\n          out, self.units,\n          kernel_regularizer=\"l2\")\n      return out\n\nlayer = CompatV1LayerModel(10)\nx = tf.random.normal(shape=(8, 5, 5, 5))\nlayer(x)\n```\n\n----------------------------------------\n\nTITLE: Using Checkpointable Wrappers for Lists in TensorFlow\nDESCRIPTION: This snippet demonstrates how TensorFlow uses wrapper objects for lists to make them checkpointable. It shows how variables added to these wrappers are automatically restored to their saved values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nrestore.listed = []\nprint(restore.listed)  # ListWrapper([])\nv1 = tf.Variable(0.)\nrestore.listed.append(v1)  # Restores v1, from restore() in the previous cell\nassert 1. == v1.numpy()\n```\n\n----------------------------------------\n\nTITLE: Using Text Embeddings with Feature Columns in TensorFlow Estimators\nDESCRIPTION: Shows how to incorporate text embeddings from TensorFlow Hub into a TensorFlow Estimator workflow using feature columns. This example creates a non-trainable text embedding column for use with a DNNClassifier.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/text.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n    feature_columns = [\n      hub.text_embedding_column(\"comment\", \"path/to/module\", trainable=False),\n    ]\n    input_fn = tf.estimator.inputs.numpy_input_fn(features, labels, shuffle=True)\n    estimator = tf.estimator.DNNClassifier(hidden_units, feature_columns)\n    estimator.train(input_fn, max_steps=100)\n```\n\n----------------------------------------\n\nTITLE: Host Training Loop with tf.function and Iterator\nDESCRIPTION: This snippet shows a basic pattern for creating a host training loop using tf.function, which executes multiple training steps in a single function call. This approach can lead to parallelization of iterations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_fn(iterator):\n  for _ in tf.range(steps_per_loop):\n    strategy.run(step_fn, args=(next(iterator),))\n```\n\n----------------------------------------\n\nTITLE: Using Sparse Tensors with Keras in TensorFlow\nDESCRIPTION: This code demonstrates how to use sparse tensors as inputs to a Keras model. It creates a simple model with a dense layer that accepts sparse input, and shows how to make predictions using sparse data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nx = tf.keras.Input(shape=(4,), sparse=True)\ny = tf.keras.layers.Dense(4)(x)\nmodel = tf.keras.Model(x, y)\n\nsparse_data = tf.sparse.SparseTensor(\n    indices = [(0,0),(0,1),(0,2),\n               (4,3),(5,0),(5,1)],\n    values = [1,1,1,1,1,1],\n    dense_shape = (6,4)\n)\n\nmodel(sparse_data)\n\nmodel.predict(sparse_data)\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model to .keras File in Python\nDESCRIPTION: This snippet demonstrates how to save a Keras sequential model to a .keras file. The .keras extension is used to indicate the specialized zip archive saving format for Keras models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nmy_sequential_model.save(\"exname_of_file.keras\")\n```\n\n----------------------------------------\n\nTITLE: Optimizing Dataset Performance\nDESCRIPTION: Configures the dataset for optimal training performance by adding caching, shuffling, batching, and prefetching. These operations significantly improve training speed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef configure_for_performance(ds):\n  ds = ds.cache()\n  ds = ds.shuffle(buffer_size=1000)\n  ds = ds.batch(batch_size)\n  ds = ds.prefetch(buffer_size=AUTOTUNE)\n  return ds\n\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple Keras Optimizers with TensorFlow Functions\nDESCRIPTION: This snippet illustrates the issue of using multiple Keras optimizers with tf.functions and provides two solutions: using a tf.Module subclass to hold optimizer instances, and creating multiple instances of the tf.function wrapper for each optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nopt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\nopt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n\n@tf.function\ndef train_step(w, x, y, optimizer):\n   with tf.GradientTape() as tape:\n       L = tf.reduce_sum(tf.square(w*x - y))\n   gradients = tape.gradient(L, [w])\n   optimizer.apply_gradients(zip(gradients, [w]))\n\nw = tf.Variable(2.)\nx = tf.constant([-1.])\ny = tf.constant([2.])\n\ntrain_step(w, x, y, opt1)\nprint(\"Calling `train_step` with different optimizer...\")\nwith assert_raises(ValueError):\n  train_step(w, x, y, opt2)\n\nclass TrainStep(tf.Module):\n  def __init__(self, optimizer):\n    self.optimizer = optimizer\n\n  @tf.function\n  def __call__(self, w, x, y):\n    with tf.GradientTape() as tape:\n       L = tf.reduce_sum(tf.square(w*x - y))\n    gradients = tape.gradient(L, [w])\n    self.optimizer.apply_gradients(zip(gradients, [w]))\n\n\nopt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\nopt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n\ntrain_o1 = TrainStep(opt1)\ntrain_o2 = TrainStep(opt2)\n\ntrain_o1(w, x, y)\ntrain_o2(w, x, y)\n\nopt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\nopt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n\n# Not a tf.function.\ndef train_step(w, x, y, optimizer):\n   with tf.GradientTape() as tape:\n       L = tf.reduce_sum(tf.square(w*x - y))\n   gradients = tape.gradient(L, [w])\n   optimizer.apply_gradients(zip(gradients, [w]))\n\nw = tf.Variable(2.)\nx = tf.constant([-1.])\ny = tf.constant([2.])\n```\n\n----------------------------------------\n\nTITLE: Loading Input Image for Pose Detection\nDESCRIPTION: Downloads a sample image and loads it using TensorFlow's image processing functions for pose detection inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!curl -o input_image.jpeg https://images.pexels.com/photos/4384679/pexels-photo-4384679.jpeg --silent\n```\n\nLANGUAGE: python\nCODE:\n```\n# Load the input image.\nimage_path = 'input_image.jpeg'\nimage = tf.io.read_file(image_path)\nimage = tf.image.decode_jpeg(image)\n```\n\n----------------------------------------\n\nTITLE: Parsing TFRecord Dataset with tf.data\nDESCRIPTION: This snippet demonstrates how to parse a TFRecord dataset using tf.data.Dataset.map with a custom parsing function. It defines a feature description and applies it to parse each record.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Create a description of the features.\nfeature_description = {\n    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n}\n\ndef _parse_function(example_proto):\n  # Parse the input `tf.train.Example` proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, feature_description)\n\nparsed_dataset = raw_dataset.map(_parse_function)\nparsed_dataset\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset\nDESCRIPTION: Loads the MNIST dataset using Keras and normalizes the pixel values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist # The MNIST dataset.\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: Inspecting Checkpoint Variables with inspect_checkpoint in Python\nDESCRIPTION: This Python snippet uses the inspect_checkpoint library to inspect variable values stored in checkpoint files. It demonstrates printing all tensor values and selectively inspecting specified tensors. Requires TensorFlow setup and access to the inspect_checkpoint tool.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# import the inspect_checkpoint library\nfrom tensorflow.python.tools import inspect_checkpoint as chkp\n\n# print all tensors in checkpoint file\nchkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='', all_tensors=True)\n\n# tensor_name:  v1\n# [ 1.  1.  1.]\n# tensor_name:  v2\n# [-1. -1. -1. -1. -1.]\n\n# print only tensor v1 in checkpoint file\nchkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v1', all_tensors=False)\n\n# tensor_name:  v1\n# [ 1.  1.  1.]\n\n# print only tensor v2 in checkpoint file\nchkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v2', all_tensors=False)\n\n# tensor_name:  v2\n# [-1. -1. -1. -1. -1.]\n```\n\n----------------------------------------\n\nTITLE: Filtering Audio Data with Pandas in Python\nDESCRIPTION: Filters a pandas DataFrame to keep only dog and cat classes, maps class labels to numeric IDs, and constructs full file paths for audio files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmy_classes = ['dog', 'cat']\nmap_class_to_id = {'dog':0, 'cat':1}\n\nfiltered_pd = pd_data[pd_data.category.isin(my_classes)]\n\nclass_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\nfiltered_pd = filtered_pd.assign(target=class_id)\n\nfull_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\nfiltered_pd = filtered_pd.assign(filename=full_path)\n\nfiltered_pd.head(10)\n```\n\n----------------------------------------\n\nTITLE: Loading I3D Model from TensorFlow Hub\nDESCRIPTION: This snippet loads the pre-trained I3D model from TensorFlow Hub, which will be used for action recognition in video data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ni3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']\n```\n\n----------------------------------------\n\nTITLE: Loading Training Dataset with Text Processing\nDESCRIPTION: Creates a TensorFlow dataset from the movie review text files with proper batching and validation split configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\nseed = 42\n\nraw_train_ds = tf.keras.utils.text_dataset_from_directory(\n    'aclImdb/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='training',\n    seed=seed)\n```\n\n----------------------------------------\n\nTITLE: Converting TF1.x Dense Layer to TF2-compatible Keras Layer in Python\nDESCRIPTION: This snippet demonstrates how to convert a TF1.x-style dense layer into a TF2-compatible Keras layer using the track_tf1_style_variables decorator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nclass DenseLayer(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    out = inputs\n    with tf.compat.v1.variable_scope(\"dense\"):\n      # The weights are created with a `regularizer`,\n      # so the layer should track their regularization losses\n      kernel = tf.compat.v1.get_variable(\n          shape=[out.shape[-1], self.units],\n          regularizer=tf.keras.regularizers.L2(),\n          initializer=tf.compat.v1.initializers.glorot_normal,\n          name=\"kernel\")\n      bias = tf.compat.v1.get_variable(\n          shape=[self.units,],\n          initializer=tf.compat.v1.initializers.zeros,\n          name=\"bias\")\n      out = tf.linalg.matmul(out, kernel)\n      out = tf.compat.v1.nn.bias_add(out, bias)\n    return out\n\nlayer = DenseLayer(10)\nx = tf.random.normal(shape=(8, 20))\nlayer(x)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Up Dataset\nDESCRIPTION: Imports TensorFlow modules and creates a simple dataset for demonstration purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/logging_stop_hook.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\nfeatures = [[1., 1.5], [2., 2.5], [3., 3.5]]\nlabels = [[0.3], [0.5], [0.7]]\n\n# Define an input function.\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Random Image Inversion Results using Matplotlib\nDESCRIPTION: Demonstrates the random inversion augmentation by displaying 9 augmented versions of the same image. This code creates a grid of subplots showing how the random inversion transforms the input image differently on each application.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  augmented_image = random_invert(image)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n  plt.axis(\"off\")\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Python Side Effects in tf.function\nDESCRIPTION: Illustrates how Python side effects like print statements only execute during tracing, while TensorFlow operations like tf.print execute on every call.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f(x):\n  print(\"Traced with\", x)\n  tf.print(\"Executed with\", x)\n\nf(1)\nf(1)\nf(2)\n```\n\n----------------------------------------\n\nTITLE: Importing and Configuring Matplotlib in Python\nDESCRIPTION: This snippet imports matplotlib and configures the figure size for subsequent plots.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nmatplotlib.rcParams['figure.figsize'] = [9, 6]\n```\n\n----------------------------------------\n\nTITLE: Loading Label Map Data\nDESCRIPTION: This code loads the label map data, which maps index numbers to category names for object detection results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nPATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Categorical Vocabulary Column\nDESCRIPTION: Demonstrates the beginning of creating a categorical vocabulary column for mapping strings to one-hot vectors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Given input \"feature_name_from_input_fn\" which is a string,\n```\n\n----------------------------------------\n\nTITLE: Broadcasting error with mismatched trailing dimensions in 3D RaggedTensor\nDESCRIPTION: Demonstrates an error when adding two 3D ragged tensors with compatible ragged dimensions but different trailing dimensions (2 vs 3). The trailing dimensions must match for broadcasting to succeed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged): 3 x (r1) x 2\n# y      (3d ragged): 3 x (r1) x 3  # trailing dimensions do not match\nx = tf.ragged.constant([[[1, 2], [3, 4], [5, 6]],\n                        [[7, 8], [9, 10]]])\ny = tf.ragged.constant([[[1, 2, 0], [3, 4, 0], [5, 6, 0]],\n                        [[7, 8, 0], [9, 10, 0]]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Loading ImageNet Labels for Classification Results\nDESCRIPTION: Downloads and loads the ImageNet label file which maps numerical class predictions to human-readable labels for image classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlabels_path = tf.keras.utils.get_file(\n    'ImageNetLabels.txt',\n    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\nimagenet_labels = np.array(open(labels_path).read().splitlines())\n```\n\n----------------------------------------\n\nTITLE: List Input/Output Op Registration Examples in C++\nDESCRIPTION: Shows various ways to register ops that handle lists of tensors, including type polymorphic lists, type-restricted lists, and fixed-type lists with length constraints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_34\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"PolymorphicListExample\")\n    .Attr(\"T: list(type)\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"ListTypeRestrictionExample\")\n    .Attr(\"T: list({float, double})\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"IntListInputExample\")\n    .Attr(\"N: int\")\n    .Input(\"in: N * int32\")\n    .Output(\"out: int32\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"SameListInputExample\")\n    .Attr(\"N: int\")\n    .Attr(\"T: type\")\n    .Input(\"in: N * T\")\n    .Output(\"out: T\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"MinLengthIntListExample\")\n    .Attr(\"N: int >= 2\")\n    .Input(\"in: N * int32\")\n    .Output(\"out: int32\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"MinimumLengthPolymorphicListExample\")\n    .Attr(\"T: list(type) >= 3\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating the TensorFlow Estimator\nDESCRIPTION: Trains the converted Estimator for 500 steps using the input function, then evaluates it for 10 steps and prints the evaluation results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nkeras_estimator.train(input_fn=input_fn, steps=500)\neval_result = keras_estimator.evaluate(input_fn=input_fn, steps=10)\nprint('Eval result: {}'.format(eval_result))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow License Definition in Python\nDESCRIPTION: Apache 2.0 license header for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from Tensor Slices\nDESCRIPTION: Uses tf.data.Dataset.from_tensor_slices to create a dataset from the features dictionary, providing a more efficient way to handle data than manual slicing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfeatures_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)\n```\n\n----------------------------------------\n\nTITLE: Defining Input Function for Estimator Training in Python\nDESCRIPTION: This snippet outlines the definition of an input function for training a TensorFlow Estimator. It returns a dataset created from tensors, designed to repeatedly produce batches for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef input_fn():\n  dataset = tf.data.Dataset.from_tensors(({\"feats\":[1.]}, [1.]))\n  return dataset.repeat(1000).batch(10)\nregressor.train(input_fn=input_fn, steps=10)\nregressor.evaluate(input_fn=input_fn, steps=10)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Model Output in Eager Execution\nDESCRIPTION: This code snippet shows how to call the model and inspect its output in eager execution mode, even before training. It takes a single batch of images from the dataset and prints the logits produced by the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfor images,labels in dataset.take(1):\n  print(\"Logits: \", mnist_model(images[0:1]).numpy())\n```\n\n----------------------------------------\n\nTITLE: Initializing Dataset and Retrieving Information\nDESCRIPTION: Code to download the flower images, split them into training and test sets, and display information about the dataset such as the number of classes and images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Download the images and split the images into train and test sets.\ndownload_images()\nTRAIN_EXAMPLES, TEST_EXAMPLES, CLASSES = make_train_and_test_sets()\nNUM_CLASSES = len(CLASSES)\n\nprint('\\nThe dataset has %d label classes: %s' % (NUM_CLASSES, CLASSES.values()))\nprint('There are %d training images' % len(TRAIN_EXAMPLES))\nprint('there are %d test images' % len(TEST_EXAMPLES))\n```\n\n----------------------------------------\n\nTITLE: Creating Generator with Specific Algorithm\nDESCRIPTION: Example showing how to create a random number generator with a specific algorithm (philox).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ng1 = tf.random.Generator.from_seed(1, alg='philox')\nprint(g1.normal(shape=[2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Attributions for Giant Panda Image Classification in Python\nDESCRIPTION: This code snippet shows how to apply the plot_img_attributions function to visualize Integrated Gradients attributions for a 'Giant Panda' image. It uses different parameters for steps, color map, and overlay alpha to highlight the model's focus on the panda's texture, nose, and facial fur.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n_ = plot_img_attributions(image=img_name_tensors['Giant Panda'],\n                          baseline=baseline,\n                          target_class_idx=389,\n                          m_steps=55,\n                          cmap=plt.cm.viridis,\n                          overlay_alpha=0.5)\n```\n\n----------------------------------------\n\nTITLE: Defining License in Python Comment Block\nDESCRIPTION: Python comment block defining the Apache License 2.0 terms under which the code is licensed, specifying distribution terms and limitations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow CPU-only Version\nDESCRIPTION: Commands to install the CPU-only version of TensorFlow and verify the installation. This is suitable for systems without GPU or where GPU support is not needed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install tensorflow\n# Verify the installation:\npython3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets\nDESCRIPTION: Creates separate tf.data.Dataset objects for positive and negative examples with shuffling and repetition.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = 100000\n\ndef make_ds(features, labels):\n  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n  ds = ds.shuffle(BUFFER_SIZE).repeat()\n  return ds\n\npos_ds = make_ds(pos_features, pos_labels)\nneg_ds = make_ds(neg_features, neg_labels)\n```\n\n----------------------------------------\n\nTITLE: Reloading TensorFlow Model in Python\nDESCRIPTION: This snippet reinitializes a model from a saved path using TensorFlow's Keras API. The `tf.keras.models.load_model` function is employed to reload the model, ensuring it operates identically to the original. Dependencies include TensorFlow and TensorFlow Hub for any custom Keras layers. The input is the export path, and no explicit output is produced, although the reloaded model is ready for inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nreloaded = tf.keras.models.load_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})\n```\n\n----------------------------------------\n\nTITLE: Creating a Titanic Dataset from CSV in TensorFlow\nDESCRIPTION: Downloads the Titanic dataset CSV file and creates a TextLineDataset for processing the data line by line.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_63\n\nLANGUAGE: python\nCODE:\n```\ntitanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\ntitanic_lines = tf.data.TextLineDataset(titanic_file)\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub SavedModel\nDESCRIPTION: Example of loading a SavedModel from TensorFlow Hub using the hub.load() function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/reusable_saved_models.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nobj = hub.load(url)\n```\n\n----------------------------------------\n\nTITLE: Formatting Video Frames in TensorFlow\nDESCRIPTION: This function pads and resizes an image frame from a video. It converts the frame to float32 and resizes it with padding to the specified output size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef format_frames(frame, output_size):\n  \"\"\"\n    Pad and resize an image from a video.\n    \n    Args:\n      frame: Image that needs to resized and padded. \n      output_size: Pixel size of the output frame image.\n\n    Return:\n      Formatted frame with padding of specified output size.\n  \"\"\"\n  frame = tf.image.convert_image_dtype(frame, tf.float32)\n  frame = tf.image.resize_with_pad(frame, *output_size)\n  return frame\n```\n\n----------------------------------------\n\nTITLE: Creating Model Instance for Custom Training in TensorFlow\nDESCRIPTION: Instantiates a new model for custom training implementation, using the same parameters as the earlier model for vocabulary size, embedding dimensions, RNN units, and batch size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nmodel = build_model(\n  vocab_size = len(vocab),\n  embedding_dim=embedding_dim,\n  rnn_units=rnn_units,\n  batch_size=BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Alternative Pixel Rescaling using Keras Layers\nDESCRIPTION: Shows how to use tf.keras.layers.Rescaling to normalize pixel values from [0, 255] to [-1, 1] as an alternative to the built-in preprocessing function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nrescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n```\n\n----------------------------------------\n\nTITLE: Configuring Training Parameters for JAX and TensorFlow\nDESCRIPTION: Defines training hyperparameters including number of epochs, batch size, learning rate, and decay settings for both JAX (using Optax) and TensorFlow training phases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Training hyperparameters.\nJAX_EPOCHS = 3\nTF_EPOCHS = 7\nSTEPS_PER_EPOCH = len(train_labels)//BATCH_SIZE\nLEARNING_RATE = 0.01\nLEARNING_RATE_EXP_DECAY = 0.6\n\n# The learning rate schedule for JAX (with Optax).\njlr_decay = optax.exponential_decay(LEARNING_RATE, transition_steps=STEPS_PER_EPOCH, decay_rate=LEARNING_RATE_EXP_DECAY, staircase=True)\n\n# THe learning rate schedule for TensorFlow.\ntflr_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=LEARNING_RATE, decay_steps=STEPS_PER_EPOCH, decay_rate=LEARNING_RATE_EXP_DECAY, staircase=True)\n```\n\n----------------------------------------\n\nTITLE: Setting Parameters for Embedding Generation in Python\nDESCRIPTION: This code snippet sets the module URL for the Universal Sentence Encoder and the projected dimension for random projection. It allows users to choose whether to use random projection or not.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodule_url = 'https://tfhub.dev/google/universal-sentence-encoder/2' #@param {type:\"string\"}\nprojected_dim = 64  #@param {type:\"number\"}\n```\n\n----------------------------------------\n\nTITLE: Downloading UCF-101 Video Dataset Subset with TensorFlow\nDESCRIPTION: This snippet demonstrates how to download a subset of the UCF-101 video dataset by specifying the number of classes and splits for training and testing purposes. It uses a URL pointing to the zip file containing the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nURL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\ndownload_dir = pathlib.Path('./UCF101_subset/')\nsubset_paths = download_ufc_101_subset(URL, \n                        num_classes = 10, \n                        splits = {\"train\": 30, \"test\": 20}, \n                        download_dir = download_dir)\n```\n\n----------------------------------------\n\nTITLE: Creating and Inspecting a Tensor Slices Dataset\nDESCRIPTION: Creates a dataset from a random uniform tensor of integers and shows how to examine the individual elements by iterating through it.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndataset1 = tf.data.Dataset.from_tensor_slices(\n    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\n\ndataset1\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Keras Callback for Model.fit - Python\nDESCRIPTION: This snippet demonstrates the creation of a custom Keras callback to log metrics, including examples per second during training with Keras Model.fit. This bridges the functionality from TensorFlow 1's hooks to TensorFlow 2's callback mechanism.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/sessionrunhook_callback.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass CustomCallback(tf.keras.callbacks.Callback):\n\n    def on_train_begin(self, logs = None):\n      self._step = -1\n      self._start_time = time.time()\n      self.log_frequency = 10\n\n    def on_train_batch_begin(self, batch, logs = None):\n      self._step += 1\n\n    def on_train_batch_end(self, batch, logs = None):\n      if self._step % self.log_frequency == 0:\n        current_time = time.time()\n        duration = current_time - self._start_time\n        self._start_time = current_time\n        examples_per_sec = self.log_frequency / duration\n        print('Time:', datetime.now(), ', Step #:', self._step,\n              ', Examples per second:', examples_per_sec)\n\ncallback = CustomCallback()\n```\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(\n    (features, labels)).batch(1).repeat(100)\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n\nmodel.compile(optimizer, \"mse\")\n\n# Begin training.\nresult = model.fit(dataset, callbacks=[callback], verbose = 0)\n# Provide the results of training metrics.\nresult.history\n```\n\n----------------------------------------\n\nTITLE: Installing Object Detection API Dependencies\nDESCRIPTION: This bash script installs the protobuf compiler and sets up the Object Detection API by compiling protobufs and installing the package.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\nsudo apt install -y protobuf-compiler\ncd models/research/\nprotoc object_detection/protos/*.proto --python_out=.\ncp object_detection/packages/tf2/setup.py .\npython -m pip install .\n```\n\n----------------------------------------\n\nTITLE: Saving and Restoring Iterator State\nDESCRIPTION: Demonstrates how to save and restore the state of a dataset iterator using tf.train.Saver and SaveableObject.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsaveable = tf.contrib.data.make_saveable_from_iterator(iterator)\n\ntf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n\n  if should_checkpoint:\n    saver.save(path_to_checkpoint)\n\nwith tf.Session() as sess:\n  saver.restore(sess, path_to_checkpoint)\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model as SavedModel\nDESCRIPTION: Save a TensorFlow Keras model using the experimental SavedModel format, generating a timestamped directory with model artifacts\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nsaved_model_path = \"./saved_models/\"+str(int(time.time()))\nmodel.save(saved_model_path, save_format='tf')\n```\n\nLANGUAGE: python\nCODE:\n```\nnew_model = tf.keras.models.load_model(saved_model_path)\nnew_model\n```\n\n----------------------------------------\n\nTITLE: Processing CSV Dataset with Selected Columns in TensorFlow\nDESCRIPTION: This snippet shows how to iterate over the CSV dataset with selected columns and print feature and label batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nfor feature_batch, label_batch in titanic_batches.take(1):\n  print(\"'survived': {}\".format(label_batch))\n  for key, value in feature_batch.items():\n    print(\"  {!r:20s}: {}\".format(key, value))\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Image for Object Detection\nDESCRIPTION: This code cell allows the user to select an image, optionally flip it horizontally or convert it to grayscale, and display it for object detection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n#@title Image Selection (don't forget to execute the cell!) { display-mode: \"form\"}\nselected_image = 'Beach' # @param ['Beach', 'Dogs', 'Naxos Taverna', 'Beatles', 'Phones', 'Birds']\nflip_image_horizontally = False #@param {type:\"boolean\"}\nconvert_image_to_grayscale = False #@param {type:\"boolean\"}\n\nimage_path = IMAGES_FOR_TEST[selected_image]\nimage_np = load_image_into_numpy_array(image_path)\n\n# Flip horizontally\nif(flip_image_horizontally):\n  image_np[0] = np.fliplr(image_np[0]).copy()\n\n# Convert image to grayscale\nif(convert_image_to_grayscale):\n  image_np[0] = np.tile(\n    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np[0])\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Setting Hyperparameters for Citation Intent Classifier\nDESCRIPTION: This code block defines and sets the hyperparameters for the citation intent classifier, including the embedding URL, training settings, and model parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#@title Hyperparmeters { run: \"auto\" }\n\nEMBEDDING = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/1'  #@param {type: \"string\"}\nTRAINABLE_MODULE = False  #@param {type: \"boolean\"}\nSTEPS =   8000#@param {type: \"integer\"}\nEVAL_EVERY = 200  #@param {type: \"integer\"}\nBATCH_SIZE = 10  #@param {type: \"integer\"}\nLEARNING_RATE = 0.01  #@param {type: \"number\"}\n\nparams = {\n    'batch_size': BATCH_SIZE,\n    'learning_rate': LEARNING_RATE,\n    'module_name': EMBEDDING,\n    'trainable_module': TRAINABLE_MODULE\n}\n```\n\n----------------------------------------\n\nTITLE: Early Stopping Callback Implementation\nDESCRIPTION: Configures an early stopping mechanism to halt model training when validation loss stops improving, preventing overfitting\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow and Data Processing\nDESCRIPTION: Import statements for TensorFlow, NumPy, and TensorFlow Datasets, which are the core dependencies required for the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport numpy as np\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Training Model with Mixed Precision\nDESCRIPTION: Demonstrates model training using fit() method with batch processing and validation split.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(x_train, y_train,\n                    batch_size=8192,\n                    epochs=5,\n                    validation_split=0.2)\ntest_scores = model.evaluate(x_test, y_test, verbose=2)\nprint('Test loss:', test_scores[0])\nprint('Test accuracy:', test_scores[1])\n```\n\n----------------------------------------\n\nTITLE: Implementing TensorGraph Subclasses in TensorFlow\nDESCRIPTION: Defines a TensorGraph class and its subclass with additional node features and propagation method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nclass TensorGraph(tf.experimental.ExtensionType):\n  num_nodes: tf.Tensor\n  edge_src: tf.Tensor   # edge_src[e] = index of src node for edge e.\n  edge_dst: tf.Tensor   # edge_dst[e] = index of dst node for edge e.\n\nclass TensorGraphWithNodeFeature(TensorGraph):\n  node_features: tf.Tensor  # node_features[n] = feature value for node n.\n\n  def propagate_features(self, weight=1.0) -> 'TensorGraphWithNodeFeature':\n    updates = tf.gather(self.node_features, self.edge_src) * weight\n    new_node_features = tf.tensor_scatter_nd_add(\n        self.node_features, tf.expand_dims(self.edge_dst, 1), updates)\n    return TensorGraphWithNodeFeature(\n        self.num_nodes, self.edge_src, self.edge_dst, new_node_features)\n\ng = TensorGraphWithNodeFeature(  # Edges: 0->1, 4->3, 2->2, 2->1\n    num_nodes=5, edge_src=[0, 4, 2, 2], edge_dst=[1, 3, 2, 1],\n    node_features=[10.0, 0.0, 2.0, 5.0, -1.0, 0.0])\n\nprint(\"Original features:\", g.node_features)\nprint(\"After propagating:\", g.propagate_features().node_features)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading TensorFlow Model with Custom I/O Device\nDESCRIPTION: This snippet demonstrates how to save a TensorFlow model to a local path using custom I/O device options, and then load it using a different strategy. It uses the 'experimental_io_device' option to specify the job as localhost.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Saving the model to a path on localhost.\nsaved_model_path = '/tmp/tf_save'\nsave_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nmodel.save(saved_model_path, options=save_options)\n\n# Loading the model from a path on localhost.\nanother_strategy = tf.distribute.MirroredStrategy()\nwith another_strategy.scope():\n  load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n  loaded = tf.keras.models.load_model(saved_model_path, options=load_options)\n```\n\n----------------------------------------\n\nTITLE: Executing Training Loop\nDESCRIPTION: Implements the main training loop over specified epochs, including both training and testing steps with progress reporting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nEPOCHS = 5\n\nfor epoch in range(EPOCHS):\n  train_loss.reset_state()\n  train_accuracy.reset_state()\n  test_loss.reset_state()\n  test_accuracy.reset_state()\n\n  for images, labels in train_ds:\n    train_step(images, labels)\n\n  for test_images, test_labels in test_ds:\n    test_step(test_images, test_labels)\n\n  print(\n    f'Epoch {epoch + 1}, '\n    f'Loss: {train_loss.result():0.2f}, '\n    f'Accuracy: {train_accuracy.result() * 100:0.2f}, '\n    f'Test Loss: {test_loss.result():0.2f}, '\n    f'Test Accuracy: {test_accuracy.result() * 100:0.2f}'\n  )\n```\n\n----------------------------------------\n\nTITLE: Transforming Ragged Tensors in Datasets using Python\nDESCRIPTION: This snippet demonstrates how to create or transform ragged tensors in Datasets using Dataset.map. It defines a function to calculate mean length and create length ranges from a features dictionary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ndef transform_lengths(features):\n  return {\n      'mean_length': tf.math.reduce_mean(features['lengths']),\n      'length_ranges': tf.ragged.range(features['lengths'])}\ntransformed_dataset = dataset.map(transform_lengths)\nprint_dictionary_dataset(transformed_dataset)\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from CSV File\nDESCRIPTION: This snippet creates a TensorFlow dataset from the downloaded CSV file, reading it directly from the gzip file without decompression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")\n```\n\n----------------------------------------\n\nTITLE: Loading Flowers Dataset with TensorFlow Datasets\nDESCRIPTION: Downloads and splits the tf_flowers dataset using TensorFlow Datasets. This provides train, validation and test sets with metadata in a single command.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n(train_ds, val_ds, test_ds), metadata = tfds.load(\n    'tf_flowers',\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n    with_info=True,\n    as_supervised=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating CsvDataset in TensorFlow\nDESCRIPTION: Initializes a CsvDataset to parse records from multiple CSV files using TensorFlow. It requires filenames and record defaults, which help in generating elements corresponding to each CSV record column.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\nfilenames = [\"/var/data/file1.csv\", \"/var/data/file2.csv\"]\nrecord_defaults = [tf.float32] * 8   # Eight required float columns\ndataset = tf.data.experimental.CsvDataset(filenames, record_defaults)\n```\n\n----------------------------------------\n\nTITLE: Calculating Path Gradients for Integrated Gradients in TensorFlow\nDESCRIPTION: This snippet computes gradients for interpolated images along the path from baseline to input image. It uses the compute_gradients function and specifies the target class index for the 'Fireboat' class (555).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\npath_gradients = compute_gradients(\n    images=interpolated_images,\n    target_class_idx=555)\n```\n\n----------------------------------------\n\nTITLE: Setting Default Field Values in ExtensionType in Python\nDESCRIPTION: Demonstrates how to define default values for fields in an ExtensionType class by setting values at the class level, using a Pencil class example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Pencil(tf.experimental.ExtensionType):\n  color: str = \"black\"\n  has_erasor: bool = True\n  length: tf.Tensor = 1.0\n\nPencil()\n```\n\n----------------------------------------\n\nTITLE: Naming Operations with TensorFlow Name Scopes\nDESCRIPTION: Demonstrates how to use name scopes to organize and name operations in a TensorFlow graph. Shows hierarchical naming and uniquification of operation names when duplicates exist.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nc_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n\n# Already-used names will be \"uniquified\".\nc_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n\n# Name scopes add a prefix to all operations created in the same context.\nwith tf.name_scope(\"outer\"):\n    c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n\n    # Name scopes nest like paths in a hierarchical file system.\n    with tf.name_scope(\"inner\"):\n      c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n\n    # Exiting a name scope context will return to the previous prefix.\n    c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n\n    # Already-used name scopes will be \"uniquified\".\n    with tf.name_scope(\"inner\"):\n      c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n```\n\n----------------------------------------\n\nTITLE: Defining Wrapper Function for Seed Updates\nDESCRIPTION: Creates a wrapper function that generates new seeds and applies them to the augment function for random transformations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: Python\nCODE:\n```\n# Create a wrapper function for updating seeds.\ndef f(x, y):\n  seed = rng.make_seeds(1)[:, 0]\n  image, label = augment((x, y), seed)\n  return image, label\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential CNN Model in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a simple Convolutional Neural Network (CNN) model using TensorFlow's Keras Sequential API. The model consists of two Conv2D layers, a GlobalAveragePooling2D layer, and a Dense output layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmnist_model = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(10)\n])\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Music Generation\nDESCRIPTION: Import required Python libraries for data processing, visualization, and neural network implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport collections\nimport datetime\nimport fluidsynth\nimport glob\nimport numpy as np\nimport pathlib\nimport pandas as pd\nimport pretty_midi\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nfrom typing import Optional\n```\n\n----------------------------------------\n\nTITLE: Creating visualization functions for semantic similarity\nDESCRIPTION: Defines utility functions to calculate and visualize the semantic similarity between sentences using a heatmap, where the inner product of sentence embeddings represents similarity.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef plot_similarity(labels, features, rotation):\n  corr = np.inner(features, features)\n  sns.set(font_scale=1.2)\n  g = sns.heatmap(\n      corr,\n      xticklabels=labels,\n      yticklabels=labels,\n      vmin=0,\n      vmax=1,\n      cmap=\"YlOrRd\")\n  g.set_xticklabels(labels, rotation=rotation)\n  g.set_title(\"Semantic Textual Similarity\")\n\n\ndef run_and_plot(session, input_placeholder, messages):\n  values, indices, dense_shape = process_to_IDs_in_sparse_format(sp,messages)\n\n  message_embeddings = session.run(\n      encodings,\n      feed_dict={input_placeholder.values: values,\n                input_placeholder.indices: indices,\n                input_placeholder.dense_shape: dense_shape})\n  \n  plot_similarity(messages, message_embeddings, 90)\n```\n\n----------------------------------------\n\nTITLE: Registering a Polymorphic TensorFlow Op in C++\nDESCRIPTION: Example of registering a backwards-compatible polymorphic TensorFlow operation that accepts and outputs a generic numeric type, defaulting to float.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_37\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"MyGeneralUnaryOp\")\n    .Input(\"in: T\")\n    .Output(\"out: T\")\n    .Attr(\"T: numerictype = DT_FLOAT\");\n```\n\n----------------------------------------\n\nTITLE: Bit-widening Restrictions in 'safe' Mode\nDESCRIPTION: Example showing that mixing int8 and uint32 types is not allowed in 'safe' mode, resulting in a TypeError to prevent bit-widening.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# This promotion is not allowed in SAFE mode.\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\na = tf.constant(10, dtype = tf.int8)\nb = tf.constant(5, dtype = tf.uint32)\ntry:\n  a + b\nexcept TypeError as e:\n   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode.\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Dependencies\nDESCRIPTION: Code for installing TensorFlow 2.11 and TensorFlow I/O 0.28, which is needed for audio file processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q \"tensorflow==2.11.*\"\n# tensorflow_io 0.28 is compatible with TensorFlow 2.11\n!pip install -q \"tensorflow_io==0.28.*\"\n```\n\n----------------------------------------\n\nTITLE: Quantizing Pitch Predictions to Notes in Python\nDESCRIPTION: This code quantizes pitch predictions into musical notes or rests. It uses heuristics to estimate the most likely sequence of notes sung, considering speed and time offsets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef quantize_predictions(group, ideal_offset):\n  # Group values are either 0, or a pitch in Hz.\n  non_zero_values = [v for v in group if v != 0]\n  zero_values_count = len(group) - len(non_zero_values)\n\n  # Create a rest if 80% is silent, otherwise create a note.\n  if zero_values_count > 0.8 * len(group):\n    # Interpret as a rest. Count each dropped note as an error, weighted a bit\n    # worse than a badly sung note (which would 'cost' 0.5).\n    return 0.51 * len(non_zero_values), \"Rest\"\n  else:\n    # Interpret as note, estimating as mean of non-rest predictions.\n    h = round(\n        statistics.mean([\n            12 * math.log2(freq / C0) - ideal_offset for freq in non_zero_values\n        ]))\n    octave = h // 12\n    n = h % 12\n    note = note_names[n] + str(octave)\n    # Quantization error is the total difference from the quantized note.\n    error = sum([\n        abs(12 * math.log2(freq / C0) - ideal_offset - h)\n        for freq in non_zero_values\n    ])\n    return error, note\n\n\ndef get_quantization_and_error(pitch_outputs_and_rests, predictions_per_eighth,\n                               prediction_start_offset, ideal_offset):\n  # Apply the start offset - we can just add the offset as rests.\n  pitch_outputs_and_rests = [0] * prediction_start_offset + \\\n                            pitch_outputs_and_rests\n  # Collect the predictions for each note (or rest).\n  groups = [\n      pitch_outputs_and_rests[i:i + predictions_per_eighth]\n      for i in range(0, len(pitch_outputs_and_rests), predictions_per_eighth)\n  ]\n\n  quantization_error = 0\n\n  notes_and_rests = []\n  for group in groups:\n    error, note_or_rest = quantize_predictions(group, ideal_offset)\n    quantization_error += error\n    notes_and_rests.append(note_or_rest)\n\n  return quantization_error, notes_and_rests\n\n\nbest_error = float(\"inf\")\nbest_notes_and_rests = None\nbest_predictions_per_note = None\n\nfor predictions_per_note in range(20, 65, 1):\n  for prediction_start_offset in range(predictions_per_note):\n\n    error, notes_and_rests = get_quantization_and_error(\n        pitch_outputs_and_rests, predictions_per_note,\n        prediction_start_offset, ideal_offset)\n\n    if error < best_error:      \n      best_error = error\n      best_notes_and_rests = notes_and_rests\n      best_predictions_per_note = predictions_per_note\n\n# At this point, best_notes_and_rests contains the best quantization.\n# Since we don't need to have rests at the beginning, let's remove these:\nwhile best_notes_and_rests[0] == 'Rest':\n  best_notes_and_rests = best_notes_and_rests[1:]\n# Also remove silence at the end.\nwhile best_notes_and_rests[-1] == 'Rest':\n  best_notes_and_rests = best_notes_and_rests[:-1]\n```\n\n----------------------------------------\n\nTITLE: Displaying Training Progress\nDESCRIPTION: Code to visualize training metrics including losses and accuracies, with a note about performance impact when restarting training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndisplay_train_curves(losses, avg_losses, eval_losses, eval_accuracies, len(eval_losses), STEPS_PER_EPOCH, ignore_first_n=2*STEPS_PER_EPOCH)\n\n# The loss takes a hit when the training restarts, but does not go back to random levels.\n# This is likely caused by the optimizer momentum being reinitialized.\n```\n\n----------------------------------------\n\nTITLE: Accessing the First CSV Filename\nDESCRIPTION: Displays the first CSV file in the list of files to be processed. This shows which file will be read first when sequential reading is used.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_50\n\nLANGUAGE: python\nCODE:\n```\nfont_csvs[0]\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Variable Data from TensorFlow Checkpoint\nDESCRIPTION: This snippet shows how to access the shape and dtype of a specific variable in a TensorFlow checkpoint using its key. It demonstrates printing the shape and dtype of the 'net/l1/kernel' variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nkey = 'net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE'\n\nprint(\"Shape:\", shape_from_key[key])\nprint(\"Dtype:\", dtype_from_key[key].name)\n```\n\n----------------------------------------\n\nTITLE: Using MonitoredTrainingSession with Dataset\nDESCRIPTION: This snippet demonstrates how to use `tf.train.MonitoredTrainingSession` with the `tf.data` API. It uses `Dataset.make_one_shot_iterator()` because `MonitoredTrainingSession` uses `tf.errors.OutOfRangeError` to signal training completion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(...)\ndataset = dataset.shuffle(buffer_size=10000)\ndataset = dataset.batch(32)\ndataset = dataset.repeat(num_epochs)\niterator = dataset.make_one_shot_iterator()\n\nnext_example, next_label = iterator.get_next()\nloss = model_function(next_example, next_label)\n\ntraining_op = tf.train.AdagradOptimizer(...).minimize(loss)\n\nwith tf.train.MonitoredTrainingSession(...) as sess:\n  while not sess.should_stop():\n    sess.run(training_op)\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow Model on Dataset\nDESCRIPTION: Initiates model training on the prepared dataset for one epoch with a limited number of steps. This demonstrates the basic training process with the constructed pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(ds, epochs=1, steps_per_epoch=3)\n```\n\n----------------------------------------\n\nTITLE: Initializing MoViNet Model States\nDESCRIPTION: Initializes the internal states of the MoViNet model's RNNs using the 'init_states' signature. It takes the shape of the input video as an argument.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ninitial_state = model.init_states(jumpingjack[tf.newaxis, ...].shape)\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function and Gradient Computation\nDESCRIPTION: Creates a sample loss function and its gradient for testing the optimizer. Includes visualization of the loss and gradient functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nx_vals = tf.linspace(-2, 2, 201)\nx_vals = tf.cast(x_vals, tf.float32)\n\ndef loss(x):\n  return 2*(x**4) + 3*(x**3) + 2\n\ndef grad(f, x):\n  with tf.GradientTape() as tape:\n    tape.watch(x)\n    result = f(x)\n  return tape.gradient(result, x)\n\nplt.plot(x_vals, loss(x_vals), c='k', label = \"Loss function\")\nplt.plot(x_vals, grad(loss, x_vals), c='tab:blue', label = \"Gradient function\")\nplt.plot(0, loss(0),  marker=\"o\", c='g', label = \"Inflection point\")\nplt.plot(-9/8, loss(-9/8),  marker=\"o\", c='r', label = \"Global minimum\")\nplt.legend()\nplt.ylim(0,5)\nplt.xlabel(\"x\")\nplt.ylabel(\"loss\")\nplt.title(\"Sample loss function and gradient\");\n```\n\n----------------------------------------\n\nTITLE: Visualizing TensorBoard for Evaluation - Shell\nDESCRIPTION: This command initializes TensorBoard, enabling users to visualize evaluation metrics from the CIFAR-10 model evaluation process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n\"tensorboard --logdir /tmp/cifar10_eval\"\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Text and PyTorch Dependencies\nDESCRIPTION: Installs required packages for the tutorial: tensorflow-text version 2.11.* and PyTorch version 1.8.1 using pip.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/senteval_for_universal_sentence_encoder_cmlm.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Install dependencies\n!pip install --quiet \"tensorflow-text==2.11.*\"\n!pip install --quiet torch==1.8.1\n```\n\n----------------------------------------\n\nTITLE: Compiling and Running TensorFlow C Program\nDESCRIPTION: These bash commands compile the hello_tf.c program using gcc, linking it with the TensorFlow C library, and then run the resulting executable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngcc hello_tf.c -ltensorflow -o hello_tf\n\n./hello_tf\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Image Classification\nDESCRIPTION: This snippet imports necessary libraries including matplotlib for visualization, numpy for numerical operations, os for file operations, and tensorflow for machine learning tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model Weights (TensorFlow Checkpoint)\nDESCRIPTION: Shows how to save and load the weights of a Keras model using `model.save_weights`. The weights are saved to a TensorFlow Checkpoint file. The `model.load_weights` method restores the model's state, requiring a model with the same architecture.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n```python\nmodel = tf.keras.Sequential([\nlayers.Dense(64, activation='relu', input_shape=(32,)),\nlayers.Dense(10, activation='softmax')])\n\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n```\n```\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Save weights to a TensorFlow Checkpoint file\nmodel.save_weights('./weights/my_model')\n\n# Restore the model's state,\n# this requires a model with the same architecture.\nmodel.load_weights('./weights/my_model')\n```\n```\n\n----------------------------------------\n\nTITLE: Initializing Crop Region for MoveNet in Python\nDESCRIPTION: Defines the default crop region for an image when the algorithm cannot reliably determine it from the previous frame. It pads the full image from both sides to make it square.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef init_crop_region(image_height, image_width):\n  \"\"\"Defines the default crop region.\n\n  The function provides the initial crop region (pads the full image from both\n  sides to make it a square image) when the algorithm cannot reliably determine\n  the crop region from the previous frame.\n  \"\"\"\n  if image_width > image_height:\n    box_height = image_width / image_height\n    box_width = 1.0\n    y_min = (image_height / 2 - image_width / 2) / image_height\n    x_min = 0.0\n  else:\n    box_height = 1.0\n    box_width = image_height / image_width\n    y_min = 0.0\n    x_min = (image_width / 2 - image_height / 2) / image_width\n\n  return {\n    'y_min': y_min,\n    'x_min': x_min,\n    'y_max': y_min + box_height,\n    'x_max': x_min + box_width,\n    'height': box_height,\n    'width': box_width\n  }\n```\n\n----------------------------------------\n\nTITLE: Generating Random Projection Matrix for Dimensionality Reduction\nDESCRIPTION: Defines a function to create a Gaussian random projection matrix for reducing embedding dimensionality, which can improve ANN index performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef generate_random_projection_weights(original_dim, projected_dim):\n  random_projection_matrix = None\n  random_projection_matrix = gaussian_random_matrix(\n      n_components=projected_dim, n_features=original_dim).T\n  print(\"A Gaussian random weight matrix was creates with shape of {}\".format(random_projection_matrix.shape))\n  print('Storing random projection matrix to disk...')\n  with open('random_projection_matrix', 'wb') as handle:\n    pickle.dump(random_projection_matrix, \n                handle, protocol=pickle.HIGHEST_PROTOCOL)\n        \n  return random_projection_matrix\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Citation Intent Classifier\nDESCRIPTION: This code trains the citation intent classifier using the defined estimator and input functions. It evaluates the model periodically and prints the loss and accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nestimator = tf.estimator.Estimator(functools.partial(model_fn, params=params))\nmetrics = []\n\nfor step in range(0, STEPS, EVAL_EVERY):\n  estimator.train(input_fn=functools.partial(input_fn_train, params=params), steps=EVAL_EVERY)\n  step_metrics = estimator.evaluate(input_fn=functools.partial(input_fn_eval, params=params))\n  print('Global step {}: loss {:.3f}, accuracy {:.3f}'.format(step, step_metrics['loss'], step_metrics['accuracy']))\n  metrics.append(step_metrics)\n```\n\n----------------------------------------\n\nTITLE: Implementing Keras Layer for Network Processing\nDESCRIPTION: Custom Keras layer implementation that processes Network ExtensionType objects to balance work between nodes\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nclass BalanceNetworkLayer(tf.keras.layers.Layer):\n  \"\"\"Layer that balances work between nodes in a network.\n\n  Shifts work from more busy nodes to less busy nodes, constrained by bandwidth.\n  \"\"\"\n  def call(self, inputs):\n    # This function is defined above in the \"Batchable `ExtensionType`s\" section.\n    return balance_work_greedy(inputs)\n```\n\n----------------------------------------\n\nTITLE: Creating a Fully Native TF2 Model\nDESCRIPTION: Completes the migration process by removing all remaining tf.compat.v1 components, including the variable scope and track_tf1_style_variables decorator. This results in a purely native TensorFlow 2.0 model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nclass FullyNativeModel(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n    self.conv_layer = tf.keras.layers.Conv2D(\n      3, 3,\n      kernel_regularizer=\"l2\")\n    self.flatten_layer = tf.keras.layers.Flatten()\n    self.dense_layer = tf.keras.layers.Dense(\n      self.units,\n      kernel_regularizer=\"l2\")\n\n  def call(self, inputs):\n    out = self.conv_layer(inputs)\n    out = self.flatten_layer(out)\n    out = self.dense_layer(out)\n    return out\n```\n\n----------------------------------------\n\nTITLE: Specifying Data Type for Numeric Feature Column\nDESCRIPTION: Shows how to create a numeric feature column with an explicit float64 data type specification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Represent a tf.float64 scalar.\nnumeric_feature_column = tf.feature_column.numeric_column(key=\"SepalLength\",\n                                                          dtype=tf.float64)\n```\n\n----------------------------------------\n\nTITLE: Preparing a simple dataset\nDESCRIPTION: This code snippet prepares a simple dataset for demonstration purposes. It defines features, embedding feature indices and values, and labels for both training and evaluation. This dataset will be used in the following code examples to demonstrate how to train embeddings on TPUs using both TensorFlow 1 and TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfeatures = [[1., 1.5]]\nembedding_features_indices = [[0, 0], [0, 1]]\nembedding_features_values = [0, 5]\nlabels = [[0.3]]\neval_features = [[4., 4.5]]\neval_embedding_features_indices = [[0, 0], [0, 1]]\neval_embedding_features_values = [4, 3]\neval_labels = [[0.8]]\n```\n\n----------------------------------------\n\nTITLE: Parsing tf.Example data into RaggedTensors\nDESCRIPTION: Shows how to use tf.io.parse_example with tf.io.RaggedFeature to parse serialized tf.Example protocol buffers into a dictionary of RaggedTensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfeature_specification = {\n    'colors': tf.io.RaggedFeature(tf.string),\n    'lengths': tf.io.RaggedFeature(tf.int64),\n}\nfeature_tensors = tf.io.parse_example(example_batch, feature_specification)\nfor name, value in feature_tensors.items():\n  print(\"{}={}\".format(name, value))\n```\n\n----------------------------------------\n\nTITLE: Measuring Graph Size with Different Data Sources in TensorFlow\nDESCRIPTION: Demonstrates how looping over Python data inside a tf.function causes multiple copies in the graph, while using tf.data.Dataset creates a more efficient graph regardless of data size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef measure_graph_size(f, *args):\n  g = f.get_concrete_function(*args).graph\n  print(\"{}({}) contains {} nodes in its graph\".format(\n      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n\n@tf.function\ndef train(dataset):\n  loss = tf.constant(0)\n  for x, y in dataset:\n    loss += tf.abs(y - x) # Some dummy computation.\n  return loss\n\nsmall_data = [(1, 1)] * 3\nbig_data = [(1, 1)] * 10\nmeasure_graph_size(train, small_data)\nmeasure_graph_size(train, big_data)\n\nmeasure_graph_size(train, tf.data.Dataset.from_generator(\n    lambda: small_data, (tf.int32, tf.int32)))\nmeasure_graph_size(train, tf.data.Dataset.from_generator(\n    lambda: big_data, (tf.int32, tf.int32)))\n```\n\n----------------------------------------\n\nTITLE: Generating Category-Conditional Samples\nDESCRIPTION: Interactive code for generating and displaying category-specific images using the BigGAN model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nnum_samples = 10\ntruncation = 0.4\nnoise_seed = 0\ncategory = \"933) cheeseburger\"\n\nz = truncated_z_sample(num_samples, truncation, noise_seed)\ny = int(category.split(')')[0])\n\nims = sample(sess, z, y, truncation=truncation)\nimshow(imgrid(ims, cols=min(num_samples, 5)))\n```\n\n----------------------------------------\n\nTITLE: Apache Beam Pipeline for Distributed Embedding Generation\nDESCRIPTION: Defines an Apache Beam pipeline function to process input text, generate embeddings in parallel, and write the results as TFRecord files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef run_hub2emb(args):\n  '''Runs the embedding generation pipeline'''\n\n  options = beam.options.pipeline_options.PipelineOptions(**args)\n  args = namedtuple(\"options\", args.keys())(*args.values())\n\n  with beam.Pipeline(args.runner, options=options) as pipeline:\n    (\n        pipeline\n        | 'Read sentences from files' >> beam.io.ReadFromText(\n            file_pattern=args.data_dir)\n        | 'Batch elements' >> util.BatchElements(\n            min_batch_size=args.batch_size, max_batch_size=args.batch_size)\n        | 'Generate embeddings' >> beam.Map(\n            generate_embeddings, args.model_url, args.random_projection_matrix)\n        | 'Encode to tf example' >> beam.FlatMap(to_tf_example)\n        | 'Write to TFRecords files' >> beam.io.WriteToTFRecord(\n            file_path_prefix='{}/emb'.format(args.output_dir),\n            file_name_suffix='.tfrecords')\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Training and Validation Datasets\nDESCRIPTION: Generating the final datasets for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntrain_data, validation_data = make_datasets(train_size)\n```\n\n----------------------------------------\n\nTITLE: Calculating Distortion in TensorFlow for Image Compression\nDESCRIPTION: This snippet calculates the mean absolute difference between the original image and the reconstructed image, which represents the distortion. It then casts the reconstructed image to uint8 and displays it.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndistortion = tf.reduce_mean(abs(x - x_tilde))\nprint(\"distortion:\", distortion)\n\nx_tilde = tf.saturate_cast(x_tilde[0] * 255, tf.uint8)\nplt.imshow(tf.squeeze(x_tilde))\nprint(f\"Data type: {x_tilde.dtype}\")\nprint(f\"Shape: {x_tilde.shape}\")\n```\n\n----------------------------------------\n\nTITLE: Constructing and Executing a TensorFlow Graph in C++\nDESCRIPTION: This example demonstrates creating a simple TensorFlow graph, performing matrix multiplication, and executing it using the C++ API. It shows how to create constants, define operations, and run a session to fetch results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/cc.md#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/cc/client/client_session.h\"\n#include \"tensorflow/cc/ops/standard_ops.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n\nint main() {\n  using namespace tensorflow;\n  using namespace tensorflow::ops;\n  Scope root = Scope::NewRootScope();\n  // Matrix A = [3 2; -1 0]\n  auto A = Const(root, { {3.f, 2.f}, {-1.f, 0.f} });\n  // Vector b = [3 5]\n  auto b = Const(root, { {3.f, 5.f} });\n  // v = Ab^T\n  auto v = MatMul(root.WithOpName(\"v\"), A, b, MatMul::TransposeB(true));\n  std::vector<Tensor> outputs;\n  ClientSession session(root);\n  // Run and fetch v\n  TF_CHECK_OK(session.Run({v}, &outputs));\n  // Expect outputs[0] == [19; -3]\n  LOG(INFO) << outputs[0].matrix<float>();\n  return 0;\n}\n```\n\n----------------------------------------\n\nTITLE: Creating tf.data Dataset from Sparse Tensor in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to create a tf.data.Dataset from a sparse tensor using tf.data.Dataset.from_tensor_slices. It preserves the sparsity of the data and iterates through the dataset, printing each element.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(sparse_data)\nfor element in dataset: \n  print(pprint_sparse_tensor(element))\n```\n\n----------------------------------------\n\nTITLE: Manually Creating a CSV Dataset with TextLineDataset\nDESCRIPTION: This snippet demonstrates how to manually create a CSV dataset using TextLineDataset and decode_csv. It shows the equivalent approach to using CsvDataset, providing more control over the parsing process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_47\n\nLANGUAGE: python\nCODE:\n```\ndef decode_titanic_line(line):\n  return tf.io.decode_csv(line, titanic_types)\n\nmanual_titanic = (\n    # Load the lines of text\n    tf.data.TextLineDataset(titanic_file_path)\n    # Skip the header row.\n    .skip(1)\n    # Decode the line.\n    .map(decode_titanic_line)\n)\n\nfor example in manual_titanic.take(1):\n  print([e.numpy() for e in example])\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing Test Audio Data\nDESCRIPTION: Loads the test audio file, plots the waveform, and creates an audio player for listening to the sound.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntesting_wav_data = load_wav_16k_mono(testing_wav_file_name)\n\n_ = plt.plot(testing_wav_data)\n\n# Play the audio file.\ndisplay.Audio(testing_wav_data, rate=16000)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for MoViNet Video Classification\nDESCRIPTION: Imports the necessary Python libraries and modules for the MoViNet transfer learning tutorial, including general utilities, data visualization tools, TensorFlow/Keras components, and the specific MoViNet implementations from the official TensorFlow models repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tqdm\nimport random\nimport pathlib\nimport itertools\nimport collections\n\nimport cv2\nimport numpy as np\nimport remotezip as rz\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\n\n# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\nfrom official.projects.movinet.modeling import movinet\nfrom official.projects.movinet.modeling import movinet_model\n```\n\n----------------------------------------\n\nTITLE: Examining Labeled Image Data in TensorFlow\nDESCRIPTION: Takes the first element from a labeled dataset containing raw image data and labels, then prints a preview of the raw image bytes and the label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_59\n\nLANGUAGE: python\nCODE:\n```\nfor image_raw, label_text in labeled_ds.take(1):\n  print(repr(image_raw.numpy()[:100]))\n  print()\n  print(label_text.numpy())\n```\n\n----------------------------------------\n\nTITLE: Visualizing YAMNet Sound Classification Results in Python\nDESCRIPTION: This code creates a visualization of the waveform, spectrogram, and top-scoring classes from the YAMNet model output using Matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(10, 6))\n\n# Plot the waveform.\nplt.subplot(3, 1, 1)\nplt.plot(waveform)\nplt.xlim([0, len(waveform)])\n\n# Plot the log-mel spectrogram (returned by the model).\nplt.subplot(3, 1, 2)\nplt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n\n# Plot and label the model output scores for the top-scoring classes.\nmean_scores = np.mean(scores, axis=0)\ntop_n = 10\ntop_class_indices = np.argsort(mean_scores)[::-1][:top_n]\nplt.subplot(3, 1, 3)\nplt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n\n# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n# values from the model documentation\npatch_padding = (0.025 / 2) / 0.01\nplt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n# Label the top_N classes.\nyticks = range(0, top_n, 1)\nplt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n_ = plt.ylim(-0.5 + np.array([top_n, 0]))\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Models Repository in Bash\nDESCRIPTION: This command clones the TensorFlow models repository from GitHub, specifically version r1.13.0, to provide sample code for testing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone --branch r1.13.0 --depth 1 https://github.com/tensorflow/models\n```\n\n----------------------------------------\n\nTITLE: Creating a Two-Dimensional Mesh in TensorFlow DTensor\nDESCRIPTION: Example showing how to create a two-dimensional mesh with dimensions 'x' and 'y' across 6 CPU devices. This creates a 3x2 device grid for distributed tensor operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 3), (\"y\", 2)], devices=DEVICES)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Distributions of Generated Music Features in Python\nDESCRIPTION: Plots the distributions of pitch, step, and duration values in the generated music to analyze the model's output patterns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nplot_distributions(generated_notes)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installation of required Python packages: tensorflow-hub, tensorflow-datasets, and tf-keras\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip install tensorflow-hub\n!pip install tensorflow-datasets\n!pip install tf-keras\n```\n\n----------------------------------------\n\nTITLE: Loading SavedModel in TensorFlow 1\nDESCRIPTION: This function demonstrates how to load a SavedModel in TensorFlow 1 using tf.saved_model.load and run inference using the loaded model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef load_tf1(path, input):\n  print('Loading from', path)\n  with tf.Graph().as_default() as g:\n    with tf1.Session() as sess:\n      meta_graph = tf1.saved_model.load(sess, [\"serve\"], path)\n      sig_def = meta_graph.signature_def[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n      input_name = sig_def.inputs['input'].name\n      output_name = sig_def.outputs['output'].name\n      print('  Output with input', input, ': ', \n            sess.run(output_name, feed_dict={input_name: input}))\n\nload_tf1('saved-model-builder', 5.)\nload_tf1('simple-save', 5.)\nload_tf1('estimator-model', [5.])  # Estimator's input must be batched.\nload_tf1('tf2-save', 5.)\nload_tf1('keras-model', 5.)\n```\n\n----------------------------------------\n\nTITLE: Interleaving TextLineDatasets in TensorFlow\nDESCRIPTION: This snippet shows how to interleave lines from multiple text files using Dataset.interleave.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nfiles_ds = tf.data.Dataset.from_tensor_slices(file_paths)\nlines_ds = files_ds.interleave(tf.data.TextLineDataset, cycle_length=3)\n\nfor i, line in enumerate(lines_ds.take(9)):\n  if i % 3 == 0:\n    print()\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: Creating Batches with tf.data.Dataset\nDESCRIPTION: This code snippet showcases how to create a batched dataset using the `tf.data.Dataset` API. It demonstrates the limitation in batch size recognition by illustrating the output shape when batching a dataset containing a finite number of elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nparams = {'batch_size':32}\nds = tf.data.Dataset.from_tensors([0, 1, 2])\nds = ds.repeat().batch(params['batch_size'])\nds\n\n<BatchDataset shapes: (?, 3), types: tf.int32>\n```\n\n----------------------------------------\n\nTITLE: Visualizing Generated Music as Piano Roll in Python\nDESCRIPTION: Creates a piano roll visualization of the generated music to see the pattern of notes over time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nplot_piano_roll(generated_notes)\n```\n\n----------------------------------------\n\nTITLE: Implementing Vectorized Mapping in TensorFlow Data Pipeline\nDESCRIPTION: Demonstrates vectorized mapping by applying the increment function to batches of data, which can improve performance by reducing function call overhead.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfast_benchmark(\n    fast_dataset\n    .batch(256)\n    # Apply function on a batch of items\n    # The tf.Tensor.__add__ method already handle batches\n    .map(increment)\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Description Dictionary for TFRecord Parsing in TensorFlow\nDESCRIPTION: Defines a dictionary that describes the structure of image data stored in TFRecord format. It specifies fixed-length features for image dimensions (height, width, depth), label, and the raw image data as a string.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'height': tf.io.FixedLenFeature([], tf.int64),\n    'width': tf.io.FixedLenFeature([], tf.int64),\n    'depth': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Linux Linker for TensorFlow C Library\nDESCRIPTION: This bash command configures the Linux linker to include the TensorFlow C library installed in /usr/local/lib. It requires sudo privileges.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo ldconfig /usr/local/lib\n```\n\n----------------------------------------\n\nTITLE: Displaying SSL Certificate Verification Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when there's an SSL certificate verification failure during the installation process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n  failed</pre>\n```\n\n----------------------------------------\n\nTITLE: Preparing and compiling custom Keras model in TensorFlow 2\nDESCRIPTION: Sets up the dataset, creates an instance of the custom Keras model, and compiles it for training using the Adagrad optimizer and mean squared error loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\neval_dataset = tf.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\nmodel = CustomModel([tf.keras.layers.Dense(1)])\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n\nmodel.compile(optimizer=optimizer, loss=\"mse\")\n```\n\n----------------------------------------\n\nTITLE: Dataset Iteration\nDESCRIPTION: Demonstrating iteration over transformed datasets\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint('Elements of ds_tensors:')\nfor x in ds_tensors:\n  print(x)\n\nprint('\\nElements in ds_file:')\nfor x in ds_file:\n  print(x)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Text Classification\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, matplotlib and standard utilities needed for text processing and model building.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport os\nimport re\nimport shutil\nimport string\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\n```\n\n----------------------------------------\n\nTITLE: Further Migration to Nearly Fully Native TF2 API\nDESCRIPTION: Progresses the migration by replacing almost all tf.compat.v1 APIs with their native Keras equivalents, including Flatten and Dense layers. Still retains the variable tracking decorator and variable scope for compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclass NearlyFullyNativeModel(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n    self.conv_layer = tf.keras.layers.Conv2D(\n      3, 3,\n      kernel_regularizer=\"l2\")\n    self.flatten_layer = tf.keras.layers.Flatten()\n    self.dense_layer = tf.keras.layers.Dense(\n      self.units,\n      kernel_regularizer=\"l2\")\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    with tf.compat.v1.variable_scope('model'):\n      out = self.conv_layer(inputs)\n      out = self.flatten_layer(out)\n      out = self.dense_layer(out)\n      return out\n```\n\n----------------------------------------\n\nTITLE: Passing tf.train.Example as Input\nDESCRIPTION: Shows how to pass tf.train.Example as input to the 'run' command using the --input_examples option.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: bash\nCODE:\n```\n`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n```\n\n----------------------------------------\n\nTITLE: Adding Final Classification Layer with Sigmoid Activation\nDESCRIPTION: Adds a Dense layer with sigmoid activation to convert features into binary predictions. This implementation is suitable for binary classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)\n```\n\n----------------------------------------\n\nTITLE: Examining the Structure of Model Outputs\nDESCRIPTION: Retrieves the default serving signature from the loaded model and displays its structured outputs to understand the model's return format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ninfer = loaded.signatures[\"serving_default\"]\nprint(infer.structured_outputs)\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Datasets for Performance\nDESCRIPTION: This code snippet shows how to configure TensorFlow datasets for optimal performance using caching and prefetching. These techniques help prevent I/O from becoming a bottleneck during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nraw_train_ds = raw_train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\nraw_val_ds = raw_val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\nraw_test_ds = raw_test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Handling numpy() Method with DTensors in TensorFlow\nDESCRIPTION: Example demonstrating the behavior of the numpy() method on different types of DTensors. Shows that while the method works on fully replicated DTensors, it raises an error on sharded DTensors to prevent unintended data gathering.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(fully_replicated_dtensor.numpy())\n\ntry:\n  fully_sharded_dtensor.numpy()\nexcept tf.errors.UnimplementedError:\n  print(\"got an error as expected for fully_sharded_dtensor\")\n\ntry:\n  hybrid_sharded_dtensor.numpy()\nexcept tf.errors.UnimplementedError:\n  print(\"got an error as expected for hybrid_sharded_dtensor\")\n```\n\n----------------------------------------\n\nTITLE: Profiling with Context Manager in Python\nDESCRIPTION: Use a context manager to profile a specific block of code. This method provides a clean and concise way to profile a particular section of your model training or execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith tf.profiler.experimental.Profile('logdir'):\n    # Train the model here\n    pass\n```\n\n----------------------------------------\n\nTITLE: Partially Migrating to Native Keras Layers\nDESCRIPTION: Begins the migration process by replacing the convolution layer with its native Keras equivalent. The other layers still use tf.compat.v1 APIs while the track_tf1_style_variables decorator is retained to maintain TF1 variable behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass PartiallyMigratedModel(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n    self.conv_layer = tf.keras.layers.Conv2D(\n      3, 3,\n      kernel_regularizer=\"l2\")\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = self.conv_layer(inputs)\n      out = tf.compat.v1.layers.flatten(out)\n      out = tf.compat.v1.layers.dropout(out, training=training)\n      out = tf.compat.v1.layers.dense(\n          out, self.units,\n          kernel_regularizer=\"l2\")\n      return out\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Random Number Generators\nDESCRIPTION: Examples of creating random number generators using different methods including from_seed and global generator access.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ng1 = tf.random.Generator.from_seed(1)\nprint(g1.normal(shape=[2, 3]))\ng2 = tf.random.get_global_generator()\nprint(g2.normal(shape=[2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Basic Operations with Ragged Tensors\nDESCRIPTION: Demonstrates various operations that can be performed on ragged tensors, including math operations, array operations, string manipulations, and control flow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndigits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\nwords = tf.ragged.constant([[\"So\", \"long\"], [\"thanks\", \"for\", \"all\", \"the\", \"fish\"]])\nprint(tf.add(digits, 3))\nprint(tf.reduce_mean(digits, axis=1))\nprint(tf.concat([digits, [[5, 3]]], axis=0))\nprint(tf.tile(digits, [1, 2]))\nprint(tf.strings.substr(words, 0, 2))\nprint(tf.map_fn(tf.math.square, digits))\n```\n\n----------------------------------------\n\nTITLE: Illustrating Tensor Leaks with Return Values in TensorFlow Functions\nDESCRIPTION: This example demonstrates that even when a leaked tensor is returned from a tf.function, it still cannot be accessed outside the function through the global variable. It also shows how attempting to use the leaked tensor in another function results in an error.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef leaky_function(a):\n  global x\n  x = a + 1  # Bad - leaks local tensor\n  return x  # Good - uses local tensor\n\ncorrect_a = leaky_function(tf.constant(1))\n\nprint(correct_a.numpy())  # Good - value obtained from function's returns\ntry:\n  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\nexcept AttributeError as expected:\n  print(expected)\n\n@tf.function\ndef captures_leaked_tensor(b):\n  b += x  # Bad - `x` is leaked from `leaky_function`\n  return b\n\nwith assert_raises(TypeError):\n  captures_leaked_tensor(tf.constant(2))\n```\n\n----------------------------------------\n\nTITLE: Installing APU Plugin Package using pip\nDESCRIPTION: Example command for installing a demonstration APU (Awesome Processing Unit) plugin package using pip\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/gpu_plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Install the APU example plug-in package\n$ pip install tensorflow-apu-0.0.1-cp36-cp36m-linux_x86_64.whl\n...\nSuccessfully installed tensorflow-apu-0.0.1\n```\n\n----------------------------------------\n\nTITLE: Loading Example Videos and Defining Text Queries in Python\nDESCRIPTION: This code loads example videos from URLs and defines corresponding text queries for demonstration. It uses the previously defined load_video function and prepares data for the text-to-video retrieval task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvideo_1_url = 'https://upload.wikimedia.org/wikipedia/commons/b/b0/YosriAirTerjun.gif' # @param {type:\"string\"}\nvideo_2_url = 'https://upload.wikimedia.org/wikipedia/commons/e/e6/Guitar_solo_gif.gif' # @param {type:\"string\"}\nvideo_3_url = 'https://upload.wikimedia.org/wikipedia/commons/3/30/2009-08-16-autodrift-by-RalfR-gif-by-wau.gif' # @param {type:\"string\"}\n\nvideo_1 = load_video(video_1_url)\nvideo_2 = load_video(video_2_url)\nvideo_3 = load_video(video_3_url)\nall_videos = [video_1, video_2, video_3]\n\nquery_1_video = 'waterfall' # @param {type:\"string\"}\nquery_2_video = 'playing guitar' # @param {type:\"string\"}\nquery_3_video = 'car drifting' # @param {type:\"string\"}\nall_queries_video = [query_1_video, query_2_video, query_3_video]\nall_videos_urls = [video_1_url, video_2_url, video_3_url]\ndisplay_video(all_videos_urls)\n```\n\n----------------------------------------\n\nTITLE: Committing Changes to TensorFlow Docs\nDESCRIPTION: This snippet shows the Git commands to view changes, stage files, and commit changes when contributing to TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# View changes\ngit status\ngit diff\n\ngit add <var>path/to/file.md</var>\ngit commit -m \"Your meaningful commit message for the change.\"\n```\n\n----------------------------------------\n\nTITLE: Building Deep Neural Network Model Function\nDESCRIPTION: Creates a function that builds and compiles a deep neural network with normalization and multiple dense layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef build_and_compile_model(norm):\n  model = keras.Sequential([\n      norm,\n      layers.Dense(64, activation='relu'),\n      layers.Dense(64, activation='relu'),\n      layers.Dense(1)\n  ])\n\n  model.compile(loss='mean_absolute_error',\n                optimizer=tf.keras.optimizers.Adam(0.001))\n  return model\n```\n\n----------------------------------------\n\nTITLE: Embedding String Data with Feature Columns\nDESCRIPTION: Demonstrates embedding of string data using a vocabulary with feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nvocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n    'col',\n    vocabulary_list=['small', 'medium', 'large'],\n    num_oov_buckets=0)\nembedding_col = tf1.feature_column.embedding_column(vocab_col, 4)\ncall_feature_columns(embedding_col, {'col': ['small', 'medium', 'large']})\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable Example\nDESCRIPTION: Setting an example environment variable to demonstrate how environment variables are inherited by subprocesses, which is relevant for the TF_CONFIG variable in multi-worker training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GREETINGS'] = 'Hello TensorFlow!'\n```\n\n----------------------------------------\n\nTITLE: Setting Deterministic Random Seeds for DTensor\nDESCRIPTION: Configures TensorFlow to use deterministic random number generation for consistent weight initialization across all DTensor clients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.backend.experimental.enable_tf_random_generator()\ntf.keras.utils.set_random_seed(1337)\n```\n\n----------------------------------------\n\nTITLE: ResNet Identity Block Implementation\nDESCRIPTION: Shows how to implement a ResNet identity block by composing multiple layers using tf.keras.Model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass ResnetIdentityBlock(tf.keras.Model):\n  def __init__(self, kernel_size, filters):\n    super(ResnetIdentityBlock, self).__init__(name='')\n    filters1, filters2, filters3 = filters\n\n    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n    self.bn2a = tf.keras.layers.BatchNormalization()\n\n    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n    self.bn2b = tf.keras.layers.BatchNormalization()\n\n    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n    self.bn2c = tf.keras.layers.BatchNormalization()\n\n  def call(self, input_tensor, training=False):\n    x = self.conv2a(input_tensor)\n    x = self.bn2a(x, training=training)\n    x = tf.nn.relu(x)\n\n    x = self.conv2b(x)\n    x = self.bn2b(x, training=training)\n    x = tf.nn.relu(x)\n\n    x = self.conv2c(x)\n    x = self.bn2c(x, training=training)\n\n    x += input_tensor\n    return tf.nn.relu(x)\n\n\nblock = ResnetIdentityBlock(1, [1, 2, 3])\nprint(block(tf.zeros([1, 2, 3, 3])))\nprint([x.name for x in block.trainable_variables])\n```\n\n----------------------------------------\n\nTITLE: Implementing a Training Step Function\nDESCRIPTION: Defines a function that performs a single training step, calculating loss and applying gradients using the provided optimizer and network.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef train_step(net, example, optimizer):\n  \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n  with tf.GradientTape() as tape:\n    output = net(example['x'])\n    loss = tf.reduce_mean(tf.abs(output - example['y']))\n  variables = net.trainable_variables\n  gradients = tape.gradient(loss, variables)\n  optimizer.apply_gradients(zip(gradients, variables))\n  return loss\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model on TPU\nDESCRIPTION: Evaluates the trained model using the evaluation dataset with specified steps and dictionary return format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(eval_dataset, steps=1, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Step Function with JAX\nDESCRIPTION: Defines a jitted training step function that performs forward pass, calculates loss and gradients, and updates model parameters using the optimizer. It handles the separation of trainable and non-trainable variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@partial(jax.jit, static_argnums=[0])\ndef train_step(model, state, optimizer_state, rng, data, labels):\n\n  other_state, params = state.pop('params')\n  (loss, batch_stats), grads = jax.value_and_grad(model.loss, has_aux=True)(params, other_state, rng, data, labels, train=True)\n\n  updates, optimizer_state = optimizer.update(grads, optimizer_state)\n  params = optax.apply_updates(params, updates)\n  new_state = state.copy(add_or_replace={**batch_stats, 'params': params})\n\n  rng, _ = jax.random.split(rng)\n\n  return new_state, optimizer_state, rng, loss\n```\n\n----------------------------------------\n\nTITLE: Loading ANNOY Index and Mapping in Python\nDESCRIPTION: Loads the previously built ANNOY index and its corresponding mapping file into memory for use in similarity matching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nindex = annoy.AnnoyIndex(embedding_dimension)\nindex.load(index_filename, prefault=True)\nprint('Annoy index is loaded.')\nwith open(index_filename + '.mapping', 'rb') as handle:\n  mapping = pickle.load(handle)\nprint('Mapping file is loaded.')\n```\n\n----------------------------------------\n\nTITLE: Mapping Augmentation Function to Training Dataset\nDESCRIPTION: Applies the wrapper function f to the training dataset, including shuffling, batching, and prefetching operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: Python\nCODE:\n```\ntrain_ds = (\n    train_datasets\n    .shuffle(1000)\n    .map(f, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Mixed Precision Policy\nDESCRIPTION: Sets the global mixed precision policy to 'mixed_float16' for improved performance on GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n```\n\n----------------------------------------\n\nTITLE: Model Compilation\nDESCRIPTION: Compiles the model with binary cross-entropy loss, Adam optimizer, and accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n    loss=losses.BinaryCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Linear Model Predictions\nDESCRIPTION: Plots the linear model's predictions on the wide window, showing how it compares to the actual values and illustrating that it often performs better than the baseline but can occasionally make worse predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nwide_window.plot(linear)\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with tf.GradientTape\nDESCRIPTION: Shows how to use TensorFlow's GradientTape to compute gradients of a model implemented with TensorFlow NumPy functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef create_batch(batch_size=32):\n  \"\"\"Creates a batch of input and labels.\"\"\"\n  return (tnp.random.randn(batch_size, 32).astype(tnp.float32),\n          tnp.random.randn(batch_size, 2).astype(tnp.float32))\n\ndef compute_gradients(model, inputs, labels):\n  \"\"\"Computes gradients of squared loss between model prediction and labels.\"\"\"\n  with tf.GradientTape() as tape:\n    assert model.weights is not None\n    # Note that `model.weights` need to be explicitly watched since they\n    # are not tf.Variables.\n    tape.watch(model.weights)\n    # Compute prediction and loss\n    prediction = model.predict(inputs)\n    loss = tnp.sum(tnp.square(prediction - labels))\n  # This call computes the gradient through the computation above.\n  return tape.gradient(loss, model.weights)\n\ninputs, labels = create_batch()\ngradients = compute_gradients(model, inputs, labels)\n\n# Inspect the shapes of returned gradients to verify they match the\n# parameter shapes.\nprint(\"Parameter shapes:\", [w.shape for w in model.weights])\nprint(\"Gradient shapes:\", [g.shape for g in gradients])\n# Verify that gradients are of type ND array.\nassert isinstance(gradients[0], tnp.ndarray)\n```\n\n----------------------------------------\n\nTITLE: Interleaving Multiple CSV Files with TensorFlow\nDESCRIPTION: Uses the interleave method to cycle through multiple CSV files, creating a dataset that reads from multiple files concurrently. The cycle_length parameter controls how many files are processed in parallel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_56\n\nLANGUAGE: python\nCODE:\n```\nfont_rows = font_files.interleave(make_font_csv_ds,\n                                  cycle_length=3)\n```\n\n----------------------------------------\n\nTITLE: Using Stateless Random Number Generators\nDESCRIPTION: Demonstrates the use of stateless random number generators in TensorFlow, which are pure functions that produce deterministic outputs based solely on the provided seed parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.random.stateless_normal(shape=[2, 3], seed=[1, 2]))\nprint(tf.random.stateless_normal(shape=[2, 3], seed=[1, 2]))\n```\n\n----------------------------------------\n\nTITLE: Creating a Polymorphic Function with tf.function in Python\nDESCRIPTION: Demonstrates how tf.function creates new graphs for different input types, and reuses existing graphs for matching input types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# `my_relu` creates new graphs as it observes different input types.\nprint(my_relu(tf.constant(5.5)))\nprint(my_relu([1, -1]))\nprint(my_relu(tf.constant([3., -3.])))\n\n# These two calls do *not* create new graphs.\nprint(my_relu(tf.constant(-2.5))) # Input type matches `tf.constant(5.5)`.\nprint(my_relu(tf.constant([-1., 1.]))) # Input type matches `tf.constant([3., -3.])`.\n\n# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n# The `ConcreteFunction` also knows the return type and shape!\nprint(my_relu.pretty_printed_concrete_signatures())\n```\n\n----------------------------------------\n\nTITLE: Implementing Fully Replicated Matrix Multiplication with DTensor\nDESCRIPTION: Demonstrates how to create fully replicated DTensors across devices and perform matrix multiplication. The operation runs identical matmuls in parallel across 6 devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 6)], devices=DEVICES)\nlayout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)\na = dtensor_from_array([[1, 2, 3], [4, 5, 6]], layout=layout)\nb = dtensor_from_array([[6, 5], [4, 3], [2, 1]], layout=layout)\n\nc = tf.matmul(a, b) # runs 6 identical matmuls in parallel on 6 devices\n\n# `c` is a DTensor replicated on all devices (same as `a` and `b`)\nprint('Sharding spec:', dtensor.fetch_layout(c).sharding_specs)\nprint(\"components:\")\nfor component_tensor in dtensor.unpack(c):\n  print(component_tensor.device, component_tensor.numpy())\n```\n\n----------------------------------------\n\nTITLE: Creating Symbolic Links for NVIDIA Libraries on Linux\nDESCRIPTION: These commands create symbolic links to NVIDIA shared libraries to resolve potential conflicts with system CUDA installations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\npushd $(dirname $(python -c 'print(__import__(\"tensorflow\").__file__)'))\\nln -svf ../nvidia/*/lib/*.so* .\\npopd\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Mixed Precision Modules\nDESCRIPTION: Imports the necessary TensorFlow modules including Keras and mixed precision.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import mixed_precision\n```\n\n----------------------------------------\n\nTITLE: Creating a Valid Ragged Tensor with Consistent Type and Rank\nDESCRIPTION: Shows a valid example of creating a ragged tensor where all elements have the same type (string) and rank (2).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]))  # ok: type=string, rank=2\n```\n\n----------------------------------------\n\nTITLE: Plotting Image and Prediction\nDESCRIPTION: This snippet defines two functions, `plot_image` and `plot_value_array`, for visualizing images and their corresponding predictions.  `plot_image` displays the image, predicted label, and true label with color-coding for correctness.  `plot_value_array` displays a bar chart of prediction confidences with color-coding for the predicted and true labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary)\n  \n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n  \n  plt.xlabel(\"{:s} {:2.0f}% ({:s})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array, true_label[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n  \n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')\n```\n\n----------------------------------------\n\nTITLE: Building Neural Network Model\nDESCRIPTION: Creates a sequential model with embedding layer, global average pooling, and dense layers for text classification\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nvocab_size = 10000\n\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(vocab_size, 16))\nmodel.add(keras.layers.GlobalAveragePooling1D())\nmodel.add(keras.layers.Dense(16, activation=tf.nn.relu))\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Training Image Classification Model with Keras Fit Generator\nDESCRIPTION: Trains the image classification model using data generators with specified epochs, steps per epoch, and validation data\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = steps_per_epoch,\n                              epochs=epochs,\n                              workers=4,\n                              validation_data=validation_generator,\n                              validation_steps=validation_steps)\n```\n\n----------------------------------------\n\nTITLE: Specifying GPUs for MirroredStrategy\nDESCRIPTION: Create a MirroredStrategy instance using only specific GPUs by providing their device identifiers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n```\n\n----------------------------------------\n\nTITLE: Implementing Projection Layer\nDESCRIPTION: Custom layer for projecting dimensions when channel sizes change in residual connections.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Project(keras.layers.Layer):\n  \"\"\"\n    Project certain dimensions of the tensor as the data is passed through different \n    sized filters and downsampled. \n  \"\"\"\n  def __init__(self, units):\n    super().__init__()\n    self.seq = keras.Sequential([\n        layers.Dense(units),\n        layers.LayerNormalization()\n    ])\n\n  def call(self, x):\n    return self.seq(x)\n```\n\n----------------------------------------\n\nTITLE: Starting Bash Session in GPU-enabled TensorFlow Container\nDESCRIPTION: Command to start a bash shell session in a GPU-enabled TensorFlow Docker container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --gpus all -it tensorflow/tensorflow:latest-gpu bash\n```\n\n----------------------------------------\n\nTITLE: Creating Bucketized Feature Column\nDESCRIPTION: Shows how to create a bucketized column by first converting raw input to numeric column and then defining bucket boundaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# First, convert the raw input to a numeric column.\nnumeric_feature_column = tf.feature_column.numeric_column(\"Year\")\n\n# Then, bucketize the numeric column on the years 1960, 1980, and 2000.\nbucketized_feature_column = tf.feature_column.bucketized_column(\n    source_column = numeric_feature_column,\n    boundaries = [1960, 1980, 2000])\n```\n\n----------------------------------------\n\nTITLE: Padding Sequence Data\nDESCRIPTION: Standardizes the length of all reviews to 256 words using padding, preparing the data for input to the neural network\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_data = keras.preprocessing.sequence.pad_sequences(train_data,\n                                                        value=word_index[\"<PAD>\"],\n                                                        padding='post',\n                                                        maxlen=256)\n\ntest_data = keras.preprocessing.sequence.pad_sequences(test_data,\n                                                       value=word_index[\"<PAD>\"],\n                                                       padding='post',\n                                                       maxlen=256)\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model Weights (HDF5 Format)\nDESCRIPTION: Demonstrates saving and loading Keras model weights using the HDF5 format. The `save_format='h5'` argument specifies the HDF5 format. The code shows how to save the weights to a file named 'my_model.h5' and then load them back into the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Save weights to a HDF5 file\nmodel.save_weights('my_model.h5', save_format='h5')\n\n# Restore the model's state\nmodel.load_weights('my_model.h5')\n```\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Error: Incompatible Trailing Dimensions\nDESCRIPTION: Demonstrates a broadcasting error that occurs when a ragged tensor and a dense tensor have incompatible trailing dimensions that cannot be broadcast together.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_52\n\nLANGUAGE: python\nCODE:\n```\n# x      (2d ragged): 3 x (r1)\n# y      (2d tensor): 3 x    4  # trailing dimensions do not match\nx = tf.ragged.constant([[1, 2], [3, 4, 5, 6], [7]])\ny = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Checking Linear Model Compatibility with Wide Windows\nDESCRIPTION: Verifies that the linear model can process wide windows by checking input and output shapes, demonstrating that the model makes independent predictions for each time step in the window.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', wide_window.example[0].shape)\nprint('Output shape:', linear(wide_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Launching the Evaluation Operation - Shell\nDESCRIPTION: This shell command runs the evaluation script for the trained CIFAR-10 model, measuring its performance on the hold-out dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n\"python cifar10_eval.py\"\n```\n\n----------------------------------------\n\nTITLE: Compiling MoViNet Model for Training in TensorFlow\nDESCRIPTION: This snippet shows how to compile the MoViNet model for training. It sets up the loss function, optimizer, and metrics for the model compilation process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nnum_epochs = 2\n\nloss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n\nmodel.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: License declaration for the notebook, specifying that the content is licensed under the Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Using ImageDataGenerator in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the ImageDataGenerator to flow images from a directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nimages, labels = next(img_gen.flow_from_directory(flowers))\n```\n\n----------------------------------------\n\nTITLE: Layer Usage and Variable Inspection\nDESCRIPTION: Shows how to use layers and inspect their variables\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlayer(tf.zeros([10, 5]))\nlayer.variables\nlayer.kernel, layer.bias\n```\n\n----------------------------------------\n\nTITLE: Processing Dataset for Sentence Similarity Benchmark\nDESCRIPTION: Processes the chosen dataset (development or test set) by converting sentences to sparse format IDs for evaluation of sentence embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n#@title Choose dataset for benchmark\ndataset = sts_dev #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\n\nvalues1, indices1, dense_shape1 = process_to_IDs_in_sparse_format(sp, dataset['sent_1'].tolist())\nvalues2, indices2, dense_shape2 = process_to_IDs_in_sparse_format(sp, dataset['sent_2'].tolist())\nsimilarity_scores = dataset['sim'].tolist()\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from Dictionary of Arrays in Python\nDESCRIPTION: This code shows how to create a tf.data.Dataset from a dictionary of arrays, which is useful for structured data like the Iris dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(dict(features))\nprint(dataset)\n```\n\n----------------------------------------\n\nTITLE: Baseline Model Training\nDESCRIPTION: Training the baseline model with the prepared IMDB dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbaseline_history = baseline_model.fit(train_data,\n                                      train_labels,\n                                      epochs=20,\n                                      batch_size=512,\n                                      validation_data=(test_data, test_labels),\n                                      verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Keras\nDESCRIPTION: Imports the necessary TensorFlow and Keras libraries for the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nfrom tensorflow import keras\n```\n\n----------------------------------------\n\nTITLE: Measuring CSV Dataset Iteration Performance with Repeated Access\nDESCRIPTION: This code snippet demonstrates the performance of iterating over a CSV dataset multiple times without caching. It prints a dot for every 40 batches processed, showing the baseline performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n%%time\nfor i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n  if i % 40 == 0:\n    print('.', end='')\nprint()\n```\n\n----------------------------------------\n\nTITLE: Implementing Nested Layers with Variable Tracking in TensorFlow\nDESCRIPTION: Example showing how to properly track variables and regularization losses when implementing nested layers using tf.compat.v1 APIs within a TensorFlow 2.x context. Demonstrates variable scope management and weight reuse patterns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass NestedLayer(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def __call__(self, inputs):\n    out = inputs\n    with tf.compat.v1.variable_scope(\"inner_dense\"):\n      # The weights are created with a `regularizer`,\n      # so the layer should track their regularization losses\n      kernel = tf.compat.v1.get_variable(\n          shape=[out.shape[-1], self.units],\n          regularizer=tf.keras.regularizers.L2(),\n          initializer=tf.compat.v1.initializers.glorot_normal,\n          name=\"kernel\")\n      bias = tf.compat.v1.get_variable(\n          shape=[self.units,],\n          initializer=tf.compat.v1.initializers.zeros,\n          name=\"bias\")\n      out = tf.linalg.matmul(out, kernel)\n      out = tf.compat.v1.nn.bias_add(out, bias)\n    return out\n\nclass WrappedDenseLayer(tf.keras.layers.Layer):\n\n  def __init__(self, units, **kwargs):\n    super().__init__(**kwargs)\n    self.units = units\n    # Only create the nested tf.variable/module/layer/model\n    # once, and then reuse it each time!\n    self._dense_layer = NestedLayer(self.units)\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs):\n    with tf.compat.v1.variable_scope('outer'):\n      outputs = tf.compat.v1.layers.dense(inputs, 3)\n      outputs = tf.compat.v1.layers.dense(inputs, 4)\n      return self._dense_layer(outputs)\n\nlayer = WrappedDenseLayer(10)\n\nlayer(tf.ones(shape=(5, 5)))\n```\n\n----------------------------------------\n\nTITLE: Constructing a New Tensor with tf.scatter_nd\nDESCRIPTION: Shows how to create a new tensor by scattering gathered values at specific indices, with zeros in other positions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Add these values into a new tensor\n\nt8 = tf.scatter_nd(indices=new_indices, updates=t7, shape=tf.constant([4, 5]))\n\nprint(t8)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Importing necessary Python libraries for data manipulation, visualization and machine learning\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport sys\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom six.moves import urllib\n```\n\n----------------------------------------\n\nTITLE: TF2 SavedModel Initialization and Inference\nDESCRIPTION: Loading and using a TF2 SavedModel for inference in a server environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_issues.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_hub as hub\n\nembedding_fn = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n```\n\nLANGUAGE: python\nCODE:\n```\nembedding_fn([\"Hello world\"])\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow License with Python Comment\nDESCRIPTION: Defines the Apache License 2.0 terms for the TensorFlow code in a Python comment block.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Fault Tolerance Examples\nDESCRIPTION: Importing TensorFlow, NumPy, tempfile, and time libraries needed for implementing fault tolerance mechanisms in the examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf1\nimport tensorflow as tf\nimport numpy as np\nimport tempfile\nimport time\n```\n\n----------------------------------------\n\nTITLE: Constructing Ragged Tensors with from_row_lengths\nDESCRIPTION: Shows how to create a ragged tensor by specifying the length of each row using the from_row_lengths factory method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_row_lengths(\n    values=[3, 1, 4, 1, 5, 9, 2],\n    row_lengths=[4, 0, 2, 1]))\n```\n\n----------------------------------------\n\nTITLE: Displaying Protobuf Import Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when there's a problem importing the descriptor module from Google's protobuf library.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>ImportError: Traceback (most recent call last):\n  File \".../tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n  from google.protobuf import descriptor as _descriptor\n  ImportError: cannot import name 'descriptor'</pre>\n```\n\n----------------------------------------\n\nTITLE: Finding Latest Checkpoint for Text Generation Model in TensorFlow\nDESCRIPTION: Retrieves the path to the latest model checkpoint from the training directory for loading weights into a new model instance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntf.train.latest_checkpoint(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Incorrect TF1 Model Loading in TF2\nDESCRIPTION: Example showing incorrect way of loading TF1 Hub model in TF2 that raises TypeError.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_issues.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# BAD: Raises error\nembed = hub.load('https://tfhub.dev/google/nnlm-en-dim128/1')\nembed(['my text', 'batch'])\n```\n\n----------------------------------------\n\nTITLE: Converting ndjson Data to TFRecord Format (Shell)\nDESCRIPTION: Command to convert the downloaded ndjson files to TFRecord format containing tf.train.Example protos, creating sharded files for training and evaluation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython create_dataset.py --ndjson_path rnn_tutorial_data \\\n   --output_path rnn_tutorial_data\n```\n\n----------------------------------------\n\nTITLE: Creating sample data for Keras model with RaggedTensors\nDESCRIPTION: Sets up sample sentences and binary labels for a text classification task to demonstrate using ragged tensors with Keras.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Task: predict whether each sentence is a question or not.\nsentences = tf.constant(\n    ['What makes you think she is a witch?',\n     'She turned me into a newt.',\n     'A newt?',\n     'Well, I got better.'])\nis_question = tf.constant([True, False, True, False])\n```\n\n----------------------------------------\n\nTITLE: Defining Feature Columns for the Estimator\nDESCRIPTION: Creates a list of feature columns that instruct the model on how to use the input data, specifying all features as numeric columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Feature columns describe how to use the input.\nmy_feature_columns = []\nfor key in train.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n```\n\n----------------------------------------\n\nTITLE: Inspecting Value Type of Dataset Elements\nDESCRIPTION: Shows how to examine the underlying value type of elements in a dataset using the value_type attribute of element_spec.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Use value_type to see the type of value represented by the element spec\ndataset4.element_spec.value_type\n```\n\n----------------------------------------\n\nTITLE: Creating Test Dataset from Validation Set in TensorFlow\nDESCRIPTION: This code creates a test dataset by taking 20% of the validation dataset, using tf.data.experimental.cardinality to determine the number of batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nval_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches // 5)\nvalidation_dataset = validation_dataset.skip(val_batches // 5)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Checkpoint Settings\nDESCRIPTION: Creates a custom RunConfig to modify checkpoint frequency and retention settings for a DNNClassifier.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmy_checkpointing_config = tf.estimator.RunConfig(\n    save_checkpoints_secs = 20*60,  # Save checkpoints every 20 minutes.\n    keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.\n)\n\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    hidden_units=[10, 10],\n    n_classes=3,\n    model_dir='models/iris',\n    config=my_checkpointing_config)\n```\n\n----------------------------------------\n\nTITLE: Running TensorBoard to Visualize TensorFlow Summaries\nDESCRIPTION: This shell command shows how to start TensorBoard and point it to the directory containing the summary logs for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntensorboard --logdir /tmp/summaries\n```\n\n----------------------------------------\n\nTITLE: Accessing Example Object Features (Python)\nDESCRIPTION: Shows how to access features within a tf.Example object, facilitating direct feature value extraction using a dictionary-like interface.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nprint(dict(example.features.feature))\n```\n\n----------------------------------------\n\nTITLE: Creating Image Preprocessing Functions for Training\nDESCRIPTION: Defines a function to preprocess training images by applying random jittering and normalization. This prepares images for training the CycleGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_image_train(image, label):\n  image = random_jitter(image)\n  image = normalize(image)\n  return image\n```\n\n----------------------------------------\n\nTITLE: Handling Error when Creating a Ragged Tensor with Inconsistent Nesting\nDESCRIPTION: Demonstrates the error that occurs when trying to create a ragged tensor with inconsistent nesting depths.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  tf.ragged.constant([\"A\", [\"B\", \"C\"]])                     # bad: multiple nesting depths\nexcept ValueError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Multiple Default Values\nDESCRIPTION: Comprehensive example showing default value specification for various attribute types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_25\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"AttrDefaultExampleForAllTypes\")\n   .Attr(\"s: string = 'foo'\")\n   .Attr(\"i: int = 0\")\n   .Attr(\"f: float = 1.0\")\n   .Attr(\"b: bool = true\")\n   .Attr(\"ty: type = DT_INT32\")\n   .Attr(\"sh: shape = { dim { size: 1 } dim { size: 2 } }\")\n   .Attr(\"te: tensor = { dtype: DT_INT32 int_val: 5 }\")\n   .Attr(\"l_empty: list(int) = []\")\n   .Attr(\"l_int: list(int) = [2, 3, 5, 7]\");\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow 1.x Compatibility Mode\nDESCRIPTION: Imports TensorFlow 1.x compatibility module to ensure code works with both TF1 and TF2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/_index.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Plotting features from a batch\nDESCRIPTION: This snippet uses matplotlib to create a scatter plot of petal length vs. sepal length from a batch of features. The plot is colored by the labels, using the viridis colormap.  It demonstrates how to visualize features and labels from a tf.data.Dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nplt.scatter(features['petal_length'].numpy(),\n            features['sepal_length'].numpy(),\n            c=labels.numpy(),\n            cmap='viridis')\n\nplt.xlabel(\"Petal length\")\nplt.ylabel(\"Sepal length\")\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Temporary Model Files in TensorFlow Distributed Training\nDESCRIPTION: Removing temporary model directories created by non-chief workers after saving is complete. This ensures only the chief worker's saved model remains for future loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nif not _is_chief(task_type, task_id):\n  tf.io.gfile.rmtree(os.path.dirname(write_model_path))\n```\n\n----------------------------------------\n\nTITLE: Creating the Input Layer for a TensorFlow Neural Network\nDESCRIPTION: Code that converts features into the input layer of a neural network model using feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Use `input_layer` to apply the feature columns.\nnet = tf.feature_column.input_layer(features, params['feature_columns'])\n```\n\n----------------------------------------\n\nTITLE: Defining Output Layer for Iris Classification in TensorFlow\nDESCRIPTION: This snippet shows how to define the output layer for the Iris classification model using tf.layers.dense. It computes logits for each class without an activation function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Compute logits (1 per class).\nlogits = tf.layers.dense(net, params['n_classes'], activation=None)\n```\n\n----------------------------------------\n\nTITLE: Unpacking DTensor Component Tensors in TensorFlow\nDESCRIPTION: Demonstration of using dtensor.unpack() to inspect the component tensors of a DTensor across different devices in the mesh. This reveals how the tensor data is distributed/replicated across devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfor component_tensor in dtensor.unpack(my_first_dtensor):\n  print(\"Device:\", component_tensor.device, \",\", component_tensor)\n```\n\n----------------------------------------\n\nTITLE: Instantiating DNN Classifier\nDESCRIPTION: Creation of a DNN Classifier with specified feature columns, hidden layers, and number of classes for the Iris classification problem.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    # Two hidden layers of 10 nodes each.\n    hidden_units=[10, 10],\n    # The model must choose between 3 classes.\n    n_classes=3)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Docs Package in Python\nDESCRIPTION: Command to install the TensorFlow docs package from GitHub using pip. This package includes tools for notebook formatting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install -U [--user] git+https://github.com/tensorflow/docs\n```\n\n----------------------------------------\n\nTITLE: Computing Predictive Logits and Variances in TensorFlow\nDESCRIPTION: This code computes the predictive logits and variances using the trained SNGP model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nsngp_logits, sngp_covmat = sngp_model(test_examples, return_covmat=True)\n\nsngp_variance = tf.linalg.diag_part(sngp_covmat)[:, None]\n```\n\n----------------------------------------\n\nTITLE: License Configuration in Python\nDESCRIPTION: A Python code block containing the Apache License 2.0 header that defines the license terms for the TensorFlow tutorial content.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining LSTM Model with TensorFlow\nDESCRIPTION: This snippet demonstrates how to define a basic LSTM model using TensorFlow. It initializes the LSTM cell, sets the state, and processes batches of word inputs to predict the next word in a sequence. The model utilizes placeholders for inputs and calculates probabilities for each word based on the LSTM's output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwords_in_dataset = tf.placeholder(tf.float32, [time_steps, batch_size, num_features])\nlstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n# Initial state of the LSTM memory.\nstate = lstm.zero_state(batch_size, dtype=tf.float32)\nprobabilities = []\nloss = 0.0\nfor current_batch_of_words in words_in_dataset:\n    # The value of state is updated after processing each batch of words.\n    output, state = lstm(current_batch_of_words, state)\n\n    # The LSTM output can be used to make next word predictions\n    logits = tf.matmul(output, softmax_w) + softmax_b\n    probabilities.append(tf.nn.softmax(logits))\n    loss += loss_function(probabilities, target_words)\n```\n\n----------------------------------------\n\nTITLE: Saving JAX Model to TensorFlow Format\nDESCRIPTION: Code to instantiate and save the converted JAX model in TensorFlow SavedModel format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Instantiate the model.\ntf_model = TFModel(state, model)\n\n# Save the model.\ntf.saved_model.save(tf_model, \"./\")\n```\n\n----------------------------------------\n\nTITLE: Compiling the Keras Model with Loss Function and Optimizer\nDESCRIPTION: Compiles the Keras model with SparseCategoricalCrossentropy loss function (for classification tasks) and Adam optimizer, then displays the model summary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              optimizer='adam')\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Creating Timeline Visualization for Benchmark Results in TensorFlow\nDESCRIPTION: Implements a function that creates timeline visualizations of benchmarking results. It filters invalid entries, organizes steps, and plots execution times using a color-coded horizontal bar chart with optional annotations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n    # Remove invalid entries (negative times, or empty steps) from the timelines\n    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n    steps = timeline['steps'][invalid_mask].numpy()\n    times = timeline['times'][invalid_mask].numpy()\n    values = timeline['values'][invalid_mask].numpy()\n    \n    # Get a set of different steps, ordered by the first time they are encountered\n    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n    step_ids = step_ids[np.argsort(indices)]\n\n    # Shift the starting time to 0 and compute the maximal time value\n    min_time = times[:,0].min()\n    times[:,0] = (times[:,0] - min_time)\n    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n    \n    cmap = mpl.cm.get_cmap(\"plasma\")\n    plt.close()\n    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n    fig.suptitle(title)\n    fig.set_size_inches(17.0, len(step_ids))\n    plt.xlim(-0.01, end)\n    \n    for i, step in enumerate(step_ids):\n        step_name = step.decode()\n        ax = axs[i]\n        ax.set_ylabel(step_name)\n        ax.set_ylim(0, 1)\n        ax.set_yticks([])\n        ax.set_xlabel(\"time (s)\")\n        ax.set_xticklabels([])\n        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n        \n        # Get timings and annotation for the given step\n        entries_mask = np.squeeze(steps==step)\n        serie = np.unique(times[entries_mask], axis=0)\n        annotations = values[entries_mask]\n        \n        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n        if annotate:\n            for j, (start, width) in enumerate(serie):\n                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n                        horizontalalignment='left', verticalalignment='center')\n    if save:\n        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")\n```\n\n----------------------------------------\n\nTITLE: Downloading Titanic CSV File for TensorFlow\nDESCRIPTION: This snippet downloads the Titanic dataset CSV file for use in subsequent examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\ntitanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\ntitanic_lines = tf.data.TextLineDataset(titanic_file)\n```\n\n----------------------------------------\n\nTITLE: Using Placeholders for Feeding Data in TensorFlow\nDESCRIPTION: Creates placeholders that allow for dynamic input to a TensorFlow graph. Demonstrates how to feed concrete values to these placeholders during session execution using the feed_dict parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nx = tf.placeholder(tf.float32)\ny = tf.placeholder(tf.float32)\nz = x + y\n```\n\n----------------------------------------\n\nTITLE: One-hot Encoding Categorical Features (Python)\nDESCRIPTION: This snippet processes the categorical 'Origin' column by performing a one-hot encoding, transforming it into three binary columns representing automobile origin.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\norigin = dataset.pop('Origin')\ndataset['USA'] = (origin == 1)*1.0\ndataset['Europe'] = (origin == 2)*1.0\ndataset['Japan'] = (origin == 3)*1.0\ndataset.tail()\n```\n\n----------------------------------------\n\nTITLE: Showing Details of a Specific SignatureDef with SavedModel CLI\nDESCRIPTION: Command using SavedModel CLI to display detailed information about a specific SignatureDef within a MetaGraphDef. This shows the input and output tensor specifications including dtype, shape, and tensor name.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir \\\n/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n```\n\n----------------------------------------\n\nTITLE: Keras Preprocessing Layers Example with Model Training in Python\nDESCRIPTION: This snippet illustrates using Keras preprocessing layers to handle feature transformations in a TensorFlow model. It involves defining a preprocessing model, applying it during data preparation, and then training using a Keras trainable model, with dependencies on `tensorflow` and `tf.keras.layers`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ninputs = {\n  'type': tf.keras.Input(shape=(), dtype='int64'),\n  'size': tf.keras.Input(shape=(), dtype='string'),\n  'weight': tf.keras.Input(shape=(), dtype='float32'),\n}\n\n# Convert index to one-hot; e.g., [2] -> [0,0,1].\ntype_output = tf.keras.layers.CategoryEncoding(\n      one_hot_dims, output_mode='one_hot')(inputs['type'])\n# Convert size strings to indices; e.g., ['small'] -> [1].\nsize_output = tf.keras.layers.StringLookup(vocabulary=vocab)(inputs['size'])\n# Normalize the numeric inputs; e.g., [2.0] -> [0.0].\nweight_output = tf.keras.layers.Normalization(\n      axis=None, mean=weight_mean, variance=weight_variance)(inputs['weight'])\noutputs = {\n  'type': type_output,\n  'size': size_output,\n  'weight': weight_output,\n}\npreprocessing_model = tf.keras.Model(inputs, outputs)\n```\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\ndataset = dataset.map(lambda x, y: (preprocessing_model(x), y),\n                      num_parallel_calls=tf.data.AUTOTUNE)\nnext(dataset.take(1).as_numpy_iterator())\n```\n\nLANGUAGE: python\nCODE:\n```\ninputs = {\n  'type': tf.keras.Input(shape=(one_hot_dims,), dtype='float32'),\n  'size': tf.keras.Input(shape=(), dtype='int64'),\n  'weight': tf.keras.Input(shape=(), dtype='float32'),\n}\n\nembedding = tf.keras.layers.Embedding(len(vocab), embedding_dims)\noutputs = tf.keras.layers.Concatenate()([\n  inputs['type'],\n  embedding(inputs['size']),\n  tf.expand_dims(inputs['weight'], -1),\n])\noutputs = tf.keras.layers.Dense(1)(outputs)\ntraining_model = tf.keras.Model(inputs, outputs)\n```\n\nLANGUAGE: python\nCODE:\n```\ntraining_model.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\ntraining_model.fit(dataset)\n```\n\nLANGUAGE: python\nCODE:\n```\ninputs = preprocessing_model.input\noutputs = training_model(preprocessing_model(inputs))\ninference_model = tf.keras.Model(inputs, outputs)\n\npredict_dataset = tf.data.Dataset.from_tensor_slices(predict_features).batch(1)\ninference_model.predict(predict_dataset)\n```\n\nLANGUAGE: python\nCODE:\n```\ninference_model.save('model.keras')\nrestored_model = tf.keras.models.load_model('model.keras')\nrestored_model.predict(predict_dataset)\n```\n\n----------------------------------------\n\nTITLE: Evaluating TensorFlow Model on Test Data\nDESCRIPTION: This code evaluates the trained model's performance on the test dataset. It returns the loss and accuracy metrics, which are then printed to assess the model's generalization ability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = model.evaluate(test_examples, test_labels)\n\nprint(results)\n```\n\n----------------------------------------\n\nTITLE: Initializing LossScaleOptimizer for Mixed Precision in TensorFlow\nDESCRIPTION: Creates a LossScaleOptimizer that wraps an existing optimizer to apply dynamic loss scaling for mixed precision training. This is a crucial step when using 'mixed_float16' policy with custom training loops.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\noptimizer = keras.optimizers.RMSprop()\noptimizer = mixed_precision.LossScaleOptimizer(optimizer)\n```\n\n----------------------------------------\n\nTITLE: Using experimental_distribute_dataset with MirroredStrategy\nDESCRIPTION: Shows how to use tf.distribute.Strategy.experimental_distribute_dataset to create a distributed dataset with MirroredStrategy and access a batch of data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 16\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n# Distribute input using the `experimental_distribute_dataset`.\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n# 1 global batch of data fed to the model in 1 step.\nprint(next(iter(dist_dataset)))\n```\n\n----------------------------------------\n\nTITLE: Shuffling and batching TensorFlow datasets\nDESCRIPTION: Prepares the datasets for training by shuffling the training data and organizing both training and test data into batches of a specified size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nBATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = 100\n\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\ntest_dataset = test_dataset.batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Visualizing a single prediction with matplotlib\nDESCRIPTION: Displays the first test image alongside its prediction probability distribution using the previously defined helper functions. Shows both the image with its prediction and a bar chart of class probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ni = 0\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  test_labels)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Implementing MNISTCompressionTrainer in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to use the MNISTCompressionTrainer class to compute rate and distortion for a batch of MNIST digits. It takes a batch of 32 images from the validation dataset and prints the resulting rate and distortion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(example_batch, _), = validation_dataset.batch(32).take(1)\ntrainer = MNISTCompressionTrainer(10)\nexample_output = trainer(example_batch)\n\nprint(\"rate: \", example_output[\"rate\"])\nprint(\"distortion: \", example_output[\"distortion\"])\n```\n\n----------------------------------------\n\nTITLE: tfdbg CLI Run Command\nDESCRIPTION: Command to execute the next Session.run() call in the debugger CLI interface.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntfdbg> run\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow Dependencies in Python\nDESCRIPTION: Imports required libraries including TensorFlow, Keras, Pandas, NumPy, Matplotlib, Seaborn, and Scikit-learn for data processing and visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nimport tempfile\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n```\n\n----------------------------------------\n\nTITLE: Setting GCS Bucket as Cache Directory in Python\nDESCRIPTION: Configures a Google Cloud Storage bucket as the cache location for TensorFlow Hub models. This enables TPU workers to access the models when running in Colab notebooks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/caching.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"TFHUB_CACHE_DIR\"] = \"gs://my-bucket/tfhub-modules-cache\"\n```\n\n----------------------------------------\n\nTITLE: Test Dataset Generation\nDESCRIPTION: Demonstrates how to use the trained model to generate images from the test dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfor inp in test_horses.take(5):\n  generate_images(generator_g, inp)\n```\n\n----------------------------------------\n\nTITLE: Creating TextLineDataset in TensorFlow\nDESCRIPTION: This snippet creates a TextLineDataset from the downloaded text files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.TextLineDataset(file_paths)\n```\n\n----------------------------------------\n\nTITLE: Loading Input Image Sequence for MoveNet\nDESCRIPTION: Downloads and loads a GIF image file to be used as input for the MoveNet pose estimation model. It uses wget to fetch the file and TensorFlow operations to decode the GIF.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n!wget -q -O dance.gif https://github.com/tensorflow/tfjs-models/raw/master/pose-detection/assets/dance_input.gif\n\n# Load the input image.\nimage_path = 'dance.gif'\nimage = tf.io.read_file(image_path)\nimage = tf.image.decode_gif(image)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and NumPy for Gradient Computation\nDESCRIPTION: This snippet imports the necessary libraries (NumPy, Matplotlib, and TensorFlow) to set up the environment for gradient computation examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow 2 and TensorFlow Hub\nDESCRIPTION: Commands to install TensorFlow 2 and the latest version of TensorFlow Hub using pip. This setup is recommended for new users and those upgrading to TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/installation.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install \"tensorflow>=2.0.0\"\n$ pip install --upgrade tensorflow-hub\n```\n\n----------------------------------------\n\nTITLE: Loading TF2 SavedModel in TensorFlow 1.15 or 2 using hub.KerasLayer\nDESCRIPTION: Shows how to load a TF2 SavedModel as a Keras layer for inference in TensorFlow 1.15 or TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nm = hub.KerasLayer(handle)\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Labeling Function in TensorFlow\nDESCRIPTION: Creates a labeling function that pairs text examples with numerical labels for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef labeler(example, index):\n  return example, tf.cast(index, tf.int64)\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Dataset Input Function for TensorFlow Estimator\nDESCRIPTION: Defines a training input function that creates a TensorFlow Dataset from a CSV file (Titanic dataset) with appropriate batching, caching, and shuffling for training an Estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef train_input_fn():\n  titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n  titanic = tf.data.experimental.make_csv_dataset(\n      titanic_file, batch_size=32,\n      label_name=\"survived\")\n  titanic_batches = (\n      titanic.cache().repeat().shuffle(500)\n      .prefetch(tf.data.AUTOTUNE))\n  return titanic_batches\n```\n\n----------------------------------------\n\nTITLE: Tensor Properties in Python\nDESCRIPTION: This code snippet demonstrates how to perform a matrix multiplication using TensorFlow, printing the resulting shape and datatype of the tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.matmul([[1]], [[2, 3]])\nprint(x.shape)\nprint(x.dtype)\n```\n\n----------------------------------------\n\nTITLE: Enabling XLA Compilation for TensorFlow Functions\nDESCRIPTION: Applies XLA (Accelerated Linear Algebra) compilation to a TensorFlow function, which can fuse operations and potentially improve performance on GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu_performance_analysis.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntf.function(jit_compile=True)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Image for Super Resolution\nDESCRIPTION: Loads the input image and applies preprocessing to prepare it for the ESRGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nhr_image = preprocess_image(IMAGE_PATH)\n```\n\n----------------------------------------\n\nTITLE: Sigmoid Implementation and Benchmarking in Python\nDESCRIPTION: This snippet defines sigmoid functions for NumPy and TensorFlow NumPy, sets up benchmarking inputs, and runs benchmarks for different implementations including CPU and GPU (if available).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Define a simple implementation of `sigmoid`, and benchmark it using\n# NumPy and TensorFlow NumPy for different input sizes.\n\ndef np_sigmoid(y):\n  return 1. / (1. + np.exp(-y))\n\ndef tnp_sigmoid(y):\n  return 1. / (1. + tnp.exp(-y))\n\n@tf.function\ndef compiled_tnp_sigmoid(y):\n  return tnp_sigmoid(y)\n\nsizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)\nnp_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]\nnp_times = benchmark(np_sigmoid, np_inputs)\n\nwith tf.device(\"/device:CPU:0\"):\n  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)\n  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)\n\nhas_gpu = len(tf.config.list_logical_devices(\"GPU\"))\nif has_gpu:\n  with tf.device(\"/device:GPU:0\"):\n    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)\nelse:\n  tnp_times_gpu = None\nplot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)\n```\n\n----------------------------------------\n\nTITLE: Implementing DELF Feature Extraction\nDESCRIPTION: Function to extract DELF features from input images using the loaded model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef run_delf(image):\n  np_image = np.array(image)\n  float_image = tf.image.convert_image_dtype(np_image, tf.float32)\n\n  return delf(\n      image=float_image,\n      score_threshold=tf.constant(100.0),\n      image_scales=tf.constant([0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0]),\n      max_feature_num=tf.constant(1000))\n```\n\n----------------------------------------\n\nTITLE: Data Preprocessing and Cleaning in Python\nDESCRIPTION: Cleans the raw dataset by removing the Time column and converting the Amount column to log space to reduce its range. Includes data normalization and splitting into train, validation and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ncleaned_df = raw_df.copy()\n\n# You don't want the `Time` column.\ncleaned_df.pop('Time')\n\n# The `Amount` column covers a huge range. Convert to log-space.\neps = 0.001 # 0 => 0.1¢\ncleaned_df['Log Amount'] = np.log(cleaned_df.pop('Amount')+eps)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset Generator\nDESCRIPTION: Defines a generator function to yield preprocessed speech and text samples for creating a TensorFlow dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef inputs_generator():\n  for speech, text in samples:\n    yield preprocess_speech(speech), preprocess_text(text)\n```\n\n----------------------------------------\n\nTITLE: Displaying Protobuf Error for Large Messages (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message related to a protobuf message being rejected due to its large size, along with instructions on how to increase the limit.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A\n  protocol message was rejected because it was too big (more than 67108864 bytes).\n  To increase the limit (or to disable these warnings), see\n  <a href=\"https://github.com/protocolbuffers/protobuf/blob/4ffb31e90681ca06bfeca92a6068206ab78959ec/src/google/protobuf/io/coded_stream.h#L389-L406\">\nCodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.</a></pre>\n```\n\n----------------------------------------\n\nTITLE: Sequential Model Creation\nDESCRIPTION: Demonstrates creating a model by stacking layers using tf.keras.Sequential\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmy_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1)),\n                               tf.keras.layers.BatchNormalization(),\n                               tf.keras.layers.Conv2D(2, 1,\n                                                      padding='same'),\n                               tf.keras.layers.BatchNormalization(),\n                               tf.keras.layers.Conv2D(3, (1, 1)),\n                               tf.keras.layers.BatchNormalization()])\nmy_seq(tf.zeros([1, 2, 3, 3]))\n```\n\n----------------------------------------\n\nTITLE: Setting Bazel and Compiler Environment Variables for TensorFlow Build on Windows\nDESCRIPTION: Commands to configure Bazel, MSVC, and CLANG environment variables to ensure proper build tool paths. These settings help resolve common build issues related to compiler locations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nset BAZEL_SH=C:/msys64/usr/bin/bash.exe \nset BAZEL_VS=C:/Program Files/Microsoft Visual Studio/2022/BuildTools \nset BAZEL_VC=C:/Program Files/Microsoft Visual Studio/2022/BuildTools/VC \nset Bazel_LLVM=C:/Program Files/LLVM (explicitly tell Bazel where LLVM is installed by BAZEL_LLVM, needed while using CLANG)\nset PATH=C:/Program Files/LLVM/bin;%PATH% (Optional, needed while using CLANG as Compiler)\n```\n\n----------------------------------------\n\nTITLE: Training with Step-Frequency Checkpointing in TensorFlow 2\nDESCRIPTION: Setting up a Keras model with BackupAndRestore callback configured to save checkpoints every 30 steps and InterruptAtStep callback to simulate a failure at the 140th step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nlog_dir_2 = tempfile.mkdtemp()\n\nbackup_restore_callback = tf.keras.callbacks.BackupAndRestore(\n    backup_dir = log_dir_2, save_freq=30\n)\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss=loss,\n              metrics=['accuracy'])\ntry:\n  model.fit(x=x_train,\n            y=y_train,\n            epochs=10,\n            steps_per_epoch=100,\n            validation_data=(x_test, y_test),\n            callbacks=[backup_restore_callback, InterruptAtStep()])\nexcept Exception as e:\n  print(f'{type(e).__name__}:{e}')\n```\n\n----------------------------------------\n\nTITLE: Defining Input Data for TensorFlow Model\nDESCRIPTION: Sets up constant input and output values for a TensorFlow model. These tensors serve as data sources for the model's computation graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_20\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\ny_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing Datasets for SNGP Model\nDESCRIPTION: Loads training, testing, and out-of-domain datasets and creates a visualization showing the training data points by class and the OOD examples. This helps understand the classification problem visually.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Load the train, test and OOD datasets.\ntrain_examples, train_labels = make_training_data(\n    sample_size=500)\ntest_examples = make_testing_data()\nood_examples = make_ood_data(sample_size=500)\n\n# Visualize\npos_examples = train_examples[train_labels == 0]\nneg_examples = train_examples[train_labels == 1]\n\nplt.figure(figsize=(7, 5.5))\n\nplt.scatter(pos_examples[:, 0], pos_examples[:, 1], c=\"#377eb8\", alpha=0.5)\nplt.scatter(neg_examples[:, 0], neg_examples[:, 1], c=\"#ff7f00\", alpha=0.5)\nplt.scatter(ood_examples[:, 0], ood_examples[:, 1], c=\"red\", alpha=0.1)\n\nplt.legend([\"Positive\", \"Negative\", \"Out-of-Domain\"])\n\nplt.ylim(DEFAULT_Y_RANGE)\nplt.xlim(DEFAULT_X_RANGE)\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow Compatibility\nDESCRIPTION: This snippet imports the TensorFlow library in compatibility mode for TensorFlow 1.x. It allows the use of legacy code from TensorFlow 1.x in a TensorFlow 2.x environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow Package Builder on Windows\nDESCRIPTION: Bazel command to build the TensorFlow package builder tool, which is used to create the pip wheel package. This is the first step in the two-step build process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nbazel build //tensorflow/tools/pip_package:wheel\n```\n\n----------------------------------------\n\nTITLE: Model Selection Configuration\nDESCRIPTION: Sets up model selection from different versions of Boundless available on TensorFlow Hub (Half, Quarter, Three Quarters).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = 'Boundless Quarter' # @param ['Boundless Half', 'Boundless Quarter', 'Boundless Three Quarters']\nmodel_handle_map = {\n    'Boundless Half' : 'https://tfhub.dev/google/boundless/half/1',\n    'Boundless Quarter' : 'https://tfhub.dev/google/boundless/quarter/1', \n    'Boundless Three Quarters' : 'https://tfhub.dev/google/boundless/three_quarter/1'\n}\n\nmodel_handle = model_handle_map[model_name]\n```\n\n----------------------------------------\n\nTITLE: Creating Basic TPUEstimator\nDESCRIPTION: Shows the minimal configuration needed to create a TPUEstimator for local testing, demonstrating the difference from standard Estimator initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmy_tpu_estimator = tf.estimator.tpu.TPUEstimator(\n    model_fn=my_model_fn,\n    config=tf.estimator.tpu.RunConfig(),\n    use_tpu=False)\n```\n\n----------------------------------------\n\nTITLE: Creating a Session Hook for Artificial Training Interruption in TF1\nDESCRIPTION: Defining a custom SessionRunHook class that artificially raises a RuntimeError during the fifth step to simulate a training failure in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass InterruptHook(tf1.train.SessionRunHook):\n  # A hook for artificially interrupting training.\n  def begin(self):\n    self._step = -1\n\n  def before_run(self, run_context):\n    self._step += 1\n\n  def after_run(self, run_context, run_values):\n    if self._step == 5:\n      raise RuntimeError('Interruption')\n```\n\n----------------------------------------\n\nTITLE: Initializing Loss Function Constants\nDESCRIPTION: Sets up the LAMBDA constant used for weighting loss components in CycleGAN and initializes the binary cross entropy loss function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nLAMBDA = 10\n\nloss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Header for SIG Playbook\nDESCRIPTION: This snippet shows the main header for the SIG playbook document, indicating the overall topic of the content.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# SIG playbook\n```\n\n----------------------------------------\n\nTITLE: Setting Up License and Copyright for TensorFlow Docs\nDESCRIPTION: This code snippet defines the copyright and license information for the TensorFlow documentation, specifying the Apache License 2.0 terms.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating Conda Environment for TensorFlow on Windows\nDESCRIPTION: This command creates a new Conda environment named 'tf' with Python 3.9, providing an isolated environment for TensorFlow installation on Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nconda create --name tf python=3.9\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Environment\nDESCRIPTION: Setting up TensorFlow imports and checking eager execution status.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport matplotlib.pyplot as plt\n\nimport tensorflow.compat.v1 as tf\n\nprint(\"TensorFlow version: {}\".format(tf.__version__))\nprint(\"Eager execution: {}\".format(tf.executing_eagerly()))\n```\n\n----------------------------------------\n\nTITLE: Final Assertion Tests for Fully Native Model\nDESCRIPTION: Performs the final verification that the fully native TensorFlow 2.0 model produces identical outputs and regularization losses to the original model, confirming a successful migration that preserves the original behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Verify that the regularization loss and output both match\nnp.testing.assert_allclose(original_regularization_loss.numpy(), migrated_regularization_loss.numpy())\nnp.testing.assert_allclose(original_output.numpy(), migrated_output.numpy())\n```\n\n----------------------------------------\n\nTITLE: Setting Up Required Imports and Dataset for Checkpoint Migration\nDESCRIPTION: Imports the necessary TensorFlow modules and loads the MNIST dataset for demonstration purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf1\nimport tensorflow as tf\nimport numpy as np\nimport tempfile\n```\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Session Run Operations\nDESCRIPTION: Demonstrates using tf.Session.run to execute operations and evaluate tensors, including variable initialization and multiple fetch operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\noutput = tf.nn.softmax(y)\ninit_op = w.initializer\n\nwith tf.Session() as sess:\n  # Run the initializer on `w`.\n  sess.run(init_op)\n\n  # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n  # the result of the computation.\n  print(sess.run(output))\n\n  # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n  # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n  # op. Both `y_val` and `output_val` will be NumPy arrays.\n  y_val, output_val = sess.run([y, output])\n```\n\n----------------------------------------\n\nTITLE: Broadcasting with 3D RaggedTensor and 2D tensor in TensorFlow\nDESCRIPTION: Demonstrates adding a 2D tensor with shape 1x1 to a 3D ragged tensor with ragged_rank=1, where the tensor value is broadcast to match the ragged dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged):  2 x (r1) x 2\n# y      (2d ragged):         1 x 1\n# Result (3d ragged):  2 x (r1) x 2\nx = tf.ragged.constant(\n    [[[1, 2], [3, 4], [5, 6]],\n     [[7, 8]]],\n    ragged_rank=1)\ny = tf.constant([[10]])\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: TF1.x Usage of NoiseAdder with Recomputed Noise\nDESCRIPTION: In TF1.x graph mode execution, this code would compute a new random noise tensor every time the session runs, correctly providing different noise per execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ng = tf.Graph()\nwith g.as_default():\n  ...\n  # initialize all variable-containing objects\n  noise_adder = NoiseAdder(shape, mean)\n  ...\n  # computation pass\n  x_with_noise = noise_adder.add_noise(x)\n  ...\n...\nsess = tf.compat.v1.Session(graph=g)\nsess.run(...)\n```\n\n----------------------------------------\n\nTITLE: Loading YAMNet Class Names\nDESCRIPTION: Loads the class names that YAMNet can recognize from the CSV mapping file and prints the first 20 classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\nclass_names =list(pd.read_csv(class_map_path)['display_name'])\n\nfor name in class_names[:20]:\n  print(name)\nprint('...')\n```\n\n----------------------------------------\n\nTITLE: Serialize Dataset Elements using TensorFlow (Python)\nDESCRIPTION: Defines a function to serialize dataset elements into tf.Example-compatible format using TensorFlow's py_function, useful for preparing data to write as TFRecord.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef serialize_example_pyfunction(feature0, feature1, feature2, feature3):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n\n  # Create a dictionary mapping the feature name to the tf.Example-compatible\n  # data type.\n\n  feature = {\n      'feature0': _int64_feature(feature0.numpy()),\n      'feature1': _int64_feature(feature1.numpy()),\n      'feature2': _bytes_feature(feature2.numpy()),\n      'feature3': _float_feature(feature3.numpy()),\n  }\n\n  # Create a Features message using tf.train.Example.\n\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating the Model with Distribution Strategy\nDESCRIPTION: Configures and creates a TensorFlow Estimator with the distribution strategy, then launches training and evaluation. The RunConfig specifies the train_distribute parameter to enable distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconfig = tf.estimator.RunConfig(train_distribute=strategy)\n\nclassifier = tf.estimator.Estimator(\n    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)\ntf.estimator.train_and_evaluate(\n    classifier,\n    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n)\n```\n\n----------------------------------------\n\nTITLE: Template-based Type Polymorphic Op Implementation in C++\nDESCRIPTION: Shows a templated implementation of ZeroOut that handles multiple types through a single class definition, with separate registrations for each supported type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_32\n\nLANGUAGE: C++\nCODE:\n```\ntemplate <typename T>\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<T>();\n\n    // Create an output tensor\n    Tensor* output = NULL;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_tensor.shape(), &output));\n    auto output_flat = output->template flat<T>();\n\n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the first input value\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<int32>(\"T\"),\n    ZeroOutOp<int32>);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<float>(\"T\"),\n    ZeroOutOp<float>);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<double>(\"T\"),\n    ZeroOutOp<double>);\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow in Docker Container\nDESCRIPTION: Example of running a simple TensorFlow operation in a Docker container to verify the installation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm tensorflow/tensorflow \\\n   python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Creating Integer TensorFlow Variable\nDESCRIPTION: Creates a TensorFlow variable with explicit int32 dtype and zeros initializer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmy_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n  initializer=tf.zeros_initializer)\n```\n\n----------------------------------------\n\nTITLE: Alternative Order with Old Type Promotion in TensorFlow\nDESCRIPTION: This snippet demonstrates that changing the order of operations with the old type promotion system produces a different result instead of an error.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# (b + a) + c returns an i32 result.\ntf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=int32, numpy=3>\n```\n\n----------------------------------------\n\nTITLE: Defining a Quadratic Model Class in TensorFlow\nDESCRIPTION: Creates a custom TensorFlow Module class representing a quadratic model with randomly initialized weights and a bias.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n\n  def __init__(self):\n    # Randomly generate weight and bias terms\n    rand_init = tf.random.uniform(shape=[3], minval=0., maxval=5., seed=22)\n    # Initialize model parameters\n    self.w_q = tf.Variable(rand_init[0])\n    self.w_l = tf.Variable(rand_init[1])\n    self.b = tf.Variable(rand_init[2])\n  \n  @tf.function\n  def __call__(self, x):\n    # Quadratic Model : quadratic_weight * x^2 + linear_weight * x + bias\n    return self.w_q * (x**2) + self.w_l * x + self.b\n```\n\n----------------------------------------\n\nTITLE: Using Eager Execution in Graph Environment\nDESCRIPTION: Demonstrates how to use eager execution functionality within a graph execution environment using tf.py_func. Allows mixing eager and graph execution modes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef my_py_func(x):\n  x = tf.matmul(x, x)  # You can use tf ops\n  print(x)  # but it's eager!\n  return x\n\nwith tf.Session() as sess:\n  x = tf.placeholder(dtype=tf.float32)\n  # Call eager function in graph!\n  pf = tf.py_func(my_py_func, [x], tf.float32)\n\n  sess.run(pf, feed_dict={x: [[2.0]]})  # [[4.0]]\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model Performance on Test Data\nDESCRIPTION: Assess the model's performance by evaluating its loss and accuracy on unseen test data to understand generalization capabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = model.evaluate(test_data,  test_labels, verbose=2)\n\nprint(results)\n```\n\n----------------------------------------\n\nTITLE: Saving Generator Module to SavedModel Format\nDESCRIPTION: Saves a module containing a random number generator to SavedModel format within a distribution strategy context, preserving its state for later loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nwith strat.scope():\n  tf.saved_model.save(m, filename)\n  print(\"RNG stream from saving point:\")\n  print(strat.run(m))\n  print(\"state:\", m.state())\n  print(strat.run(m))\n  print(\"state:\", m.state())\n```\n\n----------------------------------------\n\nTITLE: Calculating Loss for Iris Classification in TensorFlow\nDESCRIPTION: This snippet shows how to calculate the loss for the Iris classification model using sparse softmax cross entropy. This loss function is used for both training and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Compute loss.\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n```\n\n----------------------------------------\n\nTITLE: Verifying Environment Variable in Subprocess\nDESCRIPTION: Using a bash subprocess to verify that the environment variable set in the parent process is accessible in child processes, demonstrating how TF_CONFIG will be passed to worker processes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\necho ${GREETINGS}\n```\n\n----------------------------------------\n\nTITLE: MNIST Classifier Model Definition with Custom Layers\nDESCRIPTION: Creates a sequential model for MNIST digit classification using the custom convolutional and dense layers defined previously. This model will serve as the base for the compression demonstration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf.keras.Sequential([\n    CustomConv2D(20, 5, strides=2, name=\"conv_1\"),\n    CustomConv2D(50, 5, strides=2, name=\"conv_2\"),\n    tf.keras.layers.Flatten(),\n    CustomDense(500, name=\"fc_1\"),\n    CustomDense(10, name=\"fc_2\"),\n], name=\"classifier\")\n```\n\n----------------------------------------\n\nTITLE: Correct Tensor Printing using tf.Print in TensorFlow\nDESCRIPTION: This example demonstrates the correct way to print a tensor's value using tf.Print. It shows that the return value of tf.Print must be used for the printing to take effect.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nt = <<some tensorflow operation>>\ntf.Print(t, [t])  # This does nothing\nt = tf.Print(t, [t])  # Here we are using the value returned by tf.Print\nresult = t + 1  # Now when result is evaluated the value of `t` will be printed.\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Operations on GPU\nDESCRIPTION: Demonstrates how to check for GPU availability and run TensorFlow operations on GPU device. Uses device context manager to ensure operations execute on GPU if available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  with tf.device(\"/gpu:0\"):\n    print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\nelse:\n  print(\"GPU: not found\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Fashion MNIST Dataset\nDESCRIPTION: Loads the Fashion MNIST dataset, adds a dimension for the channel, and normalizes the pixel values to be between 0 and 1 for better model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n# Add a dimension to the array -> new shape == (28, 28, 1)\n# This is done because the first layer in our model is a convolutional\n# layer and it requires a 4D input (batch_size, height, width, channels).\n# batch_size dimension will be added later on.\ntrain_images = train_images[..., None]\ntest_images = test_images[..., None]\n\n# Scale the images to the [0, 1] range.\ntrain_images = train_images / np.float32(255)\ntest_images = test_images / np.float32(255)\n```\n\n----------------------------------------\n\nTITLE: Full TensorFlow Program for Training a Linear Model\nDESCRIPTION: Presents a complete TensorFlow program defining, initializing, and training a simple linear regression model. The code iterates over training steps, adjusting weights to minimize the error between predicted and true outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_24\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\ny_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n\nlinear_model = tf.layers.Dense(units=1)\n\ny_pred = linear_model(x)\nloss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\n\nsess = tf.Session()\nsess.run(init)\nfor i in range(100):\n  _, loss_value = sess.run((train, loss))\n  print(loss_value)\n\nprint(sess.run(y_pred))\n```\n\n----------------------------------------\n\nTITLE: Filtering Titanic Dataset in TensorFlow\nDESCRIPTION: This snippet shows how to filter the Titanic dataset to include only survivors and skip the header line.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\ndef survived(line):\n  return tf.not_equal(tf.strings.substr(line, 0, 1), \"0\")\n\nsurvivors = titanic_lines.skip(1).filter(survived)\n\nfor line in survivors.take(10):\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: Initializing Input Sentences in TensorFlow\nDESCRIPTION: Defines input sentences to be processed for segmentation, including mixed-script examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nsentence_texts = [u'Hello, world.', u'世界こんにちは']\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Installs the seaborn library using pip in a Jupyter notebook cell with output capture.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n!pip3 install seaborn\n```\n\n----------------------------------------\n\nTITLE: Defining Model Handle Map in Python\nDESCRIPTION: This snippet defines a dictionary mapping model names to their corresponding TensorFlow Hub URLs for various MobileNet models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{\n  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\",\n  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/4\",\n  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\",\n  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/classification/5\",\n  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\",\n  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/classification/5\",\n}\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Dataset Pipeline\nDESCRIPTION: Sets up a TensorFlow data pipeline by creating a dataset from tensors and defining the element specifications.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfilenames = filtered_pd['filename']\ntargets = filtered_pd['target']\nfolds = filtered_pd['fold']\n\nmain_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\nmain_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Libraries for DTensor\nDESCRIPTION: Imports the necessary TensorFlow modules, including the experimental DTensor module and TensorFlow Datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.experimental import dtensor\n```\n\n----------------------------------------\n\nTITLE: Avoiding feed_dict for Better Performance in TensorFlow\nDESCRIPTION: Example showing the feed_dict approach in TensorFlow, which is noted as resulting in suboptimal performance. This pattern should be avoided for all but trivial examples in favor of the tf.data API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# feed_dict often results in suboptimal performance.\nsess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n```\n\n----------------------------------------\n\nTITLE: Running MNIST Debug Example Command\nDESCRIPTION: Command line instruction for running the MNIST example with debugging enabled using the --debug flag.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython -m tensorflow.python.debug.examples.v1.debug_mnist --debug\n```\n\n----------------------------------------\n\nTITLE: Normalizing Numeric Features with Keras\nDESCRIPTION: Shows how to normalize numeric input using Keras Normalization layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nnormalization_layer = tf.keras.layers.Normalization(mean=2.0, variance=1.0)\nnormalization_layer(tf.constant([[0.], [1.], [2.]]))\n```\n\n----------------------------------------\n\nTITLE: Placing TensorFlow Variables on Specific Devices\nDESCRIPTION: These snippets demonstrate how to place TensorFlow variables and operations on specific devices (CPU or GPU) using tf.device context manager.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device('CPU:0'):\n\n  # Create some tensors\n  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n  c = tf.matmul(a, b)\n\nprint(c)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device('CPU:0'):\n  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.Variable([[1.0, 2.0, 3.0]])\n\nwith tf.device('GPU:0'):\n  # Element-wise multiply\n  k = a * b\n\nprint(k)\n```\n\n----------------------------------------\n\nTITLE: Testing Model Input Shape Compatibility\nDESCRIPTION: Demonstrates a limitation of the multi-step dense model by showing it cannot handle different input shapes than what it was designed for, resulting in an error.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', wide_window.example[0].shape)\ntry:\n  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\nexcept Exception as e:\n  print(f'\\n{type(e).__name__}:{e}')\n```\n\n----------------------------------------\n\nTITLE: MirroredStrategy with Custom Cross-Device Operations\nDESCRIPTION: Creates a MirroredStrategy instance with custom cross-device communication implementation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy(\n    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n```\n\n----------------------------------------\n\nTITLE: Selecting Object Detection Model\nDESCRIPTION: This code cell allows the user to select an object detection model from a predefined list of models available in TensorFlow Hub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#@title Model Selection { display-mode: \"form\", run: \"auto\" }\nmodel_display_name = 'CenterNet HourGlass104 Keypoints 512x512' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\nmodel_handle = ALL_MODELS[model_display_name]\n\nprint('Selected model:'+ model_display_name)\nprint('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Variables\nDESCRIPTION: Initializes all TensorFlow global variables using `tf.global_variables_initializer`. This operation must be executed within a session to allocate values to variables, ensuring they are ready for computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\ninit = tf.global_variables_initializer()\nsess.run(init)\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Fixed-Type Tensor Sequence in C++\nDESCRIPTION: Example of registering a TensorFlow operation that accepts a sequence of tensors of the same fixed type. The op accepts 'NumTensors' number of int32 tensors, where 'NumTensors' is an integer attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_43\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"Int32SequenceExample\")\n    .Attr(\"NumTensors: int\")\n    .Input(\"in: NumTensors * int32\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Communication Options for MultiWorkerMirroredStrategy\nDESCRIPTION: Code to create MultiWorkerMirroredStrategy with specific cross-device communication implementation. Options include RING (RPC-based, supports CPU and GPU) and NCCL (optimized for GPUs).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncommunication_options = tf.distribute.experimental.CommunicationOptions(\n    implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)\nstrategy = tf.distribute.MultiWorkerMirroredStrategy(\n    communication_options=communication_options)\n```\n\n----------------------------------------\n\nTITLE: Loading and Running BERT Model on Sample Sentences\nDESCRIPTION: Loads the BERT model from TensorFlow Hub, processes the sentences through the preprocessing model, and generates embeddings for each sentence. This demonstrates the core workflow for using BERT models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npreprocess = hub.load(PREPROCESS_MODEL)\nbert = hub.load(BERT_MODEL)\ninputs = preprocess(sentences)\noutputs = bert(inputs)\n```\n\n----------------------------------------\n\nTITLE: Calculating Classification Metrics for Video Recognition in Python\nDESCRIPTION: This function calculates precision and recall for each class in a video classification model. It takes actual labels, predicted labels, and class labels as inputs and returns dictionaries of precision and recall values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef calculate_classification_metrics(y_actual, y_pred, labels):\n  \"\"\"\n    Calculate the precision and recall of a classification model using the ground truth and\n    predicted values. \n\n    Args:\n      y_actual: Ground truth labels.\n      y_pred: Predicted labels.\n      labels: List of classification labels.\n\n    Return:\n      Precision and recall measures.\n  \"\"\"\n  cm = tf.math.confusion_matrix(y_actual, y_pred)\n  tp = np.diag(cm) # Diagonal represents true positives\n  precision = dict()\n  recall = dict()\n  for i in range(len(labels)):\n    col = cm[:, i]\n    fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n    \n    row = cm[i, :]\n    fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n    \n    precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision \n    \n    recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n  \n  return precision, recall\n```\n\n----------------------------------------\n\nTITLE: Converting Generated Notes to MIDI and Playing Audio in Python\nDESCRIPTION: Converts the generated notes to a MIDI file and displays an audio player to listen to the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nout_file = 'output.mid'\nout_pm = notes_to_midi(\n    generated_notes, out_file=out_file, instrument_name=instrument_name)\ndisplay_audio(out_pm)\n```\n\n----------------------------------------\n\nTITLE: Classifying and Displaying Top Predictions for Sample Images\nDESCRIPTION: Iterates through the sample images, displays each image, and prints the top 3 predicted labels with their probabilities using the Inception V1 model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfor (name, img_tensor) in img_name_tensors.items():\n  plt.imshow(img_tensor)\n  plt.title(name, fontweight='bold')\n  plt.axis('off')\n  plt.show()\n\n  pred_label, pred_prob = top_k_predictions(img_tensor)\n  for label, prob in zip(pred_label, pred_prob):\n    print(f'{label}: {prob:0.1%}')\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Libraries\nDESCRIPTION: Installs necessary Python packages including remotezip for ZIP file inspection, tqdm for progress bar functionality, OpenCV for video processing, einops for tensor operations, and TensorFlow/Keras for deep learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install remotezip tqdm opencv-python einops \n!pip install -U tensorflow keras\n```\n\n----------------------------------------\n\nTITLE: Counting Parsed Notes in Python\nDESCRIPTION: Displays the total number of musical notes extracted from the MIDI files, providing a measure of the dataset size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nn_notes = len(all_notes)\nprint('Number of notes parsed:', n_notes)\n```\n\n----------------------------------------\n\nTITLE: Dataset Performance Configuration\nDESCRIPTION: Configures datasets for optimal performance using caching and prefetching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Resetting TF_CONFIG Environment Variable\nDESCRIPTION: Removing any existing TF_CONFIG environment variable to ensure a clean setup before configuring it for multi-worker training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nos.environ.pop('TF_CONFIG', None)\n```\n\n----------------------------------------\n\nTITLE: Implementing Properties in ExtensionType in Python\nDESCRIPTION: Demonstrates how to define properties in an ExtensionType class using the @property decorator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  @property\n  def dtype(self):\n    return self.values.dtype\n\nMaskedTensor([1, 2, 3], [True, False, True]).dtype\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss\nDESCRIPTION: Visualize the training and validation loss across epochs to understand model learning progression and potential overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\n\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating a Boosted Trees Estimator in TensorFlow 1\nDESCRIPTION: This snippet shows how to train and evaluate a BoostedTreesEstimator in TensorFlow 1. It uses input functions for both training and evaluation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nbt_estimator.train(input_fn=_input_fn, steps=1000)\nbt_estimator.evaluate(input_fn=_eval_input_fn, steps=100)\n```\n\n----------------------------------------\n\nTITLE: Creating Hello TensorFlow C Program\nDESCRIPTION: This C program demonstrates a simple use of the TensorFlow C API by printing the TensorFlow version. It includes the TensorFlow C header and uses the TF_Version() function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: c\nCODE:\n```\n#include <stdio.h>\n#include <tensorflow/c/c_api.h>\n\nint main() {\n  printf(\"Hello from TensorFlow C library version %s\\n\", TF_Version());\n  return 0;\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom BatchNorm Layer\nDESCRIPTION: Custom BatchNormalization layer implementation for DTensor that handles global batch normalization\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass BatchNorm(tf.Module):\n\n  def __init__(self):\n    super().__init__()\n\n  def __call__(self, x, training=True):\n    if not training:\n      # This branch is not used in the Tutorial.\n      pass\n    mean, variance = tf.nn.moments(x, axes=[0])\n    return tf.nn.batch_normalization(x, mean, variance, 0.0, 1.0, 1e-5)\n```\n\n----------------------------------------\n\nTITLE: Printing AutoGraph Generated Code\nDESCRIPTION: Displays the TensorFlow graph code that AutoGraph automatically generates from the Python square_if_positive function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.autograph.to_code(square_if_positive))\n```\n\n----------------------------------------\n\nTITLE: Executing ANNOY Index Building in Python\nDESCRIPTION: Calls the build_index function with specific parameters to create the ANNOY index for the generated embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nembedding_files = \"{}/emb-*.tfrecords\".format(output_dir)\nembedding_dimension = projected_dim\nindex_filename = \"index\"\n\n!rm {index_filename}\n!rm {index_filename}.mapping\n\n%time build_index(embedding_files, index_filename, embedding_dimension)\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Dataset with Standard API\nDESCRIPTION: Uses TensorFlow's make_csv_dataset function to create a dataset from multiple CSV files. This approach automatically handles batching and parallel reading but is less efficient for large datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_58\n\nLANGUAGE: python\nCODE:\n```\nBATCH_SIZE=2048\nfonts_ds = tf.data.experimental.make_csv_dataset(\n    file_pattern = \"fonts/*.csv\",\n    batch_size=BATCH_SIZE, num_epochs=1,\n    num_parallel_reads=100)\n```\n\n----------------------------------------\n\nTITLE: Converting Keras Model to Estimator in Python\nDESCRIPTION: This snippet demonstrates how to convert a simple Keras sequential model to a TensorFlow estimator. It creates a model with two dense layers, compiles it, and then converts it to an estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([layers.Dense(64, activation='relu', input_shape=(32,)),\n                          layers.Dense(10,activation='softmax')])\n\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nestimator = tf.keras.estimator.model_to_estimator(model)\n```\n\n----------------------------------------\n\nTITLE: Downloading the Higgs Dataset in TensorFlow\nDESCRIPTION: This code downloads the Higgs dataset using TensorFlow's get_file utility and sets the number of features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ngz = tf.keras.utils.get_file('HIGGS.csv.gz', 'http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz')\n\nFEATURES = 28\n```\n\n----------------------------------------\n\nTITLE: Iterating Over a Distributed Dataset in TensorFlow Training Loop\nDESCRIPTION: Shows how to iterate over a distributed dataset and execute training steps for each batch of data in the distributed training context.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfor dist_inputs in dist_dataset:\n  print(distributed_train_step(dist_inputs))\n```\n\n----------------------------------------\n\nTITLE: Loading and Parsing the Iris Dataset\nDESCRIPTION: Downloads the Iris dataset using Keras utils and loads it into Pandas dataframes for training and testing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_path = tf.keras.utils.get_file(\n    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\ntest_path = tf.keras.utils.get_file(\n    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n\ntrain = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\ntest = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n```\n\n----------------------------------------\n\nTITLE: Downloading the ESC-50 Dataset\nDESCRIPTION: Downloads and extracts the ESC-50 dataset, a labeled collection of 2,000 five-second environmental audio recordings across 50 classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n_ = tf.keras.utils.get_file('esc-50.zip',\n                        'https://github.com/karoldvl/ESC-50/archive/master.zip',\n                        cache_dir='./',\n                        cache_subdir='datasets',\n                        extract=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Octave-based Deep Dream Processing in Python with TensorFlow\nDESCRIPTION: Processes images through multiple octaves (scaled versions) to generate DeepDream effects at different granularities. Includes image resizing, gradient computation, and progress display.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport time\nstart = time.time()\n\nOCTAVE_SCALE = 1.30\n\nimg = tf.constant(np.array(original_img))\nbase_shape = tf.shape(img)[:-1]\nfloat_base_shape = tf.cast(base_shape, tf.float32)\n\nfor n in range(-2, 3):\n  new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n\n  img = tf.image.resize(img, new_shape).numpy()\n\n  img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n\ndisplay.clear_output(wait=True)\nimg = tf.image.resize(img, base_shape)\nimg = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\nshow(img)\n\nend = time.time()\nend-start\n```\n\n----------------------------------------\n\nTITLE: Creating Parameter Server Strategy in TensorFlow\nDESCRIPTION: Instantiates a ParameterServerStrategy for distributed training across multiple machines using parameter servers and workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nps_strategy = tf.distribute.experimental.ParameterServerStrategy()\n```\n\n----------------------------------------\n\nTITLE: Creating Keras BatchNorm with DTensor Layout\nDESCRIPTION: Helper function to create a Keras BatchNormalization layer with DTensor layout specifications\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef make_keras_bn(bn_layout):\n  return tf.keras.layers.BatchNormalization(gamma_layout=bn_layout,\n                                            beta_layout=bn_layout,\n                                            moving_mean_layout=bn_layout,\n                                            moving_variance_layout=bn_layout,\n                                            fused=False)\n```\n\n----------------------------------------\n\nTITLE: Defining Helper Functions for Video Data Preprocessing in Python\nDESCRIPTION: This snippet defines various helper functions for downloading, processing, and organizing video data from the UCF-101 dataset. It includes functions for listing files, extracting class information, downloading from zip files, and splitting data into training, validation, and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title\n\ndef list_files_per_class(zip_url):\n  \"\"\"\n    List the files in each class of the dataset given the zip URL.\n\n    Args:\n      zip_url: URL from which the files can be unzipped. \n\n    Return:\n      files: List of files in each of the classes.\n  \"\"\"\n  files = []\n  with rz.RemoteZip(URL) as zip:\n    for zip_info in zip.infolist():\n      files.append(zip_info.filename)\n  return files\n\ndef get_class(fname):\n  \"\"\"\n    Retrieve the name of the class given a filename.\n\n    Args:\n      fname: Name of the file in the UCF101 dataset.\n\n    Return:\n      Class that the file belongs to.\n  \"\"\"\n  return fname.split('_')[-3]\n\ndef get_files_per_class(files):\n  \"\"\"\n    Retrieve the files that belong to each class. \n\n    Args:\n      files: List of files in the dataset.\n\n    Return:\n      Dictionary of class names (key) and files (values).\n  \"\"\"\n  files_for_class = collections.defaultdict(list)\n  for fname in files:\n    class_name = get_class(fname)\n    files_for_class[class_name].append(fname)\n  return files_for_class\n\ndef download_from_zip(zip_url, to_dir, file_names):\n  \"\"\"\n    Download the contents of the zip file from the zip URL.\n\n    Args:\n      zip_url: Zip URL containing data.\n      to_dir: Directory to download data to.\n      file_names: Names of files to download.\n  \"\"\"\n  with rz.RemoteZip(zip_url) as zip:\n    for fn in tqdm.tqdm(file_names):\n      class_name = get_class(fn)\n      zip.extract(fn, str(to_dir / class_name))\n      unzipped_file = to_dir / class_name / fn\n\n      fn = pathlib.Path(fn).parts[-1]\n      output_file = to_dir / class_name / fn\n      unzipped_file.rename(output_file,)\n\ndef split_class_lists(files_for_class, count):\n  \"\"\"\n    Returns the list of files belonging to a subset of data as well as the remainder of\n    files that need to be downloaded.\n    \n    Args:\n      files_for_class: Files belonging to a particular class of data.\n      count: Number of files to download.\n\n    Return:\n      split_files: Files belonging to the subset of data.\n      remainder: Dictionary of the remainder of files that need to be downloaded.\n  \"\"\"\n  split_files = []\n  remainder = {}\n  for cls in files_for_class:\n    split_files.extend(files_for_class[cls][:count])\n    remainder[cls] = files_for_class[cls][count:]\n  return split_files, remainder\n\ndef download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n  \"\"\"\n    Download a subset of the UFC101 dataset and split them into various parts, such as\n    training, validation, and test. \n\n    Args:\n      zip_url: Zip URL containing data.\n      num_classes: Number of labels.\n      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n              (value is number of files per split).\n      download_dir: Directory to download data to.\n\n    Return:\n      dir: Posix path of the resulting directories containing the splits of data.\n  \"\"\"\n  files = list_files_per_class(zip_url)\n  for f in files:\n    tokens = f.split('/')\n    if len(tokens) <= 2:\n      files.remove(f) # Remove that item from the list if it does not have a filename\n  \n  files_for_class = get_files_per_class(files)\n\n  classes = list(files_for_class.keys())[:num_classes]\n\n  for cls in classes:\n    new_files_for_class = files_for_class[cls]\n    random.shuffle(new_files_for_class)\n    files_for_class[cls] = new_files_for_class\n    \n  # Only use the number of classes you want in the dictionary\n  files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n\n  dirs = {}\n  for split_name, split_count in splits.items():\n    print(split_name, \":\")\n    split_dir = download_dir / split_name\n    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n    download_from_zip(zip_url, split_dir, split_files)\n    dirs[split_name] = split_dir\n\n  return dirs\n\ndef format_frames(frame, output_size):\n  \"\"\"\n    Pad and resize an image from a video.\n    \n    Args:\n      frame: Image that needs to resized and padded. \n      output_size: Pixel size of the output frame image.\n\n    Return:\n      Formatted frame with padding of specified output size.\n  \"\"\"\n  frame = tf.image.convert_image_dtype(frame, tf.float32)\n  frame = tf.image.resize_with_pad(frame, *output_size)\n  return frame\n\ndef frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n  \"\"\"\n    Creates frames from each video file present for each category.\n\n    Args:\n      video_path: File path to the video.\n      n_frames: Number of frames to be created per video file.\n      output_size: Pixel size of the output frame image.\n\n    Return:\n      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n  \"\"\"\n  # Read each video frame by frame\n  result = []\n  src = cv2.VideoCapture(str(video_path))  \n\n  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n\n  need_length = 1 + (n_frames - 1) * frame_step\n\n  if need_length > video_length:\n    start = 0\n  else:\n    max_start = video_length - need_length\n    start = random.randint(0, max_start + 1)\n\n  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n  # ret is a boolean indicating whether read was successful, frame is the image itself\n  ret, frame = src.read()\n  result.append(format_frames(frame, output_size))\n\n  for _ in range(n_frames - 1):\n    for _ in range(frame_step):\n      ret, frame = src.read()\n    if ret:\n      frame = format_frames(frame, output_size)\n      result.append(frame)\n    else:\n      result.append(np.zeros_like(result[0]))\n  src.release()\n  result = np.array(result)[..., [2, 1, 0]]\n\n  return result\n\nclass FrameGenerator:\n  def __init__(self, path, n_frames, training = False):\n    \"\"\" Returns a set of frames with their associated label. \n\n      Args:\n        path: Video file paths.\n        n_frames: Number of frames. \n        training: Boolean to determine if training dataset is being created.\n    \"\"\"\n    self.path = path\n    self.n_frames = n_frames\n    self.training = training\n    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n\n  def get_files_and_class_names(self):\n    video_paths = list(self.path.glob('*/*.avi'))\n    classes = [p.parent.name for p in video_paths] \n    return video_paths, classes\n\n  def __call__(self):\n    video_paths, classes = self.get_files_and_class_names()\n\n    pairs = list(zip(video_paths, classes))\n\n    if self.training:\n      random.shuffle(pairs)\n\n    for path, name in pairs:\n      video_frames = frames_from_video_file(path, self.n_frames) \n      label = self.class_ids_for_name[name] # Encode labels\n      yield video_frames, label\n```\n\n----------------------------------------\n\nTITLE: Reading TFRecord File using TensorFlow (Python)\nDESCRIPTION: Demonstrates loading TFRecord files into raw dataset format using tf.data.TFRecordDataset, useful for reading previously serialized data into programmatic TensorFlow workflows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [filename]\nraw_dataset = tf.data.TFRecordDataset(filenames)\nraw_dataset\n```\n\n----------------------------------------\n\nTITLE: Implementing MLP Class with DTensor Layouts in Python\nDESCRIPTION: Defines an MLP class using TensorFlow and DTensor, with two Dense layers and a BatchNorm layer. The class takes layout arguments for each Dense layer to specify DTensor sharding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Tuple\n\nclass MLP(tf.Module):\n\n  def __init__(self, dense_layouts: Tuple[dtensor.Layout, dtensor.Layout]):\n    super().__init__()\n\n    self.dense1 = Dense(\n        1200, 48, (1, 2), dense_layouts[0], activation=tf.nn.relu)\n    self.bn = BatchNorm()\n    self.dense2 = Dense(48, 2, (3, 4), dense_layouts[1])\n\n  def __call__(self, x):\n    y = x\n    y = self.dense1(y)\n    y = self.bn(y)\n    y = self.dense2(y)\n    return y\n```\n\n----------------------------------------\n\nTITLE: Custom 2D Convolutional Layer Implementation for Model Compression\nDESCRIPTION: Defines a custom 2D convolutional layer similar to the dense layer, with a copy constructor for initializing from another layer. This supports the compression workflow by allowing weight transfer between models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass CustomConv2D(tf.keras.layers.Layer):\n\n  def __init__(self, filters, kernel_size,\n               strides=1, padding=\"SAME\", name=\"conv2d\"):\n    super().__init__(name=name)\n    self.filters = filters\n    self.kernel_size = kernel_size\n    self.strides = strides\n    self.padding = padding\n\n  @classmethod\n  def copy(cls, other, **kwargs):\n    \"\"\"Returns an instantiated and built layer, initialized from `other`.\"\"\"\n    self = cls(filters=other.filters, kernel_size=other.kernel_size,\n               strides=other.strides, padding=other.padding, name=other.name,\n               **kwargs)\n    self.build(None, other=other)\n    return self\n\n  def build(self, input_shape, other=None):\n    \"\"\"Instantiates weights, optionally initializing them from `other`.\"\"\"\n    if other is None:\n      kernel_shape = 2 * (self.kernel_size,) + (input_shape[-1], self.filters)\n      kernel = tf.keras.initializers.GlorotUniform()(shape=kernel_shape)\n      bias = tf.keras.initializers.Zeros()(shape=(self.filters,))\n    else:\n      kernel, bias = other.kernel, other.bias\n    self.kernel = tf.Variable(\n        tf.cast(kernel, self.variable_dtype), name=\"kernel\")\n    self.bias = tf.Variable(\n        tf.cast(bias, self.variable_dtype), name=\"bias\")\n    self.built = True\n\n  def call(self, inputs):\n    outputs = tf.nn.convolution(\n        inputs, self.kernel, strides=self.strides, padding=self.padding)\n    outputs = tf.nn.bias_add(outputs, self.bias)\n    return tf.nn.leaky_relu(outputs)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Dataset Labels in TensorFlow\nDESCRIPTION: This snippet demonstrates how to examine the labels from the training dataset to ensure proper shuffling of the data. It iterates through the first 10 batches and prints their labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfor frames, labels in train_ds.take(10):\n  print(labels)\n```\n\n----------------------------------------\n\nTITLE: Adding Methods to ExtensionType in Python\nDESCRIPTION: Demonstrates how to add custom methods to an ExtensionType class, such as a with_default method for MaskedTensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  def with_default(self, default):\n    return tf.where(self.mask, self.values, default)\n\nMaskedTensor([1, 2, 3], [True, False, True]).with_default(0)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing the TensorFlow Dataset\nDESCRIPTION: This code applies the pack_row function to batches of data, then unbatches it to create individual records in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\npacked_ds = ds.batch(10000).map(pack_row).unbatch()\n```\n\n----------------------------------------\n\nTITLE: Creating DynamicRaggedShape from Static Lengths\nDESCRIPTION: Shows how to create a DynamicRaggedShape when the lengths of all rows are known statically using the from_lengths factory method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_47\n\nLANGUAGE: python\nCODE:\n```\ntf.experimental.DynamicRaggedShape.from_lengths([4, (2, 1, 0, 8), 12])\n```\n\n----------------------------------------\n\nTITLE: Debugging tf-slim Training\nDESCRIPTION: Shows how to debug training process in tf-slim using LocalCLIDebugWrapperSession.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\n\n# ... Code that creates the graph and the train_op ...\ntf.contrib.slim.learning.train(\n    train_op,\n    logdir,\n    number_of_steps=10,\n    session_wrapper=tf_debug.LocalCLIDebugWrapperSession)\n```\n\n----------------------------------------\n\nTITLE: Adding MetaGraph to SavedModel in Python\nDESCRIPTION: This Python snippet demonstrates adding a MetaGraph to a SavedModel using the `tf.saved_model.builder.SavedModelBuilder` class. Setting `strip_default_attrs=True` can help maintain forward compatibility by stripping default-valued attributes from `NodeDefs`. Ensure TensorFlow is installed as a dependency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Session(graph=tf.Graph()) as sess:\n  ...\n  builder.add_meta_graph([tag_constants.SERVING], strip_default_attrs=True)\n...\nbuilder.save()\n```\n\n----------------------------------------\n\nTITLE: Defining input and model functions for tf.estimator.Estimator\nDESCRIPTION: Creates input functions for training and evaluation data, and a model function for use with tf.estimator.Estimator in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n\ndef _eval_input_fn():\n  return tf1.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\ndef _model_fn(features, labels, mode):\n  logits = tf1.layers.Dense(1)(features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  return tf1.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\n----------------------------------------\n\nTITLE: Defining Model Image Size Map in Python\nDESCRIPTION: This snippet creates a dictionary mapping model names to their corresponding input image sizes for various EfficientNet and other models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel_image_size_map = {\n  \"efficientnetv2-s\": 384,\n  \"efficientnetv2-m\": 480,\n  \"efficientnetv2-l\": 480,\n  \"efficientnetv2-b0\": 224,\n  \"efficientnetv2-b1\": 240,\n  \"efficientnetv2-b2\": 260,\n  \"efficientnetv2-b3\": 300,\n  \"efficientnetv2-s-21k\": 384,\n  \"efficientnetv2-m-21k\": 480,\n  \"efficientnetv2-l-21k\": 480,\n  \"efficientnetv2-xl-21k\": 512,\n  \"efficientnetv2-b0-21k\": 224,\n  \"efficientnetv2-b1-21k\": 240,\n  \"efficientnetv2-b2-21k\": 260,\n  \"efficientnetv2-b3-21k\": 300,\n  \"efficientnetv2-s-21k-ft1k\": 384,\n  \"efficientnetv2-m-21k-ft1k\": 480,\n  \"efficientnetv2-l-21k-ft1k\": 480,\n  \"efficientnetv2-xl-21k-ft1k\": 512,\n  \"efficientnetv2-b0-21k-ft1k\": 224,\n  \"efficientnetv2-b1-21k-ft1k\": 240,\n  \"efficientnetv2-b2-21k-ft1k\": 260,\n  \"efficientnetv2-b3-21k-ft1k\": 300, \n  \"efficientnet_b0\": 224,\n  \"efficientnet_b1\": 240,\n  \"efficientnet_b2\": 260,\n  \"efficientnet_b3\": 300,\n  \"efficientnet_b4\": 380,\n  \"efficientnet_b5\": 456,\n  \"efficientnet_b6\": 528,\n  \"efficientnet_b7\": 600,\n  \"inception_v3\": 299,\n  \"inception_resnet_v2\": 299,\n  \"mobilenet_v2_100_224\": 224,\n  \"mobilenet_v2_130_224\": 224,\n  \"mobilenet_v2_140_224\": 224,\n  \"nasnet_large\": 331,\n  \"nasnet_mobile\": 224,\n  \"pnasnet_large\": 331,\n  \"resnet_v1_50\": 224,\n  \"resnet_v1_101\": 224,\n  \"resnet_v1_152\": 224,\n  \"resnet_v2_50\": 224,\n  \"resnet_v2_101\": 224,\n  \"resnet_v2_152\": 224,\n  \"mobilenet_v3_small_100_224\": 224,\n  \"mobilenet_v3_small_075_224\": 224,\n  \"mobilenet_v3_large_100_224\": 224,\n  \"mobilenet_v3_large_075_224\": 224,\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Model Save Specification\nDESCRIPTION: This snippet demonstrates how to check if a model has any traced concrete functions by examining its save_spec. This is useful for verifying if a model is ready to be saved.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(my_model.save_spec() is None)\n```\n\n----------------------------------------\n\nTITLE: Training Neural Network with Batch Processing\nDESCRIPTION: Implements the training loop with batch processing, including helper functions for batch generation and label encoding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nNUM_TRAIN_STEPS = 100\nTRAIN_BATCH_SIZE = 10\nEVAL_EVERY = 10\n\ndef get_batch(batch_size=None, test=False):\n  \"\"\"Get a random batch of examples.\"\"\"\n  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n  return batch_examples\n\ndef get_images_and_labels(batch_examples):\n  images = [get_encoded_image(e) for e in batch_examples]\n  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n  return images, one_hot_labels\n\ndef get_label_one_hot(example):\n  \"\"\"Get the one hot encoding vector for the example.\"\"\"\n  one_hot_vector = np.zeros(NUM_CLASSES)\n  np.put(one_hot_vector, get_label(example), 1)\n  return one_hot_vector\n\nwith tf.Session() as sess:\n  sess.run(tf.global_variables_initializer())\n  for i in range(NUM_TRAIN_STEPS):\n    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n    batch_images, batch_labels = get_images_and_labels(train_batch)\n    train_loss, _, train_accuracy = sess.run(\n        [cross_entropy_mean, train_op, accuracy],\n        feed_dict={encoded_images: batch_images, labels: batch_labels})\n    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n    if i % EVAL_EVERY == 0 or is_final_step:\n      test_batch = get_batch(batch_size=None, test=True)\n      batch_images, batch_labels = get_images_and_labels(test_batch)\n      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n        feed_dict={encoded_images: batch_images, labels: batch_labels})\n      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))\n```\n\n----------------------------------------\n\nTITLE: Setting Model Constants\nDESCRIPTION: Definition of key model parameters including audio length and batch size\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nAUDIO_MAXLEN = 246000\nLABEL_MAXLEN = 256\nBATCH_SIZE = 2\n```\n\n----------------------------------------\n\nTITLE: Image Classification Output Example\nDESCRIPTION: Sample output from the classification script showing predicted classes and their confidence scores for a panda image. The model provides top-5 predictions with corresponding confidence scores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ngiant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.88493)\nindri, indris, Indri indri, Indri brevicaudatus (score = 0.00878)\nlesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00317)\ncustard apple (score = 0.00149)\nearthstar (score = 0.00127)\n```\n\n----------------------------------------\n\nTITLE: Building ANNOY Index for Embeddings in Python\nDESCRIPTION: Defines a function to build an ANNOY (Approximate Nearest Neighbors Oh Yeah) index from embedding files. It loads embeddings, adds them to the index, and saves both the index and a mapping file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef build_index(embedding_files_pattern, index_filename, vector_length, \n    metric='angular', num_trees=100):\n  '''Builds an ANNOY index'''\n\n  annoy_index = annoy.AnnoyIndex(vector_length, metric=metric)\n  # Mapping between the item and its identifier in the index\n  mapping = {}\n\n  embed_files = tf.io.gfile.glob(embedding_files_pattern)\n  num_files = len(embed_files)\n  print('Found {} embedding file(s).'.format(num_files))\n\n  item_counter = 0\n  for i, embed_file in enumerate(embed_files):\n    print('Loading embeddings in file {} of {}...'.format(i+1, num_files))\n    dataset = tf.data.TFRecordDataset(embed_file)\n    for record in dataset.map(_parse_example):\n      text = record['text'].numpy().decode(\"utf-8\")\n      embedding = record['embedding'].numpy()\n      mapping[item_counter] = text\n      annoy_index.add_item(item_counter, embedding)\n      item_counter += 1\n      if item_counter % 100000 == 0:\n        print('{} items loaded to the index'.format(item_counter))\n\n  print('A total of {} items added to the index'.format(item_counter))\n\n  print('Building the index with {} trees...'.format(num_trees))\n  annoy_index.build(n_trees=num_trees)\n  print('Index is successfully built.')\n  \n  print('Saving index to disk...')\n  annoy_index.save(index_filename)\n  print('Index is saved to disk.')\n  print(\"Index file size: {} GB\".format(\n    round(os.path.getsize(index_filename) / float(1024 ** 3), 2)))\n  annoy_index.unload()\n\n  print('Saving mapping to disk...')\n  with open(index_filename + '.mapping', 'wb') as handle:\n    pickle.dump(mapping, handle, protocol=pickle.HIGHEST_PROTOCOL)\n  print('Mapping is saved to disk.')\n  print(\"Mapping file size: {} MB\".format(\n    round(os.path.getsize(index_filename + '.mapping') / float(1024 ** 2), 2)))\n```\n\n----------------------------------------\n\nTITLE: Displaying Sheet Music with Open Sheet Music Display in Python\nDESCRIPTION: This helper function uses Open Sheet Music Display (a JavaScript library) to render the sheet music score in the notebook. It converts the music21 score to MusicXML and displays it using JavaScript.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.core.display import display, HTML, Javascript\nimport json, random\n\ndef showScore(score):\n    xml = open(score.write('musicxml')).read()\n    showMusicXML(xml)\n    \ndef showMusicXML(xml):\n    DIV_ID = \"OSMD_div\"\n    display(HTML('<div id=\"'+DIV_ID+'\">loading OpenSheetMusicDisplay</div>'))\n    script = \"\"\"\n    var div_id = %%DIV_ID%%;\n    function loadOSMD() { \n        return new Promise(function(resolve, reject){\n            if (window.opensheetmusicdisplay) {\n                return resolve(window.opensheetmusicdisplay)\n            }\n            // OSMD script has a 'define' call which conflicts with requirejs\n            var _define = window.define // save the define object \n            window.define = undefined // now the loaded script will ignore requirejs\n            var s = document.createElement( 'script' );\n            s.setAttribute( 'src', \"https://cdn.jsdelivr.net/npm/opensheetmusicdisplay@0.7.6/build/opensheetmusicdisplay.min.js\" );\n            //s.setAttribute( 'src', \"/custom/opensheetmusicdisplay.js\" );\n            s.onload=function(){\n                window.define = _define\n                resolve(opensheetmusicdisplay);\n            };\n            document.body.appendChild( s ); // browser will try to load the new script tag\n        }) \n    }\n    loadOSMD().then((OSMD)=>{\n        window.openSheetMusicDisplay = new OSMD.OpenSheetMusicDisplay(div_id, {\n          drawingParameters: \"compacttight\"\n        });\n        openSheetMusicDisplay\n            .load(%%data%%)\n            .then(\n              function() {\n                openSheetMusicDisplay.render();\n              }\n            );\n    })\n    \"\"\".replace('%%DIV_ID%%',DIV_ID).replace('%%data%%',json.dumps(xml))\n    display(Javascript(script))\n    return\n```\n\n----------------------------------------\n\nTITLE: Using Overloaded Operators with Ragged Tensors\nDESCRIPTION: Shows how Python arithmetic operators can be used with ragged tensors for elementwise operations, both with scalars and other ragged tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(digits + 3)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(digits + tf.ragged.constant([[1, 2, 3, 4], [], [5, 6, 7], [8], []]))\n```\n\n----------------------------------------\n\nTITLE: Creating Linear and DNN Models for Wide & Deep Learning in TensorFlow 2\nDESCRIPTION: This snippet demonstrates how to create and compile individual Linear and DNN components that will later be combined in a Wide & Deep model. It creates a LinearModel and a Sequential DNN model, both compiled with MSE loss and the same optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create LinearModel and DNN Model as in Examples 1 and 2\noptimizer = create_sample_optimizer('tf2')\n\nlinear_model = tf.compat.v1.keras.experimental.LinearModel()\nlinear_model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\nlinear_model.fit(x_train, y_train, epochs=10, verbose=0)\n\ndnn_model = tf.keras.models.Sequential(\n    [tf.keras.layers.Dense(128, activation='relu'),\n     tf.keras.layers.Dense(1)])\ndnn_model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Processing Full Video with MoViNet Streaming Model\nDESCRIPTION: Processes the entire video frame by frame using the MoViNet streaming model. It updates the model's state with each frame and collects the logits for all frames.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n%%time\nstate = initial_state.copy()\nall_logits = []\n\nfor n in range(len(jumpingjack)):\n  inputs = state\n  inputs['image'] = jumpingjack[tf.newaxis, n:n+1, ...]\n  result, state = model(inputs)\n  all_logits.append(logits)\n\nprobabilities = tf.nn.softmax(all_logits, axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Verifying Variable Names and Paths in TensorFlow 2 Model\nDESCRIPTION: This snippet demonstrates how to verify that the variables in the updated model match the expected names and paths from the original TensorFlow 1.x checkpoint. It ensures that both variable name and object-oriented paths are correctly maintained.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nweights = {v.name: v for v in layer.weights}\nassert weights['model/conv2d/kernel:0'] is layer.conv_1.kernel\nassert weights['model/conv2d_1/bias:0'] is layer.conv_2.bias\n```\n\n----------------------------------------\n\nTITLE: Defining Helper Functions for UCF101 Dataset\nDESCRIPTION: This code block defines utility functions for fetching and processing videos from the UCF101 dataset, including video listing, downloading, and preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nUCF_ROOT = \"https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/\"\n_VIDEO_LIST = None\n_CACHE_DIR = tempfile.mkdtemp()\nunverified_context = ssl._create_unverified_context()\n\ndef list_ucf_videos():\n  global _VIDEO_LIST\n  if not _VIDEO_LIST:\n    index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n    videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n    _VIDEO_LIST = sorted(set(videos))\n  return list(_VIDEO_LIST)\n\ndef fetch_ucf_video(video):\n  cache_path = os.path.join(_CACHE_DIR, video)\n  if not os.path.exists(cache_path):\n    urlpath = request.urljoin(UCF_ROOT, video)\n    print(\"Fetching %s => %s\" % (urlpath, cache_path))\n    data = request.urlopen(urlpath, context=unverified_context).read()\n    open(cache_path, \"wb\").write(data)\n  return cache_path\n\ndef crop_center_square(frame):\n  y, x = frame.shape[0:2]\n  min_dim = min(y, x)\n  start_x = (x // 2) - (min_dim // 2)\n  start_y = (y // 2) - (min_dim // 2)\n  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n\ndef load_video(path, max_frames=0, resize=(224, 224)):\n  cap = cv2.VideoCapture(path)\n  frames = []\n  try:\n    while True:\n      ret, frame = cap.read()\n      if not ret:\n        break\n      frame = crop_center_square(frame)\n      frame = cv2.resize(frame, resize)\n      frame = frame[:, :, [2, 1, 0]]\n      frames.append(frame)\n      \n      if len(frames) == max_frames:\n        break\n  finally:\n    cap.release()\n  return np.array(frames) / 255.0\n\ndef to_gif(images):\n  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n  imageio.mimsave('./animation.gif', converted_images, duration=40)\n  return embed.embed_file('./animation.gif')\n```\n\n----------------------------------------\n\nTITLE: Interpolating BigGAN Samples with Python\nDESCRIPTION: Implements interpolation between two BigGAN-generated samples using configurable parameters like number of samples, interpolation steps, truncation value, noise seeds, and categories. The code generates a grid of interpolated images between two specified categories (e.g., golden retriever and hen) using latent space interpolation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n#@title Interpolation { display-mode: \"form\", run: \"auto\" }\n\nnum_samples = 2 #@param {type:\"slider\", min:1, max:5, step:1}\nnum_interps = 5 #@param {type:\"slider\", min:2, max:10, step:1}\ntruncation = 0.2 #@param {type:\"slider\", min:0.02, max:1, step:0.02}\nnoise_seed_A = 0 #@param {type:\"slider\", min:0, max:100, step:1}\ncategory_A = \"207) golden retriever\"\nnoise_seed_B = 0 #@param {type:\"slider\", min:0, max:100, step:1}\ncategory_B = \"8) hen\"\n\ndef interpolate_and_shape(A, B, num_interps):\n  interps = interpolate(A, B, num_interps)\n  return (interps.transpose(1, 0, *range(2, len(interps.shape)))\n                 .reshape(num_samples * num_interps, *interps.shape[2:]))\n\nz_A, z_B = [truncated_z_sample(num_samples, truncation, noise_seed)\n            for noise_seed in [noise_seed_A, noise_seed_B]]\ny_A, y_B = [one_hot([int(category.split(')')[0])] * num_samples)\n            for category in [category_A, category_B]]\n\nz_interp = interpolate_and_shape(z_A, z_B, num_interps)\ny_interp = interpolate_and_shape(y_A, y_B, num_interps)\n\nims = sample(sess, z_interp, y_interp, truncation=truncation)\nimshow(imgrid(ims, cols=num_interps))\n```\n\n----------------------------------------\n\nTITLE: Incorrect Tensor Printing in TensorFlow\nDESCRIPTION: This snippet illustrates an incorrect way of printing a tensor. It shows that simply using print() on a tensor object will print the symbolic tensor rather than its value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nt = <<some tensorflow operation>>\nprint(t)  # This will print the symbolic tensor when the graph is being built.\n          # This tensor does not have a value in this context.\n```\n\n----------------------------------------\n\nTITLE: Importing Object Detection Dependencies\nDESCRIPTION: This snippet imports the necessary dependencies from the Object Detection API for later use in the script.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.utils import ops as utils_ops\n\n%matplotlib inline\n```\n\n----------------------------------------\n\nTITLE: Displaying Incorrect Predictions\nDESCRIPTION: Identifies and displays examples where the model made incorrect predictions for analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nincorrect = [\n    (example, CLASSES[prediction])\n    for example, prediction, is_correct in zip(test_batch, test_prediction, correct_predicate)\n    if not is_correct\n]\ndisplay_images(\n  [(get_image(example), \"prediction: {0}\\nlabel:{1}\".format(incorrect_prediction, get_class(example)))\n   for (example, incorrect_prediction) in incorrect[:20]])\n```\n\n----------------------------------------\n\nTITLE: Defining a Pretty-Print Function for Sparse Tensors\nDESCRIPTION: This function creates a formatted string representation of a sparse tensor, displaying each non-zero value with its corresponding index. It helps in visualizing the content of sparse tensors more clearly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef pprint_sparse_tensor(st):\n  s = \"<SparseTensor shape=%s \\n values={\" % (st.dense_shape.numpy().tolist(),)\n  for (index, value) in zip(st.indices, st.values):\n    s += f\"\\n  %s: %s\" % (index.numpy().tolist(), value.numpy().tolist())\n  return s + \"}>\"\n```\n\n----------------------------------------\n\nTITLE: Training a Model on TPU Using Keras High-Level APIs\nDESCRIPTION: Demonstrates how to train a model using Keras Model.fit and Model.compile APIs within a TPU strategy scope. The example configures a model with Adam optimizer and sparse categorical crossentropy loss function, then trains it for 5 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = create_model()\n  model.compile(optimizer='adam',\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['sparse_categorical_accuracy'])\n\nbatch_size = 200\nsteps_per_epoch = 60000 // batch_size\nvalidation_steps = 10000 // batch_size\n\ntrain_dataset = get_dataset(batch_size, is_training=True)\ntest_dataset = get_dataset(batch_size, is_training=False)\n\nmodel.fit(train_dataset,\n          epochs=5,\n          steps_per_epoch=steps_per_epoch,\n          validation_data=test_dataset,\n          validation_steps=validation_steps)\n```\n\n----------------------------------------\n\nTITLE: Profiling with TensorBoard Keras Callback in Python\nDESCRIPTION: Use the TensorBoard Keras Callback to profile batches 10 to 15 during model training. This method allows for collecting performance profiling data while training the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Profile from batches 10 to 15\ntb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n                                             profile_batch='10, 15')\n\n# Train the model and use the TensorBoard Keras callback to collect\n# performance profiling data\nmodel.fit(train_data,\n          steps_per_epoch=20,\n          epochs=5,\n          callbacks=[tb_callback])\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Default Integer Attribute (C++)\nDESCRIPTION: This code shows how to specify a default value for an `int` attribute. The `Attr` method defines the `i` attribute with a default value of 0, making it optional for users when adding the op to a graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_18\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"AttrDefaultExample\")\n    .Attr(\"i: int = 0\");\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset in TensorFlow\nDESCRIPTION: Loads the MNIST dataset using TensorFlow's built-in datasets API and preprocesses it by limiting to 1000 examples, reshaping the images, and normalizing pixel values to be between 0 and 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\ntrain_labels = train_labels[:1000]\ntest_labels = test_labels[:1000]\n\ntrain_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\ntest_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n```\n\n----------------------------------------\n\nTITLE: Examining audio data shapes in the training dataset\nDESCRIPTION: This code extracts and prints the shapes of audio samples and their corresponding labels from the first batch of the training dataset to understand the data structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfor example_audio, example_labels in train_ds.take(1):  \n  print(example_audio.shape)\n  print(example_labels.shape)\n```\n\n----------------------------------------\n\nTITLE: Downloading Image Data for TensorFlow\nDESCRIPTION: This snippet downloads a dataset of flower images to be used in subsequent examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nflowers = tf.keras.utils.get_file(\n    'flower_photos',\n    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n    untar=True)\n```\n\n----------------------------------------\n\nTITLE: Exporting Word Embeddings\nDESCRIPTION: Converting fastText embeddings to TF-Hub module format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython export_v2.py --embedding_file=cc.bn.300.vec --export_path=text_module --num_lines_to_ignore=1 --num_lines_to_use=100000\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Semantic Search\nDESCRIPTION: Installs the Apache Beam, scikit-learn, and Annoy libraries required for processing embeddings and building the approximate nearest neighbors index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q apache_beam\n!pip install -q 'scikit_learn~=0.23.0'  # For gaussian_random_matrix.\n!pip install -q annoy\n```\n\n----------------------------------------\n\nTITLE: Tensor Concatenation\nDESCRIPTION: Demonstrates concatenating multiple copies of the same tensor along axis 0 using tf.concat.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntf.concat([x, x, x], axis=0)\n```\n\n----------------------------------------\n\nTITLE: Implementing Note Prediction Function in TensorFlow\nDESCRIPTION: Creates a function to generate the next musical note based on a sequence of previous notes, using the trained model and temperature-controlled sampling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef predict_next_note(\n    notes: np.ndarray, \n    model: tf.keras.Model, \n    temperature: float = 1.0) -> tuple[int, float, float]:\n  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n\n  assert temperature > 0\n\n  # Add batch dimension\n  inputs = tf.expand_dims(notes, 0)\n\n  predictions = model.predict(inputs)\n  pitch_logits = predictions['pitch']\n  step = predictions['step']\n  duration = predictions['duration']\n \n  pitch_logits /= temperature\n  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n  pitch = tf.squeeze(pitch, axis=-1)\n  duration = tf.squeeze(duration, axis=-1)\n  step = tf.squeeze(step, axis=-1)\n\n  # `step` and `duration` values should be non-negative\n  step = tf.maximum(0, step)\n  duration = tf.maximum(0, duration)\n\n  return int(pitch), float(step), float(duration)\n```\n\n----------------------------------------\n\nTITLE: Defining a Test Function for Debug Stripper Optimization\nDESCRIPTION: This function creates and returns a TensorFlow function that uses debugging operations. It's used to demonstrate the effect of debug stripper optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef test_function_2():\n  @tf.function\n  def simple_func(input_arg):\n    output = input_arg\n    tf.debugging.check_numerics(output, \"Bad!\")\n    return output\n  return simple_func\n```\n\n----------------------------------------\n\nTITLE: Displaying Flower Images with Labels for Visualization\nDESCRIPTION: Functions to display a grid of flower images with their class labels, helping to visualize the dataset before training. The code extracts images and their labels from the training examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n#@title Show some labeled images\ndef get_label(example):\n  \"\"\"Get the label (number) for given example.\"\"\"\n  return example[1]\n\ndef get_class(example):\n  \"\"\"Get the class (string) of given example.\"\"\"\n  return CLASSES[get_label(example)]\n\ndef get_encoded_image(example):\n  \"\"\"Get the image data (encoded jpg) of given example.\"\"\"\n  image_path = example[0]\n  return tf.gfile.GFile(image_path, 'rb').read()\n\ndef get_image(example):\n  \"\"\"Get image as np.array of pixels for given example.\"\"\"\n  return plt.imread(io.BytesIO(get_encoded_image(example)), format='jpg')\n\ndef display_images(images_and_classes, cols=5):\n  \"\"\"Display given images and their labels in a grid.\"\"\"\n  rows = int(math.ceil(len(images_and_classes) / cols))\n  fig = plt.figure()\n  fig.set_size_inches(cols * 3, rows * 3)\n  for i, (image, flower_class) in enumerate(images_and_classes):\n    plt.subplot(rows, cols, i + 1)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(flower_class)\n\nNUM_IMAGES = 15 #@param {type: 'integer'}\ndisplay_images([(get_image(example), get_class(example))\n               for example in TRAIN_EXAMPLES[:NUM_IMAGES]])\n```\n\n----------------------------------------\n\nTITLE: Reloading the Dataset for Augmentation Pipeline Example\nDESCRIPTION: Reloads the TensorFlow Flowers dataset to ensure a clean starting point for the dataset augmentation pipeline example. This ensures the images haven't been modified by previous operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n(train_datasets, val_ds, test_ds), metadata = tfds.load(\n    'tf_flowers',\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n    with_info=True,\n    as_supervised=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Exploring Rate-Distortion Trade-off in MNIST Compression\nDESCRIPTION: This code demonstrates how changing the lambda parameter affects the compression rate and distortion of MNIST digits. It defines a function to train the model and visualize results for different lambda values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef train_and_visualize_model(lmbda):\n  trainer = train_mnist_model(lmbda=lmbda)\n  compressor, decompressor = make_mnist_codec(trainer)\n  strings, entropies = compressor(originals)\n  reconstructions = decompressor(strings)\n  display_digits(originals, strings, entropies, reconstructions)\n\ntrain_and_visualize_model(lmbda=500)\n\ntrain_and_visualize_model(lmbda=300)\n```\n\n----------------------------------------\n\nTITLE: Additional Matrix Multiplication Sharding Optimization\nDESCRIPTION: Demonstrates further optimization by applying additional sharding along the first axis, reducing floating point operations by distributing computation across more devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 3), (\"y\", 2)], devices=DEVICES)\n\na_layout = dtensor.Layout(['y', 'x'], mesh)\na = dtensor_from_array([[1, 2, 3], [4, 5, 6]], layout=a_layout)\nb_layout = dtensor.Layout(['x', dtensor.UNSHARDED], mesh)\nb = dtensor_from_array([[6, 5], [4, 3], [2, 1]], layout=b_layout)\n\nc = tf.matmul(a, b)\n# The sharding of `a` on the first axis is carried to `c'\nprint('Sharding spec:', dtensor.fetch_layout(c).sharding_specs)\nprint(\"components:\")\nfor component_tensor in dtensor.unpack(c):\n  print(component_tensor.device, component_tensor.numpy())\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom TensorFlow Estimator with Configuration Parameters\nDESCRIPTION: Code that instantiates a custom TensorFlow Estimator with specific parameters for feature columns, hidden layer sizes, and number of output classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf.estimator.Estimator(\n    model_fn=my_model_fn,\n    params={\n        'feature_columns': my_feature_columns,\n        # Two hidden layers of 10 nodes each.\n        'hidden_units': [10, 10],\n        # The model must choose between 3 classes.\n        'n_classes': 3,\n    })\n```\n\n----------------------------------------\n\nTITLE: Viewing Dropout Upgrade Report in Bash\nDESCRIPTION: This command displays the contents of the dropout upgrade report.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncat dropout_report.txt\n```\n\n----------------------------------------\n\nTITLE: Creating Integer WeakTensors\nDESCRIPTION: Example showing how WeakTensors are created when using tf.constant without specifying a dtype for integer values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=5, weak=True>\n```\n\n----------------------------------------\n\nTITLE: Handling Invalid GPU Device Specification in TensorFlow\nDESCRIPTION: This snippet demonstrates how to handle the case when an invalid GPU device is specified, showing the resulting RuntimeError.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\n\ntry:\n  # Specify an invalid GPU device\n  with tf.device('/device:GPU:2'):\n    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n    c = tf.matmul(a, b)\nexcept RuntimeError as e:\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset\nDESCRIPTION: Loading the MNIST dataset using Keras API and normalizing the pixel values by dividing by 255.0 to prepare the data for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: Training the Model\nDESCRIPTION: Code to train the classifier using the input function and specified number of steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Train the Model.\nclassifier.train(\n    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n    steps=args.train_steps)\n```\n\n----------------------------------------\n\nTITLE: Plotting Model Training Learning Curves\nDESCRIPTION: Visualizes training and validation accuracy and loss curves using matplotlib to analyze model performance during training\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(8, 8))\nplot.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Docs Package for Python API Reference Generation\nDESCRIPTION: This snippet shows how to install the tensorflow_docs package, which includes the generator for the Python API reference docs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/tensorflow/docs\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Generated Data\nDESCRIPTION: Plots the generated data points to visualize the linear relationship with added noise.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Plot all the data\nplt.plot(x, y, '.')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Displaying Missing Module Error for 'copyreg' (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when the 'copyreg' module cannot be imported, which is typically a Python 2 vs Python 3 compatibility issue.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>ImportError: No module named copyreg</pre>\n```\n\n----------------------------------------\n\nTITLE: MaskedTensor Constructor Example\nDESCRIPTION: Demonstrates usage of automatically generated constructor for MaskedTensor extension type\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n# Constructor takes one parameter for each field.\nmt = MaskedTensor(values=[[1, 2, 3], [4, 5, 6]],\n                  mask=[[True, True, False], [True, False, True]])\n\n# Fields are type-checked and converted to the declared types.\n```\n\n----------------------------------------\n\nTITLE: Using Standalone Keras Metrics in Eager Mode\nDESCRIPTION: Demonstrating direct usage of Keras metrics objects in eager execution mode, showing how to update state with new data and retrieve results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\naccuracy = tf.keras.metrics.Accuracy()\n\naccuracy.update_state(y_true=[0, 0, 1, 1], y_pred=[0, 0, 0, 1])\naccuracy.result().numpy()\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with GradientTape\nDESCRIPTION: Demonstrates using TensorFlow's automatic differentiation to calculate the derivative of a function with respect to its input using GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n  y = f(x)\n\ng_x = tape.gradient(y, x)  # g(x) = dy/dx\n\ng_x\n```\n\n----------------------------------------\n\nTITLE: Running MoveNet Inference on Image\nDESCRIPTION: Processes an input image through the MoveNet model to detect human pose keypoints. Includes resizing, inference, and visualization of the predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Resize and pad the image to keep the aspect ratio and fit the expected size.\ninput_image = tf.expand_dims(image, axis=0)\ninput_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n\n# Run model inference.\nkeypoints_with_scores = movenet(input_image)\n\n# Visualize the predictions with image.\ndisplay_image = tf.expand_dims(image, axis=0)\ndisplay_image = tf.cast(tf.image.resize_with_pad(\n    display_image, 1280, 1280), dtype=tf.int32)\noutput_overlay = draw_prediction_on_image(\n    np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores)\n\nplt.figure(figsize=(5, 5))\nplt.imshow(output_overlay)\n_ = plt.axis('off')\n```\n\n----------------------------------------\n\nTITLE: Creating Model and Optimizer with MirroredStrategy in Python\nDESCRIPTION: This snippet demonstrates creating a Keras model and optimizer within the scope of a MirroredStrategy. This ensures that the model and optimizer variables are created as mirrored variables for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nwith mirrored_strategy.scope():\n  model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n  optimizer = tf.train.GradientDescentOptimizer(0.1)\n```\n\n----------------------------------------\n\nTITLE: Loading and Using Image Feature Vector SavedModel in Python\nDESCRIPTION: Example showing how to load a TensorFlow Hub image feature vector model and extract features from a batch of images. This demonstrates the basic usage pattern for feature extraction models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/images.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nobj = hub.load(\"path/to/model\")  # That's tf.saved_model.load() after download.\nimages = ...  # A batch of images with shape [batch_size, height, width, 3].\nfeatures = obj(images)   # A batch with shape [batch_size, num_features].\n```\n\n----------------------------------------\n\nTITLE: Computing Text Embeddings\nDESCRIPTION: Demonstrates embedding computation for different text lengths including a word, sentence, and paragraph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Compute a representation for each message, showing various lengths supported.\nword = \"Elephant\"\nsentence = \"I am a sentence for which I would like to get its embedding.\"\nparagraph = (\n    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n    \"the more 'diluted' the embedding will be.\")\nmessages = [word, sentence, paragraph]\n\n# Reduce logging output.\nlogging.set_verbosity(logging.ERROR)\n\nmessage_embeddings = embed(messages)\n\nfor i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n  print(\"Message: {}\".format(messages[i]))\n  print(\"Embedding size: {}\".format(len(message_embedding)))\n  message_embedding_snippet = \", \".join(\n      (str(x) for x in message_embedding[:3]))\n  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n```\n\n----------------------------------------\n\nTITLE: Loading Checkpoint with init_from_checkpoint\nDESCRIPTION: Shows how to use tf.compat.v1.train.init_from_checkpoint to load variables with scope remapping in a graph session context.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  with tf1.variable_scope('new_scope'):\n    a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n    b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n    c = tf1.get_variable('scoped/c', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n  with tf1.Session() as sess:\n    tf1.train.init_from_checkpoint(\n        'tf1-ckpt',\n        assignment_map={'/': 'new_scope/'})\n    sess.run(tf1.global_variables_initializer())\n\n    print(\"Restored [a, b, c]: \", sess.run([a, b, c]))\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Neural Network Model in TensorFlow\nDESCRIPTION: Defines a function that creates a sequential neural network model for MNIST classification with two dense layers and dropout. The model is compiled with Adam optimizer and sparse categorical crossentropy loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define a simple sequential model\ndef create_model():\n  model = tf.keras.Sequential([\n    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10)\n  ])\n\n  model.compile(optimizer='adam',\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\n  return model\n\n# Create a basic model instance\nmodel = create_model()\n\n# Display the model's architecture\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op with List Type Restrictions\nDESCRIPTION: Demonstrates registering an op that accepts lists of tensors with type restrictions, where each tensor in the list must be one of the specified types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_31\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ListTypeRestrictionExample\")\n    .Attr(\"T: list({float, double})\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Defining Optimizer and Accuracy Metric for Multi-Worker Training\nDESCRIPTION: This code defines an optimizer (RMSprop) and an accuracy metric (SparseCategoricalAccuracy) within the strategy scope. These are essential components for the custom training loop in multi-worker scenarios.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  # The creation of optimizer and train_accuracy needs to be in\n  # `strategy.scope()` as well, since they create variables.\n  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='train_accuracy')\n```\n\n----------------------------------------\n\nTITLE: Adding TensorFlow Dependency to Maven POM\nDESCRIPTION: This XML snippet shows how to add the TensorFlow dependency to a Maven project's pom.xml file. It specifies the groupId, artifactId, and version for the TensorFlow library.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_java_legacy.md#2025-04-21_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.tensorflow</groupId>\n  <artifactId>tensorflow</artifactId>\n  <version>2.4.0</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Handling dtype Validation Error in MaskedTensor in Python\nDESCRIPTION: Shows how the __validate__ method catches errors when creating a MaskedTensor with an incorrect mask dtype.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  MaskedTensor([1, 2, 3], [0, 1, 0])  # Wrong `dtype` for mask.\nexcept AssertionError as e:\n  print(f\"Got expected AssertionError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Training Dataset\nDESCRIPTION: Setting up TensorFlow dataset pipeline for training data preparation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# The maximum length sentence you want for a single input in characters\nseq_length = 100\nexamples_per_epoch = len(text)//seq_length\n\n# Create training examples / targets\nchar_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for TensorFlow Hub Image Classification\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, TensorFlow Hub, requests, PIL, matplotlib, and numpy for image classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Decision Forests in TensorFlow 2\nDESCRIPTION: This snippet shows how to install the TensorFlow Decision Forests package, which is used as the replacement for BoostedTreesEstimator in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n!pip install tensorflow_decision_forests\n```\n\n----------------------------------------\n\nTITLE: Initializing LocalCLIDebugHook in TensorFlow\nDESCRIPTION: This snippet demonstrates how to initialize the LocalCLIDebugHook to debug TensorFlow models using the command-line interface. It sets the dump_root parameter to a directory where tfdbg will store the debugging data. The directory should be empty or nonexistent.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n\"hooks = [tf_debug.LocalCLIDebugHook(dump_root=\\\"/with/lots/of/space\\\")]\"\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Audio Processing\nDESCRIPTION: Imports essential libraries for audio processing including TensorFlow, TensorFlow Hub for model loading, and visualization libraries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom IPython import display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_io as tfio\n```\n\n----------------------------------------\n\nTITLE: Loading and Checking a Model with a Signature\nDESCRIPTION: Loads a SavedModel that has a signature and verifies the signature key is available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nimported_with_signatures = tf.saved_model.load(module_with_signature_path)\nlist(imported_with_signatures.signatures.keys())  # [\"serving_default\"]\n```\n\n----------------------------------------\n\nTITLE: Viewing Element Specifications in TensorFlow Dataset\nDESCRIPTION: Demonstrates how to check the structure, data types, and shapes of dataset elements using the element_spec property on a TensorFlow Dataset object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Each element is an (inputs, label) pair.\nw2.train.element_spec\n```\n\n----------------------------------------\n\nTITLE: Plotting Batch Sizes in TensorFlow Datasets\nDESCRIPTION: Defines a function to plot the sizes of batches in a dataset, which helps visualize the distribution of batch sizes across epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_64\n\nLANGUAGE: python\nCODE:\n```\ndef plot_batch_sizes(ds):\n  batch_sizes = [batch.shape[0] for batch in ds]\n  plt.bar(range(len(batch_sizes)), batch_sizes)\n  plt.xlabel('Batch number')\n  plt.ylabel('Batch size')\n```\n\n----------------------------------------\n\nTITLE: Importing Required Dependencies\nDESCRIPTION: Installation and import of necessary Python libraries including TensorFlow, TensorFlow Hub, TensorFlow IO, and librosa for audio processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q \"tensorflow_io==0.28.*\"\n!pip install -q librosa\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_io as tfio\nimport numpy as np\nimport librosa\nimport csv\nimport io\nfrom IPython.display import Audio\n```\n\n----------------------------------------\n\nTITLE: Training and evaluating with built-in Keras methods in TensorFlow 2\nDESCRIPTION: Shows how to train and evaluate a model using the built-in Keras methods Model.fit and Model.evaluate in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nmodel.fit(dataset)\n\nmodel.evaluate(eval_dataset, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Latent Space Interpolation for Face Generation\nDESCRIPTION: This function performs latent space interpolation between two random vectors and generates a sequence of face images using the loaded GAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndef interpolate_between_vectors():\n  v1 = tf.random.normal([latent_dim])\n  v2 = tf.random.normal([latent_dim])\n    \n  # Creates a tensor with 25 steps of interpolation between v1 and v2.\n  vectors = interpolate_hypersphere(v1, v2, 50)\n\n  # Uses module to generate images from the latent space.\n  interpolated_images = progan(vectors)['default']\n\n  return interpolated_images\n\ninterpolated_images = interpolate_between_vectors()\nanimate(interpolated_images)\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Model\nDESCRIPTION: Creating a sequential model with embedding layer and dense layers for classification\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nmodel = keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(keras.layers.Dense(16, activation='relu'))\nmodel.add(keras.layers.Dense(1))\n\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Combining Linear and DNN Models with WideDeepModel in TensorFlow 2\nDESCRIPTION: This snippet shows how to create a combined Wide & Deep model using the TensorFlow 2 Keras API. It uses the previously defined linear and DNN models, compiles them with a specified optimizer, and demonstrates training and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncombined_model = tf.compat.v1.keras.experimental.WideDeepModel(linear_model,\n                                                               dnn_model)\ncombined_model.compile(\n    optimizer=[optimizer, optimizer], loss='mse', metrics=['accuracy'])\ncombined_model.fit([x_train, x_train], y_train, epochs=10)\ncombined_model.evaluate(x_eval, y_eval, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Building a SavedModel Manually with tf.saved_model.builder in Python\nDESCRIPTION: This snippet details manually building a SavedModel using the tf.saved_model.builder API. Allows saving multiple MetaGraphDefs with variable and asset management for custom serialization scenarios.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nexport_dir = ...\n...\nbuilder = tf.saved_model.builder.SavedModelBuilder(export_dir)\nwith tf.Session(graph=tf.Graph()) as sess:\n  ...\n  builder.add_meta_graph_and_variables(sess,\n                                       [tag_constants.TRAINING],\n                                       signature_def_map=foo_signatures,\n                                       assets_collection=foo_assets,\n                                       strip_default_attrs=True)\n...\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Repacking for DTensor in Python\nDESCRIPTION: Defines a function to repack training data batches into DTensors sharded along the 'batch' axis, distributing the data evenly across the 'batch' mesh dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef repack_batch(x, y, mesh):\n  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n  return x, y\n\nsample_x, sample_y = train_data_vec.take(1).get_single_element()\nsample_x, sample_y = repack_batch(sample_x, sample_y, mesh)\n\nprint('x', sample_x[:, 0])\nprint('y', sample_y)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and TensorBoard\nDESCRIPTION: Imports necessary libraries including TensorFlow 1.x compatibility, TensorFlow 2.x, and loads the TensorBoard extension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf1\nimport tensorflow as tf\nimport tempfile\nimport numpy as np\nimport datetime\n%load_ext tensorboard\n```\n\n----------------------------------------\n\nTITLE: Verifying TensorFlow CPU Installation\nDESCRIPTION: Python command to verify successful TensorFlow CPU installation by generating and reducing a random tensor\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\npython3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow 1 Estimator for MNIST Classification\nDESCRIPTION: Defines a DNN classifier using tf.estimator API with feature columns for MNIST data, specifying hidden layers, optimizer, and number of classes for the classification task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfeature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\n\nclassifier = tf1.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf1.train.AdamOptimizer(0.001),\n    n_classes=10,\n    dropout=0.2\n)\n\ntrain_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_train},\n    y=y_train.astype(np.int32),\n    num_epochs=10,\n    batch_size=50,\n    shuffle=True,\n)\n\ntest_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_test},\n    y=y_test.astype(np.int32),\n    num_epochs=10,\n    shuffle=False\n)\n\ntrain_spec = tf1.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10)\neval_spec = tf1.estimator.EvalSpec(input_fn=test_input_fn,\n                                   steps=10,\n                                   throttle_secs=0)\n```\n\n----------------------------------------\n\nTITLE: Creating NumPy Array from Parsed Notes in Python\nDESCRIPTION: Stacks pitch, step, and duration values from the parsed notes into a NumPy array to prepare for creating a TensorFlow dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nkey_order = ['pitch', 'step', 'duration']\ntrain_notes = np.stack([all_notes[key] for key in key_order], axis=1)\n```\n\n----------------------------------------\n\nTITLE: Using a TensorFlow Custom Operation\nDESCRIPTION: Example demonstrating how to call a custom TensorFlow operation with appropriate parameters and naming.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\noutput = my_op(t1, t2, my_param=0.5, other_param=0.6,\n               output_collections=['MY_OPS'], name='add_t1t2')\n```\n\n----------------------------------------\n\nTITLE: Defining a Concatenation Function with Testable Docstring in Python\nDESCRIPTION: This snippet demonstrates how to write a testable docstring for the 'concat' function in TensorFlow. It includes a code example that can be executed by DocTest, along with function arguments and return value descriptions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef concat(values, axis, name=\"concat\"):\n  \"\"\"Concatenates tensors along one dimension.\n  ...\n\n  >>> t1 = [[1, 2, 3], [4, 5, 6]]\n  >>> t2 = [[7, 8, 9], [10, 11, 12]]\n  >>> concat([t1, t2], 0)\n  <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n  array([[ 1,  2,  3],\n         [ 4,  5,  6],\n         [ 7,  8,  9],\n         [10, 11, 12]], dtype=int32)>\n\n  <... more description or code snippets ...>\n\n  Args:\n    values: A list of `tf.Tensor` objects or a single `tf.Tensor`.\n    axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n      in the range `[-rank(values), rank(values))`. As in Python, indexing for\n      axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n      to `axis`-th dimension. And negative axis refers to `axis +\n      rank(values)`-th dimension.\n    name: A name for the operation (optional).\n\n    Returns:\n      A `tf.Tensor` resulting from concatenation of the input tensors.\n  \"\"\"\n\n  <code here>\n```\n\n----------------------------------------\n\nTITLE: Displaying Model Summary (Python)\nDESCRIPTION: This snippet uses the `.summary()` method to display a brief overview of the model's architecture, including layer types and output shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Action Recognition\nDESCRIPTION: This snippet imports necessary Python libraries including TensorFlow, TensorFlow Hub, and various utilities for video processing and visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom absl import logging\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow_docs.vis import embed\n\nlogging.set_verbosity(logging.ERROR)\n\nimport random\nimport re\nimport os\nimport tempfile\nimport ssl\nimport cv2\nimport numpy as np\n\nimport imageio\nfrom IPython import display\n\nfrom urllib import request\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a Basic TensorFlow Model with CSV Data\nDESCRIPTION: This code creates a simple sequential model in TensorFlow, compiles it, and trains it using the prepared CSV data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nabalone_model = tf.keras.Sequential([\n  layers.Dense(64, activation='relu'),\n  layers.Dense(1)\n])\n\nabalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n                      optimizer = tf.keras.optimizers.Adam())\n\nabalone_model.fit(abalone_features, abalone_labels, epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning a Pre-trained Model in TensorFlow\nDESCRIPTION: This code demonstrates fine-tuning a pre-trained model for additional epochs, continuing from where the initial training left off. It fits the model using training and validation datasets with the specified parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nfine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=len(history.epoch),\n                         validation_data=validation_dataset)\n```\n\n----------------------------------------\n\nTITLE: Plotting ROC Curve in Python for TensorFlow Model\nDESCRIPTION: This function plots the Receiver Operating Characteristic (ROC) curve using scikit-learn's roc_curve function. It visualizes the trade-off between true positive rate and false positive rate.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef plot_roc(name, labels, predictions, **kwargs):\n  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n  plt.xlabel('False positives [%]')\n  plt.ylabel('True positives [%]')\n  plt.xlim([-0.5,20])\n  plt.ylim([80,100.5])\n  plt.grid(True)\n  ax = plt.gca()\n  ax.set_aspect('equal')\n```\n\n----------------------------------------\n\nTITLE: Variable Assignment Operations\nDESCRIPTION: Shows how to assign new values to variables using assign_add.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nassignment = v.assign_add(1)\ntf.global_variables_initializer().run()\nsess.run(assignment)  # or assignment.op.run(), or assignment.eval()\n```\n\n----------------------------------------\n\nTITLE: Adding Upstream Remote to TensorFlow Docs Repository\nDESCRIPTION: This code block demonstrates how to add an upstream remote to keep your local repository in sync with the main TensorFlow docs repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit remote add upstream git@github.com:tensorflow/docs.git\n\n# View remote repos\ngit remote -v\n```\n\n----------------------------------------\n\nTITLE: Testing Immutability of ExtensionType Fields in Python\nDESCRIPTION: Shows how ExtensionType prevents direct attribute modification, enforcing immutability by overriding __setattr__.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  mt.mask = [True, True, True]\nexcept AttributeError as e:\n  print(f\"Got expected AttributeError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Compatibility Module\nDESCRIPTION: This code imports the TensorFlow library in compatibility mode, allowing the use of TensorFlow 1.x features in TensorFlow 2.x environments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard from Command Line\nDESCRIPTION: Command to start TensorBoard and load the histogram data from the specified log directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensorboard_histograms.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ntensorboard --logdir=/tmp/histogram_example\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets for Video Classification\nDESCRIPTION: This code snippet demonstrates how to create TensorFlow datasets for training and validation using the FrameGenerator class. It sets up the output signature and creates datasets that can be used for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Create the training set\noutput_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n                    tf.TensorSpec(shape = (), dtype = tf.int16))\ntrain_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], 10, training=True),\n                                          output_signature = output_signature)\n\n# Create the validation set\nval_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], 10),\n                                        output_signature = output_signature)\n```\n\n----------------------------------------\n\nTITLE: Adding Index Counter to Dataset in TensorFlow\nDESCRIPTION: Creates a dataset with indices by zipping a counter with a text line dataset, then shuffles and batches it to demonstrate the effect of shuffling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_67\n\nLANGUAGE: python\nCODE:\n```\nlines = tf.data.TextLineDataset(titanic_file)\ncounter = tf.data.experimental.Counter()\n\ndataset = tf.data.Dataset.zip((counter, lines))\ndataset = dataset.shuffle(buffer_size=100)\ndataset = dataset.batch(20)\ndataset\n```\n\n----------------------------------------\n\nTITLE: Displaying CSV Line Format\nDESCRIPTION: This snippet prints the first line of the Titanic CSV data to show the format of the data before parsing it with appropriate types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nprint(lines[0])\n```\n\n----------------------------------------\n\nTITLE: Registering a GPU Kernel for TensorFlow Pad Op in C++\nDESCRIPTION: Example of registering a GPU kernel for the TensorFlow Pad operation, specifying that the 'paddings' input should be in host memory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_38\n\nLANGUAGE: C++\nCODE:\n```\n#define REGISTER_GPU_KERNEL(T)                         \\\n  REGISTER_KERNEL_BUILDER(Name(\"Pad\")                  \\\n                              .Device(DEVICE_GPU)      \\\n                              .TypeConstraint<T>(\"T\")  \\\n                              .HostMemory(\"paddings\"), \\\n                          PadOp<GPUDevice, T>)\n```\n\n----------------------------------------\n\nTITLE: Registering Op with String Enum Attribute (C++)\nDESCRIPTION: This code demonstrates registering a TensorFlow op with a string-based enum attribute. The `Attr` method specifies that the `e` attribute must be a string and can only have the values 'apple' or 'orange'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_12\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"EnumExample\")\n    .Attr(\"e: {'apple', 'orange'}\");\n```\n\n----------------------------------------\n\nTITLE: Restoring Model Variables with tf.train.Saver in Python\nDESCRIPTION: This Python snippet demonstrates restoring model variables from checkpoint files using tf.train.Saver. It includes setting up a TensorFlow session, restoring session state, and evaluating variable values. Requires TensorFlow environment setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntf.reset_default_graph()\n\n# Create some variables.\nv1 = tf.get_variable(\"v1\", shape=[3])\nv2 = tf.get_variable(\"v2\", shape=[5])\n\n# Add ops to save and restore all the variables.\nsaver = tf.train.Saver()\n\n# Later, launch the model, use the saver to restore variables from disk, and\n# do some work with the model.\nwith tf.Session() as sess:\n  # Restore variables from disk.\n  saver.restore(sess, \"/tmp/model.ckpt\")\n  print(\"Model restored.\")\n  # Check the values of the variables\n  print(\"v1 : %s\" % v1.eval())\n  print(\"v2 : %s\" % v2.eval())\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow 1 Estimator with Artificial Interruption\nDESCRIPTION: Starting the training process with the InterruptHook that will artificially raise an exception during the fifth checkpoint to demonstrate fault tolerance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  classifier.train(input_fn=train_input_fn,\n                   hooks=[InterruptHook()],\n                   max_steps=10)\nexcept Exception as e:\n  print(f'{type(e).__name__}:{e}')\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from CSV File in Python\nDESCRIPTION: This snippet shows how to create a tf.data.TextLineDataset to read a CSV file line by line, skipping the header.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nds = tf.data.TextLineDataset(train_path).skip(1)\n```\n\n----------------------------------------\n\nTITLE: Creating Word RaggedTensor\nDESCRIPTION: Constructs a RaggedTensor containing word characters using the identified word start positions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nword_char_codepoint = tf.RaggedTensor.from_row_starts(\n    values=sentence_char_codepoint.values,\n    row_starts=word_starts)\nprint(word_char_codepoint)\n```\n\n----------------------------------------\n\nTITLE: Overriding Constructor in ExtensionType in Python\nDESCRIPTION: Shows how to override the default constructor in an ExtensionType class to perform additional logic during initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nclass Toy(tf.experimental.ExtensionType):\n  name: str\n  price: tf.Tensor\n  def __init__(self, name, price, discount=0):\n    self.name = name\n    self.price = price * (1 - discount)\n\nprint(Toy(\"ball\", 5.0, discount=0.2))  # On sale -- 20% off!\n```\n\n----------------------------------------\n\nTITLE: Creating a Ragged Tensor from Value Rowids\nDESCRIPTION: Demonstrates how to construct a ragged tensor using tf.RaggedTensor.from_value_rowids by specifying which row each value belongs to.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_value_rowids(\n    values=[3, 1, 4, 1, 5, 9, 2, 6],\n    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Using Transformer Encoder Preprocessor for Multiple Text Segments\nDESCRIPTION: Demonstrates tokenizing and packing multiple text segments (premise and hypothesis) for tasks like sentence entailment using a Transformer encoder preprocessor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npreprocessor = hub.load(\"path/to/preprocessor\")\n\n# Tokenize batches of both text inputs.\ntext_premises = tf.constant([\"The quick brown fox jumped over the lazy dog.\",\n                             \"Good day.\"])\ntokenized_premises = preprocessor.tokenize(text_premises)\ntext_hypotheses = tf.constant([\"The dog was lazy.\",  # Implied.\n                               \"Axe handle!\"])       # Not implied.\ntokenized_hypotheses = preprocessor.tokenize(text_hypotheses)\n\n# Pack input sequences for the Transformer encoder.\nseq_length = 128\nencoder_inputs = preprocessor.bert_pack_inputs(\n    [tokenized_premises, tokenized_hypotheses],\n    seq_length=seq_length)  # Optional argument.\n```\n\n----------------------------------------\n\nTITLE: License Information for TensorFlow Tutorial\nDESCRIPTION: Provides the Apache License 2.0 information for this TensorFlow tutorial on adversarial examples using FGSM.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Plotting Baseline and L2 Regularized Model History\nDESCRIPTION: Uses the previously defined `plot_history` function to compare the training histories of a baseline model and an L2 regularized model.  The plot visualizes how L2 regularization affects the training and validation loss curves.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nplot_history([('baseline', baseline_history),\n              ('l2', l2_model_history)])\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting IMDB Dataset\nDESCRIPTION: Downloads the Large Movie Review Dataset from Stanford's AI Lab and extracts it to the local filesystem for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nurl = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n\ndataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n                                    untar=True, cache_dir='.',\n                                    cache_subdir='')\n\ndataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n```\n\n----------------------------------------\n\nTITLE: Creating Early Stopping Callback\nDESCRIPTION: Defines an early stopping callback to prevent overfitting during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n```\n\n----------------------------------------\n\nTITLE: Exploring Training Data\nDESCRIPTION: Displaying batch of training examples and their corresponding labels\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\ntrain_examples_batch\n```\n\n----------------------------------------\n\nTITLE: Building the ResNet Block\nDESCRIPTION: Initializes the ResNet block by calling it with a zero tensor of appropriate shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n_ = block(tf.zeros([1, 2, 3, 3])) \n```\n\n----------------------------------------\n\nTITLE: Forcing Retracing in TensorFlow Functions\nDESCRIPTION: Shows how to force retracing by creating new tf.function objects, which are guaranteed not to share traces.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef f():\n  print('Tracing!')\n  tf.print('Executing')\n\ntf.function(f)()\ntf.function(f)()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Early Stopping with TF2 Built-in Callback\nDESCRIPTION: Uses TensorFlow 2's built-in EarlyStopping callback with Keras Model.fit. This example monitors the loss metric and stops training after 3 epochs with no improvement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\n# Only around 25 epochs are run during training, instead of 100.\nhistory = model.fit(\n    ds_train,\n    epochs=100,\n    validation_data=ds_test,\n    callbacks=[callback]\n)\n\nlen(history.history['loss'])\n```\n\n----------------------------------------\n\nTITLE: Defining input functions and model function in TF1\nDESCRIPTION: This code snippet defines the input functions (`_input_fn` and `_eval_input_fn`) for training and evaluation data, as well as the model function (`_model_fn`) for instructing the `TPUEstimator` on how to define the training op. These functions are essential for training the model on TPUs using the `TPUEstimator` API in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef _input_fn(params):\n  dataset = tf1.data.Dataset.from_tensor_slices((\n      {\"dense_feature\": features,\n       \"sparse_feature\": tf1.SparseTensor(\n           embedding_features_indices,\n           embedding_features_values, [1, 2])},\n           labels))\n  dataset = dataset.repeat()\n  return dataset.batch(params['batch_size'], drop_remainder=True)\n\ndef _eval_input_fn(params):\n  dataset = tf1.data.Dataset.from_tensor_slices((\n      {\"dense_feature\": eval_features,\n       \"sparse_feature\": tf1.SparseTensor(\n           eval_embedding_features_indices,\n           eval_embedding_features_values, [1, 2])},\n           eval_labels))\n  dataset = dataset.repeat()\n  return dataset.batch(params['batch_size'], drop_remainder=True)\n\ndef _model_fn(features, labels, mode, params):\n  embedding_features = tf1.keras.layers.DenseFeatures(embedding_column)(features)\n  concatenated_features = tf1.keras.layers.Concatenate(axis=1)(\n      [embedding_features, features[\"dense_feature\"]])\n  logits = tf1.layers.Dense(1)(concatenated_features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  optimizer = tf1.tpu.CrossShardOptimizer(optimizer)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  return tf1.estimator.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\n----------------------------------------\n\nTITLE: Loading Pretrained MobileNetV2 Model for Adversarial Example Generation\nDESCRIPTION: Loads a pretrained MobileNetV2 model with ImageNet weights that will be used as the target model for the adversarial attack.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n                                                     weights='imagenet')\npretrained_model.trainable = False\n\n# ImageNet labels\ndecode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n```\n\n----------------------------------------\n\nTITLE: Testing Adam Optimizer Convergence with Different Learning Rates\nDESCRIPTION: This snippet tests the performance of the Adam optimizer with different learning rates (1e-3, 1e-2, 1e-1) using a convergence test function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nparam_map_adam = {}\nlearning_rates = [1e-3, 1e-2, 1e-1]\nfor learning_rate in learning_rates:\n  param_map_adam[learning_rate] = (convergence_test(\n      Adam(learning_rate=learning_rate), loss_fn=loss))\n```\n\n----------------------------------------\n\nTITLE: Building Stochastic Depth Model with Conv2D layers in TensorFlow\nDESCRIPTION: This code builds a `StochasticNetworkDepth` model consisting of 20 `Conv2D` layers with ReLU activation. It defines the model within a `tf.Graph()` and initializes it. The `model.build` method is explicitly called to define the model's parameters before use.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  model = StochasticNetworkDepth(\n      [\n        layers.Conv2D(filters=16, activation=tf.nn.relu,\n                  kernel_size=(3, 3), padding='same')\n        for n in range(20)\n      ],\n      pfirst=1.0, plast=0.5\n  )\n\n  model.build(tf.TensorShape((None, None, None, 1)))\n\n  init = tf.global_variables_initializer()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Dataset Reader in C++\nDESCRIPTION: Core C++ implementation of a custom dataset reader including the dataset op kernel, dataset class, and iterator. Demonstrates the required class hierarchy and methods for creating a custom file format reader.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/formats.md#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/dataset.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n\nnamespace myproject {\nnamespace {\n\nusing ::tensorflow::DT_STRING;\nusing ::tensorflow::PartialTensorShape;\nusing ::tensorflow::Status;\n\nclass MyReaderDatasetOp : public tensorflow::DatasetOpKernel {\n public:\n\n  MyReaderDatasetOp(tensorflow::OpKernelConstruction* ctx)\n      : DatasetOpKernel(ctx) {\n    // Parse and validate any attrs that define the dataset using\n    // `ctx->GetAttr()`, and store them in member variables.\n  }\n\n  void MakeDataset(tensorflow::OpKernelContext* ctx,\n                   tensorflow::DatasetBase** output) override {\n    // Parse and validate any input tensors that define the dataset using\n    // `ctx->input()` or the utility function\n    // `ParseScalarArgument<T>(ctx, &arg)`.\n\n    // Create the dataset object, passing any (already-validated) arguments from\n    // attrs or input tensors.\n    *output = new Dataset(ctx);\n  }\n\n private:\n  class Dataset : public tensorflow::GraphDatasetBase {\n   public:\n    Dataset(tensorflow::OpKernelContext* ctx) : GraphDatasetBase(ctx) {}\n\n    std::unique_ptr<tensorflow::IteratorBase> MakeIteratorInternal(\n        const string& prefix) const override {\n      return std::unique_ptr<tensorflow::IteratorBase>(new Iterator(\n          {this, tensorflow::strings::StrCat(prefix, \"::MyReader\")}));\n    }\n\n    const tensorflow::DataTypeVector& output_dtypes() const override {\n      static auto* const dtypes = new tensorflow::DataTypeVector({DT_STRING});\n      return *dtypes;\n    }\n    const std::vector<PartialTensorShape>& output_shapes() const override {\n      static std::vector<PartialTensorShape>* shapes =\n          new std::vector<PartialTensorShape>({{}});\n      return *shapes;\n    }\n\n    string DebugString() const override { return \"MyReaderDatasetOp::Dataset\"; }\n\n   protected:\n    Status AsGraphDefInternal(DatasetGraphDefBuilder* b,\n                              tensorflow::Node** output) const override {\n      std::vector<tensorflow::Node*> input_tensors;\n      TF_RETURN_IF_ERROR(b->AddDataset(this, input_tensors, output));\n      return Status::OK();\n    }\n\n   private:\n    class Iterator : public tensorflow::DatasetIterator<Dataset> {\n     public:\n      explicit Iterator(const Params& params)\n          : DatasetIterator<Dataset>(params), i_(0) {}\n\n      Status GetNextInternal(tensorflow::IteratorContext* ctx,\n                             std::vector<tensorflow::Tensor>* out_tensors,\n                             bool* end_of_sequence) override {\n        tensorflow::mutex_lock l(mu_);\n        if (i_ < 10) {\n          tensorflow::Tensor record_tensor(ctx->allocator({}), DT_STRING, {});\n          record_tensor.scalar<string>()() = \"MyReader!\";\n          out_tensors->emplace_back(std::move(record_tensor));\n          ++i_;\n          *end_of_sequence = false;\n        } else {\n          *end_of_sequence = true;\n        }\n        return Status::OK();\n      }\n\n     protected:\n      Status SaveInternal(tensorflow::IteratorStateWriter* writer) override {\n        tensorflow::mutex_lock l(mu_);\n        TF_RETURN_IF_ERROR(writer->WriteScalar(full_name(\"i\"), i_));\n        return Status::OK();\n      }\n      Status RestoreInternal(tensorflow::IteratorContext* ctx,\n                             tensorflow::IteratorStateReader* reader) override {\n        tensorflow::mutex_lock l(mu_);\n        TF_RETURN_IF_ERROR(reader->ReadScalar(full_name(\"i\"), &i_));\n        return Status::OK();\n      }\n\n     private:\n      tensorflow::mutex mu_;\n      int64 i_ GUARDED_BY(mu_);\n    };\n  };\n};\n\nREGISTER_OP(\"MyReaderDataset\")\n    .Output(\"handle: variant\")\n    .SetIsStateful()\n    .SetShapeFn(tensorflow::shape_inference::ScalarShape);\n\nREGISTER_KERNEL_BUILDER(Name(\"MyReaderDataset\").Device(tensorflow::DEVICE_CPU),\n                        MyReaderDatasetOp);\n\n}  // namespace\n}  // namespace myproject\n```\n\n----------------------------------------\n\nTITLE: Generating Multiple Distribution Types in Python\nDESCRIPTION: Creates and combines multiple types of distributions including normal, gamma, poisson, and uniform distributions. Shows how to visualize complex multi-distribution data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensorboard_histograms.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nk = tf.placeholder(tf.float32)\n\n# Make a normal distribution, with a shifting mean\nmean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n# Record that distribution into a histogram summary\ntf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n\n# Make a normal distribution with shrinking variance\nvariance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))\n# Record that distribution too\ntf.summary.histogram(\"normal/shrinking_variance\", variance_shrinking_normal)\n\n# Let's combine both of those distributions into one dataset\nnormal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)\n# We add another histogram summary to record the combined distribution\ntf.summary.histogram(\"normal/bimodal\", normal_combined)\n\n# Add a gamma distribution\ngamma = tf.random_gamma(shape=[1000], alpha=k)\ntf.summary.histogram(\"gamma\", gamma)\n\n# And a poisson distribution\npoisson = tf.random_poisson(shape=[1000], lam=k)\ntf.summary.histogram(\"poisson\", poisson)\n\n# And a uniform distribution\nuniform = tf.random_uniform(shape=[1000], maxval=k*10)\ntf.summary.histogram(\"uniform\", uniform)\n\n# Finally, combine everything together!\nall_distributions = [mean_moving_normal, variance_shrinking_normal,\n                     gamma, poisson, uniform]\nall_combined = tf.concat(all_distributions, 0)\ntf.summary.histogram(\"all_combined\", all_combined)\n\nsummaries = tf.summary.merge_all()\n\n# Setup a session and summary writer\nsess = tf.Session()\nwriter = tf.summary.FileWriter(\"/tmp/histogram_example\")\n\n# Setup a loop and write the summaries to disk\nN = 400\nfor step in range(N):\n  k_val = step/float(N)\n  summ = sess.run(summaries, feed_dict={k: k_val})\n  writer.add_summary(summ, global_step=step)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Semantic Search Implementation\nDESCRIPTION: Imports the necessary Python libraries for data processing, embedding generation, and approximate nearest neighbors search.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport sys\nimport pathlib\nimport pickle\nfrom collections import namedtuple\nfrom datetime import datetime\n\nimport numpy as np\nimport apache_beam as beam\nimport annoy\nfrom sklearn.random_projection import gaussian_random_matrix\n\nimport tensorflow.compat.v1 as tf\nimport tensorflow_hub as hub\n```\n\n----------------------------------------\n\nTITLE: Configuring Image Classification Model Selection in TensorFlow Hub\nDESCRIPTION: Sets up a selection mechanism for various image classification models from TensorFlow Hub. Defines model names, handles, and configuration parameters like image size and dynamic sizing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title Select an Image Classification model\n\nimage_size = 224\ndynamic_size = False\n\nmodel_name = \"efficientnetv2-s\" # @param ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n\nmodel_handle_map = {\n  \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\",\n  \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/classification/2\",\n  \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/classification/2\",\n  \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/classification/2\",\n  \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/classification/2\",\n  \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/classification/2\",\n  \"efficientnetv2-xl-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/classification/2\",\n  \"efficientnetv2-b0-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/classification/2\",\n  \"efficientnetv2-b1-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b1/classification/2\",\n  \"efficientnetv2-b2-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/classification/2\",\n  \"efficientnetv2-b3-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b3/classification/2\",\n  \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/classification/2\",\n  \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/classification/2\",\n  \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/classification/2\",\n  \"efficientnetv2-xl-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/classification/2\",\n  \"efficientnetv2-b0-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2\",\n  \"efficientnetv2-b1-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b1/classification/2\",\n  \"efficientnetv2-b2-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/classification/2\",\n  \"efficientnetv2-b3-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/classification/2\",\n  \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/classification/2\",\n  \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/classification/2\",\n  \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/classification/2\",\n  \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/classification/2\",\n  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/classification/1\",\n  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/classification/1\",\n  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/classification/1\",\n  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/classification/1\",\n  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/classification/1\",\n  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/classification/1\",\n  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/classification/1\",\n  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\",\n  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/ilsvrc2012_classification/1\",\n  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/classification/4\",\n  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/4\",\n  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/4\",\n  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/classification/4\",\n  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/classification/4\",\n  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/4\",\n  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/4\",\n  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4\",\n  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/classification/4\",\n  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/classification/4\",\n  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/classification/4\",\n  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\"\n```\n\n----------------------------------------\n\nTITLE: Saving a TensorFlow Graph for TensorBoard Visualization\nDESCRIPTION: Demonstrates how to save a TensorFlow computational graph to a summary file for visualization in TensorBoard. This is useful for understanding and debugging complex models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwriter = tf.summary.FileWriter('.')\nwriter.add_graph(tf.get_default_graph())\nwriter.flush()\n```\n\n----------------------------------------\n\nTITLE: Loading and Using Saved DTensor Model in Python\nDESCRIPTION: This code demonstrates how to load a saved DTensor model and use it for inference. It loads the model, retrieves the signature, and runs inference on a sample batch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nloaded = tf.saved_model.load(\"/tmp/saved_model\")\n\nrun_sig = loaded.signatures[\"serving_default\"]\nresult = run_sig(sample_batch['text'])['result']\n\nnp.mean(tf.argmax(result, axis=-1) == sample_batch['label'])\n```\n\n----------------------------------------\n\nTITLE: Defining Convolutional Neural Network Model using Flax\nDESCRIPTION: Creates a ConvModel class using Flax linen module. The model includes convolutional layers, batch normalization, dropout, and dense layers. It also defines methods for loss calculation, prediction, and accuracy computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass ConvModel(flax.linen.Module):\n\n  @flax.linen.compact\n  def __call__(self, x, train):\n    x = flax.linen.Conv(features=12, kernel_size=(3,3), padding=\"SAME\", use_bias=False)(x)\n    x = flax.linen.BatchNorm(use_running_average=not train, use_scale=False, use_bias=True)(x)\n    x = x.reshape((x.shape[0], -1))  # flatten\n    x = flax.linen.Dense(features=200, use_bias=True)(x)\n    x = flax.linen.BatchNorm(use_running_average=not train, use_scale=False, use_bias=True)(x)\n    x = flax.linen.Dropout(rate=0.3, deterministic=not train)(x)\n    x = flax.linen.relu(x)\n    x = flax.linen.Dense(features=10)(x)\n    #x = flax.linen.log_softmax(x)\n    return x\n\n  def loss(self, params, other_state, rng, data, labels, train):\n    logits, batch_stats = self.apply({'params': params, **other_state},\n                                     data,\n                                     mutable=['batch_stats'],\n                                     rngs={'dropout': rng},\n                                     train=train)\n    loss = optax.softmax_cross_entropy(logits, labels).mean()\n    return loss, batch_stats\n\n  def predict(self, state, data):\n    logits = self.apply(state, data, train=False)\n    probabilities = flax.linen.log_softmax(logits)\n    return probabilities\n\n  def accuracy(self, state, data, labels):\n    probabilities = self.predict(state, data)\n    predictions = jnp.argmax(probabilities, axis=-1)\n    dense_labels = jnp.argmax(labels, axis=-1)\n    accuracy = jnp.equal(predictions, dense_labels).mean()\n    return accuracy\n```\n\n----------------------------------------\n\nTITLE: Initializing the Export Module with Model and Helper Functions\nDESCRIPTION: Creates an instance of the ExportModule by passing the trained MLP model along with the preprocessing and class prediction functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nmlp_model_export = ExportModule(model=mlp_model,\n                                preprocess=preprocess_test,\n                                class_pred=class_pred_test)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Setup and Imports\nDESCRIPTION: Initial setup code installing TensorFlow nightly build and importing required dependencies\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q tf_nightly\nimport tensorflow as tf\nimport numpy as np\nfrom typing import Tuple, List, Mapping, Union, Optional\nimport tempfile\n```\n\n----------------------------------------\n\nTITLE: Implementing Visualization Utilities for Training Progress\nDESCRIPTION: Defines visualization functions for displaying training and validation curves, including loss and accuracy metrics, along with a text-based progress bar for monitoring training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title Visualization utilities\n\nplt.rcParams[\"figure.figsize\"] = (20,8)\n\n# The utility for displaying training and validation curves.\ndef display_train_curves(loss, avg_loss, eval_loss, eval_accuracy, epochs, steps_per_epochs, ignore_first_n=10):\n\n  ignore_first_n_epochs = int(ignore_first_n/steps_per_epochs)\n\n  # The losses.\n  ax = plt.subplot(121)\n  if loss is not None:\n    x = np.arange(len(loss)) / steps_per_epochs #* epochs\n    ax.plot(x, loss)\n  ax.plot(range(1, epochs+1), avg_loss, \"-o\", linewidth=3)\n  ax.plot(range(1, epochs+1), eval_loss, \"-o\", linewidth=3)\n  ax.set_title('Loss')\n  ax.set_ylabel('loss')\n  ax.set_xlabel('epoch')\n  if loss is not None:\n    ax.set_ylim(0, np.max(loss[ignore_first_n:]))\n    ax.legend(['train', 'avg train', 'eval'])\n  else:\n    ymin = np.min(avg_loss[ignore_first_n_epochs:])\n    ymax = np.max(avg_loss[ignore_first_n_epochs:])\n    ax.set_ylim(ymin-(ymax-ymin)/10, ymax+(ymax-ymin)/10)\n    ax.legend(['avg train', 'eval'])\n\n  # The accuracy.\n  ax = plt.subplot(122)\n  ax.set_title('Eval Accuracy')\n  ax.set_ylabel('accuracy')\n  ax.set_xlabel('epoch')\n  ymin = np.min(eval_accuracy[ignore_first_n_epochs:])\n  ymax = np.max(eval_accuracy[ignore_first_n_epochs:])\n  ax.set_ylim(ymin-(ymax-ymin)/10, ymax+(ymax-ymin)/10)\n  ax.plot(range(1, epochs+1), eval_accuracy, \"-o\", linewidth=3)\n\nclass Progress:\n    \"\"\"Text mode progress bar.\n    Usage:\n            p = Progress(30)\n            p.step()\n            p.step()\n            p.step(reset=True) # to restart form 0%\n    The progress bar displays a new header at each restart.\"\"\"\n    def __init__(self, maxi, size=100, msg=\"\"):\n        \"\"\"\n        :param maxi: the number of steps required to reach 100%\n        :param size: the number of characters taken on the screen by the progress bar\n        :param msg: the message displayed in the header of the progress bar\n        \"\"\"\n        self.maxi = maxi\n        self.p = self.__start_progress(maxi)()  # `()`: to get the iterator from the generator.\n        self.header_printed = False\n        self.msg = msg\n        self.size = size\n        self.lock = Lock()\n\n    def step(self, reset=False):\n        with self.lock:\n            if reset:\n                self.__init__(self.maxi, self.size, self.msg)\n            if not self.header_printed:\n                self.__print_header()\n            next(self.p)\n\n    def __print_header(self):\n        print()\n        format_string = \"0%{: ^\" + str(self.size - 6) + \"}100%\"\n        print(format_string.format(self.msg))\n        self.header_printed = True\n\n    def __start_progress(self, maxi):\n        def print_progress():\n            # Bresenham's algorithm. Yields the number of dots printed.\n            # This will always print 100 dots in max invocations.\n            dx = maxi\n            dy = self.size\n            d = dy - dx\n            for x in range(maxi):\n                k = 0\n                while d >= 0:\n                    print('=', end=\"\", flush=True)\n                    k += 1\n                    d -= dx\n                d += dy\n                yield k\n            # Keep yielding the last result if there are too many steps.\n            while True:\n              yield k\n\n        return print_progress\n```\n\n----------------------------------------\n\nTITLE: Creating a New Branch for TensorFlow Docs Contributions\nDESCRIPTION: This code block demonstrates how to create a new branch from the local master branch for making documentation changes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b <var>feature-name</var>\n\ngit branch\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Input Function Example\nDESCRIPTION: Demonstrates the format of an input function by creating a simple example with predefined values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef input_evaluation_set():\n    features = {'SepalLength': np.array([6.4, 5.0]),\n                'SepalWidth':  np.array([2.8, 2.3]),\n                'PetalLength': np.array([5.6, 3.3]),\n                'PetalWidth':  np.array([2.2, 1.0])}\n    labels = np.array([2, 1])\n    return features, labels\n```\n\n----------------------------------------\n\nTITLE: Running the Speech Commands Training Script in TensorFlow\nDESCRIPTION: Command to start training a speech recognition model using TensorFlow's speech_commands example. This initiates the download of the Speech Commands dataset and begins the training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython tensorflow/examples/speech_commands/train.py\n```\n\n----------------------------------------\n\nTITLE: Second Call to tf.function with Same TypeSpec in Python\nDESCRIPTION: Shows that a tf.function is not retraced when called with an ExtensionType that has the same TypeSpec but different tensor values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# Function does NOT get traced (same TypeSpec: just tensor values changed)\nanonymize_player(Player(\"Bart\", {\"height\": 8.1, \"speed\": 25.3}))\n```\n\n----------------------------------------\n\nTITLE: Using MNIST Decoder as a Generative Model in TensorFlow\nDESCRIPTION: This snippet demonstrates how to use the trained decoder as a generative model. It feeds random strings into the decompressor to generate new MNIST-like digits and visualizes the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\ncompressor, decompressor = make_mnist_codec(trainer, decode_sanity_check=False)\n\nstrings = tf.constant([os.urandom(8) for _ in range(16)])\nsamples = decompressor(strings)\n\nfig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(5, 5))\naxes = axes.ravel()\nfor i in range(len(axes)):\n  axes[i].imshow(tf.squeeze(samples[i]))\n  axes[i].axis(\"off\")\nplt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n```\n\n----------------------------------------\n\nTITLE: Setting up Loss Function and Optimizer\nDESCRIPTION: Configuration of CTC Loss function and Adam optimizer for model training\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom wav2vec2 import CTCLoss\n\nLEARNING_RATE = 5e-5\n\nloss_fn = CTCLoss(config, (BATCH_SIZE, AUDIO_MAXLEN), division_factor=BATCH_SIZE)\noptimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n```\n\n----------------------------------------\n\nTITLE: Generating and Saving Images from CVAE Model in Python\nDESCRIPTION: Defines a function to generate and save images using the trained CVAE model. It encodes test samples, applies reparameterization, and then decodes to generate images which are saved and displayed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\ndef generate_and_save_images(model, epoch, test_sample):\n  mean, logvar = model.encode(test_sample)\n  z = model.reparameterize(mean, logvar)\n  predictions = model.sample(z)\n  fig = plt.figure(figsize=(4, 4))\n\n  for i in range(predictions.shape[0]):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n    plt.axis('off')\n\n  # tight_layout minimizes the overlap between 2 sub-plots\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Debugging TensorFlow Functions with Eager Execution\nDESCRIPTION: Example showing how to debug a TensorFlow function using eager execution mode and pdb debugger. Demonstrates setting breakpoints inside tf.function decorated code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f(x):\n  if x > 0:\n    import pdb\n    pdb.set_trace()\n    x = x + 1\n  return x\n\ntf.config.run_functions_eagerly(True)\nf(tf.constant(1))\n```\n\n----------------------------------------\n\nTITLE: Unbatching Sparse Tensors with Dataset.unbatch in TensorFlow\nDESCRIPTION: This snippet shows how to unbatch a previously batched dataset containing sparse tensors using the Dataset.unbatch method. It separates the batched elements back into individual elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nunbatched_dataset = batched_dataset.unbatch()\nfor element in unbatched_dataset:\n  print (pprint_sparse_tensor(element))\n```\n\n----------------------------------------\n\nTITLE: Extracting Encoder Features from BigBiGAN in Python\nDESCRIPTION: This code demonstrates how to compute features from a BigBiGAN encoder for representation learning. It extracts both average pooling features and BN+CReLU features, which can be used for downstream tasks like classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n_out_features = sess.run(enc_features, feed_dict={enc_ph: test_images_batch})\nprint('AvePool features shape:', _out_features['avepool_feat'].shape)\nprint('BN+CReLU features shape:', _out_features['bn_crelu_feat'].shape)\n```\n\n----------------------------------------\n\nTITLE: Bucketizing and One-hot Encoding with Feature Columns\nDESCRIPTION: Demonstrates bucketizing and one-hot encoding of numeric features using feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nnumeric_col = tf1.feature_column.numeric_column('col')\nbucketized_col = tf1.feature_column.bucketized_column(numeric_col, [1, 4, 5])\ncall_feature_columns(bucketized_col, {'col': tf.constant([1., 2., 3., 4., 5.])})\n```\n\n----------------------------------------\n\nTITLE: Recovering and Displaying Images from Parsed TFRecord Dataset\nDESCRIPTION: Iterates through the parsed image dataset, extracts the raw image data from each record, and displays the images. This demonstrates how to access and visualize images that were stored in TFRecord format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfor image_features in parsed_image_dataset:\n  image_raw = image_features['image_raw'].numpy()\n  display.display(display.Image(data=image_raw))\n```\n\n----------------------------------------\n\nTITLE: Building CPU-only TensorFlow Wheel with MSVC on Windows\nDESCRIPTION: Bazel command to build a CPU-only version of TensorFlow with Microsoft Visual C++ compiler. This command specifies options for Python version and wheel naming.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nbazel build --config=opt --repo_env=TF_PYTHON_VERSION=3.11 //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu\n```\n\n----------------------------------------\n\nTITLE: Creating float32 WeakTensor with tnp.array Using New Type Promotion\nDESCRIPTION: This example shows how TensorFlow-NumPy's array function creates int32 WeakTensors for floating-point inputs with the new type promotion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ntnp.array(1.0)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>\n```\n\n----------------------------------------\n\nTITLE: Training a Keras Model with NumPy Data\nDESCRIPTION: This snippet demonstrates how to train a Keras model using NumPy arrays as input data. It generates random data and labels, then fits the model for 10 epochs with a batch size of 32.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef random_one_hot_labels(shape):\n  n, n_class = shape\n  classes = np.random.randint(0, n_class, n)\n  labels = np.zeros((n, n_class))\n  labels[np.arange(n), classes] = 1\n  return labels\n\ndata = np.random.random((1000, 32))\nlabels = random_one_hot_labels((1000, 10))\n\nmodel.fit(data, labels, epochs=10, batch_size=32)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from MNIST Data in Python\nDESCRIPTION: This snippet demonstrates how to create a tf.data.Dataset from the MNIST dataset, slicing it into individual images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ntrain, test = tf.keras.datasets.mnist.load_data()\nmnist_x, mnist_y = train\n\nmnist_ds = tf.data.Dataset.from_tensor_slices(mnist_x)\nprint(mnist_ds)\n```\n\n----------------------------------------\n\nTITLE: Plotting Baseline Model Predictions\nDESCRIPTION: Visualizes the baseline model's predictions using the wide window configuration, which shows how the model simply shifts the input temperature by one hour to make predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nwide_window.plot(baseline)\n```\n\n----------------------------------------\n\nTITLE: Finding bounding shape for a RaggedTensor in TensorFlow\nDESCRIPTION: Demonstrates how to use the bounding_shape() method to find a tight bounding shape for a given RaggedTensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).bounding_shape())\n```\n\n----------------------------------------\n\nTITLE: Loading and Using Image Feature Vector Module in TensorFlow\nDESCRIPTION: Example showing how to load an image feature vector module and extract features from a batch of images. The module maps images to dense 1-D feature vectors for classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/images.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n  module_spec = hub.load_module_spec(\"path/to/module\")\n  height, width = hub.get_expected_image_size(module_spec)\n  images = ...  # A batch of images with shape [batch_size, height, width, 3].\n  module = hub.Module(module_spec)\n  features = module(images)   # A batch with shape [batch_size, num_features].\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Library\nDESCRIPTION: Importing the TensorFlow library which provides the distributed training capabilities demonstrated in this tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Environment After Training\nDESCRIPTION: This code removes the TF_CONFIG environment variable and kills any remaining background tasks to prepare for subsequent operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n# Delete the `'TF_CONFIG'`, and kill any background tasks so they don't affect the next section.\nos.environ.pop('TF_CONFIG', None)\n%killbgscripts\n```\n\n----------------------------------------\n\nTITLE: Defining Callbacks for Training\nDESCRIPTION: Set up callbacks for TensorBoard logging, model checkpointing, learning rate scheduling, and custom printing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ndef decay(epoch):\n  if epoch < 3:\n    return 1e-3\n  elif epoch >= 3 and epoch < 7:\n    return 1e-4\n  else:\n    return 1e-5\n\nclass PrintLR(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print ('\\nLearning rate for epoch {} is {}'.format(\n        epoch + 1, tf.keras.backend.get_value(model.optimizer.lr)))\n\ncallbacks = [\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n                                       save_weights_only=True),\n    tf.keras.callbacks.LearningRateScheduler(decay),\n    PrintLR()\n]\n```\n\n----------------------------------------\n\nTITLE: Visualizing TensorFlow Graphs with TensorBoard\nDESCRIPTION: This snippet illustrates creating a computational graph and writing it to logs for visualization in TensorBoard. It involves building a graph with constants and variables, running training operations, and using `tf.summary.FileWriter` to log the graph. TensorBoard's graph visualizer can be used subsequently for visual inspection. TensorFlow and TensorBoard are prerequisites.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Build your graph.\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\n# ...\nloss = ...\ntrain_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n\nwith tf.Session() as sess:\n  # `sess.graph` provides access to the graph used in a `tf.Session`.\n  writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n\n  # Perform your computation...\n  for i in range(1000):\n    sess.run(train_op)\n    # ...\n\n  writer.close()\n```\n\n----------------------------------------\n\nTITLE: Plotting Model Predictions After Training\nDESCRIPTION: Visualizes the model's performance after completing the custom training loop.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nplot_preds(x, y, f, quad_model, 'After training')\n```\n\n----------------------------------------\n\nTITLE: Training JAX Model\nDESCRIPTION: Executes the training loop for the specified number of epochs, updating the model state and optimizer state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nnew_state, new_optimizer_state = train(model, state, optimizer_state, train_data, JAX_EPOCHS+TF_EPOCHS, losses, avg_losses, eval_losses, eval_accuracies)\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TensorFlow Function\nDESCRIPTION: Shows how to calculate the output of a defined function with a specific input value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nf(x)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Initial Discriminator Outputs\nDESCRIPTION: Creates visualizations of the initial discriminator outputs for real horse and zebra images. This shows how the discriminators evaluate images before training begins.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(8, 8))\n\nplt.subplot(121)\nplt.title('Is a real zebra?')\nplt.imshow(discriminator_y(sample_zebra)[0, ..., -1], cmap='RdBu_r')\n\nplt.subplot(122)\nplt.title('Is a real horse?')\nplt.imshow(discriminator_x(sample_horse)[0, ..., -1], cmap='RdBu_r')\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Preparing Distributed Dataset for Custom Training\nDESCRIPTION: This code prepares a distributed dataset for use in custom training loops with a distribution strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(\n    global_batch_size)\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n```\n\n----------------------------------------\n\nTITLE: Center Cropping an Image with tf.image\nDESCRIPTION: Demonstrates center cropping of an image using tf.image.central_crop. The example crops the central 50% of the image by specifying a central_fraction of 0.5.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ncropped = tf.image.central_crop(image, central_fraction=0.5)\nvisualize(image, cropped)\n```\n\n----------------------------------------\n\nTITLE: Implementing MNIST Compressor and Decompressor in TensorFlow\nDESCRIPTION: This snippet defines two classes: MNISTCompressor for compressing MNIST images to strings, and MNISTDecompressor for decompressing strings back to images. These classes use the trained analysis and synthesis transforms along with an entropy model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass MNISTCompressor(tf.keras.Model):\n  \"\"\"Compresses MNIST images to strings.\"\"\"\n\n  def __init__(self, analysis_transform, entropy_model):\n    super().__init__()\n    self.analysis_transform = analysis_transform\n    self.entropy_model = entropy_model\n\n  def call(self, x):\n    # Ensure inputs are floats in the range (0, 1).\n    x = tf.cast(x, self.compute_dtype) / 255.\n    y = self.analysis_transform(x)\n    # Also return the exact information content of each digit.\n    _, bits = self.entropy_model(y, training=False)\n    return self.entropy_model.compress(y), bits\n\nclass MNISTDecompressor(tf.keras.Model):\n  \"\"\"Decompresses MNIST images from strings.\"\"\"\n\n  def __init__(self, entropy_model, synthesis_transform):\n    super().__init__()\n    self.entropy_model = entropy_model\n    self.synthesis_transform = synthesis_transform\n\n  def call(self, string):\n    y_hat = self.entropy_model.decompress(string, ())\n    x_hat = self.synthesis_transform(y_hat)\n    # Scale and cast back to 8-bit integer.\n    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n```\n\n----------------------------------------\n\nTITLE: Resuming Custom Training Loop with TensorFlow\nDESCRIPTION: This code continues a multi-worker custom training loop until the specified number of epochs is reached. It handles iteration through the dataset, loss calculation, and checkpoint management across workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Resume our CTL training\nwhile epoch.numpy() < num_epochs:\n  iterator = iter(multi_worker_dataset)\n  total_loss = 0.0\n  num_batches = 0\n\n  while step_in_epoch.numpy() < num_steps_per_epoch:\n    total_loss += train_step(iterator)\n    num_batches += 1\n    step_in_epoch.assign_add(1)\n\n  train_loss = total_loss / num_batches\n  print('Epoch: %d, accuracy: %f, train_loss: %f.'\n                %(epoch.numpy(), train_accuracy.result(), train_loss))\n\n  train_accuracy.reset_states()\n\n  checkpoint_manager.save()\n  if not _is_chief(task_type, task_id, cluster_spec):\n    tf.io.gfile.rmtree(write_checkpoint_dir)\n\n  epoch.assign_add(1)\n  step_in_epoch.assign(0)\n```\n\n----------------------------------------\n\nTITLE: Distributing Dataset with MirroredStrategy in Python\nDESCRIPTION: This snippet shows how to create a dataset and distribute it according to the MirroredStrategy. It uses experimental_distribute_dataset to handle the distribution of inputs for training across different replicas.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(\n    global_batch_size)\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n```\n\n----------------------------------------\n\nTITLE: Listing Checkpoint Files in TensorFlow\nDESCRIPTION: Lists the files in the checkpoint directory to verify that checkpoints were created during model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nos.listdir(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Accumulating Values in a Dynamic RNN with TensorArray\nDESCRIPTION: Shows how to use tf.TensorArray to accumulate results from a dynamically unrolled loop instead of Python lists, which is required for proper behavior in tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 2\nseq_len = 3\nfeature_size = 4\n\ndef rnn_step(inp, state):\n  return inp + state\n\n@tf.function\ndef dynamic_rnn(rnn_step, input_data, initial_state):\n  # [batch, time, features] -> [time, batch, features]\n  input_data = tf.transpose(input_data, [1, 0, 2])\n  max_seq_len = input_data.shape[0]\n\n  states = tf.TensorArray(tf.float32, size=max_seq_len)\n  state = initial_state\n  for i in tf.range(max_seq_len):\n    state = rnn_step(input_data[i], state)\n    states = states.write(i, state)\n  return tf.transpose(states.stack(), [1, 0, 2])\n\ndynamic_rnn(rnn_step,\n            tf.random.uniform([batch_size, seq_len, feature_size]),\n            tf.zeros([batch_size, feature_size]))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Uncertainty Surface in Python\nDESCRIPTION: Defines a function to plot the 2D uncertainty surface of the model predictions, including training data and out-of-domain examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef plot_uncertainty_surface(test_uncertainty, ax, cmap=None):\n  \"\"\"Visualizes the 2D uncertainty surface.\n  \n  For simplicity, assume these objects already exist in the memory:\n\n    test_examples: Array of test examples, shape (num_test, 2).\n    train_labels: Array of train labels, shape (num_train, ).\n    train_examples: Array of train examples, shape (num_train, 2).\n  \n  Arguments:\n    test_uncertainty: Array of uncertainty scores, shape (num_test,).\n    ax: A matplotlib Axes object that specifies a matplotlib figure.\n    cmap: A matplotlib colormap object specifying the palette of the\n      predictive surface.\n\n  Returns:\n    pcm: A matplotlib PathCollection object that contains the palette\n      information of the uncertainty plot.\n  \"\"\"\n  # Normalize uncertainty for better visualization.\n  test_uncertainty = test_uncertainty / np.max(test_uncertainty)\n\n  # Set view limits.\n  ax.set_ylim(DEFAULT_Y_RANGE)\n  ax.set_xlim(DEFAULT_X_RANGE)\n\n  # Plot normalized uncertainty surface.\n  pcm = ax.imshow(\n      np.reshape(test_uncertainty, [DEFAULT_N_GRID, DEFAULT_N_GRID]),\n      cmap=cmap,\n      origin=\"lower\",\n      extent=DEFAULT_X_RANGE + DEFAULT_Y_RANGE,\n      vmin=DEFAULT_NORM.vmin,\n      vmax=DEFAULT_NORM.vmax,\n      interpolation='bicubic',\n      aspect='auto')\n\n  # Plot training data.\n  ax.scatter(train_examples[:, 0], train_examples[:, 1],\n             c=train_labels, cmap=DEFAULT_CMAP, alpha=0.5)\n  ax.scatter(ood_examples[:, 0], ood_examples[:, 1], c=\"red\", alpha=0.1)\n\n  return pcm\n```\n\n----------------------------------------\n\nTITLE: Using a Python Generator\nDESCRIPTION: This snippet shows how to use the previously defined count generator in a for loop, printing the generated numbers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfor n in count(5):\n  print(n)\n```\n\n----------------------------------------\n\nTITLE: Reusing Traced Graphs with Same Input Types\nDESCRIPTION: Shows how tf.function reuses previously traced graphs when called with the same input types, avoiding retracing for performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# This doesn't print 'Tracing with ...'\nprint(double(tf.constant(\"b\")))\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for CVAE Implementation\nDESCRIPTION: Installs TensorFlow Probability for statistical distributions, and imageio with tensorflow/docs for generating GIFs and documentation support.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install tensorflow-probability\n\n# to generate gifs\n!pip install imageio\n!pip install git+https://github.com/tensorflow/docs\n```\n\n----------------------------------------\n\nTITLE: Displaying Model Outputs for Multilingual Text Generation\nDESCRIPTION: These snippets demonstrate how to access and display various outputs from the text generation model, including perplexity, token IDs, activation shape, and embeddings. This is useful for analyzing the model's performance and internal representations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nppl_result\n```\n\nLANGUAGE: Python\nCODE:\n```\ntoken_ids_result\n```\n\nLANGUAGE: Python\nCODE:\n```\nactivations_result.shape\n```\n\nLANGUAGE: Python\nCODE:\n```\nembeddings_result\n```\n\n----------------------------------------\n\nTITLE: Defining SIG Scope in Markdown\nDESCRIPTION: This snippet presents a section header for defining the scope of a Special Interest Group (SIG) within the TensorFlow community.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## Scope of a SIG\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Models Repository\nDESCRIPTION: Commands to download and access the Iris classification example code from TensorFlow's models repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tensorflow/models/\ncd models/samples/core/get_started\n```\n\n----------------------------------------\n\nTITLE: Dataset Creation in tf.function\nDESCRIPTION: Example showing how dataset creation works within tf.function when there's no variable creation involved.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.dataset = None\n\n  @tf.function\n  def __call__(self):\n    print(\"trace\") # This will print once: only traced once\n    if self.dataset is None:\n      self.dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n    it = iter(self.dataset)\n    return next(it)\n\nm = Model()\nm()\n```\n\n----------------------------------------\n\nTITLE: Implementing LoggingTensorHook and StopAtStepHook in TensorFlow 1\nDESCRIPTION: Demonstrates how to use LoggingTensorHook and StopAtStepHook with tf.estimator in TensorFlow 1. The hooks are used to log tensors and stop training at a specific step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/logging_stop_hook.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _model_fn(features, labels, mode):\n  dense = tf1.layers.Dense(1)\n  logits = dense(features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n\n  # Define the stop hook.\n  stop_hook = tf1.train.StopAtStepHook(num_steps=2)\n\n  # Access tensors to be logged by names.\n  kernel_name = tf.identity(dense.weights[0])\n  bias_name = tf.identity(dense.weights[1])\n  logging_weight_hook = tf1.train.LoggingTensorHook(\n      tensors=[kernel_name, bias_name],\n      every_n_iter=1)\n  # Log the training loss by the tensor object.\n  logging_loss_hook = tf1.train.LoggingTensorHook(\n      {'loss from LoggingTensorHook': loss},\n      every_n_secs=3)\n\n  # Pass all hooks to `EstimatorSpec`.\n  return tf1.estimator.EstimatorSpec(mode,\n                                     loss=loss,\n                                     train_op=train_op,\n                                     training_hooks=[stop_hook,\n                                                     logging_weight_hook,\n                                                     logging_loss_hook])\n\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\n\n# Begin training.\n# The training will stop after 2 steps, and the weights/loss will also be logged.\nestimator.train(_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Checking GPU Availability in Python\nDESCRIPTION: Demonstrates checking for GPU availability using TensorFlow and verifies whether specific operations are assigned to GPU or not.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.random.uniform([3, 3])\n\nprint(\"Is there a GPU available: \"),\nprint(tf.config.list_physical_devices('GPU'))\n\nprint(\"Is the Tensor on GPU #0:  \"),\nprint(x.device.endswith('GPU:0'))\n```\n\n----------------------------------------\n\nTITLE: Stochastic Network Depth Layer Definition in TensorFlow\nDESCRIPTION: This code defines a custom Keras layer called `StochasticNetworkDepth` that implements stochastic depth. During training, layers are randomly dropped based on a linearly decreasing probability schedule.  It leverages `tf.keras.backend.learning_phase()` to determine training mode and `tf.autograph.to_graph` for graph conversion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nK = tf.keras.backend\n\nclass StochasticNetworkDepth(tf.keras.Sequential):\n  def __init__(self, layers, pfirst=1.0, plast=0.5,**kwargs):\n    self.pfirst = pfirst\n    self.plast = plast\n    super(StochasticNetworkDepth, self).__init__(layers,**kwargs)\n\n  def build(self, input_shape):\n    self.depth = len(self.layers)\n    self.plims = np.linspace(self.pfirst, self.plast, self.depth + 1)[:-1]\n    super(StochasticNetworkDepth, self).build(input_shape.as_list())\n\n  def call(self, inputs):\n    training = tf.cast(K.learning_phase(), dtype=bool)\n    if not training:\n      count = self.depth\n      return super(StochasticNetworkDepth, self).call(inputs), count\n\n    p = tf.random_uniform((self.depth,))\n\n    keeps = (p <= self.plims)\n    x = inputs\n\n    count = tf.reduce_sum(tf.cast(keeps, tf.int32))\n    for i in range(self.depth):\n      if keeps[i]:\n        x = self.layers[i](x)\n\n    # return both the final-layer output and the number of layers executed.\n    return x, count\n\nStochasticNetworkDepth.call = tf.autograph.to_graph(StochasticNetworkDepth.call)\n```\n\n----------------------------------------\n\nTITLE: Initializing Common Imports and Visualization Functions\nDESCRIPTION: Sets up imports and defines a visualization function for displaying similarity matrices between embeddings using Bokeh plots.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title Setup common imports and functions\nimport bokeh\nimport bokeh.models\nimport bokeh.plotting\nimport numpy as np\nimport os\nimport pandas as pd\nimport tensorflow.compat.v2 as tf\nimport tensorflow_hub as hub\nfrom tensorflow_text import SentencepieceTokenizer\nimport sklearn.metrics.pairwise\n\nfrom simpleneighbors import SimpleNeighbors\nfrom tqdm import tqdm\nfrom tqdm import trange\n\ndef visualize_similarity(embeddings_1, embeddings_2, labels_1, labels_2,\n                         plot_title,\n                         plot_width=1200, plot_height=600,\n                         xaxis_font_size='12pt', yaxis_font_size='12pt'):\n\n  assert len(embeddings_1) == len(labels_1)\n  assert len(embeddings_2) == len(labels_2)\n\n  # arccos based text similarity (Yang et al. 2019; Cer et al. 2019)\n  sim = 1 - np.arccos(\n      sklearn.metrics.pairwise.cosine_similarity(embeddings_1,\n                                                 embeddings_2))/np.pi\n\n  embeddings_1_col, embeddings_2_col, sim_col = [], [], []\n  for i in range(len(embeddings_1)):\n    for j in range(len(embeddings_2)):\n      embeddings_1_col.append(labels_1[i])\n      embeddings_2_col.append(labels_2[j])\n      sim_col.append(sim[i][j])\n  df = pd.DataFrame(zip(embeddings_1_col, embeddings_2_col, sim_col),\n                    columns=['embeddings_1', 'embeddings_2', 'sim'])\n\n  mapper = bokeh.models.LinearColorMapper(\n      palette=[*reversed(bokeh.palettes.YlOrRd[9])], low=df.sim.min(),\n      high=df.sim.max())\n\n  p = bokeh.plotting.figure(title=plot_title, x_range=labels_1,\n                            x_axis_location=\"above\",\n                            y_range=[*reversed(labels_2)],\n                            plot_width=plot_width, plot_height=plot_height,\n                            tools=\"save\",toolbar_location='below', tooltips=[\n                                ('pair', '@embeddings_1 ||| @embeddings_2'),\n                                ('sim', '@sim')])\n  p.rect(x=\"embeddings_1\", y=\"embeddings_2\", width=1, height=1, source=df,\n         fill_color={'field': 'sim', 'transform': mapper}, line_color=None)\n\n  p.title.text_font_size = '12pt'\n  p.axis.axis_line_color = None\n  p.axis.major_tick_line_color = None\n  p.axis.major_label_standoff = 16\n  p.xaxis.major_label_text_font_size = xaxis_font_size\n  p.xaxis.major_label_orientation = 0.25 * np.pi\n  p.yaxis.major_label_text_font_size = yaxis_font_size\n  p.min_border_right = 300\n\n  bokeh.io.output_notebook()\n  bokeh.io.show(p)\n```\n\n----------------------------------------\n\nTITLE: Building and Preprocessing Image Dataset in TensorFlow\nDESCRIPTION: Creates training and validation datasets from the flower images directory with optional data augmentation. Includes normalization, random transformations, and proper batching for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef build_dataset(subset):\n  return tf.keras.preprocessing.image_dataset_from_directory(\n      data_dir,\n      validation_split=.20,\n      subset=subset,\n      label_mode=\"categorical\",\n      # Seed needs to provided when using validation_split and shuffle = True.\n      # A fixed seed is used so that the validation set is stable across runs.\n      seed=123,\n      image_size=IMAGE_SIZE,\n      batch_size=1)\n\ntrain_ds = build_dataset(\"training\")\nclass_names = tuple(train_ds.class_names)\ntrain_size = train_ds.cardinality().numpy()\ntrain_ds = train_ds.unbatch().batch(BATCH_SIZE)\ntrain_ds = train_ds.repeat()\n\nnormalization_layer = tf.keras.layers.Rescaling(1. / 255)\npreprocessing_model = tf.keras.Sequential([normalization_layer])\ndo_data_augmentation = False #@param {type:\"boolean\"}\nif do_data_augmentation:\n  preprocessing_model.add(\n      tf.keras.layers.RandomRotation(40))\n  preprocessing_model.add(\n      tf.keras.layers.RandomTranslation(0, 0.2))\n  preprocessing_model.add(\n      tf.keras.layers.RandomTranslation(0.2, 0))\n  # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n  # image sizes are fixed when reading, and then a random zoom is applied.\n  # If all training inputs are larger than image_size, one could also use\n  # RandomCrop with a batch size of 1 and rebatch later.\n  preprocessing_model.add(\n      tf.keras.layers.RandomZoom(0.2, 0.2))\n  preprocessing_model.add(\n      tf.keras.layers.RandomFlip(mode=\"horizontal\"))\ntrain_ds = train_ds.map(lambda images, labels:\n                        (preprocessing_model(images), labels))\n\nval_ds = build_dataset(\"validation\")\nvalid_size = val_ds.cardinality().numpy()\nval_ds = val_ds.unbatch().batch(BATCH_SIZE)\nval_ds = val_ds.map(lambda images, labels:\n                    (normalization_layer(images), labels))\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: License declaration for the TensorFlow documentation, specifying the Apache License 2.0 terms and conditions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Accuracy in TensorFlow with Matplotlib\nDESCRIPTION: This snippet creates a plot to visualize the training and validation accuracy over epochs using Matplotlib. It clears the previous figure, extracts accuracy data from the history dictionary, and plots the learning curves.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.clf()   # clear figure\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Implementing Training with Callbacks\nDESCRIPTION: Sets up training workflow with callbacks for model checkpointing, backup/restore functionality, and TensorBoard logging. Demonstrates how to configure working directories and execute model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nworking_dir = \"/tmp/my_working_dir\"\nlog_dir = os.path.join(working_dir, \"log\")\nckpt_filepath = os.path.join(working_dir, \"ckpt\")\nbackup_dir = os.path.join(working_dir, \"backup\")\n\ncallbacks = [\n    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n    tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath),\n    tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir),\n]\n\nmodel.fit(dataset, epochs=5, steps_per_epoch=20, callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Downloading the Flowers Dataset in TensorFlow\nDESCRIPTION: Downloads and extracts the flower_photos dataset using TensorFlow's utility function. This dataset contains images of different flower types for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata_dir = tf.keras.utils.get_file(\n    'flower_photos',\n    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n    untar=True)\n```\n\n----------------------------------------\n\nTITLE: Accessing Dimension Value in TF1.x Style\nDESCRIPTION: Shows the TensorFlow 1.x approach to accessing a dimension value from a TensorShape object, which requires the .value attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nvalue = shape[i].value\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow\nDESCRIPTION: Basic TensorFlow import statement for eager execution mode\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Loading Model Graph from Disk in TensorFlow\nDESCRIPTION: This function loads a pre-defined TensorFlow model's graph definition from a file, creating a session object for running the model later.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_8\n\nLANGUAGE: C++\nCODE:\n```\nStatus LoadGraph(string graph_file_name,\n                 std::unique_ptr<tensorflow::Session>* session) {\n  tensorflow::GraphDef graph_def;\n  Status load_graph_status =\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\n  if (!load_graph_status.ok()) {\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\n                                        graph_file_name, \"'\");\n  }\n\n  session->reset(tensorflow::NewSession(tensorflow::SessionOptions()));\n  Status session_create_status = (*session)->Create(graph_def);\n  if (!session_create_status.ok()) {\n    return session_create_status;\n  }\n  return Status::OK();\n}\n```\n\n----------------------------------------\n\nTITLE: Combining tf.gather_nd and tf.scatter_nd for Sparse Operations\nDESCRIPTION: Demonstrates how to use tf.gather_nd to collect values from one tensor and then use tf.scatter_nd to place them into a new tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Gather values from one tensor by specifying indices\n\nnew_indices = tf.constant([[0, 2], [2, 1], [3, 3]])\nt7 = tf.gather_nd(t2, indices=new_indices)\n```\n\n----------------------------------------\n\nTITLE: Plotting U-Net Model Architecture in TensorFlow\nDESCRIPTION: This code uses Keras utilities to visualize the U-Net model architecture, showing shapes and expanding nested layers for a detailed view.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, dpi=64)\n```\n\n----------------------------------------\n\nTITLE: Defining Image Display Utility Functions\nDESCRIPTION: Implements helper functions for image grid creation, array interleaving, image display, and float to uint8 conversion for visualization purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef imgrid(imarray, cols=4, pad=1, padval=255, row_major=True):\n  \"\"\"Lays out a [N, H, W, C] image array as a single image grid.\"\"\"\n  pad = int(pad)\n  if pad < 0:\n    raise ValueError('pad must be non-negative')\n  cols = int(cols)\n  assert cols >= 1\n  N, H, W, C = imarray.shape\n  rows = N // cols + int(N % cols != 0)\n  batch_pad = rows * cols - N\n  assert batch_pad >= 0\n  post_pad = [batch_pad, pad, pad, 0]\n  pad_arg = [[0, p] for p in post_pad]\n  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=padval)\n  H += pad\n  W += pad\n  grid = (imarray\n          .reshape(rows, cols, H, W, C)\n          .transpose(0, 2, 1, 3, 4)\n          .reshape(rows*H, cols*W, C))\n  if pad:\n    grid = grid[:-pad, :-pad]\n  return grid\n\ndef interleave(*args):\n  \"\"\"Interleaves input arrays of the same shape along the batch axis.\"\"\"\n  if not args:\n    raise ValueError('At least one argument is required.')\n  a0 = args[0]\n  if any(a.shape != a0.shape for a in args):\n    raise ValueError('All inputs must have the same shape.')\n  if not a0.shape:\n    raise ValueError('Inputs must have at least one axis.')\n  out = np.transpose(args, [1, 0] + list(range(2, len(a0.shape) + 1)))\n  out = out.reshape(-1, *a0.shape[1:])\n  return out\n\ndef imshow(a, format='png', jpeg_fallback=True):\n  \"\"\"Displays an image in the given format.\"\"\"\n  a = a.astype(np.uint8)\n  data = io.BytesIO()\n  PIL.Image.fromarray(a).save(data, format)\n  im_data = data.getvalue()\n  try:\n    disp = IPython.display.display(IPython.display.Image(im_data))\n  except IOError:\n    if jpeg_fallback and format != 'jpeg':\n      print ('Warning: image was too large to display in format \"{}\"; '\n             'trying jpeg instead.').format(format)\n      return imshow(a, format='jpeg')\n    else:\n      raise\n  return disp\n\ndef image_to_uint8(x):\n  \"\"\"Converts [-1, 1] float array to [0, 255] uint8.\"\"\"\n  x = np.asarray(x)\n  x = (256. / 2.) * (x + 1.)\n  x = np.clip(x, 0, 255)\n  x = x.astype(np.uint8)\n  return x\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow for Specific CPU Architecture with Bazel\nDESCRIPTION: This Python command uses Bazel to compile TensorFlow targeting Intel's Broadwell processor with specific compiler options. It's an example of tuning build settings to leverage CPU-specific optimizations for better model performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# This command optimizes for Intel’s Broadwell processor\nbazel build -c opt --copt=-march=\"broadwell\" --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n\n----------------------------------------\n\nTITLE: Cropping and Resizing Image for MoveNet Input\nDESCRIPTION: Prepares the input image for the MoveNet model by cropping and resizing it based on the determined crop region. This ensures the input is in the correct format for inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef crop_and_resize(image, crop_region, crop_size):\n  \"\"\"Crops and resize the image to prepare for the model input.\"\"\"\n  boxes=[[crop_region['y_min'], crop_region['x_min'],\n          crop_region['y_max'], crop_region['x_max']]]\n  output_image = tf.image.crop_and_resize(\n      image, box_indices=[0], boxes=boxes, crop_size=crop_size)\n  return output_image\n```\n\n----------------------------------------\n\nTITLE: Defining Utility Functions for GAN Image Generation and Visualization\nDESCRIPTION: This code block defines several utility functions for interpolating between vectors, displaying images, and creating animations from generated images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef interpolate_hypersphere(v1, v2, num_steps):\n  v1_norm = tf.norm(v1)\n  v2_norm = tf.norm(v2)\n  v2_normalized = v2 * (v1_norm / v2_norm)\n\n  vectors = []\n  for step in range(num_steps):\n    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n    interpolated_norm = tf.norm(interpolated)\n    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n    vectors.append(interpolated_normalized)\n  return tf.stack(vectors)\n\ndef display_image(image):\n  image = tf.constant(image)\n  image = tf.image.convert_image_dtype(image, tf.uint8)\n  return PIL.Image.fromarray(image.numpy())\n\ndef animate(images):\n  images = np.array(images)\n  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n  imageio.mimsave('./animation.gif', converted_images)\n  return embed.embed_file('./animation.gif')\n\nlogging.set_verbosity(logging.ERROR)\n```\n\n----------------------------------------\n\nTITLE: Checking First Worker Log After Training\nDESCRIPTION: This bash command displays the updated log file of the first worker to verify its participation in the distributed training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\ncat job_0.log\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Combined Type Constraints\nDESCRIPTION: Shows how to register an op that accepts either numeric types or boolean type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_19\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"NumberOrBooleanType\")\n    .Attr(\"t: {numbertype, bool}\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Pipeline for Image Segmentation\nDESCRIPTION: This snippet sets up the data pipeline, including dataset splitting, batching, and applying data augmentation for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nTRAIN_LENGTH = info.splits['train'].num_examples\nBATCH_SIZE = 64\nBUFFER_SIZE = 1000\nSTEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n\ntrain_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n\nclass Augment(tf.keras.layers.Layer):\n  def __init__(self, seed=42):\n    super().__init__()\n    self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n    self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n\n  def call(self, inputs, labels):\n    inputs = self.augment_inputs(inputs)\n    labels = self.augment_labels(labels)\n    return inputs, labels\n\ntrain_batches = (\n    train_images\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE)\n    .repeat()\n    .map(Augment())\n    .prefetch(buffer_size=tf.data.AUTOTUNE))\n\ntest_batches = test_images.batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Verifying Remaining TensorFlow 1.x Compatible Layer Names\nDESCRIPTION: This snippet demonstrates how to verify that the remaining TensorFlow 1.x compatible layers maintain their expected variable names after partial migration to native Keras layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nweights = set(v.name for v in layer.weights)\nassert 'model/conv2d_2/kernel:0' in weights\nassert 'model/conv2d_2/bias:0' in weights\n```\n\n----------------------------------------\n\nTITLE: Accessing a Test Label\nDESCRIPTION: This snippet shows how to access the actual label for the first image in the test set. `test_labels` is assumed to be an array containing the true labels for the test images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_labels[0]\n```\n\n----------------------------------------\n\nTITLE: Creating Training and Evaluation Datasets\nDESCRIPTION: Defines functions to create training and evaluation datasets with proper batching and prefetching. Uses DatasetCreator with TPU-specific input options and fixed batch sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 8\n\ndef _input_dataset(context: tf.distribute.InputContext):\n  dataset = tf.data.Dataset.from_tensor_slices((\n      {\"dense_feature\": features,\n       \"sparse_feature\": tf.SparseTensor(\n           embedding_features_indices,\n           embedding_features_values, [1, 2])},\n           labels))\n  dataset = dataset.shuffle(10).repeat()\n  dataset = dataset.batch(\n      context.get_per_replica_batch_size(global_batch_size),\n      drop_remainder=True)\n  return dataset.prefetch(2)\n\ndef _eval_dataset(context: tf.distribute.InputContext):\n  dataset = tf.data.Dataset.from_tensor_slices((\n      {\"dense_feature\": eval_features,\n       \"sparse_feature\": tf.SparseTensor(\n           eval_embedding_features_indices,\n           eval_embedding_features_values, [1, 2])},\n           eval_labels))\n  dataset = dataset.repeat()\n  dataset = dataset.batch(\n      context.get_per_replica_batch_size(global_batch_size),\n      drop_remainder=True)\n  return dataset.prefetch(2)\n\ninput_options = tf.distribute.InputOptions(\n    experimental_fetch_to_device=False)\n\ninput_dataset = tf.keras.utils.experimental.DatasetCreator(\n    _input_dataset, input_options=input_options)\n\neval_dataset = tf.keras.utils.experimental.DatasetCreator(\n    _eval_dataset, input_options=input_options)\n```\n\n----------------------------------------\n\nTITLE: Setting TF_CONFIG for Multi-worker Training - Python\nDESCRIPTION: This code snippet sets the TF_CONFIG environment variable as a JSON string for TensorFlow's multi-worker training setup. It defines the cluster configuration with hosts and ports for workers and parameter servers, along with the role of the current task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"TF_CONFIG\"] = json.dumps({\n    \"cluster\": {\n        \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n        \"ps\": [\"host4:port\", \"host5:port\"]\n    },\n   \"task\": {\"type\": \"worker\", \"index\": 1}\n})\n```\n\n----------------------------------------\n\nTITLE: Audio Processing Functions\nDESCRIPTION: Utility functions for framing audio and ensuring correct sample rate for model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef frame_audio(\n      audio_array: np.ndarray,\n      window_size_s: float = 5.0,\n      hop_size_s: float = 5.0,\n      sample_rate = 32000,\n  ) -> np.ndarray:\n    \"\"\"Helper function for framing audio for inference.\"\"\"\n    if window_size_s is None or window_size_s < 0:\n      return audio_array[np.newaxis, :]\n    frame_length = int(window_size_s * sample_rate)\n    hop_length = int(hop_size_s * sample_rate)\n    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n    return framed_audio\n\ndef ensure_sample_rate(waveform, original_sample_rate,\n                       desired_sample_rate=32000):\n  \"\"\"Resample waveform if required.\"\"\"\n  if original_sample_rate != desired_sample_rate:\n    waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n  return desired_sample_rate, waveform\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Estimator Model\nDESCRIPTION: Trains the Estimator model using the specified input function for 100 steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = model.train(input_fn=train_input_fn, steps=100)\n```\n\n----------------------------------------\n\nTITLE: Configuring Test Dataset Pipeline\nDESCRIPTION: Sets up the test dataset pipeline similar to the validation pipeline, applying only the necessary preprocessing without augmentation. This ensures consistent evaluation of the final model on clean test data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ntest_ds = (\n    test_ds\n    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Parsing Class Names from CSV for YAMNet Model in Python\nDESCRIPTION: This function reads class names from a CSV file provided with the YAMNet model. It's used to map numerical class predictions to human-readable labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/yamnet.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef class_names_from_csv(class_map_csv_text):\n  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n  class_names = []\n  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n      class_names.append(row['display_name'])\n\n  return class_names\n\nclass_map_path = model.class_map_path().numpy()\nclass_names = class_names_from_csv(class_map_path)\n```\n\n----------------------------------------\n\nTITLE: Using Generators with tf.function\nDESCRIPTION: Examples showing different ways to use random number generators with tf.function decorators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef foo():\n  return g.normal([])\nprint(foo())\n```\n\n----------------------------------------\n\nTITLE: Creating a Keras Callback for Step-Based Interruption\nDESCRIPTION: Defining a custom Keras callback that counts training steps and artificially raises a RuntimeError at a specified step count to simulate training failure at a particular step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass InterruptAtStep(tf.keras.callbacks.Callback):\n  # A callback for artificially interrupting training.\n  def __init__(self, interrupting_step=140):\n    self.total_step_count = 0\n    self.interrupting_step = interrupting_step\n\n  def on_batch_begin(self, batch, logs=None):\n    self.total_step_count += 1\n\n  def on_batch_end(self, batch, logs=None):\n    if self.total_step_count == self.interrupting_step:\n      print(\"\\nInterrupting at step count\", self.total_step_count)\n      raise RuntimeError('Interruption')\n```\n\n----------------------------------------\n\nTITLE: Preparing Test Dataset Pipeline\nDESCRIPTION: Sets up the test dataset pipeline with normalization, batching, caching, and prefetching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nds_test = ds_test.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_test = ds_test.batch(batch_size)\nds_test = ds_test.cache()\nds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Device Placement Logging\nDESCRIPTION: This snippet imports TensorFlow and optionally enables device placement logging for debugging purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Uncomment to see where your variables get placed (see below)\n# tf.debugging.set_log_device_placement(True)\n```\n\n----------------------------------------\n\nTITLE: Creating Indicator Column in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to represent a categorical column as an indicator column using TensorFlow's feature column API. This method is suitable for cases with a limited number of categories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nindicator_column = tf.feature_column.indicator_column(categorical_column)\n```\n\n----------------------------------------\n\nTITLE: Synthesizing Training Data\nDESCRIPTION: This snippet generates synthetic training data for the model. It creates inputs based on a true linear relationship, with added noise to simulate real-world conditions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nTRUE_W = 3.0\nTRUE_b = 2.0\nNUM_EXAMPLES = 1000\n\ninputs  = tf.random_normal(shape=[NUM_EXAMPLES])\nnoise   = tf.random_normal(shape=[NUM_EXAMPLES])\noutputs = inputs * TRUE_W + TRUE_b + noise\n```\n\n----------------------------------------\n\nTITLE: Using NumberType Op in Python\nDESCRIPTION: Python examples showing valid and invalid usage of the NumberType op.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ntf.number_type(t=tf.int32)  # Valid\ntf.number_type(t=tf.bool)   # Invalid\n```\n\n----------------------------------------\n\nTITLE: Updating Local TensorFlow Docs Repository\nDESCRIPTION: This snippet shows the commands to update your local repository with changes from the upstream TensorFlow docs repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout master\ngit pull upstream master\n\ngit push\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Data Analysis (Python)\nDESCRIPTION: This snippet imports essential libraries such as matplotlib for plotting, pandas for data manipulation, seaborn for statistical visualization, and TensorFlow for building the model. It also sets TensorFlow to version 1 compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Exploring Dataset for Iliad Translations\nDESCRIPTION: Downloads text files containing translations of Homer's Iliad by different authors and explores the directory structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nDIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\nFILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n\nfor name in FILE_NAMES:\n  text_dir = utils.get_file(name, origin=DIRECTORY_URL + name)\n\nparent_dir = pathlib.Path(text_dir).parent\nlist(parent_dir.iterdir())\n```\n\n----------------------------------------\n\nTITLE: Plotting Precision-Recall Curve in Python for TensorFlow Model\nDESCRIPTION: This function plots the Precision-Recall Curve (PRC) using scikit-learn's precision_recall_curve function. It visualizes the trade-off between precision and recall for different thresholds.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef plot_prc(name, labels, predictions, **kwargs):\n    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n\n    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n    plt.xlabel('Precision')\n    plt.ylabel('Recall')\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')\n```\n\n----------------------------------------\n\nTITLE: Creating Spectrogram Dataset from Audio\nDESCRIPTION: Utility function to transform audio dataset into spectrogram dataset using tf.data API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef make_spec_ds(ds):\n  return ds.map(\n      map_func=lambda audio,label: (get_spectrogram(audio), label),\n      num_parallel_calls=tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Numeric Features with Normalization\nDESCRIPTION: Concatenates numeric inputs and applies a normalization layer that adapts to the data distribution, preparing numeric features for model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nnumeric_inputs = {name:input for name,input in inputs.items()\n                  if input.dtype==tf.float32}\n\nx = layers.Concatenate()(list(numeric_inputs.values()))\nnorm = layers.Normalization()\nnorm.adapt(np.array(titanic[numeric_inputs.keys()]))\nall_numeric_inputs = norm(x)\n\nall_numeric_inputs\n```\n\n----------------------------------------\n\nTITLE: Checking Available GPU Devices\nDESCRIPTION: Lists all physical GPU devices available to TensorFlow in the current environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.config.list_physical_devices('GPU'))\n```\n\n----------------------------------------\n\nTITLE: Installing MSYS2 Tools for TensorFlow Build on Windows\nDESCRIPTION: Commands to install and configure MSYS2 package manager and the required Unix-like tools (git, patch, unzip, rsync) needed for building TensorFlow on Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npacman -Syu (requires a console restart)\npacman -S git patch unzip\npacman -S git patch unzip rsync\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Accuracy\nDESCRIPTION: Create a visualization of training and validation accuracy to analyze model performance and identify potential overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.clf()   # clear figure\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss in TensorFlow with Matplotlib\nDESCRIPTION: Visualizing the training and validation loss over epochs using Matplotlib. This plot helps identify overfitting by comparing how loss changes during training versus validation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nacc = history_dict['binary_accuracy']\nval_acc = history_dict['val_binary_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Transcoding a UTF-8 String to UTF-16-BE\nDESCRIPTION: This code snippet demonstrates the transcode operation that converts an encoded string scalar from UTF-8 to UTF-16-BE in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_transcode(text_utf8,\n                             input_encoding='UTF8',\n                             output_encoding='UTF-16-BE')\n```\n\n----------------------------------------\n\nTITLE: Converting a SparseTensor to Dense Representation\nDESCRIPTION: Shows how to convert a SparseTensor into a dense tensor with tf.sparse.to_dense.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Convert the sparse tensor into a dense tensor\n\nt10 = tf.sparse.to_dense(t9)\n\nprint(t10)\n```\n\n----------------------------------------\n\nTITLE: Waiting for Worker Process to Start\nDESCRIPTION: This code implements a simple delay to allow time for the worker process to initialize before proceeding with further operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimport time\ntime.sleep(20)\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Session for Mandelbrot Set Computation\nDESCRIPTION: This snippet creates an interactive TensorFlow session and initializes the complex number grid for the Mandelbrot set computation using NumPy and TensorFlow tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/mandelbrot.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsess = tf.InteractiveSession()\n\n# Use NumPy to create a 2D array of complex numbers\n\nY, X = np.mgrid[-1.3:1.3:0.005, -2:1:0.005]\nZ = X+1j*Y\n\nxs = tf.constant(Z.astype(np.complex64))\nzs = tf.Variable(xs)\nns = tf.Variable(tf.zeros_like(xs, tf.float32))\n\ntf.global_variables_initializer().run()\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Scalar with 2D RaggedTensor\nDESCRIPTION: Demonstrates broadcasting between a scalar value and a 2D ragged tensor, resulting in the scalar being added to each element.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_48\n\nLANGUAGE: python\nCODE:\n```\n# x       (2D ragged):  2 x (num_rows)\n# y       (scalar)\n# result  (2D ragged):  2 x (num_rows)\nx = tf.ragged.constant([[1, 2], [3]])\ny = 3\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Testing Embeddings\nDESCRIPTION: Testing the embedding layer with sample Bangla words.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nembedding_layer(['বাস', 'বসবাস', 'ট্রেন', 'যাত্রী', 'ট্রাক'])\n```\n\n----------------------------------------\n\nTITLE: Using tf.function with Sparse Tensors in TensorFlow\nDESCRIPTION: This snippet shows how to use the tf.function decorator with sparse tensors to precompute TensorFlow graphs for improved performance. It demonstrates sparse-dense matrix multiplication with a concrete example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f(x,y):\n  return tf.sparse.sparse_dense_matmul(x,y)\n\na = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n                    values=[15, 25],\n                    dense_shape=[3, 10])\n\nb = tf.sparse.to_dense(tf.sparse.transpose(a))\n\nc = f(a,b)\n\nprint(c)\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow 1.x checkpoint in eager mode using Python\nDESCRIPTION: Creates variables with matching names and loads a TF1 checkpoint using tf.compat.v1.train.Saver in eager mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(0.0, name='a')\nb = tf.Variable(0.0, name='b')\nwith tf.name_scope('scoped'):\n  c = tf.Variable(0.0, name='c')\n\n# With the removal of collections in TF2, you must pass in the list of variables\n# to the Saver object:\nsaver = tf1.train.Saver(var_list=[a, b, c])\nsaver.restore(sess=None, save_path=save_path)\nprint(f\"loaded values of [a, b, c]:  [{a.numpy()}, {b.numpy()}, {c.numpy()}]\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Batch of Images with Labels\nDESCRIPTION: Creates a grid of images from a batch with their corresponding class labels. This helps verify that images and labels are correctly paired.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimage_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n  label = label_batch[i]\n  plt.title(class_names[label])\n  plt.axis(\"off\")\n```\n\n----------------------------------------\n\nTITLE: Converting Ragged Tensors to Python Lists and NumPy Arrays\nDESCRIPTION: Shows how to convert ragged tensors to nested Python lists and NumPy arrays for compatibility with non-TensorFlow code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndigits.to_list()\n```\n\nLANGUAGE: python\nCODE:\n```\ndigits.numpy()\n```\n\n----------------------------------------\n\nTITLE: Randomly Cropping Images with Stateless Operations\nDESCRIPTION: Demonstrates tf.image.stateless_random_crop for deterministic random cropping. The example shows how different seeds produce different crop locations while maintaining the specified output dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(3):\n  seed = (i, 0)  # tuple of size (2,)\n  stateless_random_crop = tf.image.stateless_random_crop(\n      image, size=[210, 300, 3], seed=seed)\n  visualize(image, stateless_random_crop)\n```\n\n----------------------------------------\n\nTITLE: Repeat-then-Shuffle Pattern in TensorFlow\nDESCRIPTION: Demonstrates the repeat-then-shuffle pattern which mixes elements across epoch boundaries, and examines indices near the expected epoch boundary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_71\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.zip((counter, lines))\nshuffled = dataset.repeat(2).shuffle(buffer_size=100).batch(10)\n\nprint(\"Here are the item ID's near the epoch boundary:\\n\")\nfor n, line_batch in shuffled.skip(55).take(15):\n  print(n.numpy())\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow CPU Package\nDESCRIPTION: Command to build a TensorFlow CPU pip package using the WHEEL_NAME environment variable. This generates a wheel file in the specified output directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nbazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu\n```\n\n----------------------------------------\n\nTITLE: Loading IMDB Dataset using TensorFlow Datasets\nDESCRIPTION: This code snippet downloads and loads the IMDB dataset using TensorFlow Datasets. It splits the data into training and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntrain_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n                                  batch_size=-1, as_supervised=True)\n\ntrain_examples, train_labels = tfds.as_numpy(train_data)\ntest_examples, test_labels = tfds.as_numpy(test_data)\n```\n\n----------------------------------------\n\nTITLE: Creating a Distributed Dataset with MirroredStrategy in TensorFlow\nDESCRIPTION: This code shows how to create a distributed dataset using tf.distribute.MirroredStrategy. It defines a dataset_fn that handles sharding and batching based on the input context.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndef dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n  dataset = dataset.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n  dataset = dataset.batch(batch_size)\n  dataset = dataset.prefetch(2)  # This prefetches 2 batches per device.\n  return dataset\n\ndist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)\n```\n\n----------------------------------------\n\nTITLE: Converting Image Range for MobileNetV2 Input\nDESCRIPTION: Defines a function to transform image values from the range [0,1] to [-1,1] which is required by MobileNetV2's preprocessing expectations. The function maintains the original label while transforming the image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef change_range(image,label):\n  return 2*image-1, label\n\nkeras_ds = ds.map(change_range)\n```\n\n----------------------------------------\n\nTITLE: Creating Text Embedding Layer using TensorFlow Hub\nDESCRIPTION: This code creates a Keras layer using a pre-trained TensorFlow Hub model for text embedding. It demonstrates the layer's output on a few examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\nhub_layer(train_examples[:3])\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for ESRGAN Model\nDESCRIPTION: Declares constants for the input image path and the TensorFlow Hub model URL for ESRGAN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Declaring Constants\nIMAGE_PATH = \"original.png\"\nSAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n```\n\n----------------------------------------\n\nTITLE: Using tf.function with FizzBuzz Example\nDESCRIPTION: Demonstrates the tf.function decorator with AutoGraph, implementing the FizzBuzz algorithm with conditionals and while loops that get converted to graph operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=tf.autograph.experimental.Feature.EQUALITY_OPERATORS)\ndef fizzbuzz(i, n):\n  while i < n:\n    msg = ''\n    if i % 3 == 0:\n      msg += 'Fizz'\n    if i % 5 == 0:\n      msg += 'Buzz'\n    if msg == '':\n      msg = tf.as_string(i)\n    tf.print(msg)\n    i += 1\n  return i\n\nwith tf.Graph().as_default():\n  final_i = fizzbuzz(tf.constant(10), tf.constant(16))\n  # The result works like a regular op: takes tensors in, returns tensors.\n  # You can inspect the graph using tf.get_default_graph().as_graph_def()\n  with tf.Session() as sess:\n    sess.run(final_i)\n```\n\n----------------------------------------\n\nTITLE: Accessing Attribute in TensorFlow Op Kernel (C++)\nDESCRIPTION: This snippet demonstrates how to access an attribute (defined during op registration) within a TensorFlow OpKernel's constructor. It uses `context->GetAttr` to retrieve the value of `preserve_index` and stores it in a member variable, also validating the attribute's value. It also shows how `OP_REQUIRES_OK` and `OP_REQUIRES` are used to ensure the attribute is valid.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_10\n\nLANGUAGE: c++\nCODE:\n```\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {\n    // Get the index of the value to preserve\n    OP_REQUIRES_OK(context,\n                   context->GetAttr(\"preserve_index\", &preserve_index_));\n    // Check that preserve_index is positive\n    OP_REQUIRES(context, preserve_index_ >= 0,\n                errors::InvalidArgument(\"Need preserve_index >= 0, got \",\n                                        preserve_index_));\n  }\n  void Compute(OpKernelContext* context) override {\n    // ...\n  }\n private:\n  int preserve_index_;\n};\n```\n\n----------------------------------------\n\nTITLE: Verifying TensorFlow GPU Installation\nDESCRIPTION: This Python command checks for available GPU devices to confirm that TensorFlow can access the GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npython3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n```\n\n----------------------------------------\n\nTITLE: Applying Dataset Transformations in Python\nDESCRIPTION: This code applies shuffle, repeat, and batch transformations to a tf.data.Dataset to prepare it for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Shuffle, repeat, and batch the examples.\ndataset = dataset.shuffle(1000).repeat().batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Overlaying Predicted Pitches on Spectrogram in Python\nDESCRIPTION: This code overlays the predicted pitch values on the original spectrogram. It uses a black and white spectrogram for better visibility of the pitch predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplot_stft(audio_samples / MAX_ABS_INT16 , \n          sample_rate=EXPECTED_SAMPLE_RATE, show_black_and_white=True)\n# Note: conveniently, since the plot is in log scale, the pitch outputs \n# also get converted to the log scale automatically by matplotlib.\nplt.scatter(confident_pitch_outputs_x, confident_pitch_values_hz, c=\"r\")\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Global List Manipulation in TF1.x\nDESCRIPTION: Example showing how global list manipulation works in TF1.x where Python logic runs only once during graph construction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nall_losses = []\n\nclass Model():\n  def __call__(...):\n    ...\n    all_losses.append(regularization_loss)\n    all_losses.append(label_loss_a)\n    all_losses.append(label_loss_b)\n    ...\n\ng = tf.Graph()\nwith g.as_default():\n  ...\n  # initialize all objects\n  model = Model()\n  optimizer = ...\n  ...\n  # train step\n  model(...)\n  total_loss = tf.reduce_sum(all_losses)\n  optimizer.minimize(total_loss)\n  ...\n...\nsess = tf.compat.v1.Session(graph=g)\nsess.run(...)\n```\n\n----------------------------------------\n\nTITLE: Verifying NVIDIA GPU Driver Installation\nDESCRIPTION: Command to check if NVIDIA GPU driver is properly installed and recognized by the system\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nnvidia-smi\n```\n\n----------------------------------------\n\nTITLE: Resuming Training from Checkpoint in TensorFlow 1\nDESCRIPTION: Recreating the classifier with the same model directory to automatically restore from the last saved checkpoint and continue training from where it was interrupted.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf1.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf1.train.AdamOptimizer(0.001),\n    n_classes=10,\n    dropout=0.2,\n    model_dir=path,\n    config = config\n)\nclassifier.train(input_fn=train_input_fn,\n                   max_steps = 10)\n```\n\n----------------------------------------\n\nTITLE: Using Attributes in TensorFlow Op Compute Method\nDESCRIPTION: C++ implementation of a TensorFlow op's Compute method that uses a stored attribute value. This example uses the 'preserve_index' attribute to determine which element of the input tensor to preserve while zeroing out others.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_14\n\nLANGUAGE: c++\nCODE:\n```\n  void Compute(OpKernelContext* context) override {\n    // ...\n\n    // We're using saved attr to validate potentially dynamic input\n    // So we check that preserve_index is in range\n    OP_REQUIRES(context, preserve_index_ < input.dimension(0),\n                errors::InvalidArgument(\"preserve_index out of range\"));\n\n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the requested input value\n    output_flat(preserve_index_) = input(preserve_index_);\n  }\n```\n\n----------------------------------------\n\nTITLE: Loading YAMNet Model from TensorFlow Hub\nDESCRIPTION: Loads the pre-trained YAMNet model from TensorFlow Hub, which can classify audio events from 521 classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nyamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\nyamnet_model = hub.load(yamnet_model_handle)\n```\n\n----------------------------------------\n\nTITLE: Setting Train-Test Split\nDESCRIPTION: Defining the training data fraction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntrain_frac = 0.8\ntrain_size = int(len(file_paths) * train_frac)\n```\n\n----------------------------------------\n\nTITLE: Implementing OpKernel and CPU Functor in C++\nDESCRIPTION: This snippet shows the implementation of the OpKernel and CPU functor for the 'Example' operation, including op registration and CPU-specific computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_4\n\nLANGUAGE: C++\nCODE:\n```\n#include \"kernel_example.h\"\n\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nusing CPUDevice = Eigen::ThreadPoolDevice;\nusing GPUDevice = Eigen::GpuDevice;\n\nREGISTER_OP(\"Example\")\n    .Attr(\"T: numbertype\")\n    .Input(\"input: T\")\n    .Output(\"input_times_two: T\")\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\n// CPU specialization of actual computation.\ntemplate <typename T>\nstruct ExampleFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, int size, const T* in, T* out) {\n    for (int i = 0; i < size; ++i) {\n      out[i] = 2 * in[i];\n    }\n  }\n};\n\n// OpKernel definition.\n// template parameter <T> is the datatype of the tensors.\ntemplate <typename Device, typename T>\nclass ExampleOp : public OpKernel {\n public:\n  explicit ExampleOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n\n    // Do the computation.\n    OP_REQUIRES(context, input_tensor.NumElements() <= tensorflow::kint32max,\n                errors::InvalidArgument(\"Too many elements in tensor\"));\n    ExampleFunctor<Device, T>()(\n        context->eigen_device<Device>(),\n        static_cast<int>(input_tensor.NumElements()),\n        input_tensor.flat<T>().data(),\n        output_tensor->flat<T>().data());\n  }\n};\n\n// Register the CPU kernels.\n#define REGISTER_CPU(T)                                          \\\n  REGISTER_KERNEL_BUILDER(                                       \\\n      Name(\"Example\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      ExampleOp<CPUDevice, T>);\nREGISTER_CPU(float);\nREGISTER_CPU(int32);\n\n// Register the GPU kernels.\n#ifdef GOOGLE_CUDA\n#define REGISTER_GPU(T)                                          \\\n  /* Declare explicit instantiations in kernel_example.cu.cc. */ \\\n  extern template class ExampleFunctor<GPUDevice, T>;            \\\n  REGISTER_KERNEL_BUILDER(                                       \\\n      Name(\"Example\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n      ExampleOp<GPUDevice, T>);\nREGISTER_GPU(float);\nREGISTER_GPU(int32);\n#endif  // GOOGLE_CUDA\n```\n\n----------------------------------------\n\nTITLE: Setting PATH for Bazel and Python in MSYS Shell\nDESCRIPTION: Commands to add Bazel and Python installation directories to the PATH environment variable when building TensorFlow using the MSYS shell.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n# Use Unix-style with ':' as separator\nexport PATH=\"/c/tools:$PATH\"\nexport PATH=\"/c/path/to/Python:$PATH\"\n```\n\n----------------------------------------\n\nTITLE: Testing Attribute Deletion Prevention in ExtensionType in Python\nDESCRIPTION: Shows that ExtensionType prevents attribute deletion by overriding __delattr__ to enforce immutability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  del mt.mask\nexcept AttributeError as e:\n  print(f\"Got expected AttributeError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Creating complex TensorFlow 2.x Checkpoint structure in Python\nDESCRIPTION: Demonstrates how to create a more complex Checkpoint object structure and how it affects the checkpoint keys.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodule = tf.Module()\nmodule.d = tf.Variable(0.)\ntest_ckpt = tf.train.Checkpoint(v={'a': a, 'b': b}, \n                                c=c,\n                                module=module)\ntest_ckpt_path = test_ckpt.save('root-tf2-ckpt')\nprint_checkpoint(test_ckpt_path)\n```\n\n----------------------------------------\n\nTITLE: Gathering Multiple Matrix Slices with tf.gather_nd\nDESCRIPTION: Shows how to extract multiple matrices from a 3D tensor by specifying paired index coordinates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Return a list of two matrices\n\nprint(tf.gather_nd(t5,\n                   indices=[[[0, 0], [0, 2]], [[1, 0], [1, 2]]]))\n```\n\n----------------------------------------\n\nTITLE: Converting Pitch Outputs to Hz in Python\nDESCRIPTION: This function converts pitch outputs from SPICE to absolute pitch values in Hz using constants from the SPICE model. It then applies this conversion to the confident pitch outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef output2hz(pitch_output):\n  # Constants taken from https://tfhub.dev/google/spice/2\n  PT_OFFSET = 25.58\n  PT_SLOPE = 63.07\n  FMIN = 10.0;\n  BINS_PER_OCTAVE = 12.0;\n  cqt_bin = pitch_output * PT_SLOPE + PT_OFFSET;\n  return FMIN * 2.0 ** (1.0 * cqt_bin / BINS_PER_OCTAVE)\n    \nconfident_pitch_values_hz = [ output2hz(p) for p in confident_pitch_outputs_y ]\n```\n\n----------------------------------------\n\nTITLE: Profiling Multiple Workers with gRPC in Python\nDESCRIPTION: Profile multiple workers in a distributed training setup using gRPC. This method allows for capturing profiles from multiple machines simultaneously.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# E.g., your worker IP addresses are 10.0.0.2, 10.0.0.3, 10.0.0.4, and you\n# would like to profile for a duration of 2 seconds.\ntf.profiler.experimental.client.trace(\n    'grpc://10.0.0.2:8466,grpc://10.0.0.3:8466,grpc://10.0.0.4:8466',\n    'gs://your_tb_logdir',\n    2000)\n```\n\n----------------------------------------\n\nTITLE: Encoding a Vector of Code Points into UTF-8\nDESCRIPTION: This snippet encodes a vector of Unicode code points into a UTF-8 encoded string scalar in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_encode(text_chars,\n                          output_encoding='UTF-8')\n```\n\n----------------------------------------\n\nTITLE: Converting Embeddings to TensorFlow Examples\nDESCRIPTION: Defines a function to convert text and embedding pairs into serialized TensorFlow Examples for efficient storage and processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef to_tf_example(entries):\n  examples = []\n\n  text_list, embedding_list = entries\n  for i in range(len(text_list)):\n    text = text_list[i]\n    embedding = embedding_list[i]\n\n    features = {\n        'text': tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[text.encode('utf-8')])),\n        'embedding': tf.train.Feature(\n            float_list=tf.train.FloatList(value=embedding.tolist()))\n    }\n  \n    example = tf.train.Example(\n        features=tf.train.Features(\n            feature=features)).SerializeToString(deterministic=True)\n  \n    examples.append(example)\n  \n  return examples\n```\n\n----------------------------------------\n\nTITLE: Adding Convolutional Layers for Handwriting Recognition in TensorFlow\nDESCRIPTION: This snippet shows how to add convolutional layers to the model. It includes options for batch normalization and dropout, and uses 1D convolutions to process the input sequence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nconvolved = inks\nfor i in range(len(params.num_conv)):\n  convolved_input = convolved\n  if params.batch_norm:\n    convolved_input = tf.layers.batch_normalization(\n        convolved_input,\n        training=(mode == tf.estimator.ModeKeys.TRAIN))\n  # Add dropout layer if enabled and not first convolution layer.\n  if i > 0 and params.dropout:\n    convolved_input = tf.layers.dropout(\n        convolved_input,\n        rate=params.dropout,\n        training=(mode == tf.estimator.ModeKeys.TRAIN))\n  convolved = tf.layers.conv1d(\n      convolved_input,\n      filters=params.num_conv[i],\n      kernel_size=params.conv_len[i],\n      activation=None,\n      strides=1,\n      padding=\"same\",\n      name=\"conv1d_%d\" % i)\nreturn convolved, lengths\n```\n\n----------------------------------------\n\nTITLE: Fixed Cross-Entropy Implementation\nDESCRIPTION: Shows the numerically stable implementation using TensorFlow's built-in softmax cross-entropy function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndiff = tf.losses.softmax_cross_entropy(labels=y_, logits=logits)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Starting Distributed Servers in TensorFlow\nDESCRIPTION: This snippet sets up worker and parameter server configurations for distributed training. It creates multiple server instances for workers and parameter servers using TensorFlow's distribute.Server.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nworker_config = tf.compat.v1.ConfigProto()\nworker_config.inter_op_parallelism_threads = 4\n\nfor i in range(3):\n  tf.distribute.Server(\n      cluster_resolver.cluster_spec(),\n      job_name=\"worker\",\n      task_index=i,\n      config=worker_config)\n\nfor i in range(2):\n  tf.distribute.Server(\n      cluster_resolver.cluster_spec(),\n      job_name=\"ps\",\n      task_index=i)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow with Eager Execution in Python\nDESCRIPTION: Import the TensorFlow library and enable TensorFlow's eager execution mode. This provides a more interactive environment for TensorFlow operations, enabling immediate execution of operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Displaying Directory Structure\nDESCRIPTION: Uses a shell command to display the directory structure of the downloaded dataset, showing how files are organized by split and class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n!find ./UCF101_subset\n```\n\n----------------------------------------\n\nTITLE: GraphDef Version Compatibility Check\nDESCRIPTION: Code snippet demonstrating the version compatibility checks required between producers and consumers of GraphDef data. Shows the logical conditions that must be met for compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/versions.md#2025-04-21_snippet_0\n\nLANGUAGE: pseudocode\nCODE:\n```\nconsumer >= data.min_consumer && \ndata.producer >= consumer.min_producer && \nconsumer not in data.bad_consumers\n```\n\n----------------------------------------\n\nTITLE: Listing Font CSV Files with Pathlib\nDESCRIPTION: This snippet uses Python's pathlib to create a sorted list of all CSV files in the fonts directory. It demonstrates how to prepare multiple files for loading with TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\nfont_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n\nfont_csvs[:10]\n```\n\n----------------------------------------\n\nTITLE: Plotting Single Image Prediction\nDESCRIPTION: This snippet plots the prediction result for a single image. It calls the `plot_value_array` function to generate a bar chart of the predicted class probabilities, and then displays the plot with class names on the x-axis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nplot_value_array(1, predictions_single[0], test_labels)\nplt.xticks(range(10), class_names, rotation=45)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Model Inference Example\nDESCRIPTION: Shows how to run inference on a model with random data and inspect the output statistics\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresult = model(tf.constant(np.random.randn(10,5), dtype = tf.float32)).numpy()\n\nprint(\"min:\", result.min())\nprint(\"max:\", result.max())\nprint(\"mean:\", result.mean())\nprint(\"shape:\", result.shape)\n```\n\n----------------------------------------\n\nTITLE: Manual Placement of Operations Across Multiple GPUs in TensorFlow\nDESCRIPTION: This snippet demonstrates how to manually distribute computations across multiple GPUs in TensorFlow. It replicates matrix multiplication operations on each available GPU and then combines the results on the CPU, showcasing fine-grained control over device placement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\n\ngpus = tf.config.list_logical_devices('GPU')\nif gpus:\n  # Replicate your computation on multiple GPUs\n  c = []\n  for gpu in gpus:\n    with tf.device(gpu.name):\n      a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n      b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n      c.append(tf.matmul(a, b))\n\n  with tf.device('/CPU:0'):\n    matmul_sum = tf.add_n(c)\n\n  print(matmul_sum)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Variable In-place Operations with New Type Promotion\nDESCRIPTION: This example shows how tf.Variable in-place operations allow implicit conversions while maintaining the variable's original dtype.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\na = tf.Variable(10, tf.int32)\na.assign_add(tf.constant(5, tf.int16))  # <tf.Variable shape=() dtype=int32, numpy=15>\n```\n\n----------------------------------------\n\nTITLE: Evaluating Ragged Tensors in Python\nDESCRIPTION: This example demonstrates various methods to access and evaluate the values in a ragged tensor, including conversion to Python lists, NumPy arrays, and accessing component tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.ragged.constant([[1, 2], [3, 4, 5], [6], [], [7]])\nprint(\"Python list:\", rt.to_list())\nprint(\"NumPy array:\", rt.numpy())\nprint(\"Values:\", rt.values.numpy())\nprint(\"Splits:\", rt.row_splits.numpy())\nprint(\"Indexed value:\", rt[1].numpy())\n```\n\n----------------------------------------\n\nTITLE: Shuffling Input Data with Dataset.shuffle()\nDESCRIPTION: This snippet demonstrates how to randomly shuffle the input dataset using the `Dataset.shuffle()` transformation.  It maintains a fixed-size buffer and chooses the next element uniformly at random from that buffer. A buffer size is required.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(...)\ndataset = dataset.shuffle(buffer_size=10000)\ndataset = dataset.batch(32)\ndataset = dataset.repeat()\n```\n\n----------------------------------------\n\nTITLE: Implementing MaskedTensor Extension Type for Keras\nDESCRIPTION: Defines a MaskedTensor class that extends BatchableExtensionType with Keras compatibility. Includes shape and dtype properties required for Keras integration and a Spec inner class for type specifications.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.BatchableExtensionType):\n  # __name__ is required for serialization in SavedModel; see below for details.\n  __name__ = 'extension_type_colab.MaskedTensor'\n\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  shape = property(lambda self: self.values.shape)\n  dtype = property(lambda self: self.values.dtype)\n\n  def with_default(self, default):\n    return tf.where(self.mask, self.values, default)\n\n  def __repr__(self):\n    return masked_tensor_str(self.values, self.mask)\n\n  class Spec:\n    def __init__(self, shape, dtype=tf.float32):\n      self.values = tf.TensorSpec(shape, dtype)\n      self.mask = tf.TensorSpec(shape, tf.bool)\n\n    shape = property(lambda self: self.values.shape)\n    dtype = property(lambda self: self.values.dtype)\n\n    def with_shape(self):\n      return MaskedTensor.Spec(tf.TensorSpec(shape, self.values.dtype),\n                               tf.TensorSpec(shape, self.mask.dtype))\n```\n\n----------------------------------------\n\nTITLE: Normalizing Images for CycleGAN Training\nDESCRIPTION: Defines a function to normalize image pixel values to the range [-1, 1], which is required for the generator and discriminator models in CycleGAN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# normalizing the images to [-1, 1]\ndef normalize(image):\n  image = tf.cast(image, tf.float32)\n  image = (image / 127.5) - 1\n  return image\n```\n\n----------------------------------------\n\nTITLE: Running Training and Testing Loops in TensorFlow with Python\nDESCRIPTION: This snippet contains helper functions 'run_train()' and 'run_test()' to execute training and testing loops on a TensorFlow session. Each function initializes dataset iterators and handles the session's control flow to iterate through dataset batches until completion. The helpers also print out resulting loss and accuracy metrics at the end of each epoch. Dependencies include 'tensorflow' library and a defined computational strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef run_train():\n  # Train\n  session.run(train_iterator_init)\n  while True:\n    try:\n      session.run(dist_train)\n    except tf.errors.OutOfRangeError:\n      break\n  print('Train loss: {:0.4f}\\t Train accuracy: {:0.4f}%'.format(\n      session.run(training_loss_result),\n      session.run(training_accuracy_result) * 100))\n  training_loss.reset_states()\n  training_accuracy.reset_states()\n\ndef run_test():\n  # Test\n  session.run(test_iterator_init)\n  while True:\n    try:\n      session.run(dist_test)\n    except tf.errors.OutOfRangeError:\n      break\n  print('Test loss: {:0.4f}\\t Test accuracy: {:0.4f}%'.format(\n      session.run(test_loss_result),\n      session.run(test_accuracy_result) * 100))\n  test_loss.reset_states()\n  test_accuracy.reset_states()\n```\n\n----------------------------------------\n\nTITLE: Examining Variables Directory Contents\nDESCRIPTION: Lists the contents of the variables directory within the SavedModel, which contains the checkpoint files for model weights.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n!ls {mobilenet_save_path}/variables\n```\n\n----------------------------------------\n\nTITLE: Debugging Output for TensorFlow Function\nDESCRIPTION: Sample debugger output showing the execution trace and source code listing when debugging a TensorFlow function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: text\nCODE:\n```\n>>> f()\n-> x = x + 1\n(Pdb) l\n  6     @tf.function\n  7     def f(x):\n  8       if x > 0:\n  9         import pdb\n 10         pdb.set_trace()\n 11  ->     x = x + 1\n 12       return x\n 13\n 14     tf.config.run_functions_eagerly(True)\n 15     f(tf.constant(1))\n[EOF]\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Distributed Configuration\nDESCRIPTION: Shows distributed TensorFlow setup with parameter servers and workers. Demonstrates variable placement and computation distribution across tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device(\"/job:ps/task:0\"):\n  weights_1 = tf.Variable(tf.truncated_normal([784, 100]))\n  biases_1 = tf.Variable(tf.zeros([100]))\n\nwith tf.device(\"/job:ps/task:1\"):\n  weights_2 = tf.Variable(tf.truncated_normal([100, 10]))\n  biases_2 = tf.Variable(tf.zeros([10]))\n\nwith tf.device(\"/job:worker\"):\n  layer_1 = tf.matmul(train_batch, weights_1) + biases_1\n  layer_2 = tf.matmul(train_batch, weights_2) + biases_2\n```\n\n----------------------------------------\n\nTITLE: Displaying Model Summary in TensorFlow\nDESCRIPTION: This code displays a summary of the model architecture, including layer information, output shapes, and the number of parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Computing Embeddings and Building SimpleNeighbors Index for Q&A Retrieval\nDESCRIPTION: Computes embeddings for all sentences and their contexts using the response_encoder, then builds a SimpleNeighbors index for efficient retrieval.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title Compute embeddings and build simpleneighbors index\nbatch_size = 100\n\nencodings = model.signatures['response_encoder'](\n  input=tf.constant([sentences[0][0]]),\n  context=tf.constant([sentences[0][1]]))\nindex = simpleneighbors.SimpleNeighbors(\n    len(encodings['outputs'][0]), metric='angular')\n\nprint('Computing embeddings for %s sentences' % len(sentences))\nslices = zip(*(iter(sentences),) * batch_size)\nnum_batches = int(len(sentences) / batch_size)\nfor s in tqdm(slices, total=num_batches):\n  response_batch = list([r for r, c in s])\n  context_batch = list([c for r, c in s])\n  encodings = model.signatures['response_encoder'](\n    input=tf.constant(response_batch),\n    context=tf.constant(context_batch)\n  )\n  for batch_index, batch in enumerate(response_batch):\n    index.add_one(batch, encodings['outputs'][batch_index])\n\nindex.build()\nprint('simpleneighbors index for %s sentences built.' % len(sentences))\n```\n\n----------------------------------------\n\nTITLE: Setting Visualization Parameters for SNGP Plots\nDESCRIPTION: Defines visualization macros for plotting the model results, including DPI settings, coordinate ranges, color maps, normalization, and grid size for consistent visualization throughout the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nplt.rcParams['figure.dpi'] = 140\n\nDEFAULT_X_RANGE = (-3.5, 3.5)\nDEFAULT_Y_RANGE = (-2.5, 2.5)\nDEFAULT_CMAP = colors.ListedColormap([\"#377eb8\", \"#ff7f00\"])\nDEFAULT_NORM = colors.Normalize(vmin=0, vmax=1,)\nDEFAULT_N_GRID = 100\n```\n\n----------------------------------------\n\nTITLE: Manual Device Placement in TensorFlow\nDESCRIPTION: This snippet showcases how to manually place operations on a specific device using `with tf.device`. It similarly initializes two constants, performs multiplication, and logs the device assignments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_gpu.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Creates a graph.\nwith tf.device('/cpu:0'):\n  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint(sess.run(c))\n```\n\n----------------------------------------\n\nTITLE: Creating Generators Inside Strategy.run Function\nDESCRIPTION: Demonstrates creating a random number generator within the Strategy.run function, allowing isolated generator instances for each function call while maintaining deterministic behavior based on the seed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nstrat = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat.scope():\n  def f():\n    g = tf.random.Generator.from_seed(1)\n    a = g.normal([])\n    b = g.normal([])\n    return tf.stack([a, b])\n  print(strat.run(f))\n  print(strat.run(f))\n```\n\n----------------------------------------\n\nTITLE: Creating String Record Defaults for CSV Parsing\nDESCRIPTION: This snippet prepares a list of string defaults for decoding the Titanic CSV file. It creates 10 empty string defaults to match the number of columns in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\ntext = pathlib.Path(titanic_file_path).read_text()\nlines = text.split('\\n')[1:-1]\n\nall_strings = [str()]*10\nall_strings\n```\n\n----------------------------------------\n\nTITLE: Visualizing MNIST Digit Examples with Matplotlib\nDESCRIPTION: Loads a small subset of MNIST data and displays a 3x3 grid of handwritten digit examples with their true labels using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nx_viz, y_viz = tfds.load(\"mnist\", split=['train[:1500]'], batch_size=-1, as_supervised=True)[0]\nx_viz = tf.squeeze(x_viz, axis=3)\n\nfor i in range(9):\n    plt.subplot(3,3,1+i)\n    plt.axis('off')\n    plt.imshow(x_viz[i], cmap='gray')\n    plt.title(f\"True Label: {y_viz[i]}\")\n    plt.subplots_adjust(hspace=.5)\n\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Restricted Tensor Sequence in C++\nDESCRIPTION: Example of registering a TensorFlow operation that accepts a sequence of tensors with restricted types. The op accepts and outputs tensors of types specified by attribute 'T', but restricts 'T' to be a list containing only int32 or int64 tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_42\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"RestrictedTensorSequenceExample\")\n    .Attr(\"T: list({int32, int64})\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Checking Python and pip Versions on macOS\nDESCRIPTION: These commands verify the installed Python and pip versions on macOS, ensuring compatibility with TensorFlow requirements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\npython3 --version\\npython3 -m pip --version\n```\n\n----------------------------------------\n\nTITLE: Manual Device Placement in TensorFlow\nDESCRIPTION: This snippet demonstrates how to manually place tensors on the CPU and perform matrix multiplication, which will likely be executed on the GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntf.debugging.set_log_device_placement(True)\n\n# Place tensors on the CPU\nwith tf.device('/CPU:0'):\n  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n\n# Run on the GPU\nc = tf.matmul(a, b)\nprint(c)\n```\n\n----------------------------------------\n\nTITLE: Creating CNN Convolutional Base\nDESCRIPTION: Define the convolutional layers of the CNN using Conv2D and MaxPooling2D layers\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Images for Style Transfer in Python\nDESCRIPTION: Defines dictionaries of content and style image URLs, loads them to specific sizes, and applies average pooling to style images. Uses predefined image dimensions of 384px for content and 256px for style images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncontent_urls = dict(\n  sea_turtle='https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg',\n  tuebingen='https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg',\n  grace_hopper='https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg',\n  )\nstyle_urls = dict(\n  kanagawa_great_wave='https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg',\n  kandinsky_composition_7='https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg',\n  hubble_pillars_of_creation='https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg',\n  van_gogh_starry_night='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg',\n  turner_nantes='https://upload.wikimedia.org/wikipedia/commons/b/b7/JMW_Turner_-_Nantes_from_the_Ile_Feydeau.jpg',\n  munch_scream='https://upload.wikimedia.org/wikipedia/commons/c/c5/Edvard_Munch%2C_1893%2C_The_Scream%2C_oil%2C_tempera_and_pastel_on_cardboard%2C_91_x_73_cm%2C_National_Gallery_of_Norway.jpg',\n  picasso_demoiselles_avignon='https://upload.wikimedia.org/wikipedia/en/4/4c/Les_Demoiselles_d%27Avignon.jpg',\n  picasso_violin='https://upload.wikimedia.org/wikipedia/en/3/3c/Pablo_Picasso%2C_1911-12%2C_Violon_%28Violin%29%2C_oil_on_canvas%2C_Kr%C3%B6ller-M%C3%BCller_Museum%2C_Otterlo%2C_Netherlands.jpg',\n  picasso_bottle_of_rum='https://upload.wikimedia.org/wikipedia/en/7/7f/Pablo_Picasso%2C_1911%2C_Still_Life_with_a_Bottle_of_Rum%2C_oil_on_canvas%2C_61.3_x_50.5_cm%2C_Metropolitan_Museum_of_Art%2C_New_York.jpg',\n  fire='https://upload.wikimedia.org/wikipedia/commons/3/36/Large_bonfire.jpg',\n  derkovits_woman_head='https://upload.wikimedia.org/wikipedia/commons/0/0d/Derkovits_Gyula_Woman_head_1922.jpg',\n  amadeo_style_life='https://upload.wikimedia.org/wikipedia/commons/8/8e/Untitled_%28Still_life%29_%281913%29_-_Amadeo_Souza-Cardoso_%281887-1918%29_%2817385824283%29.jpg',\n  derkovtis_talig='https://upload.wikimedia.org/wikipedia/commons/3/37/Derkovits_Gyula_Talig%C3%A1s_1920.jpg',\n  amadeo_cardoso='https://upload.wikimedia.org/wikipedia/commons/7/7d/Amadeo_de_Souza-Cardoso%2C_1915_-_Landscape_with_black_figure.jpg'\n)\n\ncontent_image_size = 384\nstyle_image_size = 256\ncontent_images = {k: load_image(v, (content_image_size, content_image_size)) for k, v in content_urls.items()}\nstyle_images = {k: load_image(v, (style_image_size, style_image_size)) for k, v in style_urls.items()}\nstyle_images = {k: tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME') for k, style_image in style_images.items()}\n```\n\n----------------------------------------\n\nTITLE: Adding Dataset Access Properties to WindowGenerator Class\nDESCRIPTION: Implements properties to access training, validation, and test datasets through the make_dataset method. Also includes an example property that caches a batch for plotting purposes, improving efficiency when repeatedly accessing example data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\nWindowGenerator.train = train\nWindowGenerator.val = val\nWindowGenerator.test = test\nWindowGenerator.example = example\n```\n\n----------------------------------------\n\nTITLE: Building a Simple Computational Graph in TensorFlow\nDESCRIPTION: Creates constant tensors and demonstrates a simple addition operation in the TensorFlow computational graph. Shows how tensor objects represent operations rather than immediate values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\na = tf.constant(3.0, dtype=tf.float32)\nb = tf.constant(4.0) # also tf.float32 implicitly\ntotal = a + b\nprint(a)\nprint(b)\nprint(total)\n```\n\n----------------------------------------\n\nTITLE: Creating Training and Validation Datasets from Image Directory\nDESCRIPTION: This code uses the Keras utility function to create training and validation datasets from a directory of images. It specifies parameters such as image size, batch size, and validation split.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\nimg_height = 180\nimg_width = 180\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n```\n\n----------------------------------------\n\nTITLE: Displaying SavedModel CLI 'run' Command Usage\nDESCRIPTION: Shows the usage syntax for the 'run' command in the SavedModel CLI, which is used to execute computations on a saved model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: bash\nCODE:\n```\nusage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n                           [--input_exprs INPUT_EXPRS]\n                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n                           [--overwrite] [--tf_debug]\n```\n\n----------------------------------------\n\nTITLE: Training U-Net Model for Image Segmentation in TensorFlow\nDESCRIPTION: This snippet trains the U-Net model on the prepared dataset, using the custom DisplayCallback to show predictions after each epoch. It sets up epochs, validation steps, and other training parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nEPOCHS = 20\nVAL_SUBSPLITS = 5\nVALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n\nmodel_history = model.fit(train_batches, epochs=EPOCHS,\n                          steps_per_epoch=STEPS_PER_EPOCH,\n                          validation_steps=VALIDATION_STEPS,\n                          validation_data=test_batches,\n                          callbacks=[DisplayCallback()])\n```\n\n----------------------------------------\n\nTITLE: Setting Dataset Size Parameters\nDESCRIPTION: Defines constants for the number of classes and files per class to use in the subset, controlling the overall dataset size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nNUM_CLASSES = 10\nFILES_PER_CLASS = 50\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Matching Function\nDESCRIPTION: Function to match features between two images using KD-tree and RANSAC for geometric verification\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef match_images(image1, image2, result1, result2):\n  distance_threshold = 0.8\n\n  # Read features.\n  num_features_1 = result1['locations'].shape[0]\n  print(\"Loaded image 1's %d features\" % num_features_1)\n  \n  num_features_2 = result2['locations'].shape[0]\n  print(\"Loaded image 2's %d features\" % num_features_2)\n\n  # Find nearest-neighbor matches using a KD tree.\n  d1_tree = cKDTree(result1['descriptors'])\n  _, indices = d1_tree.query(\n      result2['descriptors'],\n      distance_upper_bound=distance_threshold)\n\n  # Select feature locations for putative matches.\n  locations_2_to_use = np.array([\n      result2['locations'][i,]\n      for i in range(num_features_2)\n      if indices[i] != num_features_1\n  ])\n  locations_1_to_use = np.array([\n      result1['locations'][indices[i],]\n      for i in range(num_features_2)\n      if indices[i] != num_features_1\n  ])\n\n  # Perform geometric verification using RANSAC.\n  _, inliers = ransac(\n      (locations_1_to_use, locations_2_to_use),\n      AffineTransform,\n      min_samples=3,\n      residual_threshold=20,\n      max_trials=1000)\n\n  print('Found %d inliers' % sum(inliers))\n\n  # Visualize correspondences.\n  _, ax = plt.subplots()\n  inlier_idxs = np.nonzero(inliers)[0]\n  plot_matches(\n      ax,\n      image1,\n      image2,\n      locations_1_to_use,\n      locations_2_to_use,\n      np.column_stack((inlier_idxs, inlier_idxs)),\n      matches_color='b')\n  ax.axis('off')\n  ax.set_title('DELF correspondences')\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Graph Optimization\nDESCRIPTION: This code imports necessary Python libraries for demonstrating TensorFlow graph optimization, including numpy for numerical operations and TensorFlow itself.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport timeit\nimport traceback\nimport contextlib\n\n\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: Installing gdown package for downloading files from Google Drive.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install gdown --no-use-pep517\n```\n\n----------------------------------------\n\nTITLE: Handling Class Imbalance with Sample Weights in TensorFlow\nDESCRIPTION: This function adds sample weights to the dataset to handle class imbalance in image segmentation. It assigns different weights to each class based on their importance or frequency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef add_sample_weights(image, label):\n  # The weights for each class, with the constraint that:\n  #     sum(class_weights) == 1.0\n  class_weights = tf.constant([2.0, 2.0, 1.0])\n  class_weights = class_weights/tf.reduce_sum(class_weights)\n\n  # Create an image of `sample_weights` by using the label at each pixel as an\n  # index into the `class weights` .\n  sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n\n  return image, label, sample_weights\n```\n\n----------------------------------------\n\nTITLE: Handling Unimplemented Gradients in TensorFlow Operations\nDESCRIPTION: This snippet demonstrates the error raised when attempting to compute gradients for an operation (adjust_contrast) that has no registered gradient implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimage = tf.Variable([[[0.5, 0.0, 0.0]]])\ndelta = tf.Variable(0.1)\n\nwith tf.GradientTape() as tape:\n  new_image = tf.image.adjust_contrast(image, delta)\n\ntry:\n  print(tape.gradient(new_image, [image, delta]))\n  assert False   # This should not happen.\nexcept LookupError as e:\n  print(f'{type(e).__name__}: {e}')\n```\n\n----------------------------------------\n\nTITLE: Applying Style Transfer with TensorFlow Hub\nDESCRIPTION: Applies style transfer using a TensorFlow Hub module. Takes a content image and style image as input, generates a stylized output image, and displays the original, style, and resulting images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncontent_name = 'sea_turtle'  # @param ['sea_turtle', 'tuebingen', 'grace_hopper']\nstyle_name = 'munch_scream'  # @param ['kanagawa_great_wave', 'kandinsky_composition_7', 'hubble_pillars_of_creation', 'van_gogh_starry_night', 'turner_nantes', 'munch_scream', 'picasso_demoiselles_avignon', 'picasso_violin', 'picasso_bottle_of_rum', 'fire', 'derkovits_woman_head', 'amadeo_style_life', 'derkovtis_talig', 'amadeo_cardoso']\n\nstylized_image = hub_module(tf.constant(content_images[content_name]),\n                            tf.constant(style_images[style_name]))[0]\n\nshow_n([content_images[content_name], style_images[style_name], stylized_image],\n       titles=['Original content image', 'Style image', 'Stylized image'])\n```\n\n----------------------------------------\n\nTITLE: Defining Evaluation Forward Pass Function in TensorFlow\nDESCRIPTION: This function defines a forward pass for evaluation, using TensorFlow's @tf.function decorator with JIT compilation for improved performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(jit_compile=True)\ndef eval_fwd(batch):\n  logits = model(batch, training=False)\n  return tf.argmax(logits, axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Training Keras Model with Artificial Epoch Interruption\nDESCRIPTION: Training the Keras model with both BackupAndRestore callback for checkpointing and InterruptAtEpoch callback to simulate a training failure after the fourth epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  model.fit(x=x_train,\n            y=y_train,\n            epochs=10,\n            steps_per_epoch=100,\n            validation_data=(x_test, y_test),\n            callbacks=[backup_restore_callback, InterruptAtEpoch()])\nexcept Exception as e:\n  print(f'{type(e).__name__}:{e}')\n```\n\n----------------------------------------\n\nTITLE: Displaying Sequential Model Summary\nDESCRIPTION: Shows a summary of the sequential model including all layers, their output shapes, and parameter counts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmy_seq.summary()\n```\n\n----------------------------------------\n\nTITLE: Loading and Checking Custom Output Names\nDESCRIPTION: Loads a model with custom output names and examines the structured outputs to verify the custom output name is preserved.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nimported_with_output_name = tf.saved_model.load(module_output_path)\nimported_with_output_name.signatures[\n    'serving_default'\n].structured_outputs  # {'custom_output_name': TensorSpec(shape=<unknown>, dtype=tf.float32, name='custom_output_name')}\n```\n\n----------------------------------------\n\nTITLE: Loading a SavedModel in Python\nDESCRIPTION: Demonstrates how to load a SavedModel without signatures using tf.saved_model.load() and use its functions and variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimported = tf.saved_model.load(module_no_signatures_path)\nassert imported(tf.constant(3.)).numpy() == 3\nimported.mutate(tf.constant(2.))\nassert imported(tf.constant(3.)).numpy() == 6\n```\n\n----------------------------------------\n\nTITLE: Plotting Model Training History with Binary Crossentropy Metric\nDESCRIPTION: Visualizes the training history for the model using a HistoryPlotter from tfdocs with binary crossentropy as the metric. Applies smoothing and sets y-axis limits for better visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nplotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\nplotter.plot(size_histories)\nplt.ylim([0.5, 0.7])\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Data Threading Options\nDESCRIPTION: Code snippet showing how to disable intra-op parallelism in tf.data to potentially improve efficiency by over 10% by setting threading options on the input pipeline.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndataset = ...\noptions = tf.data.Options()\noptions.experimental_threading.max_intra_op_parallelism = 1\ndataset = dataset.with_options(options)\n```\n\n----------------------------------------\n\nTITLE: Building Keras Model with Subclassing\nDESCRIPTION: Illustrates how to build a Keras model by subclassing `tf.keras.Model`. The code defines a custom model `MyModel` with two dense layers. The `__init__` method defines the layers, and the `call` method defines the forward pass. The `compute_output_shape` method is overridden to specify the output shape. The model is then compiled and trained.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n```python\nclass MyModel(tf.keras.Model):\n\n  def __init__(self, num_classes=10):\n    super(MyModel, self).__init__(name='my_model')\n    self.num_classes = num_classes\n    # Define your layers here.\n    self.dense_1 = layers.Dense(32, activation='relu')\n    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n\n  def call(self, inputs):\n    # Define your forward pass here,\n    # using layers you previously defined (in `__init__`).\n    x = self.dense_1(inputs)\n    return self.dense_2(x)\n\n  def compute_output_shape(self, input_shape):\n    # You need to override this function if you want to use the subclassed model\n    # as part of a functional-style model.\n    # Otherwise, this method is optional.\n    shape = tf.TensorShape(input_shape).as_list()\n    shape[-1] = self.num_classes\n    return tf.TensorShape(shape)\n```\n```\n\nLANGUAGE: python\nCODE:\n```\n```python\nmodel = MyModel(num_classes=10)\n\n# The compile step specifies the training configuration.\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Trains for 5 epochs.\nmodel.fit(data, labels, batch_size=32, epochs=5)\n```\n```\n\n----------------------------------------\n\nTITLE: Running Inference with YAMNet\nDESCRIPTION: Performs audio classification using YAMNet on the test file, showing the main sound class and the shape of the embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nscores, embeddings, spectrogram = yamnet_model(testing_wav_data)\nclass_scores = tf.reduce_mean(scores, axis=0)\ntop_class = tf.math.argmax(class_scores)\ninferred_class = class_names[top_class]\n\nprint(f'The main sound is: {inferred_class}')\nprint(f'The embeddings shape: {embeddings.shape}')\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow with GPU Support on Windows WSL2\nDESCRIPTION: Commands to install TensorFlow with GPU support on Windows Subsystem for Linux 2 (WSL2) and verify the installation. Requires Windows 10 19044 or higher.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install tensorflow[and-cuda]\n# Verify the installation:\npython3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n```\n\n----------------------------------------\n\nTITLE: Loading a TensorFlow Graph from Binary or Text Format in Python\nDESCRIPTION: Conditional code that loads a graph definition from either binary or text format based on a user-specified flag. Binary format uses ParseFromString while text format uses text_format.Merge.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/model_files.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n  if FLAGS.input_binary:\n    graph_def.ParseFromString(f.read())\n  else:\n    text_format.Merge(f.read(), graph_def)\n```\n\n----------------------------------------\n\nTITLE: Counting Font CSV Files\nDESCRIPTION: A simple snippet that displays the total number of font CSV files found in the directory, providing insight into the dataset size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nlen(font_csvs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic TensorFlow Input Pipeline in Python\nDESCRIPTION: This snippet demonstrates a basic TensorFlow input pipeline using TFRecordDataset, map, batch, and repeat operations. It serves as an example for performance analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.TFRecordDataset(filename)\ndataset = dataset.map(parse_record)\ndataset = dataset.batch(32)\ndataset = dataset.repeat()\n```\n\n----------------------------------------\n\nTITLE: Displaying Elements from Dataset using Python\nDESCRIPTION: Illustrates how to iterate over a dataset to print components of tuples, used here to output the first example from the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Use `take(1)` to only pull one example from the dataset.\nfor f0,f1,f2,f3 in features_dataset.take(1):\n  print(f0)\n  print(f1)\n  print(f2)\n  print(f3)\n```\n\n----------------------------------------\n\nTITLE: Fitting the Model and Calculating Loss and Accuracy in TensorFlow/Keras\nDESCRIPTION: This code defines a `fit` function to calculate the loss and accuracy on a batch and perform a gradient descent step. It calls the `predict` function to compute loss and accuracy, then uses the optimizer to minimize the loss. `tf.control_dependencies` are automatically added for ensuring correct execution order within the TensorFlow graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef fit(m, x, y, opt):\n  l, accuracy = predict(m, x, y)\n  # Autograph automatically adds the necessary `tf.control_dependencies` here.\n  # (Without them nothing depends on `opt.minimize`, so it doesn't run.)\n  # This makes it much more like eager-code.\n  opt.minimize(l)\n  return l, accuracy\n```\n\n----------------------------------------\n\nTITLE: Error Handling in TensorFlow C++ Implementation\nDESCRIPTION: This snippet demonstrates error handling using TensorFlow's Status object. It checks if the printing operation completed successfully and logs an error message if it failed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_15\n\nLANGUAGE: C++\nCODE:\n```\n  if (!print_status.ok()) {\n    LOG(ERROR) << \"Running print failed: \" << print_status;\n    return -1;\n  }\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Environment\nDESCRIPTION: Basic setup importing TensorFlow and time modules for performance testing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport time\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Session\nDESCRIPTION: Creates and initializes a TensorFlow session for model execution\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ninitializer = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(initializer)\n```\n\n----------------------------------------\n\nTITLE: Plotting Image Attributions with Integrated Gradients in Python\nDESCRIPTION: This function visualizes attributions using Integrated Gradients. It creates a 2x2 plot showing the baseline image, original image, attribution mask, and an overlay of the attribution on the original image. The function uses TensorFlow for computations and matplotlib for plotting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef plot_img_attributions(baseline,\n                          image,\n                          target_class_idx,\n                          m_steps=50,\n                          cmap=None,\n                          overlay_alpha=0.4):\n\n  attributions = integrated_gradients(baseline=baseline,\n                                      image=image,\n                                      target_class_idx=target_class_idx,\n                                      m_steps=m_steps)\n\n  # Sum of the attributions across color channels for visualization.\n  # The attribution mask shape is a grayscale image with height and width\n  # equal to the original image.\n  attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n\n  fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n\n  axs[0, 0].set_title('Baseline image')\n  axs[0, 0].imshow(baseline)\n  axs[0, 0].axis('off')\n\n  axs[0, 1].set_title('Original image')\n  axs[0, 1].imshow(image)\n  axs[0, 1].axis('off')\n\n  axs[1, 0].set_title('Attribution mask')\n  axs[1, 0].imshow(attribution_mask, cmap=cmap)\n  axs[1, 0].axis('off')\n\n  axs[1, 1].set_title('Overlay')\n  axs[1, 1].imshow(attribution_mask, cmap=cmap)\n  axs[1, 1].imshow(image, alpha=overlay_alpha)\n  axs[1, 1].axis('off')\n\n  plt.tight_layout()\n  return fig\n```\n\n----------------------------------------\n\nTITLE: Creating Function to Split Data into Subsets\nDESCRIPTION: Defines a function that splits the files for each class into specified counts for different data subsets (like train, validation, test), returning both the selected files and the remaining files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef split_class_lists(files_for_class, count):\n  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n    files that need to be downloaded.\n    \n    Args:\n      files_for_class: Files belonging to a particular class of data.\n      count: Number of files to download.\n\n    Returns:\n      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n  \"\"\"\n  split_files = []\n  remainder = {}\n  for cls in files_for_class:\n    split_files.extend(files_for_class[cls][:count])\n    remainder[cls] = files_for_class[cls][count:]\n  return split_files, remainder\n```\n\n----------------------------------------\n\nTITLE: Handling Exceptions in TensorFlow DocTest\nDESCRIPTION: This snippet demonstrates how to handle exceptions in DocTest for TensorFlow documentation, showing that exception details are ignored except for the type of exception raised.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> np_var = np.array([1, 2])\n>>> tf.keras.backend.is_keras_tensor(np_var)\nTraceback (most recent call last):\n...\nValueError: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`.\n```\n\n----------------------------------------\n\nTITLE: Creating Helper Functions for Error Demonstration\nDESCRIPTION: Defines a context manager that catches and displays specific exceptions for demonstration purposes in the guide.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport traceback\nimport contextlib\n\n# Some helper code to demonstrate the kinds of errors you might encounter.\n@contextlib.contextmanager\ndef assert_raises(error_class):\n  try:\n    yield\n  except error_class as e:\n    print('Caught expected exception \\n  {}:'.format(error_class))\n    traceback.print_exc(limit=2)\n  except Exception as e:\n    raise e\n  else:\n    raise Exception('Expected {} to be raised but no error was raised!'.format(\n        error_class))\n```\n\n----------------------------------------\n\nTITLE: Downloading Inception-v3 Model Archive using CURL\nDESCRIPTION: This snippet demonstrates how to download the Inception-v3 model's GraphDef using CURL and extract the files into the specified directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L \"https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\" |\n  tar -C tensorflow/examples/label_image/data -xz\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Estimators\nDESCRIPTION: Imports necessary Python libraries including tempfile, os, TensorFlow, and TensorFlow Datasets for working with Estimators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\nimport os\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n```\n\n----------------------------------------\n\nTITLE: Using Zero Instead of None for Unconnected Gradients in TensorFlow\nDESCRIPTION: This snippet shows how to use the unconnected_gradients argument to return zero instead of None for unconnected gradients in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable([2., 2.])\ny = tf.Variable(3.)\n\nwith tf.GradientTape() as tape:\n  z = y**2\nprint(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and importing dependencies for CORD-19 embeddings analysis\nDESCRIPTION: This snippet sets up the necessary imports and configurations for TensorFlow, matplotlib, and other libraries needed for the tutorial. It also defines a custom function for displaying DataFrames.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport functools\nimport itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\n\nimport tensorflow.compat.v1 as tf\ntf.disable_eager_execution()\ntf.logging.set_verbosity('ERROR')\n\nimport tensorflow_datasets as tfds\nimport tensorflow_hub as hub\n\ntry:\n  from google.colab import data_table\n  def display_df(df):\n    return data_table.DataTable(df, include_index=False)\nexcept ModuleNotFoundError:\n  # If google-colab is not available, just display the raw DataFrame\n  def display_df(df):\n    return df\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow C Program with Explicit Library Path\nDESCRIPTION: This bash command compiles the hello_tf.c program with explicit include and library paths for the TensorFlow C library, then runs the resulting executable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngcc -I/usr/local/include -L/usr/local/lib hello_tf.c -ltensorflow -o hello_tf\n\n./hello_tf\n```\n\n----------------------------------------\n\nTITLE: Setup for Old Type Promotion Example in TensorFlow-NumPy\nDESCRIPTION: This code sets up variables for demonstrating the old type promotion behavior by enabling the legacy dtype conversion mode and creating arrays of different types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Setup\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\na = np.array(1, dtype=np.int8)\nb = tf.constant(1)\nc = np.array(1, dtype=np.float16)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow dependencies with pip\nDESCRIPTION: This command installs or updates TensorFlow and TensorFlow datasets packages quietly, which are required for the audio recognition tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -U -q tensorflow tensorflow_datasets\n```\n\n----------------------------------------\n\nTITLE: Defining Frame Dimensions in Python\nDESCRIPTION: Sets the height and width dimensions for video frame processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nHEIGHT = 224\nWIDTH = 224\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset from Tuple of Arrays using TensorFlow (Python)\nDESCRIPTION: Applies the from_tensor_slices method to a tuple of arrays, generating a dataset of tuples, which can be used for accessing multiple features collectively.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfeatures_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\nfeatures_dataset\n```\n\n----------------------------------------\n\nTITLE: Separating Features and Labels\nDESCRIPTION: Splits the datasets into features (X) and labels (y) by removing the target Species column.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_y = train.pop('Species')\ntest_y = test.pop('Species')\n\n# The label column has now been removed from the features.\ntrain.head()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Import and Version Check\nDESCRIPTION: Importing TensorFlow and checking its version\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\n\ntf.__version__\n```\n\n----------------------------------------\n\nTITLE: Installing System Dependencies\nDESCRIPTION: Installing unzip utility using apt-get.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install -y unzip\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Type Constraints in C++\nDESCRIPTION: Shows how to register the ZeroOut op with type constraints and default values for backward compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_31\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n  .Attr(\"T: {float, int32} = DT_INT32\")\n  .Input(\"to_zero: T\")\n  .Output(\"zeroed: T\")\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: {float, double, int32}\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Test Losses and Accuracies in TensorFlow\nDESCRIPTION: This code uses `matplotlib.pyplot` to plot the training and test losses and accuracies.  It displays two plots: one for loss and one for accuracy, showing the trends over the training steps.  Labels, legends, and axis titles are included for clarity.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nplt.title('MNIST train/test losses')\nplt.plot(train_losses, label='train loss')\nplt.plot(test_losses, label='test loss')\nplt.legend()\nplt.xlabel('Training step')\nplt.ylabel('Loss')\nplt.show()\nplt.title('MNIST train/test accuracies')\nplt.plot(train_accuracies, label='train accuracy')\nplt.plot(test_accuracies, label='test accuracy')\nplt.legend(loc='lower right')\nplt.xlabel('Training step')\nplt.ylabel('Accuracy')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Error: Incompatible Ragged Dimensions\nDESCRIPTION: Shows a broadcasting error that occurs when two ragged tensors have incompatible ragged dimensions, where neither can be broadcast to match the other.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_53\n\nLANGUAGE: python\nCODE:\n```\n# x      (2d ragged): 3 x (r1)\n# y      (2d ragged): 3 x (r2)  # ragged dimensions do not match.\nx = tf.ragged.constant([[1, 2, 3], [4], [5, 6]])\ny = tf.ragged.constant([[10, 20], [30, 40], [50]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Reloading Package Resources in Python\nDESCRIPTION: Refreshes the pkg_resources module to ensure it recognizes the newly installed packages. This is important after installing new dependencies to make them available in the current Python session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# refresh pkg_resources so it takes the changes into account.\nimport pkg_resources\nimport importlib\nimportlib.reload(pkg_resources)\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Neural Network Model\nDESCRIPTION: Creates a sequential neural network model with flatten, dense, dropout layers and configures training parameters using Adam optimizer and sparse categorical crossentropy loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/_index.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Softmax Activation Function with TensorFlow\nDESCRIPTION: Plots the softmax activation function which converts numbers into a probability distribution. This function is used in the output layer for multi-class classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linspace(-4, 4, 201)\nx = tf.cast(x, tf.float32)\nplt.plot(x, tf.nn.softmax(x, axis=0));\nplt.xlabel('x')\nplt.ylabel('Softmax(x)')\nplt.title('Softmax activation function');\n```\n\n----------------------------------------\n\nTITLE: Getting the Default Distribution Strategy\nDESCRIPTION: Code to obtain the Default Strategy singleton instance. This strategy provides no actual distribution and is useful for writing distribution-aware code that works with or without an explicit strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndefault_strategy = tf.distribute.get_strategy()\n```\n\n----------------------------------------\n\nTITLE: Broadcasting scalar values with 2D RaggedTensor in TensorFlow\nDESCRIPTION: Demonstrates adding a scalar value to each element of a 2D ragged tensor, resulting in a 2D ragged tensor with the same shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# result  (2D ragged):  2 x (num_rows)\nx = tf.ragged.constant([[1, 2], [3]])\ny = 3\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Model Evaluation\nDESCRIPTION: Evaluates the model's performance on validation dataset and prints loss and accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nloss, accuracy = model.evaluate(val_ds)\n\nprint(\"Loss: \", loss)\nprint(\"Accuracy: {:2.2%}\".format(accuracy))\n```\n\n----------------------------------------\n\nTITLE: Importing Required TensorFlow Libraries and Dependencies\nDESCRIPTION: Imports the necessary Python libraries for the tutorial, including TensorFlow, TensorFlow Datasets, os, and json modules.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\nimport os, json\n```\n\n----------------------------------------\n\nTITLE: Configuring Bazel Build for TensorFlow C++ Example\nDESCRIPTION: This BUILD file configuration is used to compile the TensorFlow C++ example. It specifies the necessary dependencies and uses the tf_cc_binary rule to properly link the TensorFlow framework.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/cc.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nload(\"//tensorflow:tensorflow.bzl\", \"tf_cc_binary\")\n\ntf_cc_binary(\n    name = \"example\",\n    srcs = [\"example.cc\"],\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:client_session\",\n        \"//tensorflow/core:tensorflow\",\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Simple Tensor in TensorFlow\nDESCRIPTION: This snippet demonstrates how to evaluate a simple tensor using the Tensor.eval method. It creates a constant tensor, performs a multiplication, and then evaluates and prints the result.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconstant = tf.constant([1, 2, 3])\ntensor = constant * constant\nprint(tensor.eval())\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TF1 Estimator\nDESCRIPTION: Evaluating the trained estimator using the evaluation input function to calculate accuracy metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nestimator.evaluate(_eval_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Loading Keras Model from .keras File in Python\nDESCRIPTION: This code shows how to load a previously saved Keras model from a .keras file. The loaded model is a reconstruction of the original model and can be used for further operations or predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nreconstructed_model = tf.keras.models.load_model(\"exname_of_file.keras\")\n```\n\n----------------------------------------\n\nTITLE: Parallelizing Data Extraction from TFRecord Files in TensorFlow\nDESCRIPTION: This snippet demonstrates how to parallelize data extraction from multiple TFRecord files using interleave. It improves performance when reading from multiple input files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\ndataset = dataset.interleave(tf.data.TFRecordDataset,\n  num_parallel_calls=tf.data.AUTOTUNE,\n  deterministic=False)\n```\n\n----------------------------------------\n\nTITLE: Running MoViNet Streaming Model on Full Video\nDESCRIPTION: Processes the entire video using the MoViNet streaming model, collecting logits for each frame and converting them to probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ninit_states = model.init_states(jumpingjack[tf.newaxis].shape)\n\n# Insert your video clip here\nvideo = jumpingjack\nimages = tf.split(video[tf.newaxis], video.shape[0], axis=1)\n\nall_logits = []\n\n# To run on a video, pass in one frame at a time\nstates = init_states\nfor image in tqdm.tqdm(images):\n  # predictions for each frame\n  logits, states = model({**states, 'image': image})\n  all_logits.append(logits)\n\n# concatenating all the logits\nlogits = tf.concat(all_logits, 0)\n# estimating probabilities\nprobs = tf.nn.softmax(logits, axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Building SavedModel CLI from Source with Bazel\nDESCRIPTION: Bazel command to build the SavedModel Command Line Interface tool from TensorFlow source code. This tool allows users to inspect and execute SavedModel files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ bazel build third_party/tensorflow/python/tools:saved_model_cli\n```\n\n----------------------------------------\n\nTITLE: Creating a Ragged Tensor from Row Lengths\nDESCRIPTION: Shows how to construct a ragged tensor using tf.RaggedTensor.from_row_lengths by specifying the length of each row.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.RaggedTensor.from_row_lengths(\n    values=[3, 1, 4, 1, 5, 9, 2, 6],\n    row_lengths=[4, 0, 3, 1]))\n```\n\n----------------------------------------\n\nTITLE: Displaying Training Labels\nDESCRIPTION: Showing the labels for the training batch\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_labels_batch\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Test Image for ESRGAN Evaluation\nDESCRIPTION: Loads the test image and applies preprocessing to prepare it for ESRGAN evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nhr_image = preprocess_image(IMAGE_PATH)\n```\n\n----------------------------------------\n\nTITLE: Using Dataset.snapshot() for Temporary CSV Dataset Storage\nDESCRIPTION: This snippet demonstrates the use of Dataset.snapshot() which saves data to disk for reuse between TensorFlow processes. Unlike cache(), snapshot files can be read by other processes, but are only meant for temporary storage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n%%time\nsnapshotting = traffic_volume_csv_gz_ds.snapshot('titanic.tfsnap').shuffle(1000)\n\nfor i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n  if i % 40 == 0:\n    print('.', end='')\nprint()\n```\n\n----------------------------------------\n\nTITLE: Plotting Spectrogram Visualization\nDESCRIPTION: Function to visualize spectrogram data using matplotlib, converting frequencies to log scale and displaying as a heatmap.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef plot_spectrogram(spectrogram, ax):\n  if len(spectrogram.shape) > 2:\n    assert len(spectrogram.shape) == 3\n    spectrogram = np.squeeze(spectrogram, axis=-1)\n  # Convert the frequencies to log scale and transpose, so that the time is\n  # represented on the x-axis (columns).\n  # Add an epsilon to avoid taking a log of zero.\n  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n  height = log_spec.shape[0]\n  width = log_spec.shape[1]\n  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n  Y = range(height)\n  ax.pcolormesh(X, Y, log_spec)\n```\n\n----------------------------------------\n\nTITLE: Training the model with TensorFlow dataset\nDESCRIPTION: Trains the neural network model using the prepared training dataset for 10 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(train_dataset, epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Float16 Overflow Example\nDESCRIPTION: Demonstrates numeric overflow with float16 data type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(256, dtype='float16')\n(x ** 2).numpy()  # Overflow\n```\n\n----------------------------------------\n\nTITLE: Setting Up Upstream Remote for TensorFlow Projects\nDESCRIPTION: Git commands for maintaining an up-to-date local repository by syncing with the upstream TensorFlow repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ git remote add upstream git@github.com:tensorflow/project-repo-name\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git checkout master\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git pull upstream master\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git push origin master\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ git checkout -b branch-name\n```\n\n----------------------------------------\n\nTITLE: Creating and Inspecting TensorFlow Tensors\nDESCRIPTION: Demonstrates how to create a 2D tensor using tf.constant and access its properties like shape and data type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nx = tf.constant([[1., 2., 3.],\n                 [4., 5., 6.]])\n\nprint(x)\nprint(x.shape)\nprint(x.dtype)\n```\n\n----------------------------------------\n\nTITLE: Debugging TensorFlow with Constant Folding\nDESCRIPTION: This snippet shows an example of how constant folding may prevent tfdbg from capturing intermediate tensor dumps. In this example, all the nodes of the TensorFlow graph are constant-folded by the TensorFlow runtime.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n\"a = tf.ones([10], name=\\\"a\\\")\\nb = tf.add(a, a, name=\\\"b\\\")\\nsess = tf.Session()\\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\\nsess.run(b)\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Batch Jacobian in TensorFlow\nDESCRIPTION: This code demonstrates the use of batch_jacobian method in TensorFlow, which efficiently computes the Jacobian for a stack of independent inputs and outputs. It compares the results with the full Jacobian calculation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.normal([7, 5])\n\nlayer1 = tf.keras.layers.Dense(8, activation=tf.nn.elu)\nlayer2 = tf.keras.layers.Dense(6, activation=tf.nn.elu)\n\nwith tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n  tape.watch(x)\n  y = layer1(x)\n  y = layer2(y)\n\nj = tape.jacobian(y, x)\njb = tape.batch_jacobian(y, x)\n```\n\n----------------------------------------\n\nTITLE: Running the TensorFlow upgrade script in SAFETY mode\nDESCRIPTION: Command that uses the tf_upgrade_v2 tool with the SAFETY mode to convert a TensorFlow 1.x file to be compatible with TensorFlow 2.x while preserving functionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n!tf_upgrade_v2 --mode SAFETY --infile dropout.py --outfile dropout_v2_safe.py > /dev/null\n```\n\n----------------------------------------\n\nTITLE: Writing Multi-Line Blocks in TensorFlow DocTest\nDESCRIPTION: This snippet shows how to properly format multi-line blocks in DocTest for TensorFlow documentation, using (...) for continued lines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> if x > 0:\n...   print(\"X is positive\")\n>>> model.compile(\n...   loss=\"mse\",\n...   optimizer=\"adam\")\n```\n\n----------------------------------------\n\nTITLE: License Declaration - Apache 2.0\nDESCRIPTION: Apache 2.0 license declaration for TensorFlow Authors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Autosharding in TensorFlow\nDESCRIPTION: This snippet demonstrates how to configure autosharding options for a TensorFlow dataset using tf.data.experimental.DistributeOptions. It sets the auto_shard_policy to DATA.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\ndataset = dataset.with_options(options)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing MNIST Dataset\nDESCRIPTION: Loads the MNIST dataset using Keras API and normalizes the pixel values by dividing by 255 to convert to floating point numbers between 0 and 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/_index.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: Manual Epoch Iteration in TensorFlow\nDESCRIPTION: Shows how to manually iterate through a dataset for a specified number of epochs, allowing custom computations at the end of each epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_66\n\nLANGUAGE: python\nCODE:\n```\nepochs = 3\ndataset = titanic_lines.batch(128)\n\nfor epoch in range(epochs):\n  for batch in dataset:\n    print(batch.shape)\n  print(\"End of epoch: \", epoch)\n```\n\n----------------------------------------\n\nTITLE: Organizing Files by Class\nDESCRIPTION: Creates a function that organizes the list of files into a dictionary where keys are class names and values are lists of files belonging to each class, using collections.defaultdict to simplify the process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef get_files_per_class(files):\n  \"\"\" Retrieve the files that belong to each class.\n\n    Args:\n      files: List of files in the dataset.\n\n    Returns:\n      Dictionary of class names (key) and files (values). \n  \"\"\"\n  files_for_class = collections.defaultdict(list)\n  for fname in files:\n    class_name = get_class(fname)\n    files_for_class[class_name].append(fname)\n  return files_for_class\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Datasets Using Iterators in TensorFlow\nDESCRIPTION: Shows an alternative way to iterate over a dataset using iterators. This method allows for more control over the number of steps in each epoch and can be used both inside and outside of tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\nfor _ in range(EPOCHS):\n  total_loss = 0.0\n  num_batches = 0\n  train_iter = iter(train_dist_dataset)\n\n  for _ in range(10):\n    total_loss += distributed_train_step(next(train_iter))\n    num_batches += 1\n  average_train_loss = total_loss / num_batches\n\n  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n  print(template.format(epoch + 1, average_train_loss, train_accuracy.result() * 100))\n  train_accuracy.reset_states()\n```\n\n----------------------------------------\n\nTITLE: Inspecting the original TensorFlow 1.x dropout code\nDESCRIPTION: Command to display the contents of a Python file named 'dropout.py' that contains TensorFlow 1.x code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n!cat dropout.py\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Similarity Searches\nDESCRIPTION: Demonstrates semantic search capabilities including cross-lingual search and mixed-language corpus search.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsample_query = 'The stock market fell four points.'\nindex_language = 'English'\nnum_results = 10\n\nquery_embedding = embed_text(sample_query)[0]\nsearch_results = language_name_to_index[index_language].nearest(query_embedding, n=num_results)\n\nprint('{} sentences similar to: \"{}\"\\n'.format(index_language, sample_query))\nsearch_results\n```\n\n----------------------------------------\n\nTITLE: Handling Python Objects in TensorFlow Functions\nDESCRIPTION: This example illustrates the limitations of passing custom Python objects to tf.functions. It shows how changes to object attributes are not reflected in function calls due to instance-based equality, and provides workarounds using tf.Variables or creating new functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nclass SimpleModel(tf.Module):\n  def __init__(self):\n    # These values are *not* tf.Variables.\n    self.bias = 0.\n    self.weight = 2.\n\n@tf.function\ndef evaluate(model, x):\n  return model.weight * x + model.bias\n\nsimple_model = SimpleModel()\nx = tf.constant(10.)\nprint(evaluate(simple_model, x))\n\nprint(\"Adding bias!\")\nsimple_model.bias += 5.0\nprint(evaluate(simple_model, x))  # Didn't change :(\n\ndef evaluate(model, x):\n  return model.weight * x + model.bias\n\nnew_model = SimpleModel()\nevaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n# Don't pass in `new_model`. `tf.function` already captured its state during tracing.\nprint(evaluate_no_bias(x))\n\nprint(\"Adding bias!\")\nnew_model.bias += 5.0\n# Create new `tf.function` and `ConcreteFunction` since you modified `new_model`.\nevaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)\nprint(evaluate_with_bias(x)) # Don't pass in `new_model`.\n```\n\n----------------------------------------\n\nTITLE: Training Deep Ensemble for Uncertainty Quantification in Python\nDESCRIPTION: This code snippet trains multiple instances of a ResNet model to create a deep ensemble. Each model is compiled and fit to the training data independently.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Deep ensemble training\nresnet_ensemble = []\nfor _ in range(num_ensemble):\n  resnet_model = DeepResNet(**resnet_config)\n  resnet_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n  resnet_model.fit(train_examples, train_labels, verbose=0, **fit_config)\n\n  resnet_ensemble.append(resnet_model)\n```\n\n----------------------------------------\n\nTITLE: Testing TensorFlow Hub Embedding Layer\nDESCRIPTION: Creating and testing a Keras layer using TensorFlow Hub's pre-trained text embedding model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nembedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\nhub_layer(train_examples_batch[:3])\n```\n\n----------------------------------------\n\nTITLE: Selecting a single test image and checking its shape\nDESCRIPTION: Extracts a single image from the test dataset and displays its shape. This demonstrates how to access individual elements from the test set for making individual predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Grab an image from the test dataset.\nimg = test_images[1]\n\nprint(img.shape)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Files in Current Directory\nDESCRIPTION: This bash command lists all Python files in the current directory. It uses the Jupyter notebook bash magic to execute the shell command.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\nls *.py\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow <2.11 on Windows for GPU Support\nDESCRIPTION: This command installs a version of TensorFlow below 2.11, which is the last version supporting GPU on Windows Native.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\npip install \"tensorflow<2.11\"\n```\n\n----------------------------------------\n\nTITLE: Iterating Through a CSV Dataset\nDESCRIPTION: Demonstrates how to iterate through a CSV dataset and print each line as a numpy array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nfor line in dataset:\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating with TPUEstimator in TensorFlow 1\nDESCRIPTION: Demonstrates how to train and evaluate a model using TPUEstimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nestimator.train(_input_fn, steps=1)\n\nestimator.evaluate(_eval_input_fn, steps=1)\n```\n\n----------------------------------------\n\nTITLE: Creating Complete Dataset Pipeline from Parsed TFRecord Tensors\nDESCRIPTION: Builds the final optimized dataset pipeline by combining parsed image tensors with labels and applying standard dataset operations. This represents the most efficient configuration using serialized preprocessed tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nds = tf.data.Dataset.zip((ds, label_ds))\nds = ds.apply(\n  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\nds=ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Installing CUDA and cuDNN with Conda on Windows\nDESCRIPTION: This command installs CUDA toolkit and cuDNN libraries using Conda, setting up the GPU environment for TensorFlow on Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n```\n\n----------------------------------------\n\nTITLE: Grabbing an Image from Test Dataset\nDESCRIPTION: This snippet retrieves a single image from the test dataset. It selects the image at index 1 from the `test_images` array and assigns it to the variable `img`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Grab an image from the test dataset\nimg = test_images[1]\n\nprint(img.shape)\n```\n\n----------------------------------------\n\nTITLE: Element-wise Operations on Sparse Tensors (Alternative Method)\nDESCRIPTION: This code demonstrates an alternative method for performing element-wise operations on sparse tensors for earlier versions of TensorFlow. It creates a new sparse tensor with modified values while preserving the structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nst2_plus_5 = tf.sparse.SparseTensor(\n    st2.indices,\n    st2.values + 5,\n    st2.dense_shape)\nprint(tf.sparse.to_dense(st2_plus_5))\n```\n\n----------------------------------------\n\nTITLE: Compiling a Keras Model for Training\nDESCRIPTION: This code shows how to compile a Keras model by specifying the optimizer, loss function, and metrics. It uses the Adam optimizer, categorical crossentropy loss, and accuracy metric.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n# Adds a densely-connected layer with 64 units to the model:\nlayers.Dense(64, activation='relu', input_shape=(32,)),\n# Add another:\nlayers.Dense(64, activation='relu'),\n# Add a softmax layer with 10 output units:\nlayers.Dense(10, activation='softmax')])\n\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Starting Jupyter Notebook Server with TensorFlow\nDESCRIPTION: Command to start a Jupyter Notebook server using TensorFlow's nightly build in a Docker container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it -p 8888:8888 tensorflow/tensorflow:nightly-jupyter\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Package Dependencies with pip on Windows\nDESCRIPTION: Commands to install the necessary Python dependencies required for building TensorFlow from source. This includes upgrading pip and installing packages like numpy, wheel, and keras_preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip3 install -U pip\npip3 install -U six numpy wheel packaging\npip3 install -U keras_preprocessing --no-deps\n```\n\n----------------------------------------\n\nTITLE: Evaluating TensorFlow Model Once in Python\nDESCRIPTION: This snippet demonstrates how to evaluate a TensorFlow model once using tfdbg's evaluation function. It requires setting the necessary evaluation operations and optional debug hooks. The checkPoint path and log directory must be properly configured beforehand.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntf.contrib.slim.evaluation.evaluate_once( '', checkpoint_path, logdir, eval_op=my_eval_op, final_op=my_value_op, hooks=[tf_debug.LocalCLIDebugHook()])\n```\n\n----------------------------------------\n\nTITLE: Helper Function for Visualization\nDESCRIPTION: Defines a plot function to visualize image examples with their labels and predictions in a grid layout\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef plot(examples, predictions=None):\n  # Get the images, labels, and optionally predictions\n  images = examples['image']\n  labels = examples['label']\n  batch_size = len(images)\n  if predictions is None:\n    predictions = batch_size * [None]\n\n  # Configure the layout of the grid\n  x = np.ceil(np.sqrt(batch_size))\n  y = np.ceil(batch_size / x)\n  fig = plt.figure(figsize=(x * 6, y * 7))\n\n  for i, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n    # Render the image\n    ax = fig.add_subplot(x, y, i+1)\n    ax.imshow(image, aspect='auto')\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    # Display the label and optionally prediction\n    x_label = 'Label: ' + name_map[class_names[label]]\n    if prediction is not None:\n      x_label = 'Prediction: ' + name_map[class_names[prediction]] + '\\n' + x_label\n      ax.xaxis.label.set_color('green' if label == prediction else 'red')\n    ax.set_xlabel(x_label)\n\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Parsing Quick Draw Ink Data in Python\nDESCRIPTION: Function to parse a line from ndjson file, extract drawing strokes and class name, normalize the size, and compute deltas between consecutive points for the RNN model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef parse_line(ndjson_line):\n  \"\"\"Parse an ndjson line and return ink (as np array) and classname.\"\"\"\n  sample = json.loads(ndjson_line)\n  class_name = sample[\"word\"]\n  inkarray = sample[\"drawing\"]\n  stroke_lengths = [len(stroke[0]) for stroke in inkarray]\n  total_points = sum(stroke_lengths)\n  np_ink = np.zeros((total_points, 3), dtype=np.float32)\n  current_t = 0\n  for stroke in inkarray:\n    for i in [0, 1]:\n      np_ink[current_t:(current_t + len(stroke[0])), i] = stroke[i]\n    current_t += len(stroke[0])\n    np_ink[current_t - 1, 2] = 1  # stroke_end\n  # Preprocessing.\n  # 1. Size normalization.\n  lower = np.min(np_ink[:, 0:2], axis=0)\n  upper = np.max(np_ink[:, 0:2], axis=0)\n  scale = upper - lower\n  scale[scale == 0] = 1\n  np_ink[:, 0:2] = (np_ink[:, 0:2] - lower) / scale\n  # 2. Compute deltas.\n  np_ink[1:, 0:2] -= np_ink[0:-1, 0:2]\n  np_ink = np_ink[1:, :]\n  return np_ink, class_name\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Training Loop with Early Stopping in TensorFlow\nDESCRIPTION: Creates a custom training loop that iterates through epochs and batches, tracking validation loss to implement early stopping when the validation loss doesn't improve for a specified number of epochs (patience).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nepochs = 100\npatience = 5\nwait = 0\nbest = float('inf')\n\nfor epoch in range(epochs):\n    print(\"\\nStart of epoch %d\" % (epoch,))\n    start_time = time.time()\n\n    for step, (x_batch_train, y_batch_train) in enumerate(ds_train):\n      loss_value = train_step(x_batch_train, y_batch_train)\n      if step % 200 == 0:\n        print(\"Training loss at step %d: %.4f\" % (step, loss_value.numpy()))\n        print(\"Seen so far: %s samples\" % ((step + 1) * 128))        \n    train_acc = train_acc_metric.result()\n    train_loss = train_loss_metric.result()\n    train_acc_metric.reset_states()\n    train_loss_metric.reset_states()\n    print(\"Training acc over epoch: %.4f\" % (train_acc.numpy()))\n\n    for x_batch_val, y_batch_val in ds_test:\n      test_step(x_batch_val, y_batch_val)\n    val_acc = val_acc_metric.result()\n    val_loss = val_loss_metric.result()\n    val_acc_metric.reset_states()\n    val_loss_metric.reset_states()\n    print(\"Validation acc: %.4f\" % (float(val_acc),))\n    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n\n    # The early stopping strategy: stop the training if `val_loss` does not\n    # decrease over a certain number of epochs.\n    wait += 1\n    if val_loss < best:\n      best = val_loss\n      wait = 0\n    if wait >= patience:\n      break\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Loop with State Management in TensorFlow\nDESCRIPTION: A complete training loop for a TensorFlow model with stateful behavior. The code handles epoch tracking, model state reset, gradient computation using GradientTape, loss calculation, and periodic checkpointing. It also includes progress tracking by printing batch and epoch losses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Training step\nEPOCHS = 1\n\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    # initializing the hidden state at the start of every epoch\n    # initially hidden is None\n    hidden = model.reset_states()\n\n    for (batch_n, (inp, target)) in enumerate(dataset):\n          with tf.GradientTape() as tape:\n              # feeding the hidden state back into the model\n              # This is the interesting step\n              predictions = model(inp)\n              loss = tf.losses.sparse_softmax_cross_entropy(target, predictions)\n\n          grads = tape.gradient(loss, model.trainable_variables)\n          optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n          if batch_n % 100 == 0:\n              template = 'Epoch {} Batch {} Loss {:.4f}'\n              print(template.format(epoch+1, batch_n, loss))\n\n    # saving (checkpoint) the model every 5 epochs\n    if (epoch + 1) % 5 == 0:\n      model.save_weights(checkpoint_prefix.format(epoch=epoch))\n\n    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n\nmodel.save_weights(checkpoint_prefix.format(epoch=epoch))\n```\n\n----------------------------------------\n\nTITLE: Wide and Deep Model\nDESCRIPTION: This code demonstrates how to create a wide and deep model using `tf.estimator.DNNLinearCombinedClassifier`. It combines linear features (wide_columns) with deep neural network features (deep_columns) and specifies the hidden units for the DNN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ne = tf.estimator.DNNLinearCombinedClassifier(\n    model_dir=YOUR_MODEL_DIR,\n    linear_feature_columns=wide_columns,\n    dnn_feature_columns=deep_columns,\n    dnn_hidden_units=[100, 50])\n```\n\n----------------------------------------\n\nTITLE: Training Step Implementation\nDESCRIPTION: Defines the core training step using gradient tape for calculating and applying gradients to both generators and discriminators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(real_x, real_y):\n  with tf.GradientTape(persistent=True) as tape:\n    fake_y = generator_g(real_x, training=True)\n    cycled_x = generator_f(fake_y, training=True)\n\n    fake_x = generator_f(real_y, training=True)\n    cycled_y = generator_g(fake_x, training=True)\n\n    same_x = generator_f(real_x, training=True)\n    same_y = generator_g(real_y, training=True)\n\n    disc_real_x = discriminator_x(real_x, training=True)\n    disc_real_y = discriminator_y(real_y, training=True)\n\n    disc_fake_x = discriminator_x(fake_x, training=True)\n    disc_fake_y = discriminator_y(fake_y, training=True)\n\n    gen_g_loss = generator_loss(disc_fake_y)\n    gen_f_loss = generator_loss(disc_fake_x)\n    \n    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n    \n    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n\n    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n  \n  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n  \n  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n  \n  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n  \n  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n  \n  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n```\n\n----------------------------------------\n\nTITLE: Registering Deprecated Operation in TensorFlow\nDESCRIPTION: Example of how to register a deprecated operation in TensorFlow using REGISTER_OP with deprecation notice. This shows the syntax for marking an operation as deprecated at a specific version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/version_compat.md#2025-04-21_snippet_1\n\nLANGUAGE: cpp\nCODE:\n```\nREGISTER_OP(...).Deprecated(deprecated_at_version, message)\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: Contains the Apache License 2.0 declaration that applies to the TensorFlow documentation and examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow 1.0 Script with TensorFlow 2.x in Bash\nDESCRIPTION: This command attempts to run the TensorFlow 1.0 script with TensorFlow 2.x installed, which is expected to fail.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n(cd models/samples/cookbook/regression && python custom_regression.py)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Hub in developer mode\nDESCRIPTION: Command to install TensorFlow Hub in developer mode for testing local changes without rebuilding the pip package.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\npython tensorflow_hub/pip_package/setup.py develop\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow in Python\nDESCRIPTION: This code snippet imports the TensorFlow library, which is essential for working with sparse tensors and other TensorFlow operations in the subsequent code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Creating a Zero Baseline for Integrated Gradients\nDESCRIPTION: Establishes a black image (all zeros) as the baseline for Integrated Gradients calculation. The baseline represents the absence of features and serves as the starting point for the path integral.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nbaseline = tf.zeros(shape=(224,224,3))\n```\n\n----------------------------------------\n\nTITLE: Cleaning Bazel Cache on Windows\nDESCRIPTION: Commands to clean the Bazel cache to resolve errors due to invalid or outdated cached data. The --expunge flag permanently removes cached files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nbazel clean \nbazel clean --expunge  \n```\n\n----------------------------------------\n\nTITLE: Using element_spec with tf.function for Type Specification\nDESCRIPTION: This snippet shows how to use the element_spec property to provide type specifications for distributed dataset elements when using tf.function. This ensures proper type checking and optimization during graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 16\nepochs = 5\nsteps_per_epoch = 5\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n\n@tf.function(input_signature=[dist_dataset.element_spec])\ndef train_step(per_replica_inputs):\n  def step_fn(inputs):\n    return 2 * inputs\n\n  return mirrored_strategy.run(step_fn, args=(per_replica_inputs,))\n\nfor _ in range(epochs):\n  iterator = iter(dist_dataset)\n  for _ in range(steps_per_epoch):\n    output = train_step(next(iterator))\n    tf.print(output)\n```\n\n----------------------------------------\n\nTITLE: Applying Parallel Interleave with TensorFlow\nDESCRIPTION: The code snippet demonstrates the use of tf.data.experimental.parallel_interleave to parallelize and interleave data extraction. It ensures efficient reading from multiple files by overlapping input operations, which is crucial for managing remote data. cycle_length specifies the number of datasets to interleave concurrently, needing tf.data.TFRecordDataset.\n\nDependencies:\n- TensorFlow library\n- Needs FLAGS.num_parallel_readers for cycle_length\n\nInputs: Files to be read concurrently\nOutputs: A tf.data.Dataset object with interleaved file contents\nNote: Balances performance with determinism using the 'sloppy' option.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/datasets.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ndataset = files.apply(tf.contrib.data.parallel_interleave(\n    tf.data.TFRecordDataset, cycle_length=FLAGS.num_parallel_readers))\n```\n\n----------------------------------------\n\nTITLE: License and Copyright Information for TensorFlow Hub\nDESCRIPTION: This code block contains the copyright notice and Apache License 2.0 information for the TensorFlow Hub Authors. It's a standard header included in TensorFlow Hub example files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Graph Nodes for Image Processing\nDESCRIPTION: This snippet constructs various TensorFlow graph nodes for reading a file, decoding image formats, and scaling the pixel values to prepare the image for the model input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_6\n\nLANGUAGE: C++\nCODE:\n```\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  tensorflow::Node* file_reader =\n      tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),\n                                b.opts().WithName(input_name));\n\n  const int wanted_channels = 3;\n  tensorflow::Node* image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = tensorflow::ops::DecodePng(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"png_reader\"));\n  } else {\n    image_reader = tensorflow::ops::DecodeJpeg(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"jpeg_reader\"));\n  }\n  tensorflow::Node* float_caster = tensorflow::ops::Cast(\n      image_reader, tensorflow::DT_FLOAT, b.opts().WithName(\"float_caster\"));\n  tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(\n      float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());\n  tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(\n      dims_expander, tensorflow::ops::Const({input_height, input_width},\n                                            b.opts().WithName(\"size\")),\n      b.opts());\n  tensorflow::ops::Div(\n      tensorflow::ops::Sub(\n          resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),\n      tensorflow::ops::Const({input_std}, b.opts()),\n      b.opts().WithName(output_name));\n```\n\n----------------------------------------\n\nTITLE: Input Handling with Feature Columns\nDESCRIPTION: Demonstrates how to handle input dictionary and create feature columns in TensorFlow 1.x style.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ninput_dict = {\n  'foo': tf.constant([1]),\n  'bar': tf.constant([0]),\n  'baz': tf.constant([-1])\n}\n\ncolumns = [\n  tf1.feature_column.numeric_column('foo'),\n  tf1.feature_column.numeric_column('bar'),\n  tf1.feature_column.numeric_column('baz'),\n]\ncall_feature_columns(columns, input_dict)\n```\n\n----------------------------------------\n\nTITLE: Downloading Compressed TensorFlow Model using wget\nDESCRIPTION: Shell command to download a compressed TensorFlow model from tfhub.dev using wget by appending the tf-hub-format parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/hosting.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nwget https://tfhub.dev/tensorflow/albert_en_xxlarge/1?tf-hub-format=compressed\n```\n\n----------------------------------------\n\nTITLE: Checking Model Trainable Variables Count\nDESCRIPTION: Counts the number of trainable variables in the model. Since MobileNetV2 weights are frozen, only the dense layer weights and biases are trainable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nlen(model.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for HRNet Model Usage\nDESCRIPTION: Imports the necessary Python libraries (TensorFlow, TensorFlow Hub, Matplotlib, PIL, and NumPy) for loading models and processing images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Viewing Upgrade Report in Bash\nDESCRIPTION: This command displays the first 20 lines of the upgrade report, which includes warnings and details about the changes made.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nhead -n 20 tree_report.txt\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Built-in Data Types in C++\nDESCRIPTION: Example of registering a TensorFlow operation that accepts inputs with specific built-in types. This op takes 'integers' of type int32 and 'complex_numbers' of type complex64.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_38\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"BuiltInTypesExample\")\n    .Input(\"integers: int32\")\n    .Input(\"complex_numbers: complex64\");\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Checking Version\nDESCRIPTION: Imports the TensorFlow library and prints its version number.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints and Cleaning Up in TensorFlow Distributed Training\nDESCRIPTION: Saving model checkpoints in a distributed environment and removing temporary checkpoint directories created by non-chief workers to avoid duplication.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_manager.save()\nif not _is_chief(task_type, task_id):\n  tf.io.gfile.rmtree(write_checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Updating TF_CONFIG for Second Worker\nDESCRIPTION: This code updates the task index in the TF_CONFIG dictionary and re-serializes it to prepare for launching the second worker process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ntf_config['task']['index'] = 1\nos.environ['TF_CONFIG'] = json.dumps(tf_config)\n```\n\n----------------------------------------\n\nTITLE: Quick Draw JSON Data Sample\nDESCRIPTION: Example of the JSON structure for a single drawing from the Quick Draw dataset, showing the word (category), country code, timestamp, and drawing data represented as strokes of x,y coordinates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\"word\":\"cat\",\n \"countrycode\":\"VE\",\n \"timestamp\":\"2017-03-02 23:25:10.07453 UTC\",\n \"recognized\":true,\n \"key_id\":\"5201136883597312\",\n \"drawing\":[\n   [\n     [130,113,99,109,76,64,55,48,48,51,59,86,133,154,170,203,214,217,215,208,186,176,162,157,132],\n     [72,40,27,79,82,88,100,120,134,152,165,184,189,186,179,152,131,114,100,89,76,0,31,65,70]\n   ],[\n     [76,28,7],\n     [136,128,128]\n   ],[\n     [76,23,0],\n     [160,164,175]\n   ],[\n     [87,52,37],\n     [175,191,204]\n   ],[\n     [174,220,246,251],\n     [134,132,136,139]\n   ],[\n     [175,255],\n     [147,168]\n   ],[\n     [171,208,215],\n     [164,198,210]\n   ],[\n     [130,110,108,111,130,139,139,119],\n     [129,134,137,144,148,144,136,130]\n   ],[\n     [107,106],\n     [96,113]\n   ]\n ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using Variables in Computations\nDESCRIPTION: Demonstrates using a variable in tensor computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n           # Any time a variable is used in an expression it gets automatically\n           # converted to a tf.Tensor representing its value.\n```\n\n----------------------------------------\n\nTITLE: Initialize TensorFlow 1.x Compatibility\nDESCRIPTION: Imports TensorFlow 1.x compatibility mode and disables v2 behavior\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n```\n\n----------------------------------------\n\nTITLE: Calculating Loss and Training on Dataset\nDESCRIPTION: This snippet calculates the loss over the dataset by feeding word batches into the LSTM, maintaining its state between iterations. It accumulates the total loss for evaluation after processing all batches, showing an example of how to manage state across time steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# A numpy array holding the state of LSTM after each batch of words.\nnumpy_state = initial_state.eval()\ntotal_loss = 0.0\nfor current_batch_of_words in words_in_dataset:\n    numpy_state, current_loss = session.run([final_state, loss],\n        # Initialize the LSTM state from the previous iteration.\n        feed_dict={initial_state: numpy_state, words: current_batch_of_words})\n    total_loss += current_loss\n```\n\n----------------------------------------\n\nTITLE: Plotting First Image and Prediction\nDESCRIPTION: This snippet plots the image and prediction for the 0th test image using the `plot_image` and `plot_value_array` functions defined previously. It creates a figure with two subplots, one for the image and one for the prediction bar chart, then displays the figure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ni = 0\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  test_labels)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Exporting TensorFlow Model with Estimator in Python\nDESCRIPTION: Demonstrates how to export a trained TensorFlow Estimator model using the export_savedmodel method. This method requires a base path for export and a serving input receiver function. Makes use of TensorFlow libraries and tools to manage checkpoints and graph sessions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nestimator.export_savedmodel(export_dir_base, serving_input_receiver_fn,\n                            strip_default_attrs=True)\n```\n\n----------------------------------------\n\nTITLE: Inserting Data at Specific Indices with tf.scatter_nd\nDESCRIPTION: Shows how to create a tensor by inserting values at specific indices using tf.scatter_nd, with zeros at other positions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nt6 = tf.constant([10])\nindices = tf.constant([[1], [3], [5], [7], [9]])\ndata = tf.constant([2, 4, 6, 8, 10])\n\nprint(tf.scatter_nd(indices=indices,\n                    updates=data,\n                    shape=t6))\n```\n\n----------------------------------------\n\nTITLE: License Configuration in Python\nDESCRIPTION: Apache License 2.0 configuration for a TensorFlow documentation notebook, defining the terms under which the code can be used, modified, and distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing License and Copyright Information in Python\nDESCRIPTION: Includes copyright and license information for TensorFlow Hub Authors under the Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Nightly Build\nDESCRIPTION: Installation command for the nightly build of TensorFlow, required to use the save_freq parameter in BackupAndRestore callback introduced in TensorFlow 2.10.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install tf-nightly\n```\n\n----------------------------------------\n\nTITLE: Creating Image Downscaling Function for ESRGAN Evaluation\nDESCRIPTION: Defines a function to artificially downscale images using bicubic interpolation, simulating low-resolution inputs for testing super resolution performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Defining helper functions\ndef downscale_image(image):\n  \"\"\"\n      Scales down images using bicubic downsampling.\n      Args:\n          image: 3D or 4D tensor of preprocessed image\n  \"\"\"\n  image_size = []\n  if len(image.shape) == 3:\n    image_size = [image.shape[1], image.shape[0]]\n  else:\n    raise ValueError(\"Dimension mismatch. Can work only on single image.\")\n\n  image = tf.squeeze(\n      tf.cast(\n          tf.clip_by_value(image, 0, 255), tf.uint8))\n\n  lr_image = np.asarray(\n    Image.fromarray(image.numpy())\n    .resize([image_size[0] // 4, image_size[1] // 4],\n              Image.BICUBIC))\n\n  lr_image = tf.expand_dims(lr_image, 0)\n  lr_image = tf.cast(lr_image, tf.float32)\n  return lr_image\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset\nDESCRIPTION: Loads the MNIST dataset using Keras datasets API and normalizes the image data by dividing by 255.0 to scale pixel values between 0 and 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: Broadcasting 1D Tensor with 3D RaggedTensor\nDESCRIPTION: Shows broadcasting between a 1D tensor with shape [3] and a 3D ragged tensor with a shape ending in [1], resulting in broadcasting across the final dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_51\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged):  2 x (r1) x (r2) x 1\n# y      (1d tensor):                    3\n# Result (3d ragged):  2 x (r1) x (r2) x 3\nx = tf.ragged.constant(\n    [\n        [\n            [[1], [2]],\n            [],\n            [[3]],\n            [[4]],\n        ],\n        [\n            [[5], [6]],\n            [[7]]\n        ]\n    ],\n    ragged_rank=2)\ny = tf.constant([10, 20, 30])\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Creating a tf.data.Dataset from CSV file\nDESCRIPTION: This snippet creates a tf.data.Dataset from a CSV file using tf.data.experimental.make_csv_dataset. It specifies the file path, batch size, column names, label name, and number of epochs. The resulting dataset is shuffled and repeated indefinitely by default.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\n\ntrain_dataset = tf.data.experimental.make_csv_dataset(\n    train_dataset_fp,\n    batch_size,\n    column_names=column_names,\n    label_name=label_name,\n    num_epochs=1)\n```\n\n----------------------------------------\n\nTITLE: Creating Higher Rank Tensors in TensorFlow\nDESCRIPTION: Demonstrates creation of rank 2 tensors (matrices) and rank 4 tensors (image processing example).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmymat = tf.Variable([[7],[11]], tf.int16)\nmyxor = tf.Variable([[False, True],[True, False]], tf.bool)\nlinear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\nsquarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\nrank_of_squares = tf.rank(squarish_squares)\nmymatC = tf.Variable([[7],[11]], tf.int32)\n```\n\n----------------------------------------\n\nTITLE: Iterating Through CSV Dataset Rows\nDESCRIPTION: Demonstrates how to iterate through the first 10 records of the CSV dataset and access specific columns. This example prints the first column (font name) of each row.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nfor row in simple_font_ds.take(10):\n  print(row[0].numpy())\n```\n\n----------------------------------------\n\nTITLE: Unexpected Behavior with Python Global Variables in tf.function\nDESCRIPTION: Demonstrates how changing Python global variables in a tf.function is a side effect that only happens during tracing, not during execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nexternal_list = []\n\n@tf.function\ndef side_effect(x):\n  print('Python side effect')\n  external_list.append(x)\n\nside_effect(1)\nside_effect(1)\nside_effect(1)\n# The list append only happened once!\nassert len(external_list) == 1\n```\n\n----------------------------------------\n\nTITLE: Initializing Variable with Constant\nDESCRIPTION: Creates a TensorFlow variable initialized with a constant tensor value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nother_variable = tf.get_variable(\"other_variable\", dtype=tf.int32,\n  initializer=tf.constant([23, 42]))\n```\n\n----------------------------------------\n\nTITLE: Using a Complex Python Generator\nDESCRIPTION: This snippet demonstrates how to use the gen_series generator, printing the first few generated items.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfor i, series in gen_series():\n  print(i, \":\", str(series))\n  if i > 5:\n    break\n```\n\n----------------------------------------\n\nTITLE: Setting Up the PDE Parameters and Update Rules in Python\nDESCRIPTION: Defines the parameters for the simulation (time resolution and wave damping) and creates TensorFlow variables for the simulation state. The update rules for the discretized PDE are established as TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Parameters:\n# eps -- time resolution\n# damping -- wave damping\neps = tf.placeholder(tf.float32, shape=())\ndamping = tf.placeholder(tf.float32, shape=())\n\n# Create variables for simulation state\nU  = tf.Variable(u_init)\nUt = tf.Variable(ut_init)\n\n# Discretized PDE update rules\nU_ = U + eps * Ut\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\n\n# Operation to update the state\nstep = tf.group(\n  U.assign(U_),\n  Ut.assign(Ut_))\n\n```\n\n----------------------------------------\n\nTITLE: Training DNNClassifier\nDESCRIPTION: Trains the classifier using the specified input function and number of steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclassifier.train(\n    input_fn=lambda: train_input_fn(train_x, train_y, batch_size=100),\n    steps=200)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Time-Based Early Stopping with Keras Model.fit\nDESCRIPTION: Demonstrates using the custom LimitTrainingTime callback to stop model training after 30 seconds, regardless of other training parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Limit the training time to 30 seconds.\ncallback = LimitTrainingTime(30)\nhistory = model.fit(\n    ds_train,\n    epochs=100,\n    validation_data=ds_test,\n    callbacks=[callback]\n)\nlen(history.history['loss'])\n```\n\n----------------------------------------\n\nTITLE: Loading Fashion MNIST Dataset in TensorFlow\nDESCRIPTION: This code loads the Fashion MNIST dataset using TensorFlow's built-in dataset API. It separates the data into training and test sets for both images and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic MNIST Classification with TensorFlow Keras\nDESCRIPTION: A basic neural network implementation for MNIST digit classification using TensorFlow's Keras API. The model includes a flattening layer, dense layer with ReLU activation, dropout for regularization, and final softmax layer for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test, y_test)\n```\n\n----------------------------------------\n\nTITLE: Creating a Keras Sequential Model\nDESCRIPTION: This code creates a tf.keras.Sequential model with three dense layers. The first layer has an input shape of (4,), representing the four features of the Iris dataset. ReLU activation functions are used in the first two layers, and the output layer has 3 nodes for the three Iris species.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n  tf.keras.layers.Dense(3)\n])\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Compression Compatible with Current TensorFlow Version\nDESCRIPTION: Bash script that detects the installed TensorFlow version and installs a compatible version of TensorFlow Compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Installs the latest version of TFC compatible with the installed TF version.\n\nread MAJOR MINOR <<< \"$(pip show tensorflow | perl -p -0777 -e 's/.*Version: (\\d+)\\.(\\d+).*/\\1 \\2/sg')\"\npip install \"tensorflow-compression<$MAJOR.$(($MINOR+1))\"\n\n```\n\n----------------------------------------\n\nTITLE: Creating tf.Example protocol buffers with variable-length features\nDESCRIPTION: Defines a batch of tf.Example messages with different feature lengths using protocol buffer text format, which is useful for serializing and storing ragged data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimport google.protobuf.text_format as pbtext\n\ndef build_tf_example(s):\n  return pbtext.Merge(s, tf.train.Example()).SerializeToString()\n\nexample_batch = [\n  build_tf_example(r'''\n    features {\n      feature {key: \"colors\" value {bytes_list {value: [\"red\", \"blue\"]} } }\n      feature {key: \"lengths\" value {int64_list {value: [7]} } } }'''),\n  build_tf_example(r'''\n    features {\n      feature {key: \"colors\" value {bytes_list {value: [\"orange\"]} } }\n      feature {key: \"lengths\" value {int64_list {value: []} } } }'''),\n  build_tf_example(r'''\n    features {\n      feature {key: \"colors\" value {bytes_list {value: [\"black\", \"yellow\"]} } }\n      feature {key: \"lengths\" value {int64_list {value: [1, 3]} } } }'''),\n  build_tf_example(r'''\n    features {\n      feature {key: \"colors\" value {bytes_list {value: [\"green\"]} } }\n      feature {key: \"lengths\" value {int64_list {value: [3, 5, 2]} } } }''')]\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Flower Classification\nDESCRIPTION: Imports necessary Python libraries for the flower classification task, including TensorFlow, TensorFlow Hub, and data visualization libraries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport collections\nimport io\nimport math\nimport os\nimport random\nfrom six.moves import urllib\n\nfrom IPython.display import clear_output, Image, display, HTML\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics as sk_metrics\nimport time\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Datasets\nDESCRIPTION: Installs or upgrades the TensorFlow Datasets package using pip.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install --quiet --upgrade tensorflow-datasets\n```\n\n----------------------------------------\n\nTITLE: Displaying Apache License 2.0 in Python\nDESCRIPTION: Contains the Apache License 2.0 text as a comment block in Python. This license governs the use of the TensorFlow codebase.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Decompressing Layers and Cloning Model in Python\nDESCRIPTION: This snippet defines a function to decompress CompressedDense and CompressedConv2D layers, and uses it to clone a compressed classifier into a decompressed model. It's useful for converting a compressed model to a regular one for inference or further training without compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef decompress_layer(layer):\n  if isinstance(layer, CompressedDense):\n    return CustomDense.copy(layer)\n  if isinstance(layer, CompressedConv2D):\n    return CustomConv2D.copy(layer)\n  return type(layer).from_config(layer.get_config())\n\ndecompressed_classifier = tf.keras.models.clone_model(\n    compressed_classifier, clone_function=decompress_layer)\n```\n\n----------------------------------------\n\nTITLE: Loading and Inspecting BigBiGAN TensorFlow Hub Module\nDESCRIPTION: Loads the specified BigBiGAN module from TensorFlow Hub and prints out its available signatures, inputs, and outputs for inspection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# module = hub.Module(module_path, trainable=True, tags={'train'})  # training\nmodule = hub.Module(module_path)  # inference\n\nfor signature in module.get_signature_names():\n  print('Signature:', signature)\n  print('Inputs:', pformat(module.get_input_info_dict(signature)))\n  print('Outputs:', pformat(module.get_output_info_dict(signature)))\n  print()\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Flower Image Dataset\nDESCRIPTION: This code downloads a flower image dataset, extracts it, and prints the root directory of the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\ndata_root_orig = tf.keras.utils.get_file('flower_photos',\n                                         'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n                                         untar=True)\ndata_root = pathlib.Path(data_root_orig)\nprint(data_root)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Visualization (Python)\nDESCRIPTION: This snippet installs the seaborn library, which is used for visualizing data distributions through pair plots and other statistical graphics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install seaborn\n```\n\n----------------------------------------\n\nTITLE: Defining NCE Weights and Biases for Skip-gram Model in Python\nDESCRIPTION: Creates TensorFlow Variables for the weights and biases used in noise-contrastive estimation (NCE) loss calculation, with weights initialized from a truncated normal distribution and biases initialized to zeros.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnce_weights = tf.Variable(\n  tf.truncated_normal([vocabulary_size, embedding_size],\n                      stddev=1.0 / math.sqrt(embedding_size)))\nnce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n```\n\n----------------------------------------\n\nTITLE: Simulating Multiple GPUs with Virtual Devices in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create virtual GPUs using TensorFlow's configuration API. It sets up two virtual GPUs with 1GB memory each, allowing for testing of multi-GPU setups on systems with limited physical GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Create 2 virtual GPUs with 1GB memory each\n  try:\n    tf.config.set_logical_device_configuration(\n        gpus[0],\n        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Checking Quick Draw Dataset with gsutil (Shell)\nDESCRIPTION: Command to list the Quick Draw dataset files stored in Google Cloud Storage using gsutil, which helps verify access to the data bucket before downloading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngsutil ls -r \"gs://quickdraw_dataset/full/simplified/*\"\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow 1.15 and TensorFlow Hub\nDESCRIPTION: Commands to install TensorFlow 1.15 (the only supported 1.x version) and TensorFlow Hub. This setup is for legacy use with TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/installation.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install \"tensorflow>=1.15,<2.0\"\n$ pip install --upgrade tensorflow-hub\n```\n\n----------------------------------------\n\nTITLE: Identifying CIFAR-10 Image Categories\nDESCRIPTION: List of 10 image categories used in the CIFAR-10 classification problem, including various vehicles and animals\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_1\n\nLANGUAGE: Text\nCODE:\n```\nairplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck\n```\n\n----------------------------------------\n\nTITLE: Generated Python Interface for ZeroOut Op\nDESCRIPTION: Example of the automatically generated Python function signature for the ZeroOut op.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ndef zero_out(to_zero, name=None):\n  \"\"\"...\n  Args:\n    to_zero: A `Tensor`. Must be one of the following types:\n        `float32`, `int32`.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor`. Has the same type as `to_zero`.\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating utility functions for STS Benchmark dataset evaluation\nDESCRIPTION: Defines functions to download and load the Semantic Textual Similarity (STS) Benchmark dataset, which is used to evaluate how well the model's similarity scores align with human judgments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport pandas\nimport scipy\nimport math\n\n\ndef load_sts_dataset(filename):\n  # Loads a subset of the STS dataset into a DataFrame. In particular both\n  # sentences and their human rated similarity score.\n  sent_pairs = []\n  with tf.gfile.GFile(filename, \"r\") as f:\n    for line in f:\n      ts = line.strip().split(\"\\t\")\n      # (sent_1, sent_2, similarity_score)\n      sent_pairs.append((ts[5], ts[6], float(ts[4])))\n  return pandas.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n\n\ndef download_and_load_sts_data():\n  sts_dataset = tf.keras.utils.get_file(\n      fname=\"Stsbenchmark.tar.gz\",\n      origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n      extract=True)\n\n  sts_dev = load_sts_dataset(\n      os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n  sts_test = load_sts_dataset(\n      os.path.join(\n          os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n\n  return sts_dev, sts_test\n\n\nsts_dev, sts_test = download_and_load_sts_data()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Checkpoint Management in TensorFlow Distributed Training\nDESCRIPTION: Creating a checkpoint system for saving model weights in a distributed environment using tf.train.Checkpoint and tf.train.CheckpointManager. This allows for resuming training without saving the entire model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ncheckpoint_dir = '/tmp/ckpt'\n\ncheckpoint = tf.train.Checkpoint(model=multi_worker_model)\nwrite_checkpoint_dir = write_filepath(checkpoint_dir, task_type, task_id)\ncheckpoint_manager = tf.train.CheckpointManager(\n    checkpoint, directory=write_checkpoint_dir, max_to_keep=1)\n```\n\n----------------------------------------\n\nTITLE: Example Use Case: Combining Unigram and Bigram Embeddings for Queries\nDESCRIPTION: Demonstrates a complete example of using ragged tensors to build and combine unigram and bigram embeddings for variable-length text queries, with special markers for sentence boundaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nqueries = tf.ragged.constant([['Who', 'is', 'Dan', 'Smith'],\n                              ['Pause'],\n                              ['Will', 'it', 'rain', 'later', 'today']])\n\n# Create an embedding table.\nnum_buckets = 1024\nembedding_size = 4\nembedding_table = tf.Variable(\n    tf.truncated_normal([num_buckets, embedding_size],\n                       stddev=1.0 / math.sqrt(embedding_size)))\n\n# Look up the embedding for each word.\nword_buckets = tf.strings.to_hash_bucket_fast(queries, num_buckets)\nword_embeddings = tf.ragged.map_flat_values(\n    tf.nn.embedding_lookup, embedding_table, word_buckets)                  # ①\n\n# Add markers to the beginning and end of each sentence.\nmarker = tf.fill([queries.nrows(), 1], '#')\npadded = tf.concat([marker, queries, marker], axis=1)                       # ②\n\n# Build word bigrams & look up embeddings.\nbigrams = tf.string_join([padded[:, :-1], padded[:, 1:]], separator='+')    # ③\n\nbigram_buckets = tf.strings.to_hash_bucket_fast(bigrams, num_buckets)\nbigram_embeddings = tf.ragged.map_flat_values(\n    tf.nn.embedding_lookup, embedding_table, bigram_buckets)                # ④\n\n# Find the average embedding for each sentence\nall_embeddings = tf.concat([word_embeddings, bigram_embeddings], axis=1)    # ⑤\navg_embedding = tf.reduce_mean(all_embeddings, axis=1)                      # ⑥\nprint(avg_embedding)\n```\n\n----------------------------------------\n\nTITLE: Implementing Type-Specific Kernel Classes for Polymorphic Ops in TensorFlow\nDESCRIPTION: Shows how to implement separate kernel classes for each supported data type in a polymorphic op. Each kernel class handles a specific data type variant of the operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_24\n\nLANGUAGE: c++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nclass ZeroOutInt32Op : public OpKernel {\n  // as before\n};\n\nclass ZeroOutFloatOp : public OpKernel {\n public:\n  explicit ZeroOutFloatOp(OpKernelConstruction* context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<float>();\n\n    // Create an output tensor\n    Tensor* output = NULL;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_tensor.shape(), &output));\n    auto output_flat = output->template flat<float>();\n\n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the first input value\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n\n// Note that TypeConstraint<int32>(\"T\") means that attr \"T\" (defined\n// in the op registration above) must be \"int32\" to use this template\n// instantiation.\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<int32>(\"T\"),\n    ZeroOutInt32Op);\nREGISTER_KERNEL_BUILDER(\n    Name(\"ZeroOut\")\n    .Device(DEVICE_CPU)\n    .TypeConstraint<float>(\"T\"),\n    ZeroOutFloatOp);\n```\n\n----------------------------------------\n\nTITLE: Building Combined Multilingual Index\nDESCRIPTION: Creates a single search index containing entries from all languages with language annotations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nnum_index_trees = 60\nprint('Computing mixed-language index')\ncombined_index = SimpleNeighbors(embedding_dimensions, metric='dot')\nfor language_code, zip_file, news_file, language_name in corpus_metadata:\n  print('Adding {} embeddings to mixed-language index'.format(language_name))\n  for i in trange(len(language_to_sentences[language_code])):\n    annotated_sentence = '({}) {}'.format(language_name, language_to_sentences[language_code][i])\n    combined_index.add_one(annotated_sentence, language_to_embeddings[language_code][i])\n\nprint('Building mixed-language index with {} trees...'.format(num_index_trees))\ncombined_index.build(n=num_index_trees)\n```\n\n----------------------------------------\n\nTITLE: Preparing dataset and model for Keras in TensorFlow 2\nDESCRIPTION: Sets up the dataset pipeline, defines a simple Keras Sequential model, and configures the model for training using Keras APIs in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\neval_dataset = tf.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n\nmodel.compile(optimizer=optimizer, loss=\"mse\")\n```\n\n----------------------------------------\n\nTITLE: Splitting Dataset into Training and Validation Sets\nDESCRIPTION: Divides the dataset into training and validation subsets using tf.data operations. This creates an 80/20 split for model training and evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nval_size = int(image_count * 0.2)\ntrain_ds = list_ds.skip(val_size)\nval_ds = list_ds.take(val_size)\n```\n\n----------------------------------------\n\nTITLE: Creating TPUClusterResolver in TF1\nDESCRIPTION: This code snippet creates a `tf.distribute.cluster_resolver.TPUClusterResolver` to provide cluster information for the TPUs. It also prints the list of available TPU devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncluster_resolver = tf1.distribute.cluster_resolver.TPUClusterResolver(tpu='')\nprint(\"All devices: \", tf1.config.list_logical_devices('TPU'))\n```\n\n----------------------------------------\n\nTITLE: Decoding Characters and Identifying Scripts\nDESCRIPTION: Converts sentences into character codepoints and determines the Unicode script identifier for each character using TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nsentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\nprint(sentence_char_codepoint)\n\nsentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\nprint(sentence_char_script)\n```\n\n----------------------------------------\n\nTITLE: Setting Dataset Parameters for CVAE Training\nDESCRIPTION: Defines dataset parameters including training set size, batch size, and test set size for MNIST digit dataset processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_size = 60000\nbatch_size = 32\ntest_size = 10000\n```\n\n----------------------------------------\n\nTITLE: Replacing Project Name in Template Files using Bash\nDESCRIPTION: This command uses find and sed to replace 'PROJECT_NAME' with the actual project name in all files within the g3doc directory. This step customizes the template for the specific project.\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/subsite/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ find tensorflow/myproject/g3doc/ -type f | xargs sed -i 's/PROJECT_NAME/myproject/g'\n```\n\n----------------------------------------\n\nTITLE: Implementing StaticMethods in ExtensionType in Python\nDESCRIPTION: Shows how to define static factory methods in an ExtensionType class using the @staticmethod decorator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  def __repr__(self):\n    return masked_tensor_str(self.values, self.mask)\n\n  @staticmethod\n  def from_tensor_and_value_to_mask(values, value_to_mask):\n    return MaskedTensor(values, values != value_to_mask)\n\nx = tf.constant([[1, 0, 2], [3, 0, 0]])\nMaskedTensor.from_tensor_and_value_to_mask(x, 0)\n```\n\n----------------------------------------\n\nTITLE: Initializing License and Copyright Declaration in Python\nDESCRIPTION: Copyright notice and Apache 2.0 license declaration for TensorFlow Hub Authors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Image Inversion Function in Python\nDESCRIPTION: Defines a function that randomly inverts image colors based on a probability parameter. The function takes an image tensor and a probability value, then inverts pixel values (255-x) if a random value is less than the specified probability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef random_invert_img(x, p=0.5):\n  if  tf.random.uniform([]) < p:\n    x = (255-x)\n  else:\n    x\n  return x\n```\n\n----------------------------------------\n\nTITLE: Using Dimension Methods in TF1.x Style\nDESCRIPTION: Shows how dimension compatibility checks were performed in TensorFlow 1.x using methods on the Dimension object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndim = shape[i]\ndim.assert_is_compatible_with(other_dim)\n```\n\n----------------------------------------\n\nTITLE: Writing TFRecord File using TensorFlow (Python)\nDESCRIPTION: Uses TFRecordWriter to write serialized dataset to a TFRecord file, standardizing data storage within TensorFlow environments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfilename = 'test.tfrecord'\nwriter = tf.data.experimental.TFRecordWriter(filename)\nwriter.write(serialized_features_dataset)\n```\n\n----------------------------------------\n\nTITLE: Extracting Tensor Slices Using tf.slice\nDESCRIPTION: Demonstrates how to extract a subset of a tensor using the tf.slice function by specifying begin indices and size parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nt1 = tf.constant([0, 1, 2, 3, 4, 5, 6, 7])\n\nprint(tf.slice(t1,\n               begin=[1],\n               size=[3]))\n```\n\n----------------------------------------\n\nTITLE: Implementing Break Statement with AutoGraph\nDESCRIPTION: Shows how a Python break statement in a loop is converted to TensorFlow operations, implementing a function that finds the index where a cumulative sum exceeds a threshold.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef argwhere_cumsum(x, threshold):\n  current_sum = 0.0\n  idx = 0\n  for i in tf.range(len(x)):\n    idx = i\n    if current_sum >= threshold:\n      break\n    current_sum += x[i]\n  return idx\n\nN = 10\nwith tf.Graph().as_default():\n  with tf.Session() as sess:\n    idx = argwhere_cumsum(tf.ones(N), tf.constant(float(N/2)))\n    print(sess.run(idx))\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for TensorFlow Evaluation Migration\nDESCRIPTION: Imports required libraries including both TensorFlow 1 compatibility APIs and TensorFlow 2 APIs, along with NumPy and utility modules for file operations and timing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf1\nimport tensorflow as tf\nimport numpy as np\nimport tempfile\nimport time\nimport os\n```\n\n----------------------------------------\n\nTITLE: Disabling MSYS Path Conversion for Bazel\nDESCRIPTION: Environment variable settings to disable MSYS automatic path conversion, which is necessary when building with Bazel in the MSYS shell.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nexport MSYS_NO_PATHCONV=1\nexport MSYS2_ARG_CONV_EXCL=\"*\"\n```\n\n----------------------------------------\n\nTITLE: Creating Local Variable\nDESCRIPTION: Creates a non-trainable local variable by adding it to LOCAL_VARIABLES collection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmy_local = tf.get_variable(\"my_local\", shape=(),\ncollections=[tf.GraphKeys.LOCAL_VARIABLES])\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Import TypeError\nDESCRIPTION: Error when importing TensorFlow due to protobuf compatibility issues\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nFile \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\",\n  line 4, in <module>\n  from tensorflow.python import *\n  ...\nFile \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\",\n  line 22, in <module>\n  serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\"d\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tb\\x06proto3')\nTypeError: __init__() got an unexpected keyword argument 'syntax'\n```\n\n----------------------------------------\n\nTITLE: Defining Dataset Structure in Python\nDESCRIPTION: Setting up column names and separating features from labels for the Iris dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# column order in CSV file\ncolumn_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n\nfeature_names = column_names[:-1]\nlabel_name = column_names[-1]\n\nprint(\"Features: {}\".format(feature_names))\nprint(\"Label: {}\".format(label_name))\n```\n\n----------------------------------------\n\nTITLE: Comparing Predictions of Original and Reloaded TensorFlow Model in Python\nDESCRIPTION: This snippet compares the predictions of the original and reloaded TensorFlow models to verify accuracy. The `predict` method is called on both models using the same input data, `image_batch`, to ensure consistency in results. The final command computes the maximum absolute difference between the two sets of predictions, aiming for values near zero indicating identical outputs. Necessary prerequisites include having both `model` and `reloaded` objects properly instantiated.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresult_batch = model.predict(image_batch)\nreloaded_result_batch = reloaded.predict(image_batch)\n```\n\nLANGUAGE: python\nCODE:\n```\nabs(reloaded_result_batch - result_batch).max()\n```\n\n----------------------------------------\n\nTITLE: Parsing Serialized TFExample Records (Python)\nDESCRIPTION: Defines a function to parse elements from a TFRecord dataset using a feature descriptor, allowing structured access to serialized data entries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Create a description of the features.\nfeature_description = {\n    'feature0': tf.FixedLenFeature([], tf.int64, default_value=0),\n    'feature1': tf.FixedLenFeature([], tf.int64, default_value=0),\n    'feature2': tf.FixedLenFeature([], tf.string, default_value=''),\n    'feature3': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n}\n\ndef _parse_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  return tf.parse_single_example(example_proto, feature_description)\n```\n\n----------------------------------------\n\nTITLE: Creating Convolutional Layer with Variable Scopes in TensorFlow\nDESCRIPTION: This snippet defines a function for creating a convolutional layer with variables like weights and biases. Dependencies include TensorFlow for managing variables. Parameters include the input tensor and shapes of kernels and biases. The function returns a ReLU activated convolution operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef conv_relu(input, kernel_shape, bias_shape):\n    # Create variable named \"weights\".\n    weights = tf.get_variable(\"weights\", kernel_shape,\n        initializer=tf.random_normal_initializer())\n    # Create variable named \"biases\".\n    biases = tf.get_variable(\"biases\", bias_shape,\n        initializer=tf.constant_initializer(0.0))\n    conv = tf.nn.conv2d(input, weights,\n        strides=[1, 1, 1, 1], padding='SAME')\n    return tf.nn.relu(conv + biases)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Flower Dataset for Image Classification\nDESCRIPTION: This code downloads and extracts a dataset of flower images for use in the image classification tutorial. It uses TensorFlow's utility function to handle the download and extraction process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\ndata_dir = pathlib.Path(data_dir).with_suffix('')\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel CLI on TensorFlow 2 SavedModel\nDESCRIPTION: This command demonstrates how to use the saved_model_cli to run inference on a SavedModel saved with TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n!saved_model_cli run --dir tf2-save --tag_set serve \\\n --signature_def serving_default --input_exprs input=10\n```\n\n----------------------------------------\n\nTITLE: Finalizing Dataset Preparation in TensorFlow\nDESCRIPTION: This code applies batching to the validation dataset and shuffling, repeating, and batching to the training dataset for optimal training performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nvalidate_ds = validate_ds.batch(BATCH_SIZE)\ntrain_ds = train_ds.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Setting up Apache License Text in Python\nDESCRIPTION: A code block that contains the Apache License 2.0 text as a Python comment, typically used at the beginning of TensorFlow example files to indicate licensing terms.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Visualizing Semantic Similarity Between Sentences\nDESCRIPTION: Uses the previously defined function to plot a heatmap of semantic similarity between the sample sentences based on their BERT embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nplot_similarity(outputs[\"pooled_output\"], sentences)\n```\n\n----------------------------------------\n\nTITLE: Library Imports for Model Compression\nDESCRIPTION: Imports the necessary libraries for model compression, including TensorFlow, TensorFlow Compression, TensorFlow Datasets, and matplotlib for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_compression as tfc\nimport tensorflow_datasets as tfds\n\n```\n\n----------------------------------------\n\nTITLE: Loading DELF Model from TensorFlow Hub\nDESCRIPTION: Initializing the DELF model from TensorFlow Hub for feature extraction\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndelf = hub.load('https://tfhub.dev/google/delf/1').signatures['default']\n```\n\n----------------------------------------\n\nTITLE: Image Loading and Preprocessing Function\nDESCRIPTION: Utility function to load and format images for the model. Handles both local and URL-based images, crops to square shape, and resizes to 257x257 pixels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef read_image(filename):\n    fd = None\n    if(filename.startswith('http')):\n      fd = urlopen(filename)\n    else:\n      fd = tf.io.gfile.GFile(filename, 'rb')\n\n    pil_image = PilImage.open(fd)\n    width, height = pil_image.size\n    # crop to make the image square\n    pil_image = pil_image.crop((0, 0, height, height))\n    pil_image = pil_image.resize((257,257),PilImage.LANCZOS)\n    image_unscaled = np.array(pil_image)\n    image_np = np.expand_dims(\n        image_unscaled.astype(np.float32) / 255., axis=0)\n    return image_np\n```\n\n----------------------------------------\n\nTITLE: Downloading Speech Sample for Inference\nDESCRIPTION: This command downloads a speech sample file for performing inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n!wget https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/SA2.wav\n```\n\n----------------------------------------\n\nTITLE: Loading Class Labels\nDESCRIPTION: Function to load and parse bird species labels from the model's CSV file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef class_names_from_csv(class_map_csv_text):\n  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n  with open(labels_path) as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=',')\n    class_names = [mid for mid, desc in csv_reader]\n    return class_names[1:]\n\nlabels_path = hub.resolve(model_handle) + \"/assets/label.csv\"\nclasses = class_names_from_csv(labels_path)\nprint(classes)\n```\n\n----------------------------------------\n\nTITLE: Defining Helper Functions for MoveNet Visualization\nDESCRIPTION: Implements helper functions for visualizing pose detection results, including keypoint and edge mapping, drawing predictions on images, and creating GIF animations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Helper functions for visualization\n\n# Dictionary that maps from joint names to keypoint indices.\nKEYPOINT_DICT = {\n    'nose': 0,\n    'left_eye': 1,\n    'right_eye': 2,\n    'left_ear': 3,\n    'right_ear': 4,\n    'left_shoulder': 5,\n    'right_shoulder': 6,\n    'left_elbow': 7,\n    'right_elbow': 8,\n    'left_wrist': 9,\n    'right_wrist': 10,\n    'left_hip': 11,\n    'right_hip': 12,\n    'left_knee': 13,\n    'right_knee': 14,\n    'left_ankle': 15,\n    'right_ankle': 16\n}\n\n# Maps bones to a matplotlib color name.\nKEYPOINT_EDGE_INDS_TO_COLOR = {\n    (0, 1): 'm',\n    (0, 2): 'c',\n    (1, 3): 'm',\n    (2, 4): 'c',\n    (0, 5): 'm',\n    (0, 6): 'c',\n    (5, 7): 'm',\n    (7, 9): 'm',\n    (6, 8): 'c',\n    (8, 10): 'c',\n    (5, 6): 'y',\n    (5, 11): 'm',\n    (6, 12): 'c',\n    (11, 12): 'y',\n    (11, 13): 'm',\n    (13, 15): 'm',\n    (12, 14): 'c',\n    (14, 16): 'c'\n}\n\ndef _keypoints_and_edges_for_display(keypoints_with_scores,\n                                     height,\n                                     width,\n                                     keypoint_threshold=0.11):\n  \"\"\"Returns high confidence keypoints and edges for visualization.\n\n  Args:\n    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n      the keypoint coordinates and scores returned from the MoveNet model.\n    height: height of the image in pixels.\n    width: width of the image in pixels.\n    keypoint_threshold: minimum confidence score for a keypoint to be\n      visualized.\n\n  Returns:\n    A (keypoints_xy, edges_xy, edge_colors) containing:\n      * the coordinates of all keypoints of all detected entities;\n      * the coordinates of all skeleton edges of all detected entities;\n      * the colors in which the edges should be plotted.\n  \"\"\"\n  keypoints_all = []\n  keypoint_edges_all = []\n  edge_colors = []\n  num_instances, _, _, _ = keypoints_with_scores.shape\n  for idx in range(num_instances):\n    kpts_x = keypoints_with_scores[0, idx, :, 1]\n    kpts_y = keypoints_with_scores[0, idx, :, 0]\n    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n    kpts_absolute_xy = np.stack(\n        [width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n    kpts_above_thresh_absolute = kpts_absolute_xy[\n        kpts_scores > keypoint_threshold, :]\n    keypoints_all.append(kpts_above_thresh_absolute)\n\n    for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n      if (kpts_scores[edge_pair[0]] > keypoint_threshold and\n          kpts_scores[edge_pair[1]] > keypoint_threshold):\n        x_start = kpts_absolute_xy[edge_pair[0], 0]\n        y_start = kpts_absolute_xy[edge_pair[0], 1]\n        x_end = kpts_absolute_xy[edge_pair[1], 0]\n        y_end = kpts_absolute_xy[edge_pair[1], 1]\n        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n        keypoint_edges_all.append(line_seg)\n        edge_colors.append(color)\n  if keypoints_all:\n    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n  else:\n    keypoints_xy = np.zeros((0, 17, 2))\n\n  if keypoint_edges_all:\n    edges_xy = np.stack(keypoint_edges_all, axis=0)\n  else:\n    edges_xy = np.zeros((0, 2, 2))\n  return keypoints_xy, edges_xy, edge_colors\n\n\ndef draw_prediction_on_image(\n    image, keypoints_with_scores, crop_region=None, close_figure=False,\n    output_image_height=None):\n  \"\"\"Draws the keypoint predictions on image.\n\n  Args:\n    image: A numpy array with shape [height, width, channel] representing the\n      pixel values of the input image.\n    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n      the keypoint coordinates and scores returned from the MoveNet model.\n    crop_region: A dictionary that defines the coordinates of the bounding box\n      of the crop region in normalized coordinates (see the init_crop_region\n      function below for more detail). If provided, this function will also\n      draw the bounding box on the image.\n    output_image_height: An integer indicating the height of the output image.\n      Note that the image aspect ratio will be the same as the input image.\n\n  Returns:\n    A numpy array with shape [out_height, out_width, channel] representing the\n    image overlaid with keypoint predictions.\n  \"\"\"\n  height, width, channel = image.shape\n  aspect_ratio = float(width) / height\n  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n  # To remove the huge white borders\n  fig.tight_layout(pad=0)\n  ax.margins(0)\n  ax.set_yticklabels([])\n  ax.set_xticklabels([])\n  plt.axis('off')\n\n  im = ax.imshow(image)\n  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n  ax.add_collection(line_segments)\n  # Turn off tick labels\n  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n\n  (keypoint_locs, keypoint_edges,\n   edge_colors) = _keypoints_and_edges_for_display(\n       keypoints_with_scores, height, width)\n\n  line_segments.set_segments(keypoint_edges)\n  line_segments.set_color(edge_colors)\n  if keypoint_edges.shape[0]:\n    line_segments.set_segments(keypoint_edges)\n    line_segments.set_color(edge_colors)\n  if keypoint_locs.shape[0]:\n    scat.set_offsets(keypoint_locs)\n\n  if crop_region is not None:\n    xmin = max(crop_region['x_min'] * width, 0.0)\n    ymin = max(crop_region['y_min'] * height, 0.0)\n    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n    rect = patches.Rectangle(\n        (xmin,ymin),rec_width,rec_height,\n        linewidth=1,edgecolor='b',facecolor='none')\n    ax.add_patch(rect)\n\n  fig.canvas.draw()\n  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n  image_from_plot = image_from_plot.reshape(\n      fig.canvas.get_width_height()[::-1] + (3,))\n  plt.close(fig)\n  if output_image_height is not None:\n    output_image_width = int(output_image_height / height * width)\n    image_from_plot = cv2.resize(\n        image_from_plot, dsize=(output_image_width, output_image_height),\n         interpolation=cv2.INTER_CUBIC)\n  return image_from_plot\n\ndef to_gif(images, duration):\n  \"\"\"Converts image sequence (4D numpy array) to gif.\"\"\"\n  imageio.mimsave('./animation.gif', images, duration=duration)\n  return embed.embed_file('./animation.gif')\n\ndef progress(value, max=100):\n  return HTML(\"\"\"\n      <progress\n          value='{value}'\n          max='{max}',\n          style='width: 100%'\n      >\n          {value}\n      </progress>\n  \"\"\".format(value=value, max=max))\n```\n\n----------------------------------------\n\nTITLE: Generating Predictions with Trained Citation Intent Classifier\nDESCRIPTION: This code uses the trained estimator to generate predictions on the evaluation dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npredictions = estimator.predict(functools.partial(input_fn_predict, params))\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow and TensorFlow NumPy APIs Together\nDESCRIPTION: Demonstrates how TensorFlow and TensorFlow NumPy functions can be used together without data copying, passing arrays in both directions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# ND array passed into TensorFlow function.\ntf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\nprint(\"Output = %s\" % tf_sum)\n\n# `tf.Tensor` passed into TensorFlow NumPy function.\ntnp_sum = tnp.sum(tf.ones([2, 3]))\nprint(\"Output = %s\" % tnp_sum)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow License Declaration in Python\nDESCRIPTION: A code snippet showing the Apache License 2.0 declaration for TensorFlow code. This is typically included at the top of TensorFlow example files and notebooks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining BigGAN Utility Functions\nDESCRIPTION: Implementation of helper functions for sampling, interpolation and image display\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninput_z = inputs['z']\ninput_y = inputs['y']\ninput_trunc = inputs['truncation']\n\ndim_z = input_z.shape.as_list()[1]\nvocab_size = input_y.shape.as_list()[1]\n\ndef truncated_z_sample(batch_size, truncation=1., seed=None):\n  state = None if seed is None else np.random.RandomState(seed)\n  values = truncnorm.rvs(-2, 2, size=(batch_size, dim_z), random_state=state)\n  return truncation * values\n\ndef one_hot(index, vocab_size=vocab_size):\n  index = np.asarray(index)\n  if len(index.shape) == 0:\n    index = np.asarray([index])\n  assert len(index.shape) == 1\n  num = index.shape[0]\n  output = np.zeros((num, vocab_size), dtype=np.float32)\n  output[np.arange(num), index] = 1\n  return output\n\ndef one_hot_if_needed(label, vocab_size=vocab_size):\n  label = np.asarray(label)\n  if len(label.shape) <= 1:\n    label = one_hot(label, vocab_size)\n  assert len(label.shape) == 2\n  return label\n\ndef sample(sess, noise, label, truncation=1., batch_size=8,\n           vocab_size=vocab_size):\n  noise = np.asarray(noise)\n  label = np.asarray(label)\n  num = noise.shape[0]\n  if len(label.shape) == 0:\n    label = np.asarray([label] * num)\n  if label.shape[0] != num:\n    raise ValueError('Got # noise samples ({}) != # label samples ({})'\n                     .format(noise.shape[0], label.shape[0]))\n  label = one_hot_if_needed(label, vocab_size)\n  ims = []\n  for batch_start in range(0, num, batch_size):\n    s = slice(batch_start, min(num, batch_start + batch_size))\n    feed_dict = {input_z: noise[s], input_y: label[s], input_trunc: truncation}\n    ims.append(sess.run(output, feed_dict=feed_dict))\n  ims = np.concatenate(ims, axis=0)\n  assert ims.shape[0] == num\n  ims = np.clip(((ims + 1) / 2.0) * 256, 0, 255)\n  ims = np.uint8(ims)\n  return ims\n\ndef interpolate(A, B, num_interps):\n  if A.shape != B.shape:\n    raise ValueError('A and B must have the same shape to interpolate.')\n  alphas = np.linspace(0, 1, num_interps)\n  return np.array([(1-a)*A + a*B for a in alphas])\n\ndef imgrid(imarray, cols=5, pad=1):\n  if imarray.dtype != np.uint8:\n    raise ValueError('imgrid input imarray must be uint8')\n  pad = int(pad)\n  assert pad >= 0\n  cols = int(cols)\n  assert cols >= 1\n  N, H, W, C = imarray.shape\n  rows = N // cols + int(N % cols != 0)\n  batch_pad = rows * cols - N\n  assert batch_pad >= 0\n  post_pad = [batch_pad, pad, pad, 0]\n  pad_arg = [[0, p] for p in post_pad]\n  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n  H += pad\n  W += pad\n  grid = (imarray\n          .reshape(rows, cols, H, W, C)\n          .transpose(0, 2, 1, 3, 4)\n          .reshape(rows*H, cols*W, C))\n  if pad:\n    grid = grid[:-pad, :-pad]\n  return grid\n\ndef imshow(a, format='png', jpeg_fallback=True):\n  a = np.asarray(a, dtype=np.uint8)\n  data = io.BytesIO()\n  PIL.Image.fromarray(a).save(data, format)\n  im_data = data.getvalue()\n  try:\n    disp = IPython.display.display(IPython.display.Image(im_data))\n  except IOError:\n    if jpeg_fallback and format != 'jpeg':\n      print(('Warning: image was too large to display in format \"{}\";\n             trying jpeg instead.').format(format))\n      return imshow(a, format='jpeg')\n    else:\n      raise\n  return disp\n```\n\n----------------------------------------\n\nTITLE: Recreating a File List Dataset in TensorFlow\nDESCRIPTION: Recreates a dataset of file paths from a directory structure, which is commonly used for image datasets with class subdirectories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_73\n\nLANGUAGE: python\nCODE:\n```\nlist_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))\n```\n\n----------------------------------------\n\nTITLE: Tensor Reduction Operation\nDESCRIPTION: Demonstrates the use of tf.reduce_sum to calculate the sum of all elements in a tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntf.reduce_sum(x)\n```\n\n----------------------------------------\n\nTITLE: Plotting Sigmoid Function and its Derivative in TensorFlow\nDESCRIPTION: This snippet demonstrates how to plot the sigmoid function and its derivative using matplotlib after computing the gradients with TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(x, y, label='y')\nplt.plot(x, dy_dx, label='dy/dx')\nplt.legend()\n_ = plt.xlabel('x')\n```\n\n----------------------------------------\n\nTITLE: Creating Image Visualization Function with Matplotlib\nDESCRIPTION: Defines a plotting function to visualize image tensors using matplotlib, handling value clipping and format conversion for proper display.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%matplotlib inline\ndef plot_image(image, title=\"\"):\n  \"\"\"\n    Plots images from image tensors.\n    Args:\n      image: 3D image tensor. [height, width, channels].\n      title: Title to display in the plot.\n  \"\"\"\n  image = np.asarray(image)\n  image = tf.clip_by_value(image, 0, 255)\n  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n  plt.imshow(image)\n  plt.axis(\"off\")\n  plt.title(title)\n```\n\n----------------------------------------\n\nTITLE: Downloading LibriSpeech Dataset\nDESCRIPTION: Downloads the dev-clean configuration of the LibriSpeech dataset and extracts it to the data directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n!wget https://www.openslr.org/resources/12/dev-clean.tar.gz -P ./data/train/\n!tar -xf ./data/train/dev-clean.tar.gz -C ./data/train/\n```\n\n----------------------------------------\n\nTITLE: Creating Visualization Function for Comparing Original and Augmented Images\nDESCRIPTION: Defines a helper function to display original and augmented images side-by-side for comparison. This utility simplifies the visualization of different augmentation techniques throughout the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef visualize(original, augmented):\n  fig = plt.figure()\n  plt.subplot(1,2,1)\n  plt.title('Original image')\n  plt.imshow(original)\n\n  plt.subplot(1,2,2)\n  plt.title('Augmented image')\n  plt.imshow(augmented)\n```\n\n----------------------------------------\n\nTITLE: Decoding and Resizing Image Data in TensorFlow\nDESCRIPTION: Demonstrates image data preprocessing by reading, decoding, and resizing images to a fixed size. Requires TensorFlow image processing functions and input filenames with their corresponding labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\ndef _parse_function(filename, label):\n  image_string = tf.read_file(filename)\n  image_decoded = tf.image.decode_jpeg(image_string)\n  image_resized = tf.image.resize_images(image_decoded, [28, 28])\n  return image_resized, label\n\nfilenames = tf.constant([\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...])\nlabels = tf.constant([0, 37, ...])\n\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\ndataset = dataset.map(_parse_function)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Checkpoint Directory\nDESCRIPTION: Creates a directory to store training checkpoints which allows for resuming training from saved states and tracking training progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a checkpoint directory to store the checkpoints.\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n```\n\n----------------------------------------\n\nTITLE: Building and Compiling Model within Strategy Scope in TensorFlow\nDESCRIPTION: Demonstrates how to build and compile a model within the scope of MultiWorkerMirroredStrategy. This ensures that the model's variables are properly distributed across workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  # Model building/compiling need to be within `strategy.scope()`.\n  multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Loss with Matplotlib\nDESCRIPTION: Defines a function `plot_history` that plots the training and validation loss curves for different models. It iterates through a list of histories, plotting the validation loss (dashed lines) and training loss (solid lines) for each model, using Matplotlib to create the visualization.  The plot includes labels, axis titles, and a legend, and it limits the x-axis to the maximum number of epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef plot_history(histories, key='binary_crossentropy'):\n  plt.figure(figsize=(16,10))\n\n  for name, history in histories:\n    val = plt.plot(history.epoch, history.history['val_'+key],\n                   '--', label=name.title()+' Val')\n    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n             label=name.title()+' Train')\n\n  plt.xlabel('Epochs')\n  plt.ylabel(key.replace('_',' ').title())\n  plt.legend()\n\n  plt.xlim([0,max(history.epoch)])\n\n\nplot_history([('baseline', baseline_history),\n              ('smaller', smaller_history),\n              ('bigger', bigger_history)])\n```\n\n----------------------------------------\n\nTITLE: Original Problematic Cross-Entropy Implementation\nDESCRIPTION: Shows the problematic implementation of cross-entropy calculation that leads to numerical instability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndiff = -(y_ * tf.log(y))\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Type Constraints\nDESCRIPTION: Example showing how to register an op with type constraints where the attribute must be one of int32, float, or bool.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_16\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"RestrictedTypeExample\")\n    .Attr(\"t: {int32, float, bool}\");\n```\n\n----------------------------------------\n\nTITLE: Describing Research and Consultation Phase in Markdown\nDESCRIPTION: This snippet shows a subheader and list of considerations for the research and consultation phase of creating a new SIG.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Research and consultation\n\nProposers of groups should gather evidence for approval, as specified below.\nSome possible avenues to consider are:\n\n*   A well-defined problem or set of problems the group would solve.\n*   Consultation with community members who would benefit, assessing both the\n    benefit and their willingness to commit.\n*   For existing projects, evidence from issues and PRs that contributors care\n    about the topic.\n*   Potential goals for the group to achieve.\n*   Resource requirements of running the group.\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow\nDESCRIPTION: Basic import statement for the TensorFlow library to use its functionality in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: License Header Declaration in Python\nDESCRIPTION: The Apache License 2.0 header included as a comment in the notebook to specify the terms under which the code is licensed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Managing Multiple TensorFlow Graphs\nDESCRIPTION: Demonstrates creating and managing multiple TensorFlow graphs within the same Python process. Each `tf.Graph` instance can run separate operations independently within its context. The example shows switching between graphs using `tf.Graph.as_default`, querying graph operations, and running them in sessions. It requires TensorFlow installed and demonstrates advanced graph management techniques.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\ng_1 = tf.Graph()\nwith g_1.as_default():\n  # Operations created in this scope will be added to `g_1`.\n  c = tf.constant(\"Node in g_1\")\n\n  # Sessions created in this scope will run operations from `g_1`.\n  sess_1 = tf.Session()\n\ng_2 = tf.Graph()\nwith g_2.as_default():\n  # Operations created in this scope will be added to `g_2`.\n  d = tf.constant(\"Node in g_2\")\n\n# Alternatively, you can pass a graph when constructing a `tf.Session`:\n# `sess_2` will run operations from `g_2`.\nsess_2 = tf.Session(graph=g_2)\n\nassert c.graph is g_1\nassert sess_1.graph is g_1\n\nassert d.graph is g_2\nassert sess_2.graph is g_2\n```\n\nLANGUAGE: Python\nCODE:\n```\n# Print all of the operations in the default graph.\ng = tf.get_default_graph()\nprint(g.get_operations())\n```\n\n----------------------------------------\n\nTITLE: Compiling CUDA Kernel for TensorFlow Custom Op\nDESCRIPTION: Bash commands to compile a CUDA kernel (cuda_op_kernel.cu.cc) and its C++ wrapper (cuda_op_kernel.cc) into a dynamically loadable library for use with TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_39\n\nLANGUAGE: Bash\nCODE:\n```\nnvcc -std=c++14 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \\\n  ${TF_CFLAGS[@]} -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\n\ng++ -std=c++14 -shared -o cuda_op_kernel.so cuda_op_kernel.cc \\\n  cuda_op_kernel.cu.o ${TF_CFLAGS[@]} -fPIC -lcudart ${TF_LFLAGS[@]}\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Generation Function in TensorFlow\nDESCRIPTION: Creates a function to generate text using the trained model. It takes a starting string, feeds it through the model character by character, and samples from the output distribution with a temperature parameter to control randomness.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef generate_text(model, start_string):\n  # Evaluation step (generating text using the learned model)\n\n  # Number of characters to generate\n  num_generate = 1000\n\n  # Converting our start string to numbers (vectorizing)\n  input_eval = [char2idx[s] for s in start_string]\n  input_eval = tf.expand_dims(input_eval, 0)\n\n  # Empty string to store our results\n  text_generated = []\n\n  # Low temperatures results in more predictable text.\n  # Higher temperatures results in more surprising text.\n  # Experiment to find the best setting.\n  temperature = 1.0\n\n  # Here batch size == 1\n  model.reset_states()\n  for i in range(num_generate):\n      predictions = model(input_eval)\n      # remove the batch dimension\n      predictions = tf.squeeze(predictions, 0)\n\n      # using a multinomial distribution to predict the word returned by the model\n      predictions = predictions / temperature\n      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n\n      # You pass the predicted word as the next input to the model\n      # along with the previous hidden state\n      input_eval = tf.expand_dims([predicted_id], 0)\n\n      text_generated.append(idx2char[predicted_id])\n\n  return (start_string + ''.join(text_generated))\n```\n\n----------------------------------------\n\nTITLE: Loading Example Images for Style Transfer\nDESCRIPTION: Loads content and style images from URLs, resizes them, and displays them side by side. The content image is resized to the output size, while the style image is kept at 256x256.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncontent_image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Golden_Gate_Bridge_from_Battery_Spencer.jpg/640px-Golden_Gate_Bridge_from_Battery_Spencer.jpg'  # @param {type:\"string\"}\nstyle_image_url = 'https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg'  # @param {type:\"string\"}\noutput_image_size = 384  # @param {type:\"integer\"}\n\n# The content image size can be arbitrary.\ncontent_img_size = (output_image_size, output_image_size)\n# The style prediction model was trained with image size 256 and it's the \n# recommended image size for the style image (though, other sizes work as \n# well but will lead to different results).\nstyle_img_size = (256, 256)  # Recommended to keep it at 256.\n\ncontent_image = load_image(content_image_url, content_img_size)\nstyle_image = load_image(style_image_url, style_img_size)\nstyle_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\nshow_n([content_image, style_image], ['Content image', 'Style image'])\n```\n\n----------------------------------------\n\nTITLE: Implementing ZeroOut OpKernel in TensorFlow\nDESCRIPTION: This code implements the kernel for the ZeroOut operation. It processes an input tensor of int32 values and produces an output tensor where all but the first element are set to zero. The implementation extends the OpKernel class and overrides the Compute method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_1\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output_flat = output_tensor->flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n    for (int i = 1; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output_flat(0) = input(0);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Custom Op Test in Shell\nDESCRIPTION: Shell command to execute the Python test for a custom TensorFlow operation. This assumes TensorFlow is installed in the environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\n$ python zero_out_op_test.py\n```\n\n----------------------------------------\n\nTITLE: Episode Rendering for CartPole Environment with TensorFlow Model\nDESCRIPTION: Function that renders and captures frames of the CartPole environment as the trained model performs actions. It converts the environment renders to PIL Images and returns them as a list for GIF creation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Render an episode and save as a GIF file\n\nfrom IPython import display as ipythondisplay\nfrom PIL import Image\n\nrender_env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n\ndef render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int):\n  state, info = env.reset()\n  state = tf.constant(state, dtype=tf.float32)\n  screen = env.render()\n  images = [Image.fromarray(screen)]\n\n  for i in range(1, max_steps + 1):\n    state = tf.expand_dims(state, 0)\n    action_probs, _ = model(state)\n    action = np.argmax(np.squeeze(action_probs))\n\n    state, reward, done, truncated, info = env.step(action)\n    state = tf.constant(state, dtype=tf.float32)\n\n    # Render screen every 10 steps\n    if i % 10 == 0:\n      screen = env.render()\n      images.append(Image.fromarray(screen))\n\n    if done:\n      break\n\n  return images\n\n\n# Save GIF image\nimages = render_episode(render_env, model, max_steps_per_episode)\nimage_file = 'cartpole-v1.gif'\n# loop=0: loop forever, duration=1: play each frame for 1ms\nimages[0].save(\n    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for TensorFlow White Paper\nDESCRIPTION: BibTeX entry for citing the original TensorFlow white paper 'Large-Scale Machine Learning on Heterogeneous Systems' published in 2015.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/about/bib.md#2025-04-21_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{tensorflow2015-whitepaper,\ntitle={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},\nurl={https://www.tensorflow.org/},\nnote={Software available from tensorflow.org},\nauthor={\n    Mart\\'{i}n~Abadi and\n    Ashish~Agarwal and\n    Paul~Barham and\n    Eugene~Brevdo and\n    Zhifeng~Chen and\n    Craig~Citro and\n    Greg~S.~Corrado and\n    Andy~Davis and\n    Jeffrey~Dean and\n    Matthieu~Devin and\n    Sanjay~Ghemawat and\n    Ian~Goodfellow and\n    Andrew~Harp and\n    Geoffrey~Irving and\n    Michael~Isard and\n    Yangqing Jia and\n    Rafal~Jozefowicz and\n    Lukasz~Kaiser and\n    Manjunath~Kudlur and\n    Josh~Levenberg and\n    Dandelion~Man\\'{e} and\n    Rajat~Monga and\n    Sherry~Moore and\n    Derek~Murray and\n    Chris~Olah and\n    Mike~Schuster and\n    Jonathon~Shlens and\n    Benoit~Steiner and\n    Ilya~Sutskever and\n    Kunal~Talwar and\n    Paul~Tucker and\n    Vincent~Vanhoucke and\n    Vijay~Vasudevan and\n    Fernanda~Vi\\'{e}gas and\n    Oriol~Vinyals and\n    Pete~Warden and\n    Martin~Wattenberg and\n    Martin~Wicke and\n    Yuan~Yu and\n    Xiaoqiang~Zheng},\n  year={2015},\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying Continuous Column\nDESCRIPTION: This snippet shows how to specify a continuous feature column using `tf.feature_column.numeric_column`. The feature 'age' is defined as a numeric column.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nage = tf.feature_column.numeric_column(\"age\")\n```\n\n----------------------------------------\n\nTITLE: Implementing L2 Regularization in TensorFlow Keras Model\nDESCRIPTION: This code snippet demonstrates how to add L2 weight regularization to a sequential model in TensorFlow Keras. It applies L2 regularization to the kernel of each Dense layer with a penalty of 0.001.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: Python\nCODE:\n```\nl2_model = tf.keras.Sequential([\n    layers.Dense(512, activation='elu',\n                 kernel_regularizer=regularizers.l2(0.001),\n                 input_shape=(FEATURES,)),\n    layers.Dense(512, activation='elu',\n                 kernel_regularizer=regularizers.l2(0.001)),\n    layers.Dense(512, activation='elu',\n                 kernel_regularizer=regularizers.l2(0.001)),\n    layers.Dense(512, activation='elu',\n                 kernel_regularizer=regularizers.l2(0.001)),\n    layers.Dense(1)\n])\n\nregularizer_histories['l2'] = compile_and_fit(l2_model, \"regularizers/l2\")\n```\n\n----------------------------------------\n\nTITLE: Setting Dataset Parameters in TensorFlow\nDESCRIPTION: This code sets the parameters for validation and training dataset sizes, buffer size, batch size, and steps per epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nN_VALIDATION = int(1e3)\nN_TRAIN = int(1e4)\nBUFFER_SIZE = int(1e4)\nBATCH_SIZE = 500\nSTEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Parameter Server Training\nDESCRIPTION: This code imports necessary Python libraries and TensorFlow modules for implementing parameter server training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport multiprocessing\nimport os\nimport random\nimport portpicker\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Using tf.gather_nd with a 3D Tensor\nDESCRIPTION: Demonstrates how to extract specific elements from a 3D tensor using tf.gather_nd with fully-specified indices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nt5 = np.reshape(np.arange(18), [2, 3, 3])\n\nprint(tf.gather_nd(t5,\n                   indices=[[0, 0, 0], [1, 2, 1]]))\n```\n\n----------------------------------------\n\nTITLE: Outlining SIG Creation Process in Markdown\nDESCRIPTION: This snippet presents a subheader and list of requirements for creating a new SIG, including purpose, leadership, and resources.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n### Creating the new group\n\nThe new group should follow the below process for chartering. In particular, it\nmust demonstrate:\n\n*   A clear purpose and benefit to TensorFlow (either around a sub-project or\n    application area)\n*   Two or more contributors willing to act as group leads, existence of other\n    contributors, and evidence of demand for the group\n*   Resources it will initially require (usually, mailing list and regular video conference \n    call.)\n```\n\n----------------------------------------\n\nTITLE: Writing Distributed Generator State to Checkpoint\nDESCRIPTION: Saves the state of a random generator that's being used in a distribution strategy, allowing the deterministic sequence to be preserved across saving points.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nwith strat.scope():\n  cp.write(filename)\n  print(\"RNG stream from saving point:\")\n  print(strat.run(lambda: g.normal([])))\n  print(strat.run(lambda: g.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Running Notebook Formatting Tool in Python\nDESCRIPTION: Command to run the nbfmt tool from the tensorflow_docs package to format Jupyter notebooks according to TensorFlow docs standards.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m tensorflow_docs.tools.nbfmt [options] notebook.ipynb [...]\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Defines the Apache License 2.0 terms under which the code is licensed, displayed as a collapsible title element in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Loading TF1 Hub Module in TensorFlow 1\nDESCRIPTION: Demonstrates how to load and use a TF1 Hub module for inference in TensorFlow 1 or TF1 compatibility mode in TF2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nm = hub.Module(handle)\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Enabling Legacy Type Promotion Mode in TensorFlow-NumPy\nDESCRIPTION: This snippet shows how to enable the legacy dtype conversion mode for TensorFlow-NumPy operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for SNGP Implementation\nDESCRIPTION: Imports necessary libraries for implementing and visualizing SNGP models, including matplotlib for visualization, sklearn for datasets, numpy for numerical operations, tensorflow for model building, and official NLP modeling layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n\nimport sklearn.datasets\n\nimport numpy as np\nimport tensorflow as tf\n\nimport official.nlp.modeling.layers as nlp_layers\n```\n\n----------------------------------------\n\nTITLE: Creating a Boosted Trees Estimator in TensorFlow 1\nDESCRIPTION: This snippet demonstrates how to create a BoostedTreesEstimator in TensorFlow 1 for binary classification. It specifies parameters like the number of trees, maximum depth, and feature columns to use.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbt_estimator = tf1.estimator.BoostedTreesEstimator(\n    head=tf.estimator.BinaryClassHead(),\n    n_batches_per_layer=1,\n    max_depth=10,\n    n_trees=1000,\n    feature_columns=feature_columns)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model Performance\nDESCRIPTION: Code to evaluate the trained model's accuracy on the test dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Evaluate the model.\neval_result = classifier.evaluate(\n    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))\n\nprint('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from a Python Generator\nDESCRIPTION: This snippet demonstrates how to create a tf.data.Dataset from the count generator using Dataset.from_generator. It specifies output types and shapes for the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration for the TensorFlow tutorial code\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Metrics and Model Architecture for Fraud Detection in Python\nDESCRIPTION: This snippet defines a set of evaluation metrics and a function to create a neural network model for fraud detection. It includes a dense hidden layer, dropout for regularization, and a sigmoid output layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMETRICS = [\n      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n      keras.metrics.MeanSquaredError(name='Brier score'),\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'),\n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef make_model(metrics=METRICS, output_bias=None):\n  if output_bias is not None:\n    output_bias = tf.keras.initializers.Constant(output_bias)\n  model = keras.Sequential([\n      keras.layers.Dense(\n          16, activation='relu',\n          input_shape=(train_features.shape[-1],)),\n      keras.layers.Dropout(0.5),\n      keras.layers.Dense(1, activation='sigmoid',\n                         bias_initializer=output_bias),\n  ])\n\n  model.compile(\n      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=metrics)\n\n  return model\n```\n\n----------------------------------------\n\nTITLE: Defining the Model Function for TensorFlow Estimator\nDESCRIPTION: Creates a model function for tf.estimator that builds a CNN for MNIST classification. This function handles different modes (train, eval, predict) and defines the loss function and optimizer for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nLEARNING_RATE = 1e-4\ndef model_fn(features, labels, mode):\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10)\n  ])\n  logits = model(features, training=False)\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {'logits': logits}\n    return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)\n\n  optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n      learning_rate=LEARNING_RATE)\n  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n  loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)\n  if mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n  return tf.estimator.EstimatorSpec(\n      mode=mode,\n      loss=loss,\n      train_op=optimizer.minimize(\n          loss, tf.compat.v1.train.get_or_create_global_step()))\n```\n\n----------------------------------------\n\nTITLE: Extracting a Batch from TensorFlow Dataset\nDESCRIPTION: Demonstrates how to extract a single batch of images and labels from a TensorFlow Dataset using Python iteration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimage_batch, label_batch = next(iter(train_data))\n```\n\n----------------------------------------\n\nTITLE: Creating and Running TensorFlow Layer with Shortcut Function\nDESCRIPTION: Illustrates the creation of a Dense layer in a single call with `tf.layers.dense`, alongside variable initialization and execution within a session. This approach simplifies usage but omits access to the layer object for further introspection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.placeholder(tf.float32, shape=[None, 3])\ny = tf.layers.dense(x, units=1)\n\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nprint(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))\n```\n\n----------------------------------------\n\nTITLE: Initialize MultiWorkerMirroredStrategy\nDESCRIPTION: Creates a MultiWorkerMirroredStrategy instance for distributed training across multiple workers\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmultiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Generating Label Names for MoViNet Model in TensorFlow\nDESCRIPTION: This snippet creates a FrameGenerator object and extracts label names from it. These label names are used for labeling the axes in the confusion matrix plot.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfg = FrameGenerator(subset_paths['train'], num_frames, training = True)\nlabel_names = list(fg.class_ids_for_name.keys())\n```\n\n----------------------------------------\n\nTITLE: Appending Fine-tuning History to Training Metrics\nDESCRIPTION: This snippet appends metrics from the fine-tuning phase to existing metrics from the initial training phase. This allows for visualizing the complete training history across both phases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nacc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n```\n\n----------------------------------------\n\nTITLE: Testing Exported TensorFlow Audio Classification Model\nDESCRIPTION: This code snippet demonstrates how to create an instance of the ExportModel and test it with a sample audio file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nexport = ExportModel(model)\nexport(tf.constant(str(data_dir/'no/01bb6a2a_nohash_0.wav')))\n```\n\n----------------------------------------\n\nTITLE: Customizing TypeSpec for MaskedTensor in TensorFlow\nDESCRIPTION: Shows how to customize the TypeSpec class for a MaskedTensor with custom properties and initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nclass MaskedTensor(tf.experimental.ExtensionType):\n  values: tf.Tensor\n  mask: tf.Tensor\n\n  shape = property(lambda self: self.values.shape)\n  dtype = property(lambda self: self.values.dtype)\n\n  def __repr__(self):\n    return masked_tensor_str(self.values, self.mask)\n\n  def with_values(self, new_values):\n    return MaskedTensor(new_values, self.mask)\n\n  class Spec:\n    def __init__(self, shape, dtype=tf.float32):\n      self.values = tf.TensorSpec(shape, dtype)\n      self.mask = tf.TensorSpec(shape, tf.bool)\n\n    def __repr__(self):\n      return f\"MaskedTensor.Spec(shape={self.shape}, dtype={self.dtype})\"\n\n    shape = property(lambda self: self.values.shape)\n    dtype = property(lambda self: self.values.dtype)\n```\n\n----------------------------------------\n\nTITLE: Logging Device Placement in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a TensorFlow session with `log_device_placement` enabled to track where operations are executed. It initializes two constants and performs matrix multiplication, printing the result and the device information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_gpu.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Creates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint(sess.run(c))\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Normalization with TF1.x Compatibility in Python\nDESCRIPTION: This code snippet shows how to implement a batch normalization layer using tf.compat.v1.layers.batch_normalization within a Keras layer. It demonstrates how the 'training' argument is handled in TF2 compared to TF1.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass CompatV1BatchNorm(tf.keras.layers.Layer):\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    print(\"Forward pass called with `training` =\", training)\n    with v1.variable_scope('batch_norm_layer'):\n      return v1.layers.batch_normalization(x, training=training)\n```\n\n----------------------------------------\n\nTITLE: Boolean Evaluation of TensorShape Objects\nDESCRIPTION: Demonstrates how TensorShape objects are evaluated as boolean values based on whether their rank is known or not in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nprint(bool(tf.TensorShape([])))      # Scalar\nprint(bool(tf.TensorShape([0])))     # 0-length vector\nprint(bool(tf.TensorShape([1])))     # 1-length vector\nprint(bool(tf.TensorShape([None])))  # Unknown-length vector\nprint(bool(tf.TensorShape([1, 10, 100])))       # 3D tensor\nprint(bool(tf.TensorShape([None, None, None]))) # 3D tensor with no known dimensions\nprint()\nprint(bool(tf.TensorShape(None)))  # A tensor with unknown rank.\n```\n\n----------------------------------------\n\nTITLE: Starting Bash Session in TensorFlow Container\nDESCRIPTION: Command to start a bash shell session within a TensorFlow-configured Docker container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it tensorflow/tensorflow bash\n```\n\n----------------------------------------\n\nTITLE: Creating MaskedTensor Instance in Python\nDESCRIPTION: Demonstrates creating a MaskedTensor instance with values and mask tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmt = MaskedTensor([1, 2, 3], [True, False, True])\n```\n\n----------------------------------------\n\nTITLE: Loading and Continuing Training with a Saved TensorFlow Model\nDESCRIPTION: Loading a previously saved model and continuing training on a single worker. This demonstrates how to restore a model that was saved during distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nloaded_model = tf.keras.models.load_model(model_path)\n\n# Now that the model is restored, and can continue with the training.\nloaded_model.fit(single_worker_dataset, epochs=2, steps_per_epoch=20)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Utility Function\nDESCRIPTION: Imports TensorFlow modules and defines a utility function for calling feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\nimport math\n\ndef call_feature_columns(feature_columns, inputs):\n  feature_layer = tf1.keras.layers.DenseFeatures(feature_columns)\n  return feature_layer(inputs)\n```\n\n----------------------------------------\n\nTITLE: Defining MNIST Compression Trainer Class in Python\nDESCRIPTION: Implements a Keras model class that trains a compressor/decompressor for MNIST images, computing rate and distortion losses during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass MNISTCompressionTrainer(tf.keras.Model):\n  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n\n  def __init__(self, latent_dims):\n    super().__init__()\n    self.analysis_transform = make_analysis_transform(latent_dims)\n    self.synthesis_transform = make_synthesis_transform()\n    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n\n  @property\n  def prior(self):\n    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n\n  def call(self, x, training):\n    \"\"\"Computes rate and distortion losses.\"\"\"\n    # Ensure inputs are floats in the range (0, 1).\n    x = tf.cast(x, self.compute_dtype) / 255.\n    x = tf.reshape(x, (-1, 28, 28, 1))\n\n    # Compute latent space representation y, perturb it and model its entropy,\n    # then compute the reconstructed pixel-level representation x_hat.\n    y = self.analysis_transform(x)\n    entropy_model = tfc.ContinuousBatchedEntropyModel(\n        self.prior, coding_rank=1, compression=False)\n    y_tilde, rate = entropy_model(y, training=training)\n    x_tilde = self.synthesis_transform(y_tilde)\n\n    # Average number of bits per MNIST digit.\n    rate = tf.reduce_mean(rate)\n\n    # Mean absolute difference across pixels.\n    distortion = tf.reduce_mean(abs(x - x_tilde))\n\n    return dict(rate=rate, distortion=distortion)\n```\n\n----------------------------------------\n\nTITLE: Initializing CVAE Model and Training Parameters in Python\nDESCRIPTION: Sets up the CVAE model with specified latent dimensions and training parameters. It also initializes a random vector for consistent image generation during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nepochs = 10\n# set the dimensionality of the latent space to a plane for visualization later\nlatent_dim = 2\nnum_examples_to_generate = 16\n\n# keeping the random vector constant for generation (prediction) so\n# it will be easier to see the improvement.\nrandom_vector_for_generation = tf.random.normal(\n    shape=[num_examples_to_generate, latent_dim])\nmodel = CVAE(latent_dim)\n```\n\n----------------------------------------\n\nTITLE: Licensing Information in Python\nDESCRIPTION: This snippet includes the Apache License information for the file. It is essential to understand and abide by the Licensing terms provided here before using or modifying the code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Obtaining Graphs and Using Atomic Functions in TensorFlow\nDESCRIPTION: This code snippet shows how to retrieve a TensorFlow graph from a concrete function and use the underlying AtomicFunction for execution. This approach can reduce overhead in high-performance applications but may have constraints like lack of gradient support.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ngraph = double_strings.graph\nfor node in graph.as_graph_def().node:\n  print(f'{node.input} -> {node.name}')\n```\n\nLANGUAGE: python\nCODE:\n```\natomic_fn = double_strings.inference_fn\natomic_fn(tf.constant(\"a\"))\n```\n\n----------------------------------------\n\nTITLE: License Header for TensorFlow Tutorial\nDESCRIPTION: Defines the Apache License 2.0 header for the TensorFlow documentation tutorial. This header specifies the licensing terms under which the code is distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Restoration in Multi-Worker Training\nDESCRIPTION: This code snippet demonstrates how to restore the latest checkpoint in a multi-worker training setup. It uses tf.train.latest_checkpoint to find the most recent checkpoint and restores it using the checkpoint object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nlatest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\nif latest_checkpoint:\n  checkpoint.restore(latest_checkpoint)\n```\n\n----------------------------------------\n\nTITLE: Distributing Tensor Values with MirroredStrategy\nDESCRIPTION: Shows how to distribute raw tensor values across devices using experimental_distribute_values_from_function with MirroredStrategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\ndef value_fn(ctx):\n  return tf.constant(ctx.replica_id_in_sync_group)\n\ndistributed_values = mirrored_strategy.experimental_distribute_values_from_function(value_fn)\nfor _ in range(4):\n  result = mirrored_strategy.run(lambda x: x, args=(distributed_values,))\n  print(result)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dense Layer with TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a `tf.layers.Dense` layer to process input data. The layer requires initialization of variables, and inputs determined via placeholders. It serves as a model's structure for making predictions in neural networks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\nx = tf.placeholder(tf.float32, shape=[None, 3])\nlinear_model = tf.layers.Dense(units=1)\ny = linear_model(x)\n```\n\n----------------------------------------\n\nTITLE: Downloading Test Data\nDESCRIPTION: Downloads BAIR robot pushing test dataset using wget\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Download the test split to $TEST_DIR\n!mkdir -p $TEST_DIR\n!wget -nv https://storage.googleapis.com/download.tensorflow.org/data/bair_test_traj_0_to_255.tfrecords -O $TEST_DIR/traj_0_to_255.tfrecords\n```\n\n----------------------------------------\n\nTITLE: Analyzing CORD-19 embeddings with correlation matrix visualization\nDESCRIPTION: This code loads the CORD-19 Swivel embeddings from TensorFlow Hub and generates a correlation matrix for a set of COVID-19 related terms. It uses the inner product between embedding vectors as a similarity measure and visualizes the results using a heatmap.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef plot_correlation(labels, features):\n  corr = np.inner(features, features)\n  corr /= np.max(corr)\n  sns.heatmap(corr, xticklabels=labels, yticklabels=labels)\n\n\nwith tf.Graph().as_default():\n  # Load the module\n  query_input = tf.placeholder(tf.string)\n  module = hub.Module('https://tfhub.dev/tensorflow/cord-19/swivel-128d/1')\n  embeddings = module(query_input)\n\n  with tf.train.MonitoredTrainingSession() as sess:\n\n    # Generate embeddings for some terms\n    queries = [\n        # Related viruses\n        \"coronavirus\", \"SARS\", \"MERS\",\n        # Regions\n        \"Italy\", \"Spain\", \"Europe\",\n        # Symptoms\n        \"cough\", \"fever\", \"throat\"\n    ]\n\n    features = sess.run(embeddings, feed_dict={query_input: queries})\n    plot_correlation(queries, features)\n```\n\n----------------------------------------\n\nTITLE: Placing Operations on Specific Devices\nDESCRIPTION: Demonstrates how to place TensorFlow NumPy operations on specific devices using tf.device context manager, indicating device placement of results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Using device: %s\" % str(device))\n# Run operations in the `tf.device` scope.\n# If a GPU is available, these operations execute on the GPU and outputs are\n# placed on the GPU memory.\nwith tf.device(device):\n  prediction = model.predict(create_batch(5)[0])\n\nprint(\"prediction is placed on %s\" % prediction.device)\n```\n\n----------------------------------------\n\nTITLE: Initializing TPU Cluster\nDESCRIPTION: Sets up connection to TPU cluster by creating TPUClusterResolver and initializing TPU system. Lists available TPU devices after initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(cluster_resolver)\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\n```\n\n----------------------------------------\n\nTITLE: Saving TensorFlow 2.x checkpoint in Python\nDESCRIPTION: Creates variables using TF2 API and saves them to a checkpoint using tf.train.Checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(5.0, name='a')\nb = tf.Variable(6.0, name='b')\nwith tf.name_scope('scoped'):\n  c = tf.Variable(7.0, name='c')\n\nckpt = tf.train.Checkpoint(variables=[a, b, c])\nsave_path_v2 = ckpt.save('tf2-ckpt')\nprint_checkpoint(save_path_v2)\n```\n\n----------------------------------------\n\nTITLE: Testing Custom Op in Python\nDESCRIPTION: Python test implementation for verifying custom TensorFlow operation functionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nclass ZeroOutTest(tf.test.TestCase):\n  def testZeroOut(self):\n    zero_out_module = tf.load_op_library('./zero_out.so')\n    with self.test_session():\n      result = zero_out_module.zero_out([5, 4, 3, 2, 1])\n      self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])\n\nif __name__ == \"__main__\":\n  tf.test.main()\n```\n\n----------------------------------------\n\nTITLE: Reading Generated Embeddings in Python\nDESCRIPTION: This code reads a sample of the generated embeddings from the TFRecord file. It demonstrates how to parse the TensorFlow Example protocol buffer and extract the text and embedding values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport itertools\n\nembed_file = os.path.join(output_dir, 'emb-00000-of-00001.tfrecords')\nsample = 5\nrecord_iterator =  tf.io.tf_record_iterator(path=embed_file)\nfor string_record in itertools.islice(record_iterator, sample):\n  example = tf.train.Example()\n  example.ParseFromString(string_record)\n  text = example.features.feature['text'].bytes_list.value\n  embedding = np.array(example.features.feature['embedding'].float_list.value)\n  print(\"Embedding dimensions: {}\".format(embedding.shape[0]))\n  print(\"{}: {}\".format(text, embedding[:10]))\n```\n\n----------------------------------------\n\nTITLE: Smaller Model Training\nDESCRIPTION: Training the smaller model with the same IMDB dataset for comparison with the baseline model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsmaller_history = smaller_model.fit(train_data,\n                                    train_labels,\n                                    epochs=20,\n                                    batch_size=512,\n                                    validation_data=(test_data, test_labels),\n                                    verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Bit-widening Operation in 'all' Mode\nDESCRIPTION: Example showing that mixing int8 and uint32 types is allowed in 'all' mode, resulting in an int64 output due to bit-widening.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# i8 + u32 returns an i64 result in ALL mode.\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\na = tf.constant(10, dtype = tf.int8)\nb = tf.constant(5, dtype = tf.uint32)\na + b\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing MNIST Data - TensorFlow Python\nDESCRIPTION: This snippet loads the MNIST dataset from TensorFlow's contrib library and prepares it for training and evaluation by defining an input function that creates mini-batches. It uses TensorFlow ops to convert images and labels into tensors for the Estimator to process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport tensorflow as tf\n\ndef get_input_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):\n\n  def _input_fn():\n    images_batch, labels_batch = tf.train.shuffle_batch(\n        tensors=[dataset_split.images, dataset_split.labels.astype(np.int32)],\n        batch_size=batch_size,\n        capacity=capacity,\n        min_after_dequeue=min_after_dequeue,\n        enqueue_many=True,\n        num_threads=4)\n    features_map = {'images': images_batch}\n    return features_map, labels_batch\n\n  return _input_fn\n\ndata = tf.contrib.learn.datasets.mnist.load_mnist()\n\ntrain_input_fn = get_input_fn(data.train, batch_size=256)\neval_input_fn = get_input_fn(data.validation, batch_size=5000)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Dependencies\nDESCRIPTION: Sets up the required TensorFlow and numpy imports for the text classification project\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow Environment\nDESCRIPTION: Installs required Python packages including TensorFlow, TensorFlow Text, Bokeh, and other dependencies using pip.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n#@title Setup Environment\n# Install the latest Tensorflow version.\n!pip install \"tensorflow-text==2.11.*\"\n!pip install bokeh\n!pip install simpleneighbors[annoy]\n!pip install tqdm\n```\n\n----------------------------------------\n\nTITLE: Creating Models with Keras in TensorFlow Eager Mode\nDESCRIPTION: Demonstrates two ways to create models using Keras: Sequential API and subclassing tf.keras.Model. Both approaches are compatible with eager execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(10, input_shape=(784,)),  # must declare input shape\n  tf.keras.layers.Dense(10)\n])\n\nclass MNISTModel(tf.keras.Model):\n  def __init__(self):\n    super(MNISTModel, self).__init__()\n    self.dense1 = tf.keras.layers.Dense(units=10)\n    self.dense2 = tf.keras.layers.Dense(units=10)\n\n  def call(self, input):\n    \"\"\"Run the model.\"\"\"\n    result = self.dense1(input)\n    result = self.dense2(result)\n    result = self.dense2(result)  # reuse variables from dense2 layer\n    return result\n\nmodel = MNISTModel()\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Reduced Bit-Widening with New Type Promotion in TensorFlow\nDESCRIPTION: This example shows how the new type promotion minimizes the number of bits needed, resulting in float16 output for the same operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nnp.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float16, numpy=54.2>\n```\n\n----------------------------------------\n\nTITLE: TPU Optimizer Configuration via Params\nDESCRIPTION: Demonstrates how to pass the optimizer through the estimator params to avoid global FLAGS usage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmy_tpu_estimator = tf.estimator.tpu.TPUEstimator(\n    model_fn=my_model_fn,\n    config = my_tpu_run_config,\n    use_tpu=FLAGS.use_tpu,\n    params={'optimizer':optimizer})\n```\n\n----------------------------------------\n\nTITLE: Building Word and Bigram Embeddings with Ragged Tensors\nDESCRIPTION: A comprehensive example demonstrating how to use ragged tensors to construct and combine unigram and bigram embeddings for variable-length text queries with sentence markers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nqueries = tf.ragged.constant([['Who', 'is', 'Dan', 'Smith'],\n                              ['Pause'],\n                              ['Will', 'it', 'rain', 'later', 'today']])\n\n# Create an embedding table.\nnum_buckets = 1024\nembedding_size = 4\nembedding_table = tf.Variable(\n    tf.random.truncated_normal([num_buckets, embedding_size],\n                       stddev=1.0 / math.sqrt(embedding_size)))\n\n# Look up the embedding for each word.\nword_buckets = tf.strings.to_hash_bucket_fast(queries, num_buckets)\nword_embeddings = tf.nn.embedding_lookup(embedding_table, word_buckets)     # ①\n\n# Add markers to the beginning and end of each sentence.\nmarker = tf.fill([queries.nrows(), 1], '#')\npadded = tf.concat([marker, queries, marker], axis=1)                       # ②\n\n# Build word bigrams and look up embeddings.\nbigrams = tf.strings.join([padded[:, :-1], padded[:, 1:]], separator='+')   # ③\n\nbigram_buckets = tf.strings.to_hash_bucket_fast(bigrams, num_buckets)\nbigram_embeddings = tf.nn.embedding_lookup(embedding_table, bigram_buckets) # ④\n\n# Find the average embedding for each sentence\nall_embeddings = tf.concat([word_embeddings, bigram_embeddings], axis=1)    # ⑤\navg_embedding = tf.reduce_mean(all_embeddings, axis=1)                      # ⑥\nprint(avg_embedding)\n```\n\n----------------------------------------\n\nTITLE: Finding Closest Latent Vector to Target Image using Gradient Descent\nDESCRIPTION: This function uses gradient descent to find the latent vector that generates an image most similar to the target image, optimizing the vector over multiple steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\ndef find_closest_latent_vector(initial_vector, num_optimization_steps,\n                               steps_per_image):\n  images = []\n  losses = []\n\n  vector = tf.Variable(initial_vector)  \n  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n  loss_fn = tf.losses.MeanAbsoluteError(reduction=\"sum\")\n\n  for step in range(num_optimization_steps):\n    if (step % 100)==0:\n      print()\n    print('.', end='')\n    with tf.GradientTape() as tape:\n      image = progan(vector.read_value())['default'][0]\n      if (step % steps_per_image) == 0:\n        images.append(image.numpy())\n      target_image_difference = loss_fn(image, target_image[:,:,:3])\n      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n      \n      loss = target_image_difference + regularizer\n      losses.append(loss.numpy())\n    grads = tape.gradient(loss, [vector])\n    optimizer.apply_gradients(zip(grads, [vector]))\n    \n  return images, losses\n\n\nnum_optimization_steps=200\nsteps_per_image=5\nimages, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)\n```\n\n----------------------------------------\n\nTITLE: Converting Keras models to TensorFlow Estimators in Python\nDESCRIPTION: Complete example showing how to instantiate a Keras InceptionV3 model, compile it, convert it to an Estimator, and then train the resulting Estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Instantiate a Keras inception v3 model.\nkeras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=None)\n\n# Compile model with the optimizer, loss, and metrics you'd like to train with.\nkeras_inception_v3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n                          loss='categorical_crossentropy',\n                          metric='accuracy')\n                          \n# Create an Estimator from the compiled Keras model. Note the initial model\n# state of the keras model is preserved in the created Estimator.\nest_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)\n\n# Treat the derived Estimator as you would with any other Estimator.\n# First, recover the input name(s) of Keras model, so we can use them as the\n# feature column name(s) of the Estimator input function:\nkeras_inception_v3.input_names  # print out: ['input_1']\n\n# Once we have the input name(s), we can create the input function, for example,\n# for input(s) in the format of numpy ndarray:\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"input_1\": train_data},\n    y=train_labels,\n    num_epochs=1,\n    shuffle=False)\n    \n# To train, we call Estimator's train function:\nest_inception_v3.train(input_fn=train_input_fn, steps=2000)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Complete Training Loop in TensorFlow\nDESCRIPTION: Creates a full training loop that iterates through epochs and batches, optimizes the model, and tracks loss and accuracy metrics. The function includes progress reporting every 50 epochs and stores results for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n## Note: Rerunning this cell uses the same model variables\n\n# keep results for plotting\ntrain_loss_results = []\ntrain_accuracy_results = []\n\nnum_epochs = 201\n\nfor epoch in range(num_epochs):\n  epoch_loss_avg = tf.keras.metrics.Mean()\n  epoch_accuracy = tf.keras.metrics.Accuracy()\n\n  # Training loop - using batches of 32\n  for x, y in train_dataset:\n    # Optimize the model\n    loss_value, grads = grad(model, x, y)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables),\n                              global_step)\n\n    # Track progress\n    epoch_loss_avg(loss_value)  # add current batch loss\n    # compare predicted label to actual label\n    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n\n  # end epoch\n  train_loss_results.append(epoch_loss_avg.result())\n  train_accuracy_results.append(epoch_accuracy.result())\n\n  if epoch % 50 == 0:\n    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n                                                                epoch_loss_avg.result(),\n                                                                epoch_accuracy.result()))\n```\n\n----------------------------------------\n\nTITLE: Accessing row-partitioning tensors from a RaggedTensor in TensorFlow\nDESCRIPTION: Shows how to access the various row-partitioning tensors from an existing RaggedTensor. Values and row_splits are properties, while the other partitioning tensors are computed on demand via methods.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\nprint(\"      values: {}\".format(rt.values))\nprint(\"  row_splits: {}\".format(rt.row_splits))\nprint(\" row_lengths: {}\".format(rt.row_lengths()))\nprint(\"  row_starts: {}\".format(rt.row_starts()))\nprint(\"  row_limits: {}\".format(rt.row_limits()))\nprint(\"value_rowids: {}\".format(rt.value_rowids()))\n```\n\n----------------------------------------\n\nTITLE: Training Model on TPU\nDESCRIPTION: Trains the compiled model using the input dataset with specified epochs and steps per epoch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(input_dataset, epochs=5, steps_per_epoch=10)\n```\n\n----------------------------------------\n\nTITLE: Creating Input Tensors from CSV Data Types\nDESCRIPTION: Builds a dictionary of tf.keras.Input objects that match the data types of CSV columns, converting object types to tf.string and numeric types to tf.float32.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ninputs = {}\n\nfor name, column in titanic_features.items():\n  dtype = column.dtype\n  if dtype == object:\n    dtype = tf.string\n  else:\n    dtype = tf.float32\n\n  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n\ninputs\n```\n\n----------------------------------------\n\nTITLE: Displaying Apache License in Python\nDESCRIPTION: This code snippet displays the Apache License 2.0 as a Python comment. It outlines the terms of use for the TensorFlow software.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and NumPy for Tensor Slicing\nDESCRIPTION: Imports the TensorFlow and NumPy libraries necessary for tensor slicing operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Dataset Operations with Extension Types\nDESCRIPTION: Demonstrates various ways to create and manipulate tf.data.Dataset objects containing extension types, including creation, batching, and unbatching operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nds = tf.data.Dataset.from_tensors(Pastry(5, 5))\niter(ds).next()\n```\n\nLANGUAGE: python\nCODE:\n```\nmt = MaskedTensor(tf.reshape(range(20), [5, 4]), tf.ones([5, 4]))\nds = tf.data.Dataset.from_tensor_slices(mt)\nfor value in ds:\n  print(value)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef value_gen():\n  for i in range(2, 7):\n    yield MaskedTensor(range(10), [j%i != 0 for j in range(10)])\n\nds = tf.data.Dataset.from_generator(\n    value_gen, output_signature=MaskedTensor.Spec(shape=[10], dtype=tf.int32))\nfor value in ds:\n  print(value)\n```\n\nLANGUAGE: python\nCODE:\n```\nbatched_ds = ds.batch(2)\nfor value in batched_ds:\n  print(value)\n```\n\nLANGUAGE: python\nCODE:\n```\nunbatched_ds = batched_ds.unbatch()\nfor value in unbatched_ds:\n  print(value)\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel with NPY Files\nDESCRIPTION: Complete example showing how to run SavedModel CLI with .npy input files and output directory specification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \\\n--signature_def x1_x2_to_y --inputs 'x1=/tmp/my_data1.npy;x2=/tmp/my_data2.npy' \\\n--outdir /tmp/out\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple TensorFlow Java Program\nDESCRIPTION: This Java code snippet demonstrates a basic TensorFlow program. It creates a computation graph with a constant operation, executes it in a session, and prints the result. The program showcases the use of TensorFlow's Java API for creating and running operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_java_legacy.md#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport org.tensorflow.Graph;\nimport org.tensorflow.Session;\nimport org.tensorflow.Tensor;\nimport org.tensorflow.TensorFlow;\n\npublic class HelloTensorFlow {\n  public static void main(String[] args) throws Exception {\n\ttry (Graph g = new Graph()) {\n\t  final String value = \"Hello from \" + TensorFlow.version();\n\n\t  // Construct the computation graph with a single operation, a constant\n\t  // named \"MyConst\" with a value \"value\".\n\t  try (Tensor t = Tensor.create(value.getBytes(\"UTF-8\"))) {\n\t    // The Java API doesn't yet include convenience functions for adding operations.\n\t\tg.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\n\t  }\n\n\t  // Execute the \"MyConst\" operation in a Session.\n\t  try (Session s = new Session(g);\n\t      // Generally, there may be multiple output tensors,\n\t\t  // all of them must be closed to prevent resource leaks.\n\t\t  Tensor output = s.runner().fetch(\"MyConst\").run().get(0)) {\n\t    System.out.println(new String(output.bytesValue(), \"UTF-8\"));\n\t  }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Serializing Keras Model to JSON\nDESCRIPTION: Shows how to serialize a Keras model's configuration to JSON format using `model.to_json()`. The resulting JSON string represents the model architecture without any weights. The code also demonstrates how to pretty-print the JSON string for better readability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Serialize a model to JSON format\njson_string = model.to_json()\njson_string\n```\n```\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport json\nimport pprint\npprint.pprint(json.loads(json_string))\n```\n```\n\n----------------------------------------\n\nTITLE: Adding TensorFlow GPU Support to Maven POM\nDESCRIPTION: This XML snippet demonstrates how to add TensorFlow dependencies with GPU support to a Maven project's pom.xml file. It includes both the core TensorFlow library and the GPU-enabled JNI library.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_java_legacy.md#2025-04-21_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.tensorflow</groupId>\n  <artifactId>libtensorflow</artifactId>\n  <version>2.4.0</version>\n</dependency>\n<dependency>\n  <groupId>org.tensorflow</groupId>\n  <artifactId>libtensorflow_jni_gpu</artifactId>\n  <version>2.4.0</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Defining a Model Function Signature for TensorFlow Estimator\nDESCRIPTION: The function signature for a custom model function (model_fn) that will be passed to a TensorFlow Estimator, defining parameters for features, labels, mode, and additional configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef my_model_fn(\n   features, # This is batch_features from input_fn\n   labels,   # This is batch_labels from input_fn\n   mode,     # An instance of tf.estimator.ModeKeys\n   params):  # Additional configuration\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Constraint and Default\nDESCRIPTION: Example showing how to combine both a constraint and default value for an attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_24\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"AttrConstraintAndDefaultExample\")\n    .Attr(\"i: int >= 1 = 1\");\n```\n\n----------------------------------------\n\nTITLE: Using the TF2 to TF1 Checkpoint Conversion Function\nDESCRIPTION: This code demonstrates how to use the convert_tf2_to_tf1 function to convert a TensorFlow 2 checkpoint to TensorFlow 1 format and then load the converted checkpoint in a TF1 session. It prints the checkpoint content before and after conversion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Make sure to run the snippet in `Save a TF2 checkpoint in TF1`.\nprint_checkpoint('tf2-ckpt-saved-in-session-1')\nconverted_path = convert_tf2_to_tf1('tf2-ckpt-saved-in-session-1',\n                                    'converted-tf2-to-tf1')\nprint(\"\\n[Converted]\")\nprint_checkpoint(converted_path)\n\n# Try loading the converted checkpoint.\nwith tf.Graph().as_default() as g:\n  a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(0))\n  b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(0))\n  with tf1.variable_scope('scoped'):\n    c = tf1.get_variable('c', shape=[], dtype=tf.float32, \n                        initializer=tf1.constant_initializer(0))\n  with tf1.Session() as sess:\n    saver = tf1.train.Saver([a, b, c])\n    saver.restore(sess, converted_path)\n    print(\"\\nRestored [a, b, c]: \", sess.run([a, b, c]))\n```\n\n----------------------------------------\n\nTITLE: Setting License Information in Python\nDESCRIPTION: Code block defining the Apache License 2.0 information as a Python comment. This establishes the licensing terms for the TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Compiling Model for Fine-Tuning with Lower Learning Rate\nDESCRIPTION: Recompiles the model with a lower learning rate to fine-tune pre-trained model layers without drastically altering learned features\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=2e-5),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Extracting Actual and Predicted Labels for Video Classification in Python\nDESCRIPTION: This function creates lists of actual ground truth values and predictions from the model. It takes a dataset as input and returns the actual and predicted labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef get_actual_predicted_labels(dataset): \n  \"\"\"\n    Create a list of actual ground truth values and the predictions from the model.\n\n    Args:\n      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n\n    Return:\n      Ground truth and predicted values for a particular dataset.\n  \"\"\"\n  actual = [labels for _, labels in dataset.unbatch()]\n  predicted = model.predict(dataset)\n\n  actual = tf.stack(actual, axis=0)\n  predicted = tf.concat(predicted, axis=0)\n  predicted = tf.argmax(predicted, axis=1)\n\n  return actual, predicted\n```\n\n----------------------------------------\n\nTITLE: Evaluating TensorFlow Lite Model Performance\nDESCRIPTION: Compares the TensorFlow Lite model predictions with the original TensorFlow model and ground truth labels on a subset of evaluation examples to measure accuracy and model agreement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n#@markdown For rapid experimentation, start with a moderate number of examples.\nnum_eval_examples = 50  #@param {type:\"slider\", min:0, max:700}\neval_dataset = ((image, label)  # TFLite expects batch size 1.\n                for batch in train_ds\n                for (image, label) in zip(*batch))\ncount = 0\ncount_lite_tf_agree = 0\ncount_lite_correct = 0\nfor image, label in eval_dataset:\n  probs_lite = lite_model(image[None, ...])[0]\n  probs_tf = model(image[None, ...]).numpy()[0]\n  y_lite = np.argmax(probs_lite)\n  y_tf = np.argmax(probs_tf)\n  y_true = np.argmax(label)\n  count +=1\n  if y_lite == y_tf: count_lite_tf_agree += 1\n  if y_lite == y_true: count_lite_correct += 1\n  if count >= num_eval_examples: break\nprint(\"TFLite model agrees with original model on %d of %d examples (%g%%).\" %\n      (count_lite_tf_agree, count, 100.0 * count_lite_tf_agree / count))\nprint(\"TFLite model is accurate on %d of %d examples (%g%%).\" %\n      (count_lite_correct, count, 100.0 * count_lite_correct / count))\n```\n\n----------------------------------------\n\nTITLE: Monitoring Model Training Output - Shell\nDESCRIPTION: This section illustrates the output you can expect from the model training, which includes loss values and processing speed for each batch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"2015-11-04 11:45:45.927302: step 0, loss = 4.68 (2.0 examples/sec; 64.221 sec/batch)\\n2015-11-04 11:45:49.133065: step 10, loss = 4.66 (533.8 examples/sec; 0.240 sec/batch)\\n2015-11-04 11:45:51.397710: step 20, loss = 4.64 (597.4 examples/sec; 0.214 sec/batch)\\n2015-11-04 11:45:54.446850: step 30, loss = 4.62 (391.0 examples/sec; 0.327 sec/batch)\\n2015-11-04 11:45:57.152676: step 40, loss = 4.61 (430.2 examples/sec; 0.298 sec/batch)\\n2015-11-04 11:46:00.437717: step 50, loss = 4.59 (406.4 examples/sec; 0.315 sec/batch)\\n...\"\n```\n\n----------------------------------------\n\nTITLE: Setting Fine-Tuning Parameter for TensorFlow Model\nDESCRIPTION: Defines a boolean parameter to control whether the feature extractor layer from the TensorFlow Hub module will be fine-tuned during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndo_fine_tuning = False #@param {type:\"boolean\"}\n```\n\n----------------------------------------\n\nTITLE: Transforming Ragged Tensor Values with map_flat_values\nDESCRIPTION: Demonstrates how to apply a function to transform the values of a ragged tensor using tf.ragged.map_flat_values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntimes_two_plus_one = lambda x: x * 2 + 1\nprint(tf.ragged.map_flat_values(times_two_plus_one, digits))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op with Fixed-Type List Input\nDESCRIPTION: Shows how to register an op that accepts a list of tensors of the same fixed type (int32), with the list length specified by an integer attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_32\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"IntListInputExample\")\n    .Attr(\"N: int\")\n    .Input(\"in: N * int32\")\n    .Output(\"out: int32\");\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from a Complex Generator\nDESCRIPTION: This snippet shows how to create a tf.data.Dataset from the gen_series generator, specifying output types and shapes for the variable-length output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nds_series = tf.data.Dataset.from_generator(\n    gen_series,\n    output_types=(tf.int32, tf.float32),\n    output_shapes=((), (None,)))\n\nds_series\n```\n\n----------------------------------------\n\nTITLE: Using Mathematical Dunder Method with New Type Promotion in TensorFlow\nDESCRIPTION: This example shows how unary operations like negation create WeakTensors with the new type promotion system.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n-tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=-5, weak=True>\n```\n\n----------------------------------------\n\nTITLE: Disabling GPUs for Multi-worker Training\nDESCRIPTION: Setting the CUDA_VISIBLE_DEVICES environment variable to -1 to disable all GPUs, preventing errors when multiple workers try to use the same GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Loaded Images using Matplotlib\nDESCRIPTION: Creates a matplotlib figure to display the loaded sample images side by side for visual inspection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(8, 8))\nfor n, (name, img_tensors) in enumerate(img_name_tensors.items()):\n  ax = plt.subplot(1, 2, n+1)\n  ax.imshow(img_tensors)\n  ax.set_title(name)\n  ax.axis('off')\nplt.tight_layout()\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: A Python code block containing the Apache License 2.0 declaration for the TensorFlow Authors. This is a standard license notice that specifies the terms under which the code can be used.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Loading Kinetics-400 Action Labels\nDESCRIPTION: This snippet fetches the Kinetics-400 action labels from the GitHub repository, which are used for interpreting the model's predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nKINETICS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\nwith request.urlopen(KINETICS_URL) as obj:\n  labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\nprint(\"Found %d labels.\" % len(labels))\n```\n\n----------------------------------------\n\nTITLE: Creating Wide Window Configuration for Time Series Visualization\nDESCRIPTION: Configures a WindowGenerator with wider input and label windows (24 hours) to generate more meaningful visualizations while maintaining the same prediction task of forecasting one hour into the future.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nwide_window = WindowGenerator(\n    input_width=24, label_width=24, shift=1,\n    label_columns=['T (degC)'])\n\nwide_window\n```\n\n----------------------------------------\n\nTITLE: Using Reinitializable Iterator with Multiple Datasets\nDESCRIPTION: Demonstrates how to use a reinitializable iterator that can be initialized from multiple different Dataset objects that have the same structure. Shows an example with training and validation datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define training and validation datasets with the same structure.\ntraining_dataset = tf.data.Dataset.range(100).map(\n    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\nvalidation_dataset = tf.data.Dataset.range(50)\n\n# A reinitializable iterator is defined by its structure. We could use the\n# `output_types` and `output_shapes` properties of either `training_dataset`\n# or `validation_dataset` here, because they are compatible.\niterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n                                           training_dataset.output_shapes)\nnext_element = iterator.get_next()\n\ntraining_init_op = iterator.make_initializer(training_dataset)\nvalidation_init_op = iterator.make_initializer(validation_dataset)\n\n# Run 20 epochs in which the training dataset is traversed, followed by the\n# validation dataset.\nfor _ in range(20):\n  # Initialize an iterator over the training dataset.\n  sess.run(training_init_op)\n  for _ in range(100):\n    sess.run(next_element)\n\n  # Initialize an iterator over the validation dataset.\n  sess.run(validation_init_op)\n  for _ in range(50):\n    sess.run(next_element)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Python Logic in TensorFlow with tf.py_func\nDESCRIPTION: Illustrates integration of custom Python logic into TensorFlow's dataset processing using tf.py_func. Involves reading images with OpenCV and resizing them using TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\nimport cv2\n\ndef _read_py_function(filename, label):\n  image_decoded = cv2.imread(filename.decode(), cv2.IMREAD_GRAYSCALE)\n  return image_decoded, label\n\ndef _resize_function(image_decoded, label):\n  image_decoded.set_shape([None, None, None])\n  image_resized = tf.image.resize_images(image_decoded, [28, 28])\n  return image_resized, label\n\nfilenames = [\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...]\nlabels = [0, 37, 29, 1, ...]\n\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\ndataset = dataset.map(\n    lambda filename, label: tuple(tf.py_func(\n        _read_py_function, [filename, label], [tf.uint8, label.dtype])))\ndataset = dataset.map(_resize_function)\n```\n\n----------------------------------------\n\nTITLE: Adding Residual Block Function\nDESCRIPTION: Helper function to add residual blocks with skip connections to the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef add_residual_block(input, filters, kernel_size):\n  \"\"\"\n    Add residual blocks to the model. If the last dimensions of the input data\n    and filter size does not match, project it such that last dimension matches.\n  \"\"\"\n  out = ResidualMain(filters, \n                     kernel_size)(input)\n  \n  res = input\n  # Using the Keras functional APIs, project the last dimension of the tensor to\n  # match the new filter size\n  if out.shape[-1] != input.shape[-1]:\n    res = Project(out.shape[-1])(res)\n\n  return layers.add([res, out])\n```\n\n----------------------------------------\n\nTITLE: Checking Final Dataset Structure in Python\nDESCRIPTION: Examines the final structure of the prepared training dataset to verify it's correctly configured before model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Creating Word Index Dictionary\nDESCRIPTION: Builds helper functions and dictionaries to convert between word indices and actual text, including special tokens for padding and unknown words\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nword_index = imdb.get_word_index()\n\nword_index = {k:(v+3) for k,v in word_index.items()}\nword_index[\"<PAD>\"] = 0\nword_index[\"<START>\"] = 1\nword_index[\"<UNK>\"] = 2\nword_index[\"<UNUSED>\"] = 3\n\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset and Creating a tf.data Dataset\nDESCRIPTION: Shows how to load the Fashion MNIST dataset using Keras, preprocess the image data by normalizing it, and create a tf.data.Dataset from the images and labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntrain, test = tf.keras.datasets.fashion_mnist.load_data()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow 1.x Input Function Setup\nDESCRIPTION: Defines input functions and feature columns for TensorFlow 1.x Estimator models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((dict(x_train), y_train)).batch(32)\n\ndef _eval_input_fn():\n  return tf1.data.Dataset.from_tensor_slices((dict(x_eval), y_eval)).batch(32)\n\nFEATURE_NAMES = [\n    'age', 'fare', 'sex', 'n_siblings_spouses', 'parch', 'class', 'alone'\n]\n\nfeature_columns = []\nfor fn in FEATURE_NAMES:\n  feat_col = tf1.feature_column.numeric_column(fn, dtype=tf.float32)\n  feature_columns.append(feat_col)\n```\n\n----------------------------------------\n\nTITLE: Apache License Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license header for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Accessing First Row of a Ragged Tensor\nDESCRIPTION: Demonstrates how to use Python-style indexing to access the first row of a ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[0])       # First row\n```\n\n----------------------------------------\n\nTITLE: Using Named Signature for Image Classification\nDESCRIPTION: Demonstrates how to explicitly invoke the image classification signature to obtain class logits. Shows the standard input format and expected output structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/images.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n  outputs = module(dict(images=images), signature=\"image_classification\",\n                   as_dict=True)\n  logits = outputs[\"default\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing Recursive Frame Generation in Python\nDESCRIPTION: A utility function that recursively generates intermediate frames between two input frames by splitting at the midpoint and applying an interpolator at each step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef _recursive_generator(\n    frame1: np.ndarray, frame2: np.ndarray, num_recursions: int,\n    interpolator: Interpolator) -> Generator[np.ndarray, None, None]:\n  \"\"\"Splits halfway to repeatedly generate more frames.\n\n  Args:\n    frame1: Input image 1.\n    frame2: Input image 2.\n    num_recursions: How many times to interpolate the consecutive image pairs.\n    interpolator: The frame interpolator instance.\n\n  Yields:\n    The interpolated frames, including the first frame (frame1), but excluding\n    the final frame2.\n  \"\"\"\n  if num_recursions == 0:\n    yield frame1\n  else:\n    # Adds the batch dimension to all inputs before calling the interpolator,\n    # and remove it afterwards.\n    time = np.full(shape=(1,), fill_value=0.5, dtype=np.float32)\n    mid_frame = interpolator(\n        np.expand_dims(frame1, axis=0), np.expand_dims(frame2, axis=0), time)[0]\n    yield from _recursive_generator(frame1, mid_frame, num_recursions - 1,\n                                    interpolator)\n    yield from _recursive_generator(mid_frame, frame2, num_recursions - 1,\n                                    interpolator)\n```\n\n----------------------------------------\n\nTITLE: Creating TPUEstimator in TF1\nDESCRIPTION: This code snippet creates a `TPUEstimator` object, configuring it for TPU training. It defines `TPUConfig` to specify TPU-specific settings and `RunConfig` to manage the execution environment.  The `TPUEstimator` is initialized with the defined model function, configuration, batch sizes, and embedding configuration specification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntpu_config = tf1.estimator.tpu.TPUConfig(\n    iterations_per_loop=10,\n    per_host_input_for_training=tf1.estimator.tpu.InputPipelineConfig\n          .PER_HOST_V2)\nconfig = tf1.estimator.tpu.RunConfig(\n    cluster=cluster_resolver,\n    save_checkpoints_steps=None,\n    tpu_config=tpu_config)\nestimator = tf1.estimator.tpu.TPUEstimator(\n    model_fn=_model_fn, config=config, train_batch_size=8, eval_batch_size=8,\n    embedding_config_spec=embedding_config_spec)\n```\n\n----------------------------------------\n\nTITLE: Implementing WritableFile for POSIX Filesystem in C++\nDESCRIPTION: This snippet demonstrates the implementation of the WritableFile interface for the POSIX filesystem. It shows how to handle file writing operations including append, flush, sync, and close.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_1\n\nLANGUAGE: C++\nCODE:\n```\nclass PosixWritableFile : public WritableFile {\n public:\n  PosixWritableFile(const string& fname, FILE* f)\n      : filename_(fname), file_(f) {}\n\n  ~PosixWritableFile() override {\n    if (file_ != NULL) {\n      fclose(file_);\n    }\n  }\n\n  Status Append(const StringPiece& data) override {\n    size_t r = fwrite(data.data(), 1, data.size(), file_);\n    if (r != data.size()) {\n      return IOError(filename_, errno);\n    }\n    return Status::OK();\n  }\n\n  Status Close() override {\n    Status result;\n    if (fclose(file_) != 0) {\n      result = IOError(filename_, errno);\n    }\n    file_ = NULL;\n    return result;\n  }\n\n  Status Flush() override {\n    if (fflush(file_) != 0) {\n      return IOError(filename_, errno);\n    }\n    return Status::OK();\n  }\n\n  Status Sync() override {\n    Status s;\n    if (fflush(file_) != 0) {\n      s = IOError(filename_, errno);\n    }\n    return s;\n  }\n\n private:\n  string filename_;\n  FILE* file_;\n};\n```\n\n----------------------------------------\n\nTITLE: Selecting and Loading a Pre-trained HRNet Model from TensorFlow Hub\nDESCRIPTION: Code to select from 17 different pre-trained HRNet models for semantic segmentation and load it from TensorFlow Hub using the hub.load() function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Choose a pre-trained HRNet model to load.\n\nhrnet_model_name = 'ade20k-hrnetv2-w48/1'  #@param [\"ade20k-hrnetv2-w48/1\", \"isprs-hrnetv2-w48/1\", \"vkitti2-hrnetv2-w48/1\", \"vgallery-hrnetv2-w48/1\", \"sunrgbd-hrnetv2-w48/1\", \"suim-hrnetv2-w48/1\", \"scannet-hrnetv2-w48/1\", \"pvoc-hrnetv2-w48/1\", \"msegpcontext-hrnetv2-w48/1\", \"mapillary-hrnetv2-w48/1\", \"kitti-hrnetv2-w48/1\", \"isaid-hrnetv2-w48/1\", \"idd-hrnetv2-w48/1\", \"coco-hrnetv2-w48/1\", \"city-hrnetv2-w48/1\", \"camvid-hrnetv2-w48/1\", \"bdd-hrnetv2-w48/1\"]\n\ntfhub_model_name = 'https://tfhub.dev/google/HRNet/' + hrnet_model_name\n\nprint('HRNet model selected           :', tfhub_model_name)\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Saving with TensorFlow 1 Estimator API\nDESCRIPTION: Demonstrates configuring tf.estimator.RunConfig to save checkpoints at every step during training with TensorFlow 1's tf.estimator.Estimator API and training a model with that configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfeature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\n\nconfig = tf1.estimator.RunConfig(save_summary_steps=1,\n                                 save_checkpoints_steps=1)\n\npath = tempfile.mkdtemp()\n\nclassifier = tf1.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf1.train.AdamOptimizer(0.001),\n    n_classes=10,\n    dropout=0.2,\n    model_dir=path,\n    config = config\n)\n\ntrain_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_train},\n    y=y_train.astype(np.int32),\n    num_epochs=10,\n    batch_size=50,\n    shuffle=True,\n)\n\ntest_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_test},\n    y=y_test.astype(np.int32),\n    num_epochs=10,\n    shuffle=False\n)\n\ntrain_spec = tf1.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10)\neval_spec = tf1.estimator.EvalSpec(input_fn=test_input_fn,\n                                   steps=10,\n                                   throttle_secs=0)\n\ntf1.estimator.train_and_evaluate(estimator=classifier,\n                                train_spec=train_spec,\n                                eval_spec=eval_spec)\n```\n\nLANGUAGE: python\nCODE:\n```\n%ls {classifier.model_dir}\n```\n\n----------------------------------------\n\nTITLE: Visualizing prediction probabilities for a single image\nDESCRIPTION: Displays a bar chart of the prediction probabilities for a single image, with class names on the x-axis. Makes it easy to interpret the model's confidence across all possible classes for this specific prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nplot_value_array(1, predictions_single[0], test_labels)\n_ = plt.xticks(range(10), class_names, rotation=45)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Importing Required TensorFlow and Image Processing Libraries\nDESCRIPTION: Sets up the necessary Python imports for TensorFlow, TensorFlow Hub, image processing, and visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom io import BytesIO\nfrom PIL import Image as PilImage\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom six.moves.urllib.request import urlopen\n```\n\n----------------------------------------\n\nTITLE: Creating Function to List Files from Remote Zip URL\nDESCRIPTION: Defines a function that examines the contents of a remote zip file without downloading it entirely, returning a list of files contained in the archive.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef list_files_from_zip_url(zip_url):\n  \"\"\" List the files in each class of the dataset given a URL with the zip file.\n\n    Args:\n      zip_url: A URL from which the files can be extracted from.\n\n    Returns:\n      List of files in each of the classes.\n  \"\"\"\n  files = []\n  with rz.RemoteZip(zip_url) as zip:\n    for zip_info in zip.infolist():\n      files.append(zip_info.filename)\n  return files\n```\n\n----------------------------------------\n\nTITLE: Executing SentEval Evaluation Task for Universal Sentence Encoder CMLM\nDESCRIPTION: Loads the Universal Sentence Encoder CMLM model and evaluates it on a selected SentEval task. Allows choosing between \"rapid prototyping\" parameters for faster results or \"slower, best performance\" parameters for more accurate evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/senteval_for_universal_sentence_encoder_cmlm.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport sys\nsys.path.append(f'{os.getcwd()}/SentEval')\n\nimport tensorflow as tf\n\n# Prevent TF from claiming all GPU memory so there is some left for pytorch.\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Memory growth needs to be the same across GPUs.\n  for gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n\nimport tensorflow_hub as hub\nimport tensorflow_text\nimport senteval\nimport time\n\nPATH_TO_DATA = f'{os.getcwd()}/SentEval/data'\nMODEL = 'https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-base/1' #@param ['https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-base/1', 'https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-large/1']\nPARAMS = 'rapid prototyping' #@param ['slower, best performance', 'rapid prototyping']\nTASK = 'CR' #@param ['CR','MR', 'MPQA', 'MRPC', 'SICKEntailment', 'SNLI', 'SST2', 'SUBJ', 'TREC']\n\nparams_prototyping = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\nparams_prototyping['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n                                 'tenacity': 3, 'epoch_size': 2}\n\nparams_best = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\nparams_best['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 16,\n                                 'tenacity': 5, 'epoch_size': 6}\n\nparams = params_best if PARAMS == 'slower, best performance' else params_prototyping\n\npreprocessor = hub.KerasLayer(\n    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\nencoder = hub.KerasLayer(\n    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-base/1\")\n\ninputs = tf.keras.Input(shape=tf.shape(''), dtype=tf.string)\noutputs = encoder(preprocessor(inputs))\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\ndef prepare(params, samples):\n    return\n\ndef batcher(_, batch):\n    batch = [' '.join(sent) if sent else '.' for sent in batch]\n    return model.predict(tf.constant(batch))[\"default\"]\n\n\nse = senteval.engine.SE(params, batcher, prepare)\nprint(\"Evaluating task %s with %s parameters\" % (TASK, PARAMS))\nstart = time.time()\nresults = se.eval(TASK)\nend = time.time()\nprint('Time took on task %s : %.1f. seconds' % (TASK, end - start))\nprint(results)\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning TF1 Hub Module in TensorFlow 1\nDESCRIPTION: Shows how to load a TF1 Hub module for fine-tuning in TensorFlow 1, making it trainable and using the appropriate tags.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nm = hub.Module(handle,\n               trainable=True,\n               tags=[\"train\"]*is_training)\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Defining Training Metrics for DTensor-based MLP\nDESCRIPTION: Implements cross-entropy loss and accuracy metric functions for training the DTensor-based MLP model on the MNIST dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef cross_entropy_loss(y_pred, y):\n  # Compute cross entropy loss with a sparse operation\n  sparse_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_pred)\n  return tf.reduce_mean(sparse_ce)\n\ndef accuracy(y_pred, y):\n  # Compute accuracy after extracting class predictions\n  class_preds = tf.argmax(y_pred, axis=1)\n  is_equal = tf.equal(y, class_preds)\n  return tf.reduce_mean(tf.cast(is_equal, tf.float32))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow and Dependencies Import\nDESCRIPTION: Importing required libraries including TensorFlow, Keras, NumPy and Matplotlib for the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Defining embedding config spec in TF1\nDESCRIPTION: This code snippet defines the TPU-specific embedding configuration using `tf1.estimator.tpu.experimental.EmbeddingConfigSpec`. It specifies the feature columns to be used for embedding and the optimization parameters.  The `feature_columns` parameter is set to a tuple containing the `embedding_column` defined earlier, and the `optimization_parameters` parameter is set to `AdagradParameters` with a learning rate of 0.05.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nembedding_config_spec = tf1.estimator.tpu.experimental.EmbeddingConfigSpec(\n    feature_columns=(embedding_column,),\n    optimization_parameters=(\n        tf1.tpu.experimental.AdagradParameters(0.05)))\n```\n\n----------------------------------------\n\nTITLE: Python Expression Input Example\nDESCRIPTION: Demonstrates passing input data using Python list expression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n`<input_key>=[[1],[2],[3]]`\n```\n\n----------------------------------------\n\nTITLE: Configuring BERT Model and Preprocessing from TF Hub\nDESCRIPTION: Sets up the BERT model and preprocessing component by selecting the appropriate URLs from TensorFlow Hub. Multiple model options are provided including models trained on wiki books, MNLI, QNLI, and PubMed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title Configure the model { run: \"auto\" }\nBERT_MODEL = \"https://tfhub.dev/google/experts/bert/wiki_books/2\" # @param {type: \"string\"} [\"https://tfhub.dev/google/experts/bert/wiki_books/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/mnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qqp/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/squad2/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\",  \"https://tfhub.dev/google/experts/bert/pubmed/2\", \"https://tfhub.dev/google/experts/bert/pubmed/squad2/2\"]\n# Preprocessing must match the model, but all the above use the same.\nPREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting SQuAD Dataset for Q&A Retrieval\nDESCRIPTION: Downloads the specified SQuAD dataset JSON file and extracts sentences and questions from it. The extracted data is used for building the retrieval index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title Download and extract SQuAD data\nsquad_url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json' #@param [\"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"]\n\nsquad_json = download_squad(squad_url)\nsentences = extract_sentences_from_squad_json(squad_json)\nquestions = extract_questions_from_squad_json(squad_json)\nprint(\"%s sentences, %s questions extracted from SQuAD %s\" % (len(sentences), len(questions), squad_url))\n\nprint(\"\\nExample sentence and context:\\n\")\nsentence = random.choice(sentences)\nprint(\"sentence:\\n\")\npprint.pprint(sentence[0])\nprint(\"\\ncontext:\\n\")\npprint.pprint(sentence[1])\nprint()\n```\n\n----------------------------------------\n\nTITLE: Saving Model Variables with tf.train.Saver in Python\nDESCRIPTION: This Python snippet demonstrates how to save model variables to checkpoint files using tf.train.Saver. It includes creating variables, initializing them, performing operations, and saving the state to disk. Requires TensorFlow environment setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create some variables.\nv1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\nv2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n\ninc_v1 = v1.assign(v1+1)\ndec_v2 = v2.assign(v2-1)\n\n# Add an op to initialize the variables.\ninit_op = tf.global_variables_initializer()\n\n# Add ops to save and restore all the variables.\nsaver = tf.train.Saver()\n\n# Later, launch the model, initialize the variables, do some work, and save the\n# variables to disk.\nwith tf.Session() as sess:\n  sess.run(init_op)\n  # Do some work with the model.\n  inc_v1.op.run()\n  dec_v2.op.run()\n  # Save the variables to disk.\n  save_path = saver.save(sess, \"/tmp/model.ckpt\")\n  print(\"Model saved in path: %s\" % save_path)\n```\n\n----------------------------------------\n\nTITLE: TF1: Using tf.metrics with Estimator API\nDESCRIPTION: Example of using TF1's metrics API with an Estimator. Shows how to create input functions, define a model function with accuracy metrics, and train the estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef _input_fn():\n  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n\ndef _eval_input_fn():\n  return tf1.data.Dataset.from_tensor_slices(\n      (eval_features, eval_labels)).batch(1)\n\ndef _model_fn(features, labels, mode):\n  logits = tf1.layers.Dense(2)(features)\n  predictions = tf.math.argmax(input=logits, axis=1)\n  loss = tf1.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  accuracy = tf1.metrics.accuracy(labels=labels, predictions=predictions)\n  return tf1.estimator.EstimatorSpec(mode, \n                                     predictions=predictions,\n                                     loss=loss, \n                                     train_op=train_op,\n                                     eval_metric_ops={'accuracy': accuracy})\n\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\nestimator.train(_input_fn)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow 1: Using TensorBoard with tf.estimator\nDESCRIPTION: Creates a DNNClassifier, trains and evaluates it on MNIST, and sets up TensorBoard logging. This snippet demonstrates the TensorFlow 1.x approach.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%reload_ext tensorboard\n\nfeature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\n\nconfig = tf1.estimator.RunConfig(save_summary_steps=1,\n                                 save_checkpoints_steps=1)\n\npath = tempfile.mkdtemp()\n\nclassifier = tf1.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf1.train.AdamOptimizer(0.001),\n    n_classes=10,\n    dropout=0.1,\n    model_dir=path,\n    config = config\n)\n\ntrain_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_train},\n    y=y_train.astype(np.int32),\n    num_epochs=10,\n    batch_size=50,\n    shuffle=True,\n)\n\ntest_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_test},\n    y=y_test.astype(np.int32),\n    num_epochs=10,\n    shuffle=False\n)\n\ntrain_spec = tf1.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10)\neval_spec = tf1.estimator.EvalSpec(input_fn=test_input_fn,\n                                   steps=10,\n                                   throttle_secs=0)\n\ntf1.estimator.train_and_evaluate(estimator=classifier,\n                                train_spec=train_spec,\n                                eval_spec=eval_spec)\n```\n\n----------------------------------------\n\nTITLE: Generating Bimodal Distribution Data in Python\nDESCRIPTION: Creates histogram summaries for two different normal distributions and combines them into a bimodal distribution. Demonstrates more complex distribution visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensorboard_histograms.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nk = tf.placeholder(tf.float32)\n\n# Make a normal distribution, with a shifting mean\nmean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n# Record that distribution into a histogram summary\ntf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n\n# Make a normal distribution with shrinking variance\nvariance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))\n# Record that distribution too\ntf.summary.histogram(\"normal/shrinking_variance\", variance_shrinking_normal)\n\n# Let's combine both of those distributions into one dataset\nnormal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)\n# We add another histogram summary to record the combined distribution\ntf.summary.histogram(\"normal/bimodal\", normal_combined)\n\nsummaries = tf.summary.merge_all()\n\n# Setup a session and summary writer\nsess = tf.Session()\nwriter = tf.summary.FileWriter(\"/tmp/histogram_example\")\n\n# Setup a loop and write the summaries to disk\nN = 400\nfor step in range(N):\n  k_val = step/float(N)\n  summ = sess.run(summaries, feed_dict={k: k_val})\n  writer.add_summary(summ, global_step=step)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Confusion Matrix\nDESCRIPTION: Creates and displays a normalized confusion matrix to visualize model performance across different classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef show_confusion_matrix(test_labels, predictions):\n  \"\"\"Compute confusion matrix and normalize.\"\"\"\n  confusion = sk_metrics.confusion_matrix(\n    np.argmax(test_labels, axis=1), predictions)\n  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n  axis_labels = list(CLASSES.values())\n  ax = sns.heatmap(\n      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n      cmap='Blues', annot=True, fmt='.2f', square=True)\n  plt.title(\"Confusion matrix\")\n  plt.ylabel(\"True label\")\n  plt.xlabel(\"Predicted label\")\n\nshow_confusion_matrix(batch_labels, test_prediction)\n```\n\n----------------------------------------\n\nTITLE: Creating the Model Instance (Python)\nDESCRIPTION: This snippet calls the previously defined function to create an instance of the neural network model ready for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmodel = build_model()\n```\n\n----------------------------------------\n\nTITLE: Downloading Iris Dataset in Python\nDESCRIPTION: Downloading the Iris training dataset using TensorFlow's utilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n\ntrain_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n                                           origin=train_dataset_url)\n\nprint(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with Respect to Intermediate Values in TensorFlow\nDESCRIPTION: Shows how to use tf.GradientTape to compute gradients with respect to intermediate values in a computation graph, requesting the derivative of z with respect to y.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nx = tf.ones((2, 2))\n\nwith tf.GradientTape() as t:\n  t.watch(x)\n  y = tf.reduce_sum(x)\n  z = tf.multiply(y, y)\n\n# Use the tape to compute the derivative of z with respect to the\n# intermediate value y.\ndz_dy = t.gradient(z, y)\nassert dz_dy.numpy() == 8.0\n```\n\n----------------------------------------\n\nTITLE: Retrieving Collection Contents\nDESCRIPTION: Shows how to retrieve all variables from a named collection.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntf.get_collection(\"my_collection_name\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Error Message for End-of-Central-Directory Signature Issue (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message related to unzipping a file during the TensorFlow build process, indicating a problem with the zip file or its contents.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>Unzipping simple_console_for_windows.zip to create runfiles tree...\n[./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip]\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nunzip: cannot find zipfile directory in one of ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip or\n        ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.zip, and cannot find ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.ZIP, period.\n</pre>\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for TensorFlow NumPy Guide\nDESCRIPTION: Imports necessary libraries for working with TensorFlow's NumPy API implementation, including matplotlib for visualization, NumPy for comparison, and TensorFlow with its experimental NumPy module.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\nimport timeit\n\nprint(\"Using TensorFlow version %s\" % tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Displaying TensorFlow Import Error for Unexpected Keyword (Markdown/HTML)\nDESCRIPTION: This snippet shows a complex error message that occurs when importing TensorFlow, indicating a compatibility issue with the installed protobuf version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>Traceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\",\n    line 4, in <module>\n    from tensorflow.python import *\n    ...\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\",\n    line 22, in <module>\n    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\"d\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02\n      \\x03(\\x0b\\x32\n      .tensorflow.TensorShapeProto.Dim\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01\n      \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tb\\x06proto3')\n  TypeError: __init__() got an unexpected keyword argument 'syntax'</pre>\n```\n\n----------------------------------------\n\nTITLE: Downloading Pretrained Embeddings\nDESCRIPTION: Downloading fastText embeddings and TF-Hub exporter script.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -O https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.vec.gz\ncurl -O https://raw.githubusercontent.com/tensorflow/hub/master/examples/text_embeddings_v2/export_v2.py\ngunzip -qf cc.bn.300.vec.gz --k\n```\n\n----------------------------------------\n\nTITLE: Configuring a Keras Model with Multiple Metrics\nDESCRIPTION: This snippet demonstrates how to compile a Keras model with multiple metrics, including both string metric names and custom metric objects. The metric names are preserved in the training history.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n    optimizer = tf.keras.optimizers.Adam(0.001),\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics = ['acc', 'accuracy', tf.keras.metrics.SparseCategoricalAccuracy(name=\"my_accuracy\")])\nhistory = model.fit(train_data)\n```\n\n----------------------------------------\n\nTITLE: Defining Input Functions for TensorFlow Estimator\nDESCRIPTION: These functions prepare the SciCite dataset for training, evaluation, and prediction. They handle data preprocessing, shuffling, and batching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocessed_input_fn(for_eval):\n  data = THE_DATASET.get_data(for_eval=for_eval)\n  data = data.map(THE_DATASET.example_fn, num_parallel_calls=1)\n  return data\n\n\ndef input_fn_train(params):\n  data = preprocessed_input_fn(for_eval=False)\n  data = data.repeat(None)\n  data = data.shuffle(1024)\n  data = data.batch(batch_size=params['batch_size'])\n  return data\n\n\ndef input_fn_eval(params):\n  data = preprocessed_input_fn(for_eval=True)\n  data = data.repeat(1)\n  data = data.batch(batch_size=params['batch_size'])\n  return data\n\n\ndef input_fn_predict(params):\n  data = preprocessed_input_fn(for_eval=True)\n  data = data.batch(batch_size=params['batch_size'])\n  return data\n```\n\n----------------------------------------\n\nTITLE: Plotting Conv1D Model Predictions on Wide Window\nDESCRIPTION: Visualizes the convolutional model's predictions using a wide window, showing how each prediction is based on the preceding time steps according to the convolutional kernel width.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nwide_conv_window.plot(conv_model)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Font Images from CSV Data\nDESCRIPTION: This code plots a 3x3 grid of font images from the transformed dataset. It displays the first 9 characters from the batch with their corresponding labels, demonstrating the successful reconstruction of the images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nfrom matplotlib import pyplot as plt\n\nplt.figure(figsize=(6,6), dpi=120)\n\nfor n in range(9):\n  plt.subplot(3,3,n+1)\n  plt.imshow(features['image'][..., n])\n  plt.title(chr(features['m_label'][n]))\n  plt.axis('off')\n```\n\n----------------------------------------\n\nTITLE: Exporting TensorFlow Model as Saved Model in Python\nDESCRIPTION: This snippet exports a trained TensorFlow model to a specified directory with a timestamp. It uses Python's time module to generate a unique folder name based on the current time. The model's save function persists the model in the specified path for later use. No specific dependencies are listed aside from TensorFlow environment. The expected output is the path to the saved model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport time\nt = time.time()\n\nexport_path = \"/tmp/saved_models/{}\".format(int(t))\nmodel.save(export_path)\n\nexport_path\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi-Layer Perceptron (MLP) Class in TensorFlow\nDESCRIPTION: Implementation of an MLP model that executes layers sequentially. The class accepts a list of layers and applies them in order during the forward pass, with TensorFlow function decoration for performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass MLP(tf.Module):\n\n  def __init__(self, layers):\n    self.layers = layers\n   \n  @tf.function\n  def __call__(self, x, preds=False): \n    # Execute the model's layers sequentially\n    for layer in self.layers:\n      x = layer(x)\n    return x\n```\n\n----------------------------------------\n\nTITLE: Data Preparation for MNIST Dataset\nDESCRIPTION: Loads and prepares the MNIST dataset for training and validation, including normalization of image data from uint8 to float32 in the range [0,1].\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef normalize_img(image, label):\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n  return tf.cast(image, tf.float32) / 255., label\n\ntraining_dataset, validation_dataset = tfds.load(\n    \"mnist\",\n    split=[\"train\", \"test\"],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=False,\n)\ntraining_dataset = training_dataset.map(normalize_img)\nvalidation_dataset = validation_dataset.map(normalize_img)\n```\n\n----------------------------------------\n\nTITLE: Downloading Multilingual News Corpus Data\nDESCRIPTION: Downloads and processes news sentences from multiple languages using the News Commentary Corpus, limiting to 1000 sentences per language for demonstration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncorpus_metadata = [\n    ('ar', 'ar-en.txt.zip', 'News-Commentary.ar-en.ar', 'Arabic'),\n    ('zh', 'en-zh.txt.zip', 'News-Commentary.en-zh.zh', 'Chinese'),\n    ('en', 'en-es.txt.zip', 'News-Commentary.en-es.en', 'English'),\n    ('ru', 'en-ru.txt.zip', 'News-Commentary.en-ru.ru', 'Russian'),\n    ('es', 'en-es.txt.zip', 'News-Commentary.en-es.es', 'Spanish'),\n]\n\nlanguage_to_sentences = {}\nlanguage_to_news_path = {}\nfor language_code, zip_file, news_file, language_name in corpus_metadata:\n  zip_path = tf.keras.utils.get_file(\n      fname=zip_file,\n      origin='http://opus.nlpl.eu/download.php?f=News-Commentary/v11/moses/' + zip_file,\n      extract=True)\n  news_path = os.path.join(os.path.dirname(zip_path), news_file)\n  language_to_sentences[language_code] = pd.read_csv(news_path, sep='\\t', header=None)[0][:1000]\n  language_to_news_path[language_code] = news_path\n\n  print('{:,} {} sentences'.format(len(language_to_sentences[language_code]), language_name))\n```\n\n----------------------------------------\n\nTITLE: Generating Random Projection Weight Matrix in Python\nDESCRIPTION: This function generates a Gaussian random projection matrix to reduce the dimensionality of embeddings. It uses scikit-learn's gaussian_random_matrix and saves the matrix to disk.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef generate_random_projection_weights(original_dim, projected_dim):\n  random_projection_matrix = None\n  if projected_dim and original_dim > projected_dim:\n    random_projection_matrix = gaussian_random_matrix(\n        n_components=projected_dim, n_features=original_dim).T\n    print(\"A Gaussian random weight matrix was creates with shape of {}\".format(random_projection_matrix.shape))\n    print('Storing random projection matrix to disk...')\n    with open('random_projection_matrix', 'wb') as handle:\n      pickle.dump(random_projection_matrix, \n                  handle, protocol=pickle.HIGHEST_PROTOCOL)\n        \n  return random_projection_matrix\n```\n\n----------------------------------------\n\nTITLE: Evaluating Initial Model Performance in Python\nDESCRIPTION: Tests the model's performance before training to understand the baseline loss values for each output component.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nlosses = model.evaluate(train_ds, return_dict=True)\nlosses\n```\n\n----------------------------------------\n\nTITLE: Computing Element-wise Maximum with tf.tensor_scatter_nd_max\nDESCRIPTION: Shows how to take the element-wise maximum between original tensor values and update values at specified indices using tf.tensor_scatter_nd_max.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nt16 = tf.tensor_scatter_nd_max(t14,\n                               indices=[[0, 2], [1, 1], [2, 0]],\n                               updates=[6, 5, 4])\n\nprint(t16)\n```\n\n----------------------------------------\n\nTITLE: Registering Restricted Polymorphic TensorFlow Op in C++\nDESCRIPTION: Example of registering a polymorphic TensorFlow operation with type restrictions. The op accepts a single input with a type determined by attribute 'T', but restricts 'T' to be either int32 or int64.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_40\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"RestrictedPolymorphicSingleInput\")\n    .Attr(\"T: {int32, int64}\")\n    .Input(\"in: T\");\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow Imports\nDESCRIPTION: Basic imports for using both TensorFlow 2.x and TensorFlow 1.x compatibility mode in the same notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow License and Setup\nDESCRIPTION: License declaration and initial setup code for TensorFlow, including configuration of virtual CPU devices for distribution strategy examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nphysical_devices = tf.config.list_physical_devices(\"CPU\")\ntf.config.experimental.set_virtual_device_configuration(\n    physical_devices[0], [\n        tf.config.experimental.VirtualDeviceConfiguration(),\n        tf.config.experimental.VirtualDeviceConfiguration(),\n        tf.config.experimental.VirtualDeviceConfiguration()\n    ])\n```\n\n----------------------------------------\n\nTITLE: Resetting Generator State\nDESCRIPTION: Demonstration of resetting a generator's state to reproduce the same sequence of random numbers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ng = tf.random.Generator.from_seed(1)\nprint(g.normal([]))\nprint(g.normal([]))\ng.reset_from_seed(1)\nprint(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Using Attribute in TensorFlow Op Compute Method (C++)\nDESCRIPTION: This snippet illustrates how to use an attribute value retrieved in the constructor within the `Compute` method of a TensorFlow OpKernel. It demonstrates how to validate the attribute against dynamic inputs and then utilizes the attribute to selectively preserve a value in the output tensor, zeroing out the rest.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_11\n\nLANGUAGE: c++\nCODE:\n```\n  void Compute(OpKernelContext* context) override {\n    // ...\n\n    // We're using saved attr to validate potentially dynamic input\n    // So we check that preserve_index is in range\n    OP_REQUIRES(context, preserve_index_ < input.dimension(0),\n                errors::InvalidArgument(\"preserve_index out of range\"));\n\n    // Set all the elements of the output tensor to 0\n    const int N = input.size();\n    for (int i = 0; i < N; i++) {\n      output_flat(i) = 0;\n    }\n\n    // Preserve the requested input value\n    output_flat(preserve_index_) = input(preserve_index_);\n  }\n```\n\n----------------------------------------\n\nTITLE: Implementing ZeroOut Gradient in Python\nDESCRIPTION: Implementation of the gradient function for the ZeroOut custom operation using TensorFlow's RegisterGradient decorator. The function computes gradients with respect to the op's inputs given gradients with respect to the op's outputs, handling sparse gradient computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import sparse_ops\n\n@ops.RegisterGradient(\"ZeroOut\")\ndef _zero_out_grad(op, grad):\n  \"\"\"The gradients for `zero_out`.\n\n  Args:\n    op: The `zero_out` `Operation` that we are differentiating, which we can use\n      to find the inputs and outputs of the original op.\n    grad: Gradient with respect to the output of the `zero_out` op.\n\n  Returns:\n    Gradients with respect to the input of `zero_out`.\n  \"\"\"\n  to_zero = op.inputs[0]\n  shape = array_ops.shape(to_zero)\n  index = array_ops.zeros_like(shape)\n  first_grad = array_ops.reshape(grad, [-1])[0]\n  to_zero_grad = sparse_ops.sparse_to_dense([index], shape, first_grad, 0)\n  return [to_zero_grad]  # List of one Tensor, since we have one input\n```\n\n----------------------------------------\n\nTITLE: Creating Object-Oriented Style Compat Model in TensorFlow 2\nDESCRIPTION: This code shows how to create a model using a mix of TensorFlow 1.x compatible layers and object-oriented style within a TensorFlow 2 Keras layer. It assigns compat.v1.layer objects as properties of the Keras layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nclass OOStyleCompatModel(tf.keras.layers.Layer):\n\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.conv_1 = tf.compat.v1.layers.Conv2D(\n          3, 3,\n          kernel_regularizer=\"l2\")\n    self.conv_2 = tf.compat.v1.layers.Conv2D(\n          4, 4,\n          kernel_regularizer=\"l2\")\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = self.conv_1(inputs)\n      out = self.conv_2(out)\n      out = tf.compat.v1.layers.conv2d(\n          out, 5, 5,\n          kernel_regularizer=\"l2\")\n      return out\n\nlayer = OOStyleCompatModel()\nlayer(tf.ones(shape=(10, 10, 10, 10)))\n[v.name for v in layer.weights]\n```\n\n----------------------------------------\n\nTITLE: Predicting and Calculating Loss and Accuracy in TensorFlow/Keras\nDESCRIPTION: This code defines a `predict` function that takes a model, input data, and labels as input. It preprocesses the input data, performs a forward pass through the model, calculates the categorical cross-entropy loss, and calculates the categorical accuracy. The function returns the loss and accuracy as TensorFlow tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef predict(m, x, y):\n  x = tf.to_float(x) / 255.0\n  y = tf.one_hot(tf.squeeze(y), 10)\n  y_p = m(tf.reshape(x, (-1, 28 * 28)))\n  losses = tf.keras.losses.categorical_crossentropy(y, y_p)\n  l = tf.reduce_mean(losses)\n  accuracies = tf.keras.metrics.categorical_accuracy(y, y_p)\n  accuracy = tf.reduce_mean(accuracies)\n  return l, accuracy\n```\n\n----------------------------------------\n\nTITLE: Collecting Metadata with TensorFlow Session Options\nDESCRIPTION: This example shows how to collect execution metadata using TensorFlow session options and run metadata. The snippet runs a matrix multiplication operation and collects trace information, including execution graphs and step statistics. It requires TensorFlow and demonstrates advanced session options for performance analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graphs.md#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\ny = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))\n\nwith tf.Session() as sess:\n  # Define options for the `sess.run()` call.\n  options = tf.RunOptions()\n  options.output_partition_graphs = True\n  options.trace_level = tf.RunOptions.FULL_TRACE\n\n  # Define a container for the returned metadata.\n  metadata = tf.RunMetadata()\n\n  sess.run(y, options=options, run_metadata=metadata)\n\n  # Print the subgraphs that executed on each device.\n  print(metadata.partition_graphs)\n\n  # Print the timings of each operation that executed.\n  print(metadata.step_stats)\n```\n\n----------------------------------------\n\nTITLE: Creating MNIST Model and Dataset Setup File\nDESCRIPTION: Creating a Python file with functions to prepare the MNIST dataset and define a CNN model using Keras. This file will be imported by the worker processes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n%%writefile mnist_setup.py\n\nimport os\nimport tensorflow as tf\nimport numpy as np\n\ndef mnist_dataset(batch_size):\n  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n  # The `x` arrays are in uint8 and have values in the [0, 255] range.\n  # You need to convert them to float32 with values in the [0, 1] range.\n  x_train = x_train / np.float32(255)\n  y_train = y_train.astype(np.int64)\n  train_dataset = tf.data.Dataset.from_tensor_slices(\n      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n  return train_dataset\n\ndef build_and_compile_cnn_model():\n  model = tf.keras.Sequential([\n      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(128, activation='relu'),\n      tf.keras.layers.Dense(10)\n  ])\n  model.compile(\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n      metrics=['accuracy'])\n  return model\n```\n\n----------------------------------------\n\nTITLE: Creating CNN Model with Keras\nDESCRIPTION: Defines a simple convolutional neural network model using Keras Sequential API for MNIST image classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef create_model(input_shape):\n  \"\"\"Creates a simple convolutional neural network model using the Keras API\"\"\"\n  return tf.keras.Sequential([\n      tf.keras.layers.Conv2D(28, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n  ])\n```\n\n----------------------------------------\n\nTITLE: Implementing Truncated Backpropagation for RNN\nDESCRIPTION: This snippet illustrates how to implement truncated backpropagation for LSTMs in a recurrent neural network setting. It establishes a placeholder for word inputs and uses a loop to process word batches over a specific number of time steps, maintaining the LSTM state across iterations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Placeholder for the inputs in a given iteration.\nwords = tf.placeholder(tf.int32, [batch_size, num_steps])\n\nlstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n# Initial state of the LSTM memory.\ninitial_state = state = lstm.zero_state(batch_size, dtype=tf.float32)\n\nfor i in range(num_steps):\n    # The value of state is updated after processing each batch of words.\n    output, state = lstm(words[:, i], state)\n\n    # The rest of the code.\n    # ...\n\nfinal_state = state\n```\n\n----------------------------------------\n\nTITLE: Loading ESRGAN Model for Performance Evaluation\nDESCRIPTION: Loads the ESRGAN model from TensorFlow Hub for performance testing on the low-resolution image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmodel = hub.load(SAVED_MODEL_PATH)\n```\n\n----------------------------------------\n\nTITLE: Visualizing CIFAR10 Training Data\nDESCRIPTION: Plot first 25 training images with their class labels using matplotlib\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i])\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow Transform with Distributed Training\nDESCRIPTION: Example demonstrating how to integrate TensorFlow Transform outputs into a distributed training workflow. The transform layer is loaded from a working directory containing the output of a previous TensorFlow Transform analysis phase.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  # working_dir contains the tf.Transform output.\n  tf_transform_output = tft.TFTransformOutput(working_dir)\n  # Loading from working_dir to create a Keras layer for applying the tf.Transform output to data\n  tft_layer = tf_transform_output.transform_features_layer()\n  ...\n\ndef dataset_fn(input_context):\n  ...\n  dataset.map(tft_layer, num_parallel_calls=tf.data.AUTOTUNE)\n  ...\n  return dataset\n\ndistributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Importing necessary Python libraries for image processing, visualization, and machine learning tasks\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom absl import logging\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image, ImageOps\nfrom scipy.spatial import cKDTree\nfrom skimage.feature import plot_matches\nfrom skimage.measure import ransac\nfrom skimage.transform import AffineTransform\nfrom six import BytesIO\n\nimport tensorflow as tf\n\nimport tensorflow_hub as hub\nfrom six.moves.urllib.request import urlopen\n```\n\n----------------------------------------\n\nTITLE: Slicing First Two Values in Each Row\nDESCRIPTION: Shows how to slice a ragged tensor to get the first two values from each row.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[:, :2])   # First two values in each row.\n```\n\n----------------------------------------\n\nTITLE: Downloading Quick Draw Dataset (Shell)\nDESCRIPTION: Commands to create a directory and download the entire Quick Draw dataset from Google Cloud Storage using gsutil. This will download approximately 23GB of data in ndjson format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmkdir rnn_tutorial_data\ncd rnn_tutorial_data\ngsutil -m cp \"gs://quickdraw_dataset/full/simplified/*\" .\n```\n\n----------------------------------------\n\nTITLE: Initializing Word Embeddings for Skip-gram Model in Python\nDESCRIPTION: Creates a TensorFlow Variable to store embeddings for each word in the vocabulary, initialized with random uniform values in the range [-1.0, 1.0].\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nembeddings = tf.Variable(\n    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n```\n\n----------------------------------------\n\nTITLE: Iterating Through Dataset Elements Using a For Loop\nDESCRIPTION: Shows how to iterate through elements of a dataset using a basic Python for loop, printing each element after converting it to a NumPy array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor elem in dataset:\n  print(elem.numpy())\n```\n\n----------------------------------------\n\nTITLE: Implementing Convergence Test Function\nDESCRIPTION: Defines a function to test the convergence of an optimizer with a single variable loss function. It tracks the parameter path and checks for convergence or gradient explosion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndef convergence_test(optimizer, loss_fn, grad_fn=grad, init_val=2., max_iters=2000):\n  # Function for optimizer convergence test\n  print(optimizer.title)\n  print(\"-------------------------------\")\n  # Initializing variables and structures\n  x_star = tf.Variable(init_val)\n  param_path = []\n  converged = False\n\n  for iter in range(1, max_iters + 1):\n    x_grad = grad_fn(loss_fn, x_star)\n\n    # Case for exploding gradient\n    if tf.math.is_nan(x_grad):\n      print(f\"Gradient exploded at iteration {iter}\\n\")\n      return []\n\n    # Updating the variable and storing its old-version\n    x_old = x_star.numpy()\n    optimizer.apply_gradients([x_grad], [x_star])\n    param_path.append(x_star.numpy())\n\n    # Checking for convergence\n    if x_star == x_old:\n      print(f\"Converged in {iter} iterations\\n\")\n      converged = True\n      break\n      \n  # Print early termination message\n  if not converged:\n    print(f\"Exceeded maximum of {max_iters} iterations. Test terminated.\\n\")\n  return param_path\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Setup and Import\nDESCRIPTION: Importing required TensorFlow libraries and utilities for graph operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport timeit\nfrom datetime import datetime\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Custom Models with Ragged Tensors in Python\nDESCRIPTION: This example shows how to save and load a custom model that works with ragged tensors. It defines a CustomModule class, builds concrete functions, saves the model, and then loads it back.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nclass CustomModule(tf.Module):\n  def __init__(self, variable_value):\n    super(CustomModule, self).__init__()\n    self.v = tf.Variable(variable_value)\n\n  @tf.function\n  def grow(self, x):\n    return x * self.v\n\nmodule = CustomModule(100.0)\n\n# Before saving a custom model, you must ensure that concrete functions are\n# built for each input signature that you will need.\nmodule.grow.get_concrete_function(tf.RaggedTensorSpec(shape=[None, None],\n                                                      dtype=tf.float32))\n\ncustom_module_path = tempfile.mkdtemp()\ntf.saved_model.save(module, custom_module_path)\nimported_model = tf.saved_model.load(custom_module_path)\nimported_model.grow(tf.ragged.constant([[1.0, 4.0, 3.0], [2.0]]))\n```\n\n----------------------------------------\n\nTITLE: Testing Embedding Extraction in Python\nDESCRIPTION: Demonstrates the use of the extract_embeddings function with a sample query.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nextract_embeddings(\"Hello Machine Learning!\")[:10]\n```\n\n----------------------------------------\n\nTITLE: Setting CycleGAN Dataset Parameters\nDESCRIPTION: Defines constants for dataset processing including buffer size for shuffling, batch size, and image dimensions for the CycleGAN training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = 1000\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel with TensorFlow Debugger\nDESCRIPTION: Example showing how to enable TensorFlow debugger while running SavedModel CLI.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \\\n--signature_def serving_default --inputs x=/tmp/data.npz[x] --tf_debug\n```\n\n----------------------------------------\n\nTITLE: Loading and Exploring the ESC-50 Dataset\nDESCRIPTION: Loads the ESC-50 dataset metadata into a pandas DataFrame for exploration and analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nesc50_csv = './datasets/ESC-50-master/meta/esc50.csv'\nbase_data_path = './datasets/ESC-50-master/audio/'\n\npd_data = pd.read_csv(esc50_csv)\npd_data.head()\n```\n\n----------------------------------------\n\nTITLE: TF_CONFIG Setup for Evaluator in TensorFlow\nDESCRIPTION: Example of setting up TF_CONFIG environment variable for an evaluator node in a distributed training setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"TF_CONFIG\"] = json.dumps({\n    \"cluster\": {\n        \"evaluator\": [\"host7:port\"]\n    },\n    \"task\": {\"type\": \"evaluator\", \"index\": 0}\n})\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow 1.x in Compatibility Mode\nDESCRIPTION: Imports TensorFlow 1.x using the compat.v1 module, which allows the code to run in TensorFlow 2.x environment with backward compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Tensor Leaks in TensorFlow Functions\nDESCRIPTION: This snippet shows how tensors can leak from a tf.function when accessed through global variables, even if they are returned. It illustrates the correct way to access function outputs and the errors that occur with leaked tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nx = None\n\n@tf.function\ndef leaky_function(a):\n  global x\n  x = a + 1  # Bad - leaks local tensor\n  return a + 2\n\ncorrect_a = leaky_function(tf.constant(1))\n\nprint(correct_a.numpy())  # Good - value obtained from function's returns\ntry:\n  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\nexcept AttributeError as expected:\n  print(expected)\n```\n\n----------------------------------------\n\nTITLE: Making predictions with the model\nDESCRIPTION: This snippet demonstrates how to use the created model to make predictions on a batch of features. It passes the features through the model and then prints the first five predictions. This step is performed before training, so the predictions are not expected to be accurate.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\npredictions = model(features)\npredictions[:5]\n```\n\n----------------------------------------\n\nTITLE: Processing Titanic Dataset in TensorFlow\nDESCRIPTION: This snippet demonstrates how to iterate over the Titanic dataset and print the first few lines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nfor line in titanic_lines.take(10):\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: Configuring Image Sources\nDESCRIPTION: Setting up image URL pairs for different landmarks to be compared using DELF\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#@title Choose images\nimages = \"Bridge of Sighs\" #@param [\"Bridge of Sighs\", \"Golden Gate\", \"Acropolis\", \"Eiffel tower\"]\nif images == \"Bridge of Sighs\":\n  IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/2/28/Bridge_of_Sighs%2C_Oxford.jpg'\n  IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/c/c3/The_Bridge_of_Sighs_and_Sheldonian_Theatre%2C_Oxford.jpg'\nelif images == \"Golden Gate\":\n  IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/1/1e/Golden_gate2.jpg'\n  IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/3/3e/GoldenGateBridge.jpg'\nelif images == \"Acropolis\":\n  IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/c/ce/2006_01_21_Ath%C3%A8nes_Parth%C3%A9non.JPG'\n  IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/5/5c/ACROPOLIS_1969_-_panoramio_-_jean_melis.jpg'\nelse:\n  IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/d/d8/Eiffel_Tower%2C_November_15%2C_2011.jpg'\n  IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/a/a8/Eiffel_Tower_from_immediately_beside_it%2C_Paris_May_2008.jpg'\n```\n\n----------------------------------------\n\nTITLE: Handling TypeError in MaskedTensor Constructor in Python\nDESCRIPTION: Shows how to handle a TypeError exception that occurs when a field value cannot be converted to its declared type in a MaskedTensor constructor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  MaskedTensor([1, 2, 3], None)\nexcept TypeError as e:\n  print(f\"Got expected TypeError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image for ESRGAN Enhancement\nDESCRIPTION: Downloads a sample image using wget to be used for demonstrating super resolution enhancement with ESRGAN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!wget \"https://user-images.githubusercontent.com/12981474/40157448-eff91f06-5953-11e8-9a37-f6b5693fa03f.png\" -O original.png\n```\n\n----------------------------------------\n\nTITLE: Bucketization of Continuous Column\nDESCRIPTION: This code demonstrates how to perform bucketization on a continuous feature, turning it into a categorical feature. `bucketized_column` is used to divide the range of 'age' into buckets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nage_buckets = tf.feature_column.bucketized_column(\n    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n```\n\n----------------------------------------\n\nTITLE: Plotting Confusion Matrix for MoViNet Model in TensorFlow\nDESCRIPTION: This function creates and plots a confusion matrix using seaborn and matplotlib. It takes actual and predicted labels, label names, and dataset type as inputs to generate a heatmap visualization of the confusion matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef plot_confusion_matrix(actual, predicted, labels, ds_type):\n  cm = tf.math.confusion_matrix(actual, predicted)\n  ax = sns.heatmap(cm, annot=True, fmt='g')\n  sns.set(rc={'figure.figsize':(12, 12)})\n  sns.set(font_scale=1.4)\n  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n  ax.set_xlabel('Predicted Action')\n  ax.set_ylabel('Actual Action')\n  plt.xticks(rotation=90)\n  plt.yticks(rotation=0)\n  ax.xaxis.set_ticklabels(labels)\n  ax.yaxis.set_ticklabels(labels)\n```\n\n----------------------------------------\n\nTITLE: Getting Number of Classes from TFDS Metadata\nDESCRIPTION: Extracts the number of classes from the dataset metadata. This information is useful for configuring the model's output layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nnum_classes = metadata.features['label'].num_classes\nprint(num_classes)\n```\n\n----------------------------------------\n\nTITLE: Creating a 2-Dimensional DTensor Mesh\nDESCRIPTION: This snippet creates a 2-dimensional mesh with 6 CPU devices in a 3x2 configuration, with 'x' and 'y' mesh dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmesh_2d = dtensor.create_mesh([('x', 3), ('y', 2)], devices=DEVICES)\nprint(mesh_2d)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Required Libraries in Python\nDESCRIPTION: This snippet imports TensorFlow, Keras layers and regularizers, and sets up the necessary libraries for the tutorial. It also prints the TensorFlow version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Type Promotion in 'all' Mode\nDESCRIPTION: Example showing that mixing int32 and float32 types is allowed in 'all' mode, resulting in a float32 output which could potentially lose precision.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# i32 + f32 returns a f32 result in ALL mode.\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\na = tf.constant(10, dtype = tf.int32)\nb = tf.constant(5.0, dtype = tf.float32)\na + b  # <tf.Tensor: shape=(), dtype=float32, numpy=15.0>\n```\n\n----------------------------------------\n\nTITLE: Parallelizing Data Transformation in TensorFlow Input Pipeline\nDESCRIPTION: This snippet demonstrates how to parallelize data transformation in a TensorFlow input pipeline using the num_parallel_calls argument in the map transformation. This optimization can significantly speed up data preprocessing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/datasets.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndataset = dataset.map(map_func=parse_fn, num_parallel_calls=FLAGS.num_parallel_calls)\n```\n\n----------------------------------------\n\nTITLE: Displaying SSE Instructions Compilation Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message indicating that the TensorFlow library wasn't compiled with SSE (Streaming SIMD Extensions) instructions enabled.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_17\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>The TensorFlow library wasn't compiled to use SSE instructions</pre>\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Video Processing\nDESCRIPTION: Imports all necessary Python libraries for the tutorial, including utilities for file handling, video processing with OpenCV, data visualization, and TensorFlow for machine learning operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tqdm\nimport random\nimport pathlib\nimport itertools\nimport collections\n\nimport os\nimport cv2\nimport numpy as np\nimport remotezip as rz\n\nimport tensorflow as tf\n\n# Some modules to display an animation using imageio.\nimport imageio\nfrom IPython import display\nfrom urllib import request\nfrom tensorflow_docs.vis import embed\n```\n\n----------------------------------------\n\nTITLE: Setting up MNIST Data Pipeline using tf.data in TensorFlow\nDESCRIPTION: This code defines a `setup_mnist_data` function that creates a `tf.data.Dataset` for either training or testing data. For training data, the dataset is shuffled and repeated indefinitely. For testing, the dataset is repeated. The dataset is then batched according to the specified `batch_size`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef setup_mnist_data(is_training, batch_size):\n  if is_training:\n    ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n    ds = ds.shuffle(batch_size * 10)\n  else:\n    ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n\n  ds = ds.repeat()\n  ds = ds.batch(batch_size)\n  return ds\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradient Function for ZeroOut Op in Python\nDESCRIPTION: This snippet demonstrates how to implement and register a gradient function for a custom 'ZeroOut' operation in TensorFlow using Python. It computes the gradient with respect to the input given the gradient with respect to the output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import sparse_ops\n\n@ops.RegisterGradient(\"ZeroOut\")\ndef _zero_out_grad(op, grad):\n  \"\"\"The gradients for `zero_out`.\n\n  Args:\n    op: The `zero_out` `Operation` that we are differentiating, which we can use\n      to find the inputs and outputs of the original op.\n    grad: Gradient with respect to the output of the `zero_out` op.\n\n  Returns:\n    Gradients with respect to the input of `zero_out`.\n  \"\"\"\n  to_zero = op.inputs[0]\n  shape = array_ops.shape(to_zero)\n  index = array_ops.zeros_like(shape)\n  first_grad = array_ops.reshape(grad, [-1])[0]\n  to_zero_grad = sparse_ops.sparse_to_dense([index], shape, first_grad, 0)\n  return [to_zero_grad]  # List of one Tensor, since we have one input\n```\n\n----------------------------------------\n\nTITLE: Plotting Multiple Images and Predictions\nDESCRIPTION: This snippet plots the first few test images along with their predictions using the previously defined `plot_image` and `plot_value_array` functions. It displays the images in a grid layout, with correct predictions in blue and incorrect predictions in red.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], test_labels)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Training the Model (Python)\nDESCRIPTION: This snippet is intended for training the model for 1000 epochs and tracking the training history, which includes performance metrics over time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(normed_train_data, train_labels, epochs=1000)\n\n```\n\n----------------------------------------\n\nTITLE: Integrating AutoGraph with Keras using Lambda Layers\nDESCRIPTION: Demonstrates how to use AutoGraph-converted functions in Keras models by wrapping them in Lambda layers. This example implements the Collatz conjecture as a model layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n@tf.function(\n    experimental_autograph_options=(\n        tf.autograph.experimental.Feature.ASSERT_STATEMENTS,\n        tf.autograph.experimental.Feature.EQUALITY_OPERATORS,\n        ))\ndef collatz(x):\n  x = tf.reshape(x,())\n  assert x > 0\n  n = tf.convert_to_tensor((0,))\n  while x != 1:\n    n += 1\n    if x % 2 == 0:\n      x = x // 2\n    else:\n      x = 3 * x + 1\n\n  return n\n\nwith tf.Graph().as_default():\n  model = tf.keras.Sequential([\n    tf.keras.layers.Lambda(collatz, input_shape=(1,), output_shape=())\n  ])\n\n  result = model.predict(np.array([6171]))\n  print(result)\n```\n\n----------------------------------------\n\nTITLE: Testing the Data Slicing Function\nDESCRIPTION: Demonstrates how the slicing function works by printing the first example with all its features and values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfor example in slices(titanic_features_dict):\n  for name, value in example.items():\n    print(f\"{name:19s}: {value}\")\n  break\n```\n\n----------------------------------------\n\nTITLE: Nested TensorFlow Function with Decorator\nDESCRIPTION: Shows how tf.function affects nested function calls and demonstrates the decorator syntax for graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef inner_function(x, y, b):\n  x = tf.matmul(x, y)\n  x = x + b\n  return x\n\n# Using the `tf.function` decorator makes `outer_function` into a\n# `PolymorphicFunction`.\n@tf.function\ndef outer_function(x):\n  y = tf.constant([[2.0], [3.0]])\n  b = tf.constant(4.0)\n\n  return inner_function(x, y, b)\n\n# Note that the callable will create a graph that\n# includes `inner_function` as well as `outer_function`.\nouter_function(tf.constant([[1.0, 2.0]])).numpy()\n```\n\n----------------------------------------\n\nTITLE: Using Common Shape Function for ZeroOut Op in C++\nDESCRIPTION: This snippet demonstrates how to use a common shape function (UnchangedShape) for the 'ZeroOut' operation in C++. It applies the same shape as the input to the output without custom logic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_50\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\")\n    .SetShapeFn(::tensorflow::shape_inference::UnchangedShape);\n```\n\n----------------------------------------\n\nTITLE: Inspecting DTensor Layout Information\nDESCRIPTION: Prints the layout information for a model weight to verify that the layouts were correctly applied.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfor weight in model.weights:\n  print(f'Weight name: {weight.name} with layout: {weight.layout}')\n  break\n```\n\n----------------------------------------\n\nTITLE: Displaying Base Model Architecture Summary\nDESCRIPTION: Shows the architecture details of the base model including layer types, output shapes, and parameter counts to better understand the model structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Let's take a look at the base model architecture\nbase_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Performing Hyperparameter Search\nDESCRIPTION: Executes the hyperparameter search using the defined tuner and prints the optimal hyperparameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(f\"\"\"\nThe hyperparameter search is complete. The optimal number of units in the first densely-connected\nlayer is {best_hps.get('units')} and the optimal learning rate for the optimizer\nis {best_hps.get('learning_rate')}.\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset for Training in Python\nDESCRIPTION: Prepares the dataset for efficient training by applying shuffling, batching, caching, and prefetching operations to optimize performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 64\nbuffer_size = n_notes - seq_length  # the number of items in the dataset\ntrain_ds = (seq_ds\n            .shuffle(buffer_size)\n            .batch(batch_size, drop_remainder=True)\n            .cache()\n            .prefetch(tf.data.experimental.AUTOTUNE))\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Image Data in Python\nDESCRIPTION: This code preprocesses the image data by scaling the pixel values from 0-255 to 0-1. This normalization is applied to both training and test sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_images = train_images / 255.0\n\ntest_images = test_images / 255.0\n```\n\n----------------------------------------\n\nTITLE: Broadcasting error with mismatched ragged dimensions in TensorFlow\nDESCRIPTION: Shows an error when attempting to broadcast two 2D ragged tensors with different ragged dimension patterns. For ragged tensors to broadcast together, their ragged dimensions must match.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# x      (2d ragged): 3 x (r1)\n# y      (2d ragged): 3 x (r2)  # ragged dimensions do not match.\nx = tf.ragged.constant([[1, 2, 3], [4], [5, 6]])\ny = tf.ragged.constant([[10, 20], [30, 40], [50]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow with Required Version\nDESCRIPTION: A command to install or upgrade TensorFlow to version 2.10.0 or higher, which is required for using the TimeDistributed layer as demonstrated in this tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -U \"tensorflow>=2.10.0\"\n```\n\n----------------------------------------\n\nTITLE: Computing WER Metric in Python\nDESCRIPTION: This code computes the final Word Error Rate metric after processing all validation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nmetric.compute()\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Trained TensorFlow Classifier for Iris Species in Python\nDESCRIPTION: This snippet shows how to use the trained classifier to make predictions on new, unlabeled data. It defines an input function for prediction and uses the classifier's predict method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Generate predictions from the model\nexpected = ['Setosa', 'Versicolor', 'Virginica']\npredict_x = {\n    'SepalLength': [5.1, 5.9, 6.9],\n    'SepalWidth': [3.3, 3.0, 3.1],\n    'PetalLength': [1.7, 4.2, 5.4],\n    'PetalWidth': [0.5, 1.5, 2.1],\n}\n\ndef input_fn(features, batch_size=256):\n    \"\"\"An input function for prediction.\"\"\"\n    # Convert the inputs to a Dataset without labels.\n    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n\npredictions = classifier.predict(\n    input_fn=lambda: input_fn(predict_x))\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow with APU Plugin Device\nDESCRIPTION: Demonstrates how to use the APU plugin device with TensorFlow, including device detection, running operations on specific devices, and using tf.function with the plugin device\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/gpu_plugins.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf   # TensorFlow registers PluggableDevices here.\ntf.config.list_physical_devices()  # APU device is visible to TensorFlow.\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:APU:0', device_type='APU')]\n\na = tf.random.normal(shape=[5], dtype=tf.float32)  # Runs on CPU.\nb =  tf.nn.relu(a)         # Runs on APU.\n\nwith tf.device(\"/APU:0\"):  # Users can also use 'with tf.device' syntax.\n  c = tf.nn.relu(a)        # Runs on APU.\n\nwith tf.device(\"/CPU:0\"):\n  c = tf.nn.relu(a)        # Runs on CPU.\n\n@tf.function  # Defining a tf.function\ndef run():\n  d = tf.random.uniform(shape=[100], dtype=tf.float32)  # Runs on CPU.\n  e = tf.nn.relu(d)        # Runs on APU.\n\nrun()  # PluggableDevices also work with tf.function and graph mode.\n```\n\n----------------------------------------\n\nTITLE: Preparing MNIST Dataset for TPU Training with tf.data\nDESCRIPTION: Creates an optimized input pipeline for the MNIST dataset using TensorFlow Datasets. The function handles normalization, shuffling, batching, and creates an infinite dataset for training to avoid partial batches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef get_dataset(batch_size, is_training=True):\n  split = 'train' if is_training else 'test'\n  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n                            as_supervised=True, try_gcs=True)\n\n  # Normalize the input data.\n  def scale(image, label):\n    image = tf.cast(image, tf.float32)\n    image /= 255.0\n    return image, label\n\n  dataset = dataset.map(scale)\n\n  # Only shuffle and repeat the dataset in training. The advantage of having an\n  # infinite dataset for training is to avoid the potential last partial batch\n  # in each epoch, so that you don't need to think about scaling the gradients\n  # based on the actual batch size.\n  if is_training:\n    dataset = dataset.shuffle(10000)\n    dataset = dataset.repeat()\n\n  dataset = dataset.batch(batch_size)\n\n  return dataset\n```\n\n----------------------------------------\n\nTITLE: Training and evaluating with tf.estimator.Estimator in TensorFlow 1\nDESCRIPTION: Demonstrates how to instantiate an Estimator, train the model, and evaluate it using the Estimator API in TensorFlow 1.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\nestimator.train(_input_fn)\n\nestimator.evaluate(_eval_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Distributed Evaluation with TensorFlow\nDESCRIPTION: Implementation of distributed evaluation for large models where tasks are distributed to workers using ClusterCoordinator methods.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  # Define the eval metric on parameter servers.\n  eval_accuracy = tf.keras.metrics.Accuracy()\n\n@tf.function\ndef eval_step(iterator):\n  def replica_fn(batch_data, labels):\n    pred = model(batch_data, training=False)\n    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n    eval_accuracy.update_state(labels, actual_pred)\n  batch_data, labels = next(iterator)\n  strategy.run(replica_fn, args=(batch_data, labels))\n\ndef eval_dataset_fn():\n  return tf.data.Dataset.from_tensor_slices(\n      feature_and_label_gen(num_examples=16)).map(\n          lambda x: (\n              {\"features\": feature_preprocess_stage(x[\"features\"])},\n              label_preprocess_stage(x[\"label\"])\n          )).shuffle(16).repeat().batch(8)\n\nper_worker_eval_dataset = coordinator.create_per_worker_dataset(eval_dataset_fn)\nper_worker_eval_iterator = iter(per_worker_eval_dataset)\n\neval_steps_per_epoch = 2\nfor _ in range(eval_steps_per_epoch):\n  coordinator.schedule(eval_step, args=(per_worker_eval_iterator,))\ncoordinator.join()\nprint(\"Evaluation accuracy: %f\" % eval_accuracy.result())\n```\n\n----------------------------------------\n\nTITLE: Loading and Evaluating Restored HDF5 Model\nDESCRIPTION: Demonstrate model restoration and performance evaluation after saving to HDF5 format, verifying model preservation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nloss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n```\n\n----------------------------------------\n\nTITLE: Resuming Training from Step-Based Checkpoint in TensorFlow 2\nDESCRIPTION: Recreating the Keras model and continuing training from the last checkpoint saved at step frequency (every 30 steps), demonstrating fine-grained recovery in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss=loss,\n              metrics=['accuracy'],\n              steps_per_execution=10)\nmodel.fit(x=x_train,\n            y=y_train,\n            epochs=10,\n            steps_per_epoch=100,\n            validation_data=(x_test, y_test),\n            callbacks=[backup_restore_callback])\n```\n\n----------------------------------------\n\nTITLE: Padding a RaggedTensor\nDESCRIPTION: This code converts a ragged Tensor into a dense Tensor with padding and prints the output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nbatch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\nprint(batch_chars_padded.numpy())\n```\n\n----------------------------------------\n\nTITLE: Alternative row-partitioning schemes for RaggedTensor in TensorFlow\nDESCRIPTION: Demonstrates five equivalent ways to create the same RaggedTensor using different row-partitioning schemes: row_splits, row_lengths, row_starts, row_limits, and value_rowids with nrows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nvalues = [3, 1, 4, 1, 5, 9, 2, 6]\nprint(tf.RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8]))\nprint(tf.RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0]))\nprint(tf.RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8]))\nprint(tf.RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8]))\nprint(tf.RaggedTensor.from_value_rowids(\n    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5))\n```\n\n----------------------------------------\n\nTITLE: Defining feature columns for TensorFlow Estimators in Python\nDESCRIPTION: Example of creating three numeric feature columns for use with TensorFlow Estimators, including a column with a normalization function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Define three numeric feature columns.\npopulation = tf.feature_column.numeric_column('population')\ncrime_rate = tf.feature_column.numeric_column('crime_rate')\nmedian_education = tf.feature_column.numeric_column('median_education',\n                    normalizer_fn=lambda x: x - global_education_mean)\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset from NumPy Arrays\nDESCRIPTION: Shows two approaches to create TensorFlow Datasets from NumPy arrays - using constants and using placeholders with feed_dict.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith np.load(\"/var/data/training_data.npy\") as data:\n  features = data[\"features\"]\n  labels = data[\"labels\"]\n\nassert features.shape[0] == labels.shape[0]\n\nfeatures_placeholder = tf.placeholder(features.dtype, features.shape)\nlabels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n\ndataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\niterator = dataset.make_initializable_iterator()\n\nsess.run(iterator.initializer, feed_dict={features_placeholder: features,\n                                          labels_placeholder: labels})\n```\n\n----------------------------------------\n\nTITLE: Calculating AllReduce Communication Time in TensorFlow\nDESCRIPTION: This snippet demonstrates how to estimate the time required for gradient AllReduce operation in distributed TensorFlow training. It calculates the communication time based on the number of model parameters and communication bandwidth.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu_performance_analysis.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n(number of parameters * 4bytes)/ (communication bandwidth)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Transform for Data Processing\nDESCRIPTION: Installs TensorFlow Transform (TFT), a library for preprocessing data with TensorFlow, and imports the necessary modules.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# TFT needs to be installed afterwards\n!pip install -q tensorflow_transform==0.24\nimport tensorflow_transform as tft\nimport tensorflow_transform.beam as tft_beam\n```\n\n----------------------------------------\n\nTITLE: Creating a Sparse Tensor in TensorFlow\nDESCRIPTION: This code demonstrates how to create a tf.sparse.SparseTensor by specifying its indices, values, and dense shape. The resulting sparse tensor represents a 3x10 matrix with two non-zero values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nst1 = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n                      values=[10, 20],\n                      dense_shape=[3, 10])\n```\n\n----------------------------------------\n\nTITLE: Adding Rests to Pitch Outputs in Python\nDESCRIPTION: This code adds zeros to the pitch outputs to indicate when there's no singing (rests). It uses a confidence threshold of 0.9 to determine valid pitch values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npitch_outputs_and_rests = [\n    output2hz(p) if c >= 0.9 else 0\n    for i, p, c in zip(indices, pitch_outputs, confidence_outputs)\n]\n```\n\n----------------------------------------\n\nTITLE: Model Loading and Inference\nDESCRIPTION: Loads the selected Boundless model from TensorFlow Hub and performs inference on the input image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nresult = model.signatures['default'](tf.constant(input_img))\ngenerated_image =  result['default']\nmasked_image = result['masked_image']\n\nvisualize_output_comparison(input_img, masked_image, generated_image)\n```\n\n----------------------------------------\n\nTITLE: Accessing Dimension Value in TF2 Style\nDESCRIPTION: Demonstrates the simplified TensorFlow 2.0 approach to accessing a dimension value, where dimensions are represented as integers directly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nvalue = shape[i]\nvalue\n```\n\n----------------------------------------\n\nTITLE: DeepDream Loss Calculation\nDESCRIPTION: Function to calculate the activation loss across selected layers of the neural network for DeepDream generation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef calc_loss(img, model):\n  img_batch = tf.expand_dims(img, axis=0)\n  layer_activations = model(img_batch)\n  if len(layer_activations) == 1:\n    layer_activations = [layer_activations]\n\n  losses = []\n  for act in layer_activations:\n    loss = tf.math.reduce_mean(act)\n    losses.append(loss)\n\n  return  tf.reduce_sum(losses)\n```\n\n----------------------------------------\n\nTITLE: Utility Function for Loading and Preprocessing Images\nDESCRIPTION: Defines a function to load images from a URL or local file, decode them, and normalize pixel values to the range [0, 1].\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n_UINT8_MAX_F = float(np.iinfo(np.uint8).max)\n\ndef load_image(img_url: str):\n  \"\"\"Returns an image with shape [height, width, num_channels], with pixels in [0..1] range, and type np.float32.\"\"\"\n\n  if (img_url.startswith(\"https\")):\n    user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n    response = requests.get(img_url, headers=user_agent)\n    image_data = response.content\n  else:\n    image_data = tf.io.read_file(img_url)\n\n  image = tf.io.decode_image(image_data, channels=3)\n  image_numpy = tf.cast(image, dtype=tf.float32).numpy()\n  return image_numpy / _UINT8_MAX_F\n```\n\n----------------------------------------\n\nTITLE: Formatting Prediction Results\nDESCRIPTION: Code to format and print the prediction results, showing predicted class and probability for each example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntemplate = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n\nfor pred_dict, expec in zip(predictions, expected):\n    class_id = pred_dict['class_ids'][0]\n    probability = pred_dict['probabilities'][class_id]\n\n    print(template.format(iris_data.SPECIES[class_id],\n                          100 * probability, expec))\n```\n\n----------------------------------------\n\nTITLE: Verifying NVIDIA Docker Installation\nDESCRIPTION: Command to verify the NVIDIA Docker installation by running nvidia-smi in a container.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/docker.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --gpus all --rm nvidia/cuda nvidia-smi\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: A Python code snippet defining the Apache License 2.0 terms under which the tutorial content is licensed. This appears at the beginning of the document as a standard license declaration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Trained TensorFlow Model in Python\nDESCRIPTION: This code snippet demonstrates how to use the trained model to classify a new image. It loads an image, preprocesses it, and uses the model to make a prediction, displaying the result with confidence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\nsunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n\nimg = tf.keras.utils.load_img(\n    sunflower_path, target_size=(img_height, img_width)\n)\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow 1 Checkpoint to TensorFlow 2\nDESCRIPTION: This function converts a TensorFlow 1 checkpoint to TensorFlow 2 format. It reads the variables from the TF1 checkpoint using tf.train.load_checkpoint, creates TF2 variables with the same values, and saves them in a new checkpoint with the TF2 format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef convert_tf1_to_tf2(checkpoint_path, output_prefix):\n  \"\"\"Converts a TF1 checkpoint to TF2.\n\n  To load the converted checkpoint, you must build a dictionary that maps\n  variable names to variable objects.\n  ```\n  ckpt = tf.train.Checkpoint(vars={name: variable})  \n  ckpt.restore(converted_ckpt_path)\n  ```\n\n  Args:\n    checkpoint_path: Path to the TF1 checkpoint.\n    output_prefix: Path prefix to the converted checkpoint.\n\n  Returns:\n    Path to the converted checkpoint.\n  \"\"\"\n  vars = {}\n  reader = tf.train.load_checkpoint(checkpoint_path)\n  dtypes = reader.get_variable_to_dtype_map()\n  for key in dtypes.keys():\n    vars[key] = tf.Variable(reader.get_tensor(key))\n  return tf.train.Checkpoint(vars=vars).save(output_prefix)\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset Performance Benchmark Function\nDESCRIPTION: Defines a utility function to measure dataset throughput in images per second. This benchmark primes the pipeline with one batch before starting timing to ensure fair measurement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\ndef timeit(ds, batches=2*steps_per_epoch+1):\n  overall_start = time.time()\n  # Fetch a single batch to prime the pipeline (fill the shuffle buffer),\n  # before starting the timer\n  it = iter(ds.take(batches+1))\n  next(it)\n\n  start = time.time()\n  for i,(images,labels) in enumerate(it):\n    if i%10 == 0:\n      print('.',end='')\n  print()\n  end = time.time()\n\n  duration = end-start\n  print(\"{} batches: {} s\".format(batches, duration))\n  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*batches/duration))\n  print(\"Total time: {}s\".format(end-overall_start))\n```\n\n----------------------------------------\n\nTITLE: Saving TF2 Checkpoint in TensorFlow 1.x\nDESCRIPTION: This snippet demonstrates how to save a TensorFlow 2 style checkpoint within a TensorFlow 1.x graph and session context. It creates variables, initializes them, and uses tf.train.Checkpoint to save the checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(1))\n  b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(2))\n  with tf1.variable_scope('scoped'):\n    c = tf1.get_variable('c', shape=[], dtype=tf.float32, \n                        initializer=tf1.constant_initializer(3))\n  with tf1.Session() as sess:\n    sess.run(tf1.global_variables_initializer())\n    ckpt = tf.train.Checkpoint(\n        var_list={v.name.split(':')[0]: v for v in tf1.global_variables()})\n    tf2_in_tf1_path = ckpt.save('tf2-ckpt-saved-in-session')\n    print_checkpoint(tf2_in_tf1_path)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Callbacks in TensorFlow 2\nDESCRIPTION: Creates custom Keras callbacks to replicate the functionality of LoggingTensorHook and StopAtStepHook in TensorFlow 2. These callbacks log tensors and stop training at a specific step.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/logging_stop_hook.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass StopAtStepCallback(tf.keras.callbacks.Callback):\n  def __init__(self, stop_step=None):\n    super().__init__()\n    self._stop_step = stop_step\n\n  def on_batch_end(self, batch, logs=None):\n    if self.model.optimizer.iterations >= self._stop_step:\n      self.model.stop_training = True\n      print('\\nstop training now')\n\nclass LoggingTensorCallback(tf.keras.callbacks.Callback):\n  def __init__(self, every_n_iter):\n      super().__init__()\n      self._every_n_iter = every_n_iter\n      self._log_count = every_n_iter\n\n  def on_batch_end(self, batch, logs=None):\n    if self._log_count > 0:\n      self._log_count -= 1\n      print(\"Logging Tensor Callback: dense/kernel:\",\n            model.layers[0].weights[0])\n      print(\"Logging Tensor Callback: dense/bias:\",\n            model.layers[0].weights[1])\n      print(\"Logging Tensor Callback loss:\", logs[\"loss\"])\n    else:\n      self._log_count -= self._every_n_iter\n```\n\n----------------------------------------\n\nTITLE: Custom Training Loop with Eager Execution in TensorFlow\nDESCRIPTION: This snippet demonstrates a custom training loop implemented with eager execution. It uses the Adam optimizer and computes the sparse softmax cross-entropy loss. The loop runs for 400 batches, updating the model parameters using gradients computed with tf.GradientTape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.AdamOptimizer()\n\nloss_history = []\n\nfor (batch, (images, labels)) in enumerate(dataset.take(400)):\n  if batch % 10 == 0:\n    print('.', end='')\n  with tf.GradientTape() as tape:\n    logits = mnist_model(images, training=True)\n    loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n\n  loss_history.append(loss_value.numpy())\n  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables),\n                            global_step=tf.train.get_or_create_global_step())\n```\n\n----------------------------------------\n\nTITLE: Instantiating a LinearClassifier Estimator with Feature Columns\nDESCRIPTION: Creates a LinearClassifier Estimator with specified model directory and feature columns for a binary classification task.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel_dir = tempfile.mkdtemp()\nmodel = tf.estimator.LinearClassifier(\n    model_dir=model_dir,\n    feature_columns=[embark, cls, age],\n    n_classes=2\n)\n```\n\n----------------------------------------\n\nTITLE: Plotting Time Series Windows with Inputs and Labels in Python\nDESCRIPTION: This method visualizes the split time series windows, showing inputs and labels. It can also display model predictions when provided. The method uses Matplotlib for creating the plots.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n  inputs, labels = self.example\n  plt.figure(figsize=(12, 8))\n  plot_col_index = self.column_indices[plot_col]\n  max_n = min(max_subplots, len(inputs))\n  for n in range(max_n):\n    plt.subplot(max_n, 1, n+1)\n    plt.ylabel(f'{plot_col} [normed]')\n    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n             label='Inputs', marker='.', zorder=-10)\n\n    if self.label_columns:\n      label_col_index = self.label_columns_indices.get(plot_col, None)\n    else:\n      label_col_index = plot_col_index\n\n    if label_col_index is None:\n      continue\n\n    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n    if model is not None:\n      predictions = model(inputs)\n      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                  marker='X', edgecolors='k', label='Predictions',\n                  c='#ff7f0e', s=64)\n\n    if n == 0:\n      plt.legend()\n\n  plt.xlabel('Time [h]')\n\nWindowGenerator.plot = plot\n```\n\n----------------------------------------\n\nTITLE: Extracting YAMNet Embeddings\nDESCRIPTION: Extracts embeddings from audio data using the YAMNet model and processes them for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef extract_embedding(wav_data, label, fold):\n  ''' run YAMNet to extract embedding from the wav data '''\n  scores, embeddings, spectrogram = yamnet_model(wav_data)\n  num_embeddings = tf.shape(embeddings)[0]\n  return (embeddings,\n            tf.repeat(label, num_embeddings),\n            tf.repeat(fold, num_embeddings))\n\nmain_ds = main_ds.map(extract_embedding).unbatch()\nmain_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Creating a Distributed Training Step with tf.function Decoration in TensorFlow\nDESCRIPTION: Implements a distributed training step function using tf.function for performance optimization. It runs the train_step across multiple devices/replicas and reduces the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef distributed_train_step(dist_inputs):\n  per_replica_losses = mirrored_strategy.run(train_step, args=(dist_inputs,))\n  return mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n                         axis=None)\n```\n\n----------------------------------------\n\nTITLE: Using get_next_as_optional to Handle End of Dataset Gracefully\nDESCRIPTION: This snippet demonstrates how to use get_next_as_optional() to avoid OutOfRange errors when reaching the end of a dataset. This approach is useful for host training loops where multiple steps are executed in a single function call.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# You can break the loop with `get_next_as_optional` by checking if the `Optional` contains a value\nglobal_batch_size = 4\nsteps_per_loop = 5\nstrategy = tf.distribute.MirroredStrategy()\n\ndataset = tf.data.Dataset.range(9).batch(global_batch_size)\ndistributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))\n\n@tf.function\ndef train_fn(distributed_iterator):\n  for _ in tf.range(steps_per_loop):\n    optional_data = distributed_iterator.get_next_as_optional()\n    if not optional_data.has_value():\n      break\n    per_replica_results = strategy.run(lambda x: x, args=(optional_data.get_value(),))\n    tf.print(strategy.experimental_local_results(per_replica_results))\ntrain_fn(distributed_iterator)\n```\n\n----------------------------------------\n\nTITLE: Saving a Model with Multiple Signatures\nDESCRIPTION: Shows how to save a model with multiple signatures by passing a dictionary mapping signature names to concrete functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nmodule_multiple_signatures_path = os.path.join(tmpdir, 'module_with_multiple_signatures')\nsignatures = {\"serving_default\": call,\n              \"array_input\": module.__call__.get_concrete_function(tf.TensorSpec([None], tf.float32))}\n\ntf.saved_model.save(module, module_multiple_signatures_path, signatures=signatures)\n```\n\n----------------------------------------\n\nTITLE: Loading S3D MIL-NCE Model and Defining Embedding Generation Function in Python\nDESCRIPTION: This code loads the S3D MIL-NCE model from TensorFlow Hub and defines a function to generate video and text embeddings using the model. It requires the model URL and input frames/words as prerequisites.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nhub_handle = 'https://tfhub.dev/deepmind/mil-nce/s3d/1'\nhub_model = hub.load(hub_handle)\n\ndef generate_embeddings(model, input_frames, input_words):\n  \"\"\"Generate embeddings from the model from video frames and input words.\"\"\"\n  # Input_frames must be normalized in [0, 1] and of the shape Batch x T x H x W x 3\n  vision_output = model.signatures['video'](tf.constant(tf.cast(input_frames, dtype=tf.float32)))\n  text_output = model.signatures['text'](tf.constant(input_words))\n  return vision_output['video_embedding'], text_output['text_embedding']\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Unsupported Recursive TensorFlow Functions\nDESCRIPTION: This snippet shows that recursive tf.functions are not supported and can cause infinite loops or performance issues due to multiple tracings. It provides examples of both a function that raises an exception and one that results in multiple tracings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef recursive_fn(n):\n  if n > 0:\n    return recursive_fn(n - 1)\n  else:\n    return 1\n\nwith assert_raises(Exception):\n  recursive_fn(tf.constant(5))  # Bad - maximum recursion error.\n\n@tf.function\ndef recursive_fn(n):\n  if n > 0:\n    print('tracing')\n    return recursive_fn(n - 1)\n  else:\n    return 1\n\nrecursive_fn(5)  # Warning - multiple tracings\n```\n\n----------------------------------------\n\nTITLE: Optimizing TPU Performance with steps_per_execution in Keras\nDESCRIPTION: Shows how to maximize TPU performance by using the steps_per_execution parameter in Model.compile. This parameter reduces Python overhead by batching multiple training steps together, potentially increasing throughput by about 50%.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = create_model()\n  model.compile(optimizer='adam',\n                # Anything between 2 and `steps_per_epoch` could help here.\n                steps_per_execution = 50,\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['sparse_categorical_accuracy'])\n\nmodel.fit(train_dataset,\n          epochs=5,\n          steps_per_epoch=steps_per_epoch,\n          validation_data=test_dataset,\n          validation_steps=validation_steps)\n```\n\n----------------------------------------\n\nTITLE: Text Vectorization and Mapping\nDESCRIPTION: Creating character-to-index and index-to-character mappings for text processing\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Creating a mapping from unique characters to indices\nchar2idx = {u:i for i, u in enumerate(vocab)}\nidx2char = np.array(vocab)\n\ntext_as_int = np.array([char2idx[c] for c in text])\n```\n\n----------------------------------------\n\nTITLE: Creating Two Moon Training Dataset with sklearn\nDESCRIPTION: Generates a two moon dataset using sklearn's make_moons function and adjusts the position of data points slightly based on their labels. This creates a non-linear classification problem for testing uncertainty quantification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef make_training_data(sample_size=500):\n  \"\"\"Create two moon training dataset.\"\"\"\n  train_examples, train_labels = sklearn.datasets.make_moons(\n      n_samples=2 * sample_size, noise=0.1)\n\n  # Adjust data position slightly.\n  train_examples[train_labels == 0] += [-0.1, 0.2]\n  train_examples[train_labels == 1] += [0.1, -0.2]\n\n  return train_examples, train_labels\n```\n\n----------------------------------------\n\nTITLE: Enabling JAX-like Type Promotion in TensorFlow\nDESCRIPTION: Code to enable NumPy behavior in TensorFlow with the 'all' mode for JAX-like type promotion, which allows all type conversions including potentially risky ones.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n```\n\n----------------------------------------\n\nTITLE: TensorFlow CPU Optimization Warning\nDESCRIPTION: Warning message indicating TensorFlow was not compiled with CPU optimizations\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n```\n\n----------------------------------------\n\nTITLE: Launching Second TensorFlow Worker Process\nDESCRIPTION: This code starts the second worker process which will trigger the actual training since all required workers are now available. Output is redirected to /dev/null.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\npython main.py > /dev/null 2>&1\n```\n\n----------------------------------------\n\nTITLE: Setting PATH for CUDA and cuDNN in MSYS Shell\nDESCRIPTION: Commands to add CUDA and cuDNN binary directories to the PATH environment variable for GPU support when building TensorFlow using the MSYS shell.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nexport PATH=\"/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/bin:$PATH\"\nexport PATH=\"/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/extras/CUPTI/libx64:$PATH\"\nexport PATH=\"/c/tools/cuda/bin:$PATH\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Compressed Dense Layer in TensorFlow\nDESCRIPTION: This class extends CustomDense to create a compressed version of a dense layer. It compresses the kernel and bias, and decompresses them when accessed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nclass CompressedDense(CustomDense):\n\n  def build(self, input_shape, other=None):\n    assert isinstance(other, CompressibleDense)\n    self.input_channels = other.kernel.shape[0]\n    self.kernel_compressed, self.kernel_log_step = compress_latent(\n        other.kernel_latent, other.kernel_log_step, \"kernel\")\n    self.bias_compressed, self.bias_log_step = compress_latent(\n        other.bias_latent, other.bias_log_step, \"bias\")\n    self.built = True\n\n  @property\n  def kernel(self):\n    kernel_shape = (self.input_channels, self.filters)\n    return decompress_latent(\n        self.kernel_compressed, kernel_shape, self.kernel_log_step)\n\n  @property\n  def bias(self):\n    bias_shape = (self.filters,)\n    return decompress_latent(\n        self.bias_compressed, bias_shape, self.bias_log_step)\n```\n\n----------------------------------------\n\nTITLE: Defining Audio Recording JavaScript Code\nDESCRIPTION: JavaScript code for recording audio directly in the browser with base64 encoding support.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nRECORD = \"\"\"\nconst sleep  = time => new Promise(resolve => setTimeout(resolve, time))\nconst b2text = blob => new Promise(resolve => {\n  const reader = new FileReader()\n  reader.onloadend = e => resolve(e.srcElement.result)\n  reader.readAsDataURL(blob)\n})\nvar record = time => new Promise(async resolve => {\n  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n  recorder = new MediaRecorder(stream)\n  chunks = []\n  recorder.ondataavailable = e => chunks.push(e.data)\n  recorder.start()\n  await sleep(time)\n  recorder.onstop = async ()=>{\n    blob = new Blob(chunks)\n    text = await b2text(blob)\n    resolve(text)\n  }\n  recorder.stop()\n})\n\"\"\"\n\ndef record(sec=5):\n  try:\n    from google.colab import output\n  except ImportError:\n    print('No possible to import output from google.colab')\n    return ''\n  else:\n    print('Recording')\n    display(Javascript(RECORD))\n    s = output.eval_js('record(%d)' % (sec*1000))\n    fname = 'recorded_audio.wav'\n    print('Saving to', fname)\n    b = b64decode(s.split(',')[1])\n    with open(fname, 'wb') as f:\n      f.write(b)\n    return fname\n```\n\n----------------------------------------\n\nTITLE: Selecting Test Samples for Image Generation in Python\nDESCRIPTION: Selects a batch of test samples to be used for generating output images during the training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n# Pick a sample of the test set for generating output images\nassert batch_size >= num_examples_to_generate\nfor test_batch in test_dataset.take(1):\n  test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n```\n\n----------------------------------------\n\nTITLE: Selective Saving and Restoring with tf.train.Saver in Python\nDESCRIPTION: This Python snippet demonstrates selectively saving and restoring particular model variables using tf.train.Saver. It includes creating specific variable mappings for restoration and session management. Requires TensorFlow environment setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntf.reset_default_graph()\n# Create some variables.\nv1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\nv2 = tf.get_variable(\"v2\", [5], initializer = tf.zeros_initializer)\n\n# Add ops to save and restore only `v2` using the name \"v2\"\nsaver = tf.train.Saver({\"v2\": v2})\n\n# Use the saver object normally after that.\nwith tf.Session() as sess:\n  # Initialize v1 since the saver will not.\n  v1.initializer.run()\n  saver.restore(sess, \"/tmp/model.ckpt\")\n\n  print(\"v1 : %s\" % v1.eval())\n  print(\"v2 : %s\" % v2.eval())\n```\n\n----------------------------------------\n\nTITLE: Setting up Model Training Loop\nDESCRIPTION: Creates functions to track training progress and defines a training loop that iteratively calls the train function, updating model parameters and tracking weight, bias, and loss values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel = MyModel()\n\n# Collect the history of W-values and b-values to plot later\nweights = []\nbiases = []\nepochs = range(10)\n\n# Define a training loop\ndef report(model, loss):\n  return f\"W = {model.w.numpy():1.2f}, b = {model.b.numpy():1.2f}, loss={loss:2.5f}\"\n\n\ndef training_loop(model, x, y):\n\n  for epoch in epochs:\n    # Update the model with the single giant batch\n    train(model, x, y, learning_rate=0.1)\n\n    # Track this before I update\n    weights.append(model.w.numpy())\n    biases.append(model.b.numpy())\n    current_loss = loss(y, model(x))\n\n    print(f\"Epoch {epoch:2d}:\")\n    print(\"    \", report(model, current_loss))\n```\n\n----------------------------------------\n\nTITLE: Using Keras Callbacks\nDESCRIPTION: Demonstrates how to use Keras callbacks to customize model training. It shows how to use `EarlyStopping` to interrupt training when validation loss stops improving and `TensorBoard` to monitor model behavior. The callbacks are passed to the `fit` method using the `callbacks` parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n```python\ncallbacks = [\n  # Interrupt training if `val_loss` stops improving for over 2 epochs\n  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n  # Write TensorBoard logs to `./logs` directory\n  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n]\nmodel.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n          validation_data=(val_data, val_labels))\n```\n```\n\n----------------------------------------\n\nTITLE: Batching Tensors with Padding in TensorFlow\nDESCRIPTION: Explains TensorFlow's Dataset.padded_batch() for batching tensors with varying shapes. Padding allows batching sequences of different lengths by specifying padded dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_20\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=(None,))\n\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==> [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]\nprint(sess.run(next_element))  # ==> [[4, 4, 4, 4, 0, 0, 0],\n                               #      [5, 5, 5, 5, 5, 0, 0],\n                               #      [6, 6, 6, 6, 6, 6, 0],\n                               #      [7, 7, 7, 7, 7, 7, 7]]\n```\n\n----------------------------------------\n\nTITLE: Representing a Unicode String in TensorFlow using UTF-8 Encoding\nDESCRIPTION: This snippet demonstrates how to represent a Unicode string as a UTF-8 encoded string scalar in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntext_utf8 = tf.constant(u\"语言处理\")\n```\n\n----------------------------------------\n\nTITLE: Instantiating a LinearClassifier Estimator in Python\nDESCRIPTION: Example of creating a LinearClassifier Estimator instance with feature columns in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Instantiate an estimator, passing the feature columns.\nestimator = tf.estimator.LinearClassifier(\n    feature_columns=[population, crime_rate, median_education])\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and Required Libraries for Image Segmentation\nDESCRIPTION: This snippet imports the necessary libraries for the image segmentation task, including TensorFlow, TensorFlow Datasets, and visualization tools.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Installing Audio Dependencies in Python\nDESCRIPTION: Installation commands for required audio libraries fluidsynth, pyfluidsynth and pretty_midi for MIDI file handling and audio playback.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!sudo apt install -y fluidsynth\n!pip install --upgrade pyfluidsynth\n!pip install pretty_midi\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Integer Constraint\nDESCRIPTION: Example of registering an op with a minimum integer value constraint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_21\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MinIntExample\")\n    .Attr(\"a: int >= 2\");\n```\n\n----------------------------------------\n\nTITLE: TensorFlow C++ Main Function Initialization\nDESCRIPTION: The main function initializes TensorFlow, parses command line flags, and loads the classification graph. It demonstrates how to set up the global state and prepare the model for inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_10\n\nLANGUAGE: C++\nCODE:\n```\nint main(int argc, char* argv[]) {\n  // We need to call this to set up global state for TensorFlow.\n  tensorflow::port::InitMain(argv[0], &argc, &argv);\n  Status s = tensorflow::ParseCommandLineFlags(&argc, argv);\n  if (!s.ok()) {\n    LOG(ERROR) << \"Error parsing command line flags: \" << s.ToString();\n    return -1;\n  }\n\n  // First we load and initialize the model.\n  std::unique_ptr<tensorflow::Session> session;\n  string graph_path = tensorflow::io::JoinPath(FLAGS_root_dir, FLAGS_graph);\n  Status load_graph_status = LoadGraph(graph_path, &session);\n  if (!load_graph_status.ok()) {\n    LOG(ERROR) << load_graph_status;\n    return -1;\n  }\n```\n\n----------------------------------------\n\nTITLE: Implementing Shape Function with Rank Constraint in C++\nDESCRIPTION: This snippet shows how to implement a shape function with a rank constraint for the 'ZeroOut' operation in C++. It ensures the input is a vector (rank 1) and sets the output shape accordingly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_51\n\nLANGUAGE: c++\nCODE:\n```\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n  ::tensorflow::shape_inference::ShapeHandle input;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n  c->set_output(0, input);\n  return Status::OK();\n});\n```\n\n----------------------------------------\n\nTITLE: Using Initializable Iterator with Parameterized Datasets\nDESCRIPTION: Shows how to use an initializable iterator that requires explicit initialization but enables parameterization of the dataset using placeholders. Demonstrates reusing the same iterator with different parameter values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmax_value = tf.placeholder(tf.int64, shape=[])\ndataset = tf.data.Dataset.range(max_value)\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\n\n# Initialize an iterator over a dataset with 10 elements.\nsess.run(iterator.initializer, feed_dict={max_value: 10})\nfor i in range(10):\n  value = sess.run(next_element)\n  assert i == value\n\n# Initialize the same iterator over a dataset with 100 elements.\nsess.run(iterator.initializer, feed_dict={max_value: 100})\nfor i in range(100):\n  value = sess.run(next_element)\n  assert i == value\n```\n\n----------------------------------------\n\nTITLE: Creating a Dynamic RNN with tf.function and Python Control Flow\nDESCRIPTION: This example shows how to implement a dynamic RNN using tf.function with Python control flow. It uses tf.TensorArray to handle variable-length sequences and demonstrates how control flow operations can be converted to graph-mode equivalents.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass DynamicRNN(tf.keras.Model):\n\n  def __init__(self, rnn_cell):\n    super(DynamicRNN, self).__init__(self)\n    self.cell = rnn_cell\n\n  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.float32, shape=[None, None, 3])])\n  def call(self, input_data):\n\n    # [batch, time, features] -> [time, batch, features]\n    input_data = tf.transpose(input_data, [1, 0, 2])\n    timesteps =  tf.shape(input_data)[0]\n    batch_size = tf.shape(input_data)[1]\n    outputs = tf.TensorArray(tf.float32, timesteps)\n    state = self.cell.get_initial_state(batch_size = batch_size, dtype=tf.float32)\n    for i in tf.range(timesteps):\n      output, state = self.cell(input_data[i], state)\n      outputs = outputs.write(i, output)\n    return tf.transpose(outputs.stack(), [1, 0, 2]), state\n```\n\n----------------------------------------\n\nTITLE: Getting Sample Images for Visualization\nDESCRIPTION: Extracts sample images from the horse and zebra datasets for visualization and initial testing of the CycleGAN model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsample_horse = next(iter(train_horses))\nsample_zebra = next(iter(train_zebras))\n```\n\n----------------------------------------\n\nTITLE: Loading Sample Image\nDESCRIPTION: Loads a sample image from Wikimedia using the previously defined read_image function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Nusfjord_road%2C_2010_09.jpg/800px-Nusfjord_road%2C_2010_09.jpg\"\ninput_img = read_image(wikimedia)\n```\n\n----------------------------------------\n\nTITLE: Computing BigBiGAN Discriminator Scores and Losses in Python\nDESCRIPTION: This code computes the discriminator scores and losses on batches of encoder and generator pairs. It evaluates how well the discriminator distinguishes between real image-latent pairs from the encoder and generated image-latent pairs from the generator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfeed_dict = {enc_ph: test_images, gen_ph: np.random.randn(32, 120)}\n_out_scores_enc, _out_scores_gen, _out_losses = sess.run(\n    [disc_scores_enc, disc_scores_gen, losses], feed_dict=feed_dict)\nprint('Encoder scores:', {k: v.mean() for k, v in _out_scores_enc.items()})\nprint('Generator scores:', {k: v.mean() for k, v in _out_scores_gen.items()})\nprint('Losses:', _out_losses)\n```\n\n----------------------------------------\n\nTITLE: Mixing TensorFlow NumPy with NumPy\nDESCRIPTION: Demonstrates operator precedence when combining TensorFlow NumPy arrays with NumPy arrays. The TensorFlow NumPy implementation takes precedence due to higher __array_priority__.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nx = tnp.ones([2]) + np.ones([2])\nprint(\"x = %s\\nclass = %s\" % (x, x.__class__))\n```\n\n----------------------------------------\n\nTITLE: Creating utility function for SentencePiece text processing\nDESCRIPTION: Defines a helper function that processes sentences using the SentencePiece processor and returns the results in a sparse tensor format with values, indices, and dense shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef process_to_IDs_in_sparse_format(sp, sentences):\n  # An utility method that processes sentences with the sentence piece processor\n  # 'sp' and returns the results in tf.SparseTensor-similar format:\n  # (values, indices, dense_shape)\n  ids = [sp.EncodeAsIds(x) for x in sentences]\n  max_len = max(len(x) for x in ids)\n  dense_shape=(len(ids), max_len)\n  values=[item for sublist in ids for item in sublist]\n  indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n  return (values, indices, dense_shape)\n```\n\n----------------------------------------\n\nTITLE: Setting Example Layout for DTensor Weights\nDESCRIPTION: Creates layout examples for model weights that are fully replicated (unsharded) across the mesh.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nexample_weight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)  # or\nexample_weight_layout = dtensor.Layout.replicated(mesh, rank=2)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training Images in TensorFlow\nDESCRIPTION: This code snippet displays the first nine images and their corresponding labels from the training dataset using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass_names = train_dataset.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")\n```\n\n----------------------------------------\n\nTITLE: Defining CNN Model Architecture\nDESCRIPTION: Creates a convolutional neural network model using Keras Sequential API with two convolutional layers, max pooling, and dense layers. L2 regularization is applied to prevent overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  regularizer = tf.keras.regularizers.L2(1e-5)\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3,\n                             activation='relu',\n                             kernel_regularizer=regularizer),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Conv2D(64, 3,\n                             activation='relu',\n                             kernel_regularizer=regularizer),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64,\n                            activation='relu',\n                            kernel_regularizer=regularizer),\n      tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n    ])\n\n  return model\n```\n\n----------------------------------------\n\nTITLE: Compiling CUDA Kernels for TensorFlow Custom Ops in Bash\nDESCRIPTION: Commands for compiling CUDA kernels for custom TensorFlow operations. This two-step process first compiles the CUDA code with nvcc, then links it with the C++ implementation using g++ to create a shared library that can be loaded in Python.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_47\n\nLANGUAGE: bash\nCODE:\n```\nnvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \\\n  ${TF_CFLAGS[@]} -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\n\ng++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc \\\n  cuda_op_kernel.cu.o ${TF_CFLAGS[@]} -fPIC -lcudart ${TF_LFLAGS[@]}\n```\n\n----------------------------------------\n\nTITLE: Plotting Precision-Recall Curves\nDESCRIPTION: Creates Precision-Recall curves to compare model performance between baseline and weighted approaches on train and test datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nplot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\nplot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n\nplot_prc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\nplot_prc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n\n\nplt.legend(loc='lower right');\n```\n\n----------------------------------------\n\nTITLE: Generating Initial CycleGAN Translations and Visualizing Results\nDESCRIPTION: Performs initial translations between horse and zebra domains using the untrained generators and visualizes the results. This shows the starting point of the CycleGAN model before training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nto_zebra = generator_g(sample_horse)\nto_horse = generator_f(sample_zebra)\nplt.figure(figsize=(8, 8))\ncontrast = 8\n\nimgs = [sample_horse, to_zebra, sample_zebra, to_horse]\ntitle = ['Horse', 'To Zebra', 'Zebra', 'To Horse']\n\nfor i in range(len(imgs)):\n  plt.subplot(2, 2, i+1)\n  plt.title(title[i])\n  if i % 2 == 0:\n    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n  else:\n    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: TensorFlow 2: TensorBoard with Keras Callback\nDESCRIPTION: Creates a Keras model, compiles it, and trains using Model.fit with a TensorBoard callback. This demonstrates the TensorFlow 2.x approach to logging.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%reload_ext tensorboard\n\ndef create_model():\n  return tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28), name='layers_flatten'),\n    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n  ])\n\nmodel = create_model()\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'],\n              steps_per_execution=10)\n\nlog_dir = tempfile.mkdtemp()\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n  log_dir=log_dir,\n  histogram_freq=1) # Enable histogram computation with each epoch.\n\nmodel.fit(x=x_train,\n          y=y_train,\n          epochs=10,\n          validation_data=(x_test, y_test),\n          callbacks=[tensorboard_callback])\n```\n\n----------------------------------------\n\nTITLE: Defining Display Function for Mandelbrot Set Fractal in Python\nDESCRIPTION: This function takes an array of iteration counts and displays it as a colorful picture of the Mandelbrot set fractal. It uses NumPy for array manipulations and PIL for image creation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/mandelbrot.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef DisplayFractal(a, fmt='jpeg'):\n  \"\"\"Display an array of iteration counts as a\n     colorful picture of a fractal.\"\"\"\n  a_cyclic = (6.28*a/20.0).reshape(list(a.shape)+[1])\n  img = np.concatenate([10+20*np.cos(a_cyclic),\n                        30+50*np.sin(a_cyclic),\n                        155-80*np.cos(a_cyclic)], 2)\n  img[a==a.max()] = 0\n  a = img\n  a = np.uint8(np.clip(a, 0, 255))\n  f = BytesIO()\n  PIL.Image.fromarray(a).save(f, fmt)\n  display(Image(data=f.getvalue()))\n```\n\n----------------------------------------\n\nTITLE: Reading and Parsing TFRecord File with Image Data in Python\nDESCRIPTION: This code shows how to read a TFRecord file and parse its contents. It defines the feature description and a parsing function to extract image data from the TFRecord.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nraw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'height': tf.FixedLenFeature([], tf.int64),\n    'width': tf.FixedLenFeature([], tf.int64),\n    'depth': tf.FixedLenFeature([], tf.int64),\n    'label': tf.FixedLenFeature([], tf.int64),\n    'image_raw': tf.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  return tf.parse_single_example(example_proto, image_feature_description)\n\nparsed_image_dataset = raw_image_dataset.map(_parse_image_function)\nparsed_image_dataset\n```\n\n----------------------------------------\n\nTITLE: Sharding Matrix Multiplication Along Contracted Axis\nDESCRIPTION: Implements efficient distributed matrix multiplication by sharding operands along the contraction axis, reducing computation per device through concurrent local matmuls and collective reduction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 3), (\"y\", 2)], devices=DEVICES)\na_layout = dtensor.Layout([dtensor.UNSHARDED, 'x'], mesh)\na = dtensor_from_array([[1, 2, 3], [4, 5, 6]], layout=a_layout)\nb_layout = dtensor.Layout(['x', dtensor.UNSHARDED], mesh)\nb = dtensor_from_array([[6, 5], [4, 3], [2, 1]], layout=b_layout)\n\nc = tf.matmul(a, b)\n# `c` is a DTensor replicated on all devices (same as `a` and `b`)\nprint('Sharding spec:', dtensor.fetch_layout(c).sharding_specs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Resizing Layer\nDESCRIPTION: Custom layer for resizing video frames using einops library for tensor manipulation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass ResizeVideo(keras.layers.Layer):\n  def __init__(self, height, width):\n    super().__init__()\n    self.height = height\n    self.width = width\n    self.resizing_layer = layers.Resizing(self.height, self.width)\n\n  def call(self, video):\n    \"\"\"\n      Use the einops library to resize the tensor.  \n      \n      Args:\n        video: Tensor representation of the video, in the form of a set of frames.\n      \n      Return:\n        A downsampled size of the video according to the new height and width it should be resized to.\n    \"\"\"\n    # b stands for batch size, t stands for time, h stands for height, \n    # w stands for width, and c stands for the number of channels.\n    old_shape = einops.parse_shape(video, 'b t h w c')\n    images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n    images = self.resizing_layer(images)\n    videos = einops.rearrange(\n        images, '(b t) h w c -> b t h w c',\n        t = old_shape['t'])\n    return videos\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op with Minimum Length for Polymorphic Lists\nDESCRIPTION: Demonstrates defining an op with a constraint on the minimum length of a polymorphic tensor list, combining list type attributes with length constraints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_35\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MinimumLengthPolymorphicListExample\")\n    .Attr(\"T: list(type) >= 3\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Accessing Layer Parameters\nDESCRIPTION: Shows how to access specific parameters of a layer using dedicated accessors like kernel and bias.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# The variables are also accessible through nice accessors\nlayer.kernel, layer.bias\n```\n\n----------------------------------------\n\nTITLE: Creating Validation and Test Datasets\nDESCRIPTION: Prepares validation and test datasets from the IMDB reviews using TensorFlow's text_dataset_from_directory utility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nraw_val_ds = tf.keras.utils.text_dataset_from_directory(\n    'aclImdb/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='validation',\n    seed=seed)\n\nraw_test_ds = tf.keras.utils.text_dataset_from_directory(\n    'aclImdb/test',\n    batch_size=batch_size)\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Models Repository with Shell Commands\nDESCRIPTION: Commands to download and access the example code for custom estimators from the TensorFlow models repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tensorflow/models/\ncd models/samples/core/get_started\n```\n\n----------------------------------------\n\nTITLE: Saving Generator State from First MirroredStrategy\nDESCRIPTION: Saves the state of a random number generator from a distribution strategy with two replicas, to be later transferred to a different strategy configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nwith strat1.scope():\n  cp1.write(filename)\n  print(\"RNG stream from saving point:\")\n  print(strat1.run(lambda: g1.normal([])))\n  print(strat1.run(lambda: g1.normal([])))\n```\n\n----------------------------------------\n\nTITLE: Reading Generated Embeddings from TFRecord in Python\nDESCRIPTION: Reads and prints a sample of the generated embeddings from a TFRecord file. It defines a feature description and parsing function for the TFRecord format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nembed_file = os.path.join(output_dir, 'emb-00000-of-00001.tfrecords')\nsample = 5\n\n# Create a description of the features.\nfeature_description = {\n    'text': tf.io.FixedLenFeature([], tf.string),\n    'embedding': tf.io.FixedLenFeature([projected_dim], tf.float32)\n}\n\ndef _parse_example(example):\n  # Parse the input `tf.Example` proto using the dictionary above.\n  return tf.io.parse_single_example(example, feature_description)\n\ndataset = tf.data.TFRecordDataset(embed_file)\nfor record in dataset.take(sample).map(_parse_example):\n  print(\"{}: {}\".format(record['text'].numpy().decode('utf-8'), record['embedding'].numpy()[:10]))\n```\n\n----------------------------------------\n\nTITLE: Implementing KernelLinearClassifier with RandomFourierFeatureMapper\nDESCRIPTION: Code that creates a kernel-based linear classifier using Random Fourier Features to transform 784-dimensional image data to 2000-dimensional vectors before linear classification. This enables non-linear classification capabilities with linear model efficiency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nkernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(\n  input_dim=784, output_dim=2000, stddev=5.0, name='rffm')\nkernel_mappers = {image_column: [kernel_mapper]}\nestimator = tf.contrib.kernel_methods.KernelLinearClassifier(\n   n_classes=10, optimizer=optimizer, kernel_mappers=kernel_mappers)\n```\n\n----------------------------------------\n\nTITLE: Filtering TextLineDataset in TensorFlow\nDESCRIPTION: Implements a TensorFlow pipeline to read text files, skipping header lines and filtering out comment lines. Transformations are applied for each file separately using Dataset.flat_map.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nfilenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\"]\n\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\n\n# Use `Dataset.flat_map()` to transform each file as a separate nested dataset,\n# and then concatenate their contents sequentially into a single \"flat\" dataset.\n# * Skip the first line (header row).\n# * Filter out lines beginning with \"#\" (comments).\ndataset = dataset.flat_map(\n    lambda filename: (\n        tf.data.TextLineDataset(filename)\n        .skip(1)\n        .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), \"#\"))))\n```\n\n----------------------------------------\n\nTITLE: Using Variable Scopes for Distinct Variable Naming in TensorFlow\nDESCRIPTION: Illustrates how variable scopes can be used to ensure the creation of distinct variable names within convolutional layers. The function my_image_filter wraps convolution calls within separate tf.variable_scope contexts. Outputs distinct layer activations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef my_image_filter(input_images):\n    with tf.variable_scope(\"conv1\"):\n        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n    with tf.variable_scope(\"conv2\"):\n        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n        return conv_relu(relu1, [5, 5, 32, 32], [32])\n```\n\n----------------------------------------\n\nTITLE: Implementing Stricter MLP Class with DTensor Layouts in Python\nDESCRIPTION: Defines an MLPStricter class that creates Layout objects in the constructor, demonstrating a more constrained approach to capturing layout dependencies between layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass MLPStricter(tf.Module):\n\n  def __init__(self, mesh, input_mesh_dim, inner_mesh_dim1, output_mesh_dim):\n    super().__init__()\n\n    self.dense1 = Dense(\n        1200, 48, (1, 2), dtensor.Layout([input_mesh_dim, inner_mesh_dim1], mesh),\n        activation=tf.nn.relu)\n    self.bn = BatchNorm()\n    self.dense2 = Dense(48, 2, (3, 4), dtensor.Layout([inner_mesh_dim1, output_mesh_dim], mesh))\n\n\n  def __call__(self, x):\n    y = x\n    y = self.dense1(y)\n    y = self.bn(y)\n    y = self.dense2(y)\n    return y\n```\n\n----------------------------------------\n\nTITLE: Testing Original Model Output and Regularization Loss\nDESCRIPTION: Uses DeterministicRandomTestTool to ensure reproducible results when testing the original model. This generates reference outputs and regularization losses that will be used to verify the migration maintains identical behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nrandom_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\nwith random_tool.scope():\n  tf.keras.utils.set_random_seed(42)\n  layer = CompatModel(10)\n\n  inputs = tf.random.normal(shape=(10, 5, 5, 5))\n  original_output = layer(inputs)\n\n  # Grab the regularization loss as well\n  original_regularization_loss = tf.math.add_n(layer.losses)\n\nprint(original_regularization_loss)\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Training and Test Steps\nDESCRIPTION: Implements custom training and test step functions within TPU strategy scope for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  def train_step(inputs):\n    \"\"\"Each training step runs this custom function which calculates\n    gradients and updates weights.\n    \"\"\"\n    x, y = inputs\n\n    logits, loss_value, grads = grad(model, x, y)\n\n    update_loss = training_loss.update_state(loss_value)\n    update_accuracy = training_accuracy.update_state(y, logits)\n\n    # Show that this is truly a custom training loop\n    # Multiply all gradients by 2.\n    grads = grads * 2\n\n    update_vars = optimizer.apply_gradients(\n        zip(grads, model.trainable_variables))\n\n    with tf.control_dependencies([update_vars, update_loss, update_accuracy]):\n      return tf.identity(loss_value)\n\n  def test_step(inputs):\n    \"\"\"Each training step runs this custom function\"\"\"\n    x, y = inputs\n\n    logits, loss_value = loss(model, x, y)\n\n    update_loss = test_loss.update_state(loss_value)\n    update_accuracy = test_accuracy.update_state(y, logits)\n\n    with tf.control_dependencies([update_loss, update_accuracy]):\n      return tf.identity(loss_value)\n```\n\n----------------------------------------\n\nTITLE: Plotting Another Image and Prediction\nDESCRIPTION: This snippet plots the image and prediction for the 12th test image using the `plot_image` and `plot_value_array` functions defined previously. It creates a figure with two subplots, one for the image and one for the prediction bar chart, then displays the figure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ni = 12\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  test_labels)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Analyzing Class-wise Accuracy for Each Digit\nDESCRIPTION: Computes and displays the model's accuracy for each individual digit (0-9). This helps identify which digits are more challenging for the model to recognize correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Accuracy breakdown by digit:\")\nprint(\"---------------------------\")\nlabel_accs = {}\nfor label in range(10):\n  label_ind = (y_test == label)\n  # extract predictions for specific true label\n  pred_label = test_classes[label_ind]\n  labels = y_test[label_ind]\n  # compute class-wise accuracy\n  label_accs[accuracy_score(pred_label, labels).numpy()] = label\nfor key in sorted(label_accs):\n  print(f\"Digit {label_accs[key]}: {key:.3f}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Training and Testing Functions with TensorFlow\nDESCRIPTION: Defines two functions decorated with @tf.function for performance optimization: train_step for updating model parameters using gradients, and test_step for evaluating the model on validation data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(x, y):\n  with tf.GradientTape() as tape:\n      logits = model(x, training=True)\n      loss_value = loss_fn(y, logits)\n  grads = tape.gradient(loss_value, model.trainable_weights)\n  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n  train_acc_metric.update_state(y, logits)\n  train_loss_metric.update_state(y, logits)\n  return loss_value\n\n@tf.function\ndef test_step(x, y):\n  logits = model(x, training=False)\n  val_acc_metric.update_state(y, logits)\n  val_loss_metric.update_state(y, logits)\n```\n\n----------------------------------------\n\nTITLE: Handling Python Global Variables in TensorFlow Functions\nDESCRIPTION: This example illustrates the issue with depending on Python global variables in tf.functions. It shows how changes to global variables are not reflected in subsequent function calls and provides a recommended approach using function arguments instead.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef buggy_add():\n  return 1 + foo\n\n@tf.function\ndef recommended_add(foo):\n  return 1 + foo\n\nfoo = 1\nprint(\"Buggy:\", buggy_add())\nprint(\"Correct:\", recommended_add(foo))\n\nprint(\"Updating the value of `foo` to 100!\")\nfoo = 100\nprint(\"Buggy:\", buggy_add())  # Did not change!\nprint(\"Correct:\", recommended_add(foo))\n```\n\n----------------------------------------\n\nTITLE: Processing Input Image for TensorFlow C++ Inference\nDESCRIPTION: This code loads, resizes, and processes an input image according to the specifications required by the main graph. It creates a tensor from the image file with the required dimensions and normalization parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_11\n\nLANGUAGE: C++\nCODE:\n```\n  // Get the image from disk as a float array of numbers, resized and normalized\n  // to the specifications the main graph expects.\n  std::vector<Tensor> resized_tensors;\n  string image_path = tensorflow::io::JoinPath(FLAGS_root_dir, FLAGS_image);\n  Status read_tensor_status = ReadTensorFromImageFile(\n      image_path, FLAGS_input_height, FLAGS_input_width, FLAGS_input_mean,\n      FLAGS_input_std, &resized_tensors);\n  if (!read_tensor_status.ok()) {\n    LOG(ERROR) << read_tensor_status;\n    return -1;\n  }\n  const Tensor& resized_tensor = resized_tensors[0];\n```\n\n----------------------------------------\n\nTITLE: Broadcasting error with mismatched trailing dimensions in TensorFlow\nDESCRIPTION: Demonstrates a broadcasting error when trying to add a 2D tensor with shape 3x4 to a 2D ragged tensor with 3 rows but varying column counts. The trailing dimensions must match for broadcasting to succeed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# x      (2d ragged): 3 x (r1)\n# y      (2d tensor): 3 x    4  # trailing dimensions do not match\nx = tf.ragged.constant([[1, 2], [3, 4, 5, 6], [7]])\ny = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\ntry:\n  x + y\nexcept tf.errors.InvalidArgumentError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Building a Keras Model using Functional API\nDESCRIPTION: Demonstrates how to create a Keras model using the functional API, which allows for more flexible model architectures and easier input shape specification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ninputs = tf.keras.Input(shape=[3,])\n\nx = FlexibleDense(3)(inputs)\nx = FlexibleDense(2)(x)\n\nmy_functional_model = tf.keras.Model(inputs=inputs, outputs=x)\n\nmy_functional_model.summary()\nmy_functional_model(tf.constant([[2.0, 2.0, 2.0]]))\n```\n\n----------------------------------------\n\nTITLE: Unicode String Encoding from a RaggedTensor\nDESCRIPTION: This code shows how to encode multiple strings of varying lengths using a RaggedTensor as input in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and TensorFlow Hub for Image Classification\nDESCRIPTION: This code snippet imports necessary libraries and prints version information for TensorFlow and TensorFlow Hub. It also checks for GPU availability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport itertools\nimport os\n\nimport matplotlib.pylab as plt\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nprint(\"TF version:\", tf.__version__)\nprint(\"Hub version:\", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for FGSM Implementation in Python\nDESCRIPTION: Imports TensorFlow and Matplotlib libraries needed for implementing the Fast Gradient Sign Method and visualizing results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.rcParams['figure.figsize'] = (8, 8)\nmpl.rcParams['axes.grid'] = False\n```\n\n----------------------------------------\n\nTITLE: Building a Sequential Model with DTensor Layouts\nDESCRIPTION: Creates a Keras Sequential model with fully replicated weights by specifying kernel_layout and bias_layout for each Dense layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, \n                        activation='relu',\n                        name='d1',\n                        kernel_layout=unsharded_layout_2d, \n                        bias_layout=unsharded_layout_1d),\n  tf.keras.layers.Dense(10,\n                        name='d2',\n                        kernel_layout=unsharded_layout_2d, \n                        bias_layout=unsharded_layout_1d)\n])\n```\n\n----------------------------------------\n\nTITLE: Variable Creation in TF1.x Style\nDESCRIPTION: Example showing variable creation in TF1.x style using Graph and Session. This pattern works as expected in TF1.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef f():\n  v = tf.Variable(1.0)\n  return v\n\nwith tf.Graph().as_default():\n  with tf.compat.v1.Session() as sess:\n    res = f()\n    sess.run(tf.compat.v1.global_variables_initializer())\n    sess.run(res)\n```\n\n----------------------------------------\n\nTITLE: Implementing Backtracking Line Search in TensorFlow\nDESCRIPTION: This code implements a backtracking line search algorithm using tf.GradientTape for automatic differentiation. It demonstrates how complex control flow can be used in differentiable code, allowing for dynamic models in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef line_search_step(fn, init_x, rate=1.0):\n  with tf.GradientTape() as tape:\n    # Variables are automatically recorded, but manually watch a tensor\n    tape.watch(init_x)\n    value = fn(init_x)\n  grad = tape.gradient(value, init_x)\n  grad_norm = tf.reduce_sum(grad * grad)\n  init_value = value\n  while value > init_value - rate * grad_norm:\n    x = init_x - rate * grad\n    value = fn(x)\n    rate /= 2.0\n  return x, value\n```\n\n----------------------------------------\n\nTITLE: Visualizing BigBiGAN Reconstructions in Python\nDESCRIPTION: This code shows how to generate and visualize reconstructions of input images using a BigBiGAN model. It passes test images through the encoder and generator, then displays the original images alongside their reconstructions in a grid format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_images_batch = test_images[:16]\n_out_recons = sess.run(recon_x, feed_dict={enc_ph: test_images_batch})\nprint('reconstructions shape:', _out_recons.shape)\n\ninputs_and_recons = interleave(test_images_batch, _out_recons)\nprint('inputs_and_recons shape:', inputs_and_recons.shape)\nimshow(imgrid(image_to_uint8(inputs_and_recons), cols=2))\n```\n\n----------------------------------------\n\nTITLE: Displaying Predictions for Sample Texts in TensorFlow\nDESCRIPTION: This snippet reads sample texts, prints a portion of each, and displays the true and predicted classes for each sample.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nsamples = file_paths[0:3]\nfor i, sample in enumerate(samples):\n  f = open(sample)\n  text = f.read()\n  print(text[0:100])\n  print(\"True Class: \", sample.split(\"/\")[0])\n  print(\"Predicted Class: \", dir_names[y_pred[i]])\n  f.close()\n```\n\n----------------------------------------\n\nTITLE: Generating or Uploading Target Image for Latent Vector Search\nDESCRIPTION: This code allows for either generating a random face image using the GAN model or uploading a custom image to use as a target for finding the closest latent vector.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nimage_from_module_space = True  # @param { isTemplate:true, type:\"boolean\" }\n\ndef get_module_space_image():\n  vector = tf.random.normal([1, latent_dim])\n  images = progan(vector)['default'][0]\n  return images\n\ndef upload_image():\n  uploaded = files.upload()\n  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n  return transform.resize(image, [128, 128])\n\nif image_from_module_space:\n  target_image = get_module_space_image()\nelse:\n  target_image = upload_image()\n\ndisplay_image(target_image)\n```\n\n----------------------------------------\n\nTITLE: Debugging TensorFlow with Variable to Prevent Constant Folding\nDESCRIPTION: This snippet shows how using `tf.Variable` prevents constant folding, allowing tfdbg to capture intermediate tensor dumps. It initializes a TensorFlow variable, adds it to itself, and runs the computation within a debug session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n\"import numpy as np\\n\\na = tf.Variable(np.ones(10), name=\\\"a\\\")\\nb = tf.add(a, a, name=\\\"b\\\")\\nsess = tf.Session()\\nsess.run(tf.global_variables_initializer())\\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\\nsess.run(b)\"\n```\n\n----------------------------------------\n\nTITLE: Converting Print Statements with AutoGraph\nDESCRIPTION: Demonstrates how Python print statements can be converted to tf.print operations in the graph, printing values during graph execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=tf.autograph.experimental.Feature.BUILTIN_FUNCTIONS)\ndef count(n):\n  i = 0\n  while i < n:\n    print(i)\n    i += 1\n  return n\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    sess.run(count(tf.constant(5)))\n```\n\n----------------------------------------\n\nTITLE: Defining a TF1-compatible Model in TF2\nDESCRIPTION: Creates a TensorFlow 1.x compatible model using tf.compat.v1 APIs within a TF2 Keras Layer. This serves as the starting point for migration and uses the track_tf1_style_variables decorator to maintain TF1 variable behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nclass CompatModel(tf.keras.layers.Layer):\n\n  def __init__(self, units, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.units = units\n\n  @tf.compat.v1.keras.utils.track_tf1_style_variables\n  def call(self, inputs, training=None):\n    with tf.compat.v1.variable_scope('model'):\n      out = tf.compat.v1.layers.conv2d(\n          inputs, 3, 3,\n          kernel_regularizer=\"l2\")\n      out = tf.compat.v1.layers.flatten(out)\n      out = tf.compat.v1.layers.dropout(out, training=training)\n      out = tf.compat.v1.layers.dense(\n          out, self.units,\n          kernel_regularizer=\"l2\")\n      return out\n```\n\n----------------------------------------\n\nTITLE: Building and training a Keras model with converted RaggedTensors\nDESCRIPTION: Creates a sequential Keras model with embedding, LSTM, and dense layers that can handle the variable-length text data by using masking.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Build the Keras model.\nkeras_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(hash_buckets, 16, mask_zero=True),\n    tf.keras.layers.LSTM(32, return_sequences=True, use_bias=False),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(32),\n    tf.keras.layers.Activation(tf.nn.relu),\n    tf.keras.layers.Dense(1)\n])\n\nkeras_model.compile(loss='binary_crossentropy', optimizer='rmsprop')\nkeras_model.fit(hashed_words.to_tensor(), is_question, epochs=5)\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Columns in TensorFlow\nDESCRIPTION: Code to create numeric feature columns for the Iris dataset features. Each feature is represented as a 32-bit floating-point value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Feature columns describe how to use the input.\nmy_feature_columns = []\nfor key in train_x.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Instance Segmentation Masks\nDESCRIPTION: This optional code visualizes instance segmentation masks for models that support it, such as Mask R-CNN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Handle models with masks:\nimage_np_with_mask = image_np.copy()\n\nif 'detection_masks' in result:\n  # we need to convert np.arrays to tensors\n  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n\n  # Reframe the bbox mask to the image size.\n  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n            detection_masks, detection_boxes,\n              image_np.shape[1], image_np.shape[2])\n  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n                                      tf.uint8)\n  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_mask[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset).astype(int),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.30,\n      agnostic_mode=False,\n      instance_masks=result.get('detection_masks_reframed', None),\n      line_thickness=8)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_mask[0])\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Computing Batch Jacobians with GradientTape\nDESCRIPTION: Demonstrates how to compute batch jacobians using tf.GradientTape with TensorFlow NumPy arrays, showing the relationship between input/output shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Computes a batch of jacobians. Each row is the jacobian of an element in the\n# batch of outputs w.r.t. the corresponding input batch element.\ndef prediction_batch_jacobian(inputs):\n  with tf.GradientTape() as tape:\n    tape.watch(inputs)\n    prediction = model.predict(inputs)\n  return prediction, tape.batch_jacobian(prediction, inputs)\n\ninp_batch = tnp.ones([16, 32], tnp.float32)\noutput, batch_jacobian = prediction_batch_jacobian(inp_batch)\n# Note how the batch jacobian shape relates to the input and output shapes.\nprint(\"Output shape: %s, input shape: %s\" % (output.shape, inp_batch.shape))\nprint(\"Batch jacobian shape:\", batch_jacobian.shape)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Compressed MNIST Digits in TensorFlow\nDESCRIPTION: This snippet defines a function to display original MNIST digits, their compressed binary representations, and the reconstructed digits. It then uses this function to visualize the results of the compression process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef display_digits(originals, strings, entropies, reconstructions):\n  \"\"\"Visualizes 16 digits together with their reconstructions.\"\"\"\n  fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(12.5, 5))\n  axes = axes.ravel()\n  for i in range(len(axes)):\n    image = tf.concat([\n        tf.squeeze(originals[i]),\n        tf.zeros((28, 14), tf.uint8),\n        tf.squeeze(reconstructions[i]),\n    ], 1)\n    axes[i].imshow(image)\n    axes[i].text(\n        .5, .5, f\"→ 0x{strings[i].numpy().hex()} →\\n{entropies[i]:0.2f} bits\",\n        ha=\"center\", va=\"top\", color=\"white\", fontsize=\"small\",\n        transform=axes[i].transAxes)\n    axes[i].axis(\"off\")\n  plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n\ndisplay_digits(originals, strings, entropies, reconstructions)\n```\n\n----------------------------------------\n\nTITLE: Making predictions with the model\nDESCRIPTION: Demonstrates how to pass an image batch through the model to get predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npredictions = model(image_batch)\n```\n\n----------------------------------------\n\nTITLE: Implementing PowerLawRegularizer for Weight Compression\nDESCRIPTION: Defines a Keras regularizer that applies the power law entropy penalty to model weights. The penalty is scaled by lambda to balance compression with model performance, and normalized by the number of model parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass PowerLawRegularizer(tf.keras.regularizers.Regularizer):\n\n  def __init__(self, lmbda):\n    super().__init__()\n    self.lmbda = lmbda\n\n  def __call__(self, variable):\n    em = tfc.PowerLawEntropyModel(coding_rank=variable.shape.rank)\n    return self.lmbda * em.penalty(variable)\n\n# Normalizing the weight of the penalty by the number of model parameters is a\n# good rule of thumb to produce comparable results across models.\nregularizer = PowerLawRegularizer(lmbda=2./classifier.count_params())\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Models with Different Regularization Strengths in TensorFlow\nDESCRIPTION: This function trains models with different lambda values, compresses them, and evaluates their performance. It's used to analyze the size-accuracy trade-off of the compression technique.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef compress_and_evaluate_model(lmbda):\n  print(f\"lambda={lmbda:0.0f}: training...\", flush=True)\n  regularizer = PowerLawRegularizer(lmbda=lmbda/classifier.count_params())\n  compressible_classifier = make_mnist_classifier(regularizer)\n  train_model(\n      compressible_classifier, training_dataset, validation_dataset, verbose=0)\n  print(\"compressing...\", flush=True)\n  compressed_classifier = tf.keras.models.clone_model(\n      compressible_classifier, clone_function=compress_layer)\n  compressed_size = sum(map(\n      get_weight_size_in_bytes, compressed_classifier.weights))\n  compressed_zip_size = float(get_disk_size(\n      compressed_classifier, \"/tmp/compressed_classifier\"))\n  print(\"evaluating...\", flush=True)\n  compressed_classifier = tf.keras.models.load_model(\n      \"/tmp/compressed_classifier\")\n  compressed_classifier.compile(\n      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n  _, compressed_accuracy = compressed_classifier.evaluate(\n      validation_dataset.batch(128), verbose=0)\n  print()\n  return compressed_size, compressed_zip_size, compressed_accuracy\n\nlambdas = (2., 5., 10., 20., 50.)\nmetrics = [compress_and_evaluate_model(l) for l in lambdas]\nmetrics = tf.convert_to_tensor(metrics, tf.float32)\n```\n\n----------------------------------------\n\nTITLE: Saving a Model in TensorFlow Distributed Training\nDESCRIPTION: Saving a TensorFlow model in a distributed environment where each worker saves to a unique location determined by the write_filepath function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nmulti_worker_model.save(write_model_path)\n```\n\n----------------------------------------\n\nTITLE: Problematic NoiseAdder Module with Cached Random Noise\nDESCRIPTION: This module incorrectly computes a random noise tensor once during initialization and reuses it for all subsequent calls, which works in TF1.x graph mode but freezes the noise in TF2 eager execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass NoiseAdder(tf.Module):\n  def __init__(shape, mean):\n    self.noise_distribution = tf.random.normal(shape=shape, mean=mean)\n    self.trainable_scale = tf.Variable(1.0, trainable=True)\n  \n  def add_noise(input):\n    return (self.noise_distribution + input) * self.trainable_scale\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Gradients in TensorFlow\nDESCRIPTION: This snippet demonstrates how to implement custom gradients in TensorFlow using the @tf.custom_gradient decorator. It shows an example of clipping the gradient norm and a more complex example of providing a numerically stable gradient for the log1pexp function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n@tf.custom_gradient\ndef clip_gradient_by_norm(x, norm):\n  y = tf.identity(x)\n  def grad_fn(dresult):\n    return [tf.clip_by_norm(dresult, norm), None]\n  return y, grad_fn\n\n@tf.custom_gradient\ndef log1pexp(x):\n  e = tf.exp(x)\n  def grad(dy):\n    return dy * (1 - 1 / (1 + e))\n  return tf.log(1 + e), grad\n\ngrad_log1pexp = Grad(log1pexp)\n```\n\n----------------------------------------\n\nTITLE: Configuring BigGAN Model Path Selection\nDESCRIPTION: Defines the TensorFlow Hub module paths for different BigGAN model variants and resolutions\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# BigGAN-deep models\n# module_path = 'https://tfhub.dev/deepmind/biggan-deep-128/1'  # 128x128 BigGAN-deep\nmodule_path = 'https://tfhub.dev/deepmind/biggan-deep-256/1'  # 256x256 BigGAN-deep\n# module_path = 'https://tfhub.dev/deepmind/biggan-deep-512/1'  # 512x512 BigGAN-deep\n\n# BigGAN (original) models\n# module_path = 'https://tfhub.dev/deepmind/biggan-128/2'  # 128x128 BigGAN\n# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'  # 256x256 BigGAN\n# module_path = 'https://tfhub.dev/deepmind/biggan-512/2'  # 512x512 BigGAN\n```\n\n----------------------------------------\n\nTITLE: Setting Up TPU Strategy and Data Pipeline\nDESCRIPTION: Initializes TPU strategy, loads and preprocesses MNIST dataset, and configures training parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntf.keras.backend.clear_session()\n\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\ninput_shape = (28, 28, 1)\n\nx_train = x_train.reshape(x_train.shape[0], *input_shape).astype(np.float32)\nx_test = x_test.reshape(x_test.shape[0], *input_shape).astype(np.float32)\ny_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n\nBATCH_SIZE = 32\nNUM_EPOCHS = 5\n\ntrain_steps_per_epoch = len(x_train) // BATCH_SIZE\ntest_steps_per_epoch = len(x_test) // BATCH_SIZE\n```\n\n----------------------------------------\n\nTITLE: Running the PDE Simulation Loop in Python\nDESCRIPTION: Initializes the TensorFlow variables to their initial conditions and runs a simulation loop for 1000 steps, updating the state at each step and displaying the final resulting image of the pond.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Initialize state to initial conditions\ntf.global_variables_initializer().run()\n\n# Run 1000 steps of PDE\nfor i in range(1000):\n  # Step simulation\n  step.run({eps: 0.03, damping: 0.04})\n\n# Show final image\nDisplayArray(U.eval(), rng=[-0.1, 0.1])\n\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Gradient Descent Training Step\nDESCRIPTION: Defines a training function that implements one step of gradient descent. It calculates gradients of the loss with respect to model parameters using tf.GradientTape and updates the parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Given a callable model, inputs, outputs, and a learning rate...\ndef train(model, x, y, learning_rate):\n\n  with tf.GradientTape() as t:\n    # Trainable variables are automatically tracked by GradientTape\n    current_loss = loss(y, model(x))\n\n  # Use GradientTape to calculate the gradients with respect to W and b\n  dw, db = t.gradient(current_loss, [model.w, model.b])\n\n  # Subtract the gradient scaled by the learning rate\n  model.w.assign_sub(learning_rate * dw)\n  model.b.assign_sub(learning_rate * db)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Semantic Similarity\nDESCRIPTION: Downloads and processes the STS Benchmark dataset for evaluating semantic textual similarity performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas\nimport scipy\nimport math\nimport csv\n\nsts_dataset = tf.keras.utils.get_file(\n    fname=\"Stsbenchmark.tar.gz\",\n    origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n    extract=True)\nsts_dev = pandas.read_table(\n    os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"),\n    skip_blank_lines=True,\n    usecols=[4, 5, 6],\n    names=[\"sim\", \"sent_1\", \"sent_2\"])\nsts_test = pandas.read_table(\n    os.path.join(\n        os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"),\n    quoting=csv.QUOTE_NONE,\n    skip_blank_lines=True,\n    usecols=[4, 5, 6],\n    names=[\"sim\", \"sent_1\", \"sent_2\"])\n# cleanup some NaN values in sts_dev\nsts_dev = sts_dev[[isinstance(s, str) for s in sts_dev['sent_2']]]\n```\n\n----------------------------------------\n\nTITLE: Defining Initial Conditions for the PDE Simulation in Python\nDESCRIPTION: Sets up the initial conditions for the simulation of the pond, initializing a 500 x 500 grid and randomly placing raindrops on the surface. This serves as the starting state for the simulation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nN = 500\n\n# Initial Conditions -- some rain drops hit a pond\n\n# Set everything to zero\nu_init = np.zeros([N, N], dtype=np.float32)\nut_init = np.zeros([N, N], dtype=np.float32)\n\n# Some rain drops hit a pond at random points\nfor n in range(40):\n  a,b = np.random.randint(0, N, 2)\n  u_init[a,b] = np.random.uniform()\n\nDisplayArray(u_init, rng=[-0.1, 0.1])\n\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Model with TensorFlow Hub for Image Classification\nDESCRIPTION: Constructs a TensorFlow model using a feature extractor from TensorFlow Hub with a dropout layer and a dense classification layer. The model includes L2 regularization on the dense layer and optional fine-tuning capability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Building model with\", model_handle)\nmodel = tf.keras.Sequential([\n    # Explicitly define the input shape so the model can be properly\n    # loaded by the TFLiteConverter\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n    hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n    tf.keras.layers.Dropout(rate=0.2),\n    tf.keras.layers.Dense(len(class_names),\n                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n])\nmodel.build((None,)+IMAGE_SIZE+(3,))\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Defining Input and Model Functions for TPUEstimator in TensorFlow 1\nDESCRIPTION: Creates input functions for training and evaluation data, and a model function for TPUEstimator that defines the training operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef _input_fn(params):\n  dataset = tf1.data.Dataset.from_tensor_slices((features, labels))\n  dataset = dataset.repeat()\n  return dataset.batch(params['batch_size'], drop_remainder=True)\n\ndef _eval_input_fn(params):\n  dataset = tf1.data.Dataset.from_tensor_slices((eval_features, eval_labels))\n  dataset = dataset.repeat()\n  return dataset.batch(params['batch_size'], drop_remainder=True)\n\ndef _model_fn(features, labels, mode, params):\n  logits = tf1.layers.Dense(1)(features)\n  loss = tf1.losses.mean_squared_error(labels=labels, predictions=logits)\n  optimizer = tf1.train.AdagradOptimizer(0.05)\n  train_op = optimizer.minimize(loss, global_step=tf1.train.get_global_step())\n  return tf1.estimator.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor with Uniform Inner Dimensions in TensorFlow\nDESCRIPTION: This code creates a ragged tensor with uniform inner dimensions using a multidimensional tf.Tensor for the flat_values. It demonstrates how to construct and print information about such a tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_60\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=[[1, 3], [0, 0], [1, 3], [5, 3], [3, 3], [1, 2]],\n    row_splits=[0, 3, 4, 6])\nprint(rt)\nprint(\"Shape: {}\".format(rt.shape))\nprint(\"Number of partitioned dimensions: {}\".format(rt.ragged_rank))\nprint(\"Flat values shape: {}\".format(rt.flat_values.shape))\nprint(\"Flat values:\\n{}\".format(rt.flat_values))\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Attribute (C++)\nDESCRIPTION: This snippet shows how to register a TensorFlow op using `REGISTER_OP` and define an attribute named `preserve_index` of type `int`. This attribute allows the user to specify which index to preserve when zeroing out elements, configuring the op at graph construction time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_9\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"preserve_index: int\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\");\n```\n\n----------------------------------------\n\nTITLE: MIDI to Notes Conversion Function\nDESCRIPTION: Function to convert MIDI file data into a pandas DataFrame containing note pitch, start time, end time, step, and duration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef midi_to_notes(midi_file: str) -> pd.DataFrame:\n  pm = pretty_midi.PrettyMIDI(midi_file)\n  instrument = pm.instruments[0]\n  notes = collections.defaultdict(list)\n\n  # Sort the notes by start time\n  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n  prev_start = sorted_notes[0].start\n\n  for note in sorted_notes:\n    start = note.start\n    end = note.end\n    notes['pitch'].append(note.pitch)\n    notes['start'].append(start)\n    notes['end'].append(end)\n    notes['step'].append(start - prev_start)\n    notes['duration'].append(end - start)\n    prev_start = start\n\n  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n```\n\n----------------------------------------\n\nTITLE: Evaluating Overall Model Accuracy on Test Data\nDESCRIPTION: Defines an accuracy function and uses it to evaluate the loaded model on the MNIST test dataset. It loads the test data, makes predictions, and calculates the accuracy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ndef accuracy_score(y_pred, y):\n  # Generic accuracy function\n  is_equal = tf.equal(y_pred, y)\n  return tf.reduce_mean(tf.cast(is_equal, tf.float32))\n\nx_test, y_test = tfds.load(\"mnist\", split=['test'], batch_size=-1, as_supervised=True)[0]\ntest_classes = mlp_loaded(x_test)\ntest_acc = accuracy_score(test_classes, y_test)\nprint(f\"Test Accuracy: {test_acc:.3f}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Analysis Transform Network in Python\nDESCRIPTION: Creates the encoder (analysis) transform network using convolutional and dense layers to convert images into latent space representations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef make_analysis_transform(latent_dims):\n  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n  return tf.keras.Sequential([\n      tf.keras.layers.Conv2D(\n          20, 5, use_bias=True, strides=2, padding=\"same\",\n          activation=\"leaky_relu\", name=\"conv_1\"),\n      tf.keras.layers.Conv2D(\n          50, 5, use_bias=True, strides=2, padding=\"same\",\n          activation=\"leaky_relu\", name=\"conv_2\"),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(\n          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n      tf.keras.layers.Dense(\n          latent_dims, use_bias=True, activation=None, name=\"fc_2\"),\n  ], name=\"analysis_transform\")\n```\n\n----------------------------------------\n\nTITLE: Performing Inference and Displaying Results in Python\nDESCRIPTION: This snippet runs the loaded model on the prepared image, computes probabilities, and displays the top 5 classification results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Run model on image\n%time probabilities = tf.nn.softmax(classifier(image)).numpy()\n\ntop_5 = tf.argsort(probabilities, axis=-1, direction=\"DESCENDING\")[0][:5].numpy()\nnp_classes = np.array(classes)\n\n# Some models include an additional 'background' class in the predictions, so\n# we must account for this when reading the class labels.\nincludes_background_class = probabilities.shape[1] == 1001\n\nfor i, item in enumerate(top_5):\n  class_index = item if includes_background_class else item + 1\n  line = f'({i+1}) {class_index:4} - {classes[class_index]}: {probabilities[0][top_5][i]}'\n  print(line)\n\nshow_image(image, '')\n```\n\n----------------------------------------\n\nTITLE: Launching Multi-GPU Training for CIFAR-10 in TensorFlow\nDESCRIPTION: Command to run the CIFAR-10 model training across multiple GPU cards. The --num_gpus parameter specifies how many GPUs to use, defaulting to 1 if not specified. If fewer GPUs are available than requested, the script will use all available GPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\npython cifar10_multi_gpu_train.py --num_gpus=2\n```\n\n----------------------------------------\n\nTITLE: TF1 Hub Module Initialization and Inference\nDESCRIPTION: Setting up and using a TF1 Hub module with placeholders for inference in a server environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_issues.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create graph and finalize (finalizing optional but recommended).\ng = tf.Graph()\nwith g.as_default():\n  # We will be feeding 1D tensors of text into the graph.\n  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n  embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n  embedded_text = embed(text_input)\n  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\ng.finalize()\n\n# Create session and initialize.\nsession = tf.Session(graph=g)\nsession.run(init_op)\n```\n\nLANGUAGE: python\nCODE:\n```\nresult = session.run(embedded_text, feed_dict={text_input: [\"Hello world\"]})\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Dense Layers in TensorFlow\nDESCRIPTION: Demonstrates creating Dense layers with and without input shape specification\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlayer = tf.keras.layers.Dense(100)\nlayer = tf.keras.layers.Dense(10, input_shape=(None, 5))\n```\n\n----------------------------------------\n\nTITLE: Defining Mandelbrot Set Computation in TensorFlow\nDESCRIPTION: This snippet defines the core computation for the Mandelbrot set, including the iterative formula z = z^2 + c and the divergence check. It uses TensorFlow operations for complex number arithmetic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/mandelbrot.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Compute the new values of z: z^2 + x\nzs_ = zs*zs + xs\n\n# Have we diverged with this new value?\nnot_diverged = tf.abs(zs_) < 4\n\n# Operation to update the zs and the iteration count.\n#\n# Note: We keep computing zs after they diverge! This\n#       is very wasteful! There are better, if a little\n#       less simple, ways to do this.\n#\nstep = tf.group(\n  zs.assign(zs_),\n  ns.assign_add(tf.cast(not_diverged, tf.float32))\n  )\n```\n\n----------------------------------------\n\nTITLE: Defining Predefined Seeds for Text Generation in Python\nDESCRIPTION: This code snippet defines a dictionary containing predefined seed texts in various languages for use in text generation. The seeds include special tokens to structure the generated text, such as _START_ARTICLE_, _START_SECTION_, and _START_PARAGRAPH_.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n#@title Predefined Seeds\nlang_to_seed = {\"en\": \"\\n_START_ARTICLE_\\n1882 Prince Edward Island general election\\n_START_PARAGRAPH_\\nThe 1882 Prince Edward Island election was held on May 8, 1882 to elect members of the House of Assembly of the province of Prince Edward Island, Canada.\",\n                \"ar\": \"\\n_START_ARTICLE_\\nأوليفيا كوك\\n_START_SECTION_\\nنشأتها والتعلي \\n_START_PARAGRAPH_\\nولدت أوليفيا كوك في أولدهام في مانشستر الكبرى لأسرة تتكون من أب يعمل كظابط شرطة، وأمها تعمل كممثلة مبيعات. عندما كانت صغيرة بدأت تأخذ دروساً في الباليه الجمباز. وفي المدرسة شاركت في المسرحيات المدرسية، إضافةً إلى عملها في مسرح سندريلا . وفي سن الرابعة عشر عاماً، حصلت على وكيلة لها في مانشستر وهي وقعت عقداً مع وكالة الفنانين المبدعين في مانشستر،\",\n                \"zh-cn\": \"\\n_START_ARTICLE_\\n上尾事件\\n_START_SECTION_\\n日本国铁劳资关系恶化\\n_START_PARAGRAPH_\\n由于日本国铁财政恶化，管理层开始重整人手安排，令工会及员工感到受威胁。但日本国铁作为公营企业，其雇员均受公营企业等劳资关系法规管——该法第17条规定公营企业员工不得发动任何罢工行为。为了规避该法例\",\n                \"zh-tw\": \"\\n_START_ARTICLE_\\n乌森\\n_START_PARAGRAPH_\\n烏森（法語：Houssen，發音：[usən]；德語：Hausen；阿爾薩斯語：Hüse）是法國上萊茵省的一個市鎮，位於該省北部，屬於科爾馬-里博維萊區（Colmar-Ribeauvillé）第二科爾馬縣（Colmar-2）。該市鎮總面積6.7平方公里，2009年時的人口為\",\n                \"nl\": \"\\n_START_ARTICLE_\\n1001 vrouwen uit de Nederlandse geschiedenis\\n_START_SECTION_\\nSelectie van vrouwen\\n_START_PARAGRAPH_\\nDe 'oudste' biografie in het boek is gewijd aan de beschermheilige\",\n                \"fr\": \"\\n_START_ARTICLE_\\nꝹ\\n_START_SECTION_\\nUtilisation\\n_START_PARAGRAPH_\\nLe d insulaire est utilisé comme lettre additionnelle dans l'édition de 1941 du recueil de chroniques galloises Brut y Tywysogion\",\n                \"de\": \"\\n_START_ARTICLE_\\nÜnal Demirkıran\\n_START_SECTION_\\nLaufbahn\\n_START_PARAGRAPH_\\nDemirkıran debütierte als junges Talent am 25. September 1999 im Auswärtsspiel des SSV Ulm 1846 bei Werder Bremen (2:2) in der Bundesliga, als er kurz\",\n                \"it\": \"\\n_START_ARTICLE_\\n28th Street (linea IRT Lexington Avenue)\\n_START_SECTION_\\nStoria\\n_START_PARAGRAPH_\\nLa stazione, i cui lavori di costruzione ebbero inizio nel 1900, venne aperta il 27 ottobre 1904, come\",\n                \"ja\": \"\\n_START_ARTICLE_\\nしのぶ・まさみshow'05 恋してラララ\\n_START_SECTION_\\n概要\\n_START_PARAGRAPH_\\n『上海ルーキーSHOW』の打ち切り後に放送された年末特番で、同番組MCの大竹しのぶと久本雅美が恋愛にまつわるテーマでトークや音楽企画を展開していた。基本は女\",\n                \"ko\": \"\\n_START_ARTICLE_\\n녹턴, Op. 9 (쇼팽)\\n_START_SECTION_\\n녹턴 3번 나장조\\n_START_PARAGRAPH_\\n쇼팽의 녹턴 3번은 세도막 형식인 (A-B-A)형식을 취하고 있다. 첫 부분은 알레그레토(Allegretto)의 빠르기가 지시되어 있으며 물 흐르듯이 부드럽게 전개되나\",\n                \"pl\": \"\\n_START_ARTICLE_\\nAK-176\\n_START_SECTION_\\nHistoria\\n_START_PARAGRAPH_\\nPod koniec lat 60 XX w. w ZSRR dostrzeżono potrzebę posiadania lekkiej armaty uniwersalnej średniego kalibru o stosunkowo dużej mocy ogniowej, która\",\n                \"pt\": \"\\n_START_ARTICLE_\\nÁcido ribonucleico\\n_START_SECTION_\\nIntermediário da transferência de informação\\n_START_PARAGRAPH_\\nEm 1957 Elliot Volkin e Lawrence Astrachan fizeram uma observação significativa. Eles descobriram que uma das mais marcantes mudanças\",\n                \"ru\": \"\\n_START_ARTICLE_\\nАрнольд, Ремо\\n_START_SECTION_\\nКлубная карьера\\n_START_PARAGRAPH_\\nАрнольд перешёл в академию «Люцерна» в 12 лет. С 2014 года выступал за вторую команду, где провёл пятнадцать встреч. С сезона 2015/2016 находится в составе основной команды. 27 сентября 2015 года дебютировал\",\n                \"es\": \"\\n_START_ARTICLE_\\n(200012) 2007 LK20\\n_START_SECTION_\\nDesignación y nombre\\n_START_PARAGRAPH_\\nDesignado provisionalmente como 2007 LK20.\\n_START_SECTION_\\nCaracterísticas orbitales\\n_START_PARAGRAPH_\\n2007 LK20\",\n                \"th\": \"\\n_START_ARTICLE_\\nการนัดหยุดเรียนเพื่อภูมิอากาศ\\n_START_SECTION_\\nเกรียตา ทืนแบร์ย\\n_START_PARAGRAPH_\\nวันที่ 20 สิงหาคม 2561 เกรียตา ทืนแบร์ย นักกิจกรรมภูมิอากาศชาวสวีเดน ซึ่งขณะนั้นศึกษาอยู่ในชั้นเกรด 9 (เทียบเท่ามัธยมศึกษาปีที่ 3) ตัดสินใจไม่เข้าเรียนจนกระทั่งการเลือกตั้งทั่วไปในประเทศสวีเดนปี\",\n                \"tr\": \"\\n_START_ARTICLE_\\nİsrail'in Muhafazakar Dostları\\n_START_SECTION_\\nFaaliyetleri\\n_START_PARAGRAPH_\\nGrubun 2005 stratejisi ile aşağıdaki faaliyet alanları tespit edilmiştir:_NEWLINE_İsrail'i destekleme\",\n                \"bg\": \"\\n_START_ARTICLE_\\nАвтомобил с повишена проходимост\\n_START_SECTION_\\nОсобености на конструкцията\\n_START_PARAGRAPH_\\nВ исторически план леки автомобили с висока проходимост се произвеждат и имат военно\",\n                \"ca\": \"\\n_START_ARTICLE_\\nAuchy-la-Montagne\\n_START_SECTION_\\nPoblació\\n_START_PARAGRAPH_\\nEl 2007 la població de fet d'Auchy-la-Montagne era de 469 persones. Hi havia 160 famílies de les quals 28\",\n                \"cs\": \"\\n_START_ARTICLE_\\nŘemeslo\\n_START_PARAGRAPH_\\nŘemeslo je určitý druh manuální dovednosti, provozovaný za účelem obživy, resp. vytváření zisku. Pro řemeslné práce je charakteristický vysoký podíl ruční práce, spojený s používáním specializovaných nástrojů a pomůcek. Řemeslné práce\",\n                \"da\": \"\\n_START_ARTICLE_\\nÖrenäs slot\\n_START_PARAGRAPH_\\nÖrenäs slot (svensk: Örenäs slott) er et slot nær Glumslöv i Landskrona stad tæt på Øresunds-kysten i Skåne i Sverige._NEWLINE_Örenäs ligger\",\n                \"el\": \"\\n_START_ARTICLE_\\nΆλβαρο Ρεκόμπα\\n_START_SECTION_\\nΒιογραφικά στοιχεία\\n_START_PARAGRAPH_\\nΟ Άλβαρο Ρεκόμπα γεννήθηκε στις 17 Μαρτίου 1976 στο Μοντεβίδεο της Ουρουγουάης από\",\n                \"et\": \"\\n_START_ARTICLE_\\nAus deutscher Geistesarbeit\\n_START_PARAGRAPH_\\nAus deutscher Geistesarbeit (alapealkiri Wochenblatt für wissenschaftliche und kulturelle Fragen der Gegenwart) oli ajakiri, mis 1924–1934 ilmus Tallinnas. Ajakirja andis 1932–1934\",\n                \"fa\": \"\\n_START_ARTICLE_\\nتفسیر بغوی\\n_START_PARAGRAPH_\\nایرانی حسین بن مسعود بغوی است. این کتاب خلاصه ای از تفسیر الکشف و البیان عن تفسیر القرآن ابواسحاق احمد ثعلبی می‌باشد. این کتاب در ۴ جلد موجود می‌باش\",\n                \"fi\": \"\\n_START_ARTICLE_\\nBovesin verilöyly\\n_START_SECTION_\\nVerilöyly\\n_START_PARAGRAPH_\\n19. syyskuuta 1943 partisaaniryhmä saapui Bovesiin tarkoituksenaan ostaa leipää kylästä. Kylässä sattui olemaan kaksi SS-miestä, jotka\",\n                \"he\": \"\\n_START_ARTICLE_\\nאוגדה 85\\n_START_SECTION_\\nהיסטוריה\\n_START_PARAGRAPH_\\nהאוגדה הוקמה בהתחלה כמשלט העמקים בשנות השבעים. בשנות השמונים הפכה להיות אוגדה מרחבית עם שתי\",\n                \"hi\": \"\\n_START_ARTICLE_\\nऑडी\\n_START_SECTION_\\nऑडी इंडिया\\n_START_PARAGRAPH_\\nऑडी इंडिया की स्थापना मार्च 2007 में फोक्सवैगन ग्रुप सेल्स इंडिया के एक विभाजन के रूप में की गई थी। दुनिया भर में 110\",\n                \"hr\": \"\\n_START_ARTICLE_\\nČimariko (jezična porodica)\\n_START_PARAGRAPH_\\nChimarikan.-porodica sjevernoameričkih indijanskih jezika koja prema Powersu obuhvaća jezike Indijanaca Chimariko (Chemaŕeko) sa rijeke Trinity i Chimalakwe\",\n                \"hu\": \"\\n_START_ARTICLE_\\nÁllami Politikai Igazgatóság\\n_START_PARAGRAPH_\\nAz Állami Politikai Igazgatóság (rövidítve: GPU, oroszul: Государственное политическое управление), majd később Egyesített Állami Politikai Igazgatóság Szovjet-Oroszország\",\n                \"id\": \"\\n_START_ARTICLE_\\n(257195) 2008 QY41\\n_START_SECTION_\\nPembentukan\\n_START_PARAGRAPH_\\nSeperti asteroid secara keseluruhan, asteroid ini terbentuk dari nebula matahari primordial sebagai pecahan planetisimal, sesuatu di\",\n                \"lt\": \"\\n_START_ARTICLE_\\nŠavijos–Uardigo regionas\\n_START_SECTION_\\nGeografija\\n_START_PARAGRAPH_\\nŠavijos-Uardigo regionas yra Atlanto vandenynu pakrantės lygumoje\",\n                \"lv\": \"\\n_START_ARTICLE_\\nApatīts\\n_START_SECTION_\\nĪpašības\\n_START_PARAGRAPH_\\nApatīta kopējā ķīmiskā formula ir Ca₁₀(PO₄)₆(OH,F,Cl)₂, ir trīs atšķirīgi apatīta veidi: apatīts: Ca₁₀(PO₄)₆(OH)₂, fluorapatīts Ca₁₀(PO₄)₆(F)₂ un hlorapatīts: Ca₁₀(PO₄)₆(Cl)₂. Pēc sastāva\",\n                \"ms\": \"\\n_START_ARTICLE_\\nEdward C. Prescott\\n_START_PARAGRAPH_\\nEdward Christian Prescott (lahir 26 Disember 1940) ialah seorang ahli ekonomi Amerika. Beliau menerima Hadiah Peringatan Nobel dalam Sains Ekonomi pada tahun 2004, berkongsi\",\n                \"no\": \"\\n_START_ARTICLE_\\nAl-Minya\\n_START_SECTION_\\nEtymologi\\n_START_PARAGRAPH_\\nDet er sprikende forklaringer på bynavnet. Det kan komme fra gammelegyptisk Men'at Khufu, i betydning byen hvor Khufu ble ammet, noe som knytter byen til farao Khufu (Keops), som\",\n                \"ro\": \"\\n_START_ARTICLE_\\nDealurile Cernăuțiului\\n_START_PARAGRAPH_\\nDealurile Cernăuțiului sunt un lanț deluros striat, care se întinde în partea centrală a interfluviului dintre Prut și Siret, în cadrul regiunii Cernăuți din\",\n                \"sk\": \"\\n_START_ARTICLE_\\n10. peruť RAAF\\n_START_PARAGRAPH_\\n10. peruť RAAF je námorná hliadkovacia peruť kráľovských austrálskych vzdušných síl (Royal Australian Air Force – RAAF) založená na základni Edinburgh v Južnej Austrálii ako súčasť 92\",\n                \"sl\": \"\\n_START_ARTICLE_\\n105 Artemida\\n_START_SECTION_\\nOdkritje\\n_START_PARAGRAPH_\\nAsteroid je 16. septembra 1868 odkril James Craig Watson (1838 – 1880). Poimenovan je po Artemidi, boginji Lune iz grške\",\n                \"sr\": \"\\n_START_ARTICLE_\\nЉанос Морелос 1. Сексион (Истапангахоја)\\n_START_SECTION_\\nСтановништво\\n_START_PARAGRAPH_\\nПрема подацима из 2010. године у насељу је живело 212\",\n                \"sv\": \"\\n_START_ARTICLE_\\nÖstra Torps landskommun\\n_START_SECTION_\\nAdministrativ historik\\n_START_PARAGRAPH_\\nKommunen bildades i Östra Torps socken i Vemmenhögs härad i Skåne när 1862 års kommunalförordningar trädde i kraft. _NEWLINE_Vid kommunreformen\"\n}\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing UCF101 Dataset\nDESCRIPTION: This code loads the list of videos from the UCF101 dataset, categorizes them, and prints a summary of the available categories and videos.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/action_recognition_with_tf_hub.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nucf_videos = list_ucf_videos()\n  \ncategories = {}\nfor video in ucf_videos:\n  category = video[2:-12]\n  if category not in categories:\n    categories[category] = []\n  categories[category].append(video)\nprint(\"Found %d videos in %d categories.\" % (len(ucf_videos), len(categories)))\n\nfor category, sequences in categories.items():\n  summary = \", \".join(sequences[:2])\n  print(\"%-20s %4d videos (%s, ...)\" % (category, len(sequences), summary))\n```\n\n----------------------------------------\n\nTITLE: License Headers - TensorFlow and MIT\nDESCRIPTION: License declarations for the TensorFlow tutorial code, including both Apache 2.0 and MIT licenses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\nLANGUAGE: python\nCODE:\n```\n#@title MIT License\n#\n# Copyright (c) 2017 François Chollet\n#\n# Permission is hereby granted, free of charge, to any person obtaining a\n# copy of this software and associated documentation files (the \"Software\"),\n# to deal in the Software without restriction, including without limitation\n# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n# and/or sell copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n```\n\n----------------------------------------\n\nTITLE: Training a Keras Model\nDESCRIPTION: This snippet trains a Keras model using the `fit` method. It feeds the training images and labels to the model for a specified number of epochs. The `train_images` and `train_labels` are the input data, and `epochs` determines how many times the training data is iterated through.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(train_images, train_labels, epochs=5)\n```\n\n----------------------------------------\n\nTITLE: Configuring MKL Environment Variables in Python\nDESCRIPTION: This Python snippet shows how to configure Intel MKL-related environment variables within a Python script using the 'os.environ' dictionary to set 'KMP_BLOCKTIME', 'KMP_AFFINITY', 'KMP_SETTINGS', and optionally 'OMP_NUM_THREADS' based on command-line flags.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"KMP_BLOCKTIME\"] = str(FLAGS.kmp_blocktime)\nos.environ[\"KMP_SETTINGS\"] = str(FLAGS.kmp_settings)\nos.environ[\"KMP_AFFINITY\"]= FLAGS.kmp_affinity\nif FLAGS.num_intra_threads > 0:\n  os.environ[\"OMP_NUM_THREADS\"]= str(FLAGS.num_intra_threads)\n```\n\n----------------------------------------\n\nTITLE: Creating a Complex RaggedTensor for Conversation Data in TensorFlow\nDESCRIPTION: This example creates a complex ragged tensor representing conversation data with multiple levels of nesting. It demonstrates the concept of ragged rank and flat values in a practical scenario.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_58\n\nLANGUAGE: python\nCODE:\n```\n# shape = [batch, (paragraph), (sentence), (word)]\nconversations = tf.ragged.constant(\n    [[[[\"I\", \"like\", \"ragged\", \"tensors.\"]],\n      [[\"Oh\", \"yeah?\"], [\"What\", \"can\", \"you\", \"use\", \"them\", \"for?\"]],\n      [[\"Processing\", \"variable\", \"length\", \"data!\"]]],\n     [[\"I\", \"like\", \"cheese.\"], [\"Do\", \"you?\"]],\n      [[\"Yes.\"], [\"I\", \"do.\"]]])\nconversations.shape\n```\n\n----------------------------------------\n\nTITLE: Executing the Distributed Training Loop\nDESCRIPTION: Implements the main training loop that initializes variables and iterators, then trains the model for the specified number of epochs while reporting progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  train_iterator = train_ds.make_initializable_iterator()\n  iterator_init = train_iterator.initializer\n  var_init = tf.global_variables_initializer()\n  loss = train_step(next(train_iterator))\n  with tf.Session() as sess:\n    sess.run([var_init])\n    for epoch in range(EPOCHS):\n        sess.run([iterator_init])\n        for step in range(10000):\n          if step % 1000 == 0:\n            print('Epoch {} Step {} Loss {:.4f}'.format(epoch+1,\n                                                        step,\n                                                        sess.run(loss)))\n```\n\n----------------------------------------\n\nTITLE: Loading MNIST Dataset using Keras in TensorFlow\nDESCRIPTION: This code uses `tf.keras.datasets.mnist.load_data()` to download and load the MNIST dataset. The dataset is split into training and testing sets, with images and labels for each set. This data is required for the in-graph training loop example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n```\n\n----------------------------------------\n\nTITLE: Assertion Tests for Partial Migration\nDESCRIPTION: Performs NumPy assertion tests to verify that the partially migrated model's outputs and regularization losses precisely match the original model, confirming that the migration hasn't altered the model's behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Verify that the regularization loss and output both match\nnp.testing.assert_allclose(original_regularization_loss.numpy(), migrated_regularization_loss.numpy())\nnp.testing.assert_allclose(original_output.numpy(), migrated_output.numpy())\n```\n\n----------------------------------------\n\nTITLE: Running Custom Training Loop with Mixed Precision in TensorFlow\nDESCRIPTION: Executes the complete custom training loop for a mixed precision model, including training steps, evaluation, and metrics tracking. This loop runs for 5 epochs using the previously defined train_step and test_step functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfor epoch in range(5):\n  epoch_loss_avg = tf.keras.metrics.Mean()\n  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n      name='test_accuracy')\n  for x, y in train_dataset:\n    loss = train_step(x, y)\n    epoch_loss_avg(loss)\n  for x, y in test_dataset:\n    predictions = test_step(x)\n    test_accuracy.update_state(y, predictions)\n  print('Epoch {}: loss={}, test accuracy={}'.format(epoch, epoch_loss_avg.result(), test_accuracy.result()))\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow 1 Estimator for Fault Tolerance\nDESCRIPTION: Setting up a DNNClassifier with RunConfig that saves checkpoints every step, enabling automatic recovery after training interruptions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfeature_columns = [tf1.feature_column.numeric_column(\"x\", shape=[28, 28])]\nconfig = tf1.estimator.RunConfig(save_summary_steps=1,\n                                 save_checkpoints_steps=1)\n\npath = tempfile.mkdtemp()\n\nclassifier = tf1.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf1.train.AdamOptimizer(0.001),\n    n_classes=10,\n    dropout=0.2,\n    model_dir=path,\n    config = config\n)\n\ntrain_input_fn = tf1.estimator.inputs.numpy_input_fn(\n    x={\"x\": x_train},\n    y=y_train.astype(np.int32),\n    num_epochs=10,\n    batch_size=50,\n    shuffle=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Metrics Plotting Function for Model Evaluation\nDESCRIPTION: Function that visualizes training and validation metrics (loss or accuracy) across epochs to evaluate model performance and convergence, with proper labeling and formatting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef plot_metrics(train_metric, val_metric, metric_type):\n  # Visualize metrics vs training Epochs\n  plt.figure()\n  plt.plot(range(len(train_metric)), train_metric, label = f\"Training {metric_type}\")\n  plt.plot(range(len(val_metric)), val_metric, label = f\"Validation {metric_type}\")\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(metric_type)\n  plt.legend()\n  plt.title(f\"{metric_type} vs Training epochs\");\n```\n\n----------------------------------------\n\nTITLE: Creating Validation Set from Training Data in Python\nDESCRIPTION: This code creates a validation set by splitting the original training data. It reserves the first 10,000 examples for validation and uses the rest for training. This allows for model evaluation on unseen data during the training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx_val = train_examples[:10000]\npartial_x_train = train_examples[10000:]\n\ny_val = train_labels[:10000]\npartial_y_train = train_labels[10000:]\n```\n\n----------------------------------------\n\nTITLE: Training and Visualizing a CART Model with TensorFlow Decision Forests\nDESCRIPTION: This snippet demonstrates how to create, train, and visualize a CART (Classification and Regression Tree) model using TensorFlow Decision Forests. CART models are particularly useful for model interpretation and are visualized with a depth-limited plot.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Train a CART model\ncart_model = tfdf.keras.CartModel()\ncart_model.fit(train_dataset)\n\n# Plot the CART model\ntfdf.model_plotter.plot_model_in_colab(cart_model, max_depth=2)\n```\n\n----------------------------------------\n\nTITLE: Performing Matrix Multiplication on a TPU Device\nDESCRIPTION: Demonstrates manual device placement by executing a matrix multiplication operation on a specific TPU device using the 'with tf.device()' context manager.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n\nwith tf.device('/TPU:0'):\n  c = tf.matmul(a, b)\n\nprint(\"c device: \", c.device)\nprint(c)\n```\n\n----------------------------------------\n\nTITLE: Creating Module with Generator for SavedModel\nDESCRIPTION: Defines a TensorFlow Module that contains a random number generator and exposes methods to generate random numbers and access the generator's state, configured within a distribution strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfilename = \"./saved_model\"\n\nclass MyModule(tf.Module):\n\n  def __init__(self):\n    super(MyModule, self).__init__()\n    self.g = tf.random.Generator.from_seed(0)\n\n  @tf.function\n  def __call__(self):\n    return self.g.normal([])\n\n  @tf.function\n  def state(self):\n    return self.g.state\n\nstrat = tf.distribute.MirroredStrategy(devices=[\"cpu:0\", \"cpu:1\"])\nwith strat.scope():\n  m = MyModule()\n  print(strat.run(m))\n  print(\"state:\", m.state())\n```\n\n----------------------------------------\n\nTITLE: Comparing Vectorized vs. Unvectorized Computation\nDESCRIPTION: Benchmarks vectorized computation against unvectorized sequential computation using tf.map_fn, demonstrating the performance advantages of vectorization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Benchmark the vectorized computation above and compare with\n# unvectorized sequential computation using `tf.map_fn`.\n@tf.function\ndef unvectorized_per_example_gradients(inputs, labels):\n  def single_example_gradient(arg):\n    inp, label = arg\n    return compute_gradients(model,\n                             tnp.expand_dims(inp, 0),\n                             tnp.expand_dims(label, 0))\n\n  return tf.map_fn(single_example_gradient, (inputs, labels),\n                   fn_output_signature=(tf.float32, tf.float32, tf.float32))\n\nprint(\"Running vectorized computation\")\nprint(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),\n                    number=10) * 100, \"ms\")\n\nprint(\"\\nRunning unvectorized computation\")\nper_example_gradients = unvectorized_per_example_gradients(inputs, labels)\nprint(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),\n                    number=10) * 100, \"ms\")\n```\n\n----------------------------------------\n\nTITLE: Creating Crossed Feature Columns for Location Data in TensorFlow\nDESCRIPTION: Shows how to create crossed feature columns combining latitude and longitude data for location-based predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef make_dataset(latitude, longitude, labels):\n    assert latitude.shape == longitude.shape == labels.shape\n\n    features = {'latitude': latitude.flatten(),\n                'longitude': longitude.flatten()}\n    labels=labels.flatten()\n\n    return tf.data.Dataset.from_tensor_slices((features, labels))\n\n\n# Bucketize the latitude and longitude using the `edges`\nlatitude_bucket_fc = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('latitude'),\n    list(atlanta.latitude.edges))\n\nlongitude_bucket_fc = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('longitude'),\n    list(atlanta.longitude.edges))\n\n# Cross the bucketized columns, using 5000 hash bins.\ncrossed_lat_lon_fc = tf.feature_column.crossed_column(\n    [latitude_bucket_fc, longitude_bucket_fc], 5000)\n\nfc = [\n    latitude_bucket_fc,\n    longitude_bucket_fc,\n    crossed_lat_lon_fc]\n\n# Build and train the Estimator.\nest = tf.estimator.LinearRegressor(fc, ...)\n```\n\n----------------------------------------\n\nTITLE: Broadcasting 1D tensor with deeply nested 3D RaggedTensor in TensorFlow\nDESCRIPTION: Shows how a 1D tensor with shape (3) is broadcast to the innermost dimension of a 3D ragged tensor with ragged_rank=2, resulting in a 3D ragged tensor with expanded innermost dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# x      (3d ragged):  2 x (r1) x (r2) x 1\n# y      (1d tensor):                    3\n# Result (3d ragged):  2 x (r1) x (r2) x 3\nx = tf.ragged.constant(\n    [\n        [\n            [[1], [2]],\n            [],\n            [[3]],\n            [[4]],\n        ],\n        [\n            [[5], [6]],\n            [[7]]\n        ]\n    ],\n    ragged_rank=2)\ny = tf.constant([10, 20, 30])\nprint(x + y)\n```\n\n----------------------------------------\n\nTITLE: Defining Model Function for Estimator in Python\nDESCRIPTION: This function defines a model for use with an Estimator. It creates a Net instance, sets up optimization, and handles checkpointing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef model_fn(features, labels, mode):\n  net = Net()\n  opt = tf.keras.optimizers.Adam(0.1)\n  ckpt = tf.train.Checkpoint(step=tf_compat.train.get_global_step(),\n                             optimizer=opt, net=net)\n  with tf.GradientTape() as tape:\n    output = net(features['x'])\n    loss = tf.reduce_mean(tf.abs(output - features['y']))\n  variables = net.trainable_variables\n  gradients = tape.gradient(loss, variables)\n  return tf.estimator.EstimatorSpec(\n    mode,\n    loss=loss,\n    train_op=tf.group(opt.apply_gradients(zip(gradients, variables)),\n                      ckpt.step.assign_add(1)),\n    # Tell the Estimator to save \"ckpt\" in an object-based format.\n    scaffold=tf_compat.train.Scaffold(saver=ckpt))\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Defines the Apache License 2.0 terms as a Python comment block. This establishes the licensing terms under which the code can be used, modified, and distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Listing Checkpoint Files in Directory\nDESCRIPTION: Uses a system command to list the files in the checkpoint directory, showing the actual files created by the CheckpointManager.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n!ls ./tf_ckpts\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow License for Documentation\nDESCRIPTION: A Python code block displaying the Apache License 2.0 that applies to this TensorFlow documentation. This appears as a form element in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Metrics in TensorFlow\nDESCRIPTION: These snippets create plots for accuracy and loss curves during training and validation, using matplotlib. They visualize the model's performance over epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Evaluating CNN Performance\nDESCRIPTION: Plot training history and evaluate model on test data\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Input Function in TensorFlow\nDESCRIPTION: Example implementation of an input function that returns features and labels for model evaluation. Demonstrates the basic structure of feature dictionary and label array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef input_evaluation_set():\n    features = {'SepalLength': np.array([6.4, 5.0]),\n                'SepalWidth':  np.array([2.8, 2.3]),\n                'PetalLength': np.array([5.6, 3.3]),\n                'PetalWidth':  np.array([2.2, 1.0])}\n    labels = np.array([2, 1])\n    return features, labels\n```\n\n----------------------------------------\n\nTITLE: Implementing Shape Function for Polymorphic Op in C++\nDESCRIPTION: This snippet demonstrates a shape function for a polymorphic operation with multiple inputs in C++. It validates that all inputs have rank 2 and merges their shapes to determine the output shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_52\n\nLANGUAGE: c++\nCODE:\n```\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n  ::tensorflow::shape_inference::ShapeHandle input;\n  ::tensorflow::shape_inference::ShapeHandle output;\n  for (size_t i = 0; i < c->num_inputs(); ++i) {\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 2, &input));\n    TF_RETURN_IF_ERROR(c->Merge(output, input, &output));\n  }\n  c->set_output(0, output);\n  return Status::OK();\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for MoveNet Pose Detection\nDESCRIPTION: Installs necessary Python libraries including imageio, opencv-python, and TensorFlow documentation tools for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q imageio\n!pip install -q opencv-python\n!pip install -q git+https://github.com/tensorflow/docs\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip for TensorFlow Installation\nDESCRIPTION: Command to upgrade pip to the latest version, ensuring compatibility with TensorFlow installation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Running Inference and Visualizing Results with HRNet Model\nDESCRIPTION: Displays the input image, runs inference to generate predictions and features, and visualizes both a prediction class map and a feature map using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nplt.imshow(img)\nplt.show()\n\n# Predictions will have shape (batch_size, h, w, dataset_output_classes)\npredictions = hrnet_model.predict([img])\nplt.imshow(predictions[0,:,:,1])\nplt.title('Predictions for class #1')\nplt.show() \n# Features will have shape (batch_size, h/4, w/4, 720)\nfeatures = hrnet_model.get_features([img])\nplt.imshow(features[0,:,:,1])\nplt.title('Feature #1 out of 720')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Implementing Continue Statement with AutoGraph\nDESCRIPTION: Shows how AutoGraph handles a function with a continue statement in a loop. This function sums even numbers in a list, skipping odd numbers with continue.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Continue in a loop\ndef sum_even(items):\n  s = 0\n  for c in items:\n    if c % 2 > 0:\n      continue\n    s += c\n  return s\n\nprint('Eager result: %d' % sum_even(tf.constant([10,12,15,20])))\n\ntf_sum_even = tf.autograph.to_graph(sum_even)\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    print('Graph result: %d\\n\\n' % sess.run(tf_sum_even(tf.constant([10,12,15,20]))))\n```\n\n----------------------------------------\n\nTITLE: Testing Converted and Reloaded JAX Model\nDESCRIPTION: Tests the converted JAX model and the reloaded SavedModel to ensure they produce the same predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Converted function predictions:\", np.argmax(m.predict(x).numpy(), axis=-1))\nreloaded_model = tf.saved_model.load(\"./\")\nprint(\"Reloaded  function predictions:\", np.argmax(reloaded_model.predict(x).numpy(), axis=-1))\n```\n\n----------------------------------------\n\nTITLE: Specifying Communication Options for MultiWorkerMirroredStrategy in TensorFlow\nDESCRIPTION: Demonstrates how to specify communication options for MultiWorkerMirroredStrategy. This example uses NCCL for collective communication, which can be optimal for GPU-based setups.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ncommunication_options=tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)\n```\n\n----------------------------------------\n\nTITLE: Parsing CSV Lines as Strings with tf.io.decode_csv\nDESCRIPTION: This code demonstrates how to use the low-level tf.io.decode_csv function to parse CSV lines as strings. It displays the type and shape of each resulting feature column.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nfeatures = tf.io.decode_csv(lines, record_defaults=all_strings) \n\nfor f in features:\n  print(f\"type: {f.dtype.name}, shape: {f.shape}\")\n```\n\n----------------------------------------\n\nTITLE: Generating Samples using BigBiGAN\nDESCRIPTION: Generates image samples from random latent vectors using the trained BigBiGAN generator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfeed_dict = {gen_ph: np.random.randn(32, 120)}\n_out_samples = sess.run(gen_samples, feed_dict=feed_dict)\nprint('samples shape:', _out_samples.shape)\nimshow(imgrid(image_to_uint8(_out_samples), cols=4))\n```\n\n----------------------------------------\n\nTITLE: Creating TFRecord Example from Image Data in Python\nDESCRIPTION: This function creates a TensorFlow Example from an image string and label. It extracts image features like height, width, depth, and includes the raw image data and label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef image_example(image_string, label):\n  image_shape = tf.image.decode_jpeg(image_string).shape\n\n  feature = {\n      'height': _int64_feature(image_shape[0]),\n      'width': _int64_feature(image_shape[1]),\n      'depth': _int64_feature(image_shape[2]),\n      'label': _int64_feature(label),\n      'image_raw': _bytes_feature(image_string),\n  }\n\n  return tf.train.Example(features=tf.train.Features(feature=feature))\n```\n\n----------------------------------------\n\nTITLE: Converting Keras Model to TensorFlow Estimator\nDESCRIPTION: Creates a temporary directory for model artifacts and converts the Keras model to a TensorFlow Estimator using the model_to_estimator function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\nmodel_dir = tempfile.mkdtemp()\nkeras_estimator = tf.keras.estimator.model_to_estimator(\n    keras_model=model, model_dir=model_dir)\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Default Attributes of All Types (C++)\nDESCRIPTION: This code shows how to define default values for attributes of various types, including string, int, float, bool, type, shape, tensor, and lists of integers.  It illustrates the syntax required to specify these defaults within the `Attr` method during op registration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_19\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"AttrDefaultExampleForAllTypes\")\n   .Attr(\"s: string = 'foo'\")\n   .Attr(\"i: int = 0\")\n   .Attr(\"f: float = 1.0\")\n   .Attr(\"b: bool = true\")\n   .Attr(\"ty: type = DT_INT32\")\n   .Attr(\"sh: shape = { dim { size: 1 } dim { size: 2 } }\")\n   .Attr(\"te: tensor = { dtype: DT_INT32 int_val: 5 }\")\n   .Attr(\"l_empty: list(int) = []\")\n   .Attr(\"l_int: list(int) = [2, 3, 5, 7]\");\n```\n\n----------------------------------------\n\nTITLE: Custom Extension Type Definitions\nDESCRIPTION: Defines custom TensorFlow extension types including TensorGraph, MaskedTensor and CSRSparseMatrix\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass TensorGraph(tf.experimental.ExtensionType):\n  \"\"\"A collection of labeled nodes connected by weighted edges.\"\"\"\n  edge_weights: tf.Tensor               # shape=[num_nodes, num_nodes]\n  node_labels: Mapping[str, tf.Tensor]  # shape=[num_nodes]; dtype=any\n\nclass MaskedTensor(tf.experimental.ExtensionType):\n  \"\"\"A tensor paired with a boolean mask, indicating which values are valid.\"\"\"\n  values: tf.Tensor\n  mask: tf.Tensor       # shape=values.shape; false for missing/invalid values.\n\nclass CSRSparseMatrix(tf.experimental.ExtensionType):\n  \"\"\"Compressed sparse row matrix (https://en.wikipedia.org/wiki/Sparse_matrix).\"\"\"\n  values: tf.Tensor     # shape=[num_nonzero]; dtype=any\n  col_index: tf.Tensor  # shape=[num_nonzero]; dtype=int64\n  row_index: tf.Tensor  # shape=[num_rows+1]; dtype=int64\n```\n\n----------------------------------------\n\nTITLE: Initializing Checkpoint Manager for DTensor Model in Python\nDESCRIPTION: This function sets up a checkpoint manager for a DTensor model. It creates a checkpoint, initializes a manager, and either restores from the latest checkpoint or starts a new training session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nCHECKPOINT_DIR = tempfile.mkdtemp()\n\ndef start_checkpoint_manager(model):\n  ckpt = tf.train.Checkpoint(root=model)\n  manager = tf.train.CheckpointManager(ckpt, CHECKPOINT_DIR, max_to_keep=3)\n\n  if manager.latest_checkpoint:\n    print(\"Restoring a checkpoint\")\n    ckpt.restore(manager.latest_checkpoint).assert_consumed()\n  else:\n    print(\"New training\")\n  return manager\n```\n\n----------------------------------------\n\nTITLE: Using Object Identity Comparison in TF2\nDESCRIPTION: Demonstrates how to compare tensor objects by identity in TensorFlow 2.0 using the 'is' operator instead of '=='.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.enable_tensor_equality()\nx = tf.Variable(0.0)\ny = tf.Variable(0.0)\n\nx is y\n```\n\n----------------------------------------\n\nTITLE: Metrics Visualization Function for DTensor Model Performance\nDESCRIPTION: A function to visualize training and testing metrics over epochs. It creates a plot showing the progression of specified metrics (like loss or accuracy) during the training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef plot_metrics(train_metric, test_metric, metric_type):\n  # Visualize metrics vs training Epochs\n  plt.figure()\n  plt.plot(range(len(train_metric)), train_metric, label = f\"Training {metric_type}\")\n  plt.plot(range(len(test_metric)), test_metric, label = f\"Testing {metric_type}\")\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(metric_type)\n  plt.legend()\n  plt.title(f\"{metric_type} vs Training Epochs\");\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Initializing License Header in Python\nDESCRIPTION: This code snippet defines the Apache License 2.0 header as a Python comment. It specifies the terms under which the software is distributed and the disclaimer of warranties.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Building Model within Strategy Scope\nDESCRIPTION: Using the strategy's scope to build the CNN model, which allows the strategy to control variable placement across devices and workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport mnist\nwith strategy.scope():\n  # Model building needs to be within `strategy.scope()`.\n  multi_worker_model = mnist.build_cnn_model()\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained Inception V1 Model from TensorFlow Hub\nDESCRIPTION: Creates a Keras Sequential model using a pre-trained Inception V1 image classifier from TensorFlow Hub. The model expects input shape (None, 224, 224, 3) and outputs logits for 1001 ImageNet classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        name='inception_v1',\n        handle='https://tfhub.dev/google/imagenet/inception_v1/classification/4',\n        trainable=False),\n])\nmodel.build([None, 224, 224, 3])\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Combined Type Attribute (C++)\nDESCRIPTION: This example shows how to combine lists and single types when defining type constraints for a `type` attribute. The `Attr` method specifies that the `t` attribute can be any numeric type or the `bool` type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_15\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"NumberOrBooleanType\")\n    .Attr(\"t: {numbertype, bool}\");\n```\n\n----------------------------------------\n\nTITLE: Displaying labeled examples from SciCite training set\nDESCRIPTION: This code retrieves and displays a specified number of labeled examples from the SciCite training set. It uses the previously defined Dataset class and displays the results in a pandas DataFrame.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nNUM_EXAMPLES = 20  #@param {type:\"integer\"}\ndata = get_example_data(THE_DATASET, NUM_EXAMPLES, for_eval=False)\ndisplay_df(\n    pd.DataFrame({\n        TEXT_FEATURE_NAME: [ex.decode('utf8') for ex in data[0]],\n        LABEL_NAME: [THE_DATASET.class_names()[x] for x in data[1]]\n    }))\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow with MKL Optimizations (v1.2.0 - v1.3.0)\nDESCRIPTION: Bash commands to compile TensorFlow with Intel MKL optimizations for versions 1.2.0 through 1.3.0. This includes the additional compile option for Eigen VML support required in these earlier versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./configure\nDo you wish to build TensorFlow with MKL support? [y/N] Y\nDo you wish to download MKL LIB from the web? [Y/n] Y\n# Select the defaults for the rest of the options.\n\nbazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -c opt //tensorflow/tools/pip_package:build_pip_package\n```\n\n----------------------------------------\n\nTITLE: DumpingDebugHook for Remote TensorFlow Estimators\nDESCRIPTION: This code snippet showcases how to initialize the `DumpingDebugHook` for TensorFlow Estimators to generate dump files for offline analysis. The debug data is stored in a specified directory, and each run corresponds to a Session.run() call. Dependencies include TensorFlow and tfdbg.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python import debug as tf_debug\n\nhooks = [tf_debug.DumpingDebugHook(\"/shared/storage/location/tfdbg_dumps_1\")]\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading TensorFlow Model with SavedModel API\nDESCRIPTION: Demonstrates how to save a trained TensorFlow model using tf.saved_model.save and load it back using tf.saved_model.load. It also shows how to use the loaded model for predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\nimport os\n\nmodels = tempfile.mkdtemp()\nsave_path = os.path.join(models, 'lin_reg_export')\ntf.saved_model.save(lin_reg_export, save_path)\n\nlin_reg_loaded = tf.saved_model.load(save_path)\ntest_preds = lin_reg_loaded(x_test)\ntest_preds[:10].numpy()\n```\n\n----------------------------------------\n\nTITLE: Accessing Tracked Variables and Regularization Losses in Python\nDESCRIPTION: This code snippet shows how to access the tracked variables and captured regularization losses of a converted Keras layer. It also demonstrates resetting variables to zero and calling the layer again to verify weight reuse.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlayer.trainable_variables\nlayer.losses\n\nprint(\"Resetting variables to zero:\", [var.name for var in layer.trainable_variables])\n\nfor var in layer.trainable_variables:\n  var.assign(var * 0.0)\n\nout = layer(x)\nprint(\"layer.losses: \", layer.losses)\nout\n```\n\n----------------------------------------\n\nTITLE: Implementing Early Stopping with TF1 Estimator Hook\nDESCRIPTION: Demonstrates early stopping in TensorFlow 1 using an early stopping hook that limits training time to 20 seconds. The hook is passed to train_and_evaluate with the Estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/early_stopping.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nestimator = tf1.estimator.Estimator(model_fn=_model_fn)\n\nstart_time = time.time()\nmax_train_seconds = 20\n\ndef should_stop_fn():\n  return time.time() - start_time > max_train_seconds\n\nearly_stopping_hook = tf1.estimator.experimental.make_early_stopping_hook(\n    estimator=estimator,\n    should_stop_fn=should_stop_fn,\n    run_every_secs=1,\n    run_every_steps=None)\n\ntrain_spec = tf1.estimator.TrainSpec(\n    input_fn=_input_fn,\n    hooks=[early_stopping_hook])\n\neval_spec = tf1.estimator.EvalSpec(input_fn=_eval_input_fn)\n\ntf1.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n```\n\n----------------------------------------\n\nTITLE: Repeating Dataset for Multiple Epochs with Dataset.repeat()\nDESCRIPTION: This snippet demonstrates how to use the `Dataset.repeat()` transformation to create a dataset that repeats its input for a specified number of epochs. This approach concatenates the data without signaling epoch boundaries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(...)\ndataset = dataset.repeat(10)\ndataset = dataset.batch(32)\n```\n\n----------------------------------------\n\nTITLE: License Declaration - MIT\nDESCRIPTION: MIT license declaration for François Chollet's contributions\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title MIT License\n#\n# Copyright (c) 2017 François Chollet\n#\n# Permission is hereby granted, free of charge, to any person obtaining a\n# copy of this software and associated documentation files (the \"Software\"),\n# to deal in the Software without restriction, including without limitation\n# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n# and/or sell copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n```\n\n----------------------------------------\n\nTITLE: Implementing (2+1)D Convolution Layer\nDESCRIPTION: Custom Keras layer that implements (2+1)D convolution by decomposing 3D convolution into separate spatial and temporal operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/video_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Conv2Plus1D(keras.layers.Layer):\n  def __init__(self, filters, kernel_size, padding):\n    \"\"\"\n      A sequence of convolutional layers that first apply the convolution operation over the\n      spatial dimensions, and then the temporal dimension. \n    \"\"\"\n    super().__init__()\n    self.seq = keras.Sequential([  \n        # Spatial decomposition\n        layers.Conv3D(filters=filters,\n                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n                      padding=padding),\n        # Temporal decomposition\n        layers.Conv3D(filters=filters, \n                      kernel_size=(kernel_size[0], 1, 1),\n                      padding=padding)\n        ])\n  \n  def call(self, x):\n    return self.seq(x)\n```\n\n----------------------------------------\n\nTITLE: Image Preprocessing and Label Extraction Helper Functions\nDESCRIPTION: Creates helper functions for preprocessing input images to the format required by MobileNetV2 and extracting class labels from probability vectors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Helper function to preprocess the image so that it can be inputted in MobileNetV2\ndef preprocess(image):\n  image = tf.cast(image, tf.float32)\n  image = tf.image.resize(image, (224, 224))\n  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n  image = image[None, ...]\n  return image\n\n# Helper function to extract labels from probability vector\ndef get_imagenet_label(probs):\n  return decode_predictions(probs, top=1)[0][0]\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor with uniform inner dimensions in TensorFlow\nDESCRIPTION: Shows how to create a RaggedTensor with uniform inner dimensions by using a multidimensional tensor for values. Each row has a variable number of elements, but each element is a fixed-size tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=[[1, 3], [0, 0], [1, 3], [5, 3], [3, 3], [1, 2]],\n    row_splits=[0, 3, 4, 6])\nprint(rt)\nprint(\"Shape: {}\".format(rt.shape))\nprint(\"Number of ragged dimensions: {}\".format(rt.ragged_rank))\n```\n\n----------------------------------------\n\nTITLE: Training the Bigger Model with Keras\nDESCRIPTION: Trains the previously defined `bigger_model` using the provided training data and labels. It fits the model for 20 epochs with a batch size of 512, using the test data as validation data and setting verbosity to 2 for detailed output during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nbigger_history = bigger_model.fit(train_data, train_labels,\n                                  epochs=20,\n                                  batch_size=512,\n                                  validation_data=(test_data, test_labels),\n                                  verbose=2)\n```\n\n----------------------------------------\n\nTITLE: Creating Tensor Values of Different Ranks\nDESCRIPTION: Demonstrates examples of tensor values with different ranks (dimensions). Shows a scalar (rank 0), vector (rank 1), matrix (rank 2), and a rank 3 tensor with their respective shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n3. # a rank 0 tensor; a scalar with shape [],\n[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]\n[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]\n```\n\n----------------------------------------\n\nTITLE: Visualizing Training Metrics with Matplotlib\nDESCRIPTION: Creates visualizations of the training loss and accuracy over time using matplotlib. The code generates a figure with two subplots showing how these metrics change during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Training Metrics')\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(train_loss_results)\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(train_accuracy_results)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Testing MLP Model with Replicated Layouts in Python\nDESCRIPTION: Creates an MLP model instance with fully replicated layouts and tests it with a sample input. This ensures the model runs correctly before applying more complex sharding strategies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nWORLD = dtensor.create_mesh([(\"world\", 8)], devices=DEVICES)\n\nmodel = MLP([dtensor.Layout.replicated(WORLD, rank=2),\n             dtensor.Layout.replicated(WORLD, rank=2)])\n\nsample_x, sample_y = train_data_vec.take(1).get_single_element()\nsample_x = dtensor.copy_to_mesh(sample_x, dtensor.Layout.replicated(WORLD, rank=2))\nprint(model(sample_x))\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Training Step with Loss Scaling in TensorFlow\nDESCRIPTION: Defines a custom training step function that properly handles loss scaling for mixed precision training. It uses the LossScaleOptimizer's methods to scale losses and unscale gradients to prevent numerical underflow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train_step(x, y):\n  with tf.GradientTape() as tape:\n    predictions = model(x)\n    loss = loss_object(y, predictions)\n    scaled_loss = optimizer.get_scaled_loss(loss)\n  scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n  gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n  return loss\n```\n\n----------------------------------------\n\nTITLE: Creating Named Component Datasets in TensorFlow\nDESCRIPTION: Shows how to create a dataset with named components using dictionaries. This approach allows for more readable code when working with datasets containing multiple features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(\n   {\"a\": tf.random_uniform([4]),\n    \"b\": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})\nprint(dataset.output_types)  # ==> \"{'a': tf.float32, 'b': tf.int32}\"\nprint(dataset.output_shapes)  # ==> \"{'a': (), 'b': (100,)}\"\n```\n\n----------------------------------------\n\nTITLE: Saving TF1 Checkpoint in TensorFlow 2.x\nDESCRIPTION: This code snippet shows how to save a TensorFlow 1.x style checkpoint in TensorFlow 2.x eager execution mode. It creates variables using tf.Variable and uses tf1.train.Saver to save the checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(1.0, name='a')\nb = tf.Variable(2.0, name='b')\nwith tf.name_scope('scoped'):\n  c = tf.Variable(3.0, name='c')\n\nsaver = tf1.train.Saver(var_list=[a, b, c])\npath = saver.save(sess=None, save_path='tf1-ckpt-saved-in-eager')\nprint_checkpoint(path)\n```\n\n----------------------------------------\n\nTITLE: Building MoViNet Classifier Function in TensorFlow\nDESCRIPTION: This function builds a MoViNet classifier on top of a backbone model. It takes parameters like batch size, number of frames, resolution, backbone model, and number of classes to construct the classifier.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n  model = movinet_model.MovinetClassifier(\n      backbone=backbone,\n      num_classes=num_classes)\n  model.build([batch_size, num_frames, resolution, resolution, 3])\n\n  return model\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Model with MobileNetV2 Base\nDESCRIPTION: Creates a sequential model that uses MobileNetV2 as a feature extractor, followed by global average pooling and a dense classification layer. The output layer has neurons matching the number of class labels with softmax activation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential([\n  mobile_net,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(len(label_names), activation = 'softmax')])\n```\n\n----------------------------------------\n\nTITLE: Applying Batching and Dropping Remainder in TensorFlow Dataset\nDESCRIPTION: This code demonstrates using `tf.data.Dataset.apply` along with `tf.contrib.data.batch_and_drop_remainder` to ensure batches of a fixed size in a dataset, effectively dropping the last batch if it doesn't meet the specified batch size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_tpu.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nparams = {'batch_size':32}\nds = tf.data.Dataset.from_tensors([0, 1, 2])\nds = ds.repeat().apply(\n    tf.contrib.data.batch_and_drop_remainder(params['batch_size']))\nds\n\n<DatasetV1Adapter shapes: (32, 3), types: tf.int32>\n```\n\n----------------------------------------\n\nTITLE: Training a Keras Model with tf.data Dataset\nDESCRIPTION: This code shows how to train a Keras model using a tf.data.Dataset. It creates a dataset from tensor slices, batches it, and repeats it indefinitely. The model is then fit to this dataset for 10 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Instantiates a toy dataset instance:\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\ndataset = dataset.batch(32)\ndataset = dataset.repeat()\n\n# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\nmodel.fit(dataset, epochs=10, steps_per_epoch=30)\n```\n\n----------------------------------------\n\nTITLE: Instantiating Custom Estimator for Iris Classification in TensorFlow\nDESCRIPTION: This code snippet demonstrates how to instantiate a custom Estimator for Iris classification. It specifies the model function and parameters including feature columns, hidden units, and number of classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Build 2 hidden layer DNN with 10, 10 units respectively.\nclassifier = tf.estimator.Estimator(\n    model_fn=my_model_fn,\n    params={\n        'feature_columns': my_feature_columns,\n        # Two hidden layers of 10 nodes each.\n        'hidden_units': [10, 10],\n        # The model must choose between 3 classes.\n        'n_classes': 3,\n    })\n```\n\n----------------------------------------\n\nTITLE: Sending a Classification Request to TensorFlow Serving via gRPC\nDESCRIPTION: Python code that demonstrates how to create a gRPC channel, initialize a prediction service stub, create a classification request with sample data, and send it to a TensorFlow Serving server with a timeout of 10 seconds.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom grpc.beta import implementations\n\nchannel = implementations.insecure_channel(host, int(port))\nstub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n\nrequest = classification_pb2.ClassificationRequest()\nexample = request.input.example_list.examples.add()\nexample.features.feature['x'].float_list.value.extend(image[0].astype(float))\n\nresult = stub.Classify(request, 10.0)  # 10 secs timeout\n```\n\n----------------------------------------\n\nTITLE: Creating a RaggedTensor with Multiple Ragged Dimensions Using Nested Row Splits\nDESCRIPTION: This code snippet shows how to create a RaggedTensor with multiple ragged dimensions using the from_nested_row_splits factory function. It directly provides a list of row_splits tensors to construct the ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_57\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_nested_row_splits(\n    flat_values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n    nested_row_splits=([0, 1, 1, 5], [0, 3, 3, 5, 9, 10]))\nprint(rt)\n```\n\n----------------------------------------\n\nTITLE: Accessing Attributes in TensorFlow Op Kernel Constructor\nDESCRIPTION: Implementation of a TensorFlow op kernel constructor that accesses and validates an attribute. This example retrieves the 'preserve_index' attribute and checks that it's a non-negative integer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_13\n\nLANGUAGE: c++\nCODE:\n```\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {\n    // Get the index of the value to preserve\n    OP_REQUIRES_OK(context,\n                   context->GetAttr(\"preserve_index\", &preserve_index_));\n    // Check that preserve_index is positive\n    OP_REQUIRES(context, preserve_index_ >= 0,\n                errors::InvalidArgument(\"Need preserve_index >= 0, got \",\n                                        preserve_index_));\n  }\n  void Compute(OpKernelContext* context) override {\n    // ...\n  }\n private:\n  int preserve_index_;\n};\n```\n\n----------------------------------------\n\nTITLE: Python Setuptools Uninstallation Error\nDESCRIPTION: Error message shown when unable to uninstall setuptools package due to permission issues\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nFound existing installation: setuptools 1.1.6\nUninstalling setuptools-1.1.6:\nException:\n...\n[Errno 1] Operation not permitted:\n'/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib'\n```\n\n----------------------------------------\n\nTITLE: Using Optimizers for Linear Models - TensorFlow Python\nDESCRIPTION: This snippet shows how to customize the LinearClassifier's optimization process by using a different optimizer, specifically the Follow-The-Regularized-Leader (FTRL) optimizer, along with setting learning rate and L2 regularization parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.FtrlOptimizer(learning_rate=5.0, l2_regularization_strength=1.0)\nestimator = tf.contrib.learn.LinearClassifier(\n    feature_columns=[image_column], n_classes=10, optimizer=optimizer)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow for Ragged Tensors\nDESCRIPTION: Imports the necessary libraries for working with ragged tensors in TensorFlow, using the compatibility mode for TensorFlow 1.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport math\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Implementing Similarity Matching Function in Python\nDESCRIPTION: This function uses the loaded ANNOY index to find similar items to a given embedding. It returns the mapped items (text) for the nearest neighbors found in the index.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef find_similar_items(embedding, num_matches=5):\n  '''Finds similar items to a given embedding in the ANN index'''\n  ids = index.get_nns_by_vector(\n  embedding, num_matches, search_k=-1, include_distances=False)\n  items = [mapping[i] for i in ids]\n  return items\n```\n\n----------------------------------------\n\nTITLE: Creating Flexible Dense Layer Module\nDESCRIPTION: Implements a flexible dense layer that defers variable creation until the first call, allowing dynamic input shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass FlexibleDenseModule(tf.Module):\n  def __init__(self, out_features, name=None):\n    super().__init__(name=name)\n    self.is_built = False\n    self.out_features = out_features\n\n  def __call__(self, x):\n    if not self.is_built:\n      self.w = tf.Variable(\n        tf.random.normal([x.shape[-1], self.out_features]), name='w')\n      self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n      self.is_built = True\n\n    y = tf.matmul(x, self.w) + self.b\n    return tf.nn.relu(y)\n```\n\n----------------------------------------\n\nTITLE: Training Loop Implementation\nDESCRIPTION: This snippet defines the training loop that uses the defined loss function to optimize the model's weights using gradient descent. It illustrates how to compute gradients and update the model's parameters iteratively.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef train(model, inputs, outputs, learning_rate):\n  with tf.GradientTape() as t:\n    current_loss = loss(model(inputs), outputs)\n  dW, db = t.gradient(current_loss, [model.W, model.b])\n  model.W.assign_sub(learning_rate * dW)\n  model.b.assign_sub(learning_rate * db)\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequential Model for Text Classification in TensorFlow\nDESCRIPTION: This function creates a Sequential model with a text embedding layer, followed by dense layers for classification. The model is compiled with sparse categorical crossentropy loss and Adam optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef create_model():\n  model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=[], dtype=tf.string),\n    embedding_layer,\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dense(16, activation=\"relu\"),\n    tf.keras.layers.Dense(5),\n  ])\n  model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n      optimizer=\"adam\", metrics=['accuracy'])\n  return model\n```\n\n----------------------------------------\n\nTITLE: Registering a Polymorphic Op with Multiple Type Support in TensorFlow\nDESCRIPTION: Demonstrates how to register an op that accepts both float and int32 data types by using an attribute to specify the input and output types. This allows the same op to work with different data types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_20\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: {float, int32}\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n```\n\n----------------------------------------\n\nTITLE: Compiling a TensorFlow Keras model with optimizer and loss function\nDESCRIPTION: Configures a model for training by specifying the optimizer, loss function, and metrics. Uses Adam optimizer and SparseCategoricalCrossentropy loss function which is appropriate for multi-class classification problems.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Dataset - Python\nDESCRIPTION: This snippet downloads a zip file containing a filtered version of the Dogs vs Cats dataset from Kaggle and extracts it. It ensures that the necessary data for training the model is available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nzip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\",\n                                   fname=\"cats_and_dogs_filtered.zip\", extract=True)\nbase_dir, _ = os.path.splitext(zip_file)\n```\n\n----------------------------------------\n\nTITLE: Training Input Function with Dataset API\nDESCRIPTION: Implementation of a training input function using TensorFlow's Dataset API. Converts features and labels into a Dataset object with shuffling, repeating, and batching capabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    return dataset.shuffle(1000).repeat().batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Loading Checkpoint with TF1 Saver\nDESCRIPTION: Demonstrates checkpoint loading using tf.compat.v1.train.Saver with variable name mapping in both graph and eager execution modes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith tf1.variable_scope('new_scope'):\n  a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                      initializer=tf1.zeros_initializer())\n  b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                      initializer=tf1.zeros_initializer())\n  c = tf1.get_variable('scoped/c', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\nsaver = tf1.train.Saver({'a': a, 'b': b, 'scoped/c': c})\nsaver.restore(sess=None, save_path='tf1-ckpt')\nprint(\"Restored [a, b, c]: \", [a.numpy(), b.numpy(), c.numpy()])\n```\n\n----------------------------------------\n\nTITLE: Testing Image Classification Model on Validation Data in TensorFlow\nDESCRIPTION: Tests the trained model on a sample image from the validation dataset, displaying the image and comparing the predicted class with the ground truth label.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nx, y = next(iter(val_ds))\nimage = x[0, :, :, :]\ntrue_index = np.argmax(y[0])\nplt.imshow(image)\nplt.axis('off')\nplt.show()\n\n# Expand the validation image to (1, 224, 224, 3) before predicting the label\nprediction_scores = model.predict(np.expand_dims(image, axis=0))\npredicted_index = np.argmax(prediction_scores)\nprint(\"True label: \" + class_names[true_index])\nprint(\"Predicted label: \" + class_names[predicted_index])\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub Model for Embedding Extraction in Python\nDESCRIPTION: Loads a TensorFlow Hub model for embedding extraction and sets up a function to generate embeddings for input queries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Load the TF-Hub model\nprint(\"Loading the TF-Hub model...\")\n%time embed_fn = hub.load(model_url)\nprint(\"TF-Hub model is loaded.\")\n\nrandom_projection_matrix = None\nif os.path.exists('random_projection_matrix'):\n  print(\"Loading random projection matrix...\")\n  with open('random_projection_matrix', 'rb') as handle:\n    random_projection_matrix = pickle.load(handle)\n  print('random projection matrix is loaded.')\n\ndef extract_embeddings(query):\n  '''Generates the embedding for the query'''\n  query_embedding =  embed_fn([query])[0].numpy()\n  if random_projection_matrix is not None:\n    query_embedding = query_embedding.dot(random_projection_matrix)\n  return query_embedding\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Optimizers with tf.function in Python\nDESCRIPTION: Example showing how to create separate tf.function instances for different optimizers in a training loop. The code alternates between two different optimizers using a conditional statement based on iteration count.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\n# Make a new tf.function and ConcreteFunction for each optimizer.\ntrain_step_1 = tf.function(train_step)\ntrain_step_2 = tf.function(train_step)\nfor i in range(10):\n  if i % 2 == 0:\n    train_step_1(w, x, y, opt1)\n  else:\n    train_step_2(w, x, y, opt2)\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Arbitrary Tensor Sequence in C++\nDESCRIPTION: Example of registering a TensorFlow operation that accepts a sequence of tensors of any types. Both inputs and outputs use the same list of types specified by attribute 'T', ensuring input and output tensors match in number and types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_41\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ArbitraryTensorSequenceExample\")\n    .Attr(\"T: list(type)\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Combining Speech and Text Samples\nDESCRIPTION: Defines a function to fetch and combine speech and text samples from the LibriSpeech dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_sound_text_mapping(data_dir):\n  all_files = os.listdir(data_dir)\n\n  flac_files = [os.path.join(data_dir, f) for f in all_files if f.endswith(\".flac\")]\n  txt_files = [os.path.join(data_dir, f) for f in all_files if f.endswith(\".txt\")]\n\n  txt_samples = {}\n  for f in txt_files:\n    txt_samples.update(read_txt_file(f))\n\n  speech_samples = {}\n  for f in flac_files:\n    speech_samples.update(read_flac_file(f))\n\n  assert len(txt_samples) == len(speech_samples)\n\n  samples = [(speech_samples[file_id], txt_samples[file_id]) for file_id in speech_samples.keys() if len(speech_samples[file_id]) < AUDIO_MAXLEN]\n  return samples\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Same-Type Tensor Sequence in C++\nDESCRIPTION: Example of registering a TensorFlow operation that accepts a sequence of tensors of the same type, but with the type specified as an attribute. The op accepts 'NumTensors' number of tensors of type 'T', allowing polymorphism while ensuring all tensors have the same type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_44\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"SameTypeSequenceExample\")\n    .Attr(\"NumTensors: int\")\n    .Attr(\"T: type\")\n    .Input(\"in: NumTensors * T\")\n```\n\n----------------------------------------\n\nTITLE: Defining OpKernel and Functor Template in C++\nDESCRIPTION: This snippet defines the header file for a custom TensorFlow operation, including the OpKernel template and functor struct for both CPU and GPU devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_3\n\nLANGUAGE: C++\nCODE:\n```\n#ifndef KERNEL_EXAMPLE_H_\n#define KERNEL_EXAMPLE_H_\n\n#include <unsupported/Eigen/CXX11/Tensor>\n\ntemplate <typename Device, typename T>\nstruct ExampleFunctor {\n  void operator()(const Device& d, int size, const T* in, T* out);\n};\n\n#if GOOGLE_CUDA\n// Partially specialize functor for GpuDevice.\ntemplate <typename T>\nstruct ExampleFunctor<Eigen::GpuDevice, T> {\n  void operator()(const Eigen::GpuDevice& d, int size, const T* in, T* out);\n};\n#endif\n\n#endif KERNEL_EXAMPLE_H_\n```\n\n----------------------------------------\n\nTITLE: Applying Style Transfer to Images\nDESCRIPTION: Uses the loaded TensorFlow Hub module to apply the style from the style image to the content image. The stylized image is then displayed alongside the original content and style images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_arbitrary_image_stylization.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Stylize content image with given style image.\n# This is pretty fast within a few milliseconds on a GPU.\n\noutputs = hub_module(tf.constant(content_image), tf.constant(style_image))\nstylized_image = outputs[0]\n\n# Visualize input images and the generated stylized image.\n\nshow_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])\n```\n\n----------------------------------------\n\nTITLE: Random Image Roll Function for Tiled Processing\nDESCRIPTION: Implements random shift functionality to prevent visible seams when processing images in tiles. Takes an image and maximum roll value as input and returns the shift amounts and rolled image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef random_roll(img, maxroll):\n  # Randomly shift the image to avoid tiled boundaries.\n  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n  img_rolled = tf.roll(img, shift=shift, axis=[0,1])\n  return shift, img_rolled\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Tensor with Placeholder in TensorFlow\nDESCRIPTION: This example shows how to evaluate a tensor that depends on a placeholder. It demonstrates both a failing case (without providing a value for the placeholder) and a successful case (using feed_dict to provide a value).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\np = tf.placeholder(tf.float32)\nt = p + 1.0\nt.eval()  # This will fail, since the placeholder did not get a value.\nt.eval(feed_dict={p:2.0})  # This will succeed because we're feeding a value\n                           # to the placeholder.\n```\n\n----------------------------------------\n\nTITLE: Using Preprocessor and Encoder Models for Text Embeddings in TensorFlow\nDESCRIPTION: Shows how to use a two-part embedding approach with separate preprocessor and encoder models, enabling TPU compatibility and efficient input pipeline processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntext_input = tf.constant([\"A long sentence.\",\n                          \"single-word\",\n                          \"http://example.com\"])\npreprocessor = hub.load(\"path/to/preprocessor\")  # Must match `encoder`.\nencoder_inputs = preprocessor(text_input)\n\nencoder = hub.load(\"path/to/encoder\")\nencoder_outputs = encoder(encoder_inputs)\nembeddings = encoder_outputs[\"default\"]\n```\n\n----------------------------------------\n\nTITLE: Setting MKL Variables with Command-Line Arguments\nDESCRIPTION: This Bash code snippet demonstrates how to set MKL environment variables for optimal performance before running a Python script. It sets 'KMP_BLOCKTIME' to '0', 'KMP_AFFINITY' to a recommended setting, and enables 'KMP_SETTINGS'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nKMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 \\\nKMP_SETTINGS=1 python your_python_script.py\n```\n\n----------------------------------------\n\nTITLE: Loading Checkpoint with tf.train.load_checkpoint\nDESCRIPTION: Shows detailed control over variable loading using tf.train.load_checkpoint API with explicit tensor assignments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  with tf1.variable_scope('new_scope'):\n    a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n    b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n    c = tf1.get_variable('scoped/c', shape=[], dtype=tf.float32, \n                        initializer=tf1.zeros_initializer())\n  with tf1.Session() as sess:\n    reader = tf.train.load_checkpoint('tf1-ckpt')\n    sess.run(a.assign(reader.get_tensor('a')))\n    sess.run(b.assign(reader.get_tensor('b')))\n    sess.run(c.assign(reader.get_tensor('scoped/c')))\n    print(\"Restored [a, b, c]: \", sess.run([a, b, c]))\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Datasets for Training and Testing\nDESCRIPTION: This code creates TensorFlow datasets for training and testing, including shuffling and batching operations for efficient model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nbatch_size = 64\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train_norm))\ntrain_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test_norm))\ntest_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)\n\n# Set training parameters\nepochs = 100\nlearning_rate = 0.01\ntrain_losses, test_losses = [], []\n```\n\n----------------------------------------\n\nTITLE: Basic Tensor Operations in Python\nDESCRIPTION: Demonstrates basic tensor operations including addition, squaring, and summation. Shows operator overloading with tensors and their automatic conversion from native Python types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nprint(tf.add(1, 2))\nprint(tf.add([1, 2], [3, 4]))\nprint(tf.square(5))\nprint(tf.reduce_sum([1, 2, 3]))\nprint(tf.encode_base64(\"hello world\"))\n\n# Operator overloading is also supported\nprint(tf.square(2) + tf.square(3))\n```\n\n----------------------------------------\n\nTITLE: Creating Zero Vector with Matrix Shape in TensorFlow\nDESCRIPTION: Shows how to create a vector of zeros with size matching the number of columns in a matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nzeros = tf.zeros(my_matrix.shape[1])\n```\n\n----------------------------------------\n\nTITLE: Creating TextLineDataset in TensorFlow\nDESCRIPTION: Initializes a TextLineDataset to read lines from one or more text files using TensorFlow. Required dependencies include a list of filenames. This dataset yields one element per line of the files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nfilenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\"]\ndataset = tf.data.TextLineDataset(filenames)\n```\n\n----------------------------------------\n\nTITLE: Listing Non-Goals of SIGs in Markdown\nDESCRIPTION: This snippet shows a subheader and a list of what SIGs are not intended to be, clarifying their purpose and limitations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### Non-goals: What a SIG is *not*\n\nSIGs are intended is to facilitate collaboration on shared work. A SIG is\ntherefore:\n\n*   *Not a support forum*: a mailing list and a SIG is not the same thing.\n*   *Not immediately required*: early on in a project's life, you may not know\n    if you have shared work or collaborators.\n*   *Not free labor*: energy is required to grow and coordinate the work\n    collaboratively.\n```\n\n----------------------------------------\n\nTITLE: Encoding sparse columns with hash bucket\nDESCRIPTION: This snippet shows how to generate a `FeatureColumn` for a categorical feature when the possible values are not known in advance. It uses `categorical_column_with_hash_bucket()` and assigns indices to feature values using a hash function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/linear.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\neducation = tf.feature_column.categorical_column_with_hash_bucket(\n    \"education\", hash_bucket_size=1000)\n```\n\n----------------------------------------\n\nTITLE: Using Python-Style Indexing for Tensor Slicing\nDESCRIPTION: Shows how to use Python's slice notation to extract elements from a tensor in a more intuitive way.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(t1[1:4])\n```\n\n----------------------------------------\n\nTITLE: Creating Categorical Feature Column with Vocabulary File in TensorFlow\nDESCRIPTION: Creates a categorical feature column using a vocabulary file instead of an in-line list. Better for large vocabularies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_file(\n    key=feature_name_from_input_fn,\n    vocabulary_file=\"product_class.txt\",\n    vocabulary_size=3)\n```\n\n----------------------------------------\n\nTITLE: Creating a Toy Dataset for Model Training\nDESCRIPTION: Defines a function that generates a synthetic dataset for training the model, creating inputs and labels with a linear relationship.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef toy_dataset():\n  inputs = tf.range(10.)[:, None]\n  labels = inputs * 5. + tf.range(5.)[None, :]\n  return tf.data.Dataset.from_tensor_slices(\n    dict(x=inputs, y=labels)).repeat().batch(2)\n```\n\n----------------------------------------\n\nTITLE: Loading CSV Data into a Pandas DataFrame for TensorFlow Processing\nDESCRIPTION: This code snippet demonstrates how to load CSV data from a URL into a pandas DataFrame, which is a common first step when working with CSV data in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nabalone_train = pd.read_csv(\n    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n           \"Viscera weight\", \"Shell weight\", \"Age\"])\n\nabalone_train.head()\n```\n\n----------------------------------------\n\nTITLE: Using One-Shot Iterator with TensorFlow Dataset\nDESCRIPTION: Demonstrates how to create and use a one-shot iterator, which is the simplest form of iterator that supports iterating once through a dataset without explicit initialization. Shows iterating through a range dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.range(100)\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nfor i in range(100):\n  value = sess.run(next_element)\n  assert i == value\n```\n\n----------------------------------------\n\nTITLE: Displaying Dataset Statistics\nDESCRIPTION: Prints the total number of classes and the number of videos available for the first class to understand the dataset distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint('Num classes:', len(classes))\nprint('Num videos for class[0]:', len(files_for_class[classes[0]]))\n```\n\n----------------------------------------\n\nTITLE: Model Initialization and Summary\nDESCRIPTION: Initializing model weights with random input and displaying model architecture summary\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel(tf.random.uniform(shape=(BATCH_SIZE, AUDIO_MAXLEN)))\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Inspecting the upgraded TensorFlow 2.x compatible code\nDESCRIPTION: Command to display the contents of the upgraded Python file that has been modified to use tensorflow.compat.v1 imports for TensorFlow 2.x compatibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n!cat dropout_v2_safe.py\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Model Class in TensorFlow\nDESCRIPTION: This snippet defines a custom Model class that inherits from tf.keras.Model. It demonstrates how to use tf.Variable for model parameters and implement a custom call method. The model represents a simple linear function y = Wx + B.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.keras.Model):\n  def __init__(self):\n    super(Model, self).__init__()\n    self.W = tf.Variable(5., name='weight')\n    self.B = tf.Variable(10., name='bias')\n  def call(self, inputs):\n    return inputs * self.W + self.B\n```\n\n----------------------------------------\n\nTITLE: Debugging Output for Keras Custom Model\nDESCRIPTION: Sample debugger output showing the execution trace and source code listing when debugging a custom Keras model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: text\nCODE:\n```\n>>> call()\n-> return input_data // 2\n(Pdb) l\n 10         if tf.reduce_mean(input_data) > 0:\n 11           return input_data\n 12         else:\n 13           import pdb\n 14           pdb.set_trace()\n 15  ->       return input_data // 2\n 16\n 17\n 18     tf.config.run_functions_eagerly(True)\n 19     model = CustomModel()\n 20     model(tf.constant([-2, -4]))\n```\n\n----------------------------------------\n\nTITLE: Training a MLP Model with Adam Optimizer\nDESCRIPTION: Code that trains a Multi-Layer Perceptron model for 10 epochs using the Adam optimizer and cross-entropy loss function, returning training and validation metrics for performance evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntrain_losses, train_accs, val_losses, val_accs = train_model(mlp_model, train_data, val_data, \n                                                             loss=cross_entropy_loss, acc=accuracy,\n                                                             optimizer=Adam(), epochs=10)\n```\n\n----------------------------------------\n\nTITLE: Generating Alpha Steps for Linear Interpolation in TensorFlow\nDESCRIPTION: Creates evenly spaced intervals between 0 and 1 that will be used to interpolate between the baseline and input image, representing steps for the Riemann sum approximation of the integral in Integrated Gradients.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nm_steps=50\nalphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1) # Generate m_steps intervals for integral_approximation() below.\n```\n\n----------------------------------------\n\nTITLE: Creating an Accuracy Metric Function for Classification\nDESCRIPTION: Function that calculates classification accuracy by comparing the model's predicted class (argmax of softmax outputs) with the true labels, returning the proportion of correct predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef accuracy(y_pred, y):\n  # Compute accuracy after extracting class predictions\n  class_preds = tf.argmax(tf.nn.softmax(y_pred), axis=1)\n  is_equal = tf.equal(y, class_preds)\n  return tf.reduce_mean(tf.cast(is_equal, tf.float32))\n```\n\n----------------------------------------\n\nTITLE: Dynamic Control Flow with TensorFlow Eager Execution\nDESCRIPTION: Implements the FizzBuzz algorithm using TensorFlow operations in eager mode. This demonstrates how eager execution allows for dynamic control flow using Python's native constructs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef fizzbuzz(max_num):\n  counter = tf.constant(0)\n  max_num = tf.convert_to_tensor(max_num)\n  for num in range(1, max_num.numpy()+1):\n    num = tf.constant(num)\n    if int(num % 3) == 0 and int(num % 5) == 0:\n      print('FizzBuzz')\n    elif int(num % 3) == 0:\n      print('Fizz')\n    elif int(num % 5) == 0:\n      print('Buzz')\n    else:\n      print(num.numpy())\n    counter += 1\n\nfizzbuzz(15)\n```\n\n----------------------------------------\n\nTITLE: Executing Basic Matrix Multiplication in TensorFlow C++\nDESCRIPTION: Creates a simple graph that performs matrix multiplication with a constant, then executes it using ClientSession. The example demonstrates creating a scope, defining operations, and retrieving the output tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/cc.md#2025-04-21_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\nScope root = Scope::NewRootScope();\nauto c = Const(root, { {1, 1} });\nauto m = MatMul(root, c, { {41}, {1} });\n\nClientSession session(root);\nstd::vector<Tensor> outputs;\nsession.Run({m}, &outputs);\n// outputs[0] == {42}\n```\n\n----------------------------------------\n\nTITLE: Defining Apache License 2.0 for TensorFlow Documentation in Python\nDESCRIPTION: This code snippet defines the Apache License 2.0 for the TensorFlow documentation. It specifies the terms under which the documentation can be used, distributed, and modified.\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/subsite/g3doc/tutorials/notebook.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Accessing Variables and Layers in TensorFlow 2 SavedModel\nDESCRIPTION: Demonstrates how to directly access model variables (like weights) after loading a SavedModel in TensorFlow 2. This replaces the TensorFlow 1 approach of using Session.run with tensor names.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.Module()\nmodel.dense_layer = tf.keras.layers.Dense(...)\ntf.saved_model.save('my_saved_model')\nloaded = tf.saved_model.load('my_saved_model')\nloaded.dense_layer.kernel\n```\n\n----------------------------------------\n\nTITLE: Implementing the Same Model with Keras\nDESCRIPTION: Reimplements the same linear regression model using Keras by subclassing tf.keras.Model instead of tf.Module, showing the equivalence between the approaches.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass MyModelKeras(tf.keras.Model):\n  def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n    # Initialize the weights to `5.0` and the bias to `0.0`\n    # In practice, these should be randomly initialized\n    self.w = tf.Variable(5.0)\n    self.b = tf.Variable(0.0)\n\n  def call(self, x):\n    return self.w * x + self.b\n\nkeras_model = MyModelKeras()\n\n# Reuse the training loop with a Keras model\ntraining_loop(keras_model, x, y)\n```\n\n----------------------------------------\n\nTITLE: Creating and Preprocessing Input Dataset\nDESCRIPTION: Demonstrates how to create and prepare a tf.data.Dataset for distributed training with shuffling, batching, and prefetching optimizations. Uses a global batch size of 64 and includes data preprocessing steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nglobal_batch_size = 64\n\nx = tf.random.uniform((10, 10))\ny = tf.random.uniform((10,))\n\ndataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(10).repeat()\ndataset = dataset.batch(global_batch_size)\ndataset = dataset.prefetch(2)\n```\n\n----------------------------------------\n\nTITLE: Evaluating the model using TPUEstimator in TF1\nDESCRIPTION: This code snippet calls `TPUEstimator.evaluate` to evaluate the trained model. It uses the `_eval_input_fn` to provide the evaluation data and evaluates for a specified number of steps (in this case, 1 step).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nestimator.evaluate(_eval_input_fn, steps=1)\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: Standard Apache License 2.0 declaration for TensorFlow documentation, specifying the terms under which the code can be used and distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating Signatures with Concrete Functions in TensorFlow 2\nDESCRIPTION: Creates a SavedModel signature by using the get_concrete_function method on a tf.function. This approach allows for creating a concrete function with specific input values, capturing the function's trace for those inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Option 2: Call `get_concrete_function`\n@tf.function\ndef fn(...):\n  ...\n  return outputs\n\ntf.saved_model.save(model, path, signatures={\n    'name': fn.get_concrete_function(...)\n})\n```\n\n----------------------------------------\n\nTITLE: Generating Training Data\nDESCRIPTION: Creates toy examples for training by generating random samples from feature vocabulary. Labels are set based on presence of 'avenger' in features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef feature_and_label_gen(num_examples=200):\n  examples = {\"features\": [], \"label\": []}\n  for _ in range(num_examples):\n    features = random.sample(feature_vocab, 3)\n    label = [\"yes\"] if \"avenger\" in features else [\"no\"]\n    examples[\"features\"].append(features)\n    examples[\"label\"].append(label)\n  return examples\n\nexamples = feature_and_label_gen()\n```\n\n----------------------------------------\n\nTITLE: Plotting Function for Performance Comparison in Python\nDESCRIPTION: This function plots the runtime comparisons between NumPy, TensorFlow NumPy on CPU, compiled TensorFlow NumPy on CPU, and optionally TensorFlow NumPy on GPU.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):\n  \"\"\"Plot the different runtimes.\"\"\"\n  plt.xlabel(\"size\")\n  plt.ylabel(\"time (ms)\")\n  plt.title(\"Sigmoid benchmark: TF NumPy vs NumPy\")\n  plt.plot(sizes, np_times, label=\"NumPy\")\n  plt.plot(sizes, tnp_times, label=\"TF NumPy (CPU)\")\n  plt.plot(sizes, compiled_tnp_times, label=\"Compiled TF NumPy (CPU)\")\n  if has_gpu:\n    plt.plot(sizes, tnp_times_gpu, label=\"TF NumPy (GPU)\")\n  plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Converting Frozen Dictionaries to Regular Dictionaries in Python\nDESCRIPTION: Helper function that recursively converts frozen mappings back to regular Python dictionaries while preserving nested structures like lists and tuples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/jax2tf.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom collections import abc\n\ndef _fix_frozen(d):\n  \"\"\"Changes any mappings (e.g. frozendict) back to dict.\"\"\"\n  if isinstance(d, list):\n    return [_fix_frozen(v) for v in d]\n  elif isinstance(d, tuple):\n    return tuple(_fix_frozen(v) for v in d)\n  elif not isinstance(d, abc.Mapping):\n    return d\n  d = dict(d)\n  for k, v in d.items():\n    d[k] = _fix_frozen(v)\n  return d\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function for Text Generation in TensorFlow\nDESCRIPTION: Creates a loss function using sparse categorical cross-entropy, appropriate for next-character prediction. Sets from_logits=True since the model outputs raw logits rather than probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef loss(labels, logits):\n  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n\nexample_batch_loss  = loss(target_example_batch, example_batch_predictions)\nprint(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\nprint(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Sequential Keras Model for Classification\nDESCRIPTION: Defines a simple fully-connected neural network using Keras Sequential API with Dense layers, ReLU activation, and Dropout for regularization. The model expects 4 input features and outputs 3 classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(3)\n])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Potential Precision Loss in 'all' Mode\nDESCRIPTION: Example showing that mixing int64 and float16 types is allowed in 'all' mode, with int64 being promoted to float16 which could result in significant precision loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# The first input is promoted to f16 in ALL mode.\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\ntf.constant(1, tf.int64) + tf.constant(3.2, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.2>\n```\n\n----------------------------------------\n\nTITLE: Using TensorArray with AutoGraph for Dynamic Lists\nDESCRIPTION: Shows how AutoGraph can handle Python list operations by automatically converting them to TensorArray operations, creating a range function implementation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@tf.function(\n    experimental_autograph_options=tf.autograph.experimental.Feature.LISTS)\ndef arange(n):\n  z = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n\n  for i in tf.range(n):\n    z.append(i)\n\n  return z.stack()\n\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    print(sess.run(arange(tf.constant(10))))\n```\n\n----------------------------------------\n\nTITLE: Manipulating TensorFlow Variables\nDESCRIPTION: This snippet shows how to create a TensorFlow variable, reassign its value, and use it in a TensorFlow operation. It illustrates the concept of mutable state in TensorFlow and how variables are used in computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nv = tf.Variable(1.0)\nassert v.numpy() == 1.0\n\n# Re-assign the value\nv.assign(3.0)\nassert v.numpy() == 3.0\n\n# Use `v` in a TensorFlow operation like tf.square() and reassign\nv.assign(tf.square(v))\nassert v.numpy() == 9.0\n```\n\n----------------------------------------\n\nTITLE: Creating Input Function for Estimators using tf.data in Python\nDESCRIPTION: This function creates a tf.data.Dataset from input features and labels, then applies shuffle, repeat, and batch operations to prepare the data for training an Estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n```\n\n----------------------------------------\n\nTITLE: Preprocessing MNIST Dataset for DTensor Training\nDESCRIPTION: Loads the MNIST dataset from TensorFlow Datasets and preprocesses it by reshaping to 2D and rescaling to [0,1] range. This prepares the data for input to the MLP model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess(x, y):\n  # Reshaping the data\n  x = tf.reshape(x, shape=[-1, 784])\n  # Rescaling the data\n  x = x/255\n  return x, y\n\ntrain_data, test_data = train_data.map(preprocess), test_data.map(preprocess)\n```\n\n----------------------------------------\n\nTITLE: Loading Universal Sentence Encoder\nDESCRIPTION: Imports required libraries and loads the Universal Sentence Encoder model from TensorFlow Hub, defining an embed function for text encoding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title Load the Universal Sentence Encoder's TF Hub module\nfrom absl import logging\n\nimport tensorflow as tf\n\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport re\nimport seaborn as sns\n\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\nmodel = hub.load(module_url)\nprint (\"module %s loaded\" % module_url)\ndef embed(input):\n  return model(input)\n```\n\n----------------------------------------\n\nTITLE: Text Embedding Function with Optional Dimensionality Reduction\nDESCRIPTION: Defines a function to embed text using a TensorFlow Hub module with optional random projection to reduce embedding dimensionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nencoder = None\n\ndef embed_text(text, module_url, random_projection_matrix):\n  # Beam will run this function in different processes that need to\n  # import hub and load embed_fn (if not previously loaded)\n  global encoder\n  if not encoder:\n    encoder = hub.Module(module_url)\n  embedding = encoder(text)\n  if random_projection_matrix is not None:\n    # Perform random projection for the embedding\n    embedding = tf.matmul(\n        embedding, tf.cast(random_projection_matrix, embedding.dtype))\n  return embedding\n```\n\n----------------------------------------\n\nTITLE: Resetting Layer Variables and Demonstrating Reuse in Python\nDESCRIPTION: This code snippet demonstrates how to reset the layer variables to zero and show that they are reused on subsequent calls.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nprint(\"Resetting variables to zero:\", [var.name for var in layer.trainable_variables])\n\nfor var in layer.trainable_variables:\n  var.assign(var * 0.0)\n\n# Note: layer.losses is not a live view and\n# will get reset only at each layer call\nprint(\"layer.losses:\", layer.losses)\nprint(\"calling layer again.\")\nout = layer(x)\nprint(\"layer.losses: \", layer.losses)\nout\n```\n\n----------------------------------------\n\nTITLE: Recreating Keras Model from JSON Configuration\nDESCRIPTION: Demonstrates how to recreate a Keras model from a JSON configuration string using `tf.keras.models.model_from_json()`. This allows you to recreate the model architecture without the original code that defined it. The recreated model is newly initialized with random weights.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n```python\nfresh_model = tf.keras.models.model_from_json(json_string)\n```\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow Dataset\nDESCRIPTION: Creates a TensorFlow dataset from the generator, applies shuffling, batching, and prefetching optimizations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\noutput_signature = (\n    tf.TensorSpec(shape=(None),  dtype=tf.float32),\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\n)\n\ndataset = tf.data.Dataset.from_generator(inputs_generator, output_signature=output_signature)\n\nBUFFER_SIZE = len(flac_files)\nSEED = 42\n\ndataset = dataset.shuffle(BUFFER_SIZE, seed=SEED)\ndataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(AUDIO_MAXLEN, LABEL_MAXLEN), padding_values=(0.0, 0))\ndataset = dataset.prefetch(tf.data.AUTOTUNE)\n\nnum_train_batches = 10\nnum_val_batches = 4\n\ntrain_dataset = dataset.take(num_train_batches)\nval_dataset = dataset.skip(num_train_batches).take(num_val_batches)\n```\n\n----------------------------------------\n\nTITLE: Defining Bazel Dependencies for TensorFlow Serving APIs in Python\nDESCRIPTION: Bazel build configuration that defines dependencies for accessing TensorFlow Serving APIs from Python. These dependencies provide access to classification, regression, prediction, and service protocol buffers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_13\n\nLANGUAGE: starlark\nCODE:\n```\n  deps = [\n    \"//tensorflow_serving/apis:classification_proto_py_pb2\",\n    \"//tensorflow_serving/apis:regression_proto_py_pb2\",\n    \"//tensorflow_serving/apis:predict_proto_py_pb2\",\n    \"//tensorflow_serving/apis:prediction_service_proto_py_pb2\"\n  ]\n```\n\n----------------------------------------\n\nTITLE: Initializing Estimator with MirroredStrategy in Python\nDESCRIPTION: This snippet demonstrates how to initialize a TensorFlow Estimator, specifically a LinearRegressor, with a MirroredStrategy for distributed training on multiple GPUs. It configures both training and evaluation distribution strategies via RunConfig.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(\n    train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\nregressor = tf.estimator.LinearRegressor(\n    feature_columns=[tf.feature_column.numeric_column('feats')],\n    optimizer='SGD',\n    config=config)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Dataset from TFRecord\nDESCRIPTION: Creates a dataset pipeline that reads raw images from a TFRecord file, applies preprocessing, and combines them with labels. This demonstrates how to reconstruct the dataset from TFRecord storage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nimage_ds = tf.data.TFRecordDataset('images.tfrec').map(preprocess_image)\nds = tf.data.Dataset.zip((image_ds, label_ds))\nds = ds.apply(\n  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\nds=ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Checking Worker Log File Output\nDESCRIPTION: This bash command displays the contents of the worker's log file to monitor its progress and state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\ncat job_0.log\n```\n\n----------------------------------------\n\nTITLE: Visualizing Normalized Feature Distributions with Seaborn in Python\nDESCRIPTION: This code creates a violin plot to visualize the distribution of normalized features across all columns in the dataset. It uses Seaborn and Matplotlib for plotting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf_std = (df - train_mean) / train_std\ndf_std = df_std.melt(var_name='Column', value_name='Normalized')\nplt.figure(figsize=(12, 6))\nax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n_ = ax.set_xticklabels(df.keys(), rotation=90)\n```\n\n----------------------------------------\n\nTITLE: Generated Python Function for Op with Explicit Type Attribute\nDESCRIPTION: Shows the auto-generated Python function for an op with an explicit output type attribute. Users must specify the output type when calling this function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef string_to_number(string_tensor, out_type=None, name=None):\n  \"\"\"Converts each string in the input Tensor to the specified numeric type.\n\n  Args:\n    string_tensor: A `Tensor` of type `string`.\n    out_type: An optional `tf.DType` from: `tf.float32, tf.int32`.\n      Defaults to `tf.float32`.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor` of type `out_type`.\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Minimum List Length Attribute (C++)\nDESCRIPTION: This example shows how to enforce a minimum length constraint on a list attribute.  The `Attr` method specifies that `a` must be a list of types (either int32 or float) with at least 3 elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_17\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"TypeListExample\")\n    .Attr(\"a: list({int32, float}) >= 3\");\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for TensorFlow 2 Logs\nDESCRIPTION: Launches TensorBoard to visualize the logs generated by the TensorFlow 2.x Keras model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%tensorboard --logdir {tensorboard_callback.log_dir}\n```\n\n----------------------------------------\n\nTITLE: Displaying TensorFlow License Information in Python\nDESCRIPTION: A code cell showing the Apache License 2.0 license information that applies to the TensorFlow documentation and examples. This is included as a hidden cell in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Session Debugging in Python Using LocalCLIDebugWrapperSession\nDESCRIPTION: This snippet demonstrates how to wrap a TensorFlow session with `LocalCLIDebugWrapperSession` for inline CLI debugging. Specific thread filtering can be applied using the `thread_name_filter` argument. Typically requires TensorFlow and tfdbg dependencies.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.python import debug as tf_debug\n\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\n```\n\n----------------------------------------\n\nTITLE: Filtering Nodes in tfdbg\nDESCRIPTION: This example demonstrates how to use tfdbg's filtering options to watch only specific nodes in the graph during debugging. It shows examples of filtering by node name, operation type, and tensor data type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_19\n\nLANGUAGE: text\nCODE:\n```\n\"tfdbg> run --node_name_filter .*hidden.*\\ntfdbg> run --op_type_filter Variable.*\\ntfdbg> run --tensor_dtype_filter int.*\"\n```\n\n----------------------------------------\n\nTITLE: Reading TFRecord Files with Dataset API\nDESCRIPTION: Demonstrates how to read TFRecord files using TFRecordDataset and switch between training and validation files using placeholders.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfilenames = tf.placeholder(tf.string, shape=[None])\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(...)  # Parse the record into tensors.\ndataset = dataset.repeat()  # Repeat the input indefinitely.\ndataset = dataset.batch(32)\niterator = dataset.make_initializable_iterator()\n\ntraining_filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\nsess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n\nvalidation_filenames = [\"/var/data/validation1.tfrecord\", ...]\nsess.run(iterator.initializer, feed_dict={filenames: validation_filenames})\n```\n\n----------------------------------------\n\nTITLE: Downloading Dataset Subset\nDESCRIPTION: Executes the download_ucf_101_subset function to download a subset of the UCF101 dataset with 10 classes and split it into training (30 videos/class), validation (10 videos/class), and test (10 videos/class) sets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndownload_dir = pathlib.Path('./UCF101_subset/')\nsubset_paths = download_ucf_101_subset(URL,\n                                       num_classes = NUM_CLASSES,\n                                       splits = {\"train\": 30, \"val\": 10, \"test\": 10},\n                                       download_dir = download_dir)\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Repacking for Spatial Parallel Training with DTensor in Python\nDESCRIPTION: This function repacks the input batch for spatial parallel training. It applies appropriate layouts to the input tensors, sharding along both batch and feature dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef repack_batch_for_spt(x, y, mesh):\n    # Shard data on feature dimension, too\n    x = repack_local_tensor(x, layout=dtensor.Layout([\"batch\", 'feature'], mesh))\n    y = repack_local_tensor(y, layout=dtensor.Layout([\"batch\"], mesh))\n    return x, y\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with Multiple Inputs and Outputs in C++\nDESCRIPTION: Example of registering a TensorFlow operation with multiple inputs and outputs of different data types. The operation accepts two inputs ('y' of type int32 and 'z' of type float) and produces two outputs ('a' of type string and 'b' of type int32).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_36\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MultipleInsAndOuts\")\n    .Input(\"y: int32\")\n    .Input(\"z: float\")\n    .Output(\"a: string\")\n    .Output(\"b: int32\");\n```\n\n----------------------------------------\n\nTITLE: Creating and Processing the Test Dataset in TensorFlow\nDESCRIPTION: Creates a TensorFlow dataset from the test CSV file and applies a feature packing function to prepare it for model evaluation. The code specifies batch size, column names, and other dataset parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ntest_dataset = tf.data.experimental.make_csv_dataset(\n    test_fp,\n    batch_size,\n    column_names=column_names,\n    label_name='species',\n    num_epochs=1,\n    shuffle=False)\n\ntest_dataset = test_dataset.map(pack_features_vector)\n```\n\n----------------------------------------\n\nTITLE: Creating a nested RaggedTensor with multiple ragged dimensions in TensorFlow\nDESCRIPTION: Shows how to create a RaggedTensor with multiple ragged dimensions by nesting RaggedTensors. The ragged_rank property indicates the number of ragged dimensions in the tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=tf.RaggedTensor.from_row_splits(\n        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n        row_splits=[0, 3, 3, 5, 9, 10]),\n    row_splits=[0, 1, 1, 5])\nprint(rt)\nprint(\"Shape: {}\".format(rt.shape))\nprint(\"Number of ragged dimensions: {}\".format(rt.ragged_rank))\n```\n\n----------------------------------------\n\nTITLE: Testing Model Output Shape and Values\nDESCRIPTION: Processes a batch of images through the complete model and examines the output properties. This verifies that the model produces properly shaped classification logits with appropriate value ranges.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlogit_batch = model(image_batch).numpy()\n\nprint(\"min logit:\", logit_batch.min())\nprint(\"max logit:\", logit_batch.max())\nprint()\n\nprint(\"Shape:\", logit_batch.shape)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow GAN Face Generation\nDESCRIPTION: This snippet imports the necessary Python libraries for working with TensorFlow, TensorFlow Hub, image processing, and visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom absl import logging\n\nimport imageio\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport tensorflow as tf\ntf.random.set_seed(0)\n\nimport tensorflow_hub as hub\nfrom tensorflow_docs.vis import embed\nimport time\n\ntry:\n  from google.colab import files\nexcept ImportError:\n  pass\n\nfrom IPython import display\nfrom skimage import transform\n\nlatent_dim = 512\n```\n\n----------------------------------------\n\nTITLE: TF1.x Code with Global Step Dependent Learning Rate\nDESCRIPTION: Example showing a TensorFlow 1.x implementation where learning rate depends on a global step variable. In the graph mode execution, learning rate is recomputed with each session run.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ng = tf.Graph()\nwith g.as_default():\n  ...\n  global_step = tf.Variable(0)\n  learning_rate = 1.0 / global_step\n  opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n  ...\n  global_step.assign_add(1)\n...\nsess = tf.compat.v1.Session(graph=g)\nsess.run(...)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow License in Python\nDESCRIPTION: This code snippet contains the Apache 2.0 license for TensorFlow, typically included at the beginning of TensorFlow example files or notebooks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Model Inference in C++\nDESCRIPTION: This snippet shows how to run a TensorFlow model with the processed image as input. It feeds the image tensor to the input layer and gets the results from the output layer of the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_12\n\nLANGUAGE: C++\nCODE:\n```\n  // Actually run the image through the model.\n  std::vector<Tensor> outputs;\n  Status run_status = session->Run({{FLAGS_input_layer, resized_tensor}},\n                                 {FLAGS_output_layer}, {}, &outputs);\n  if (!run_status.ok()) {\n    LOG(ERROR) << \"Running model failed: \" << run_status;\n    return -1;\n  }\n```\n\n----------------------------------------\n\nTITLE: Visualizing the PowerLaw Entropy Penalty Function\nDESCRIPTION: Demonstrates plotting the penalty function from the PowerLawEntropyModel, which encourages sparsity by using a concave function with a cusp at zero. This penalty corresponds to an Elias gamma coding scheme for compression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n_ = tf.linspace(-5., 5., 501)\nplt.plot(_, tfc.PowerLawEntropyModel(0).penalty(_));\n```\n\n----------------------------------------\n\nTITLE: Executing ANNOY Index Building in Python\nDESCRIPTION: This code snippet sets up the parameters for building the ANNOY index and executes the build_index function. It also measures the execution time of the index building process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nembedding_files = \"{}/emb-*.tfrecords\".format(output_dir)\nembedding_dimension = projected_dim\nindex_filename = \"index\"\n\n!rm {index_filename}\n!rm {index_filename}.mapping\n\n%time build_index(embedding_files, index_filename, embedding_dimension)\n```\n\n----------------------------------------\n\nTITLE: Generated Python Function for Type-Polymorphic Ops in TensorFlow\nDESCRIPTION: Shows the auto-generated Python function for a type-polymorphic op. When this op is used in Python, TensorFlow infers the type attribute 'T' based on the input tensor type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef zero_out(to_zero, name=None):\n  \"\"\"...\n  Args:\n    to_zero: A `Tensor`. Must be one of the following types:\n        `float32`, `int32`.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor`. Has the same type as `to_zero`.\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Plotting Accuracy Metrics for Model Evaluation\nDESCRIPTION: Code snippet that calls the plotting function to visualize training and validation accuracy over epochs, providing insight into the model's classification performance and generalization ability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nplot_metrics(train_accs, val_accs, \"accuracy\")\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Debugger Session Wrapper\nDESCRIPTION: Code snippet showing how to wrap a TensorFlow session with the debugger wrapper class. This enables debugging features like CLI control and tensor value inspection during execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Let your BUILD target depend on \"//tensorflow/python/debug:debug_py\"\n# (You don't need to worry about the BUILD dependency if you are using a pip\n#  install of open-source TensorFlow.)\nfrom tensorflow.python import debug as tf_debug\n\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Number Type Attribute (C++)\nDESCRIPTION: This snippet demonstrates using the `numbertype` shortcut to restrict a `type` attribute to numeric types. The `Attr` method specifies that the `t` attribute must be a numeric type (excluding strings and booleans).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_14\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"NumberType\")\n    .Attr(\"t: numbertype\");\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Keras Sequential Model in Python\nDESCRIPTION: This code snippet creates a simple Keras sequential model with two dense layers. It then compiles the model using gradient descent optimizer and binary crossentropy loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10,)))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\noptimizer = tf.train.GradientDescentOptimizer(0.2)\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Converting Sparse Tensor to Dense Tensor in TensorFlow\nDESCRIPTION: This code shows how to convert a sparse tensor back to its dense representation using tf.sparse.to_dense. It reconstructs the full matrix from the sparse tensor created in the previous snippet.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nst3 = tf.sparse.to_dense(st2)\nprint(st3)\n```\n\n----------------------------------------\n\nTITLE: Building Hidden Layers in a TensorFlow Neural Network\nDESCRIPTION: Code that creates multiple dense (fully connected) hidden layers with ReLU activation, with sizes specified by a parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Build the hidden layers, sized according to the 'hidden_units' param.\nfor units in params['hidden_units']:\n    net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n```\n\n----------------------------------------\n\nTITLE: Creating TFRecord File from Raw Images\nDESCRIPTION: Builds a TFRecord file from raw image data for more efficient storage and loading. This approach reads image paths, loads the raw files, and writes them to a single TFRecord file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimage_ds = tf.data.Dataset.from_tensor_slices(all_image_paths).map(tf.read_file)\ntfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\ntfrec.write(image_ds)\n```\n\n----------------------------------------\n\nTITLE: Creating and Compiling a Keras Sequential Model\nDESCRIPTION: Defines a new model using Keras Sequential API with Lambda and Dense layers, then compiles it with MSE loss and SGD optimizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nnew_model = tf.keras.Sequential([\n    tf.keras.layers.Lambda(lambda x: tf.stack([x, x**2], axis=1)),\n    tf.keras.layers.Dense(units=1, kernel_initializer=tf.random.normal)])\n\nnew_model.compile(\n    loss=tf.keras.losses.MSE,\n    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n\nhistory = new_model.fit(x, y,\n                        epochs=100,\n                        batch_size=32,\n                        verbose=0)\n\nnew_model.save('./my_new_model.keras')\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Recommenders\nDESCRIPTION: This code snippet installs the TensorFlow Recommenders package, which is required for using the `TPUEmbedding` layer in TensorFlow 2. This package provides specialized layers and tools for building recommendation models, including support for TPU embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"!pip install tensorflow-recommenders\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Basic Operations with Ragged Tensors\nDESCRIPTION: Shows common operations that can be performed on ragged tensors, including math operations, array operations, and string manipulation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndigits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\nwords = tf.ragged.constant([[\"So\", \"long\"], [\"thanks\", \"for\", \"all\", \"the\", \"fish\"]])\nprint(tf.add(digits, 3))\nprint(tf.reduce_mean(digits, axis=1))\nprint(tf.concat([digits, [[5, 3]]], axis=0))\nprint(tf.tile(digits, [1, 2]))\nprint(tf.strings.substr(words, 0, 2))\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: Displays the Apache 2.0 license information for the TensorFlow documentation as a hidden code cell in a Jupyter notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/automatic_differentiation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating Float WeakTensors\nDESCRIPTION: Example showing how WeakTensors are created when using tf.constant without specifying a dtype for mixed float and integer values in a list.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntf.constant([5.0, 10.0, 3])  # <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 5., 10.,  3.], dtype=float32), weak=True>\n```\n\n----------------------------------------\n\nTITLE: Adding Variable to Collection\nDESCRIPTION: Demonstrates adding a variable to a custom collection after creation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntf.add_to_collection(\"my_collection_name\", my_local)\n```\n\n----------------------------------------\n\nTITLE: Training TensorFlow Estimator with CSV Input\nDESCRIPTION: Shows how to set up and train a LinearClassifier using CSV data. Creates numeric feature columns, builds the estimator, and trains it using a CSV input function with specified batch size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets_for_estimators.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntrain_path, test_path = iris_data.maybe_download()\n\n# All the inputs are numeric\nfeature_columns = [\n    tf.feature_column.numeric_column(name)\n    for name in iris_data.CSV_COLUMN_NAMES[:-1]]\n\n# Build the estimator\nest = tf.estimator.LinearClassifier(feature_columns,\n                                    n_classes=3)\n# Train the estimator\nbatch_size = 100\nest.train(\n    steps=1000,\n    input_fn=lambda : iris_data.csv_input_fn(train_path, batch_size))\n```\n\n----------------------------------------\n\nTITLE: Implementing File-Based Dataset Caching\nDESCRIPTION: Sets up a dataset pipeline that uses file-based caching for scenarios where data doesn't fit in memory. This approach stores cached data on disk to conserve RAM.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nds = image_label_ds.cache(filename='./cache.tf-data')\nds = ds.apply(\n  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\nds = ds.batch(BATCH_SIZE).prefetch(1)\nds\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license declaration for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Saving the TensorFlow Model to Disk\nDESCRIPTION: Uses tf.saved_model.save to export the model to a temporary directory. This saves both the model architecture and weights in a format that can be deployed to various environments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nmodels = tempfile.mkdtemp()\nsave_path = os.path.join(models, 'mlp_model_export')\ntf.saved_model.save(mlp_model_export, save_path)\n```\n\n----------------------------------------\n\nTITLE: Compiling a Keras Model\nDESCRIPTION: This snippet compiles a Keras model, specifying the optimizer, loss function, and metrics to be used during training. The optimizer is set to 'adam', the loss function to 'sparse_categorical_crossentropy', and the metric to 'accuracy'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Displaying Text-to-Video Retrieval Results in Python\nDESCRIPTION: This code visualizes the results of the text-to-video retrieval task. It iterates through the text queries and displays the top matching videos along with their similarity scores using HTML formatting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Display results.\nhtml = ''\nfor i, words in enumerate(words_np):\n  html += display_query_and_results_video(words, all_videos_urls, all_scores[i, :])\n  html += '<br>'\ndisplay.HTML(html)\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Gradient Boosted Trees Model with TensorFlow Decision Forests\nDESCRIPTION: This snippet demonstrates how to compile and evaluate a trained Gradient Boosted Trees model using accuracy as the metric. It evaluates the model on the evaluation dataset and prints the results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/canned_estimators.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ngbt_model.compile(metrics=['accuracy'])\ngbt_evaluation = gbt_model.evaluate(eval_dataset, return_dict=True)\nprint(gbt_evaluation)\n```\n\n----------------------------------------\n\nTITLE: Model Creation and Summary\nDESCRIPTION: Creates the model with specified vocabulary size and number of labels, then displays its summary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model(vocab_size=VOCAB_SIZE, num_labels=1)\nmodel.summary()\n```\n\n----------------------------------------\n\nTITLE: Inspecting Batch Shapes in TensorFlow Dataset\nDESCRIPTION: Shows how to iterate through a dataset and print the shapes of input and label tensors, which is useful for debugging and understanding the data structure before model training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfor example_inputs, example_labels in w2.train.take(1):\n  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n```\n\n----------------------------------------\n\nTITLE: Loading a TensorFlow 2 Checkpoint in TensorFlow 1\nDESCRIPTION: This snippet demonstrates how to load a TensorFlow 2 checkpoint in a TensorFlow 1 environment. It creates variables in a TF1 graph, initializes them, and then restores their values from a TF2 checkpoint using tf.train.Checkpoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Graph().as_default() as g:\n  a = tf1.get_variable('a', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(0))\n  b = tf1.get_variable('b', shape=[], dtype=tf.float32, \n                       initializer=tf1.constant_initializer(0))\n  with tf1.variable_scope('scoped'):\n    c = tf1.get_variable('c', shape=[], dtype=tf.float32, \n                        initializer=tf1.constant_initializer(0))\n  with tf1.Session() as sess:\n    sess.run(tf1.global_variables_initializer())\n    print(\"Initialized [a, b, c]: \", sess.run([a, b, c]))\n    ckpt = tf.train.Checkpoint(\n        var_list={v.name.split(':')[0]: v for v in tf1.global_variables()})\n    ckpt.restore('tf2-ckpt-saved-in-session-1').run_restore_ops()\n    print(\"Restored [a, b, c]: \", sess.run([a, b, c]))\n```\n\n----------------------------------------\n\nTITLE: Generating Interpolated Images Between Baseline and Input\nDESCRIPTION: Applies the interpolation function to create a series of images along the linear path from the black baseline to the 'Fireboat' input image, which will be used for gradient calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ninterpolated_images = interpolate_images(\n    baseline=baseline,\n    image=img_name_tensors['Fireboat'],\n    alphas=alphas)\n```\n\n----------------------------------------\n\nTITLE: Creating a Fully Sharded Rank-2 DTensor in TensorFlow\nDESCRIPTION: Example of creating a 3x2 rank-2 DTensor that is fully sharded across both mesh dimensions, with its first axis sharded along 'x' and second axis along 'y'. Each device receives a single element of the tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfully_sharded_dtensor = dtensor_from_array(\n    tf.reshape(tf.range(6), (3, 2)),\n    layout=dtensor.Layout([\"x\", \"y\"], mesh))\n\nfor raw_component in dtensor.unpack(fully_sharded_dtensor):\n  print(\"Device:\", raw_component.device, \",\", raw_component)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Font CSV Dataset\nDESCRIPTION: This code downloads a character font images dataset that is distributed as a collection of CSV files, one per font. It uses Keras' get_file utility to handle downloading and extraction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfonts_zip = tf.keras.utils.get_file(\n    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n    cache_dir='.', cache_subdir='fonts',\n    extract=True)\n```\n\n----------------------------------------\n\nTITLE: Setting Up TPUStrategy and Model in TensorFlow 2\nDESCRIPTION: Creates datasets, TPUStrategy, and compiles a Keras model for TPU training in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensor_slices(\n    (features, labels)).shuffle(10).repeat().batch(\n        8, drop_remainder=True).prefetch(2)\neval_dataset = tf.data.Dataset.from_tensor_slices(\n    (eval_features, eval_labels)).batch(1, drop_remainder=True)\n\nstrategy = tf.distribute.TPUStrategy(cluster_resolver)\nwith strategy.scope():\n  model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\n  optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05)\n  model.compile(optimizer, \"mse\", steps_per_execution=10)\n```\n\n----------------------------------------\n\nTITLE: Preparing Sample Data for Metrics Demo\nDESCRIPTION: Creating simple feature and label data arrays for demonstration purposes in both training and evaluation contexts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfeatures = [[1., 1.5], [2., 2.5], [3., 3.5]]\nlabels = [0, 0, 1]\neval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\neval_labels = [0, 1, 1]\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow and Visualization Libraries in Python\nDESCRIPTION: This snippet imports the necessary libraries for performing numerical simulations with TensorFlow and visualization using PIL. TensorFlow is imported in compatibility mode to ensure smooth execution with older versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#Import libraries for simulation\nimport tensorflow.compat.v1 as tf\n\nimport numpy as np\n\n#Imports for visualization\nimport PIL.Image\nfrom io import BytesIO\nfrom IPython.display import clear_output, Image, display\n\n```\n\n----------------------------------------\n\nTITLE: Viewing TensorBoard Logs in Jupyter Notebook\nDESCRIPTION: This code snippet shows how to view TensorBoard logs directly in a Jupyter notebook. It uses the %tensorboard magic command to display the logs from the 'regularizers' directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: Python\nCODE:\n```\n%tensorboard --logdir {logdir}/regularizers\n```\n\n----------------------------------------\n\nTITLE: Serializing tf.Example Messages in Python\nDESCRIPTION: This function creates a tf.Example message from feature values and serializes it to a string. It demonstrates how to construct a tf.Example from multiple features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef serialize_example(feature0, feature1, feature2, feature3):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n\n  feature = {\n      'feature0': _int64_feature(feature0),\n      'feature1': _int64_feature(feature1),\n      'feature2': _bytes_feature(feature2),\n      'feature3': _float_feature(feature3),\n  }\n\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()\n```\n\n----------------------------------------\n\nTITLE: Determining CSV Column Types Dynamically\nDESCRIPTION: Calculates the number of features in a CSV file by counting commas and creates appropriate column types for loading the data. It assumes the first two columns are strings and the rest are floats.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nnum_font_features = font_line.count(',')+1\nfont_column_types = [str(), str()] + [float()]*(num_font_features-2)\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU-aware RNN Layer in TensorFlow\nDESCRIPTION: Conditionally selects the appropriate GRU implementation based on GPU availability. Uses CuDNNGRU for GPU acceleration if available, otherwise falls back to regular GRU with sigmoid recurrent activation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  rnn = tf.keras.layers.CuDNNGRU\nelse:\n  import functools\n  rnn = functools.partial(\n    tf.keras.layers.GRU, recurrent_activation='sigmoid')\n```\n\n----------------------------------------\n\nTITLE: Creating DVariable for Mutable Distributed State\nDESCRIPTION: Demonstrates the creation and usage of DVariable, DTensor's equivalent of tf.Variable for maintaining mutable distributed state with fixed layouts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 6)], devices=DEVICES)\nlayout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)\n\nv = dtensor.DVariable(\n    initial_value=dtensor.call_with_layout(\n        tf.function(tf.random.stateless_normal),\n        layout=layout,\n        shape=tf.TensorShape([64, 32]),\n        seed=[1, 1],\n        dtype=tf.float32))\n\nprint(v.handle)\nassert layout == dtensor.fetch_layout(v)\n```\n\n----------------------------------------\n\nTITLE: Calculating Global Batch Size for Distributed Training\nDESCRIPTION: This code calculates the global batch size based on the number of replicas in the distribution strategy and adjusts the learning rate accordingly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\nBATCH_SIZE_PER_REPLICA = 5\nglobal_batch_size = (BATCH_SIZE_PER_REPLICA *\n                     mirrored_strategy.num_replicas_in_sync)\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100)\ndataset = dataset.batch(global_batch_size)\n\nLEARNING_RATES_BY_BATCH_SIZE = {5: 0.1, 10: 0.15, 20:0.175}\nlearning_rate = LEARNING_RATES_BY_BATCH_SIZE[global_batch_size]\n```\n\n----------------------------------------\n\nTITLE: Applying Transformations to Different Dataset Structures\nDESCRIPTION: Demonstrates how dataset transformations like map(), flat_map(), and filter() work with different dataset structures. Shows how the element structure determines the arguments of transformation functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset1 = dataset1.map(lambda x: ...)\n\ndataset2 = dataset2.flat_map(lambda x, y: ...)\n\n# Note: Argument destructuring is not available in Python 3.\ndataset3 = dataset3.filter(lambda x, (y, z): ...)\n```\n\n----------------------------------------\n\nTITLE: Displaying SavedModel CLI 'show' Command Usage\nDESCRIPTION: Shows the usage syntax for the 'show' command in the SavedModel CLI, which is used to examine the contents of a SavedModel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: bash\nCODE:\n```\nusage: saved_model_cli show [-h] --dir DIR [--all]\n[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n```\n\n----------------------------------------\n\nTITLE: Enabling Soft Device Placement in TensorFlow\nDESCRIPTION: This code enables soft device placement, allowing TensorFlow to automatically choose an existing and supported device if the specified one doesn't exist.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntf.config.set_soft_device_placement(True)\ntf.debugging.set_log_device_placement(True)\n\n# Creates some tensors\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\n\nprint(c)\n```\n\n----------------------------------------\n\nTITLE: Using an Initializable Iterator with a TensorFlow Dataset\nDESCRIPTION: Creates a Dataset with random values and demonstrates how to use an initializable iterator. This approach is necessary when the Dataset depends on stateful operations that need initialization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nr = tf.random_normal([10,3])\ndataset = tf.data.Dataset.from_tensor_slices(r)\niterator = dataset.make_initializable_iterator()\nnext_row = iterator.get_next()\n\nsess.run(iterator.initializer)\nwhile True:\n  try:\n    print(sess.run(next_row))\n  except tf.errors.OutOfRangeError:\n    break\n```\n\n----------------------------------------\n\nTITLE: Testing Momentum Optimizer Convergence with Different Learning Rates\nDESCRIPTION: This snippet tests the convergence of the momentum optimizer for different learning rates (1e-3, 1e-2, 1e-1) using a convergence test function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nparam_map_mtm = {}\nlearning_rates = [1e-3, 1e-2, 1e-1]\nfor learning_rate in learning_rates:\n  param_map_mtm[learning_rate] = (convergence_test(\n      Momentum(learning_rate=learning_rate),\n      loss_fn=loss, grad_fn=grad))\n```\n\n----------------------------------------\n\nTITLE: TF1.x Dataset Caching with Dictionaries\nDESCRIPTION: Example showing how dataset caching works in TF1.x using dictionaries to store datasets and iterators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.datasets = {}\n    self.iterators = {}\n\n  def __call__(self, key):\n    if key not in self.datasets:\n      self.datasets[key] = tf.compat.v1.data.Dataset.from_tensor_slices([1, 2, 3])\n      self.iterators[key] = self.datasets[key].make_initializable_iterator()\n    return self.iterators[key]\n\nwith tf.Graph().as_default():\n  with tf.compat.v1.Session() as sess:\n    m = Model()\n    it = m('a')\n    sess.run(it.initializer)\n    for _ in range(3):\n      print(sess.run(it.get_next()))\n```\n\n----------------------------------------\n\nTITLE: Getting the Predicted Label for Single Image\nDESCRIPTION: This snippet extracts the predicted class label from the prediction results for a single image. It uses `np.argmax` to find the index of the class with the highest probability, which represents the model's prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nprediction_result = np.argmax(predictions_single[0])\nprint(prediction_result)\n```\n\n----------------------------------------\n\nTITLE: Checking Dataset Dimensions in TensorFlow\nDESCRIPTION: This code prints the shapes of the frames and labels tensors from the dataset to verify the expected dimensions. This helps confirm the correct structure of the data before training a model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/video/transfer_learning_with_movinet.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"Shape: {frames.shape}\")\nprint(f\"Label: {labels.shape}\")\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: Apache License 2.0 declaration for the TensorFlow documentation, outlining the terms of use, distribution, and modification of the content.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/evaluator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow Imports and Logging for TFLite Migration\nDESCRIPTION: This snippet sets up the necessary TensorFlow imports, configures logging, and defines a utility function to remove directories. It prepares the environment for TFLite migration examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tflite.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\nimport numpy as np\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\n\nimport shutil\ndef remove_dir(path):\n  try:\n    shutil.rmtree(path)\n  except:\n    pass\n```\n\n----------------------------------------\n\nTITLE: Preprocessing News Headlines Data\nDESCRIPTION: Extracts just the headline text from the downloaded dataset, removing publication dates and storing the headlines in a clean format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n!rm -r corpus\n!mkdir corpus\n\nwith open('corpus/text.txt', 'w') as out_file:\n  with open('raw.tsv', 'r') as in_file:\n    for line in in_file:\n      headline = line.split('\\t')[1].strip().strip('\"')\n      out_file.write(headline+\"\\n\")\n```\n\n----------------------------------------\n\nTITLE: Importing the Dataset using Pandas (Python)\nDESCRIPTION: This snippet reads the downloaded dataset using pandas, assigns appropriate column names, manages missing values, and prepares it for analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncolumn_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n                'Acceleration', 'Model Year', 'Origin']\nraw_dataset = pd.read_csv(dataset_path, names=column_names,\n                      na_values = \"?\", comment='\\t',\n                      sep=\" \", skipinitialspace=True)\n\ndataset = raw_dataset.copy()\ndataset.tail()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Zebra Images with Random Jitter\nDESCRIPTION: Creates a plot to visualize a sample zebra image before and after applying random jitter. This demonstrates the effect of image augmentation on zebra images for CycleGAN training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(121)\nplt.title('Zebra')\nplt.imshow(sample_zebra[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Zebra with random jitter')\nplt.imshow(random_jitter(sample_zebra[0]) * 0.5 + 0.5)\n```\n\n----------------------------------------\n\nTITLE: Running Feature Column Inputs\nDESCRIPTION: Executes a feature column input layer within a TensorFlow session. Outputs processed inputs, where categorical data is represented in a dense numerical format for use in further computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_19\n\nLANGUAGE: Python\nCODE:\n```\nprint(sess.run(inputs))\n```\n\n----------------------------------------\n\nTITLE: Installing required packages for Universal Sentence Encoder-Lite\nDESCRIPTION: Installs seaborn for visualization and sentencepiece package which is required for the Universal Sentence Encoder Lite model to process text and perform sentence feature ID lookup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Install seaborn for pretty visualizations\n!pip3 install --quiet seaborn\n# Install SentencePiece package\n# SentencePiece package is needed for Universal Sentence Encoder Lite. We'll\n# use it for all the text processing and sentence feature ID lookup.\n!pip3 install --quiet sentencepiece\n```\n\n----------------------------------------\n\nTITLE: Retrieving Nearest Neighbors for Random Question from SQuAD Dataset\nDESCRIPTION: Selects a random question from the SQuAD dataset, encodes it using the question_encoder, and retrieves the nearest neighbors from the built index for demonstration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n#@title Retrieve nearest neighbors for a random question from SQuAD\nnum_results = 25 #@param {type:\"slider\", min:5, max:40, step:1}\n\nquery = random.choice(questions)\ndisplay_nearest_neighbors(query[0], query[1])\n```\n\n----------------------------------------\n\nTITLE: Creating a Keras layer from TensorFlow Hub model\nDESCRIPTION: Creates a frozen feature extractor layer using the hub.KerasLayer API with a pre-trained model. The layer is set as non-trainable to freeze its weights during transfer learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfeature_extractor_layer = hub.KerasLayer(\n    feature_extractor_model,\n    input_shape=(224, 224, 3),\n    trainable=False)\n```\n\n----------------------------------------\n\nTITLE: Getting the Predicted Label\nDESCRIPTION: This snippet determines the predicted class label for the first image by finding the index with the highest confidence score in the predictions array. `np.argmax` returns the index of the maximum value in the array, representing the predicted class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nnp.argmax(predictions[0])\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Sample Image for FGSM Attack\nDESCRIPTION: Loads a sample Labrador Retriever image, preprocesses it, and runs it through the model to get initial predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimage_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\nimage_raw = tf.io.read_file(image_path)\nimage = tf.image.decode_image(image_raw)\n\nimage = preprocess(image)\nimage_probs = pretrained_model.predict(image)\n```\n\n----------------------------------------\n\nTITLE: FILM Academic Citation in BibTeX Format\nDESCRIPTION: BibTeX citation for the ECCV 2022 paper \"FILM: Frame Interpolation for Large Motion\" that introduced the frame interpolation technique implemented in this code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{reda2022film,\n title = {FILM: Frame Interpolation for Large Motion},\n author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n booktitle = {The European Conference on Computer Vision (ECCV)},\n year = {2022}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Input Pipeline for Distributed Training\nDESCRIPTION: Configure batch sizes and define a scaling function for normalizing image pixel values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nnum_train_examples = ds_info.splits['train'].num_examples\nnum_test_examples = ds_info.splits['test'].num_examples\n\nBUFFER_SIZE = 10000\n\nBATCH_SIZE_PER_REPLICA = 64\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\ndef scale(image, label):\n  image = tf.cast(image, tf.float32)\n  image /= 255\n\n  return image, label\n\ntrain_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\neval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Multiplying Sparse Tensor with Dense Matrix in TensorFlow\nDESCRIPTION: This code snippet shows how to multiply a sparse tensor with a dense matrix using tf.sparse.sparse_dense_matmul. It creates a 2x2 sparse matrix and multiplies it with a 2x1 dense matrix.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nst_c = tf.sparse.SparseTensor(indices=([0, 1], [1, 0], [1, 1]),\n                       values=[13, 15, 17],\n                       dense_shape=(2,2))\n\nmb = tf.constant([[4], [6]])\nproduct = tf.sparse.sparse_dense_matmul(st_c, mb)\n\nprint(product)\n```\n\n----------------------------------------\n\nTITLE: Preventing Unnecessary Retracing with Tensor Arguments in TensorFlow\nDESCRIPTION: Illustrates how using Tensor arguments instead of Python literals can prevent unnecessary retracing in tf.function, improving performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef train_one_step():\n  pass\n\n@tf.function\ndef train(num_steps):\n  print(\"Tracing with num_steps = \", num_steps)\n  tf.print(\"Executing with num_steps = \", num_steps)\n  for _ in tf.range(num_steps):\n    train_one_step()\n\nprint(\"Retracing occurs for different Python arguments.\")\ntrain(num_steps=10)\ntrain(num_steps=20)\n\nprint()\nprint(\"Traces are reused for Tensor arguments.\")\ntrain(num_steps=tf.constant(10))\ntrain(num_steps=tf.constant(20))\n\n```\n\n----------------------------------------\n\nTITLE: Creating a One-Shot Iterator from a TensorFlow Dataset\nDESCRIPTION: Demonstrates how to create a tf.data.Dataset from a tensor and use a one-shot iterator to access its elements. This is the recommended way to stream data into TensorFlow models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmy_data = [\n    [0, 1,],\n    [2, 3,],\n    [4, 5,],\n    [6, 7,],\n]\nslices = tf.data.Dataset.from_tensor_slices(my_data)\nnext_item = slices.make_one_shot_iterator().get_next()\n```\n\n----------------------------------------\n\nTITLE: Displaying SignatureDef Keys for a Tag Set\nDESCRIPTION: Shows how to use the 'show' command to list all available SignatureDef keys for a specific tag set in a SavedModel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\nThe given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\nfollowing keys:\nSignatureDef key: \"classify_x2_to_y3\"\nSignatureDef key: \"classify_x_to_y\"\nSignatureDef key: \"regress_x2_to_y3\"\nSignatureDef key: \"regress_x_to_y\"\nSignatureDef key: \"regress_x_to_y2\"\nSignatureDef key: \"serving_default\"\n```\n\n----------------------------------------\n\nTITLE: Freezing TensorFlow Speech Recognition Model\nDESCRIPTION: This command freezes the trained speech recognition model, converting it to a format suitable for mobile deployment. It specifies the checkpoint to start from and the output file for the frozen graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npython tensorflow/examples/speech_commands/freeze.py \\\n--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000 \\\n--output_file=/tmp/my_frozen_graph.pb\n```\n\n----------------------------------------\n\nTITLE: Defining a Conditional Function for AutoGraph Conversion\nDESCRIPTION: A simple Python function that demonstrates conditional logic which AutoGraph will convert to graph operations. The function squares its input if positive, otherwise returns zero.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef square_if_positive(x):\n  if x > 0:\n    x = x * x\n  else:\n    x = 0.0\n  return x\n```\n\n----------------------------------------\n\nTITLE: Setting Up Input Pipeline for Distributed Training\nDESCRIPTION: Configures the input pipeline with appropriate batch sizes for distributed training, creates datasets from tensors, and distributes them across devices using strategy.experimental_distribute_dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = len(train_images)\n\nBATCH_SIZE_PER_REPLICA = 64\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\nEPOCHS = 10\n```\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n(train_images, train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ntrain_ds = strategy.experimental_distribute_dataset(train_dataset)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices(\n    (test_images, test_labels)).batch(BATCH_SIZE)\ntest_ds = strategy.experimental_distribute_dataset(test_dataset)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Keras Models with Ragged Tensors in Python\nDESCRIPTION: This snippet demonstrates how to save and load a Keras model that works with ragged tensors. It uses a temporary directory to save the model and then loads it back.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\n\nkeras_module_path = tempfile.mkdtemp()\nkeras_model.save(keras_module_path+\"/my_model.keras\")\n\nimported_model = tf.keras.models.load_model(keras_module_path+\"/my_model.keras\")\n\nimported_model(hashed_words.to_tensor())\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Input/Output Specification Format in C++\nDESCRIPTION: Shows the general format for specifying inputs and outputs in TensorFlow op registration. Each input or output follows the pattern '<name>: <io-type-expr>' where name is an alphanumeric identifier and io-type-expr is a type expression.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_37\n\nLANGUAGE: c++\nCODE:\n```\n<name>: <io-type-expr>\n```\n\n----------------------------------------\n\nTITLE: Creating the Base Model from Pre-trained MobileNet V2 - Python\nDESCRIPTION: This snippet demonstrates how to create a base model using the MobileNet V2 architecture, pre-trained on the ImageNet dataset for feature extraction in image classification tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nIMG_SHAPE = (image_size, image_size, 3)\n\n# Create the base model from the pre-trained model MobileNet V2\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n```\n\n----------------------------------------\n\nTITLE: Defining GPU Kernel Header Structure in C++\nDESCRIPTION: Header file defining the template structure for CPU and GPU kernel implementations with ExampleFunctor template class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// kernel_example.h\n#ifndef KERNEL_EXAMPLE_H_\n#define KERNEL_EXAMPLE_H_\n\ntemplate <typename Device, typename T>\nstruct ExampleFunctor {\n  void operator()(const Device& d, int size, const T* in, T* out);\n};\n\n#if GOOGLE_CUDA\n// Partially specialize functor for GpuDevice.\ntemplate <typename Eigen::GpuDevice, typename T>\nstruct ExampleFunctor {\n  void operator()(const Eigen::GpuDevice& d, int size, const T* in, T* out);\n};\n#endif\n\n#endif KERNEL_EXAMPLE_H_\n```\n\n----------------------------------------\n\nTITLE: Fusing Map and Batch Transformations in TensorFlow\nDESCRIPTION: This code snippet shows how to use the map_and_batch transformation to fuse the map and batch operations in a TensorFlow input pipeline. This can provide additional performance benefits for large batch sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/datasets.md#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndataset = dataset.apply(tf.contrib.data.map_and_batch(\n    map_func=parse_fn, batch_size=FLAGS.batch_size))\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing Adversarial Perturbations\nDESCRIPTION: Generates the adversarial perturbations for the input image targeting a specific class label and visualizes these perturbations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Get the input label of the image.\nlabrador_retriever_index = 208\nlabel = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\nlabel = tf.reshape(label, (1, image_probs.shape[-1]))\n\nperturbations = create_adversarial_pattern(image, label)\nplt.imshow(perturbations[0] * 0.5 + 0.5);  # To change [-1, 1] to [0,1]\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow License Header in Python\nDESCRIPTION: A code block containing the Apache License 2.0 header as a Python comment, indicating the licensing terms for the TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Minimum Integer Attribute (C++)\nDESCRIPTION: This code demonstrates setting a minimum value constraint for an `int` attribute. The `Attr` method specifies that the `a` attribute must be an integer greater than or equal to 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_16\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MinIntExample\")\n    .Attr(\"a: int >= 2\");\n```\n\n----------------------------------------\n\nTITLE: Copyright Notice for TensorFlow Hub Documentation\nDESCRIPTION: Standard copyright and license notice for TensorFlow Hub Authors, licensed under Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Monitoring GPU Utilization with NVIDIA SMI\nDESCRIPTION: This command uses NVIDIA's System Management Interface to monitor GPU utilization, memory usage, and availability, outputting the data in CSV format for analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nnvidia-smi\n--query-gpu=utilization.gpu,utilization.memory,memory.total,\nmemory.free,memory.used --format=csv\n```\n\n----------------------------------------\n\nTITLE: Creating Source Datasets in Python\nDESCRIPTION: Creates a TensorFlow Dataset from a tensor slices and a text file. Uses tempfile to create a temporary text file for the TextLineDataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n\n# Create a CSV file\nimport tempfile\n_, filename = tempfile.mkstemp()\n\nwith open(filename, 'w') as f:\n  f.write(\"\"\"Line 1\nLine 2\nLine 3\n  \"\"\")\n\nds_file = tf.data.TextLineDataset(filename)\n```\n\n----------------------------------------\n\nTITLE: Defining TensorFlow Ops with List Type Attributes\nDESCRIPTION: Shows how to register an op that accepts or produces lists of tensors, where all tensors in the list can have different types specified by a list type attribute.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_30\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"PolymorphicListExample\")\n    .Attr(\"T: list(type)\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Using DynamicRaggedShape with TensorFlow Shape Operations\nDESCRIPTION: Demonstrates how DynamicRaggedShape objects can be used with common TensorFlow operations that expect shape inputs, including reshape, zeros, ones, and fill.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"tf.reshape(x, rt_shape) = {tf.reshape(x, rt_shape)}\")\nprint(f\"tf.zeros(rt_shape) = {tf.zeros(rt_shape)}\")\nprint(f\"tf.ones(rt_shape) = {tf.ones(rt_shape)}\")\nprint(f\"tf.fill(rt_shape, 9) = {tf.fill(rt_shape, 'x')}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Checkpoint Objects for Manual Checkpointing\nDESCRIPTION: Creates a tf.train.Checkpoint and tf.train.CheckpointManager to manually manage model checkpoints, tracking the optimizer, model, step counter, and dataset iterator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nopt = tf.keras.optimizers.Adam(0.1)\ndataset = toy_dataset()\niterator = iter(dataset)\nckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\nmanager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n```\n\n----------------------------------------\n\nTITLE: Splitting Dataset into Training and Testing Sets (Python)\nDESCRIPTION: This snippet creates training and testing datasets by sampling 80% of the data for training, ensuring that the model will be evaluated on unseen data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n```\n\n----------------------------------------\n\nTITLE: Running Test Function with Debug Stripper Disabled\nDESCRIPTION: This code executes the debug test function with an invalid input and debug stripper turned off, showing how it raises an error when numeric checks fail.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntest_func = test_function_2()\np1 = tf.constant(float('inf'))\ntry:\n  test_func(p1)\nexcept tf.errors.InvalidArgumentError as e:\n  traceback.print_exc(limit=2)\n```\n\n----------------------------------------\n\nTITLE: Verifying Linear Model Output Shape\nDESCRIPTION: Confirms that the linear model correctly transforms the input shape by printing the input and output tensor shapes, ensuring the model preserves the batch and time dimensions while changing only the feature dimension.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', single_step_window.example[0].shape)\nprint('Output shape:', linear(single_step_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for TensorFlow Object Detection\nDESCRIPTION: This snippet imports the necessary Python libraries and modules for running object detection, including TensorFlow, TensorFlow Hub, NumPy, PIL, and matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport pathlib\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport io\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nfrom six.moves.urllib.request import urlopen\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\ntf.get_logger().setLevel('ERROR')\n```\n\n----------------------------------------\n\nTITLE: Using Reconstructed Keras Model for Prediction in Python\nDESCRIPTION: This snippet illustrates how to use a reconstructed Keras model to make predictions. It demonstrates that the reconstructed model produces the same result when called on the same data as the original model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nreconstructed_model(tf.constant([[2.0, 2.0, 2.0]]))\n```\n\n----------------------------------------\n\nTITLE: Custom Training Loop with tf.function Decoration\nDESCRIPTION: Implements a custom training loop function decorated with tf.function for better performance, showing gradient tape usage for training a model with a dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/effective_tf2.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef train(model, dataset, optimizer):\n  for x, y in dataset:\n    with tf.GradientTape() as tape:\n      # training=True is only needed if there are layers with different\n      # behavior during training versus inference (e.g. Dropout).\n      prediction = model(x, training=True)\n      loss = loss_fn(prediction, y)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n```\n\n----------------------------------------\n\nTITLE: Selecting Specific Columns in CsvDataset\nDESCRIPTION: Configures a CsvDataset to read selected columns only, skipping header lines. This involves specifying defaults for the selected columns and utilizing the header and select_cols options.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\nrecord_defaults = [[0.0]] * 2  # Only provide defaults for the selected columns\ndataset = tf.data.experimental.CsvDataset(filenames, record_defaults, header=True, select_cols=[2,4])\n```\n\n----------------------------------------\n\nTITLE: Applying Rejection Resampling to TensorFlow Dataset\nDESCRIPTION: Demonstrates how to rebalance a dataset using rejection_resample() with target distribution and initial distribution parameters\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_79\n\nLANGUAGE: python\nCODE:\n```\nresample_ds = (\n    creditcard_ds\n    .unbatch()\n    .rejection_resample(class_func, target_dist=[0.5,0.5],\n                        initial_dist=fractions)\n    .batch(10))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Weight and Bias Evolution During Training\nDESCRIPTION: Creates a plot showing how the model's weight and bias parameters evolve during training compared to their true values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(epochs, weights, label='Weights', color=colors[0])\nplt.plot(epochs, [TRUE_W] * len(epochs), '--',\n         label = \"True weight\", color=colors[0])\n\nplt.plot(epochs, biases, label='bias', color=colors[1])\nplt.plot(epochs, [TRUE_B] * len(epochs), \"--\",\n         label=\"True bias\", color=colors[1])\n\nplt.legend()\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Accessing Training History in TensorFlow\nDESCRIPTION: This snippet shows how to access the training history from the History object returned by model.fit(). It retrieves the dictionary containing metrics for each epoch during training and validation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nhistory_dict = history.history\nhistory_dict.keys()\n```\n\n----------------------------------------\n\nTITLE: Analyzing Specific Debug Runs in Bash\nDESCRIPTION: This bash command is used to analyze specific TensorFlow debug runs by specifying the run directory pattern including epoch timestamp and uuid. Useful for sifting through multiple debug sessions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npython -m tensorflow.python.debug.cli.offline_analyzer \\\n    --dump_dir=\"/shared/storage/location/tfdbg_dumps_1/run_<epoch_timestamp_microsec>_<uuid>\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Bit-Widening with Old Type Promotion in TensorFlow\nDESCRIPTION: This example shows how the old type promotion tends to widen types to 64-bit, resulting in float64 output even when lower precision would be sufficient.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nnp.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float64, numpy=54.19921875>\n```\n\n----------------------------------------\n\nTITLE: Creating a Helper Function to Display Adversarial Images with Predictions\nDESCRIPTION: Defines a function to display adversarial images along with their predicted classes and confidence scores to evaluate the effectiveness of the attack.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef display_images(image, description):\n  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n  plt.figure()\n  plt.imshow(image[0]*0.5+0.5)\n  plt.title('{} \\n {} : {:.2f}% Confidence'.format(description,\n                                                   label, confidence*100))\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Creating Validation Set from Training Data\nDESCRIPTION: Partition the training data into a validation set and partial training set. Reserves 10,000 examples for validation to monitor model performance during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nx_val = train_data[:10000]\npartial_x_train = train_data[10000:]\n\ny_val = train_labels[:10000]\npartial_y_train = train_labels[10000:]\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Random Seed in Python\nDESCRIPTION: This snippet imports TensorFlow and other necessary libraries, prints the TensorFlow version, and sets a random seed for reproducible results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib\nfrom matplotlib import pyplot as plt\nprint(\"TensorFlow version:\", tf.__version__)\n# Set a random seed for reproducible results \ntf.random.set_seed(22)\n```\n\n----------------------------------------\n\nTITLE: Plotting Loss Metrics for Model Evaluation\nDESCRIPTION: Code snippet that calls the plotting function to visualize training and validation loss over epochs, helping to assess model convergence and potential overfitting.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nplot_metrics(train_losses, val_losses, \"cross entropy loss\")\n```\n\n----------------------------------------\n\nTITLE: Using tf.sparse.reduce_max with Sparse Tensors in TensorFlow\nDESCRIPTION: This snippet demonstrates how tf.sparse.reduce_max treats implicit zeros differently from explicit zeros when applied to a sparse tensor. It shows the result of finding the maximum value in a sparse tensor created from a dense tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.sparse.reduce_max(tf.sparse.from_dense([-5, 0, -3])))\n```\n\n----------------------------------------\n\nTITLE: Loading and initializing SentencePiece model from TF-Hub module\nDESCRIPTION: Retrieves the SentencePiece model from the TF-Hub module's assets and initializes the SentencePiece processor for text tokenization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith tf.Session() as sess:\n  spm_path = sess.run(module(signature=\"spm_path\"))\n\nsp = spm.SentencePieceProcessor()\nwith tf.io.gfile.GFile(spm_path, mode=\"rb\") as f:\n  sp.LoadFromSerializedProto(f.read())\nprint(\"SentencePiece model loaded at {}.\".format(spm_path))\n```\n\n----------------------------------------\n\nTITLE: Op with Explicit Type Attribute in TensorFlow\nDESCRIPTION: Example of registering an op with an explicit output type attribute that must be specified by the user, rather than being inferred from the input type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_22\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"StringToNumber\")\n    .Input(\"string_tensor: string\")\n    .Output(\"output: out_type\")\n    .Attr(\"out_type: {float, int32} = DT_FLOAT\");\n    .Doc(R\"doc(\nConverts each string in the input Tensor to the specified numeric type.\n)doc\");\n```\n\n----------------------------------------\n\nTITLE: Implementing Shape Function for ZeroOut Op in C++\nDESCRIPTION: This snippet shows how to implement a shape function for the 'ZeroOut' operation in C++. It demonstrates setting the output shape to be the same as the input shape using the TensorFlow shape inference API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_49\n\nLANGUAGE: c++\nCODE:\n```\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n  c->set_output(0, c->input(0));\n  return Status::OK();\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Quick Draw RNN Training Script (Shell)\nDESCRIPTION: Command to execute the training script for the RNN-based drawing classifier model, specifying the paths to training data, evaluation data, and class definitions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython train_model.py \\\n  --training_data=rnn_tutorial_data/training.tfrecord-?????-of-????? \\\n  --eval_data=rnn_tutorial_data/eval.tfrecord-?????-of-????? \\\n  --classes_file=rnn_tutorial_data/training.tfrecord.classes\n```\n\n----------------------------------------\n\nTITLE: Creating RaggedTensor with Row Splits Encoding\nDESCRIPTION: Demonstrates how to create a RaggedTensor using the row_splits encoding, which specifies the split points between rows in the flattened values tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_55\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_row_splits(\n    values=[3, 1, 4, 1, 5, 9, 2],\n    row_splits=[0, 4, 4, 6, 7])\nprint(rt)\n```\n\n----------------------------------------\n\nTITLE: Customizing Cross-Device Communication in MirroredStrategy\nDESCRIPTION: Initialize a MirroredStrategy with a custom cross-device communication method using the HierarchicalCopyAllReduce algorithm.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy(\n    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n```\n\n----------------------------------------\n\nTITLE: Adjusting Image Brightness in TensorFlow Python\nDESCRIPTION: Demonstrates the tf.image.adjust_brightness function to modify the brightness of an image. This is part of the image adjustment capabilities in the tf.image module.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntf.image.adjust_brightness\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for BigBiGAN Usage\nDESCRIPTION: Imports necessary Python libraries including TensorFlow, TensorFlow Hub, NumPy, and PIL for image processing and display.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport io\nimport IPython.display\nimport PIL.Image\nfrom pprint import pformat\n\nimport numpy as np\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\n```\n\n----------------------------------------\n\nTITLE: Testing Nearly Fully Native Model\nDESCRIPTION: Tests the nearly fully native model to capture its outputs and regularization losses for comparison. This step ensures that further migration steps continue to maintain the original model's behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nrandom_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\nwith random_tool.scope():\n  tf.keras.utils.set_random_seed(42)\n  layer = NearlyFullyNativeModel(10)\n\n  inputs = tf.random.normal(shape=(10, 5, 5, 5))\n  migrated_output = layer(inputs)\n\n  # Grab the regularization loss as well\n  migrated_regularization_loss = tf.math.add_n(layer.losses)\n\nprint(migrated_regularization_loss)\n```\n\n----------------------------------------\n\nTITLE: Importing Supporting Libraries\nDESCRIPTION: Imports additional libraries including pathlib, os, matplotlib, pandas, and numpy that will be used for data manipulation, visualization, and file handling in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nnp.set_printoptions(precision=4)\n```\n\n----------------------------------------\n\nTITLE: Listing and Shuffling Image Paths\nDESCRIPTION: This snippet lists all image paths in the dataset, shuffles them, and counts the total number of images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport random\nall_image_paths = list(data_root.glob('*/*'))\nall_image_paths = [str(path) for path in all_image_paths]\nrandom.shuffle(all_image_paths)\n\nimage_count = len(all_image_paths)\nimage_count\n```\n\n----------------------------------------\n\nTITLE: Initializing ParameterServerStrategy with Variable Partitioning\nDESCRIPTION: Sets up a ParameterServerStrategy instance with MinSizePartitioner for variable sharding across parameter servers. The partitioner ensures variables are split into appropriate shard sizes with a minimum of 256KB per shard.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nvariable_partitioner = (\n    tf.distribute.experimental.partitioners.MinSizePartitioner(\n        min_shard_bytes=(256 << 10),\n        max_shards=NUM_PS))\n\nstrategy = tf.distribute.ParameterServerStrategy(\n    cluster_resolver,\n    variable_partitioner=variable_partitioner)\n```\n\n----------------------------------------\n\nTITLE: Visualizing MoViNet Predictions Over Time\nDESCRIPTION: Plots the probability of the top predicted class over time as the model processes the video frames sequentially.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nid = tf.argmax(probabilities[-1])\nplt.plot(probabilities[:, id])\nplt.xlabel('Frame #')\nplt.ylabel(f\"p('{KINETICS_600_LABELS[id]}')\")\n```\n\n----------------------------------------\n\nTITLE: Manual Module Download and Loading\nDESCRIPTION: Bash commands to manually download and extract a TF Hub module, followed by Python code to load it locally.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_issues.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Create a folder for the TF hub module.\n$ mkdir /tmp/moduleA\n# Download the module, and uncompress it to the destination folder. You might want to do this manually.\n$ curl -L \"https://tfhub.dev/google/universal-sentence-encoder/2?tf-hub-format=compressed\" | tar -zxvC /tmp/moduleA\n# Test to make sure it works.\n$ python\n> import tensorflow_hub as hub\n> hub.Module(\"/tmp/moduleA\")\n```\n\n----------------------------------------\n\nTITLE: Parsing TensorFlow Example Protocol Buffers\nDESCRIPTION: Function to parse TFRecord Example protocol buffers containing image and text data. Extracts encoded image and text features from the examples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_76\n\nLANGUAGE: python\nCODE:\n```\ndef tf_parse(eg):\n  example = tf.io.parse_example(\n      eg[tf.newaxis], {\n          'image/encoded': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n          'image/text': tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n      })\n  return example['image/encoded'][0], example['image/text'][0]\n```\n\n----------------------------------------\n\nTITLE: Visualizing ReLU Activation Function with TensorFlow\nDESCRIPTION: Plots the ReLU activation function across a range of input values using TensorFlow. ReLU outputs the input if positive and 0 otherwise.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linspace(-2, 2, 201)\nx = tf.cast(x, tf.float32)\nplt.plot(x, tf.nn.relu(x));\nplt.xlabel('x')\nplt.ylabel('ReLU(x)')\nplt.title('ReLU activation function');\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training Loop in Python\nDESCRIPTION: This snippet runs the training loop in a TensorFlow session, initializing variables and the input iterator. It executes the defined training step for a specified number of iterations, demonstrating the overall workflow for distributed training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nwith mirrored_strategy.scope():\n  input_iterator = dist_dataset.make_initializable_iterator()\n  iterator_init = input_iterator.initializer\n  var_init = tf.global_variables_initializer()\n  loss = train_step(input_iterator.get_next())\n  with tf.Session() as sess:\n    sess.run([var_init, iterator_init])\n    for _ in range(10):\n      print(sess.run(loss))\n```\n\n----------------------------------------\n\nTITLE: Setting up license and copyright information in Python\nDESCRIPTION: This code defines the license information for the TensorFlow tutorial, specifying the Apache License 2.0 terms that govern the use of the tutorial code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing necessary libraries for audio processing in Python\nDESCRIPTION: This code imports the required Python modules including TensorFlow, NumPy, Matplotlib, and Seaborn for audio processing, model building, and visualization. It also sets a random seed for reproducibility.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom IPython import display\n\n# Set the seed value for experiment reproducibility.\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n```\n\n----------------------------------------\n\nTITLE: Creating a nested RaggedTensor using from_nested_row_splits in TensorFlow\nDESCRIPTION: Demonstrates a more convenient way to create a RaggedTensor with multiple ragged dimensions by providing a list of row_splits tensors to the from_nested_row_splits factory method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.RaggedTensor.from_nested_row_splits(\n    flat_values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n    nested_row_splits=([0, 1, 1, 5], [0, 3, 3, 5, 9, 10]))\nprint(rt)\n```\n\n----------------------------------------\n\nTITLE: Creating Scoped TensorFlow Operations with Name Scope\nDESCRIPTION: Demonstrates how to use tf.name_scope to organize TensorFlow operations into hierarchical groups. Creates three operations (constant and variables) under a 'hidden' namespace for better graph visualization organization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graph_viz.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nwith tf.name_scope('hidden') as scope:\n  a = tf.constant(5, name='alpha')\n  W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0), name='weights')\n  b = tf.Variable(tf.zeros([1]), name='biases')\n```\n\n----------------------------------------\n\nTITLE: Counting Variables in ResNet Block\nDESCRIPTION: Displays the number of variables in the ResNet block to understand the model's complexity.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nlen(block.variables)\n```\n\n----------------------------------------\n\nTITLE: Creating Serving Input Receiver Function with TensorFlow in Python\nDESCRIPTION: Defines a serving input receiver function for TensorFlow models that accepts serialized tf.Example inputs. This function specifies a feature dictionary and uses tf.parse_example to parse incoming data. Dependencies include TensorFlow and properly configured feature specifications.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nfeature_spec = {'foo': tf.FixedLenFeature(...),\n                'bar': tf.VarLenFeature(...)}\n\ndef serving_input_receiver_fn():\n  \"\"\"An input receiver that expects a serialized tf.Example.\"\"\"\n  serialized_tf_example = tf.placeholder(dtype=tf.string,\n                                         shape=[default_batch_size],\n                                         name='input_example_tensor')\n  receiver_tensors = {'examples': serialized_tf_example}\n  features = tf.parse_example(serialized_tf_example, feature_spec)\n  return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n```\n\n----------------------------------------\n\nTITLE: Inspecting the audio dataset structure\nDESCRIPTION: This code displays the structure of the created dataset, showing the types and shapes of the audio data and labels in each batch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_ds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Mode in TensorFlow Custom Estimator\nDESCRIPTION: This snippet shows how to implement the training mode in a custom Estimator. It creates an optimizer, builds a training operation, and returns an EstimatorSpec with loss and train_op.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\noptimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n```\n\n----------------------------------------\n\nTITLE: Training Image Classification Model with TensorFlow\nDESCRIPTION: Trains the model for 5 epochs on the flower dataset, using the prepared training and validation datasets. Training progress is tracked through the history object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsteps_per_epoch = train_size // BATCH_SIZE\nvalidation_steps = valid_size // BATCH_SIZE\nhist = model.fit(\n    train_ds,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,\n    validation_steps=validation_steps).history\n```\n\n----------------------------------------\n\nTITLE: Loading and Using Image Classification Module in TensorFlow\nDESCRIPTION: Example showing how to load an image classification module and obtain classification logits for a batch of images. The module maps images to class scores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/images.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n  module_spec = hub.load_module_spec(\"path/to/module\")\n  height, width = hub.get_expected_image_size(module_spec)\n  images = ...  # A batch of images with shape [batch_size, height, width, 3].\n  module = hub.Module(module_spec)\n  logits = module(images)   # A batch with shape [batch_size, num_classes].\n```\n\n----------------------------------------\n\nTITLE: Converting Compressible Model to Compressed Model in TensorFlow\nDESCRIPTION: This function clones a compressible model and converts its layers to compressed versions. It uses tf.keras.models.clone_model with a custom clone function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef compress_layer(layer):\n  if isinstance(layer, CompressibleDense):\n    return CompressedDense.copy(layer)\n  if isinstance(layer, CompressibleConv2D):\n    return CompressedConv2D.copy(layer)\n  return type(layer).from_config(layer.get_config())\n\ncompressed_classifier = tf.keras.models.clone_model(\n    compressible_classifier, clone_function=compress_layer)\n```\n\n----------------------------------------\n\nTITLE: Selective Debugging Using Thread Name Filters in Python\nDESCRIPTION: Shows how to configure `LocalCLIDebugWrapperSession` to only debug specific threads, using `thread_name_filter`. The example targets debugging the main thread, relying on Python's default thread naming.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nsess = tf_debug.LocalCLIDebugWrapperSession(sess, thread_name_filter=\"MainThread$\")\n```\n\n----------------------------------------\n\nTITLE: Writing TFRecord File with Image Examples in Python\nDESCRIPTION: This snippet demonstrates how to write TFRecord examples to a file. It processes image files, creates TFRecord examples, and writes them to 'images.tfrecords'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nwith tf.python_io.TFRecordWriter('images.tfrecords') as writer:\n  for filename, label in image_labels.items():\n    image_string = open(filename, 'rb').read()\n    tf_example = image_example(image_string, label)\n    writer.write(tf_example.SerializeToString())\n```\n\n----------------------------------------\n\nTITLE: Compiling TensorFlow Model with Adam Optimizer and Binary Crossentropy Loss\nDESCRIPTION: Configure the neural network model with an optimizer, loss function, and accuracy metric for binary classification. Uses Adam optimizer and binary cross-entropy loss to train the model effectively.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['acc'])\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing Test Dataset\nDESCRIPTION: Downloads the test dataset from a URL and prepares it for evaluation. The code uses TensorFlow's utilities to fetch the file and creates a CSV dataset with appropriate configurations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntest_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n\ntest_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n                                  origin=test_url)\n```\n\n----------------------------------------\n\nTITLE: Actor-Critic Model Implementation\nDESCRIPTION: Definition of ActorCritic class inheriting from tf.keras.Model with both actor and critic components\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass ActorCritic(tf.keras.Model):\n  \"\"\"Combined actor-critic network.\"\"\"\n\n  def __init__(\n      self,\n      num_actions: int,\n      num_hidden_units: int):\n    \"\"\"Initialize.\"\"\"\n    super().__init__()\n\n    self.common = layers.Dense(num_hidden_units, activation=\"relu\")\n    self.actor = layers.Dense(num_actions)\n    self.critic = layers.Dense(1)\n\n  def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n    x = self.common(inputs)\n    return self.actor(x), self.critic(x)\n```\n\n----------------------------------------\n\nTITLE: Creating MirroredStrategy for Distributed Training\nDESCRIPTION: Initializes a tf.distribute.MirroredStrategy to distribute training across available GPUs and prints the number of devices that will be used for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# If the list of devices is not specified in the\n# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\nstrategy = tf.distribute.MirroredStrategy()\n```\n\nLANGUAGE: python\nCODE:\n```\nprint ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n```\n\n----------------------------------------\n\nTITLE: Getting the predicted class index\nDESCRIPTION: This snippet uses tf.argmax to find the predicted class index from the predictions. It then prints the predicted class index and the corresponding labels. Since the model is untrained, these predictions are random.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\nprint(\"    Labels: {}\".format(labels))\n```\n\n----------------------------------------\n\nTITLE: Defining TF_CONFIG for Multi-Worker Setup\nDESCRIPTION: Creating a TF_CONFIG dictionary that defines the cluster configuration with two workers running on localhost with different ports. This is required for distributed training coordination.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntf_config = {\n    'cluster': {\n        'worker': ['localhost:12345', 'localhost:23456']\n    },\n    'task': {'type': 'worker', 'index': 0}\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Ragged Rank and Flat Values of a RaggedTensor in TensorFlow\nDESCRIPTION: This snippet demonstrates how to access the ragged rank and flat values of a previously created ragged tensor. It verifies the relationship between ragged rank and nested row splits, and prints the flat values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_59\n\nLANGUAGE: python\nCODE:\n```\nassert conversations.ragged_rank == len(conversations.nested_row_splits)\nconversations.ragged_rank  # Number of partitioned dimensions.\n```\n\nLANGUAGE: python\nCODE:\n```\nconversations.flat_values.numpy()\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow Hub Encoder with Keras in Python\nDESCRIPTION: Shows how to load a TensorFlow Hub encoder as a Keras layer and use it to process encoder inputs. This approach allows for integration with Keras models and potential fine-tuning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/text.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nencoder = hub.KerasLayer(\"path/to/encoder\", trainable=True)\nencoder_outputs = encoder(encoder_inputs)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Serving API Libraries in Python\nDESCRIPTION: Python imports for TensorFlow Serving API protocol buffer libraries. These imports allow client code to access the classification, regression, prediction, and service definitions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import regression_pb2\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import prediction_service_pb2\n```\n\n----------------------------------------\n\nTITLE: Using Tensor References for Hashing in TF2\nDESCRIPTION: Shows how to create hashable references to tensors using the .ref() method in TensorFlow 2.0, allowing them to be used in sets or as dictionary keys.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.enable_tensor_equality()\nx = tf.Variable(0.0)\n\ntensor_set = set([x.ref(), tf.constant(2.0).ref()])\nassert x.ref() in tensor_set\n\ntensor_set\n```\n\n----------------------------------------\n\nTITLE: Defining and Compiling Keras Model with MirroredStrategy\nDESCRIPTION: Create a Keras sequential model for MNIST classification and compile it within the MirroredStrategy scope.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ])\n\n  model.compile(loss='sparse_categorical_crossentropy',\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Calculating Steps per Epoch for Training\nDESCRIPTION: Computes the number of steps required for one epoch of training based on the dataset size and batch size. This ensures all data is processed during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nsteps_per_epoch=tf.ceil(len(all_image_paths)/BATCH_SIZE).numpy()\nsteps_per_epoch\n```\n\n----------------------------------------\n\nTITLE: Implementing Dense Layer Module\nDESCRIPTION: Creates a custom dense (linear) layer implementation using tf.Module with weights and bias variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Dense(tf.Module):\n  def __init__(self, in_features, out_features, name=None):\n    super().__init__(name=name)\n    self.w = tf.Variable(\n      tf.random.normal([in_features, out_features]), name='w')\n    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n  def __call__(self, x):\n    y = tf.matmul(x, self.w) + self.b\n    return tf.nn.relu(y)\n```\n\n----------------------------------------\n\nTITLE: TensorShape API Error Example - Missing value Attribute\nDESCRIPTION: Demonstrates an AttributeError that can occur when trying to access the .value attribute on an integer dimension in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  # Create a shape and choose an index\n  shape = tf.TensorShape([16, None, 256])\n  value = shape[0].value\nexcept AttributeError as e:\n  # 'int' object has no attribute 'value'\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Implementing Evaluation Step for DTensor Model\nDESCRIPTION: Defines a custom evaluation step function that computes loss and metrics for the DTensor model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef eval_step(model, x, y, metrics):\n  logits = model(x, training=False)\n  loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n        y, logits, from_logits=True))\n\n  for metric in metrics.values():\n    metric.update_state(y_true=y, y_pred=logits)\n\n  loss_per_sample = loss / len(x)\n  results = {'eval_loss': loss_per_sample}\n  return results\n```\n\n----------------------------------------\n\nTITLE: Computing Language Embeddings in Batches\nDESCRIPTION: Computes sentence embeddings in batches using a pre-trained model to handle GPU memory constraints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 2048\nlanguage_to_embeddings = {}\nfor language_code, zip_file, news_file, language_name in corpus_metadata:\n  print('\\nComputing {} embeddings'.format(language_name))\n  with tqdm(total=len(language_to_sentences[language_code])) as pbar:\n    for batch in pd.read_csv(language_to_news_path[language_code], sep='\\t',header=None, chunksize=batch_size):\n      language_to_embeddings.setdefault(language_code, []).extend(embed_text(batch[0]))\n      pbar.update(len(batch))\n```\n\n----------------------------------------\n\nTITLE: TensorShape API Error Example - Missing Dimension Methods\nDESCRIPTION: Shows an AttributeError that can occur when trying to use dimension methods on None values in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  # Create a shape and choose an index\n  shape = tf.TensorShape([16, None, 256])\n  dim = shape[1]\n  other_dim = shape[2]\n  dim.assert_is_compatible_with(other_dim)\nexcept AttributeError as e:\n  # 'NoneType' object has no attribute 'assert_is_compatible_with'\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Hub Transfer Learning\nDESCRIPTION: This snippet imports the necessary Python libraries for working with TensorFlow, TensorFlow Hub, and image processing. It also loads the TensorBoard extension for visualization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\nimport time\n\nimport PIL.Image as Image\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport datetime\n\n%load_ext tensorboard\n```\n\n----------------------------------------\n\nTITLE: Serializing Tensor Dataset for TFRecord Storage\nDESCRIPTION: Converts a dataset of image tensors to serialized format and writes it to a TFRecord file. This preserves the preprocessed state of the images for faster loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nds = image_ds.map(tf.serialize_tensor)\nds\n\ntfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\ntfrec.write(ds)\n```\n\n----------------------------------------\n\nTITLE: Setting Up New Model and Continuing Training\nDESCRIPTION: Demonstrates how to create new model instances but continue training from a previously saved checkpoint, maintaining the training state.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nopt = tf.keras.optimizers.Adam(0.1)\nnet = Net()\ndataset = toy_dataset()\niterator = iter(dataset)\nckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\nmanager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n\ntrain_and_checkpoint(net, manager)\n```\n\n----------------------------------------\n\nTITLE: Running Image Classification with Inception-v3 in Python\nDESCRIPTION: Commands to clone the TensorFlow models repository and run image classification using the pre-trained Inception-v3 model. The script downloads the model (~200MB) on first run and classifies a sample panda image by default.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd models/tutorials/image/imagenet\npython classify_image.py\n```\n\n----------------------------------------\n\nTITLE: Setup for New Type Promotion Example in TensorFlow-NumPy\nDESCRIPTION: This code sets up variables for demonstrating the new type promotion behavior by enabling the new dtype conversion mode and creating arrays of different types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\na = np.array(1, dtype=np.int8)\nb = tf.constant(1)\nc = np.array(1, dtype=np.float16)\n```\n\n----------------------------------------\n\nTITLE: Protocol Buffer Files Referenced in TensorFlow API\nDESCRIPTION: List of core protocol buffer files that are part of TensorFlow's public API and covered by compatibility guarantees. These files define key data structures and configurations used throughout TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/version_compat.md#2025-04-21_snippet_0\n\nLANGUAGE: Protocol Buffers\nCODE:\n```\nattr_value\nconfig\nevent\ngraph\nop_def\nreader_base\nsummary\ntensor\ntensor_shape\ntypes\n```\n\n----------------------------------------\n\nTITLE: Calculating Gradients with tf.GradientTape\nDESCRIPTION: Defines a gradient calculation function using tf.GradientTape context. The function computes the loss value and returns both the loss and the gradients with respect to the model's trainable variables.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef grad(model, inputs, targets):\n  with tf.GradientTape() as tape:\n    loss_value = loss(model, inputs, targets)\n  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n```\n\n----------------------------------------\n\nTITLE: Training a TensorFlow Model with Early Stopping\nDESCRIPTION: This code trains the model using the fit method, with training and validation data, for 5 epochs. It includes the early stopping callback to potentially halt training early.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(train_data, \n                    validation_data=validation_data, \n                    epochs=5, \n                    callbacks=[early_stopping_callback])\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for ESRGAN Image Enhancement\nDESCRIPTION: Imports necessary Python libraries for image processing, TensorFlow operations, TensorFlow Hub, and visualization. Sets environment variable to display TensorFlow Hub download progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport time\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nos.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n```\n\n----------------------------------------\n\nTITLE: Exploring LibriSpeech File Structure\nDESCRIPTION: Explores the file structure of the LibriSpeech dataset, identifying FLAC audio files and text transcription files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndata_dir = \"./data/train/LibriSpeech/dev-clean/2428/83705/\"\nall_files = os.listdir(data_dir)\n\nflac_files = [f for f in all_files if f.endswith(\".flac\")]\ntxt_files = [f for f in all_files if f.endswith(\".txt\")]\n\nprint(\"Transcription files:\", txt_files, \"\\nSound files:\", flac_files)\n```\n\n----------------------------------------\n\nTITLE: Testing Frozen Speech Recognition Model\nDESCRIPTION: This command tests the frozen speech recognition model using the label_wav.py script. It specifies the frozen graph, label file, and a WAV file to classify.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npython tensorflow/examples/speech_commands/label_wav.py \\\n--graph=/tmp/my_frozen_graph.pb \\\n--labels=/tmp/speech_commands_train/conv_labels.txt \\\n--wav=/tmp/speech_dataset/left/a5d485dc_nohash_0.wav\n```\n\n----------------------------------------\n\nTITLE: Normalizing Feature Data (Python)\nDESCRIPTION: This snippet normalizes the dataset features using the training dataset's mean and standard deviation, promoting effective training by standardizing the input values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Implicit Conversions in tf.constant with New Type Promotion\nDESCRIPTION: This example shows how tf.constant allows implicit conversion of tensors to the specified dtype, converting an int16 tensor to float32.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ntnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\na = tf.constant(10, tf.int16)\ntf.constant(a, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=10.0>\n```\n\n----------------------------------------\n\nTITLE: Dataset Caching Issues in tf.function\nDESCRIPTION: Example showing how dictionary-based dataset caching fails in tf.function due to Python side effects being ignored.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.datasets = {}\n    self.iterators = {}\n\n  @tf.function\n  def __call__(self, key):\n    if key not in self.datasets:\n      self.datasets[key] = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n      self.iterators[key] = iter(self.datasets[key])\n    return self.iterators[key]\n\nm = Model()\nfor _ in range(3):\n  print(next(m('a')))\n```\n\n----------------------------------------\n\nTITLE: Running the TensorFlow Graph for Image Processing\nDESCRIPTION: This snippet runs the TensorFlow session with the constructed model to obtain results after processing the input image through the graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_7\n\nLANGUAGE: C++\nCODE:\n```\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(b.ToGraphDef(&graph));\n\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n```\n\n----------------------------------------\n\nTITLE: Setting Up TPUEstimator in TensorFlow 1\nDESCRIPTION: Creates a TPUClusterResolver, RunConfig, and TPUEstimator for training and evaluation on TPUs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ncluster_resolver = tf1.distribute.cluster_resolver.TPUClusterResolver(tpu='')\nprint(\"All devices: \", tf1.config.list_logical_devices('TPU'))\n\ntpu_config = tf1.estimator.tpu.TPUConfig(iterations_per_loop=10)\nconfig = tf1.estimator.tpu.RunConfig(\n    cluster=cluster_resolver,\n    save_checkpoints_steps=None,\n    tpu_config=tpu_config)\nestimator = tf1.estimator.tpu.TPUEstimator(\n    model_fn=_model_fn,\n    config=config,\n    train_batch_size=8,\n    eval_batch_size=8)\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow with MKL Optimizations (Post v1.3.0)\nDESCRIPTION: Bash commands to compile TensorFlow with Intel MKL (Math Kernel Library) optimizations for versions after 1.3.0. These optimizations significantly improve performance for CNN-based models on Intel processors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/performance/overview.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./configure\n# Pick the desired options\nbazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package\n```\n\n----------------------------------------\n\nTITLE: Testing Model Output Shape in TensorFlow\nDESCRIPTION: Takes a single batch from the dataset and passes it through the model to verify the output shape, which should be (batch_size, sequence_length, vocab_size).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfor input_example_batch, target_example_batch in dataset.take(1):\n  example_batch_predictions = model(input_example_batch)\n  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n```\n\n----------------------------------------\n\nTITLE: License and Copyright Declaration Python\nDESCRIPTION: Standard Apache 2.0 license header for TensorFlow Hub Authors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Managing GPU Memory with Variables in TensorFlow\nDESCRIPTION: This snippet demonstrates how to manage GPU memory using variables in eager execution mode. It creates a variable on the GPU and then sets it to None to free up the GPU memory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  with tf.device(\"gpu:0\"):\n    v = tf.Variable(tf.random_normal([1000, 1000]))\n    v = None  # v no longer takes up GPU memory\n```\n\n----------------------------------------\n\nTITLE: Filtering and Displaying Video Files from Dataset\nDESCRIPTION: Retrieves all files from the remote zip URL, filters to include only .avi video files, and displays the first 10 entries to inspect the data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfiles = list_files_from_zip_url(URL)\nfiles = [f for f in files if f.endswith('.avi')]\nfiles[:10]\n```\n\n----------------------------------------\n\nTITLE: Training Loop for Skip-gram Model in Python\nDESCRIPTION: Implements the training loop that feeds batches of input data to the model, executes the optimizer operation, and tracks the loss over time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfor inputs, labels in generate_batch(...):\n  feed_dict = {train_inputs: inputs, train_labels: labels}\n  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)\n```\n\n----------------------------------------\n\nTITLE: Model Inference Implementation\nDESCRIPTION: Performs inference on audio frames and processes the model predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bird_vocalization_classifier.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nall_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\nfor window in fixed_tm[1:]:\n  logits, embeddings = model.infer_tf(window[np.newaxis, :])\n  all_logits = np.concatenate([all_logits, logits], axis=0)\n\nframe = 0\nfor frame_logits in all_logits:\n  probabilities = tf.nn.softmax(frame_logits)\n  argmax = np.argmax(probabilities)\n  print(f\"For frame {frame}, the audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[argmax]}\")\n  frame += 1\n```\n\n----------------------------------------\n\nTITLE: IMDB Dataset Processing\nDESCRIPTION: Loading and processing the IMDB dataset with multi-hot encoding of sequences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nNUM_WORDS = 10000\n\n(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n\ndef multi_hot_sequences(sequences, dimension):\n    # Create an all-zero matrix of shape (len(sequences), dimension)\n    results = np.zeros((len(sequences), dimension))\n    for i, word_indices in enumerate(sequences):\n        results[i, word_indices] = 1.0  # set specific indices of results[i] to 1s\n    return results\n\n\ntrain_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\ntest_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)\n```\n\n----------------------------------------\n\nTITLE: Deprecating TensorFlow Ops\nDESCRIPTION: Example showing how to deprecate an operator in TensorFlow using the REGISTER_OP macro with deprecation notice.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/versions.md#2025-04-21_snippet_1\n\nLANGUAGE: cpp\nCODE:\n```\nREGISTER_OP(...).Deprecated(deprecated_at_version, message)\n```\n\n----------------------------------------\n\nTITLE: Bucketizing and One-hot Encoding with Keras\nDESCRIPTION: Shows how to bucketize and one-hot encode numeric features using Keras Discretization and CategoryEncoding layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndiscretization_layer = tf.keras.layers.Discretization(bin_boundaries=[1, 4, 5])\none_hot_layer = tf.keras.layers.CategoryEncoding(\n    num_tokens=4, output_mode='one_hot')\none_hot_layer(discretization_layer([1., 2., 3., 4., 5.]))\n```\n\n----------------------------------------\n\nTITLE: Registering Polymorphic TensorFlow Op in C++\nDESCRIPTION: Example of registering a polymorphic TensorFlow operation using attribute-based type specification. The op accepts a single input with a type determined by attribute 'T', allowing for type flexibility at graph construction time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_39\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"PolymorphicSingleInput\")\n    .Attr(\"T: type\")\n    .Input(\"in: T\");\n```\n\n----------------------------------------\n\nTITLE: Creating Embedding Column in TensorFlow\nDESCRIPTION: This snippet shows how to create an embedding column from a categorical column in TensorFlow. The embedding column is suitable for handling a larger number of categories while maintaining efficiency in learning representations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nembedding_column = tf.feature_column.embedding_column(\\\n    categorical_column=categorical_column,\\\n    dimension=embedding_dimensions)\n```\n\n----------------------------------------\n\nTITLE: Computing Posterior Mean Probability in TensorFlow\nDESCRIPTION: This function computes the posterior mean probability using the mean-field method, adjusting logits based on uncertainty.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef compute_posterior_mean_probability(logits, covmat, lambda_param=np.pi / 8.):\n  # Computes uncertainty-adjusted logits using the built-in method.\n  logits_adjusted = nlp_layers.gaussian_process.mean_field_logits(\n      logits, covmat, mean_field_factor=lambda_param)\n  \n  return tf.nn.softmax(logits_adjusted, axis=-1)[:, 0]\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and TensorFlow Version Check - Python\nDESCRIPTION: This snippet imports necessary libraries and checks the TensorFlow version being used. It is crucial to ensure compatibility with the provided code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\nprint(\"TensorFlow version is \", tf.__version__)\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n```\n\n----------------------------------------\n\nTITLE: Testing Conv1D Model on Wide Window Input\nDESCRIPTION: Demonstrates the flexibility of the convolutional model by showing it can handle wider input windows, producing appropriately sized output predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Wide window\")\nprint('Input shape:', wide_window.example[0].shape)\nprint('Labels shape:', wide_window.example[1].shape)\nprint('Output shape:', conv_model(wide_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Type Conversion in Binary Operations with New Type Promotion\nDESCRIPTION: This example shows how binary operations between different types follow the new type promotion rules, converting int16 and float32 to float32.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ntf.constant(5, tf.int16) - tf.constant(1, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n```\n\n----------------------------------------\n\nTITLE: License Declarations in Python\nDESCRIPTION: License declarations for the TensorFlow tutorial, including both Apache 2.0 and MIT licenses.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python for TensorFlow Documentation\nDESCRIPTION: License declaration for the TensorFlow documentation, specifying that the content is licensed under the Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Mandelbrot Set Visualization in Python\nDESCRIPTION: This snippet imports necessary libraries for the Mandelbrot set simulation and visualization, including TensorFlow, NumPy, PIL, and IPython display utilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/mandelbrot.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import libraries for simulation\nimport tensorflow.compat.v1 as tf\n\nimport numpy as np\n\n# Imports for visualization\nimport PIL.Image\nfrom io import BytesIO\nfrom IPython.display import clear_output, Image, display\n```\n\n----------------------------------------\n\nTITLE: Converting Recognized Notes to MIDI File in Python\nDESCRIPTION: Creates a MIDI file from recognized musical notes using the 'sc.write' function. The code generates a MIDI filename by replacing the file extension of the source audio file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Saving the recognized musical notes as a MIDI file\nconverted_audio_file_as_midi = converted_audio_file[:-4] + '.mid'\nfp = sc.write('midi', fp=converted_audio_file_as_midi)\n```\n\n----------------------------------------\n\nTITLE: Plotting Pitch and Confidence Values in Python\nDESCRIPTION: This snippet plots the pitch and confidence outputs from SPICE analysis using matplotlib. It visualizes the pitch estimates and their corresponding confidence levels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nconfidence_outputs = 1.0 - uncertainty_outputs\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 10)\nplt.plot(pitch_outputs, label='pitch')\nplt.plot(confidence_outputs, label='confidence')\nplt.legend(loc=\"lower right\")\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Plotting Loss History with Matplotlib in TensorFlow\nDESCRIPTION: This code snippet uses Matplotlib to plot the loss history of the training process. It creates a line plot of the loss values over batches, with appropriate labels for the x and y axes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\n\nplt.plot(loss_history)\nplt.xlabel('Batch #')\nplt.ylabel('Loss [entropy]')\n```\n\n----------------------------------------\n\nTITLE: Implementing In-Memory Dataset Caching\nDESCRIPTION: Enhances the dataset pipeline with in-memory caching to improve performance across epochs. This caches the preprocessed images to avoid redundant computations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nds = image_label_ds.cache()\nds = ds.apply(\n  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\nds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Displaying Images from Parsed TFRecord Dataset in Python\nDESCRIPTION: This snippet demonstrates how to iterate through a parsed TFRecord dataset, extract the raw image data, and display the images using IPython's display functionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfor image_features in parsed_image_dataset:\n  image_raw = image_features['image_raw'].numpy()\n  display.display(display.Image(data=image_raw))\n```\n\n----------------------------------------\n\nTITLE: Compiling and Creating Estimator from Keras Model in Python\nDESCRIPTION: This snippet demonstrates how to compile a Keras model and create an Estimator from it. It uses the Adam optimizer and binary crossentropy loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nestimator_model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=['accuracy'])\n\nest_mobilenet_v2 = tf.keras.estimator.model_to_estimator(keras_model=estimator_model)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Dependencies\nDESCRIPTION: Installs the required TensorFlow packages including tf-models-official for the SNGP implementation. Uses pip with the quiet flag and legacy resolver to handle dependency resolution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -U -q --use-deprecated=legacy-resolver tf-models-official tensorflow\n```\n\n----------------------------------------\n\nTITLE: Getting Substrings using tf.strings.substr\nDESCRIPTION: This code snippet demonstrates how to extract a substring from a UTF-8 encoded string using TensorFlow, while specifying the unit of measurement for the substring.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.substr(thanks, pos=7, len=1).numpy()\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())\n```\n\n----------------------------------------\n\nTITLE: Dataset Creation with Variable in tf.function\nDESCRIPTION: Example showing how to handle dataset creation outside tf.function while keeping variable creation inside.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = None\n    self.dataset = None\n\n  def initialize(self):\n    if self.dataset is None:\n      self.dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n\n  @tf.function\n  def __call__(self):\n    if self.v is None:\n      self.v = tf.Variable(0)\n    it = iter(self.dataset)\n    return [self.v, next(it)]\n\nm = Model()\nm.initialize()\nm()\n```\n\n----------------------------------------\n\nTITLE: Sampling From Model Predictions in TensorFlow\nDESCRIPTION: Generates character indices by sampling from the model's output distribution using categorical sampling rather than argmax to avoid getting stuck in prediction loops.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n```\n\n----------------------------------------\n\nTITLE: Registering ZeroOut OpKernel for CPU in TensorFlow\nDESCRIPTION: This code registers the ZeroOut operation kernel with the TensorFlow system, specifying that it runs on CPU devices. The registration connects the operation name with its implementation class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_2\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\n```\n\n----------------------------------------\n\nTITLE: Creating Input Placeholders for Skip-gram Model in Python\nDESCRIPTION: Defines TensorFlow placeholder nodes for input context words and target words, which will be used to feed data during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Placeholders for inputs\ntrain_inputs = tf.placeholder(tf.int32, shape=[batch_size])\ntrain_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n```\n\n----------------------------------------\n\nTITLE: Preprocessing text data into hashed tokens with RaggedTensors\nDESCRIPTION: Splits text into words, hashes them into buckets, and creates a RaggedTensor containing the hashed tokens for each sentence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Preprocess the input strings.\nhash_buckets = 1000\nwords = tf.strings.split(sentences, ' ')\nhashed_words = tf.strings.to_hash_bucket_fast(words, hash_buckets)\nhashed_words.to_list()\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Bag-of-Words Linear Model in TensorFlow\nDESCRIPTION: Defines and compiles a simple linear model for binary vectorized data using the binary_vectorize_layer and a Dense layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nbinary_model = tf.keras.Sequential([\n    binary_vectorize_layer,\n    layers.Dense(4)])\n\nbinary_model.compile(\n    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Finding Optimal Number of Epochs\nDESCRIPTION: Trains the model with the best hyperparameters to determine the optimal number of epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\nmodel = tuner.hypermodel.build(best_hps)\nhistory = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n\nval_acc_per_epoch = history.history['val_accuracy']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\nprint('Best epoch: %d' % (best_epoch,))\n```\n\n----------------------------------------\n\nTITLE: Training Custom Estimator for Iris Classification in TensorFlow\nDESCRIPTION: This snippet shows how to train the custom Estimator for Iris classification. It uses the train method of the Estimator, specifying the input function and number of training steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/custom_estimators.md#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Train the Model.\nclassifier.train(\n    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n    steps=args.train_steps)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Basic Operations\nDESCRIPTION: Demonstration of basic TensorFlow mathematical operations and operator overloading\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.math.add(1, 2))\nprint(tf.math.add([1, 2], [3, 4]))\nprint(tf.math.square(5))\nprint(tf.math.reduce_sum([1, 2, 3]))\n\n# Operator overloading is also supported\nprint(tf.math.square(2) + tf.math.square(3))\n```\n\n----------------------------------------\n\nTITLE: Exploring IMDB Dataset in TensorFlow\nDESCRIPTION: This snippet prints the number of training and test entries, and displays the first 10 examples and labels from the training set.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Training entries: {}, test entries: {}\".format(len(train_examples), len(test_examples)))\n\ntrain_examples[:10]\n\ntrain_labels[:10]\n```\n\n----------------------------------------\n\nTITLE: Creating and Inspecting Compressed Model Archive\nDESCRIPTION: Shell commands demonstrating how to create a compressed tar.gz archive from a SavedModel directory and inspect its contents.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/hosting.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Create a compressed model from a SavedModel directory.\n$ tar -cz -f model.tar.gz --owner=0 --group=0 -C /tmp/export-model/ .\n\n# Inspect files inside a compressed model\n$ tar -tf model.tar.gz\n./\n./variables/\n./variables/variables.data-00000-of-00001\n./variables/variables.index\n./assets/\n./saved_model.pb\n```\n\n----------------------------------------\n\nTITLE: Evaluating Metrics in TensorFlow Estimator\nDESCRIPTION: Code to evaluate a trained estimator model and print metrics, which is a common step after training a model to assess its performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/kernel_methods.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics)\n```\n\n----------------------------------------\n\nTITLE: Smaller Model Creation\nDESCRIPTION: Creating and compiling a smaller neural network model with two hidden layers of 4 units each for comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsmaller_model = keras.Sequential([\n    keras.layers.Dense(4, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(4, activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nsmaller_model.compile(optimizer='adam',\n                loss='binary_crossentropy',\n                metrics=['accuracy', 'binary_crossentropy'])\n\nsmaller_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Freezing Convolutional Base of MobileNet V2 - Python\nDESCRIPTION: This snippet demonstrates how to freeze the convolutional base of the MobileNet V2 model, which prevents its weights from being updated during training, preserving the learned features.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbase_model.trainable = False\n```\n\n----------------------------------------\n\nTITLE: Loading ImageNet Labels in Python\nDESCRIPTION: This snippet downloads the ImageNet labels file and creates a list of class names for classification results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nlabels_file = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n\n#download labels and creates a maps\ndownloaded_file = tf.keras.utils.get_file(\"labels.txt\", origin=labels_file)\n\nclasses = []\n\nwith open(downloaded_file) as f:\n  labels = f.readlines()\n  classes = [l.strip() for l in labels]\n```\n\n----------------------------------------\n\nTITLE: Handling Shape Validation Error in MaskedTensor in Python\nDESCRIPTION: Shows how the __validate__ method catches errors when creating a MaskedTensor with incompatible shapes between values and mask.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  MaskedTensor([1, 2, 3], [True, False])  # shapes don't match.\nexcept ValueError as e:\n  print(f\"Got expected ValueError: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Separating Features from Labels (Python)\nDESCRIPTION: This snippet separates the target variable 'MPG' from the feature dataset, preparing it for model training by defining inputs and outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntrain_labels = train_dataset.pop('MPG')\ntest_labels = test_dataset.pop('MPG')\n```\n\n----------------------------------------\n\nTITLE: Instantiating Text Generation Model in TensorFlow\nDESCRIPTION: Creates a model instance using the build_model function with specific vocabulary size, embedding dimensions, RNN units, and batch size parameters for text generation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel = build_model(\n  vocab_size = len(vocab),\n  embedding_dim=embedding_dim,\n  rnn_units=rnn_units,\n  batch_size=BATCH_SIZE)\n```\n\n----------------------------------------\n\nTITLE: Displaying BERT Model Inputs and Outputs\nDESCRIPTION: Prints the original sentences, tokenized inputs, pooled embeddings, and per-token embeddings to demonstrate what the BERT model processes and produces.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Sentences:\")\nprint(sentences)\n\nprint(\"\\nBERT inputs:\")\nprint(inputs)\n\nprint(\"\\nPooled embeddings:\")\nprint(outputs[\"pooled_output\"])\n\nprint(\"\\nPer token embeddings:\")\nprint(outputs[\"sequence_output\"])\n```\n\n----------------------------------------\n\nTITLE: Testing Gradient Descent Optimizer\nDESCRIPTION: Applies the convergence test to the gradient descent optimizer with different learning rates and stores the parameter paths.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nparam_map_gd = {}\nlearning_rates = [1e-3, 1e-2, 1e-1]\nfor learning_rate in learning_rates:\n  param_map_gd[learning_rate] = (convergence_test(\n      GradientDescent(learning_rate=learning_rate), loss_fn=loss))\n```\n\n----------------------------------------\n\nTITLE: Running the Initial Training with Checkpoints\nDESCRIPTION: Executes the training and checkpointing function to train the model and save checkpoints periodically.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrain_and_checkpoint(net, manager)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow Library\nDESCRIPTION: Basic setup code for importing the TensorFlow library, which is required for all TensorFlow operations in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Simple Saving of Models with tf.saved_model.simple_save in Python\nDESCRIPTION: This snippet shows how to save models simply using tf.saved_model.simple_save in Python. It requires a TensorFlow session, specified input, and output mappings to save the model in a way compatible with TensorFlow Serving Predict API.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsimple_save(session,\n            export_dir,\n            inputs={\"x\": x, \"y\": y},\n            outputs={\"z\": z})\n```\n\n----------------------------------------\n\nTITLE: Downloading and Examining News Headlines Dataset\nDESCRIPTION: Downloads a dataset of news headlines from Harvard Dataverse, examines its size and content structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!wget 'https://dataverse.harvard.edu/api/access/datafile/3450625?format=tab&gbrecs=true' -O raw.tsv\n!wc -l raw.tsv\n!head raw.tsv\n```\n\n----------------------------------------\n\nTITLE: Visualizing Initial Model Predictions and Loss\nDESCRIPTION: Plots the initial model predictions against the ground truth and data points, and displays the current loss value before training begins.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(x, y, '.', label=\"Data\")\nplt.plot(x, f(x), label=\"Ground truth\")\nplt.plot(x, model(x), label=\"Predictions\")\nplt.legend()\nplt.show()\n\nprint(\"Current loss: %1.6f\" % loss(y, model(x)).numpy())\n```\n\n----------------------------------------\n\nTITLE: Encoding and Computing Sentence Similarity with TensorFlow\nDESCRIPTION: Encodes two sentences using L2 normalization and computes similarity scores between them using cosine distance. The code uses a sparse tensor format for input processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsts_encode1 = tf.nn.l2_normalize(\n    module(\n        inputs=dict(values=sts_input1.values,\n                    indices=sts_input1.indices,\n                    dense_shape=sts_input1.dense_shape)),\n    axis=1)\nsts_encode2 = tf.nn.l2_normalize(\n    module(\n        inputs=dict(values=sts_input2.values,\n                    indices=sts_input2.indices,\n                    dense_shape=sts_input2.dense_shape)),\n    axis=1)\n\nsim_scores = -tf.acos(tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1))\n```\n\n----------------------------------------\n\nTITLE: Using tf.math.reduce_max with Dense Tensors in TensorFlow\nDESCRIPTION: This snippet shows the contrasting behavior between tf.sparse.reduce_max and tf.math.reduce_max when finding maximum values. When applied to a dense tensor, tf.math.reduce_max returns the expected maximum value.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/sparse_tensor.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.math.reduce_max([-5, 0, -3]))\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Static Shapes of Tensors and Ragged Tensors in Python\nDESCRIPTION: This snippet shows how to access the static shape of both regular Tensors and RaggedTensors using the .shape property. It illustrates that ragged dimensions are represented as None in the static shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([[1, 2], [3, 4], [5, 6]])\nx.shape  # shape of a tf.tensor\n```\n\nLANGUAGE: python\nCODE:\n```\nrt = tf.ragged.constant([[1], [2, 3], [], [4]])\nrt.shape  # shape of a tf.RaggedTensor\n```\n\n----------------------------------------\n\nTITLE: Importing MetaGraphDef as Concrete Function in TensorFlow 2\nDESCRIPTION: This snippet shows how to import a saved MetaGraphDef into a concrete function that can be executed in eager mode in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef import_multiply():\n  # Any graph-building code is allowed here.\n  tf1.train.import_meta_graph('multiply.pb')\n\n# Creates a tf.function with all the imported elements in the function graph.\nwrapped_import = tf1.wrap_function(import_multiply, [])\nimport_graph = wrapped_import.graph\nx = import_graph.get_tensor_by_name('x:0')\ny = import_graph.get_tensor_by_name('y:0')\n\n# Restore the variable values.\ntf1.train.Saver(wrapped_import.variables).restore(\n    sess=None, save_path='multiply_values.ckpt')\n\n# Create a concrete function by pruning the wrap_function (similar to sess.run).\nmultiply_fn = wrapped_import.prune(feeds=x, fetches=y)\n\n# Run this function\nmultiply_fn(tf.constant(5.))  # inputs to concrete functions must be Tensors.\n```\n\n----------------------------------------\n\nTITLE: TF2 Checkpoint Compatibility Example\nDESCRIPTION: Example showing compatible checkpoint configurations using tf.train.Checkpoint with consistent object structures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nckpt = tf.train.Checkpoint(foo=[var_a, var_b])\n\n# compatible with ckpt\ntf.train.Checkpoint(foo=[var_a, var_b])\n```\n\n----------------------------------------\n\nTITLE: Generating Random Input Data for MNIST in TensorFlow\nDESCRIPTION: This code snippet generates a random batch of data that is shaped like a batch of MNIST images, which are 28x28 grayscale images. The data is then converted to the correct datatype `np.float32` for use in a TensorFlow model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntrain_batch = np.random.randn(64, 28, 28, 1).astype(np.float32)\n```\n\n----------------------------------------\n\nTITLE: Macro-based Kernel Registration in C++\nDESCRIPTION: Demonstrates using macros to simplify registration of multiple kernel types, showing both manual registration and integration with TensorFlow's built-in type registration macros.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_33\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\n#define REGISTER_KERNEL(type)                                       \\\n  REGISTER_KERNEL_BUILDER(                                          \\\n      Name(\"ZeroOut\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      ZeroOutOp<type>)\n\nREGISTER_KERNEL(int32);\nREGISTER_KERNEL(float);\nREGISTER_KERNEL(double);\n\n#undef REGISTER_KERNEL\n```\n\nLANGUAGE: C++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: realnumbertype\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n\ntemplate <typename T>\nclass ZeroOutOp : public OpKernel { ... };\n\n#define REGISTER_KERNEL(type)                                       \\\n  REGISTER_KERNEL_BUILDER(                                          \\\n      Name(\"ZeroOut\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      ZeroOutOp<type>)\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n```\n\n----------------------------------------\n\nTITLE: Compiling and Evaluating Baseline Time Series Model\nDESCRIPTION: Instantiates the baseline model for temperature prediction, compiles it with MSE loss and MAE metrics, and evaluates its performance on validation and test datasets, storing results for later comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nbaseline = Baseline(label_index=column_indices['T (degC)'])\n\nbaseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n\nval_performance = {}\nperformance = {}\nval_performance['Baseline'] = baseline.evaluate(single_step_window.val, return_dict=True)\nperformance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Baseline Model Creation\nDESCRIPTION: Creating and compiling a baseline neural network model with two hidden layers of 16 units each.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nbaseline_model = keras.Sequential([\n    # `input_shape` is only required here so that `.summary` works.\n    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nbaseline_model.compile(optimizer='adam',\n                       loss='binary_crossentropy',\n                       metrics=['accuracy', 'binary_crossentropy'])\n\nbaseline_model.summary()\n```\n\n----------------------------------------\n\nTITLE: Computing Gradients with TensorFlow GradientTape\nDESCRIPTION: Shows how to use tf.GradientTape to compute gradients of operations with respect to variables. This is crucial for implementing training algorithms in eager mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nw = tf.Variable([[1.0]])\nwith tf.GradientTape() as tape:\n  loss = w * w\n\ngrad = tape.gradient(loss, w)\nprint(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)\n```\n\n----------------------------------------\n\nTITLE: Formatting Label Metadata for TensorFlow Embeddings\nDESCRIPTION: This snippet demonstrates the TSV file format for label metadata in TensorFlow embeddings. The first line contains column headers, and subsequent lines contain metadata values separated by tab characters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/embedding.md#2025-04-21_snippet_1\n\nLANGUAGE: tsv\nCODE:\n```\nWord\\tFrequency\nAirplane\\t345\nCar\\t241\n...\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel with NPZ and Pickle Files\nDESCRIPTION: Example demonstrating SavedModel CLI usage with .npz and pickle input files, including overwrite option.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \\\n--signature_def x1_x2_to_y \\\n--inputs 'x1=/tmp/my_data1.npz[x];x2=/tmp/my_data2.pkl' --outdir /tmp/out \\\n--overwrite\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Consistent Results with New Type Promotion in TensorFlow (Order 1)\nDESCRIPTION: This example shows how the new type promotion system produces consistent results regardless of operation order, returning float16 in this case.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# (a + b) + c returns a f16 result.\ntf.add(tf.add(a, b), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>\n```\n\n----------------------------------------\n\nTITLE: Testing Embedding Extraction in Python\nDESCRIPTION: This code snippet tests the extract_embeddings function by generating an embedding for a sample query and displaying the first 10 dimensions of the embedding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nextract_embeddings(\"Hello Machine Learning!\")[:10]\n```\n\n----------------------------------------\n\nTITLE: Downloading a Compressed CSV Dataset\nDESCRIPTION: Downloads a gzipped CSV file containing traffic volume data, demonstrating how to work with compressed datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ntraffic_volume_csv_gz = tf.keras.utils.get_file(\n    'Metro_Interstate_Traffic_Volume.csv.gz', \n    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n    cache_dir='.', cache_subdir='traffic')\n```\n\n----------------------------------------\n\nTITLE: Initializing Optimizers\nDESCRIPTION: Sets up Adam optimizers for both generators and discriminators with specific learning rates and beta parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ngenerator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ngenerator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\ndiscriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n```\n\n----------------------------------------\n\nTITLE: Testing Equality Operators for ExtensionType in Python\nDESCRIPTION: Shows how the default equality operators work with ExtensionType instances, comparing MaskedTensor objects for equality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\na = MaskedTensor([1, 2], [True, False])\nb = MaskedTensor([[3, 4], [5, 6]], [[False, True], [True, True]])\nprint(f\"a == a: {a==a}\")\nprint(f\"a == b: {a==b}\")\nprint(f\"a == a.values: {a==a.values}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing License and Copyright\nDESCRIPTION: Standard TensorFlow Hub copyright and Apache 2.0 license declaration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, \n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Creating int32 WeakTensor with tnp.array Using New Type Promotion\nDESCRIPTION: This example shows how TensorFlow-NumPy's array function creates int32 WeakTensors for integer inputs with the new type promotion.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ntnp.array(1)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>\n```\n\n----------------------------------------\n\nTITLE: Creating New TF1 Hub Module\nDESCRIPTION: Shows how to create a new module specification using hub.create_module_spec() with a custom neural network architecture.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tf1_hub_module.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef module_fn():\n  inputs = tf.placeholder(dtype=tf.float32, shape=[None, 50])\n  layer1 = tf.layers.dense(inputs, 200)\n  layer2 = tf.layers.dense(layer1, 100)\n  outputs = dict(default=layer2, hidden_activations=layer1)\n  # Add default signature.\n  hub.add_signature(inputs=inputs, outputs=outputs)\n\n...\nspec = hub.create_module_spec(module_fn)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow and Hub Import Dependencies\nDESCRIPTION: Setup required imports for TensorFlow, TensorFlow Hub, and data manipulation libraries to enable image classification and transfer learning workflows\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/hub_with_keras.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pylab as plt\n\nimport tensorflow.compat.v1 as tf\n\nimport os\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\n\n# Load compressed models from tensorflow_hub\nos.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"COMPRESSED\"\n```\n\n----------------------------------------\n\nTITLE: Creating Rank 1 Tensors in TensorFlow\nDESCRIPTION: Shows how to create vector (rank 1) tensors using lists of values with different data types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmystr = tf.Variable([\"Hello\"], tf.string)\ncool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\nfirst_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\nits_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)\n```\n\n----------------------------------------\n\nTITLE: Accessing DTensor Layout in TensorFlow\nDESCRIPTION: Example showing how to access and validate the layout of a DTensor using dtensor.fetch_layout(). Layout is not a regular attribute of tf.Tensor but can be accessed through this special function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(dtensor.fetch_layout(my_first_dtensor))\nassert layout == dtensor.fetch_layout(my_first_dtensor)\n```\n\n----------------------------------------\n\nTITLE: Iterating Through a TensorFlow Dataset with Exception Handling\nDESCRIPTION: Shows how to iterate through all elements of a Dataset using a while loop with try/except to handle the OutOfRangeError that occurs when the dataset is exhausted.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nwhile True:\n  try:\n    print(sess.run(next_item))\n  except tf.errors.OutOfRangeError:\n    break\n```\n\n----------------------------------------\n\nTITLE: Initializing Gaussian Process Layer Parameters in Python\nDESCRIPTION: This snippet initializes basic parameters for the Gaussian Process layer, including batch size, input dimension, and number of classes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 32\ninput_dim = 1024\nnum_classes = 10\n```\n\n----------------------------------------\n\nTITLE: Preparing Dataset Files\nDESCRIPTION: Creating file paths and labels for the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndir_names = ['economy', 'sports', 'entertainment', 'state', 'international']\n\nfile_paths = []\nlabels = []\nfor i, dir in enumerate(dir_names):\n  file_names = [\"/\".join([dir, name]) for name in os.listdir(dir)]\n  file_paths += file_names\n  labels += [i] * len(os.listdir(dir))\n  \nnp.random.seed(42)\npermutation = np.random.permutation(len(file_paths))\n\nfile_paths = np.array(file_paths)[permutation]\nlabels = np.array(labels)[permutation]\n```\n\n----------------------------------------\n\nTITLE: Iterating Through Nodes in a TensorFlow GraphDef in Python\nDESCRIPTION: Loops through all the nodes in a loaded GraphDef object. Each node is a NodeDef object that defines a single operation in the graph along with its connections.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/model_files.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor node in graph_def.node\n```\n\n----------------------------------------\n\nTITLE: Cross-Device Tensor Operations in TensorFlow\nDESCRIPTION: Shows how to copy tensor objects between CPU and GPU devices and execute matrix multiplication operations on specific devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nif tf.config.list_physical_devices('GPU'):\n  x = tf.random_normal([10, 10])\n\n  x_gpu0 = x.gpu()\n  x_cpu = x.cpu()\n\n  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n```\n\n----------------------------------------\n\nTITLE: Using Explicit Iterators for Fixed-Step Training in TensorFlow\nDESCRIPTION: Demonstrates how to use explicit iterators when you want to run for a specific number of steps rather than iterating over the entire dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\niterator = iter(dist_dataset)\nfor _ in range(10):\n  print(distributed_train_step(next(iterator)))\n```\n\n----------------------------------------\n\nTITLE: Model Training with Progress Tracking\nDESCRIPTION: Trains a neural network model using specified number of epochs, with validation split and custom callback for progress monitoring\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(\n  normed_train_data, train_labels,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[PrintDot()])\n```\n\n----------------------------------------\n\nTITLE: Training Text Generation Model in TensorFlow\nDESCRIPTION: Trains the model using the dataset, specified number of epochs, steps per epoch, and checkpoint callback for saving model weights during training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nhistory = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])\n```\n\n----------------------------------------\n\nTITLE: Displaying Raw Records from TFRecord Dataset (Python)\nDESCRIPTION: Illustrates iterating over a raw dataset of serialized samples using take to view entries, applicable for debugging serialized data before parsing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfor raw_record in raw_dataset.take(10):\n  print(repr(raw_record))\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Header for TensorFlow Tutorials\nDESCRIPTION: This snippet demonstrates how to create a top-level header in Markdown for TensorFlow project tutorials. It uses a placeholder PROJECT_NAME which would likely be replaced with the actual project name in real documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/subsite/g3doc/tutorials/index.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# PROJECT_NAME tutorials\n```\n\n----------------------------------------\n\nTITLE: Reading First Line of a CSV File in Python\nDESCRIPTION: Reads the first line from a CSV file to inspect its structure. This is used to determine the column types for subsequent CSV parsing operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nfont_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\nprint(font_line)\n```\n\n----------------------------------------\n\nTITLE: Basic Input File Specification in SavedModel CLI\nDESCRIPTION: Shows the basic syntax for specifying input files using the --inputs option. Supports .npy, .npz and pickle file formats.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n--inputs <INPUTS>\n```\n\n----------------------------------------\n\nTITLE: Reusing TensorFlow Variables with Variable Scope Attributes\nDESCRIPTION: Shows how to reuse variables by setting the reuse attribute of tf.variable_scope to True. Examples demonstrate scope reuse with direct variable scope naming and scope objects as parameters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nwith tf.variable_scope(\"model\"):\n  output1 = my_image_filter(input1)\nwith tf.variable_scope(\"model\", reuse=True):\n  output2 = my_image_filter(input2)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith tf.variable_scope(\"model\") as scope:\n  output1 = my_image_filter(input1)\n  scope.reuse_variables()\n  output2 = my_image_filter(input2)\n```\n\nLANGUAGE: python\nCODE:\n```\nwith tf.variable_scope(\"model\") as scope:\n  output1 = my_image_filter(input1)\nwith tf.variable_scope(scope, reuse=True):\n  output2 = my_image_filter(input2)\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Parallel Mesh for DTensor\nDESCRIPTION: Defines a mesh for data parallel training where each device runs a replica of the model that receives a shard from the global batch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"batch\", 8)], devices=devices)\n```\n\n----------------------------------------\n\nTITLE: Defining a Complex Python Generator\nDESCRIPTION: This snippet defines a more complex generator that yields tuples of an incrementing integer and a random normal array of variable size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef gen_series():\n  i = 0\n  while True:\n    size = np.random.randint(0, 10)\n    yield i, np.random.normal(size=(size,))\n    i += 1\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Environment for TensorFlow\nDESCRIPTION: Imports necessary packages for working with TensorFlow, including NumPy for array operations and TensorFlow itself. This setup is a common starting point for TensorFlow programs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Creating WeakTensor with WeakTensor-supporting API in TensorFlow\nDESCRIPTION: This example shows how a WeakTensor is created when an input with no user-specified dtype is passed to a WeakTensor-supporting API like tf.math.abs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntf.math.abs([100.0, 4.0])  # <tf.Tensor: shape=(2,), dtype=float32, numpy=array([100., 4.], dtype=float32), weak=True>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Disconnected Gradients in TensorFlow\nDESCRIPTION: This snippet shows a case where the gradient is disconnected (returns None) because the target is not dependent on the source variable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(2.)\ny = tf.Variable(3.)\n\nwith tf.GradientTape() as tape:\n  z = y * y\nprint(tape.gradient(z, x))\n```\n\n----------------------------------------\n\nTITLE: Variable Creation Workaround using Caching\nDESCRIPTION: Solution showing how to properly handle variable creation in tf.function by caching the variable after first creation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = None\n\n  @tf.function\n  def __call__(self):\n    print(\"trace\") # This will print twice because the python body is run twice\n    if self.v is None:\n      self.v = tf.Variable(0)\n    return self.v\n\nm = Model()\nm()\n```\n\n----------------------------------------\n\nTITLE: Unicode Decoding with Offsets\nDESCRIPTION: This code demonstrates how to decode a Unicode string and obtain the byte offsets of each character using TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ncodepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"🎈🎉🎊\", 'UTF-8')\nfor (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n  print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))\n```\n\n----------------------------------------\n\nTITLE: Converting Keras Model to Estimator with Distribution Configuration in Python\nDESCRIPTION: This code converts a Keras model to a TensorFlow Estimator, incorporating the previously defined distribution configuration. It specifies a model directory for saving checkpoints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nkeras_estimator = tf.keras.estimator.model_to_estimator(\n  keras_model=model,\n  config=config,\n  model_dir='/tmp/model_dir')\n```\n\n----------------------------------------\n\nTITLE: Iterating Through a TensorFlow Dataset\nDESCRIPTION: Shows how to iterate through a tf.data.Dataset like any Python iterable, accessing individual examples and their feature values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfor example in features_ds:\n  for name, value in example.items():\n    print(f\"{name:19s}: {value}\")\n  break\n```\n\n----------------------------------------\n\nTITLE: Training the Small Model and Storing its History\nDESCRIPTION: Compiles and trains the small model with two hidden layers, then stores its training history in the size_histories dictionary for comparison with other model sizes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nsize_histories['Small'] = compile_and_fit(small_model, 'sizes/Small')\n```\n\n----------------------------------------\n\nTITLE: Configuring Virtual CPUs for DTensor\nDESCRIPTION: Creates multiple virtual CPUs from a single physical CPU for simulating a distributed environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef configure_virtual_cpus(ncpu):\n  phy_devices = tf.config.list_physical_devices('CPU')\n  tf.config.set_logical_device_configuration(\n        phy_devices[0], \n        [tf.config.LogicalDeviceConfiguration()] * ncpu)\n  \nconfigure_virtual_cpus(8)\ntf.config.list_logical_devices('CPU')\n\ndevices = [f'CPU:{i}' for i in range(8)]\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Wiki40B Language Models\nDESCRIPTION: Imports necessary Python packages including NumPy, TensorFlow, TensorFlow Hub, and TensorFlow Text with configuration for TensorFlow v1 compatibility mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#@title Imports\nimport numpy as np\nimport tensorflow.compat.v1 as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as tf_text\n\ntf.disable_eager_execution()\ntf.logging.set_verbosity(tf.logging.WARN)\n\n```\n\n----------------------------------------\n\nTITLE: Displaying Pip Install Permission Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs during pip installation when there's a permission issue, often related to system-level Python installations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>OSError: [Errno 1] Operation not permitted</pre>\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Library Import Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message indicating that a required CUDA library (libcudart.so) could not be found during TensorFlow import.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>ImportError: libcudart.so.<i>Version</i>: cannot open shared object file:\n  No such file or directory</pre>\n```\n\n----------------------------------------\n\nTITLE: Creating CsvDataset with Missing Values\nDESCRIPTION: Demonstrates handling of missing data by providing defaults for potentially empty columns. This example shows a CsvDataset for CSV files with missing values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\nrecord_defaults = [[0.0]] * 8\ndataset = tf.data.experimental.CsvDataset(filenames, record_defaults)\n```\n\n----------------------------------------\n\nTITLE: License Declaration - Apache 2.0\nDESCRIPTION: Copyright notice and Apache 2.0 license declaration for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating Dataset of Preprocessed Images\nDESCRIPTION: Generates a dataset of preprocessed image tensors by loading and transforming raw images. This preparation step is used before serializing to TFRecord format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\npaths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\nimage_ds = paths_ds.map(load_and_preprocess_image)\nimage_ds\n```\n\n----------------------------------------\n\nTITLE: Enabling Tensor Equality for TF2 Behavior\nDESCRIPTION: Shows the default TensorFlow 2.0 behavior where tensors with the same values return true when compared with the equality operator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.enable_tensor_equality()\nx = tf.Variable(0.0)\ny = tf.Variable(0.0)\n\nx == y\n```\n\n----------------------------------------\n\nTITLE: Creating Symbolic Link for ptxas on Linux\nDESCRIPTION: This command creates a symbolic link to the ptxas binary, which is required for some GPU operations in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nln -sf $(find $(dirname $(dirname $(python -c \"import nvidia.cuda_nvcc;         \\nprint(nvidia.cuda_nvcc.__file__)\"))/*/bin/) -name ptxas -print -quit) $VIRTUAL_ENV/bin/ptxas\n```\n\n----------------------------------------\n\nTITLE: Checking LSTM Model Input/Output Shapes\nDESCRIPTION: Verifies the input and output shapes of the LSTM model to ensure proper dimension handling for time series prediction with return sequences enabled.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nprint('Input shape:', wide_window.example[0].shape)\nprint('Output shape:', lstm_model(wide_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Setting up Basic TensorFlow Dataset Pipeline\nDESCRIPTION: Creates a dataset pipeline with shuffling, batching, and prefetching. This represents the baseline configuration for performance comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nds = image_label_ds.apply(\n  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\nds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nds\n```\n\n----------------------------------------\n\nTITLE: Configuring License and Copyright in Python\nDESCRIPTION: License declaration for TensorFlow documentation under Apache License 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for CVAE Implementation\nDESCRIPTION: Imports necessary Python libraries for the CVAE implementation, including TensorFlow, TensorFlow Probability for probabilistic modeling, and visualization libraries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython import display\n\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport time\n```\n\n----------------------------------------\n\nTITLE: MNIST Dataset Loading and Preprocessing\nDESCRIPTION: Loading and preprocessing MNIST dataset, limiting to first 1000 examples for demonstration\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\ntrain_labels = train_labels[:1000]\ntest_labels = test_labels[:1000]\n\ntrain_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\ntest_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n```\n\n----------------------------------------\n\nTITLE: Checking Conv1D Model Input/Output Shapes\nDESCRIPTION: Verifies the input and output shapes of the convolutional model to ensure it properly maintains dimensions when processing time series data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Conv model on `conv_window`\")\nprint('Input shape:', conv_window.example[0].shape)\nprint('Output shape:', conv_model(conv_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Creating Optimizer for Skip-gram Model in Python\nDESCRIPTION: Sets up a stochastic gradient descent optimizer to minimize the NCE loss with a specified learning rate, enabling the model to learn word embeddings.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# We use the SGD optimizer.\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)\n```\n\n----------------------------------------\n\nTITLE: Normalizing Numeric Features with Feature Columns\nDESCRIPTION: Demonstrates normalizing numeric input using a custom normalizer function in feature columns.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef normalize(x):\n  mean, variance = (2.0, 1.0)\n  return (x - mean) / math.sqrt(variance)\nnumeric_col = tf1.feature_column.numeric_column('col', normalizer_fn=normalize)\ncall_feature_columns(numeric_col, {'col': tf.constant([[0.], [1.], [2.]])})\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Nightly Build\nDESCRIPTION: Commands to install the nightly (development) build of TensorFlow and verify the installation. This version contains the latest features but may be less stable.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install tf-nightly\n# Verify the installation:\npython3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Loading the Saved TensorFlow Model\nDESCRIPTION: Demonstrates how to load the previously saved model using tf.saved_model.load, which restores the model with all its functionality intact.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nmlp_loaded = tf.saved_model.load(save_path)\n```\n\n----------------------------------------\n\nTITLE: Loading Text Transcriptions\nDESCRIPTION: Defines a function to read and parse text transcription files from the LibriSpeech dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef read_txt_file(f):\n  with open(f, \"r\") as f:\n    samples = f.read().split(\"\\n\")\n    samples = {s.split()[0]: \" \".join(s.split()[1:]) for s in samples if len(s.split()) > 2}\n  return samples\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Importing TensorFlow, audio processing, and visualization libraries with logger configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\nfrom librosa import display as librosadisplay\n\nimport logging\nimport math\nimport statistics\nimport sys\n\nfrom IPython.display import Audio, Javascript\nfrom scipy.io import wavfile\n\nfrom base64 import b64decode\n\nimport music21\nfrom pydub import AudioSegment\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.ERROR)\n\nprint(\"tensorflow: %s\" % tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Saving Keras Model Checkpoint in Python\nDESCRIPTION: This snippet demonstrates how to save a checkpoint of a Keras model using the built-in save_weights method. It allows for saving the model's state during or after training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nkeras_model.save_weights(\"my_checkpoint\")\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 declaration typically included at the beginning of TensorFlow documentation notebooks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Generating Classification Report for TensorFlow Model\nDESCRIPTION: This snippet uses scikit-learn's classification_report function to compare true and predicted labels, providing a detailed performance breakdown by class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nprint(classification_report(y_true, y_pred, target_names=dir_names))\n```\n\n----------------------------------------\n\nTITLE: Image Preprocessing Function\nDESCRIPTION: Defines a function to preprocess images by normalizing pixel values and resizing to 224x224\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_fn(data):\n  image = data['image']\n\n  # Normalize [0, 255] to [0, 1]\n  image = tf.cast(image, tf.float32)\n  image = image / 255.\n\n  # Resize the images to 224 x 224\n  image = tf.image.resize(image, (224, 224))\n\n  data['image'] = image\n  return data\n```\n\n----------------------------------------\n\nTITLE: Setting Up Imports and Dataset - Python\nDESCRIPTION: This snippet demonstrates the necessary imports and dataset preparation required for the migration example, including the use of TensorFlow and compatibility imports.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/sessionrunhook_callback.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\nimport time\nfrom datetime import datetime\nfrom absl import flags\n```\n\nLANGUAGE: python\nCODE:\n```\nfeatures = [[1., 1.5], [2., 2.5], [3., 3.5]]\nlabels = [[0.3], [0.5], [0.7]]\neval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\neval_labels = [[0.8], [0.9], [1.]]\n```\n\n----------------------------------------\n\nTITLE: Reading Value from Protocol Buffer using Getters (Python)\nDESCRIPTION: Demonstrates accessing individual feature values from a tf.Example using getters, useful for examining specific data entries in serialized datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nprint(example.features.feature['feature3'])\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Code for sum_even Function\nDESCRIPTION: Shows the TensorFlow graph code that AutoGraph generated for the sum_even function, demonstrating how it handles loops and continue statements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.autograph.to_code(sum_even))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies and Directories\nDESCRIPTION: Imports required libraries and sets up temporary directory for test data\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n\nfrom tensorflow_datasets.core import SplitGenerator\nfrom tensorflow_datasets.video.bair_robot_pushing import BairRobotPushingSmall\n\nimport tempfile\nimport pathlib\n\nTEST_DIR = pathlib.Path(tempfile.mkdtemp()) / \"bair_robot_pushing_small/softmotion30_44k/test/\"\n```\n\n----------------------------------------\n\nTITLE: Using Dimension Methods in TF2 Style\nDESCRIPTION: Demonstrates how to perform dimension compatibility checks in TensorFlow 2.0 by using the compat.v1.Dimension class when needed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nother_dim = 16\nDimension = tf.compat.v1.Dimension\n\nif shape.rank is None:\n  dim = Dimension(None)\nelse:\n  dim = shape.dims[i]\ndim.is_compatible_with(other_dim) # or any other dimension method\n```\n\n----------------------------------------\n\nTITLE: Creating a Python Virtual Environment for TensorFlow on Linux\nDESCRIPTION: This command creates a new Python virtual environment named 'tf' using the venv module, which is the officially recommended way to create virtual environments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m venv tf\n```\n\n----------------------------------------\n\nTITLE: Monitoring Model Evaluation Output - Shell\nDESCRIPTION: This section demonstrates the output of running the evaluation script, providing the precision of the model's predictions on the validation dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"2015-11-06 08:30:44.391206: precision @ 1 = 0.860\\n...\"\n```\n\n----------------------------------------\n\nTITLE: Exporting and Loading SavedModel\nDESCRIPTION: Save the trained model in SavedModel format and demonstrate loading it without MirroredStrategy scope.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npath = 'saved_model/'\nmodel.save(path)\n\nunreplicated_model = tf.keras.models.load_model(path)\n\nunreplicated_model.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=['accuracy'])\n\neval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\nprint ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n```\n\n----------------------------------------\n\nTITLE: Copying Tiny Model Logs as Baseline for Regularization Comparison\nDESCRIPTION: Copies the training logs from the tiny model to use as a baseline for comparing regularization strategies in the next section of the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nshutil.rmtree(logdir/'regularizers/Tiny', ignore_errors=True)\nshutil.copytree(logdir/'sizes/Tiny', logdir/'regularizers/Tiny')\n```\n\n----------------------------------------\n\nTITLE: Unicode String Encoding from a Dense Tensor\nDESCRIPTION: This snippet demonstrates how to encode multiple strings of the same length using a TensorFlow dense tensor as input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n                          output_encoding='UTF-8')\n```\n\n----------------------------------------\n\nTITLE: Model Performance Evaluation on Test Data\nDESCRIPTION: Evaluates the trained model's performance using test dataset, calculating mean absolute and mean squared errors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nloss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n\nprint(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n```\n\n----------------------------------------\n\nTITLE: Installing Pre-release Versions of TensorFlow and TensorFlow Hub\nDESCRIPTION: Commands to install nightly builds of TensorFlow and TensorFlow Hub for developers who want to try out the latest code without building from source.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/installation.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install tf-nightly\n$ pip install --upgrade tf-hub-nightly\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Random Seed\nDESCRIPTION: Imports TensorFlow and TensorFlow Datasets, displays the TensorFlow version, and sets a random seed for reproducible results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nprint(tf.__version__)\n# Set random seed for reproducible results \ntf.random.set_seed(22)\n```\n\n----------------------------------------\n\nTITLE: Reducing Dataset Elements to a Single Value\nDESCRIPTION: Shows how to use the dataset.reduce() method to compute a single value (in this case, the sum) from all elements in the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(dataset.reduce(0, lambda state, value: state + value).numpy())\n```\n\n----------------------------------------\n\nTITLE: Processing a Complex TensorFlow Dataset\nDESCRIPTION: This snippet demonstrates how to process the complex dataset by shuffling and using padded batching to handle variable-length sequences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nds_series_batch = ds_series.shuffle(20).padded_batch(10)\n\nids, sequence_batch = next(iter(ds_series_batch))\nprint(ids.numpy())\nprint()\nprint(sequence_batch.numpy())\n```\n\n----------------------------------------\n\nTITLE: Checking Torso Visibility in MoveNet Keypoints\nDESCRIPTION: Determines if there are enough visible torso keypoints in the MoveNet output. It checks if the model is confident in predicting at least one shoulder or hip keypoint.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef torso_visible(keypoints):\n  \"\"\"Checks whether there are enough torso keypoints.\n\n  This function checks whether the model is confident at predicting one of the\n  shoulders/hips which is required to determine a good crop region.\n  \"\"\"\n  return ((keypoints[0, 0, KEYPOINT_DICT['left_hip'], 2] >\n           MIN_CROP_KEYPOINT_SCORE or\n          keypoints[0, 0, KEYPOINT_DICT['right_hip'], 2] >\n           MIN_CROP_KEYPOINT_SCORE) and\n          (keypoints[0, 0, KEYPOINT_DICT['left_shoulder'], 2] >\n           MIN_CROP_KEYPOINT_SCORE or\n          keypoints[0, 0, KEYPOINT_DICT['right_shoulder'], 2] >\n           MIN_CROP_KEYPOINT_SCORE))\n```\n\n----------------------------------------\n\nTITLE: Testing Streaming Accuracy - Bash\nDESCRIPTION: Command to test the streaming accuracy of a trained model against a test audio file. Includes parameters for the frozen graph, labels, input audio, and ground truth labels.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nbazel run tensorflow/examples/speech_commands:test_streaming_accuracy -- \\\n--graph=/tmp/my_frozen_graph.pb \\\n--labels=/tmp/speech_commands_train/conv_labels.txt \\\n--wav=/tmp/speech_commands_train/streaming_test.wav \\\n--ground_truth=/tmp/speech_commands_train/streaming_test_labels.txt \\\n--verbose\n```\n\n----------------------------------------\n\nTITLE: Calculating Loss for Regression in TensorFlow\nDESCRIPTION: Defines the mean squared error loss function using the `tf.losses` module for a regression model. Running this operation evaluates the model's error between predicted and actual values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_22\n\nLANGUAGE: Python\nCODE:\n```\nloss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n\nprint(sess.run(loss))\n```\n\n----------------------------------------\n\nTITLE: Handling Error when Creating a Ragged Tensor with Multiple Types\nDESCRIPTION: Shows the error that occurs when attempting to create a ragged tensor with mixed types (strings and integers).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  tf.ragged.constant([[\"one\", \"two\"], [3, 4]])              # bad: multiple types\nexcept ValueError as exception:\n  print(exception)\n```\n\n----------------------------------------\n\nTITLE: Using Image Feature Vector SavedModel with Keras\nDESCRIPTION: Example showing how to use a TensorFlow Hub image feature vector model with the Keras API. This demonstrates integration with Keras for feature extraction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_saved_model_apis/images.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfeatures = hub.KerasLayer(\"path/to/model\")(images)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Datasets Package\nDESCRIPTION: Command to install or upgrade the TensorFlow Datasets package, which provides a collection of ready-to-use datasets for machine learning models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -U tensorflow_datasets\n```\n\n----------------------------------------\n\nTITLE: Basic TensorFlow Function with Graph Execution\nDESCRIPTION: Demonstrates converting a regular Python function to a TensorFlow graph function using tf.function with matrix multiplication operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Define a Python function.\ndef a_regular_function(x, y, b):\n  x = tf.matmul(x, y)\n  x = x + b\n  return x\n\n# The Python type of `a_function_that_uses_a_graph` will now be a\n# `PolymorphicFunction`.\na_function_that_uses_a_graph = tf.function(a_regular_function)\n\n# Make some tensors.\nx1 = tf.constant([[1.0, 2.0]])\ny1 = tf.constant([[2.0], [3.0]])\nb1 = tf.constant(4.0)\n\norig_value = a_regular_function(x1, y1, b1).numpy()\n# Call a `tf.function` like a Python function.\ntf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\nassert(orig_value == tf_function_value)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Python Operation Implementation Example\nDESCRIPTION: Example of implementing a TensorFlow operation in Python following the project conventions. This showcases proper argument handling, name scoping, tensor conversion, and documentation standards.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef my_op(tensor_in, other_tensor_in, my_param, other_param=0.5,\n          output_collections=(), name=None):\n  \"\"\"My operation that adds two tensors with given coefficients.\n\n  Args:\n    tensor_in: `Tensor`, input tensor.\n    other_tensor_in: `Tensor`, same shape as `tensor_in`, other input tensor.\n    my_param: `float`, coefficient for `tensor_in`.\n    other_param: `float`, coefficient for `other_tensor_in`.\n    output_collections: `tuple` of `string`s, name of the collection to\n                        collect result of this op.\n    name: `string`, name of the operation.\n\n  Returns:\n    `Tensor` of same shape as `tensor_in`, sum of input values with coefficients.\n\n  Example:\n    >>> my_op([1., 2.], [3., 4.], my_param=0.5, other_param=0.6,\n              output_collections=['MY_OPS'], name='add_t1t2')\n    [2.3, 3.4]\n  \"\"\"\n  with tf.name_scope(name or \"my_op\"):\n    tensor_in = tf.convert_to_tensor(tensor_in)\n    other_tensor_in = tf.convert_to_tensor(other_tensor_in)\n    result = my_param * tensor_in + other_param * other_tensor_in\n    tf.add_to_collection(output_collections, result)\n    return result\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Inconsistent Results with Old Type Promotion in TensorFlow\nDESCRIPTION: This example shows how the old type promotion system produces an error when operations are performed in a certain order, highlighting its inconsistency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# (a + b) + c throws an InvalidArgumentError.\ntry:\n  tf.add(tf.add(a, b), c)\nexcept tf.errors.InvalidArgumentError as e:\n  print(f'{type(e)}: {e}')  # InvalidArgumentError\n```\n\n----------------------------------------\n\nTITLE: Converting logits to probabilities using softmax\nDESCRIPTION: This code uses the tf.nn.softmax function to convert the logits outputted by the model into probabilities for each class. It applies the softmax function to the first five predictions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntf.nn.softmax(predictions[:5])\n```\n\n----------------------------------------\n\nTITLE: Descriptive Statistics of Training Data (Python)\nDESCRIPTION: This snippet calculates and prints descriptive statistics for the training dataset, excluding the target variable 'MPG', offering insights into the features' distributions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"MPG\")\ntrain_stats = train_stats.transpose()\ntrain_stats\n```\n\n----------------------------------------\n\nTITLE: Multiple Input/Output Op Registration Examples in C++\nDESCRIPTION: Demonstrates various input/output specifications for ops, including multiple inputs/outputs, built-in types, polymorphic types, and tensor sequences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_35\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"MultipleInsAndOuts\")\n    .Input(\"y: int32\")\n    .Input(\"z: float\")\n    .Output(\"a: string\")\n    .Output(\"b: int32\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"BuiltInTypesExample\")\n    .Input(\"integers: int32\")\n    .Input(\"complex_numbers: complex64\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"PolymorphicSingleInput\")\n    .Attr(\"T: type\")\n    .Input(\"in: T\");\n\nREGISTER_OP(\"RestrictedPolymorphicSingleInput\")\n    .Attr(\"T: {int32, int64}\")\n    .Input(\"in: T\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"ArbitraryTensorSequenceExample\")\n    .Attr(\"T: list(type)\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n\nREGISTER_OP(\"RestrictedTensorSequenceExample\")\n    .Attr(\"T: list({int32, int64})\")\n    .Input(\"in: T\")\n    .Output(\"out: T\");\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"Int32SequenceExample\")\n    .Attr(\"NumTensors: int\")\n    .Input(\"in: NumTensors * int32\")\n```\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"SameTypeSequenceExample\")\n    .Attr(\"NumTensors: int\")\n    .Attr(\"T: type\")\n    .Input(\"in: NumTensors * T\")\n```\n\n----------------------------------------\n\nTITLE: Verifying TensorFlow CPU Installation\nDESCRIPTION: This Python command imports TensorFlow and performs a simple tensor operation to verify that the CPU installation is working correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Initializing MultiWorkerMirroredStrategy\nDESCRIPTION: Creating an instance of the MultiWorkerMirroredStrategy class, which will be used to distribute the training across multiple workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Getting Class Information\nDESCRIPTION: Retrieves the dictionary of files per class and extracts the list of class names for further processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfiles_for_class = get_files_per_class(files)\nclasses = list(files_for_class.keys())\n```\n\n----------------------------------------\n\nTITLE: License and Copyright Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license header for TensorFlow Hub Authors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 header for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Cloning the TensorFlow Repository on Windows\nDESCRIPTION: Git commands to clone the TensorFlow source code repository and navigate to the project directory. Includes an optional step to check out a specific release branch.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/tensorflow/tensorflow.git\ncd tensorflow\n```\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout branch_name  # r1.9, r1.10, etc.\n```\n\n----------------------------------------\n\nTITLE: Configuring Training Parameters for ResNet\nDESCRIPTION: Sets up the loss function, metrics, and optimizer for training the ResNet model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetrics = tf.keras.metrics.SparseCategoricalAccuracy(),\noptimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n\ntrain_config = dict(loss=loss, metrics=metrics, optimizer=optimizer)\n```\n\nLANGUAGE: python\nCODE:\n```\nfit_config = dict(batch_size=128, epochs=100)\n```\n\nLANGUAGE: python\nCODE:\n```\nresnet_model.compile(**train_config)\nresnet_model.fit(train_examples, train_labels, **fit_config)\n```\n\n----------------------------------------\n\nTITLE: Listing Generated Embedding Files in Python\nDESCRIPTION: This code lists the files in the output directory after the embedding generation process is complete. It shows the generated embedding files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n!ls {output_dir}\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Dataset from ImageDataGenerator\nDESCRIPTION: This snippet creates a tf.data.Dataset from the ImageDataGenerator, specifying output types and shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nds = tf.data.Dataset.from_generator(\n    lambda: img_gen.flow_from_directory(flowers),\n    output_types=(tf.float32, tf.float32),\n    output_shapes=([32,256,256,3], [32,5])\n)\n\nds.element_spec\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TensorFlow Data Augmentation\nDESCRIPTION: Initial setup importing necessary Python libraries including matplotlib, numpy, tensorflow and tensorflow_datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow.keras import layers\n```\n\n----------------------------------------\n\nTITLE: Creating a Nested Ragged Tensor of Paragraphs\nDESCRIPTION: Shows how to create a doubly-nested ragged tensor representing paragraphs containing sentences with variable lengths.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nparagraphs = tf.ragged.constant([\n    [['I', 'have', 'a', 'cat'], ['His', 'name', 'is', 'Mat']],\n    [['Do', 'you', 'want', 'to', 'come', 'visit'], [\"I'm\", 'free', 'tomorrow']],\n])\nprint(paragraphs)\n```\n\n----------------------------------------\n\nTITLE: Embedding String Data with Keras\nDESCRIPTION: Shows how to embed string data using a vocabulary with Keras StringLookup and Embedding layers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nstring_lookup_layer = tf.keras.layers.StringLookup(\n    vocabulary=['small', 'medium', 'large'], num_oov_indices=0)\nembedding = tf.keras.layers.Embedding(3, 4)\nembedding(string_lookup_layer(['small', 'medium', 'large']))\n```\n\n----------------------------------------\n\nTITLE: Creating a Ragged Tensor of Sentences with tf.ragged.constant\nDESCRIPTION: Demonstrates how to create a ragged tensor representing a list of sentences (variable-length lists of words) using tf.ragged.constant.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsentences = tf.ragged.constant([\n    [\"Let's\", \"build\", \"some\", \"ragged\", \"tensors\", \"!\"],\n    [\"We\", \"can\", \"use\", \"tf.ragged.constant\", \".\"]])\nprint(sentences)\n```\n\n----------------------------------------\n\nTITLE: Defining a Plotting Function for Model Predictions\nDESCRIPTION: Creates a function to plot the original data, ground truth, and model predictions for visual comparison.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ndef plot_preds(x, y, f, model, title):\n  plt.figure()\n  plt.plot(x, y, '.', label='Data')\n  plt.plot(x, f(x), label='Ground truth')\n  plt.plot(x, model(x), label='Predictions')\n  plt.title(title)\n  plt.legend()\n```\n\n----------------------------------------\n\nTITLE: Dropping Missing Values (Python)\nDESCRIPTION: This snippet simplifies the dataset by dropping rows that contain any missing values, ensuring the integrity of the data used for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndataset = dataset.dropna()\n```\n\n----------------------------------------\n\nTITLE: Segmenting Words into Sentences\nDESCRIPTION: Groups words back into sentences using RaggedTensor operations and word counts per sentence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nsentence_num_words = tf.reduce_sum(\n    tf.cast(sentence_char_starts_word, tf.int64),\n    axis=1)\n\nsentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n    values=word_char_codepoint,\n    row_lengths=sentence_num_words)\nprint(sentence_word_char_codepoint)\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow with GPU Support on Windows\nDESCRIPTION: Command to build TensorFlow package with GPU support on Windows. Note that GPU support is only available for TensorFlow 2.10 or earlier versions on native Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nbazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\n```\n\n----------------------------------------\n\nTITLE: Vector Constraint Shape Function in C++\nDESCRIPTION: Shape function implementation that enforces a vector shape constraint on the input tensor using WithRank validation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_43\n\nLANGUAGE: c++\nCODE:\n```\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      ::tensorflow::shape_inference::ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n      c->set_output(0, input);\n      return Status::OK();\n    });\n```\n\n----------------------------------------\n\nTITLE: Detecting Word Boundaries\nDESCRIPTION: Identifies word boundaries by detecting script changes between adjacent characters and marking sentence starts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nsentence_char_starts_word = tf.concat(\n    [tf.fill([sentence_char_script.nrows(), 1], True),\n     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n    axis=1)\n\nword_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\nprint(word_starts)\n```\n\n----------------------------------------\n\nTITLE: Creating an Empty GraphDef Object in Python\nDESCRIPTION: Creates an empty GraphDef object that will be populated with data from a file. This object is generated from the protocol buffer definition in graph.proto.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/model_files.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ngraph_def = graph_pb2.GraphDef()\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Tensors in a TensorFlow Session\nDESCRIPTION: Demonstrates how to evaluate multiple tensors in a single session run call by passing a dictionary or tuple structure. The session returns results in the same structure format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(sess.run({'ab':(a, b), 'total':total}))\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installation of gsoc-wav2vec2 package and sound processing libraries using pip and apt-get\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main\n!sudo apt-get install -y libsndfile1-dev\n!pip3 install -q SoundFile\n```\n\n----------------------------------------\n\nTITLE: Creating ParameterServerStrategy in TensorFlow\nDESCRIPTION: This snippet demonstrates how to create a ParameterServerStrategy object using a cluster resolver. This strategy is used for distributed training across multiple machines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Up Data in Python\nDESCRIPTION: Imports TensorFlow libraries and sets up simple feature and label datasets for demonstration purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\nfeatures = [[1., 1.5]]\nlabels = [[0.3]]\neval_features = [[4., 4.5]]\neval_labels = [[0.8]]\n```\n\n----------------------------------------\n\nTITLE: Extending Polymorphic Op with Additional Type Support\nDESCRIPTION: Shows how to extend a polymorphic op to support additional data types by adding more types to the type constraint in the op registration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_26\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: {float, double, int32}\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n```\n\n----------------------------------------\n\nTITLE: Defining Bazel Build Rule for Custom Op\nDESCRIPTION: This snippet shows a Bazel build rule for compiling the custom operation as a shared library using TensorFlow's build system.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\n\ntf_custom_op_library(\n    name = \"zero_out.so\",\n    srcs = [\"zero_out.cc\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Op in Python\nDESCRIPTION: This snippet demonstrates how to load and use the custom operation in Python using TensorFlow's load_op_library function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nzero_out_module = tf.load_op_library('./zero_out.so')\nprint(zero_out_module.zero_out([[1, 2], [3, 4]]).numpy())\n\n# Prints\narray([[1, 0], [0, 0]], dtype=int32)\n```\n\n----------------------------------------\n\nTITLE: Defining Replicated Layouts for Keras Layers\nDESCRIPTION: Creates layout objects for 1D and 2D tensors that are fully replicated across all devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nunsharded_layout_2d = dtensor.Layout.replicated(mesh, 2)\nunsharded_layout_1d = dtensor.Layout.replicated(mesh, 1)\n```\n\n----------------------------------------\n\nTITLE: Visualizing TensorBoard for Training - Shell\nDESCRIPTION: This command initializes TensorBoard, allowing users to visualize training metrics and insights from the CIFAR-10 training process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"tensorboard --logdir /tmp/cifar10_train\"\n```\n\n----------------------------------------\n\nTITLE: Creating a SparseTensor and Converting to Dense\nDESCRIPTION: Demonstrates an alternative approach using SparseTensor to represent scattered values, which is similar to using tf.scatter_nd.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor_slicing.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nt9 = tf.SparseTensor(indices=[[0, 2], [2, 1], [3, 3]],\n                     values=[2, 11, 18],\n                     dense_shape=[4, 5])\n\nprint(t9)\n```\n\n----------------------------------------\n\nTITLE: Downloading Test Image for ESRGAN Performance Evaluation\nDESCRIPTION: Downloads a new test image to evaluate the model's performance on different inputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n!wget \"https://lh4.googleusercontent.com/-Anmw5df4gj0/AAAAAAAAAAI/AAAAAAAAAAc/6HxU8XFLnQE/photo.jpg64\" -O test.jpg\nIMAGE_PATH = \"test.jpg\"\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Keras in Python\nDESCRIPTION: This snippet shows how to import TensorFlow 1.x compatibility mode and Keras layers, then prints the versions of TensorFlow and Keras being used.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow.keras import layers\n\nprint(tf.version.VERSION)\nprint(tf.keras.__version__)\n```\n\n----------------------------------------\n\nTITLE: Loading and Executing SPICE Model\nDESCRIPTION: Loading the SPICE model from TensorFlow Hub and processing audio to obtain pitch and uncertainty outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel = hub.load(\"https://tfhub.dev/google/spice/2\")\n\n# We now feed the audio to the SPICE tf.hub model to obtain pitch and uncertainty outputs as tensors.\nmodel_output = model.signatures[\"serving_default\"](tf.constant(audio_samples, tf.float32))\n\npitch_outputs = model_output[\"pitch\"]\nuncertainty_outputs = model_output[\"uncertainty\"]\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Helper Libraries\nDESCRIPTION: Imports TensorFlow v1 compatibility mode and helper libraries like NumPy and os, then prints the TensorFlow version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import TensorFlow\nimport tensorflow.compat.v1 as tf\n\n\n# Helper libraries\nimport numpy as np\nimport os\n\nprint(tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Building TensorFlow Nightly CPU Package\nDESCRIPTION: Command to build a TensorFlow nightly CPU pip package. This sets the wheel name to tf_nightly_cpu instead of tensorflow_cpu for nightly builds.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nbazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tf_nightly_cpu\n```\n\n----------------------------------------\n\nTITLE: Listing Directory Contents using Shell Command (Python)\nDESCRIPTION: Executes a shell command to list the contents of the current directory, often used to verify file creation or directory state after an operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n!ls\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Packages\nDESCRIPTION: Importing essential Python packages (json, os, sys) needed for file operations and environment configuration in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport os\nimport sys\n```\n\n----------------------------------------\n\nTITLE: Copying Subsite Template in Bash\nDESCRIPTION: This command copies the subsite template directory from the TensorFlow docs repository to the project repository. It sets up the base structure for the project's documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/subsite/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ cp -r tensorflow/docs/tools/templates/subsite/g3doc tensorflow/myproject/\n```\n\n----------------------------------------\n\nTITLE: Creating Normal Tensor with Specified dtype in TensorFlow\nDESCRIPTION: This snippet demonstrates how a normal Tensor is created when the dtype argument is explicitly specified using tf.constant.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntf.constant(5, tf.int32)  # <tf.Tensor: shape=(), dtype=int32, numpy=5>\n```\n\n----------------------------------------\n\nTITLE: Displaying Predictions During U-Net Model Training in TensorFlow\nDESCRIPTION: This callback class is used to display sample predictions after each epoch during the training process, allowing visual monitoring of the model's improvement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass DisplayCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    clear_output(wait=True)\n    show_predictions()\n    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n```\n\n----------------------------------------\n\nTITLE: Launching the Training Operation - Shell\nDESCRIPTION: This shell command launches the training script for the CIFAR-10 model, which initializes the training process and begins model optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n\"python cifar10_train.py\"\n```\n\n----------------------------------------\n\nTITLE: Building Wav2Vec2 Model Architecture\nDESCRIPTION: Construction of the model using Keras Functional API, combining pre-trained layer with dense output layer\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ninputs = tf.keras.Input(shape=(AUDIO_MAXLEN,))\nhidden_states = pretrained_layer(inputs)\noutputs = tf.keras.layers.Dense(config.vocab_size)(hidden_states)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-output Baseline Model\nDESCRIPTION: Creates and compiles a baseline model for multi-output prediction using mean squared error loss and mean absolute error metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nbaseline = Baseline()\nbaseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n```\n\n----------------------------------------\n\nTITLE: Verifying Dataset Sizes\nDESCRIPTION: Prints the size of training and validation datasets using tf.data.experimental.cardinality. This ensures the split was performed correctly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\n```\n\n----------------------------------------\n\nTITLE: Setting up dependencies for MoViNet video classification\nDESCRIPTION: Installs required packages like ffmpeg and mediapy, and imports necessary libraries for video processing and machine learning.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!sudo apt install -y ffmpeg\n!pip install -q mediapy\n```\n\nLANGUAGE: bash\nCODE:\n```\n!pip uninstall -q -y opencv-python-headless\n!pip install -q \"opencv-python-headless<4.3\"\n```\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport mediapy as media\nimport numpy as np\nimport PIL\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tqdm\n\nmpl.rcParams.update({\n    'font.size': 10,\n})\n```\n\n----------------------------------------\n\nTITLE: Displaying Unknown Op Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when TensorFlow encounters an unknown operation (op) that it doesn't recognize.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_16\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits</pre>\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Printing MaskedTensor Representation in Python\nDESCRIPTION: Demonstrates the default printable representation provided by ExtensionType, which shows the class name and values for each field.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(MaskedTensor(values=[1, 2, 3], mask=[True, True, False]))\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and NumPy in Python\nDESCRIPTION: This snippet imports TensorFlow (v1 compatibility mode) and NumPy, setting up the environment for working with TFRecords and tf.Example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n\nimport numpy as np\nimport IPython.display as display\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Default Value for Backward Compatibility\nDESCRIPTION: Demonstrates adding a default value for an attribute when extending an existing op to preserve backward compatibility with existing code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_25\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n  .Attr(\"T: {float, int32} = DT_INT32\")\n  .Input(\"to_zero: T\")\n  .Output(\"zeroed: T\")\n```\n\n----------------------------------------\n\nTITLE: Creating Image Normalization Function\nDESCRIPTION: Defines a function to normalize MNIST images from uint8 to float32 in the range [0,1].\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef normalize_img(image, label):\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n  return tf.cast(image, tf.float32) / 255., label\n```\n\n----------------------------------------\n\nTITLE: Building Neural Network Model\nDESCRIPTION: Constructs a sequential neural network with flatten and dense layers for image classification using Keras.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation=tf.nn.relu),\n    keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n```\n\n----------------------------------------\n\nTITLE: Converting a RaggedTensor to SparseTensor\nDESCRIPTION: This code converts a ragged TensorFlow tensor into a sparse tensor, which can be helpful for storage and performance.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nbatch_chars_sparse = batch_chars_ragged.to_sparse()\n```\n\n----------------------------------------\n\nTITLE: Mapping Serialization Function over Dataset using TensorFlow (Python)\nDESCRIPTION: Applies a serialization function to each dataset element using tf.map function, preparing dataset entries for TFRecord file writing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/tf_records.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nserialized_features_dataset = features_dataset.map(tf_serialize_example)\nserialized_features_dataset\n```\n\n----------------------------------------\n\nTITLE: VersionDef Protocol Buffer Reference\nDESCRIPTION: Reference to the VersionDef protocol buffer definition used for versioning in TensorFlow, which contains producer version, minimum consumer version, and bad consumer version information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/version_compat.md#2025-04-21_snippet_2\n\nLANGUAGE: protobuf\nCODE:\n```\nVersionDef versions\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Supporting Modules\nDESCRIPTION: Importing the required libraries for the AutoGraph examples, including TensorFlow, Keras layers, NumPy, and matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\nLANGUAGE: python\nCODE:\n```\nlayers = tf.keras.layers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Accessing Training History Dictionary\nDESCRIPTION: Retrieve the training history dictionary to access metrics like training and validation loss and accuracy for further analysis.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_text_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nhistory_dict = history.history\nhistory_dict.keys()\n```\n\n----------------------------------------\n\nTITLE: Training Keras Model with Dataset API\nDESCRIPTION: Shows how to train a distributed Keras model using tf.data.Dataset for input pipeline with batching and repetition.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(10)\nmodel.fit(dataset, epochs=2)\nmodel.evaluate(dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing Tensor API Dispatch in TensorFlow\nDESCRIPTION: Demonstrates how to use dispatch decorators to override default TensorFlow operations for custom types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n@tf.experimental.dispatch_for_api(tf.stack)\ndef masked_stack(values: List[MaskedTensor], axis = 0):\n  return MaskedTensor(tf.stack([v.values for v in values], axis),\n                      tf.stack([v.mask for v in values], axis))\n```\n\nLANGUAGE: python\nCODE:\n```\n@tf.experimental.dispatch_for_unary_elementwise_apis(MaskedTensor)\ndef masked_tensor_unary_elementwise_api_handler(api_func, x):\n  return MaskedTensor(api_func(x.values), x.mask)\n```\n\nLANGUAGE: python\nCODE:\n```\n@tf.experimental.dispatch_for_binary_elementwise_apis(MaskedTensor, MaskedTensor)\ndef masked_tensor_binary_elementwise_api_handler(api_func, x, y):\n  return MaskedTensor(api_func(x.values, y.values), x.mask & y.mask)\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained Progressive GAN Model from TensorFlow Hub\nDESCRIPTION: This snippet loads the pre-trained Progressive GAN model for face generation from TensorFlow Hub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_generative_image_module.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nprogan = hub.load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']\n```\n\n----------------------------------------\n\nTITLE: Cropping Image Center in TensorFlow Python\nDESCRIPTION: Shows how to use tf.image.central_crop function to crop the center portion of an image. This is a common preprocessing step in image analysis pipelines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/index.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntf.image.central_crop\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Neural Network Model\nDESCRIPTION: Creates a sequential neural network with Flatten, Dense, and Dropout layers for image classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])\n```\n\n----------------------------------------\n\nTITLE: Custom Output Shape Function in C++\nDESCRIPTION: Shape function that sets a specific output shape (n,3) based on the first dimension of the input tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_45\n\nLANGUAGE: c++\nCODE:\n```\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    c->set_output(0, c->Matrix(c->Dim(c->input(0), 0), 3));\n    return Status::OK();\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and TPU Environment\nDESCRIPTION: Sets up TensorFlow imports, version checks and TPU environment configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/tpu_custom_training.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\ntf.compat.v1.disable_eager_execution()\nimport numpy as np\nimport os\n\nassert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n\nassert float('.'.join(tf.__version__.split('.')[:2])) >= 1.14, 'Make sure that Tensorflow version is at least 1.14'\n```\n\n----------------------------------------\n\nTITLE: Python Dataset Wrapper Class\nDESCRIPTION: Python code snippet showing how to wrap the C++ dataset implementation in a Python tf.data.Dataset subclass for easier usage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/formats.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Saving a TensorFlow Module with SavedModel\nDESCRIPTION: Demonstrates how to save a tf.Module using tf.saved_model.save, which preserves both the model architecture and variable values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nsave_path = './saved'\ntf.saved_model.save(mod, save_path)\n```\n\n----------------------------------------\n\nTITLE: Printing Image and Label Information\nDESCRIPTION: This snippet prints the data type and shape of the images and labels obtained from the ImageDataGenerator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nprint(images.dtype, images.shape)\nprint(labels.dtype, labels.shape)\n```\n\n----------------------------------------\n\nTITLE: Executing Convolutional Layers Sequentially without Variable Reuse\nDESCRIPTION: Demonstrates attempting to sequentially execute two convolutional layers which fails due to variable name conflicts. Inputs are random normal tensors. Highlights the need for distinct variable scopes to prevent reuse errors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ninput1 = tf.random_normal([1,10,10,32])\ninput2 = tf.random_normal([1,20,20,32])\nx = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\nx = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails.\n```\n\n----------------------------------------\n\nTITLE: Loading TF1 Checkpoint Using TF2 API\nDESCRIPTION: Demonstrates loading a TensorFlow 1.x checkpoint using the TF2 Checkpoint API with variable name scoping and verification of loaded values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\na = tf.Variable(0.0, name='a')\nb = tf.Variable(0.0, name='b')\nwith tf.name_scope('scoped'):\n  c = tf.Variable(0.0, name='c')\n\n# Without the name_scope, name=\"scoped/c\" works too:\nc_2 = tf.Variable(0.0, name='scoped/c')\n\nprint(\"Variable names: \")\nprint(f\"  a.name = {a.name}\")\nprint(f\"  b.name = {b.name}\")\nprint(f\"  c.name = {c.name}\")\nprint(f\"  c_2.name = {c_2.name}\")\n\n# Restore the values with tf.train.Checkpoint\nckpt = tf.train.Checkpoint(variables=[a, b, c, c_2])\nckpt.restore(save_path)\nprint(f\"loaded values of [a, b, c, c_2]:  [{a.numpy()}, {b.numpy()}, {c.numpy()}, {c_2.numpy()}]\")\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Docs and Importing Additional Libraries in Python\nDESCRIPTION: This code installs the TensorFlow docs package and imports additional libraries needed for visualization and data manipulation in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n!pip install git+https://github.com/tensorflow/docs\n\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\nimport tensorflow_docs.plots\n\nfrom  IPython import display\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\n\nimport pathlib\nimport shutil\nimport tempfile\n```\n\n----------------------------------------\n\nTITLE: Verifying TensorFlow GPU Installation\nDESCRIPTION: Python command to list available GPU devices and confirm successful TensorFlow GPU installation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\npython3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n```\n\n----------------------------------------\n\nTITLE: Adding RNN Layers with LSTM for Handwriting Recognition in TensorFlow\nDESCRIPTION: This snippet demonstrates how to add bidirectional LSTM layers to the model using TensorFlow's contrib module. It also includes code for creating a fixed-length embedding by summing up the LSTM outputs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\noutputs, _, _ = contrib_rnn.stack_bidirectional_dynamic_rnn(\n    cells_fw=[cell(params.num_nodes) for _ in range(params.num_layers)],\n    cells_bw=[cell(params.num_nodes) for _ in range(params.num_layers)],\n    inputs=convolved,\n    sequence_length=lengths,\n    dtype=tf.float32,\n    scope=\"rnn_classification\")\n```\n\nLANGUAGE: Python\nCODE:\n```\nmask = tf.tile(\n    tf.expand_dims(tf.sequence_mask(lengths, tf.shape(outputs)[1]), 2),\n    [1, 1, tf.shape(outputs)[2]])\nzero_outside = tf.where(mask, outputs, tf.zeros_like(outputs))\noutputs = tf.reduce_sum(zero_outside, axis=1)\n```\n\n----------------------------------------\n\nTITLE: Defining a Medium Neural Network with Three 64-Unit Layers\nDESCRIPTION: Creates a medium-sized neural network with three hidden layers of 64 units each using the ELU activation function. This model has significantly more capacity than the small model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nmedium_model = tf.keras.Sequential([\n    layers.Dense(64, activation='elu', input_shape=(FEATURES,)),\n    layers.Dense(64, activation='elu'),\n    layers.Dense(64, activation='elu'),\n    layers.Dense(1)\n])\n```\n\n----------------------------------------\n\nTITLE: Fine-Tuning Pre-trained Model Layers\nDESCRIPTION: Enables training of specific layers in the base model by unfreezing the model and selectively setting trainable layers\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nbase_model.trainable = True\n\nfine_tune_at = 100\n\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable = False\n```\n\n----------------------------------------\n\nTITLE: Verifying Wide Conv1D Window Shapes\nDESCRIPTION: Confirms that the wide convolutional window configuration produces compatible shapes for inputs, labels, and model outputs when using the Conv1D model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Wide conv window\")\nprint('Input shape:', wide_conv_window.example[0].shape)\nprint('Labels shape:', wide_conv_window.example[1].shape)\nprint('Output shape:', conv_model(wide_conv_window.example[0]).shape)\n```\n\n----------------------------------------\n\nTITLE: Implementing Model Function for Citation Intent Classification\nDESCRIPTION: This function defines the model architecture using CORD-19 embeddings and a classification layer. It handles different modes (PREDICT, TRAIN, EVAL) and sets up loss and metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef model_fn(features, labels, mode, params):\n  # Embed the text\n  embed = hub.Module(params['module_name'], trainable=params['trainable_module'])\n  embeddings = embed(features['feature'])\n\n  # Add a linear layer on top\n  logits = tf.layers.dense(\n      embeddings, units=THE_DATASET.num_classes(), activation=None)\n  predictions = tf.argmax(input=logits, axis=1)\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions={\n            'logits': logits,\n            'predictions': predictions,\n            'features': features['feature'],\n            'labels': features['label']\n        })\n  \n  # Set up a multi-class classification head\n  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n      labels=labels, logits=logits)\n  loss = tf.reduce_mean(loss)\n\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  elif mode == tf.estimator.ModeKeys.EVAL:\n    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions)\n    precision = tf.metrics.precision(labels=labels, predictions=predictions)\n    recall = tf.metrics.recall(labels=labels, predictions=predictions)\n\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        loss=loss,\n        eval_metric_ops={\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n        })\n```\n\n----------------------------------------\n\nTITLE: Accessing a Single Prediction\nDESCRIPTION: This snippet shows how to access the prediction for the first image in the test set.  It assumes `predictions` is an array generated by `model.predict`.  The output is the array of confidences for each class for the first image.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npredictions[0]\n```\n\n----------------------------------------\n\nTITLE: Installing and Importing Keras Tuner\nDESCRIPTION: Installs the Keras Tuner library and imports it for use in the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q -U keras-tuner\n```\n\nLANGUAGE: python\nCODE:\n```\nimport keras_tuner as kt\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Iris Dataset Parsing\nDESCRIPTION: Sets up constants for column names and species classes needed for parsing the Iris dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nCSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\nSPECIES = ['Setosa', 'Versicolor', 'Virginica']\n```\n\n----------------------------------------\n\nTITLE: Defining embedding column in TF1\nDESCRIPTION: This code snippet converts sparse categorical inputs to a dense representation using `tf1.tpu.experimental.embedding_column`.  It creates an embedding column that maps the categorical IDs to dense embedding vectors. The `dimension` parameter is set to 5, specifying the width of the embedding table, which will store an embedding vector for each of the `num_buckets` defined earlier.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nembedding_column = tf1.tpu.experimental.embedding_column(\n    embedding_id_column, dimension=5)\n```\n\n----------------------------------------\n\nTITLE: Inspecting and Visualizing Dataset Features in TensorFlow\nDESCRIPTION: This snippet prints a sample of features and creates a histogram of the flattened features to inspect the data distribution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nfor features,label in packed_ds.batch(1000).take(1):\n  print(features[0])\n  plt.hist(features.numpy().flatten(), bins = 101)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Estimator in Python\nDESCRIPTION: These snippets show how to train and evaluate an Estimator using the previously defined input function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nest_mobilenet_v2.train(input_fn=lambda: train_input_fn(32), steps=50)\n\nest_mobilenet_v2.evaluate(input_fn=lambda: train_input_fn(32), steps=10)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MNIST Dataset\nDESCRIPTION: Loads the MNIST dataset and normalizes pixel values to range [0,1] by dividing by 255.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n\n----------------------------------------\n\nTITLE: Upgrading DeepLab Model with tf_upgrade_v2 in Bash\nDESCRIPTION: This command uses tf_upgrade_v2 to upgrade the DeepLab model directory and generate a report.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntf_upgrade_v2 \\\n    --intree models/research/deeplab \\\n    --outtree deeplab_v2 \\\n    --reportfile deeplab_report.txt > /dev/null\n```\n\n----------------------------------------\n\nTITLE: Running SavedModel with Python Expression\nDESCRIPTION: Example showing how to combine file input with Python expression input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\n$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \\\n--signature_def x1_x2_to_y --inputs x1=/tmp/my_data1.npz[x] \\\n--input_exprs 'x2=np.ones((3,1))'\n```\n\n----------------------------------------\n\nTITLE: Creating Image Tensor in TensorFlow\nDESCRIPTION: Shows creation of a rank 4 tensor commonly used for image processing with batch, height, width, and color channel dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmy_image = tf.zeros([10, 299, 299, 3])  # batch x height x width x color\n```\n\n----------------------------------------\n\nTITLE: Compiling Text Generation Model in TensorFlow\nDESCRIPTION: Configures the model for training by setting the optimizer to Adam and using the custom loss function for character prediction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n    optimizer = tf.train.AdamOptimizer(),\n    loss = loss)\n```\n\n----------------------------------------\n\nTITLE: Audio Format Conversion Function\nDESCRIPTION: Function to convert audio files to 16kHz mono format required by the SPICE model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nEXPECTED_SAMPLE_RATE = 16000\n\ndef convert_audio_for_model(user_file, output_file='converted_audio_file.wav'):\n  audio = AudioSegment.from_file(user_file)\n  audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)\n  audio.export(output_file, format=\"wav\")\n  return output_file\n```\n\n----------------------------------------\n\nTITLE: Unicode String Encoding from Padded or Sparse Format\nDESCRIPTION: This code converts a Tensor with multiple strings in padded or sparse format to a RaggedTensor for encoding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n tf.strings.unicode_encode(\n     tf.RaggedTensor.from_sparse(batch_chars_sparse),\n     output_encoding='UTF-8')\n```\n\nLANGUAGE: python\nCODE:\n```\n tf.strings.unicode_encode(\n     tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n     output_encoding='UTF-8')\n```\n\n----------------------------------------\n\nTITLE: Indexing DynamicRaggedShape for Uniform Dimensions\nDESCRIPTION: Shows how to index a DynamicRaggedShape to access the size of uniform dimensions, similar to how you would index a regular tensor shape.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nrt_shape[0]\n```\n\n----------------------------------------\n\nTITLE: Printing Initial Model Performance Metrics\nDESCRIPTION: Displays the initial loss and accuracy metrics obtained from evaluating the untrained model on the validation dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nprint(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))\n```\n\n----------------------------------------\n\nTITLE: Performing Text-to-Video Retrieval with S3D MIL-NCE Model in Python\nDESCRIPTION: This snippet demonstrates the text-to-video retrieval process using the S3D MIL-NCE model. It prepares video and text inputs, generates embeddings, and computes similarity scores between videos and text queries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_to_video_retrieval_with_s3d_milnce.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Prepare video inputs.\nvideos_np = np.stack(all_videos, axis=0)\n\n# Prepare text input.\nwords_np = np.array(all_queries_video)\n\n# Generate the video and text embeddings.\nvideo_embd, text_embd = generate_embeddings(hub_model, videos_np, words_np)\n\n# Scores between video and text is computed by dot products.\nall_scores = np.dot(text_embd, tf.transpose(video_embd))\n```\n\n----------------------------------------\n\nTITLE: Using tf_upgrade_v2 on a Single File in Bash\nDESCRIPTION: This command demonstrates how to use tf_upgrade_v2 to upgrade a single Python file from TensorFlow 1.x to 2.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntf_upgrade_v2 \\\n  --infile models/samples/cookbook/regression/custom_regression.py \\\n  --outfile /tmp/custom_regression_v2.py\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Linear Model with TensorFlow Keras\nDESCRIPTION: Creates a simple neural network class that inherits from tf.keras.Model with a single dense layer. This model will be used to demonstrate checkpoint saving and loading.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Net(tf.keras.Model):\n  \"\"\"A simple linear model.\"\"\"\n\n  def __init__(self):\n    super(Net, self).__init__()\n    self.l1 = tf.keras.layers.Dense(5)\n\n  def call(self, x):\n    return self.l1(x)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading TensorFlow Models using SavedModel\nDESCRIPTION: Demonstrates how to save a TensorFlow model using SavedModel format and then load it back as a new object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntf.saved_model.save(my_model, \"the_saved_model\")\n\nnew_model = tf.saved_model.load(\"the_saved_model\")\n\nprint(my_model([[2.0, 2.0, 2.0]]))\nprint(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))\n```\n\n----------------------------------------\n\nTITLE: Training the Music Generation Model in TensorFlow\nDESCRIPTION: Executes the model training process for a specified number of epochs using the prepared dataset and callbacks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n%%time\nepochs = 50\n\nhistory = model.fit(\n    train_ds,\n    epochs=epochs,\n    callbacks=callbacks,\n)\n```\n\n----------------------------------------\n\nTITLE: Training the Large Model and Storing its History\nDESCRIPTION: Compiles and trains the large model with four 512-unit hidden layers, then stores its training history to demonstrate overfitting behavior in comparison to smaller models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nsize_histories['large'] = compile_and_fit(large_model, \"sizes/large\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TensorFlow Estimator Model\nDESCRIPTION: Evaluates the trained Estimator model using the training input function and prints evaluation metrics.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/estimator.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresult = model.evaluate(train_input_fn, steps=10)\n\nfor key, value in result.items():\n  print(key, \":\", value)\n```\n\n----------------------------------------\n\nTITLE: Importing Basic Python Modules\nDESCRIPTION: Importing essential Python modules (json, os, sys) needed for environment configuration and JSON handling in the multi-worker training setup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport os\nimport sys\n```\n\n----------------------------------------\n\nTITLE: Reusable SavedModel Call Interface\nDESCRIPTION: Pseudo-code showing the interface for calling a reusable SavedModel object, demonstrating the basic call pattern with inputs and optional training parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/reusable_saved_models.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\noutputs = obj(inputs, trainable=..., **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Distributed Variable Placement\nDESCRIPTION: Demonstrates automatic variable placement in a distributed setting using replica_device_setter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncluster_spec = {\n    \"ps\": [\"ps0:2222\", \"ps1:2222\"],\n    \"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]}\nwith tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n  v = tf.get_variable(\"v\", shape=[20, 20])  # this variable is placed\n                                            # in the parameter server\n                                            # by the replica_device_setter\n```\n\n----------------------------------------\n\nTITLE: Implementing Parallel Mapping in TensorFlow Data Pipeline\nDESCRIPTION: Demonstrates how to use parallel mapping in a TensorFlow data pipeline using tf.data.AUTOTUNE for automatic parallelism optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbenchmark(\n    ArtificialDataset()\n    .map(\n        mapped_function,\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Activating Python Virtual Environment for TensorFlow on Linux\nDESCRIPTION: This command activates the 'tf' virtual environment, ensuring that subsequent Python commands use the isolated environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsource tf/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Visualizing Gradient Descent Optimization Paths\nDESCRIPTION: Calls the visualization function to display the optimization paths for gradient descent with different learning rates.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/optimizers_core.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nviz_paths(param_map_gd, x_vals, loss, \"Gradient descent\")\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow from Built Wheel Package\nDESCRIPTION: Command to install the TensorFlow package from the built wheel file. The filename depends on the TensorFlow version and platform tags.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npip install bazel-bin/tensorflow/tools/pip_package/wheel_house/tensorflow-<version>-<tags>.whl\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for TensorFlow Model Saving\nDESCRIPTION: Installs the Python packages pyyaml and h5py which are required for saving TensorFlow models in the HDF5 format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip install pyyaml h5py  # Required to save models in HDF5 format.\n```\n\n----------------------------------------\n\nTITLE: Slicing DynamicRaggedShape in TensorFlow\nDESCRIPTION: Shows how to slice a DynamicRaggedShape, which is allowed as long as the slice begins with axis 0 or contains only dense dimensions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nrt_shape[:1]\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Fashion MNIST Dataset\nDESCRIPTION: Demonstrates loading and preprocessing the Fashion MNIST dataset for use with tf.data and Keras\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_82\n\nLANGUAGE: python\nCODE:\n```\ntrain, test = tf.keras.datasets.fashion_mnist.load_data()\n\nimages, labels = train\nimages = images/255.0\nlabels = labels.astype(np.int32)\n```\n\n----------------------------------------\n\nTITLE: Evaluating the Trained Model\nDESCRIPTION: Load the latest checkpoint and evaluate the model's performance on the test dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n\neval_loss, eval_acc = model.evaluate(eval_dataset)\nprint ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n```\n\n----------------------------------------\n\nTITLE: Defining a Test Function for Constant Folding Optimization\nDESCRIPTION: This function creates and returns a TensorFlow function that performs matrix multiplication operations on constants. It's used to demonstrate the effect of constant folding optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef test_function_1():\n  @tf.function\n  def simple_function(input_arg):\n    print('Tracing!')\n    a = tf.constant(np.random.randn(2000,2000), dtype = tf.float32)\n    c = a\n    for n in range(50):\n      c = c@a\n    return tf.reduce_mean(c+input_arg)\n\n  return simple_function\n```\n\n----------------------------------------\n\nTITLE: Executing TensorFlow Hub Embedding Pipeline in Python\nDESCRIPTION: Runs the previously set up embedding pipeline and prints the execution time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Running pipeline...\")\n%time run_hub2emb(args)\nprint(\"Pipeline is done.\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Builder\nDESCRIPTION: Sets up the dataset builder to work with test data only\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Since the dataset builder expects the train and test split to be downloaded,\n# patch it so it only expects the test data to be available\nbuilder = BairRobotPushingSmall()\ntest_generator = SplitGenerator(name='test', gen_kwargs={\"filedir\": str(TEST_DIR)})\nbuilder._split_generators = lambda _: [test_generator]\nbuilder.download_and_prepare()\n```\n\n----------------------------------------\n\nTITLE: Reusing Compiled Graph in tf.function\nDESCRIPTION: Demonstrates subsequent execution of a tf.function with same-shaped inputs, which reuses the previously created graph without re-tracing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant([10, 9, 8])\nmy_func(x)\n```\n\n----------------------------------------\n\nTITLE: Opening a TensorFlow Graph File for Reading in Python\nDESCRIPTION: Opens a TensorFlow graph file in binary read mode to prepare for loading its contents into a GraphDef object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/model_files.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith open(FLAGS.graph, \"rb\") as f:\n```\n\n----------------------------------------\n\nTITLE: Creating a basic input function for TensorFlow Estimators in Python\nDESCRIPTION: Skeleton code for an input function that manipulates a dataset and returns a feature dictionary and label for TensorFlow Estimators.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef input_fn(dataset):\n   ...  # manipulate dataset, extracting the feature dict and the label\n   return feature_dict, label\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow 1.x Dropout Example in Python\nDESCRIPTION: This snippet creates a Python file with TensorFlow 1.x code using dropout and zeros_like functions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n%%writefile dropout.py\nimport tensorflow as tf\n\nd = tf.nn.dropout(tf.range(10), 0.2)\nz = tf.zeros_like(d, optimize=False)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Setting Up AUTOTUNE\nDESCRIPTION: This snippet imports TensorFlow and sets up the AUTOTUNE constant for optimal performance in data pipeline operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n\ntf.__version__\n```\n\nLANGUAGE: python\nCODE:\n```\nAUTOTUNE = tf.data.AUTOTUNE\n```\n\n----------------------------------------\n\nTITLE: Processing Validation Dataset\nDESCRIPTION: Applies the resize_and_rescale function to the validation dataset, including batching and prefetching operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: Python\nCODE:\n```\nval_ds = (\n    val_ds\n    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Running Upgraded Script with TensorFlow 2.x in Bash\nDESCRIPTION: This command runs the upgraded TensorFlow script with TensorFlow 2.x and displays the last few lines of output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n(cd regression_v2 && python custom_regression.py 2>&1) | tail\n```\n\n----------------------------------------\n\nTITLE: Applying Unicode Script to a RaggedTensor\nDESCRIPTION: This code snippet applies the tf.strings.unicode_script operation to a RaggedTensor of code points to determine the scripts of each character.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.strings.unicode_script(batch_chars_ragged))\n```\n\n----------------------------------------\n\nTITLE: Processing Test Dataset\nDESCRIPTION: Applies the resize_and_rescale function to the test dataset, including batching and prefetching operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: Python\nCODE:\n```\ntest_ds = (\n    test_ds\n    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(AUTOTUNE)\n)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow for CPU on Linux and macOS\nDESCRIPTION: This command installs the CPU-only version of TensorFlow using pip, suitable for systems without GPU support.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npip install tensorflow\n```\n\n----------------------------------------\n\nTITLE: Loading TF1 Hub Module in TensorFlow 2 using hub.load\nDESCRIPTION: Shows how to load a TF1 Hub module in TensorFlow 2 using the hub.load function and access its signatures.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nm = hub.load(handle)\noutputs = m.signatures[\"sig\"](inputs)\n```\n\n----------------------------------------\n\nTITLE: Training and evaluating custom Keras model in TensorFlow 2\nDESCRIPTION: Demonstrates how to train the custom Keras model using Model.fit and evaluate it using Model.evaluate in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nmodel.fit(dataset)\n\nmodel.evaluate(eval_dataset, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Representing a Unicode String in TensorFlow using UTF-16 Encoding\nDESCRIPTION: This code shows how to represent a Unicode string as a UTF-16-BE encoded string scalar in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntext_utf16be = tf.constant(u\"语言处理\".encode(\"UTF-16-BE\"))\n```\n\n----------------------------------------\n\nTITLE: Allowing GPU Memory Growth in TensorFlow\nDESCRIPTION: This code segment shows how to configure TensorFlow to allow GPU memory growth, preventing it from pre-allocating all GPU memory. It demonstrates setting the `allow_growth` option in the session configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/using_gpu.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config, ...)\n```\n\n----------------------------------------\n\nTITLE: Creating a Valid Ragged Tensor with Higher Rank\nDESCRIPTION: Demonstrates creating a ragged tensor with a higher rank (3) while maintaining a consistent type (int32).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprint(tf.ragged.constant([[[1, 2], [3]], [[4, 5]]]))        # ok: type=int32, rank=3\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Models repository\nDESCRIPTION: Git command to clone the TensorFlow Models repository from GitHub, which contains the sample code for the Iris classification example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\ngit clone https://github.com/tensorflow/models\n```\n\n----------------------------------------\n\nTITLE: Registering String to Number Conversion Op\nDESCRIPTION: Example of registering an op with explicit output type specification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_28\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"StringToNumber\")\n    .Input(\"string_tensor: string\")\n    .Output(\"output: out_type\")\n    .Attr(\"out_type: {float, int32} = DT_FLOAT\");\n    .Doc(R\"doc(\nConverts each string in the input Tensor to the specified numeric type.\n)doc\");\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning TF2 SavedModel in TensorFlow 2\nDESCRIPTION: Demonstrates how to load and fine-tune a TF2 SavedModel using hub.load in TensorFlow 2, with support for training mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nm = hub.load(handle)\noutputs = m(inputs, training=is_training)\n```\n\n----------------------------------------\n\nTITLE: Unbatching a TensorFlow Dataset of RaggedTensors\nDESCRIPTION: Demonstrates how to transform a batched dataset back into individual elements using the Dataset.unbatch method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nunbatched_dataset = batched_dataset.unbatch()\nprint_dictionary_dataset(unbatched_dataset)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Low Resolution Image for ESRGAN Input\nDESCRIPTION: Displays the downscaled low-resolution image that will be enhanced by ESRGAN.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Plotting Low Resolution Image\nplot_image(tf.squeeze(lr_image), title=\"Low Resolution\")\n```\n\n----------------------------------------\n\nTITLE: NumPy-TensorFlow Compatibility\nDESCRIPTION: Examples of converting between NumPy arrays and TensorFlow tensors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nndarray = np.ones([3, 3])\n\nprint(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\ntensor = tf.math.multiply(ndarray, 42)\nprint(tensor)\n\nprint(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\nprint(np.add(tensor, 1))\n\nprint(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\nprint(tensor.numpy())\n```\n\n----------------------------------------\n\nTITLE: Loading and Using CropNet Classifier\nDESCRIPTION: Loading the pre-trained CropNet classifier from TensorFlow Hub and generating predictions\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclassifier = hub.KerasLayer('https://tfhub.dev/google/cropnet/classifier/cassava_disease_V1/2')\nprobabilities = classifier(examples['image'])\npredictions = tf.argmax(probabilities, axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Nightly Build\nDESCRIPTION: Installing the nightly build of TensorFlow to access the latest features needed for this tutorial, particularly the save_freq argument in callbacks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!pip install tf-nightly\n```\n\n----------------------------------------\n\nTITLE: Viewing TensorFlow 1.0 Sample Code in Bash\nDESCRIPTION: This command displays a portion of a TensorFlow 1.0 script from the cloned models repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhead -n 65 models/samples/cookbook/regression/custom_regression.py | tail -n 10\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow and Dependencies\nDESCRIPTION: Imports required libraries and configures TensorFlow v1 compatibility mode\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport os\nimport io\nimport IPython.display\nimport numpy as np\nimport PIL.Image\nfrom scipy.stats import truncnorm\nimport tensorflow_hub as hub\n```\n\n----------------------------------------\n\nTITLE: Slicing Last Two Values in Each Row\nDESCRIPTION: Demonstrates how to slice a ragged tensor to get the last two values from each row.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(digits[:, -2:])  # Last two values in each row.\n```\n\n----------------------------------------\n\nTITLE: Loading TF1 Hub Module in TensorFlow 2 using hub.KerasLayer\nDESCRIPTION: Demonstrates loading a TF1 Hub module as a Keras layer in TensorFlow 2, specifying the signature to use.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nm = hub.KerasLayer(handle, signature=\"sig\")\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Instantiating and Using a TensorFlow Module\nDESCRIPTION: Shows how to create an instance of a custom tf.Module and execute its method with a tensor input.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nmod = MyModule(3)\nmod.multiply(tf.constant([1, 2, 3]))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Example Input Format\nDESCRIPTION: Demonstrates the format for passing tf.train.Example inputs using dictionary syntax.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n```\n\n----------------------------------------\n\nTITLE: Resetting TF_CONFIG Environment Variable\nDESCRIPTION: Removing any existing TF_CONFIG environment variable to ensure a clean slate before configuring the distributed training environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nos.environ.pop('TF_CONFIG', None)\n```\n\n----------------------------------------\n\nTITLE: Label Mapping Function\nDESCRIPTION: Helper function to map labels to unknown class for non-cassava datasets during evaluation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef label_to_unknown_fn(data):\n  data['label'] = 5  # Override label to unknown.\n  return data\n```\n\n----------------------------------------\n\nTITLE: Training Keras Model with NumPy Arrays\nDESCRIPTION: Demonstrates training a distributed Keras model using NumPy arrays as input data with explicit batch size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\ninputs, targets = np.ones((100, 1)), np.ones((100, 1))\nmodel.fit(inputs, targets, epochs=2, batch_size=10)\n```\n\n----------------------------------------\n\nTITLE: Iterating Over TensorFlow Datasets in Python\nDESCRIPTION: Demonstrates iteration over TensorFlow datasets using Python's native iteration structures, enabled by TensorFlow's eager execution mode.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/eager_basics.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nprint('Elements of ds_tensors:')\nfor x in ds_tensors:\n  print(x)\n\nprint('\\nElements in ds_file:')\nfor x in ds_file:\n  print(x)\n```\n\n----------------------------------------\n\nTITLE: Hashing Tensors in TF1.x Style\nDESCRIPTION: Shows how tensors could be directly used as set elements or dictionary keys in TensorFlow 1.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(0.0)\nset([x, tf.constant(2.0)])\n```\n\n----------------------------------------\n\nTITLE: Attempting to Call a SavedModel Function with Incompatible Signature\nDESCRIPTION: Shows what happens when calling a tf.function with input types that don't match any saved signatures, resulting in a ValueError.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimported(tf.constant([3.]))\n```\n\n----------------------------------------\n\nTITLE: Writing TensorBoard Summaries in TensorFlow\nDESCRIPTION: This snippet shows how to write summary events for TensorBoard visualization in TensorFlow. It creates a file writer, sets it as default, and then writes scalar summaries for a global step variable in a loop.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom tensorflow.compat.v2 import summary\n\nglobal_step = tf.train.get_or_create_global_step()\n\nlogdir = \"./tb/\"\nwriter = summary.create_file_writer(logdir)\nwriter.set_as_default()\n\nfor _ in range(10):\n  global_step.assign_add(1)\n  # your model code goes here\n  summary.scalar('global_step', global_step, step=global_step)\n```\n\n----------------------------------------\n\nTITLE: Creating Embedding Layer\nDESCRIPTION: Loading exported embeddings as a Keras layer using TF-Hub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodule_path = \"text_module\"\nembedding_layer = hub.KerasLayer(module_path, trainable=False)\n```\n\n----------------------------------------\n\nTITLE: First Call to tf.function with ExtensionType in Python\nDESCRIPTION: Demonstrates the first call to a tf.function with an ExtensionType parameter, which causes function tracing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/extension_type.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Function gets traced (first time the function has been called):\nanonymize_player(Player(\"Anne\", {\"height\": 8.3, \"speed\": 28.1}))\n```\n\n----------------------------------------\n\nTITLE: Hashed Feature Column Example in TensorFlow\nDESCRIPTION: Demonstrates hash bucket based feature column creation for handling large numbers of categories.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/feature_columns.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhashed_feature_column = tf.feature_column.categorical_column_with_hash_bucket(\n    key = \"some_feature\",\n    hash_bucket_size = 100) # The number of categories\n```\n\n----------------------------------------\n\nTITLE: SavedModel Directory Structure\nDESCRIPTION: Shows the standard directory structure created when saving a model in SavedModel format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\nassets/\nassets.extra/\nvariables/\n    variables.data-?????-of-?????\n    variables.index\nsaved_model.pb|saved_model.pbtxt\n```\n\n----------------------------------------\n\nTITLE: Registering TensorFlow Op with String Enum Constraint\nDESCRIPTION: Example of registering a TensorFlow op with an enum-like string attribute constraint that must be either 'apple' or 'orange'.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_15\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"EnumExample\")\n    .Attr(\"e: {'apple', 'orange'}\");\n```\n\n----------------------------------------\n\nTITLE: Setting up imports and dataset for TensorFlow migration example\nDESCRIPTION: Imports TensorFlow libraries and sets up a simple dataset for demonstrating the migration from Estimator to Keras APIs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_estimator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\nfeatures = [[1., 1.5], [2., 2.5], [3., 3.5]]\nlabels = [[0.3], [0.5], [0.7]]\neval_features = [[4., 4.5], [5., 5.5], [6., 6.5]]\neval_labels = [[0.8], [0.9], [1.]]\n```\n\n----------------------------------------\n\nTITLE: Feeding Values to Placeholders in TensorFlow\nDESCRIPTION: Shows how to provide values to placeholders during session execution using the feed_dict parameter. Demonstrates feeding both scalar values and arrays to compute results dynamically.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(sess.run(z, feed_dict={x: 3, y: 4.5}))\nprint(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))\n```\n\n----------------------------------------\n\nTITLE: Displaying Array as Image in Python\nDESCRIPTION: Defines a function that takes a NumPy array, normalizes it, and displays it as an image. It uses PIL for image creation and IPython display for rendering the output in a Jupyter notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/non-ml/pdes.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\n  \"\"\"Display an array as a picture.\"\"\"\n  a = (a - rng[0])/float(rng[1] - rng[0])*255\n  a = np.uint8(np.clip(a, 0, 255))\n  f = BytesIO()\n  PIL.Image.fromarray(a).save(f, fmt)\n  clear_output(wait = True)\n  display(Image(data=f.getvalue()))\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Fourier Transform Functions for Kernel Reparameterization\nDESCRIPTION: Defines functions to convert convolutional kernels to and from the real-valued discrete Fourier transform (RDFT) domain. This reparameterization makes convolutional kernels more compressible by separating frequency components.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef to_rdft(kernel, kernel_size):\n  # The kernel has shape (H, W, I, O) -> transpose to take DFT over last two\n  # dimensions.\n  kernel = tf.transpose(kernel, (2, 3, 0, 1))\n  # The RDFT has type complex64 and shape (I, O, FH, FW).\n  kernel_rdft = tf.signal.rfft2d(kernel)\n  # Map real and imaginary parts into regular floats. The result is float32\n  # and has shape (I, O, FH, FW, 2).\n  kernel_rdft = tf.stack(\n      [tf.math.real(kernel_rdft), tf.math.imag(kernel_rdft)], axis=-1)\n  # Divide by kernel size to make the DFT orthonormal (length-preserving).\n  return kernel_rdft / kernel_size\n\ndef from_rdft(kernel_rdft, kernel_size):\n  # Undoes the transformations in to_rdft.\n  kernel_rdft *= kernel_size\n  kernel_rdft = tf.dtypes.complex(*tf.unstack(kernel_rdft, axis=-1))\n  kernel = tf.signal.irfft2d(kernel_rdft, fft_length=2 * (kernel_size,))\n  return tf.transpose(kernel, (2, 3, 0, 1))\n```\n\n----------------------------------------\n\nTITLE: Running Test Function with Constant Folding Disabled\nDESCRIPTION: This code executes the test function with constant folding optimization turned off, measuring and displaying the execution time without optimization.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith options({'constant_folding': False}):\n  print(tf.config.optimizer.get_experimental_options())\n  simple_function = test_function_1()\n  # Trace once\n  x = tf.constant(2.2)\n  simple_function(x)\n  print(\"Vanilla execution:\", timeit.timeit(lambda: simple_function(x), number = 1), \"s\")\n```\n\n----------------------------------------\n\nTITLE: Creating DNNClassifier without Model Directory\nDESCRIPTION: Instantiates a DNNClassifier without specifying a model directory, resulting in automatic temporary directory creation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    hidden_units=[10, 10],\n    n_classes=3)\n\nprint(classifier.model_dir)\n```\n\n----------------------------------------\n\nTITLE: Initializing Checkpoint System in TensorFlow 2\nDESCRIPTION: Sets up the model, optimizer, loss function and creates checkpoint management objects. Uses tf.train.Checkpoint to track model and optimizer states, and tf.train.CheckpointManager to handle checkpoint storage and rotation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/fault_tolerance.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmodel = create_model()\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nlog_dir = tempfile.mkdtemp()\nepochs = 5\nsteps_per_epoch = 5\n\ncheckpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\ncheckpoint_manager = tf.train.CheckpointManager(\n            checkpoint, log_dir, max_to_keep=2)\n```\n\n----------------------------------------\n\nTITLE: Training Initial Model Configuration\nDESCRIPTION: Creates and trains a DNNClassifier with initial model architecture.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[10, 10],\n    n_classes=3,\n    model_dir='models/iris')\n\nclassifier.train(\n    input_fn=lambda:train_input_fn(train_x, train_y, batch_size=100),\n        steps=200)\n```\n\n----------------------------------------\n\nTITLE: Viewing DeepLab Upgrade Errors in Bash\nDESCRIPTION: This command displays the first three errors from the DeepLab upgrade report.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncat deeplab_report.txt | grep -i models/research/deeplab | grep -i error | head -n 3\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and Matplotlib for Automatic Differentiation Examples\nDESCRIPTION: Imports TensorFlow and configures Matplotlib for displaying visualizations with a specific figure size.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.rcParams['figure.figsize'] = (8, 6)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Datasets Library\nDESCRIPTION: Command to install the TensorFlow Datasets library, which is required for loading the CIFAR-10 dataset\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/deep_cnn.md#2025-04-21_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\npip install tensorflow-datasets\n```\n\n----------------------------------------\n\nTITLE: Processing TextLineDataset in TensorFlow\nDESCRIPTION: This snippet demonstrates how to iterate over the TextLineDataset and print the first few lines.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nfor line in dataset.take(5):\n  print(line.numpy())\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Code Block in Python\nDESCRIPTION: Standard Apache License 2.0 notification included as a Python comment block at the beginning of the tutorial file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/keras_model_to_estimator.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Visualizing Original Input Image for ESRGAN\nDESCRIPTION: Displays the original image before super resolution and saves it to disk.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Plotting Original Resolution image\nplot_image(tf.squeeze(hr_image), title=\"Original Image\")\nsave_image(tf.squeeze(hr_image), filename=\"Original Image\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Available Checkpoints\nDESCRIPTION: Prints the list of available checkpoints managed by the CheckpointManager, showing the three most recent checkpoints as specified in the manager configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(manager.checkpoints)  # List the three remaining checkpoints\n```\n\n----------------------------------------\n\nTITLE: Compiling protobuf files for developer installation\nDESCRIPTION: Command to compile .proto files into _pb2.py files for developer installation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nprotoc -I=tensorflow_hub --python_out=tensorflow_hub tensorflow_hub/*.proto\n```\n\n----------------------------------------\n\nTITLE: Adding Two Ragged Tensors Together\nDESCRIPTION: Demonstrates how to add two ragged tensors with matching shapes using the + operator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(digits + tf.ragged.constant([[1, 2, 3, 4], [], [5, 6, 7], [8], []]))\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Keras Model\nDESCRIPTION: Demonstrates creating a simple sequential neural network model with dense layers using Keras\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Build the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation='relu', input_shape=(None, 5)),\n    tf.keras.layers.Dense(3)\n])\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Text Dependencies\nDESCRIPTION: Command to install the TensorFlow Text package which is required for working with text in TensorFlow models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wiki40b_lm.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title Installing Dependencies\n!pip install --quiet \"tensorflow-text==2.11.*\"\n\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip in Python Virtual Environment\nDESCRIPTION: This command upgrades pip to the latest version within the active virtual environment, ensuring compatibility with TensorFlow installation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Evaluating a TF2 Keras Model\nDESCRIPTION: Evaluating the Keras model on the evaluation dataset and returning results as a dictionary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.evaluate(eval_dataset, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Forcing Variable Value Re-read\nDESCRIPTION: Demonstrates how to force a re-read of a variable's value using read_value().\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nassignment = v.assign_add(1)\nwith tf.control_dependencies([assignment]):\n  w = v.read_value()  # w is guaranteed to reflect v's value after the\n                      # assign_add operation.\n```\n\n----------------------------------------\n\nTITLE: Listing Output Directory Contents in Python\nDESCRIPTION: Lists the contents of the output directory where embeddings were saved.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n!ls {output_dir}\n```\n\n----------------------------------------\n\nTITLE: Registering a Non-Polymorphic TensorFlow Op in C++\nDESCRIPTION: Example of registering a basic, non-polymorphic TensorFlow operation that takes a float input and produces a float output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_36\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_OP(\"MyGeneralUnaryOp\")\n    .Input(\"in: float\")\n    .Output(\"out: float\");\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Docs Repository\nDESCRIPTION: This snippet shows how to clone your forked copy of the TensorFlow docs repository to your local machine.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<var>username</var>/docs\ncd ./docs\n```\n\n----------------------------------------\n\nTITLE: Managing Conda Environment for TensorFlow on Windows\nDESCRIPTION: These commands demonstrate how to deactivate and activate the 'tf' Conda environment on Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nconda deactivate\\nconda activate tf\n```\n\n----------------------------------------\n\nTITLE: Verifying NVIDIA GPU Driver Installation on Linux\nDESCRIPTION: This command checks if the NVIDIA GPU driver is installed correctly on a Linux system by displaying GPU information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnvidia-smi\n```\n\n----------------------------------------\n\nTITLE: Using a Layer for Forward Pass\nDESCRIPTION: Shows how to use a layer by calling it with input tensors to perform a forward pass computation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# To use a layer, simply call it.\nlayer(tf.zeros([10, 5]))\n```\n\n----------------------------------------\n\nTITLE: Using NumberOrBooleanType Op in Python\nDESCRIPTION: Python examples demonstrating valid and invalid uses of the NumberOrBooleanType op.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ntf.number_or_boolean_type(t=tf.int32)  # Valid\ntf.number_or_boolean_type(t=tf.bool)   # Valid\ntf.number_or_boolean_type(t=tf.string) # Invalid\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Importing necessary Python libraries including TensorFlow, TensorFlow Hub, and visualization packages\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport tensorflow_hub as hub\n```\n\n----------------------------------------\n\nTITLE: Defining a Function for Automatic Differentiation\nDESCRIPTION: Sets up a quadratic function using a TensorFlow Variable as input for gradient calculation demonstration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nx = tf.Variable(1.0)\n\ndef f(x):\n  y = x**2 + 2*x - 5\n  return y\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Constant with Unicode String\nDESCRIPTION: This snippet shows how to create a constant TensorFlow tensor from a Unicode string using UTF-8 encoding.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntf.constant(u\"Thanks 😊\")\n```\n\n----------------------------------------\n\nTITLE: Non-Deterministic Generator Creation\nDESCRIPTION: Creating a random number generator with a non-deterministic state based on system time and OS.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ng = tf.random.Generator.from_non_deterministic_state()\nprint(g.normal(shape=[2, 3]))\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Related Libraries\nDESCRIPTION: Import TensorFlow, TensorFlow Datasets, and the os module for file operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\nimport tensorflow_datasets as tfds\nimport os\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow and Matplotlib for Basic Training Loops\nDESCRIPTION: Imports TensorFlow and Matplotlib libraries and configures color settings for visualizations in the notebook.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basic_training_loops.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\n\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies and Configuration\nDESCRIPTION: Setup of required TensorFlow modules and Wav2Vec2 configuration\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom wav2vec2 import Wav2Vec2Config\n\nconfig = Wav2Vec2Config()\n\nprint(\"TF version:\", tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Registering Custom Filesystem in C++\nDESCRIPTION: This snippet shows how to register a custom filesystem implementation with TensorFlow using the REGISTER_FILE_SYSTEM macro.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_2\n\nLANGUAGE: C++\nCODE:\n```\nREGISTER_FILE_SYSTEM(\"foobar\", FooBarFileSystem);\n```\n\n----------------------------------------\n\nTITLE: Instantiating the TensorFlow Model\nDESCRIPTION: Creates an instance of the Net model defined above which will be used for demonstrating checkpoint operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nnet = Net()\n```\n\n----------------------------------------\n\nTITLE: Defining Test Images Map in Python\nDESCRIPTION: This snippet creates a dictionary mapping image names to their corresponding URLs for testing the image classification models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimages_for_test_map = {\n    \"tiger\": \"https://upload.wikimedia.org/wikipedia/commons/b/b0/Bengal_tiger_%28Panthera_tigris_tigris%29_female_3_crop.jpg\",\n    \"bus\": \"https://upload.wikimedia.org/wikipedia/commons/6/63/LT_471_%28LTZ_1471%29_Arriva_London_New_Routemaster_%2819522859218%29.jpg\",\n    \"car\": \"https://upload.wikimedia.org/wikipedia/commons/4/49/2013-2016_Toyota_Corolla_%28ZRE172R%29_SX_sedan_%282018-09-17%29_01.jpg\",\n    \"cat\": \"https://upload.wikimedia.org/wikipedia/commons/4/4d/Cat_November_2010-1a.jpg\",\n    \"dog\": \"https://upload.wikimedia.org/wikipedia/commons/archive/a/a9/20090914031557%21Saluki_dog_breed.jpg\",\n    \"apple\": \"https://upload.wikimedia.org/wikipedia/commons/1/15/Red_Apple.jpg\",\n    \"banana\": \"https://upload.wikimedia.org/wikipedia/commons/1/1c/Bananas_white_background.jpg\",\n    \"turtle\": \"https://upload.wikimedia.org/wikipedia/commons/8/80/Turtle_golfina_escobilla_oaxaca_mexico_claudio_giovenzana_2010.jpg\",\n    \"flamingo\": \"https://upload.wikimedia.org/wikipedia/commons/b/b8/James_Flamingos_MC.jpg\",\n    \"piano\": \"https://upload.wikimedia.org/wikipedia/commons/d/da/Steinway_%26_Sons_upright_piano%2C_model_K-132%2C_manufactured_at_Steinway%27s_factory_in_Hamburg%2C_Germany.png\",\n    \"honeycomb\": \"https://upload.wikimedia.org/wikipedia/commons/f/f7/Honey_comb.jpg\",\n    \"teapot\": \"https://upload.wikimedia.org/wikipedia/commons/4/44/Black_tea_pot_cropped.jpg\",\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping Resampled Dataset in TensorFlow\nDESCRIPTION: Maps the resampled dataset to remove extra labels from the rejection_resample output\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_80\n\nLANGUAGE: python\nCODE:\n```\nbalanced_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)\n```\n\n----------------------------------------\n\nTITLE: Creating and activating a virtual environment\nDESCRIPTION: Commands to create a new virtual environment for TensorFlow Hub and activate it in different shells.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nvirtualenv --system-site-packages tensorflow_hub_env\n```\n\nLANGUAGE: shell\nCODE:\n```\nsource ~/tensorflow_hub_env/bin/activate  # bash, sh, ksh, or zsh\n```\n\nLANGUAGE: shell\nCODE:\n```\nsource ~/tensorflow_hub_env/bin/activate.csh  # csh or tcsh\n```\n\n----------------------------------------\n\nTITLE: Loading Saved TensorFlow Model for Inference\nDESCRIPTION: This snippet loads a previously saved TensorFlow model for inference using keras.models.load_model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfinetuned_model = tf.keras.models.load_model(save_dir)\n```\n\n----------------------------------------\n\nTITLE: Running the TensorFlow Iris classification program\nDESCRIPTION: Command to execute the Python script that demonstrates the use of premade Estimators for Iris classification in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\npython premade_estimator.py\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Text Package\nDESCRIPTION: Installs the TensorFlow Text package with a specific version to ensure compatibility with the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bert_experts.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install --quiet \"tensorflow-text==2.11.*\"\n```\n\n----------------------------------------\n\nTITLE: Plotting ND Arrays with Histogram\nDESCRIPTION: Shows how to create a histogram using TensorFlow NumPy's random functionality with matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nlabels = 15 + 2 * tnp.random.randn(1, 1000)\n_ = plt.hist(labels)\n```\n\n----------------------------------------\n\nTITLE: Creating Independent Random Number Streams\nDESCRIPTION: Using Generator.split() to create multiple independent random number streams.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ng = tf.random.Generator.from_seed(1)\nprint(g.normal([]))\nnew_gs = g.split(3)\nfor new_g in new_gs:\n  print(new_g.normal([]))\nprint(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Metrics to TF1 Estimator\nDESCRIPTION: Demonstrating how to add custom metrics to an estimator using tf.estimator.add_metrics() with a mean squared error metric function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/metrics_optimizers.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef mean_squared_error(labels, predictions):\n  labels = tf.cast(labels, predictions.dtype)\n  return {\"mean_squared_error\": \n          tf1.metrics.mean_squared_error(labels=labels, predictions=predictions)}\n\nestimator = tf1.estimator.add_metrics(estimator, mean_squared_error)\nestimator.evaluate(_eval_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Initializing TPU for TPUStrategy in TensorFlow 2\nDESCRIPTION: Sets up TPUClusterResolver and initializes the TPU system for use with TPUStrategy in TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_estimator.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(cluster_resolver)\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and Checking Version\nDESCRIPTION: Imports the necessary TensorFlow modules and prints the TensorFlow version. This code sets up the environment for the tutorial.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.version.VERSION)\n```\n\n----------------------------------------\n\nTITLE: Configuring NCCL Communication in MultiWorkerMirroredStrategy\nDESCRIPTION: Example of how to configure the communication protocol for MultiWorkerMirroredStrategy to use NCCL for collective operations. This is particularly useful when working with NVIDIA GPUs in a distributed environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_estimator.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncommunication=tf.distribute.experimental.CollectiveCommunication.NCCL\n```\n\n----------------------------------------\n\nTITLE: Calculating Jacobian for Scalar Source in TensorFlow\nDESCRIPTION: This snippet demonstrates how to calculate the Jacobian of a vector-target with respect to a scalar-source using TensorFlow's GradientTape. It applies the sigmoid function to a range of values and computes the Jacobian.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/advanced_autodiff.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nx = tf.linspace(-10.0, 10.0, 200+1)\ndelta = tf.Variable(0.0)\n\nwith tf.GradientTape() as tape:\n  y = tf.nn.sigmoid(x+delta)\n\ndy_dx = tape.jacobian(y, delta)\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Transform Preprocessing Function\nDESCRIPTION: Creates a preprocessing function compatible with TensorFlow Transform that generates embeddings for input text data.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef make_preprocess_fn(module_url, random_projection_matrix=None):\n  '''Makes a tft preprocess_fn'''\n\n  def _preprocess_fn(input_features):\n    '''tft preprocess_fn'''\n    text = input_features['text']\n    # Generate the embedding for the input text\n    embedding = embed_text(text, module_url, random_projection_matrix)\n    \n    output_features = {\n        'text': text, \n        'embedding': embedding\n        }\n        \n    return output_features\n  \n  return _preprocess_fn\n```\n\n----------------------------------------\n\nTITLE: Converting TensorFlow 1 Keras Model to TFLite Model in TF2\nDESCRIPTION: This snippet shows how to convert a TensorFlow 1 Keras model file to a TFLite model using TensorFlow 2. It first converts the TF1 Keras model to a TF2 SavedModel, then uses the TF2 converter to create a TFLite model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tflite.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Convert TF1 Keras model file to TF2 SavedModel.\nmodel = tf.keras.models.load_model(KERAS_MODEL_PATH)\nmodel.save(filepath='saved_model_2/')\n\n# Convert TF2 SavedModel to a TFLite model.\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_2/')\ntflite_model = converter.convert()\n```\n\n----------------------------------------\n\nTITLE: Instantiating TPUStrategy for Tensor Processing Units\nDESCRIPTION: Code to create a TPUStrategy instance for running TensorFlow training on TPUs. This requires resolving the TPU cluster, connecting to it, and initializing the TPU system before creating the strategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n    tpu=tpu_address)\ntf.config.experimental_connect_to_cluster(cluster_resolver)\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\ntpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n```\n\n----------------------------------------\n\nTITLE: Solution: Initialize Outside tf.function\nDESCRIPTION: Example showing the proper way to handle both dataset and variable creation by moving initialization outside tf.function.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = None\n    self.dataset = None\n\n  def initialize(self):\n    if self.dataset is None:\n      self.dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n    if self.v is None:\n      self.v = tf.Variable(0)\n\n  @tf.function\n  def __call__(self):\n    it = iter(self.dataset)\n    return [self.v, next(it)]\n\nm = Model()\nm.initialize()\nm()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimized Timeline in TensorFlow Benchmark\nDESCRIPTION: Calls the draw_timeline function to create a visualization of the optimized pipeline's execution timeline with a width of 15 units.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndraw_timeline(optimized_timeline, \"Optimized\", 15)\n```\n\n----------------------------------------\n\nTITLE: Saving TensorFlow Model for Deployment\nDESCRIPTION: Saves the trained flower classification model to disk in the SavedModel format, which can be used for deployment to TensorFlow Serving or conversion to TensorFlow Lite.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsaved_model_path = f\"/tmp/saved_flowers_model_{model_name}\"\ntf.saved_model.save(model, saved_model_path)\n```\n\n----------------------------------------\n\nTITLE: Cloning TensorFlow Hub repository\nDESCRIPTION: Git commands to clone the TensorFlow Hub repository and navigate to the project directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tensorflow/hub\n```\n\nLANGUAGE: shell\nCODE:\n```\ncd hub\n```\n\n----------------------------------------\n\nTITLE: Loading Selected Model from TensorFlow Hub\nDESCRIPTION: This code loads the selected object detection model from TensorFlow Hub using the model handle.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint('loading model...')\nhub_model = hub.load(model_handle)\nprint('model loaded!')\n```\n\n----------------------------------------\n\nTITLE: Locating Generated TensorFlow Wheel Package\nDESCRIPTION: Path where the generated TensorFlow wheel package is located after a successful build.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nbazel-bin/tensorflow/tools/pip_package/wheel_house/\n```\n\n----------------------------------------\n\nTITLE: Creating Data Loading Functions\nDESCRIPTION: Helper functions for loading and processing the dataset files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef load_file(path, label):\n    return tf.io.read_file(path), label\n```\n\nLANGUAGE: python\nCODE:\n```\ndef make_datasets(train_size):\n  batch_size = 256\n\n  train_files = file_paths[:train_size]\n  train_labels = labels[:train_size]\n  train_ds = tf.data.Dataset.from_tensor_slices((train_files, train_labels))\n  train_ds = train_ds.map(load_file).shuffle(5000)\n  train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n  test_files = file_paths[train_size:]\n  test_labels = labels[train_size:]\n  test_ds = tf.data.Dataset.from_tensor_slices((test_files, test_labels))\n  test_ds = test_ds.map(load_file)\n  test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n\n  return train_ds, test_ds\n```\n\n----------------------------------------\n\nTITLE: Defining Mean Squared Error Loss Function in TensorFlow\nDESCRIPTION: Implements the Mean Squared Error (MSE) loss function for model evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ndef mse_loss(y_pred, y):\n  return tf.reduce_mean(tf.square(y_pred - y))\n```\n\n----------------------------------------\n\nTITLE: Installing pandas dependency for TensorFlow\nDESCRIPTION: Command to install or upgrade the pandas library, which is a prerequisite for the sample code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\npip install pandas\n```\n\n----------------------------------------\n\nTITLE: Deactivating the virtual environment\nDESCRIPTION: Command to deactivate the virtual environment after finishing work with TensorFlow Hub.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ndeactivate\n```\n\n----------------------------------------\n\nTITLE: Plotting Keras Model Predictions After Training\nDESCRIPTION: Visualizes the performance of the trained Keras model on the original dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nplot_preds(x, y, f, new_model, 'After Training: Keras')\n```\n\n----------------------------------------\n\nTITLE: Training the Model with MirroredStrategy\nDESCRIPTION: Train the model using the fit method with the prepared dataset and callbacks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(train_dataset, epochs=10, callbacks=callbacks)\n```\n\n----------------------------------------\n\nTITLE: Creating MirroredStrategy for Distributed Training\nDESCRIPTION: Initialize a MirroredStrategy object for synchronous training across multiple GPUs on a single machine.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/keras.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow Import\nDESCRIPTION: Basic import statement to include TensorFlow library for the examples in this guide.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Initialize MirroredStrategy\nDESCRIPTION: Creates a MirroredStrategy instance for synchronous training across multiple GPUs on a single machine\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\n```\n\n----------------------------------------\n\nTITLE: GPU Device Detection\nDESCRIPTION: Checking GPU availability and tensor device placement\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nx = tf.random.uniform([3, 3])\n\nprint(\"Is there a GPU available: \"),\nprint(tf.config.list_physical_devices(\"GPU\"))\n\nprint(\"Is the Tensor on GPU #0:  \"),\nprint(x.device.endswith('GPU:0'))\n```\n\n----------------------------------------\n\nTITLE: MultiWorkerMirroredStrategy with NCCL\nDESCRIPTION: Creates a MultiWorkerMirroredStrategy instance using NCCL for collective communications\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmultiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n    tf.distribute.experimental.CollectiveCommunication.NCCL)\n```\n\n----------------------------------------\n\nTITLE: Using Arithmetic Operations with Ragged Tensors\nDESCRIPTION: Shows how to use Python arithmetic operators with ragged tensors to perform elementwise addition.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(digits + 3)\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Notes in Python\nDESCRIPTION: Shows the first 10 rows of the generated notes DataFrame to inspect the prediction results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/music_generation.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ngenerated_notes.head(10)\n```\n\n----------------------------------------\n\nTITLE: Loading TF2 SavedModel in TensorFlow 1.15 or 2 using hub.load\nDESCRIPTION: Demonstrates loading a TF2 SavedModel for inference using hub.load in TensorFlow 1.15 or TensorFlow 2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/model_compatibility.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nm = hub.load(handle)\noutputs = m(inputs)\n```\n\n----------------------------------------\n\nTITLE: Dataset Transformations\nDESCRIPTION: Applying transformations to datasets using map, shuffle, and batch operations\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)\n\nds_file = ds_file.batch(2)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installation of required Python packages h5py and pyyaml for model saving functionality\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/save_and_restore_models.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip install h5py pyyaml\n```\n\n----------------------------------------\n\nTITLE: Type Inference in TensorFlow NumPy Array Creation\nDESCRIPTION: Demonstrates how TensorFlow NumPy infers data types when creating arrays from literals, preferring wider types like int64 and float64 by default, similar to NumPy's behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Type inference during array creation\")\nprint(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype.name)\nprint(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype.name)\n```\n\n----------------------------------------\n\nTITLE: MirroredStrategy with Specific Devices\nDESCRIPTION: Creates a MirroredStrategy instance using specified GPU devices\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n```\n\n----------------------------------------\n\nTITLE: Defining Class Names in Python\nDESCRIPTION: Creating a list of Iris species class names for label mapping.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n```\n\n----------------------------------------\n\nTITLE: Matrix Multiplication with Transpose\nDESCRIPTION: Shows matrix multiplication between a tensor and its transpose using the @ operator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx @ tf.transpose(x)\n```\n\n----------------------------------------\n\nTITLE: Creating Probability Model\nDESCRIPTION: Wraps trained model with softmax layer to output probabilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\n```\n\n----------------------------------------\n\nTITLE: Pip Installation Permission Error\nDESCRIPTION: Error message when pip install fails due to permission issues\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nOSError: [Errno 1] Operation not permitted\n```\n\n----------------------------------------\n\nTITLE: Timing Standard CSV Dataset Processing\nDESCRIPTION: Times the processing of 20 batches from the standard CSV dataset to establish a performance baseline. This code uses Jupyter's %%time magic for timing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_59\n\nLANGUAGE: python\nCODE:\n```\n%%time\nfor i,batch in enumerate(fonts_ds.take(20)):\n  print('.',end='')\n\nprint()\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow with CUDA Support on Linux\nDESCRIPTION: Commands to install TensorFlow with CUDA support on Linux and verify the GPU installation. This installs the tensorflow[and-cuda] package which includes GPU support.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install 'tensorflow[and-cuda]'\n# Verify the installation:\npython3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Preprocessing and Class Prediction Functions\nDESCRIPTION: Defines two helper functions: one for preprocessing raw MNIST data (reshaping and normalizing) and another for converting model outputs to class predictions using softmax and argmax.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_test(x):\n  # The export module takes in unprocessed and unlabeled data\n  x = tf.reshape(x, shape=[-1, 784])\n  x = x/255\n  return x\n\ndef class_pred_test(y):\n  # Generate class predictions from MLP output\n  return tf.argmax(tf.nn.softmax(y), axis=1)\n```\n\n----------------------------------------\n\nTITLE: Initializing DNNClassifier with Model Directory\nDESCRIPTION: Creates a DNNClassifier with specified model directory for checkpoint storage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    hidden_units=[10, 10],\n    n_classes=3,\n    model_dir='models/iris')\n```\n\n----------------------------------------\n\nTITLE: Preprocessing with MirroredStrategy in Custom Training Loop\nDESCRIPTION: Complete example of implementing preprocessing layers with a custom training loop using MirroredStrategy. The StringLookup layer is created within strategy scope, and a dataset function is defined to properly shard and batch the data before applying the preprocessing layer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nstrategy = tf.distribute.MirroredStrategy()\nvocab = [\"a\", \"b\", \"c\", \"d\", \"f\"]\n\nwith strategy.scope():\n  # Create the layer(s) under scope.\n  layer = tf.keras.layers.StringLookup(vocabulary=vocab)\n\ndef dataset_fn(input_context):\n  # a tf.data.Dataset\n  dataset = tf.data.Dataset.from_tensor_slices([\"a\", \"c\", \"e\"]).repeat()\n\n  # Custom your batching, sharding, prefetching, etc.\n  global_batch_size = 4\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  dataset = dataset.batch(batch_size)\n  dataset = dataset.shard(\n      input_context.num_input_pipelines,\n      input_context.input_pipeline_id)\n\n  # Apply the preprocessing layer(s) to the tf.data.Dataset\n  def preprocess_with_kpl(input):\n    return layer(input)\n\n  processed_ds = dataset.map(preprocess_with_kpl)\n  return processed_ds\n\ndistributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n\n# Print out a few example batches.\ndistributed_dataset_iterator = iter(distributed_dataset)\nfor _ in range(3):\n  print(next(distributed_dataset_iterator))\n```\n\n----------------------------------------\n\nTITLE: Setting Up TF_CONFIG for ParameterServerStrategy in TensorFlow 2\nDESCRIPTION: Configures TF_CONFIG for ParameterServerStrategy, setting up an in-process cluster with threads simulating parameter servers and workers.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/multi_worker_cpu_gpu_training.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport portpicker\n\nchief_port = portpicker.pick_unused_port()\nworker_ports = [portpicker.pick_unused_port() for _ in range(3)]\nps_ports = [portpicker.pick_unused_port() for _ in range(2)]\n\ntf_config = {\n    'cluster': {\n        'chief': [\"localhost:%s\" % chief_port],\n        'worker': [\"localhost:%s\" % port for port in worker_ports],\n        'ps':  [\"localhost:%s\" % port for port in ps_ports],\n    },\n    'task': {'type': 'chief', 'index': 0}\n}\nos.environ['TF_CONFIG'] = json.dumps(tf_config)\n\ncluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n```\n\n----------------------------------------\n\nTITLE: Testing Mutation Support in TensorFlow NumPy\nDESCRIPTION: Demonstrates that TensorFlow NumPy currently does not support array mutation operations, unlike standard NumPy which allows in-place modification of array elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Mutation is currently not supported\ntry:\n  tnp.arange(6)[1] = -1\nexcept TypeError:\n  print(\"Currently, TensorFlow NumPy does not support mutation.\")\n```\n\n----------------------------------------\n\nTITLE: Enabling Eager Execution in TensorFlow\nDESCRIPTION: This snippet shows how to import TensorFlow and enable eager execution mode. Eager execution allows for immediate evaluation of operations without building a computational graph.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/eager.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Problematic TF2 Usage of NoiseAdder with Frozen Noise\nDESCRIPTION: In TF2 eager execution, this code initializes noise_adder once, causing the noise_distribution to be computed only once and remain frozen for all training steps.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n...\n# initialize all variable-containing objects\nnoise_adder = NoiseAdder(shape, mean) # Freezes `self.noise_distribution`!\n...\n# computation pass\nx_with_noise = noise_adder.add_noise(x)\n...\n```\n\n----------------------------------------\n\nTITLE: Visualizing and Saving Super Resolution Image Result\nDESCRIPTION: Displays the enhanced super resolution image and saves it to disk for comparison with the original.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_enhancing.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Plotting Super Resolution Image\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\nsave_image(tf.squeeze(fake_image), filename=\"Super Resolution\")\n```\n\n----------------------------------------\n\nTITLE: Computing NCE Loss for Skip-gram Model in Python\nDESCRIPTION: Calculates the noise-contrastive estimation loss, which is used to train the skip-gram model. This loss function helps discriminate real context words from noise words.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Compute the NCE loss, using a sample of the negative labels each time.\nloss = tf.reduce_mean(\n  tf.nn.nce_loss(weights=nce_weights,\n                 biases=nce_biases,\n                 labels=train_labels,\n                 inputs=embed,\n                 num_sampled=num_sampled,\n                 num_classes=vocabulary_size))\n```\n\n----------------------------------------\n\nTITLE: Creating Testing Data Grid for Model Evaluation\nDESCRIPTION: Creates a mesh grid over the 2D input space to evaluate model predictions across the entire domain. This allows visualization of decision boundaries and uncertainty estimates throughout the feature space.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/understanding/sngp.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef make_testing_data(x_range=DEFAULT_X_RANGE, y_range=DEFAULT_Y_RANGE, n_grid=DEFAULT_N_GRID):\n  \"\"\"Create a mesh grid in 2D space.\"\"\"\n  # testing data (mesh grid over data space)\n  x = np.linspace(x_range[0], x_range[1], n_grid)\n  y = np.linspace(y_range[0], y_range[1], n_grid)\n  xv, yv = np.meshgrid(x, y)\n  return np.stack([xv.flatten(), yv.flatten()], axis=-1)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Layers in ResNet Block\nDESCRIPTION: Accesses the layers property of the ResNet block to display all layers contained within the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nblock.layers\n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow Hub Model\nDESCRIPTION: Loads the video inbetweening model from TensorFlow Hub\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tweening_conv3d.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nhub_handle = 'https://tfhub.dev/google/tweening_conv3d_bair/1'\nmodule = hub.load(hub_handle).signatures['default']\n```\n\n----------------------------------------\n\nTITLE: Installing Required Matplotlib Package\nDESCRIPTION: Installing a specific version of matplotlib package required for visualization\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install matplotlib==3.2.2\n```\n\n----------------------------------------\n\nTITLE: Installing virtualenv on Linux\nDESCRIPTION: Command to install virtualenv using apt-get on a Linux system.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt-get install python-virtualenv\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow for CPU\nDESCRIPTION: Pip command to install TensorFlow CPU-only version for systems without GPU support\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\npip install tensorflow\n```\n\n----------------------------------------\n\nTITLE: Converting Python List to Tensor\nDESCRIPTION: Shows how to explicitly convert a Python list to a TensorFlow tensor using tf.convert_to_tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntf.convert_to_tensor([1,2,3])\n```\n\n----------------------------------------\n\nTITLE: Defining Loss Function\nDESCRIPTION: Creates sparse categorical crossentropy loss function for training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Hub tests\nDESCRIPTION: Bazel command to run all TensorFlow Hub tests.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/build_from_source.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nbazel test tensorflow_hub:all\n```\n\n----------------------------------------\n\nTITLE: Creating Non-Trainable Variable\nDESCRIPTION: Creates a non-trainable variable using the trainable parameter.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n```\n\n----------------------------------------\n\nTITLE: Device Placement for Variables\nDESCRIPTION: Places a variable on a specific GPU device.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith tf.device(\"/device:GPU:1\"):\n  v = tf.get_variable(\"v\", [1])\n```\n\n----------------------------------------\n\nTITLE: Loading Cassava Dataset\nDESCRIPTION: Loading the cassava dataset from TensorFlow Datasets\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cropnet_cassava.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndataset, info = tfds.load('cassava', with_info=True)\n```\n\n----------------------------------------\n\nTITLE: Basic Tensor Operations: Addition\nDESCRIPTION: Shows how to perform element-wise addition of a tensor with itself.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nx + x\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow with Compatibility Mode\nDESCRIPTION: Imports TensorFlow 1.x compatibility mode for the tutorial\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_layers.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow.compat.v1 as tf\n```\n\n----------------------------------------\n\nTITLE: Decoding a Batch of UTF-8 Encoded Unicode Strings\nDESCRIPTION: This snippet decodes a batch of UTF-8 encoded Unicode strings and represents them as a ragged tensor.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# A batch of Unicode strings, each represented as a UTF8-encoded string.\nbatch_utf8 = [s.encode('UTF-8') for s in\n              [u'hÃllo',  u'What is the weather tomorrow',  u'Göödnight', u'😊']]\nbatch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n                                               input_encoding='UTF-8')\nfor sentence_chars in batch_chars_ragged.to_list():\n  print(sentence_chars)\n```\n\n----------------------------------------\n\nTITLE: Adding CUPTI to Library Path\nDESCRIPTION: Command to add the CUPTI installation directory to the LD_LIBRARY_PATH environment variable if it's not already in the path.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nexport LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\n```\n\n----------------------------------------\n\nTITLE: Initializing License Header in Python\nDESCRIPTION: Apache 2.0 license header for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Decoding a UTF-8 String Scalar into Code Points\nDESCRIPTION: This code decodes a UTF-8 encoded string scalar into a vector of Unicode code points using TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntf.strings.unicode_decode(text_utf8,\n                          input_encoding='UTF-8')\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Dependencies\nDESCRIPTION: Imports required TensorFlow libraries and loads TensorBoard extension\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nimport os\n\n# Load the TensorBoard notebook extension.\n%load_ext tensorboard\n```\n\n----------------------------------------\n\nTITLE: Extracting Class Names from Filenames\nDESCRIPTION: Defines a function that parses the filename of a UCF101 video to extract the action class name, which is the third element from the end when split by underscores.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef get_class(fname):\n  \"\"\" Retrieve the name of the class given a filename.\n\n    Args:\n      fname: Name of the file in the UCF101 dataset.\n\n    Returns:\n      Class that the file belongs to.\n  \"\"\"\n  return fname.split('_')[-3]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating DocTest Usage in TensorFlow Python Documentation\nDESCRIPTION: This snippet shows how to write a testable docstring for a new layer in TensorFlow. It includes examples of using TensorFlow's public API, handling non-deterministic output, and formatting multi-line blocks for DocTest.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef NewLayer():\n  \"\"\"This layer does cool stuff.\n\n  Example usage:\n\n  >>> x = tf.random.normal((1, 28, 28, 3))\n  >>> new_layer = NewLayer(x)\n  >>> new_layer\n  <tf.Tensor: shape=(1, 14, 14, 3), dtype=int32, numpy=...>\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Using Named Signature for Image Feature Vector Extraction\nDESCRIPTION: Demonstrates how to explicitly invoke the image feature vector signature to extract features. Shows the standard input format and expected output structure.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/common_signatures/images.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n  outputs = module(dict(images=images), signature=\"image_feature_vector\",\n                   as_dict=True)\n  features = outputs[\"default\"]\n```\n\n----------------------------------------\n\nTITLE: Displaying cuDNN Library Import Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message indicating that the cuDNN library (libcudnn) could not be found during TensorFlow import.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>ImportError: libcudnn.<i>Version</i>: cannot open shared object file:\n  No such file or directory</pre>\n```\n\n----------------------------------------\n\nTITLE: Extracting Batch Data from TensorFlow Dataset\nDESCRIPTION: Retrieves the next batch of images and labels from the dataset iterator. This is used to test the data pipeline and demonstrate how to access dataset elements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# The dataset may take a few seconds to start, as it fills its shuffle buffer.\nimage_batch, label_batch = next(iter(keras_ds))\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and TensorFlow Recommenders\nDESCRIPTION: This code snippet imports the necessary TensorFlow modules, including `tensorflow` as `tf`, `tensorflow.compat.v1` as `tf1` (for compatibility with TensorFlow 1 APIs), and `tensorflow_recommenders` as `tfrs` (for using the `TPUEmbedding` layer).  It also explicitly notes that the `TPUEmbedding` layer is not part of the core TensorFlow library, highlighting the dependency on the TensorFlow Recommenders package.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tpu_embedding.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\n# TPUEmbedding layer is not part of TensorFlow.\nimport tensorflow_recommenders as tfrs\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow and TensorFlow Hub for Text Classification\nDESCRIPTION: This snippet imports the necessary libraries and prints version information for TensorFlow, TensorFlow Hub, and checks GPU availability.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_text_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n\nimport matplotlib.pyplot as plt\n\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n```\n\n----------------------------------------\n\nTITLE: Filtering and Plotting Confident Pitch Outputs in Python\nDESCRIPTION: This code filters pitch outputs based on confidence levels, keeping only those with confidence >= 0.9. It then plots the confident pitch outputs using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconfidence_outputs = list(confidence_outputs)\npitch_outputs = [ float(x) for x in pitch_outputs]\n\nindices = range(len (pitch_outputs))\nconfident_pitch_outputs = [ (i,p)  \n  for i, p, c in zip(indices, pitch_outputs, confidence_outputs) if  c >= 0.9  ]\nconfident_pitch_outputs_x, confident_pitch_outputs_y = zip(*confident_pitch_outputs)\n \nfig, ax = plt.subplots()\nfig.set_size_inches(20, 10)\nax.set_ylim([0, 1])\nplt.scatter(confident_pitch_outputs_x, confident_pitch_outputs_y, )\nplt.scatter(confident_pitch_outputs_x, confident_pitch_outputs_y, c=\"r\")\n\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Using tf_upgrade_v2 on a Directory Tree in Bash\nDESCRIPTION: This command shows how to use tf_upgrade_v2 to upgrade an entire directory of Python files from TensorFlow 1.x to 2.x.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntf_upgrade_v2 \\\n    --intree models/samples/cookbook/regression/ \\\n    --outtree regression_v2/ \\\n    --reportfile tree_report.txt\n```\n\n----------------------------------------\n\nTITLE: FILM Implementation Citation in BibTeX Format\nDESCRIPTION: BibTeX citation for the TensorFlow 2 implementation of the FILM technique, referencing the GitHub repository where the full implementation can be found.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_film_example.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{film-tf,\n  title = {Tensorflow 2 Implementation of \"FILM: Frame Interpolation for Large Motion\"},\n  author = {Fitsum Reda and Janne Kontkanen and Eric Tabellion and Deqing Sun and Caroline Pantofaru and Brian Curless},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/google-research/frame-interpolation}}\n}\n```\n\n----------------------------------------\n\nTITLE: Python Module Import Error - copyreg\nDESCRIPTION: Error message when the copyreg module cannot be imported\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nImportError: No module named copyreg\n```\n\n----------------------------------------\n\nTITLE: Training Model\nDESCRIPTION: Trains the model on the training data for 5 epochs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(x_train, y_train, epochs=5)\n```\n\n----------------------------------------\n\nTITLE: Playing Converted Audio in Python using IPython.display.Audio\nDESCRIPTION: Plays the generated WAV file using the IPython.display.Audio functionality. This allows for audio playback directly in notebook environments like Jupyter or Google Colab.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nAudio(wav_from_created_midi)\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Library Load Error on Windows (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when TensorFlow is unable to load the CUDA library (nvcuda.dll) on Windows.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>[...\\stream_executor\\dso_loader.cc] Couldn't open CUDA library nvcuda.dll</pre>\n```\n\n----------------------------------------\n\nTITLE: Instantiating the Quadratic Model in TensorFlow\nDESCRIPTION: Creates an instance of the custom quadratic model class.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nquad_model = Model()\n```\n\n----------------------------------------\n\nTITLE: Printing Test Accuracy\nDESCRIPTION: Display the final test accuracy of the model\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(test_acc)\n```\n\n----------------------------------------\n\nTITLE: Single Variable Initialization\nDESCRIPTION: Initializes a specific variable in a TensorFlow session.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/variables.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsession.run(my_variable.initializer)\n```\n\n----------------------------------------\n\nTITLE: Attempting Incompatible Model Restoration\nDESCRIPTION: Demonstrates an attempt to restore a model with incompatible architecture, which will result in an error.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/checkpoints.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclassifier2 = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    hidden_units=[20, 20],  # Change the number of neurons in the model.\n    n_classes=3,\n    model_dir='models/iris')\n\nclassifier.train(\n    input_fn=lambda:train_input_fn(train_x, train_y, batch_size=100),\n        steps=200)\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven POM for TensorFlow Project\nDESCRIPTION: This XML snippet shows a complete Maven pom.xml configuration for a TensorFlow Java project. It includes project metadata, compiler settings, and the TensorFlow dependency.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_java_legacy.md#2025-04-21_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<project>\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.myorg</groupId>\n  <artifactId>hellotensorflow</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <properties>\n    <exec.mainClass>HelloTensorFlow</exec.mainClass>\n\t<!-- The sample code requires at least JDK 1.7. -->\n\t<!-- The maven compiler plugin defaults to a lower version -->\n\t<maven.compiler.source>1.7</maven.compiler.source>\n\t<maven.compiler.target>1.7</maven.compiler.target>\n  </properties>\n  <dependencies>\n    <dependency>\n\t  <groupId>org.tensorflow</groupId>\n\t  <artifactId>tensorflow</artifactId>\n\t  <version>1.14.0</version>\n\t</dependency>\n  </dependencies>\n</project>\n```\n\n----------------------------------------\n\nTITLE: Viewing Upgraded Dropout File in Bash\nDESCRIPTION: This command shows the contents of the upgraded dropout file, demonstrating how argument names were added to handle moved and renamed arguments.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncat dropout_v2.py\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow License and Copyright Notice\nDESCRIPTION: This code snippet includes the copyright notice and Apache 2.0 license information for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting TensorFlow C Library on Linux\nDESCRIPTION: This bash script downloads the TensorFlow C library for Linux x86_64 and extracts it to the /usr/local directory. It requires sudo privileges.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/lang_c.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nFILENAME=libtensorflow-cpu-linux-x86_64.tar.gz\nwget -q --no-check-certificate https://storage.googleapis.com/tensorflow/versions/2.18.1/${FILENAME}\nsudo tar -C /usr/local -xzf ${FILENAME}\n```\n\n----------------------------------------\n\nTITLE: Model Compilation\nDESCRIPTION: Configures the model for training by setting the optimizer and loss function\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.categorical_crossentropy)\n```\n\n----------------------------------------\n\nTITLE: Registering Polymorphic TensorFlow Op\nDESCRIPTION: Example of registering a polymorphic op that can handle multiple input/output types.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_26\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: {float, int32}\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n```\n\n----------------------------------------\n\nTITLE: Testing Partially Migrated Model for Behavioral Consistency\nDESCRIPTION: Tests the partially migrated model using the same random seed and input to ensure it produces identical outputs and regularization losses to the original model. This verifies that the initial migration step maintains the same behavior.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/model_mapping.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nrandom_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\nwith random_tool.scope():\n  tf.keras.utils.set_random_seed(42)\n  layer = PartiallyMigratedModel(10)\n\n  inputs = tf.random.normal(shape=(10, 5, 5, 5))\n  migrated_output = layer(inputs)\n\n  # Grab the regularization loss as well\n  migrated_regularization_loss = tf.math.add_n(layer.losses)\n\nprint(migrated_regularization_loss)\n```\n\n----------------------------------------\n\nTITLE: Setting TF_CONFIG Environment Variable for Distributed Training\nDESCRIPTION: This code serializes the TF_CONFIG dictionary to JSON and sets it as an environment variable, which is required for TensorFlow distributed training configuration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nos.environ['TF_CONFIG'] = json.dumps(tf_config)\n```\n\n----------------------------------------\n\nTITLE: Restricting TensorFlow to Use Only One GPU\nDESCRIPTION: This code snippet shows how to limit TensorFlow to use only the first GPU on a multi-GPU system using tf.config.set_visible_devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/gpu.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only use the first GPU\n  try:\n    tf.config.set_visible_devices(gpus[0], 'GPU')\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n  except RuntimeError as e:\n    # Visible devices must be set before GPUs have been initialized\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Configuring Keras Layers with Various Parameters\nDESCRIPTION: This snippet shows different ways to configure Keras layers, including setting activation functions, regularizers, and initializers for kernels and biases.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/keras.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create a sigmoid layer:\nlayers.Dense(64, activation='sigmoid')\n# Or:\nlayers.Dense(64, activation=tf.sigmoid)\n\n# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\nlayers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n\n# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\nlayers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n\n# A linear layer with a kernel initialized to a random orthogonal matrix:\nlayers.Dense(64, kernel_initializer='orthogonal')\n\n# A linear layer with a bias vector initialized to 2.0s:\nlayers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))\n```\n\n----------------------------------------\n\nTITLE: Printing Classification Results in TensorFlow C++\nDESCRIPTION: This code prints the top classification labels found by the model. It calls a helper function to display the results in a user-friendly format.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_14\n\nLANGUAGE: C++\nCODE:\n```\n  // Do something interesting with the results we've generated.\n  Status print_status = PrintTopLabels(outputs, FLAGS_labels);\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dataset Generation for Performance Comparison in TensorFlow\nDESCRIPTION: Defines a constant for batch size and a dataset generator function that creates instances of TimeMeasuredDataset with a specified number of samples.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n_batch_map_num_items = 50\n\ndef dataset_generator_fun(*args):\n    return TimeMeasuredDataset(num_samples=_batch_map_num_items)\n```\n\n----------------------------------------\n\nTITLE: Implementing Outer Parallelism in TensorFlow Input Pipeline\nDESCRIPTION: This snippet shows how to introduce outer parallelism in a TensorFlow input pipeline by sharding the input and processing multiple shards concurrently. It's useful for parallelizing inherently sequential operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance_analysis.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfilenames = tf.data.Dataset.list_files(file_path, shuffle=is_training)\n\ndef make_dataset(shard_index):\n  filenames = filenames.shard(NUM_SHARDS, shard_index)\n  dataset = filenames_to_dataset(filenames)\n  Return dataset.batch(batch_size)\n\nindices = tf.data.Dataset.range(NUM_SHARDS)\ndataset = indices.interleave(make_dataset,\n                             num_parallel_calls=tf.data.AUTOTUNE)\ndataset = dataset.prefetch(tf.data.AUTOTUNE)\n```\n\n----------------------------------------\n\nTITLE: Checking Signatures in a Custom Module\nDESCRIPTION: Verifies that a custom tf.Module has no signatures by default when loaded from a SavedModel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nassert len(imported.signatures) == 0\n```\n\n----------------------------------------\n\nTITLE: Accessing Tensor Elements in TensorFlow\nDESCRIPTION: Demonstrates different ways to access elements and slices of tensors using indexing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/tensors.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmy_scalar = my_vector[2]\nmy_scalar = my_matrix[1, 2]\nmy_row_vector = my_matrix[2]\nmy_column_vector = my_matrix[:, 3]\n```\n\n----------------------------------------\n\nTITLE: DeepDream Execution Function\nDESCRIPTION: Main function to run the DeepDream algorithm with specified parameters and display intermediate results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef run_deep_dream_simple(img, steps=100, step_size=0.01):\n  img = tf.keras.applications.inception_v3.preprocess_input(img)\n  img = tf.convert_to_tensor(img)\n  step_size = tf.convert_to_tensor(step_size)\n  steps_remaining = steps\n  step = 0\n  while steps_remaining:\n    if steps_remaining>100:\n      run_steps = tf.constant(100)\n    else:\n      run_steps = tf.constant(steps_remaining)\n    steps_remaining -= run_steps\n    step += run_steps\n\n    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n    \n    display.clear_output(wait=True)\n    show(deprocess(img))\n    print (\"Step {}, loss {}\".format(step, loss))\n\n  result = deprocess(img)\n  display.clear_output(wait=True)\n  show(result)\n\n  return result\n```\n\n----------------------------------------\n\nTITLE: Building C++ Binary for TensorFlow Example\nDESCRIPTION: This command compiles the TensorFlow label image example using Bazel, ensuring that all necessary dependencies for the model are included.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbazel build tensorflow/examples/label_image/...\n```\n\n----------------------------------------\n\nTITLE: Redirecting tfdbg Output to File\nDESCRIPTION: Example showing how to redirect the output of a tfdbg command to a file using bash-style redirection. The command prints specific slices of a tensor named 'cross_entropy/Log:0' to a text file.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/debugger.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntfdbg> pt cross_entropy/Log:0[:, 0:10] > /tmp/xent_value_slices.txt\n```\n\n----------------------------------------\n\nTITLE: Broadcasting in TensorFlow NumPy\nDESCRIPTION: Demonstrates how TensorFlow NumPy handles broadcasting with arrays of different shapes, following NumPy broadcasting rules to create compatible output shapes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nx = tnp.ones([2, 3])\ny = tnp.ones([3])\nz = tnp.ones([1, 2, 1])\nprint(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (\n    x.shape, y.shape, z.shape, (x + y + z).shape))\n```\n\n----------------------------------------\n\nTITLE: Loading and Checking Multiple Signatures\nDESCRIPTION: Loads a SavedModel with multiple signatures and verifies that all the signature keys are available.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimported_with_multiple_signatures = tf.saved_model.load(\n    module_multiple_signatures_path\n)\nlist(\n    imported_with_multiple_signatures.signatures.keys()\n)  # [\"serving_default\", \"array_input\"]\n```\n\n----------------------------------------\n\nTITLE: Output Visualization Function\nDESCRIPTION: Creates a visualization function to display the original, masked, and generated images side by side using matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/boundless.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef visualize_output_comparison(img_original, img_masked, img_filled):\n  plt.figure(figsize=(24,12))\n  plt.subplot(131)\n  plt.imshow((np.squeeze(img_original)))\n  plt.title(\"Original\", fontsize=24)\n  plt.axis('off')\n  plt.subplot(132)\n  plt.imshow((np.squeeze(img_masked)))\n  plt.title(\"Masked\", fontsize=24)\n  plt.axis('off')\n  plt.subplot(133)\n  plt.imshow((np.squeeze(img_filled)))\n  plt.title(\"Generated\", fontsize=24)\n  plt.axis('off')\n  plt.show()\n```\n\n----------------------------------------\n\nTITLE: Resetting Model Weights for Mixed Precision Training\nDESCRIPTION: Loads the initial weights of the model to ensure training starts from the same state for fair comparison between different precision modes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmodel.set_weights(initial_weights)\n```\n\n----------------------------------------\n\nTITLE: Downloading Shakespeare Dataset\nDESCRIPTION: Fetching Shakespeare's text data using TensorFlow's utility function\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npath_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n```\n\n----------------------------------------\n\nTITLE: Displaying Prediction Results for Citation Intent Classifier\nDESCRIPTION: This code creates a DataFrame to display the first 10 predictions, showing the input text, true label, and predicted label for each example.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfirst_10_predictions = list(itertools.islice(predictions, 10))\n\ndisplay_df(\n  pd.DataFrame({\n      TEXT_FEATURE_NAME: [pred['features'].decode('utf8') for pred in first_10_predictions],\n      LABEL_NAME: [THE_DATASET.class_names()[pred['labels']] for pred in first_10_predictions],\n      'prediction': [THE_DATASET.class_names()[pred['predictions']] for pred in first_10_predictions]\n  }))\n```\n\n----------------------------------------\n\nTITLE: Defining a Subclassed Model in Python for DTensor API\nDESCRIPTION: Shows the definition of a subclassed Keras model that will be used to demonstrate the LayoutMap functionality for specifying DTensor layouts.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_keras_tutorial.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nclass SubclassedModel(tf.keras.Model):\n\n  def __init__(self, name=None):\n    super().__init__(name=name)\n    self.feature = tf.keras.layers.Dense(16)\n    self.feature_2 = tf.keras.layers.Dense(24)\n    self.dropout = tf.keras.layers.Dropout(0.1)\n\n  def call(self, inputs, training=None):\n    x = self.feature(inputs)\n    x = self.dropout(x, training=training)\n    return self.feature_2(x)\n```\n\n----------------------------------------\n\nTITLE: Testing Universal Sentence Encoder-Lite with example sentences\nDESCRIPTION: Demonstrates how to compute embeddings for text examples of varying lengths (word, sentence, paragraph) using the Universal Sentence Encoder-Lite model and displays embedding information.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Compute a representation for each message, showing various lengths supported.\nword = \"Elephant\"\nsentence = \"I am a sentence for which I would like to get its embedding.\"\nparagraph = (\n    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n    \"the more 'diluted' the embedding will be.\")\nmessages = [word, sentence, paragraph]\n\nvalues, indices, dense_shape = process_to_IDs_in_sparse_format(sp, messages)\n\n# Reduce logging output.\nlogging.set_verbosity(logging.ERROR)\n\nwith tf.Session() as session:\n  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n  message_embeddings = session.run(\n      encodings,\n      feed_dict={input_placeholder.values: values,\n                input_placeholder.indices: indices,\n                input_placeholder.dense_shape: dense_shape})\n\n  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n    print(\"Message: {}\".format(messages[i]))\n    print(\"Embedding size: {}\".format(len(message_embedding)))\n    message_embedding_snippet = \", \".join(\n        (str(x) for x in message_embedding[:3]))\n    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n```\n\n----------------------------------------\n\nTITLE: Plotting Mean Item IDs for Shuffle-then-Repeat Pattern\nDESCRIPTION: Calculates and plots the mean item IDs for each batch in a shuffle-then-repeat dataset to visualize the epoch boundary.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_70\n\nLANGUAGE: python\nCODE:\n```\nshuffle_repeat = [n.numpy().mean() for n, line_batch in shuffled]\nplt.plot(shuffle_repeat, label=\"shuffle().repeat()\")\nplt.ylabel(\"Mean item ID\")\nplt.legend()\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Basic Dataset Performance\nDESCRIPTION: Measures the performance of the baseline dataset configuration using the timeit function. This establishes a reference point for comparison with optimized versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/load_data/images.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntimeit(ds)\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow License and Imports\nDESCRIPTION: Sets up the Apache 2.0 license header and imports required TensorFlow, NumPy and IPython display libraries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: One-Hot Encoding Origin Feature in TensorFlow\nDESCRIPTION: This function performs one-hot encoding on the 'Origin' feature of the dataset using TensorFlow operations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/quickstart_core.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef onehot_origin(x):\n  origin = tf.cast(x[:, -1], tf.int32)\n  # Use `origin - 1` to account for 1-indexed feature\n  origin_oh = tf.one_hot(origin - 1, 3)\n  x_ohe = tf.concat([x[:, :-1], origin_oh], axis = 1)\n  return x_ohe\n\nx_train_ohe, x_test_ohe = onehot_origin(x_train), onehot_origin(x_test)\nx_train_ohe.numpy()\n```\n\n----------------------------------------\n\nTITLE: Changing directory to sample code location\nDESCRIPTION: Command to navigate to the directory containing the Iris classification example code within the cloned repository.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/premade_estimators.md#2025-04-21_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\ncd models/samples/core/get_started/\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow and NumPy\nDESCRIPTION: Basic setup imports for TensorFlow, NumPy, and TensorFlow's experimental NumPy module, followed by printing the TensorFlow version.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\n\nprint(\"Using TensorFlow version %s\" % tf.__version__)\n```\n\n----------------------------------------\n\nTITLE: Installing SentEval and Downloading Task Data\nDESCRIPTION: Clones the SentEval repository from GitHub and downloads the necessary task data for evaluation using the provided script.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/senteval_for_universal_sentence_encoder_cmlm.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title Install SentEval and download task data\n!rm -rf ./SentEval\n!git clone https://github.com/facebookresearch/SentEval.git\n!cd $PWD/SentEval/data/downstream && bash get_transfer_data.bash > /dev/null 2>&1\n```\n\n----------------------------------------\n\nTITLE: Creating Function to Download Files from Zip\nDESCRIPTION: Defines a function that downloads specific files from a remote zip URL and organizes them into directories by class name, using the tqdm library to display progress.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef download_from_zip(zip_url, to_dir, file_names):\n  \"\"\" Download the contents of the zip file from the zip URL.\n\n    Args:\n      zip_url: A URL with a zip file containing data.\n      to_dir: A directory to download data to.\n      file_names: Names of files to download.\n  \"\"\"\n  with rz.RemoteZip(zip_url) as zip:\n    for fn in tqdm.tqdm(file_names):\n      class_name = get_class(fn)\n      zip.extract(fn, str(to_dir / class_name))\n      unzipped_file = to_dir / class_name / fn\n\n      fn = pathlib.Path(fn).parts[-1]\n      output_file = to_dir / class_name / fn\n      unzipped_file.rename(output_file)\n```\n\n----------------------------------------\n\nTITLE: Using Macros for Multiple Kernel Registrations in TensorFlow\nDESCRIPTION: Demonstrates using macros to simplify registering multiple kernel implementations for different data types, reducing code duplication in kernel registration.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_28\n\nLANGUAGE: c++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n\n#define REGISTER_KERNEL(type)                                       \\\n  REGISTER_KERNEL_BUILDER(                                          \\\n      Name(\"ZeroOut\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      ZeroOutOp<type>)\n\nREGISTER_KERNEL(int32);\nREGISTER_KERNEL(float);\nREGISTER_KERNEL(double);\n\n#undef REGISTER_KERNEL\n```\n\n----------------------------------------\n\nTITLE: Loading ANNOY Index and Mapping in Python\nDESCRIPTION: This code loads the previously built ANNOY index and the corresponding mapping file into memory for use in similarity matching.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nindex = annoy.AnnoyIndex(embedding_dimension)\nindex.load(index_filename, prefault=True)\nprint('Annoy index is loaded.')\nwith open(index_filename + '.mapping', 'rb') as handle:\n  mapping = pickle.load(handle)\nprint('Mapping file is loaded.')\n```\n\n----------------------------------------\n\nTITLE: Defining Similarity Matching Function in Python\nDESCRIPTION: Creates a function to find similar items in the ANNOY index given an embedding vector.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef find_similar_items(embedding, num_matches=5):\n  '''Finds similar items to a given embedding in the ANN index'''\n  ids = index.get_nns_by_vector(\n  embedding, num_matches, search_k=-1, include_distances=False)\n  items = [mapping[i] for i in ids]\n  return items\n```\n\n----------------------------------------\n\nTITLE: Decoding Speech Recognition Predictions in Python\nDESCRIPTION: This snippet decodes the model's numeric outputs back into text sequences using a Wav2Vec2tokenizer.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/wav2vec2_saved_model_finetuning.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\npredictions = tf.argmax(outputs, axis=-1)\npredictions = [tokenizer.decode(pred) for pred in predictions.numpy().tolist()]\npredictions\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op with Minimum List Length Constraint\nDESCRIPTION: Shows how to register an op with a constraint on the minimum length of a tensor list, ensuring that at least a certain number of tensors are provided.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_34\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MinLengthIntListExample\")\n    .Attr(\"N: int >= 2\")\n    .Input(\"in: N * int32\")\n    .Output(\"out: int32\");\n```\n\n----------------------------------------\n\nTITLE: Registering Op with Restricted Type Attribute (C++)\nDESCRIPTION: This example shows how to register a TensorFlow op with a `type` attribute that is restricted to a specific set of allowed `tf.DType` values. The `Attr` method specifies that the `t` attribute must be one of `int32`, `float`, or `bool`.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_13\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"RestrictedTypeExample\")\n    .Attr(\"t: {int32, float, bool}\");\n```\n\n----------------------------------------\n\nTITLE: Comparing Eager and Graph Execution with AutoGraph\nDESCRIPTION: Demonstrates the square_if_positive function running in eager mode, then converts it to a graph function and runs it in graph mode, showing equivalent results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint('Eager results: %2.2f, %2.2f' % (square_if_positive(tf.constant(9.0)),\n                                       square_if_positive(tf.constant(-9.0))))\n```\n\nLANGUAGE: python\nCODE:\n```\ntf_square_if_positive = tf.autograph.to_graph(square_if_positive)\n\nwith tf.Graph().as_default():\n  # The result works like a regular op: takes tensors in, returns tensors.\n  # You can inspect the graph using tf.get_default_graph().as_graph_def()\n  g_out1 = tf_square_if_positive(tf.constant( 9.0))\n  g_out2 = tf_square_if_positive(tf.constant(-9.0))\n  with tf.Session() as sess:\n    print('Graph results: %2.2f, %2.2f\\n' % (sess.run(g_out1), sess.run(g_out2)))\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Hub Copyright and Apache License 2.0 Notice in Python\nDESCRIPTION: Standard copyright header and Apache License 2.0 notice that appears at the top of TensorFlow Hub Python files. This notice specifies the legal terms under which the code can be used, modified, and distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Downloading Dataset Files\nDESCRIPTION: Downloading and extracting the BARD dataset using gdown.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngdown.download(\n    url='https://drive.google.com/uc?id=1Ag0jd21oRwJhVFIBohmX_ogeojVtapLy',\n    output='bard.zip',\n    quiet=True\n)\n```\n\nLANGUAGE: bash\nCODE:\n```\nunzip -qo bard.zip\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Slicing Function\nDESCRIPTION: Implements a function that yields individual examples from a dictionary of features, extracting one example at a time for each feature.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport itertools\n\ndef slices(features):\n  for i in itertools.count():\n    # For each feature take index `i`\n    example = {name:values[i] for name, values in features.items()}\n    yield example\n```\n\n----------------------------------------\n\nTITLE: Creating Non-Trainable TensorFlow Variables\nDESCRIPTION: This code shows how to create a non-trainable TensorFlow variable, which is useful for values that should not be updated during training, such as step counters.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/variable.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstep_counter = tf.Variable(1, trainable=False)\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow Configuration Script on Windows\nDESCRIPTION: Command to run the TensorFlow configuration script that prepares the build environment. This interactive script prompts for dependency locations and build options.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython ./configure.py\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Subprocess Demonstration\nDESCRIPTION: Setting a GREETINGS environment variable to demonstrate how subprocesses inherit environment variables from their parent process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_ctl.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GREETINGS'] = 'Hello TensorFlow!'\n```\n\n----------------------------------------\n\nTITLE: Analyzing MNIST Digit Distribution with Seaborn\nDESCRIPTION: Creates a count plot using seaborn to visualize the distribution of digits in the MNIST dataset, confirming balanced class representation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/mlp_core.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsns.countplot(x=y_viz.numpy());\nplt.xlabel('Digits')\nplt.title(\"MNIST Digit Distribution\");\n```\n\n----------------------------------------\n\nTITLE: Visualizing Linear Model Weights\nDESCRIPTION: Creates a bar chart of the linear model's learned weights for each input feature, which helps interpret what the model has learned and highlights that sometimes the model doesn't place the most weight on the target feature itself.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nplt.bar(x = range(len(train_df.columns)),\n        height=linear.layers[0].kernel[:,0].numpy())\naxis = plt.gca()\naxis.set_xticks(range(len(train_df.columns)))\n_ = axis.set_xticklabels(train_df.columns, rotation=90)\n```\n\n----------------------------------------\n\nTITLE: Adding Current Directory to Python Path\nDESCRIPTION: Adding the current directory to the Python path to allow importing files created within the notebook, which is needed for the worker processes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif '.' not in sys.path:\n  sys.path.insert(0, '.')\n```\n\n----------------------------------------\n\nTITLE: Basic TensorFlow Imports\nDESCRIPTION: Essential imports for TensorFlow and NumPy libraries\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Representing a Unicode String as a Vector of Code Points\nDESCRIPTION: This snippet demonstrates how to represent a Unicode string as a vector of Unicode code points in TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntext_chars = tf.constant([ord(char) for char in u\"语言处理\"])\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing an Image for Model Inference\nDESCRIPTION: Downloads a sample image, resizes it to 224x224 pixels, converts it to an array, and preprocesses it for a MobileNet model using Keras utilities.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfile = tf.keras.utils.get_file(\n    \"grace_hopper.jpg\",\n    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\nimg = tf.keras.utils.load_img(file, target_size=[224, 224])\nplt.imshow(img)\nplt.axis('off')\nx = tf.keras.utils.img_to_array(img)\nx = tf.keras.applications.mobilenet.preprocess_input(\n    x[tf.newaxis,...])\n```\n\n----------------------------------------\n\nTITLE: Visualizing predictions from the reloaded model\nDESCRIPTION: Creates a grid of images with predicted labels from the reloaded model to verify it produces the expected visual output.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(10,9))\nplt.subplots_adjust(hspace=0.5)\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(reloaded_predicted_label_batch[n].title())\n  plt.axis('off')\n_ = plt.suptitle(\"Model predictions\")\n```\n\n----------------------------------------\n\nTITLE: Converting Dataset Rows to a Pandas DataFrame\nDESCRIPTION: Demonstrates how to extract data from the TensorFlow dataset and convert it into a pandas DataFrame. This example extracts font names and characters from the dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb#2025-04-21_snippet_57\n\nLANGUAGE: python\nCODE:\n```\nfonts_dict = {'font_name':[], 'character':[]}\n\nfor row in font_rows.take(10):\n  fonts_dict['font_name'].append(row[0].numpy().decode())\n  fonts_dict['character'].append(chr(int(row[2].numpy())))\n\npd.DataFrame(fonts_dict)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies in Python\nDESCRIPTION: Installing scikit-learn package required for the tutorial\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/linear.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install sklearn\n```\n\n----------------------------------------\n\nTITLE: Fixed NoiseAdder Module with Lambda for Random Noise Generation\nDESCRIPTION: Refactored NoiseAdder class that uses a lambda function to ensure a new random tensor is generated for each call, which works correctly in both TF1.x and TF2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nclass NoiseAdder(tf.Module):\n  def __init__(shape, mean):\n    self.noise_distribution = lambda: tf.random.normal(shape=shape, mean=mean)\n    self.trainable_scale = tf.Variable(1.0, trainable=True)\n  \n  def add_noise(input):\n    return (self.noise_distribution() + input) * self.trainable_scale\n```\n\n----------------------------------------\n\nTITLE: Setting up evaluation inputs for STS Benchmark test\nDESCRIPTION: Creates input placeholders for the Semantic Textual Similarity (STS) Benchmark test, which will be used to evaluate the model's performance on semantic similarity tasks.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder_lite.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsts_input1 = tf.sparse_placeholder(tf.int64, shape=(None, None))\nsts_input2 = tf.sparse_placeholder(tf.int64, shape=(None, None))\n\n# For evaluation we use exactly normalized rather than\n```\n\n----------------------------------------\n\nTITLE: Displaying Xcode License Agreement Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs during pip installation on macOS when the Xcode license agreements have not been accepted.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>...<lots of warnings and errors>\nYou have not agreed to the Xcode license agreements, please run\n'xcodebuild -license' (for user-level acceptance) or\n'sudo xcodebuild -license' (for system-wide acceptance) from within a\nTerminal window to review and agree to the Xcode license agreements.\n...<more stack trace output>\n  File \"numpy/core/setup.py\", line 653, in get_mathlib_info\n\n    raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n\nRuntimeError: Broken toolchain: cannot link a simple C program</pre>\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Importing TensorFlow, TF-Hub and other required Python packages.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bangla_article_classifier.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport gdown\nimport numpy as np\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n\n----------------------------------------\n\nTITLE: Setting TFHUB_CACHE_DIR in Bash Environment\nDESCRIPTION: Configures a persistent cache directory in the user's home folder for storing downloaded TensorFlow Hub models. This setting persists across system reboots but requires manual cleanup.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/caching.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport TFHUB_CACHE_DIR=$HOME/.cache/tfhub_modules\n```\n\n----------------------------------------\n\nTITLE: Implementing CUDA Kernel in C++\nDESCRIPTION: CUDA implementation file containing the GPU kernel definition and launch code for the Example operation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_5\n\nLANGUAGE: c++\nCODE:\n```\n// kernel_example.cu.cc\n#ifdef GOOGLE_CUDA\n#define EIGEN_USE_GPU\n#include \"example.h\"\n#include \"tensorflow/core/util/gpu_kernel_helper.h\"\n\nusing namespace tensorflow;\n\nusing GPUDevice = Eigen::GpuDevice;\n\n// Define the CUDA kernel.\ntemplate <typename T>\n__global__ void ExampleCudaKernel(const int size, const T* in, T* out) {\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < size;\n       i += blockDim.x * gridDim.x) {\n    out[i] = 2 * ldg(in + i);\n  }\n}\n\n// Define the GPU implementation that launches the CUDA kernel.\ntemplate <typename T>\nvoid ExampleFunctor<GPUDevice, T>::operator()(\n    const GPUDevice& d, int size, const T* in, T* out) {\n  // Launch the cuda kernel.\n  //\n  // See core/util/gpu_kernel_helper.h for example of computing\n  // block count and thread_per_block count.\n  int block_count = 1024;\n  int thread_per_block = 20;\n  ExampleCudaKernel<T>\n      <<<block_count, thread_per_block, 0, d.stream()>>>(size, in, out);\n}\n\n// Explicitly instantiate functors for the types of OpKernels registered.\ntemplate struct ExampleFunctor<GPUDevice, float>;\ntemplate struct ExampleFunctor<GPUDevice, int32>;\n\n#endif  // GOOGLE_CUDA\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Non-strict Execution in tf.function Graph Mode in Python\nDESCRIPTION: Shows how graph execution skips unnecessary operations, potentially avoiding runtime errors that would occur in eager execution.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef unused_return_eager(x):\n  # Get index 1 will fail when `len(x) == 1`\n  tf.gather(x, [1]) # unused \n  return x\n\ntry:\n  print(unused_return_eager(tf.constant([0.0])))\nexcept tf.errors.InvalidArgumentError as e:\n  # All operations are run during eager execution so an error is raised.\n  print(f'{type(e).__name__}: {e}')\n\n@tf.function\ndef unused_return_graph(x):\n  tf.gather(x, [1]) # unused\n  return x\n\n# Only needed operations are run during graph execution. The error is not raised.\nprint(unused_return_graph(tf.constant([0.0])))\n```\n\n----------------------------------------\n\nTITLE: Checking C++ Files with clang-format\nDESCRIPTION: Commands to verify if a C++ file conforms to Google style guidelines using clang-format, outputting the formatted code to a temporary file and comparing differences.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/code_style.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ clang-format <my_cc_file> --style=google > /tmp/my_cc_file.cc\n$ diff <my_cc_file> /tmp/my_cc_file.cc\n```\n\n----------------------------------------\n\nTITLE: Displaying cuDNN Library Load Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when TensorFlow is unable to load the cuDNN library.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>[...\\stream_executor\\cuda\\cuda_dnn.cc] Unable to load cuDNN DSO</pre>\n```\n\n----------------------------------------\n\nTITLE: Saving Random Generator with Checkpoint\nDESCRIPTION: Initializes a random number generator and creates a checkpoint for saving its state. The generator outputs a random normal value to demonstrate the state before saving.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfilename = \"./checkpoint\"\ng = tf.random.Generator.from_seed(1)\ncp = tf.train.Checkpoint(generator=g)\nprint(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow on MacOS\nDESCRIPTION: Commands to install TensorFlow on MacOS and verify the installation. Note that there is currently no official GPU support for MacOS.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# There is currently no official GPU support for MacOS.\npython3 -m pip install tensorflow\n# Verify the installation:\npython3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Examining a Basic DTensor in TensorFlow\nDESCRIPTION: Example demonstrating how to create a first DTensor with a simple unsharded layout, then examine its basic properties including shape and dtype. This shows the fundamental structure of a DTensor object.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/dtensor_overview.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"x\", 6)], devices=DEVICES)\nlayout = dtensor.Layout([dtensor.UNSHARDED], mesh)\n\nmy_first_dtensor = dtensor_from_array([0, 1], layout)\n\n# Examine the DTensor content\nprint(my_first_dtensor)\nprint(\"global shape:\", my_first_dtensor.shape)\nprint(\"dtype:\", my_first_dtensor.dtype)\n```\n\n----------------------------------------\n\nTITLE: Importing TensorFlow for API Behavior Demonstrations\nDESCRIPTION: Simple import statement for TensorFlow, used as a starting point for demonstrating API changes between TF1.x and TF2.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Swapping Loss Functions in TensorFlow Word2Vec\nDESCRIPTION: Example of flexibility in TensorFlow for changing training objectives by swapping loss functions. Shows switching between NCE loss and sampled softmax loss.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/word2vec.md#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\ntf.nn.nce_loss()\ntf.nn.sampled_softmax_loss()\n```\n\n----------------------------------------\n\nTITLE: Tensor Hashing Error in TF2\nDESCRIPTION: Demonstrates the TypeError that occurs when trying to directly use tensors as hashable objects in TensorFlow 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.enable_tensor_equality()\nx = tf.Variable(0.0)\n\ntry:\n  set([x, tf.constant(2.0)])\nexcept TypeError as e:\n  # TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Setting up TensorFlow for Ragged Tensors\nDESCRIPTION: Install the latest pre-release version of TensorFlow and import necessary modules for working with ragged tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install --pre -U tensorflow\nimport math\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Listing Upgraded DeepLab Files in Bash\nDESCRIPTION: This command lists the files in the upgraded DeepLab directory.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nls deeplab_v2\n```\n\n----------------------------------------\n\nTITLE: Inspecting Dataset with Shell Command\nDESCRIPTION: Viewing the first 5 lines of the downloaded dataset file using shell command.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/eager/custom_training_walkthrough.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!head -n5 {train_dataset_fp}\n```\n\n----------------------------------------\n\nTITLE: Verifying CUPTI Installation\nDESCRIPTION: Command to check if NVIDIA CUDA Profiling Tools Interface (CUPTI) is present in the system path. This is a prerequisite for GPU profiling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n/sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | \\\ngrep libcupti\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Input Image in Python\nDESCRIPTION: This snippet selects an input image from the predefined map and loads it using a custom function, preparing it for inference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_classification.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimg_url = images_for_test_map[image_name]\nimage, original_image = load_image(img_url, image_size, dynamic_size, max_dynamic_size)\nshow_image(image, 'Scaled image')\n```\n\n----------------------------------------\n\nTITLE: Making a TensorFlow Op Polymorphic in a Backward-Compatible Way in C++\nDESCRIPTION: Example showing how to convert a non-polymorphic TensorFlow operation to a polymorphic one while maintaining backward compatibility. By adding a type attribute 'T' with a default value that matches the original type, existing usages of the op continue to work.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_45\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MyGeneralUnaryOp\")\n    .Input(\"in: float\")\n    .Output(\"out: float\");\n```\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"MyGeneralUnaryOp\")\n    .Input(\"in: T\")\n    .Output(\"out: T\")\n    .Attr(\"T: numerictype = DT_FLOAT\");\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing Flower Dataset for Training\nDESCRIPTION: Functions to download flower images and split them into training and test sets with a specified ratio. The dataset contains 5 classes of flower images.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/image_feature_vector.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nFLOWERS_DIR = './flower_photos'\nTRAIN_FRACTION = 0.8\nRANDOM_SEED = 2018\n\n\ndef download_images():\n  \"\"\"If the images aren't already downloaded, save them to FLOWERS_DIR.\"\"\"\n  if not os.path.exists(FLOWERS_DIR):\n    DOWNLOAD_URL = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n    print('Downloading flower images from %s...' % DOWNLOAD_URL)\n    urllib.request.urlretrieve(DOWNLOAD_URL, 'flower_photos.tgz')\n    !tar xfz flower_photos.tgz\n  print('Flower photos are located in %s' % FLOWERS_DIR)\n\n\ndef make_train_and_test_sets():\n  \"\"\"Split the data into train and test sets and get the label classes.\"\"\"\n  train_examples, test_examples = [], []\n  shuffler = random.Random(RANDOM_SEED)\n  is_root = True\n  for (dirname, subdirs, filenames) in tf.gfile.Walk(FLOWERS_DIR):\n    # The root directory gives us the classes\n    if is_root:\n      subdirs = sorted(subdirs)\n      classes = collections.OrderedDict(enumerate(subdirs))\n      label_to_class = dict([(x, i) for i, x in enumerate(subdirs)])\n      is_root = False\n    # The sub directories give us the image files for training.\n    else:\n      filenames.sort()\n      shuffler.shuffle(filenames)\n      full_filenames = [os.path.join(dirname, f) for f in filenames]\n      label = dirname.split('/')[-1]\n      label_class = label_to_class[label]\n      # An example is the image file and it's label class.\n      examples = list(zip(full_filenames, [label_class] * len(filenames)))\n      num_train = int(len(filenames) * TRAIN_FRACTION)\n      train_examples.extend(examples[:num_train])\n      test_examples.extend(examples[num_train:])\n\n  shuffler.shuffle(train_examples)\n  shuffler.shuffle(test_examples)\n  return train_examples, test_examples, classes\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow on Windows Native with GPU Support\nDESCRIPTION: Commands to install TensorFlow with GPU support on Windows Native. Only supported for versions before 2.11, requiring specific CUDA toolkit and cuDNN versions.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n# Anything above 2.10 is not supported on the GPU on Windows Native\npython -m pip install \"tensorflow<2.11\"\n# Verify the installation:\npython -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for TensorFlow 1 Logs\nDESCRIPTION: Launches TensorBoard to visualize the logs generated by the TensorFlow 1.x Estimator.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tensorboard.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n%tensorboard --logdir {classifier.model_dir}\n```\n\n----------------------------------------\n\nTITLE: Self-Test Validation for TensorFlow C++ Image Classification\nDESCRIPTION: This code performs an automated test to verify the model produces the expected result with default settings. It checks that the top label for the test image matches the expected label (866 - military uniform).\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_13\n\nLANGUAGE: C++\nCODE:\n```\n  // This is for automated testing to make sure we get the expected result with\n  // the default settings. We know that label 866 (military uniform) should be\n  // the top label for the Admiral Hopper image.\n  if (FLAGS_self_test) {\n    bool expected_matches;\n    Status check_status = CheckTopLabel(outputs, 866, &expected_matches);\n    if (!check_status.ok()) {\n      LOG(ERROR) << \"Running check failed: \" << check_status;\n      return -1;\n    }\n    if (!expected_matches) {\n      LOG(ERROR) << \"Self-test failed!\";\n      return -1;\n    }\n  }\n```\n\n----------------------------------------\n\nTITLE: Numpy Function Input Example\nDESCRIPTION: Shows how to use numpy functions to generate input data directly.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#2025-04-21_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n`<input_key>=np.ones((32,32,3))`\n```\n\n----------------------------------------\n\nTITLE: Compiling Image Classification Model with TensorFlow Optimizer\nDESCRIPTION: Configures the model training parameters including SGD optimizer with momentum, categorical cross-entropy loss with label smoothing, and accuracy metrics for training evaluation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_image_retraining.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel.compile(\n  optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9), \n  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Task Role Branching in TensorFlow\nDESCRIPTION: Code for branching program execution based on task type in a distributed setup using TFConfigClusterResolver.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ncluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\nif cluster_resolver.task_type in (\"worker\", \"ps\"):\n  # Start a TensorFlow server and wait.\nelif cluster_resolver.task_type == \"evaluator\":\n  # Run sidecar evaluation\nelse:\n  # Run the coordinator.\n```\n\n----------------------------------------\n\nTITLE: Processing Epochs with OutOfRangeError\nDESCRIPTION: This snippet demonstrates how to process multiple epochs by catching the `tf.errors.OutOfRangeError` at the end of each epoch. This approach allows for performing end-of-epoch calculations.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/datasets.md#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(...)\ndataset = dataset.batch(32)\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\n\n# Compute for 100 epochs.\nfor _ in range(100):\n  sess.run(iterator.initializer)\n  while True:\n    try:\n      sess.run(next_element)\n    except tf.errors.OutOfRangeError:\n      break\n\n  # [Perform end-of-epoch calculations here.]\n```\n\n----------------------------------------\n\nTITLE: Determining Unicode Script for Code Points\nDESCRIPTION: This snippet demonstrates how to use TensorFlow to determine the Unicode script of a given set of code points.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/representation/unicode.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nuscript = tf.strings.unicode_script([33464, 1041])  # ['芸', 'Б']\nprint(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorShape Object for API Comparison\nDESCRIPTION: Creates a TensorShape object with mixed known and unknown dimensions and selects an index for demonstration purposes.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Create a shape and choose an index\ni = 0\nshape = tf.TensorShape([16, None, 256])\nshape\n```\n\n----------------------------------------\n\nTITLE: Setting up SciCite dataset for citation intent classification\nDESCRIPTION: This code defines a Dataset class to handle the SciCite dataset from TensorFlow Datasets. It includes methods for data preprocessing, splitting, and example generation. The class is then instantiated with specific parameters for the SciCite dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/cord_19_embeddings.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Dataset:\n  \"\"\"Build a dataset from a TFDS dataset.\"\"\"\n  def __init__(self, tfds_name, feature_name, label_name):\n    self.dataset_builder = tfds.builder(tfds_name)\n    self.dataset_builder.download_and_prepare()\n    self.feature_name = feature_name\n    self.label_name = label_name\n  \n  def get_data(self, for_eval):\n    splits = THE_DATASET.dataset_builder.info.splits\n    if tfds.Split.TEST in splits:\n      split = tfds.Split.TEST if for_eval else tfds.Split.TRAIN\n    else:\n      SPLIT_PERCENT = 80\n      split = \"train[{}%:]\".format(SPLIT_PERCENT) if for_eval else \"train[:{}%]\".format(SPLIT_PERCENT)\n    return self.dataset_builder.as_dataset(split=split)\n\n  def num_classes(self):\n    return self.dataset_builder.info.features[self.label_name].num_classes\n\n  def class_names(self):\n    return self.dataset_builder.info.features[self.label_name].names\n\n  def preprocess_fn(self, data):\n    return data[self.feature_name], data[self.label_name]\n\n  def example_fn(self, data):\n    feature, label = self.preprocess_fn(data)\n    return {'feature': feature, 'label': label}, label\n\n\ndef get_example_data(dataset, num_examples, **data_kw):\n  \"\"\"Show example data\"\"\"\n  with tf.Session() as sess:\n    batched_ds = dataset.get_data(**data_kw).take(num_examples).map(dataset.preprocess_fn).batch(num_examples)\n    it = tf.data.make_one_shot_iterator(batched_ds).get_next()\n    data = sess.run(it)\n  return data\n\n\nTFDS_NAME = 'scicite' #@param {type: \"string\"}\nTEXT_FEATURE_NAME = 'string' #@param {type: \"string\"}\nLABEL_NAME = 'label' #@param {type: \"string\"}\nTHE_DATASET = Dataset(TFDS_NAME, TEXT_FEATURE_NAME, LABEL_NAME)\n```\n\n----------------------------------------\n\nTITLE: Building MLP Model with DTensor Support\nDESCRIPTION: Constructs an MLP (Multi-Layer Perceptron) model using DTensor-aware dense layers. The model is designed for data parallel training across multiple devices.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/core/distribution.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MLP(tf.Module):\n\n  def __init__(self, layers):\n    self.layers = layers\n   \n  def __call__(self, x, preds=False): \n    # Execute the model's layers sequentially\n    for layer in self.layers:\n      x = layer(x)\n    return x\n\nmesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\nweight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)\n\ninput_size = 784\nhidden_layer_1_size = 700\nhidden_layer_2_size = 500\nhidden_layer_2_size = 10\n\nmlp_model = MLP([\n    DenseLayer(in_dim=input_size, out_dim=hidden_layer_1_size, \n               weight_layout=weight_layout,\n               activation=tf.nn.relu),\n    DenseLayer(in_dim=hidden_layer_1_size , out_dim=hidden_layer_2_size,\n               weight_layout=weight_layout,\n               activation=tf.nn.relu),\n    DenseLayer(in_dim=hidden_layer_2_size, out_dim=hidden_layer_2_size, \n               weight_layout=weight_layout)])\n```\n\n----------------------------------------\n\nTITLE: TensorFlow License Header\nDESCRIPTION: Apache 2.0 license header for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/distribute_strategy.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Class Names\nDESCRIPTION: Creates a list of class names mapping numerical labels to clothing categories for the Fashion MNIST dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Parallel Training with DTensor in Python\nDESCRIPTION: This snippet shows how to set up a model for model parallel training using DTensor. It creates a 2D mesh and configures the model with appropriate layouts for model parallelism.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/dtensor_ml_tutorial.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmesh = dtensor.create_mesh([(\"batch\", 4), (\"model\", 2)], devices=DEVICES)\nmodel = MLP([dtensor.Layout([dtensor.UNSHARDED, \"model\"], mesh), \n             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])\n```\n\n----------------------------------------\n\nTITLE: Transforming Ragged Tensor Values with map_flat_values\nDESCRIPTION: Shows how to apply an elementwise transformation to the values of a ragged tensor using tf.ragged.map_flat_values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/ragged_tensors.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntimes_two_plus_one = lambda x: x * 2 + 1\nprint(tf.ragged.map_flat_values(times_two_plus_one, digits))\n```\n\n----------------------------------------\n\nTITLE: Restoring Generator State from Checkpoint\nDESCRIPTION: Restores a previously saved random number generator state from a checkpoint, which allows the generator to continue producing the same sequence from the saved point.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/random_numbers.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ncp.restore(filename)\nprint(\"RNG stream from restoring point:\")\nprint(g.normal([]))\nprint(g.normal([]))\n```\n\n----------------------------------------\n\nTITLE: Adding Fully Connected Layer for Classification in TensorFlow\nDESCRIPTION: This snippet shows how to add a fully connected layer to the model, which is used as a softmax layer for classification.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\ntf.layers.dense(final_state, params.num_classes)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Model Weights in TensorFlow\nDESCRIPTION: This snippet shows how to save the initial model weights to a temporary file and load them back into the model. This allows for consistent initialization across different training runs.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ninitial_weights = os.path.join(tempfile.mkdtemp(), 'initial.weights.h5')\nmodel.save_weights(initial_weights)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Final Model on Test Data\nDESCRIPTION: Evaluates the performance of the final trained model on the test dataset.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\neval_result = hypermodel.evaluate(img_test, label_test)\nprint(\"[test loss, test accuracy]:\", eval_result)\n```\n\n----------------------------------------\n\nTITLE: Outlining SIG Lifecycle in Markdown\nDESCRIPTION: This snippet presents the main header for the SIG lifecycle section, introducing the stages of a SIG's existence.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/sig_playbook.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n## SIG lifecycle\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python for TensorFlow Documentation\nDESCRIPTION: This code snippet contains the license declaration for TensorFlow documentation, specifying that the content is licensed under the Apache License, Version 2.0.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/graph_optimization.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Using Generator Input with TensorFlow Distribution Strategy\nDESCRIPTION: Example of creating a distributed dataset from a generator function using tf.data.Dataset.from_generator with MirroredStrategy.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/input.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nmirrored_strategy = tf.distribute.MirroredStrategy()\ndef input_gen():\n  while True:\n    yield np.random.rand(4)\n\n# use Dataset.from_generator\ndataset = tf.data.Dataset.from_generator(\n    input_gen, output_types=(tf.float32), output_shapes=tf.TensorShape([4]))\ndist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\niterator = iter(dist_dataset)\nfor _ in range(4):\n  result = mirrored_strategy.run(lambda x: x, args=(next(iterator),))\n  print(result)\n```\n\n----------------------------------------\n\nTITLE: Setting BigBiGAN Module Path in Python\nDESCRIPTION: Defines the TensorFlow Hub module path for loading a pre-trained BigBiGAN model. Offers options for ResNet-50 or RevNet-50 x4 based models.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nmodule_path = 'https://tfhub.dev/deepmind/bigbigan-resnet50/1'  # ResNet-50\n# module_path = 'https://tfhub.dev/deepmind/bigbigan-revnet50x4/1'  # RevNet-50 x4\n```\n\n----------------------------------------\n\nTITLE: Rendering Music Score and Printing Notes in Python\nDESCRIPTION: This code renders the music score using the showScore function and prints the list of best notes and rests determined by the quantization process.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# rendering the music score\nshowScore(sc)\nprint(best_notes_and_rests)\n```\n\n----------------------------------------\n\nTITLE: Initializing License and Copyright Header in Python\nDESCRIPTION: Standard Apache 2.0 license header and copyright notice for TensorFlow Hub Authors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Profiler Plugin\nDESCRIPTION: Command to install the Profiler plugin for TensorBoard using pip. Requires TensorFlow and TensorBoard versions 2.2 or higher.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -U tensorboard_plugin_profile\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Consistent Results with New Type Promotion in TensorFlow (Order 2)\nDESCRIPTION: This snippet confirms that changing the order of operations with the new type promotion system still produces the same result type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/tf_numpy_type_promotion.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# (b + a) + c also returns a f16 result.\ntf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>\n```\n\n----------------------------------------\n\nTITLE: Displaying TensorFlow Version Satisfaction Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when pip is unable to find a TensorFlow version that satisfies the installation requirements.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_18\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>Could not find a version that satisfies the requirement tensorflow</pre>\n```\n\n----------------------------------------\n\nTITLE: Setting Up License and Copyright for TensorFlow Hub\nDESCRIPTION: Establishes the copyright notice and Apache License 2.0 terms for the TensorFlow Hub Authors code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Configuring Checkpoints for Text Generation Model in TensorFlow\nDESCRIPTION: Sets up a ModelCheckpoint callback to save model weights during training, specifying the directory and file naming pattern for checkpoints.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Directory where the checkpoints will be saved\ncheckpoint_dir = './training_checkpoints'\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)\n```\n\n----------------------------------------\n\nTITLE: Displaying TensorFlow Pywrap Import Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs when the pywrap_tensorflow module cannot be imported, which is a critical component of TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>No module named \"pywrap_tensorflow\"</pre>\n```\n\n----------------------------------------\n\nTITLE: Loading License and Copyright Information in Python\nDESCRIPTION: Copyright and Apache 2.0 license declaration for TensorFlow Hub Authors\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/biggan_generation_with_tf_hub.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n```\n\n----------------------------------------\n\nTITLE: Implementing RandomAccessFile for POSIX Filesystem in C++\nDESCRIPTION: This snippet shows the implementation of the RandomAccessFile interface for the POSIX filesystem. It demonstrates how to handle file reading operations with error handling and retries.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\nclass PosixRandomAccessFile : public RandomAccessFile {\n public:\n  PosixRandomAccessFile(const string& fname, int fd)\n      : filename_(fname), fd_(fd) {}\n  ~PosixRandomAccessFile() override { close(fd_); }\n\n  Status Read(uint64 offset, size_t n, StringPiece* result,\n              char* scratch) const override {\n    Status s;\n    char* dst = scratch;\n    while (n > 0 && s.ok()) {\n      ssize_t r = pread(fd_, dst, n, static_cast<off_t>(offset));\n      if (r > 0) {\n        dst += r;\n        n -= r;\n        offset += r;\n      } else if (r == 0) {\n        s = Status(error::OUT_OF_RANGE, \"Read less bytes than requested\");\n      } else if (errno == EINTR || errno == EAGAIN) {\n        // Retry\n      } else {\n        s = IOError(filename_, errno);\n      }\n    }\n    *result = StringPiece(scratch, dst - scratch);\n    return s;\n  }\n\n private:\n  string filename_;\n  int fd_;\n};\n```\n\n----------------------------------------\n\nTITLE: Predicting with the Model (Python)\nDESCRIPTION: This snippet utilizes the model to make predictions on a sample batch of normalized training data, allowing for initial evaluation of its functionality.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_regression.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nexample_batch = normed_train_data[:10]\nexample_result = model.predict(example_batch)\nexample_result\n```\n\n----------------------------------------\n\nTITLE: Displaying Pip Build Error for Missing Setup File (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs during pip installation when the setup.py file cannot be found in the expected location.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>IOError: [Errno 2] No such file or directory:\n  '/tmp/pip-o6Tpui-build/setup.py'</pre>\n```\n\n----------------------------------------\n\nTITLE: Inspecting Layer Variables\nDESCRIPTION: Demonstrates how to access and inspect the variables (weights and biases) of a layer using the variables property.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Layers have many useful methods. For example, you can inspect all variables\n# in a layer using `layer.variables` and trainable variables using\n# `layer.trainable_variables`. In this case a fully-connected layer\n# will have variables for weights and biases.\nlayer.variables\n```\n\n----------------------------------------\n\nTITLE: Printing Dataset Elements\nDESCRIPTION: Shows how to iterate through the dataset and print each element after converting it to a NumPy array.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfor z in dataset1:\n  print(z.numpy())\n```\n\n----------------------------------------\n\nTITLE: Environment Step Function with TensorFlow\nDESCRIPTION: A function decorated with tf.numpy_function that executes a single environment step and returns state, reward and done flag. Converts environment outputs to appropriate numpy arrays.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@tf.numpy_function(Tout=[tf.float32, tf.int32, tf.int32])\ndef env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n\n  state, reward, done, truncated, info = env.step(action)\n  return (state.astype(np.float32),\n          np.array(reward, np.int32),\n          np.array(done, np.int32))\n```\n\n----------------------------------------\n\nTITLE: Running the C++ TensorFlow Label Image Example\nDESCRIPTION: This command runs the compiled label image example binary, utilizing the default image provided with the example for testing the model.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/images/image_recognition.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbazel-bin/tensorflow/examples/label_image/label_image\n```\n\n----------------------------------------\n\nTITLE: Loading the Selected HRNet Model\nDESCRIPTION: Loads the selected pre-trained HRNet model from TensorFlow Hub and confirms successful loading with a print statement.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/hrnet_semantic_segmentation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nhrnet_model = hub.load(tfhub_model_name)\n\nprint('HRNet model loaded           :', tfhub_model_name)\n```\n\n----------------------------------------\n\nTITLE: Loading TF-Flowers Dataset for Testing\nDESCRIPTION: Defines function to load and preprocess images from TF-Flowers dataset for testing BigBiGAN reconstruction.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/bigbigan_with_tf_hub.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef get_flowers_data():\n  \"\"\"Returns a [32, 256, 256, 3] np.array of preprocessed TF-Flowers samples.\"\"\"\n  import tensorflow_datasets as tfds\n  ds, info = tfds.load('tf_flowers', split='train', with_info=True)\n\n  # Just get the images themselves as we don't need labels for this demo.\n  ds = ds.map(lambda x: x['image'])\n\n  # Filter out small images (with minor edge length <256).\n  ds = ds.filter(lambda x: tf.reduce_min(tf.shape(x)[:2]) >= 256)\n\n  # Take the center square crop of the image and resize to 256x256.\n  def crop_and_resize(image):\n    imsize = tf.shape(image)[:2]\n    minor_edge = tf.reduce_min(imsize)\n    start = (imsize - minor_edge) // 2\n    stop = start + minor_edge\n    cropped_image = image[start[0] : stop[0], start[1] : stop[1]]\n    resized_image = tf.image.resize_bicubic([cropped_image], [256, 256])[0]\n    return resized_image\n  ds = ds.map(crop_and_resize)\n\n  # Convert images from [0, 255] uint8 to [-1, 1] float32.\n  ds = ds.map(lambda image: tf.cast(image, tf.float32) / (255. / 2.) - 1)\n\n  # Take the first 32 samples.\n  ds = ds.take(32)\n\n  return np.array(list(tfds.as_numpy(ds)))\n\ntest_images = get_flowers_data()\n```\n\n----------------------------------------\n\nTITLE: Building a SavedModel for serving using TensorFlow 1 simple_save\nDESCRIPTION: This snippet shows how to build a SavedModel for serving using the TensorFlow 1 simple_save API. It creates a graph that adds 2 to an input and saves it as a SavedModel.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/saved_model.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nremove_dir(\"simple-save\")\n\nwith tf.Graph().as_default() as g:\n  with tf1.Session() as sess:\n    input = tf1.placeholder(tf.float32, shape=[])\n    output = add_two(input)\n    print(\"add_two output: \", sess.run(output, {input: 3.}))\n\n    tf1.saved_model.simple_save(\n        sess, 'simple-save',\n        inputs={'input': input},\n        outputs={'output': output})\n```\n\n----------------------------------------\n\nTITLE: Licensing Header for TensorFlow Documentation\nDESCRIPTION: The Apache 2.0 license header that specifies the legal terms under which the TensorFlow documentation is distributed.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Custom Dense Layer Implementation for Model Compression\nDESCRIPTION: Defines a custom dense layer that can be used with entropy-penalized reparameterization. Includes a copy constructor to initialize from another layer instance, which is crucial for the compression workflow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass CustomDense(tf.keras.layers.Layer):\n\n  def __init__(self, filters, name=\"dense\"):\n    super().__init__(name=name)\n    self.filters = filters\n\n  @classmethod\n  def copy(cls, other, **kwargs):\n    \"\"\"Returns an instantiated and built layer, initialized from `other`.\"\"\"\n    self = cls(filters=other.filters, name=other.name, **kwargs)\n    self.build(None, other=other)\n    return self\n\n  def build(self, input_shape, other=None):\n    \"\"\"Instantiates weights, optionally initializing them from `other`.\"\"\"\n    if other is None:\n      kernel_shape = (input_shape[-1], self.filters)\n      kernel = tf.keras.initializers.GlorotUniform()(shape=kernel_shape)\n      bias = tf.keras.initializers.Zeros()(shape=(self.filters,))\n    else:\n      kernel, bias = other.kernel, other.bias\n    self.kernel = tf.Variable(\n        tf.cast(kernel, self.variable_dtype), name=\"kernel\")\n    self.bias = tf.Variable(\n        tf.cast(bias, self.variable_dtype), name=\"bias\")\n    self.built = True\n\n  def call(self, inputs):\n    outputs = tf.linalg.matvec(self.kernel, inputs, transpose_a=True)\n    outputs = tf.nn.bias_add(outputs, self.bias)\n    return tf.nn.leaky_relu(outputs)\n```\n\n----------------------------------------\n\nTITLE: Generating WAV Filename from MIDI File in Python\nDESCRIPTION: Creates a filename for the WAV output that will be generated from the MIDI file. It replaces spaces with underscores and adds '_midioutput.wav' suffix to the filename.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nwav_from_created_midi = converted_audio_file_as_midi.replace(' ', '_') + \"_midioutput.wav\"\nprint(wav_from_created_midi)\n```\n\n----------------------------------------\n\nTITLE: Upgrading Dropout Example with tf_upgrade_v2 in Bash\nDESCRIPTION: This command uses tf_upgrade_v2 to upgrade the dropout example file and generate a report.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntf_upgrade_v2 \\\n  --infile dropout.py \\\n  --outfile dropout_v2.py \\\n  --reportfile dropout_report.txt > /dev/null\n```\n\n----------------------------------------\n\nTITLE: Evaluating Tensors Using a TensorFlow Session\nDESCRIPTION: Creates a TensorFlow session and uses it to evaluate a tensor. The session provides the runtime environment for executing the computational graph and retrieving actual values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/low_level_intro.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsess = tf.Session()\nprint(sess.run(total))\n```\n\n----------------------------------------\n\nTITLE: Loading ImageNet Labels for Classification Results\nDESCRIPTION: Defines a function to load ImageNet labels from a file, which will be used to interpret the model's classification results.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef load_imagenet_labels(file_path):\n  labels_file = tf.keras.utils.get_file('ImageNetLabels.txt', file_path)\n  with open(labels_file) as reader:\n    f = reader.read()\n    labels = f.splitlines()\n  return np.array(labels)\n\nimagenet_labels = load_imagenet_labels('https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration for TensorFlow documentation\nSOURCE: https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running Docker with CUPTI Privileges\nDESCRIPTION: Docker run command with the --privileged option to resolve CUPTI privilege issues in a Docker environment.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/profiler.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker run option '--privileged=true'\n```\n\n----------------------------------------\n\nTITLE: Float16 Underflow Example\nDESCRIPTION: Demonstrates numeric underflow with float16 data type.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nx = tf.constant(1e-5, dtype='float16')\n(x ** 2).numpy()  # Underflow\n```\n\n----------------------------------------\n\nTITLE: Polymorphic Shape Function in C++\nDESCRIPTION: Advanced shape function implementation for ops with multiple inputs, demonstrating shape validation and merging across multiple tensors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/create_op.md#2025-04-21_snippet_44\n\nLANGUAGE: c++\nCODE:\n```\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      ::tensorflow::shape_inference::ShapeHandle input;\n      ::tensorflow::shape_inference::ShapeHandle output;\n      for (size_t i = 0; i < c->num_inputs(); ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 2, &input));\n        TF_RETURN_IF_ERROR(c->Merge(output, input, &output));\n      }\n      c->set_output(0, output);\n      return Status::OK();\n    });\n```\n\n----------------------------------------\n\nTITLE: Opening and Writing with gfile in Python\nDESCRIPTION: This Python snippet demonstrates how to open a file and write to it using the gfile module, which ties into the FileSystem implementation in TensorFlow. It requires the gfile module and a properly loaded filesystem library. The input is a file path using a custom protocol scheme, and the output results in a file with content written to the specified path on the shared filesystem.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/filesystem.md#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nwith gfile.Open(\"foobar://path/to/file.txt\") as w:\\n\\n  w.write(\"hi\")\n```\n\n----------------------------------------\n\nTITLE: Recording Summaries and Runtime Statistics in TensorFlow\nDESCRIPTION: This snippet demonstrates how to record summaries and runtime statistics during model training in TensorFlow. It shows how to capture test and train set accuracies, and how to periodically record execution stats using RunOptions and RunMetadata.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graph_viz.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n  # Train the model, and also write summaries.\n  # Every 10th step, measure test-set accuracy, and write test summaries\n  # All other steps, run train_step on training data, & add training summaries\n\n  def feed_dict(train):\n    \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n    if train or FLAGS.fake_data:\n      xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n      k = FLAGS.dropout\n    else:\n      xs, ys = mnist.test.images, mnist.test.labels\n      k = 1.0\n    return {x: xs, y_: ys, keep_prob: k}\n\n  for i in range(FLAGS.max_steps):\n    if i % 10 == 0:  # Record summaries and test-set accuracy\n      summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n      test_writer.add_summary(summary, i)\n      print('Accuracy at step %s: %s' % (i, acc))\n    else:  # Record train set summaries, and train\n      if i % 100 == 99:  # Record execution stats\n        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n        run_metadata = tf.RunMetadata()\n        summary, _ = sess.run([merged, train_step],\n                              feed_dict=feed_dict(True),\n                              options=run_options,\n                              run_metadata=run_metadata)\n        train_writer.add_run_metadata(run_metadata, 'step%d' % i)\n        train_writer.add_summary(summary, i)\n        print('Adding run metadata for', i)\n      else:  # Record a summary\n        summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))\n        train_writer.add_summary(summary, i)\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Documentation\nDESCRIPTION: A code block displaying the Apache 2.0 license that applies to this TensorFlow documentation. It outlines the terms under which the content can be used, distributed, and modified.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Using TensorFlow's register_types.h for Type Registration\nDESCRIPTION: Shows how to use the predefined type macros from register_types.h to register kernels for groups of related types (like all real number types) efficiently.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_29\n\nLANGUAGE: c++\nCODE:\n```\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n\nREGISTER_OP(\"ZeroOut\")\n    .Attr(\"T: realnumbertype\")\n    .Input(\"to_zero: T\")\n    .Output(\"zeroed: T\");\n\ntemplate <typename T>\nclass ZeroOutOp : public OpKernel { ... };\n\n#define REGISTER_KERNEL(type)                                       \\\n  REGISTER_KERNEL_BUILDER(                                          \\\n      Name(\"ZeroOut\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      ZeroOutOp<type>)\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Op with Polymorphic List Input\nDESCRIPTION: Demonstrates registering an op that accepts a list of tensors all of the same type, where that type is specified by a type attribute, making the op type-polymorphic.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/op.md#2025-04-21_snippet_33\n\nLANGUAGE: c++\nCODE:\n```\nREGISTER_OP(\"SameListInputExample\")\n    .Attr(\"N: int\")\n    .Attr(\"T: type\")\n    .Input(\"in: N * T\")\n    .Output(\"out: T\");\n```\n\n----------------------------------------\n\nTITLE: Variable Creation with tf.function\nDESCRIPTION: Example demonstrating how tf.function handles variable creation and why it fails when variables are created multiple times.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@tf.function\ndef f():\n  print(\"trace\") # This will print twice because the python body is run twice\n  v = tf.Variable(1.0)\n  return v\n\ntry:\n  f()\nexcept ValueError as e:\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Verifying Checkpoint Restoration Status\nDESCRIPTION: Demonstrates how to verify that objects were successfully restored from a checkpoint using the status object returned by the restore method.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/checkpoint.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nstatus.assert_existing_objects_matched()\n```\n\n----------------------------------------\n\nTITLE: Pushing Local Branch to GitHub in Bash\nDESCRIPTION: Command to push local changes to a remote GitHub repository for the TensorFlow docs project.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit push\n```\n\n----------------------------------------\n\nTITLE: Dataset Configuration Constants\nDESCRIPTION: Defines buffer size, batch size and validation size constants for dataset processing.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/text.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nBUFFER_SIZE = 50000\nBATCH_SIZE = 64\nVALIDATION_SIZE = 5000\n```\n\n----------------------------------------\n\nTITLE: Disabling Tensor Equality for TF1.x Behavior\nDESCRIPTION: Demonstrates how to disable tensor equality by value in TensorFlow 2.0 to preserve TensorFlow 1.x behavior where tensors are compared by reference.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\ntf.compat.v1.disable_tensor_equality()\nx = tf.Variable(0.0)\ny = tf.Variable(0.0)\n\nx == y\n```\n\n----------------------------------------\n\nTITLE: Defining URL for UCF101 Dataset\nDESCRIPTION: Sets the URL pointing to the zip file containing the UCF101 dataset stored in Google Cloud Storage.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/video.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nURL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\n```\n\n----------------------------------------\n\nTITLE: Setting Training Epochs for Text Generation in TensorFlow\nDESCRIPTION: Defines the number of training epochs for the text generation model, keeping it relatively small to maintain reasonable training time.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nEPOCHS=3\n```\n\n----------------------------------------\n\nTITLE: Setting up checkpoint printing utility function in Python\nDESCRIPTION: Defines a utility function to print the contents of a TensorFlow checkpoint, including variable names, shapes, data types and values.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_checkpoints.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tf1\n\ndef print_checkpoint(save_path):\n  reader = tf.train.load_checkpoint(save_path)\n  shapes = reader.get_variable_to_shape_map()\n  dtypes = reader.get_variable_to_dtype_map()\n  print(f\"Checkpoint at '{save_path}':\")\n  for key in shapes:\n    print(f\"  (key='{key}', shape={shapes[key]}, dtype={dtypes[key].name}, \"\n          f\"value={reader.get_tensor(key)})\") \n```\n\n----------------------------------------\n\nTITLE: Loading TensorFlow and NumPy libraries\nDESCRIPTION: Imports the necessary libraries for working with NumPy arrays and TensorFlow datasets.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport tensorflow as tf\n```\n\n----------------------------------------\n\nTITLE: Listing Files After Index Building in Python\nDESCRIPTION: This simple command lists the files in the current directory after the ANNOY index building process, showing the newly created index and mapping files.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_approximate_nearest_neighbors.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n!ls\n```\n\n----------------------------------------\n\nTITLE: Basic Python Code Block Example\nDESCRIPTION: Demonstrates the proper formatting for a Python code block in Markdown using triple backticks\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_style.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```python\n# some python code here\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Required Package for TensorFlow Tutorial\nDESCRIPTION: This code installs the 'portpicker' package, which is used in the tutorial for selecting available network ports.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\n!pip install portpicker\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Pip\nDESCRIPTION: Installing the scikit-image package required for image processing operations\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/tf_hub_delf_module.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install scikit-image\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Data Visualization in Python\nDESCRIPTION: Imports necessary Python libraries for data visualization, including itertools, collections, numpy, and matplotlib.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport itertools\nfrom collections import defaultdict\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Dataset and Variable Creation Causing Error\nDESCRIPTION: Example demonstrating how combining dataset and variable creation in tf.function can lead to scope errors.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/tf1_vs_tf2.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass Model(tf.Module):\n  def __init__(self):\n    self.v = None\n    self.dataset = None\n\n  @tf.function\n  def __call__(self):\n    print(\"trace\") # This will print twice because the python body is run twice\n    if self.v is None:\n      self.v = tf.Variable(0)\n    if self.dataset is None:\n      self.dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n    it = iter(self.dataset)\n    return [self.v, next(it)]\n\nm = Model()\ntry:\n  m()\nexcept TypeError as e:\n  print(e)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow with GPU Support on Linux\nDESCRIPTION: This command installs TensorFlow with CUDA support for GPU acceleration using pip.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/pip.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npip install tensorflow[and-cuda]\n```\n\n----------------------------------------\n\nTITLE: Plotting Model Predictions Before Training\nDESCRIPTION: Calls the plotting function to visualize the model's performance before training.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/basics.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nplot_preds(x, y, f, quad_model, 'Before training')\n```\n\n----------------------------------------\n\nTITLE: Displaying Pip Uninstall Permission Error (Markdown/HTML)\nDESCRIPTION: This snippet shows an error message that occurs during pip installation when there's a permission issue while trying to uninstall an existing package.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/install/errors.md#2025-04-21_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n<pre>\n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib' </pre>\n```\n\n----------------------------------------\n\nTITLE: Displaying tf_upgrade_v2 Help in Bash\nDESCRIPTION: This command shows the built-in help for the tf_upgrade_v2 script, which is installed with TensorFlow.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/upgrade.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntf_upgrade_v2 -h\n```\n\n----------------------------------------\n\nTITLE: Installing Python Audio Libraries\nDESCRIPTION: Installation of Python packages pydub, librosa, and music21 for audio handling.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/spice.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip install pydub librosa music21\n```\n\n----------------------------------------\n\nTITLE: Configuring License Header in Python\nDESCRIPTION: Apache License 2.0 header configuration for TensorFlow documentation.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Declaration for TensorFlow Compression\nDESCRIPTION: License declaration specifying that the code is licensed under Apache License 2.0, which governs usage, modification, and distribution terms.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/optimization/compression.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Header in Python\nDESCRIPTION: Standard Apache License 2.0 header that defines the legal terms for using the code in this document.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/checkpoint_saver.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Loading and Licensing the TensorFlow Code\nDESCRIPTION: This code block contains the Apache License 2.0 license information that governs the use of the TensorFlow tutorial code.\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Declaration - MIT\nDESCRIPTION: MIT license declaration for François Chollet's contributions\nSOURCE: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#@title MIT License\n#\n# Copyright (c) 2017 François Chollet\n#\n# Permission is hereby granted, free of charge, to any person obtaining a\n# copy of this software and associated documentation files (the \"Software\"),\n# to deal in the Software without restriction, including without limitation\n# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n# and/or sell copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n```"
  }
]