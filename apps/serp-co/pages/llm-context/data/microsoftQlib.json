[
  {
    "owner": "microsoft",
    "repo": "qlib",
    "content": "TITLE: Defining a Quantitative Research Workflow Configuration in YAML\nDESCRIPTION: A complete YAML configuration example for Qlib's workflow management system, defining data handling, model parameters, evaluation settings, and analysis configuration.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nqlib_init:\n    provider_uri: \"~/.qlib/qlib_data/cn_data\"\n    region: cn\nmarket: &market csi300\nbenchmark: &benchmark SH000300\ndata_handler_config: &data_handler_config\n    start_time: 2008-01-01\n    end_time: 2020-08-01\n    fit_start_time: 2008-01-01\n    fit_end_time: 2014-12-31\n    instruments: *market\nport_analysis_config: &port_analysis_config\n    strategy:\n        class: TopkDropoutStrategy\n        module_path: qlib.contrib.strategy.strategy\n        kwargs:\n            topk: 50\n            n_drop: 5\n            signal: <PRED>\n    backtest:\n        limit_threshold: 0.095\n        account: 100000000\n        benchmark: *benchmark\n        deal_price: close\n        open_cost: 0.0005\n        close_cost: 0.0015\n        min_cost: 5\ntask:\n    model:\n        class: LGBModel\n        module_path: qlib.contrib.model.gbdt\n        kwargs:\n            loss: mse\n            colsample_bytree: 0.8879\n            learning_rate: 0.0421\n            subsample: 0.8789\n            lambda_l1: 205.6999\n            lambda_l2: 580.9768\n            max_depth: 8\n            num_leaves: 210\n            num_threads: 20\n    dataset:\n        class: DatasetH\n        module_path: qlib.data.dataset\n        kwargs:\n            handler:\n                class: Alpha158\n                module_path: qlib.contrib.data.handler\n                kwargs: *data_handler_config\n            segments:\n                train: [2008-01-01, 2014-12-31]\n                valid: [2015-01-01, 2016-12-31]\n                test: [2017-01-01, 2020-08-01]\n    record:\n        - class: SignalRecord\n          module_path: qlib.workflow.record_temp\n          kwargs: {}\n        - class: PortAnaRecord\n          module_path: qlib.workflow.record_temp\n          kwargs:\n              config: *port_analysis_config\n```\n\n----------------------------------------\n\nTITLE: Initializing and Running LightGBM Model in Qlib\nDESCRIPTION: This snippet demonstrates how to initialize Qlib, set up a LightGBM model configuration, create a dataset, train the model, and generate predictions. It uses the Alpha158 data handler and SignalRecord for recording results.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/model.rst#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom qlib.contrib.model.gbdt import LGBModel\nfrom qlib.contrib.data.handler import Alpha158\nfrom qlib.utils import init_instance_by_config, flatten_dict\nfrom qlib.workflow import R\nfrom qlib.workflow.record_temp import SignalRecord, PortAnaRecord\n\nmarket = \"csi300\"\nbenchmark = \"SH000300\"\n\ndata_handler_config = {\n    \"start_time\": \"2008-01-01\",\n    \"end_time\": \"2020-08-01\",\n    \"fit_start_time\": \"2008-01-01\",\n    \"fit_end_time\": \"2014-12-31\",\n    \"instruments\": market,\n}\n\ntask = {\n    \"model\": {\n        \"class\": \"LGBModel\",\n        \"module_path\": \"qlib.contrib.model.gbdt\",\n        \"kwargs\": {\n            \"loss\": \"mse\",\n            \"colsample_bytree\": 0.8879,\n            \"learning_rate\": 0.0421,\n            \"subsample\": 0.8789,\n            \"lambda_l1\": 205.6999,\n            \"lambda_l2\": 580.9768,\n            \"max_depth\": 8,\n            \"num_leaves\": 210,\n            \"num_threads\": 20,\n        },\n    },\n    \"dataset\": {\n        \"class\": \"DatasetH\",\n        \"module_path\": \"qlib.data.dataset\",\n        \"kwargs\": {\n            \"handler\": {\n                \"class\": \"Alpha158\",\n                \"module_path\": \"qlib.contrib.data.handler\",\n                \"kwargs\": data_handler_config,\n            },\n            \"segments\": {\n                \"train\": (\"2008-01-01\", \"2014-12-31\"),\n                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\n                \"test\": (\"2017-01-01\", \"2020-08-01\"),\n            },\n        },\n    },\n}\n\n# model initialization\nmodel = init_instance_by_config(task[\"model\"])\ndataset = init_instance_by_config(task[\"dataset\"])\n\n# start exp\nwith R.start(experiment_name=\"workflow\"):\n    # train\n    R.log_params(**flatten_dict(task))\n    model.fit(dataset)\n\n    # prediction\n    recorder = R.get_recorder()\n    sr = SignalRecord(model, dataset, recorder)\n    sr.generate()\n```\n\n----------------------------------------\n\nTITLE: Implementing Complex Expressions in Qlib using Python\nDESCRIPTION: Demonstrate how to build and use complex expressions for feature calculation in Qlib using the Feature class and arithmetic operations.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data.ops import *\nf1 = Feature(\"high\") / Feature(\"close\")\nf2 = Feature(\"open\") / Feature(\"close\")\nf3 = f1 + f2\nf4 = f3 * f3 / f3\n\ndata = D.features([\"sh600519\"], [f4], start_time=\"20200101\")\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Training LightGBM Model with Qlib in Python\nDESCRIPTION: This snippet configures and trains a LightGBM model using Qlib's workflow. It sets up data handling, model parameters, and dataset configuration. The trained model is then saved using Qlib's experiment tracking feature.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndata_handler_config = {\n    \"start_time\": \"2008-01-01\",\n    \"end_time\": \"2020-08-01\",\n    \"fit_start_time\": \"2008-01-01\",\n    \"fit_end_time\": \"2014-12-31\",\n    \"instruments\": market,\n}\n\ntask = {\n    \"model\": {\n        \"class\": \"LGBModel\",\n        \"module_path\": \"qlib.contrib.model.gbdt\",\n        \"kwargs\": {\n            \"loss\": \"mse\",\n            \"colsample_bytree\": 0.8879,\n            \"learning_rate\": 0.0421,\n            \"subsample\": 0.8789,\n            \"lambda_l1\": 205.6999,\n            \"lambda_l2\": 580.9768,\n            \"max_depth\": 8,\n            \"num_leaves\": 210,\n            \"num_threads\": 20,\n        },\n    },\n    \"dataset\": {\n        \"class\": \"DatasetH\",\n        \"module_path\": \"qlib.data.dataset\",\n        \"kwargs\": {\n            \"handler\": {\n                \"class\": \"Alpha158\",\n                \"module_path\": \"qlib.contrib.data.handler\",\n                \"kwargs\": data_handler_config,\n            },\n            \"segments\": {\n                \"train\": (\"2008-01-01\", \"2014-12-31\"),\n                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\n                \"test\": (\"2017-01-01\", \"2020-08-01\"),\n            },\n        },\n    },\n}\n\n# model initialization\nmodel = init_instance_by_config(task[\"model\"])\ndataset = init_instance_by_config(task[\"dataset\"])\n\n# start exp to train model\nwith R.start(experiment_name=\"train_model\"):\n    R.log_params(**flatten_dict(task))\n    model.fit(dataset)\n    R.save_objects(trained_model=model)\n    rid = R.get_recorder().id\n```\n\n----------------------------------------\n\nTITLE: Loading Features with Multiple Filters in Qlib using Python\nDESCRIPTION: Retrieve features for a dynamically filtered stock pool using multiple filters (NameDFilter and ExpressionDFilter) within a specified time range and frequency.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\nfrom qlib.data.filter import NameDFilter, ExpressionDFilter\nnameDFilter = NameDFilter(name_rule_re='SH[0-9]{4}55')\nexpressionDFilter = ExpressionDFilter(rule_expression='$close>Ref($close,1)')\ninstruments = D.instruments(market='csi300', filter_pipe=[nameDFilter, expressionDFilter])\nfields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']\nD.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head().to_string()\n```\n\n----------------------------------------\n\nTITLE: Importing Qlib Modules and Setting Up Data in Python\nDESCRIPTION: This snippet imports necessary Qlib modules, sets up the data provider, and initializes Qlib with Chinese stock market data. It also defines the market and benchmark variables.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nimport pandas as pd\nfrom qlib.constant import REG_CN\nfrom qlib.utils import exists_qlib_data, init_instance_by_config\nfrom qlib.workflow import R\nfrom qlib.workflow.record_temp import SignalRecord, PortAnaRecord\nfrom qlib.utils import flatten_dict\n\n# use default data\n# NOTE: need to download data from remote: python scripts/get_data.py qlib_data_cn --target_dir ~/.qlib/qlib_data/cn_data\nprovider_uri = \"~/.qlib/qlib_data/cn_data\"  # target_dir\nif not exists_qlib_data(provider_uri):\n    print(f\"Qlib data is not found in {provider_uri}\")\n    sys.path.append(str(scripts_dir))\n    from get_data import GetData\n\n    GetData().qlib_data(target_dir=provider_uri, region=REG_CN)\nqlib.init(provider_uri=provider_uri, region=REG_CN)\n\nmarket = \"csi300\"\nbenchmark = \"SH000300\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing Analysis Results with Qlib in Python\nDESCRIPTION: This snippet loads the analysis results and generates various graphs for model performance evaluation. It includes position analysis, risk analysis, score IC, and overall model performance visualization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.contrib.report import analysis_model, analysis_position\nfrom qlib.data import D\n\nrecorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")\nprint(recorder)\npred_df = recorder.load_object(\"pred.pkl\")\nreport_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\npositions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\nanalysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")\n\n# analysis position\n## report\nanalysis_position.report_graph(report_normal_df)\n\n## risk analysis\nanalysis_position.risk_analysis_graph(analysis_df, report_normal_df)\n\n# analysis model\nlabel_df = dataset.prepare(\"test\", col_set=\"label\")\nlabel_df.columns = [\"label\"]\n\n## score IC\npred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\nanalysis_position.score_ic_graph(pred_label)\n\n## model performance\nanalysis_model.model_performance_graph(pred_label)\n```\n\n----------------------------------------\n\nTITLE: Initializing LGBM Model with Configuration\nDESCRIPTION: Creates a LightGBM model instance using a configuration dictionary that specifies model parameters like loss function, learning rate, and tree structure parameters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = init_instance_by_config(\n    {\n        \"class\": \"LGBModel\",\n        \"module_path\": \"qlib.contrib.model.gbdt\",\n        \"kwargs\": {\n            \"loss\": \"mse\",\n            \"colsample_bytree\": 0.8879,\n            \"learning_rate\": 0.0421,\n            \"subsample\": 0.8789,\n            \"lambda_l1\": 205.6999,\n            \"lambda_l2\": 580.9768,\n            \"max_depth\": 8,\n            \"num_leaves\": 210,\n            \"num_threads\": 20,\n        },\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing fit Method for LightGBM in Qlib\nDESCRIPTION: Example of implementing the fit method for a LightGBM-based model in Qlib. This method prepares training and validation datasets, creates LightGBM datasets, and trains the model with the specified parameters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/integration.rst#2025-04-07_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef fit(self, dataset: DatasetH, num_boost_round = 1000, **kwargs):\n\n    # prepare dataset for lgb training and evaluation\n    df_train, df_valid = dataset.prepare(\n        [\"train\", \"valid\"], col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_L\n    )\n    x_train, y_train = df_train[\"feature\"], df_train[\"label\"]\n    x_valid, y_valid = df_valid[\"feature\"], df_valid[\"label\"]\n\n    # Lightgbm need 1D array as its label\n    if y_train.values.ndim == 2 and y_train.values.shape[1] == 1:\n        y_train, y_valid = np.squeeze(y_train.values), np.squeeze(y_valid.values)\n    else:\n        raise ValueError(\"LightGBM doesn't support multi-label training\")\n\n    dtrain = lgb.Dataset(x_train.values, label=y_train)\n    dvalid = lgb.Dataset(x_valid.values, label=y_valid)\n\n    # fit the model\n    self.model = lgb.train(\n        self.params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        valid_sets=[dtrain, dvalid],\n        valid_names=[\"train\", \"valid\"],\n        early_stopping_rounds=early_stopping_rounds,\n        verbose_eval=verbose_eval,\n        evals_result=evals_result,\n        **kwargs\n    )\n```\n\n----------------------------------------\n\nTITLE: Training Model and Generating Signals\nDESCRIPTION: Initiates an experiment to train the model, save it, and generate trading signals. The recorder (R) manages experiment records and allows for retrieving the experiment ID.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# start exp to train model\nwith R.start(experiment_name=EXP_NAME):\n    model.fit(dataset)\n    R.save_objects(trained_model=model)\n\n    rec = R.get_recorder()\n    rid = rec.id  # save the record id\n\n    # Inference and saving signal\n    sr = SignalRecord(model, dataset, rec)\n    sr.generate()\n```\n\n----------------------------------------\n\nTITLE: Running Signal Analysis and Portfolio Backtest\nDESCRIPTION: Performs both signal-based analysis and portfolio-based analysis (backtest) using the previously trained model. Results are generated and saved through the recorder.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# backtest and analysis\nwith R.start(experiment_name=EXP_NAME, recorder_id=rid, resume=True):\n    # signal-based analysis\n    rec = R.get_recorder()\n    sar = SigAnaRecord(rec)\n    sar.generate()\n\n    #  portfolio-based analysis: backtest\n    par = PortAnaRecord(rec, port_analysis_config, \"day\")\n    par.generate()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Performance Metrics\nDESCRIPTION: Creates comprehensive visualizations of model performance using the predictions and actual labels to assess predictive accuracy.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nanalysis_model.model_performance_graph(pred_label)\n```\n\n----------------------------------------\n\nTITLE: Generating Position Report Graph\nDESCRIPTION: Creates a graphical representation of the portfolio performance report showing metrics like returns, drawdowns, and other performance indicators.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nanalysis_position.report_graph(report_normal_df)\n```\n\n----------------------------------------\n\nTITLE: Implementing Localformer Model Class in Python\nDESCRIPTION: Defines the Localformer class, a PyTorch neural network module for time series forecasting. It includes the model's architecture, forward pass, and initialization methods.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Localformer/README.md#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass Localformer(nn.Module):\n    def __init__(\n        self,\n        d_feat: int = 6,\n        d_model: int = 8,\n        nhead: int = 4,\n        num_layers: int = 2,\n        dropout: float = 0.5,\n        out_feat: int = 1,\n    ):\n        super(Localformer, self).__init__()\n        self.rnn = nn.GRU(input_size=d_feat, hidden_size=d_model, batch_first=True)\n        encoder_layer = TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True, dropout=dropout\n        )\n        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.linear1 = nn.Linear(d_model, d_model // 2)\n        self.linear2 = nn.Linear(d_model // 2, out_feat)\n        self.leaky_relu = nn.LeakyReLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = x.reshape(len(x), x.shape[-1], -1)\n        x = x.transpose(1, 2)\n        x, _ = self.rnn(x)\n        x = self.transformer_encoder(x)\n        x = x[:, -1, :]\n        x = self.leaky_relu(x)\n        x = self.linear1(x)\n        x = self.dropout(x)\n        x = self.leaky_relu(x)\n        return self.linear2(x).squeeze()\n```\n\n----------------------------------------\n\nTITLE: Importing QLib Workflow Components\nDESCRIPTION: Imports essential components from QLib's workflow module for handling records and signals.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.workflow import R\nfrom qlib.workflow.record_temp import SignalRecord, PortAnaRecord, SigAnaRecord\n```\n\n----------------------------------------\n\nTITLE: Generating Risk Analysis Graph\nDESCRIPTION: Produces a risk analysis visualization based on portfolio analysis data and report data to evaluate risk-adjusted performance.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nanalysis_position.risk_analysis_graph(analysis_df, report_normal_df)\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for LightGBM in Qlib\nDESCRIPTION: Example of a YAML configuration file section for a LightGBM model in Qlib. The configuration specifies the model class, module path, and hyperparameters that will be passed to the model's initialization method.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/integration.rst#2025-04-07_snippet_4\n\nLANGUAGE: YAML\nCODE:\n```\nmodel:\n    class: LGBModel\n    module_path: qlib.contrib.model.gbdt\n    args:\n        loss: mse\n        colsample_bytree: 0.8879\n        learning_rate: 0.0421\n        subsample: 0.8789\n        lambda_l1: 205.6999\n        lambda_l2: 580.9768\n        max_depth: 8\n        num_leaves: 210\n        num_threads: 20\n```\n\n----------------------------------------\n\nTITLE: Computing Score Information Coefficient (IC)\nDESCRIPTION: Calculates and visualizes the Information Coefficient between model predictions and actual labels, a key metric for evaluating prediction quality.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_17\n\nLANGUAGE: python\nCODE:\n```\npred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\nanalysis_position.score_ic_graph(pred_label)\n```\n\n----------------------------------------\n\nTITLE: Data Handler Example using Alpha158 in Python\nDESCRIPTION: Example demonstrates how to initialize and use the Alpha158 data handler in Qlib. It shows configuration setup and basic operations like fetching features and labels.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\nimport qlib\nfrom qlib.contrib.data.handler import Alpha158\n\ndata_handler_config = {\n    \"start_time\": \"2008-01-01\",\n    \"end_time\": \"2020-08-01\",\n    \"fit_start_time\": \"2008-01-01\",\n    \"fit_end_time\": \"2014-12-31\",\n    \"instruments\": \"csi300\",\n}\n\nif __name__ == \"__main__\":\n    qlib.init()\n    h = Alpha158(**data_handler_config)\n\n    # get all the columns of the data\n    print(h.get_cols())\n\n    # fetch all the labels\n    print(h.fetch(col_set=\"label\"))\n\n    # fetch all the features\n    print(h.fetch(col_set=\"feature\"))\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Models with Qlib Script\nDESCRIPTION: Example command for running all models for 10 iterations using run_all_model.py script. The script creates unique virtual environments for each model and stores experiment results like IC and backtest results.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npython run_all_model.py run 10\n```\n\n----------------------------------------\n\nTITLE: Backtesting and Analyzing Model Performance with Qlib in Python\nDESCRIPTION: This snippet performs backtesting and analysis on the trained model. It sets up a portfolio analysis configuration, generates predictions, and conducts backtesting. The results are recorded for further analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nport_analysis_config = {\n    \"executor\": {\n        \"class\": \"SimulatorExecutor\",\n        \"module_path\": \"qlib.backtest.executor\",\n        \"kwargs\": {\n            \"time_per_step\": \"day\",\n            \"generate_portfolio_metrics\": True,\n        },\n    },\n    \"strategy\": {\n        \"class\": \"TopkDropoutStrategy\",\n        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n        \"kwargs\": {\n            \"model\": model,\n            \"dataset\": dataset,\n            \"topk\": 50,\n            \"n_drop\": 5,\n        },\n    },\n    \"backtest\": {\n        \"start_time\": \"2017-01-01\",\n        \"end_time\": \"2020-08-01\",\n        \"account\": 100000000,\n        \"benchmark\": benchmark,\n        \"exchange_kwargs\": {\n            \"freq\": \"day\",\n            \"limit_threshold\": 0.095,\n            \"deal_price\": \"close\",\n            \"open_cost\": 0.0005,\n            \"close_cost\": 0.0015,\n            \"min_cost\": 5,\n        },\n    },\n}\n\n# backtest and analysis\nwith R.start(experiment_name=\"backtest_analysis\"):\n    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n    model = recorder.load_object(\"trained_model\")\n\n    # prediction\n    recorder = R.get_recorder()\n    ba_rid = recorder.id\n    sr = SignalRecord(model, dataset, recorder)\n    sr.generate()\n\n    # backtest & analysis\n    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n    par.generate()\n```\n\n----------------------------------------\n\nTITLE: Downloading Qlib Data for Different Regions and Intervals\nDESCRIPTION: These commands demonstrate how to download Qlib data for different regions (China, US, India) and time intervals (daily, minute) using the get_data.py script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# cn 1d\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n# cn 1min\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n# us 1d\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/us_data --region us --interval 1d\n# us 1min\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/us_data_1min --region us --interval 1min\n# in 1d\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/in_data --region in --interval 1d\n# in 1min\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/in_data_1min --region in --interval 1min\n```\n\n----------------------------------------\n\nTITLE: Implementing MACD Alpha using Qlib's Data Handler in Python\nDESCRIPTION: This code snippet demonstrates how to create a MACD (Moving Average Convergence/Divergence) alpha using Qlib's Data Handler. It defines the MACD expression, sets up data loader configuration, and loads the data for the CSI300 index from 2010 to 2017.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/advanced/alpha.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data.dataset.loader import QlibDataLoader\nMACD_EXP = '(EMA($close, 12) - EMA($close, 26))/$close - EMA((EMA($close, 12) - EMA($close, 26))/$close, 9)/$close'\nfields = [MACD_EXP] # MACD\nnames = ['MACD']\nlabels = ['Ref($close, -2)/Ref($close, -1) - 1'] # label\nlabel_names = ['LABEL']\ndata_loader_config = {\n    \"feature\": (fields, names),\n    \"label\": (labels, label_names)\n}\ndata_loader = QlibDataLoader(config=data_loader_config)\ndf = data_loader.load(instruments='csi300', start_time='2010-01-01', end_time='2017-12-31')\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Configuring Portfolio Backtest Parameters\nDESCRIPTION: Sets up a comprehensive configuration for portfolio backtesting, including executor settings, signal-based strategy parameters, and backtest parameters like time period, account size, and trading costs.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n###################################\n# prediction, backtest & analysis\n###################################\nport_analysis_config = {\n    \"executor\": {\n        \"class\": \"SimulatorExecutor\",\n        \"module_path\": \"qlib.backtest.executor\",\n        \"kwargs\": {\n            \"time_per_step\": \"day\",\n            \"generate_portfolio_metrics\": True,\n        },\n    },\n    \"strategy\": {\n        \"class\": \"TopkDropoutStrategy\",\n        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n        \"kwargs\": {\n            \"signal\": \"<PRED>\",\n            \"topk\": 50,\n            \"n_drop\": 5,\n        },\n    },\n    \"backtest\": {\n        \"start_time\": \"2017-01-01\",\n        \"end_time\": \"2020-08-01\",\n        \"account\": 100000000,\n        \"benchmark\": BENCHMARK,\n        \"exchange_kwargs\": {\n            \"freq\": \"day\",\n            \"limit_threshold\": 0.095,\n            \"deal_price\": \"close\",\n            \"open_cost\": 0.0005,\n            \"close_cost\": 0.0015,\n            \"min_cost\": 5,\n        },\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Crypto Data Collection Pipeline\nDESCRIPTION: Three-step process to download, normalize, and dump cryptocurrency data from Coingecko into QLib format. Downloads daily data from 2015 to 2021, normalizes it, and converts to binary format with price, volume, and market cap fields.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crypto/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# download from https://api.coingecko.com/api/v3/\npython collector.py download_data --source_dir ~/.qlib/crypto_data/source/1d --start 2015-01-01 --end 2021-11-30 --delay 1 --interval 1d\n\n# normalize\npython collector.py normalize_data --source_dir ~/.qlib/crypto_data/source/1d --normalize_dir ~/.qlib/crypto_data/source/1d_nor --interval 1d --date_field_name date\n\n# dump data\ncd qlib/scripts\npython dump_bin.py dump_all --csv_path ~/.qlib/crypto_data/source/1d_nor --qlib_dir ~/.qlib/qlib_data/crypto_data --freq day --date_field_name date --include_fields prices,total_volumes,market_caps\n```\n\n----------------------------------------\n\nTITLE: Loading Dynamic Instruments with Name Filter in Qlib using Python\nDESCRIPTION: Use a NameDFilter to dynamically filter instruments from a base market based on a regular expression rule. This example filters stocks with codes matching 'SH[0-9]{4}55'.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\nfrom qlib.data.filter import NameDFilter\nnameDFilter = NameDFilter(name_rule_re='SH[0-9]{4}55')\ninstruments = D.instruments(market='csi300', filter_pipe=[nameDFilter])\nD.list_instruments(instruments=instruments, start_time='2015-01-01', end_time='2016-02-15', as_list=True)\n```\n\n----------------------------------------\n\nTITLE: Performing Backtest with Trained Policy in Qlib RL\nDESCRIPTION: Demonstrates how to run a backtest using the trained policy. It initializes a simulator, applies the policy to get an action, and calculates the reward for a single step.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom tianshou.data import Batch\n\nsimulator = SimpleSimulator(100.0, NSTEPS)\nstate = simulator.get_state()\nobs = [{\"obs\": state_interpreter.interpret(state)}]\npolicy_out = policy(Batch(obs))\nact = float(action_interpreter.interpret(state, policy_out.act))\n\nsimulator.step(act)\nrew = float(reward(simulator.get_state()))\n\nprint(f\"Action = {act:.6f}, Reward = {rew:.6f}.\")\n```\n\n----------------------------------------\n\nTITLE: Backtesting a Portfolio Strategy with backtest_daily in Python\nDESCRIPTION: Example of running a backtest using the TopkDropoutStrategy with backtest_daily function. It demonstrates how to configure the strategy, run the backtest, and analyze the results with risk metrics.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/strategy.rst#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\nimport qlib\nimport pandas as pd\nfrom qlib.utils.time import Freq\nfrom qlib.utils import flatten_dict\nfrom qlib.contrib.evaluate import backtest_daily\nfrom qlib.contrib.evaluate import risk_analysis\nfrom qlib.contrib.strategy import TopkDropoutStrategy\n\n# init qlib\nqlib.init(provider_uri=<qlib data dir>)\n\nCSI300_BENCH = \"SH000300\"\nSTRATEGY_CONFIG = {\n    \"topk\": 50,\n    \"n_drop\": 5,\n    # pred_score, pd.Series\n    \"signal\": pred_score,\n}\n\n\nstrategy_obj = TopkDropoutStrategy(**STRATEGY_CONFIG)\nreport_normal, positions_normal = backtest_daily(\n    start_time=\"2017-01-01\", end_time=\"2020-08-01\", strategy=strategy_obj\n)\nanalysis = dict()\n# default frequency will be daily (i.e. \"day\")\nanalysis[\"excess_return_without_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"])\nanalysis[\"excess_return_with_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"] - report_normal[\"cost\"])\n\nanalysis_df = pd.concat(analysis)  # type: pd.DataFrame\npprint(analysis_df)\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Running RL Training Workflow with Qlib\nDESCRIPTION: Configures and launches the training workflow using the previously defined components. It sets up training parameters, checkpointing, and initiates the training process.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom typing import cast\nfrom qlib.rl.trainer import Checkpoint, train\n\nNSTEPS = 10\n\ntrainer_kwargs = {\n    \"max_iters\": 10,\n    \"finite_env_type\": \"dummy\",\n    \"callbacks\": [\n        Checkpoint(\n            dirpath=Path(\"./checkpoints\"),\n            every_n_iters=1,\n            save_latest=\"copy\",\n        )\n    ],\n}\nvessel_kwargs = {\n    \"update_kwargs\": {\"batch_size\": 16, \"repeat\": 5},\n    \"episode_per_iter\": 50,\n}\n\nprint(\"Training started\")\ntrain(\n    simulator_fn=lambda position: SimpleSimulator(position, NSTEPS),\n    state_interpreter=state_interpreter,\n    action_interpreter=action_interpreter,\n    policy=policy,\n    reward=reward,\n    initial_states=cast(List[float], SimpleDataset([10.0, 50.0, 100.0])),\n    trainer_kwargs=trainer_kwargs,\n    vessel_kwargs=vessel_kwargs,\n)\nprint(\"Training finished\")\n```\n\n----------------------------------------\n\nTITLE: Downloading US Stock Data in Qlib Format\nDESCRIPTION: Command to download US stock market data in Qlib's binary format\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/us_data --region us\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running Portfolio Backtest\nDESCRIPTION: Sets up backtest configuration including time period, account size, benchmark, and trading costs. Executes the TopkDropoutStrategy and analyzes portfolio performance using risk metrics.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/strategy.rst#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbacktest_config = {\n    \"start_time\": \"2017-01-01\",\n    \"end_time\": \"2020-08-01\",\n    \"account\": 100000000,\n    \"benchmark\": CSI300_BENCH,\n    \"exchange_kwargs\": {\n        \"freq\": FREQ,\n        \"limit_threshold\": 0.095,\n        \"deal_price\": \"close\",\n        \"open_cost\": 0.0005,\n        \"close_cost\": 0.0015,\n        \"min_cost\": 5,\n    },\n}\n\n# strategy object\nstrategy_obj = TopkDropoutStrategy(**STRATEGY_CONFIG)\n# executor object\nexecutor_obj = executor.SimulatorExecutor(**EXECUTOR_CONFIG)\n# backtest\nportfolio_metric_dict, indicator_dict = backtest(executor=executor_obj, strategy=strategy_obj, **backtest_config)\n```\n\n----------------------------------------\n\nTITLE: Downloading YahooFinance Data with Python\nDESCRIPTION: Python command to download stock data from YahooFinance API. It allows specifying parameters such as source directory, interval, region, date range, and concurrency.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py download_data --source_dir ~/.qlib/stock_data/source/cn_data --start 2020-01-01 --end 2020-12-31 --delay 1 --interval 1d --region CN\n```\n\n----------------------------------------\n\nTITLE: Advanced Portfolio Strategy Backtesting with Custom Executor in Python\nDESCRIPTION: Example of a more detailed backtest setup that allows users to have more control over their strategies, such as using an advanced version of the executor. It demonstrates how to configure the strategy and executor components.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/strategy.rst#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\nimport qlib\nimport pandas as pd\nfrom qlib.utils.time import Freq\nfrom qlib.utils import flatten_dict\nfrom qlib.backtest import backtest, executor\nfrom qlib.contrib.evaluate import risk_analysis\nfrom qlib.contrib.strategy import TopkDropoutStrategy\n\n# init qlib\nqlib.init(provider_uri=<qlib data dir>)\n\nCSI300_BENCH = \"SH000300\"\n# Benchmark is for calculating the excess return of your strategy.\n# Its data format will be like **ONE normal instrument**.\n# For example, you can query its data with the code below\n# `D.features([\"SH000300\"], [\"$close\"], start_time='2010-01-01', end_time='2017-12-31', freq='day')`\n# It is different from the argument `market`, which indicates a universe of stocks (e.g. **A SET** of stocks like csi300)\n# For example, you can query all data from a stock market with the code below.\n# ` D.features(D.instruments(market='csi300'), [\"$close\"], start_time='2010-01-01', end_time='2017-12-31', freq='day')`\n\nFREQ = \"day\"\nSTRATEGY_CONFIG = {\n    \"topk\": 50,\n    \"n_drop\": 5,\n    # pred_score, pd.Series\n    \"signal\": pred_score,\n}\n\nEXECUTOR_CONFIG = {\n    \"time_per_step\": \"day\",\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Trained Model from Recorder\nDESCRIPTION: Demonstrates how to load a previously trained model from the recorder, though notes that it's not used in the current context.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Previous Model can be loaded. but it is not used.\nloaded_model = recorder.load_object(\"trained_model\")\nloaded_model\n```\n\n----------------------------------------\n\nTITLE: Qlib Init Configuration Example\nDESCRIPTION: Basic configuration parameters for initializing Qlib, specifying the data provider URI and region for stock market data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_3\n\nLANGUAGE: YAML\nCODE:\n```\nprovider_uri: \"~/.qlib/qlib_data/cn_data\"\nregion: cn\n```\n\n----------------------------------------\n\nTITLE: Downloading Pre-built Qlib Data\nDESCRIPTION: Commands to download and extract pre-built Qlib binary data files to the default Qlib data directory. This provides a quick way to get started with historical financial data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crowd_source/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz\ntar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with Basic Configuration\nDESCRIPTION: Code snippet for initializing Qlib with essential parameters. It sets the data provider URI and region to use the Chinese stock market data. This must be executed before calling other Qlib APIs.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/initialization.rst#2025-04-07_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport qlib\n# region in [REG_CN, REG_US]\nfrom qlib.constant import REG_CN\nprovider_uri = \"~/.qlib/qlib_data/cn_data\"  # target_dir\nqlib.init(provider_uri=provider_uri, region=REG_CN)\n```\n\n----------------------------------------\n\nTITLE: Portfolio Performance Analysis Results\nDESCRIPTION: Shows the structure of backtest results including excess returns metrics both with and without trading costs. Includes metrics like mean return, standard deviation, annualized return, information ratio, and maximum drawdown.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/strategy.rst#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n                                                  risk\nexcess_return_without_cost mean               0.000605\n                           std                0.005481\n                           annualized_return  0.152373\n                           information_ratio  1.751319\n                           max_drawdown      -0.059055\nexcess_return_with_cost    mean               0.000410\n                           std                0.005478\n                           annualized_return  0.103265\n                           information_ratio  1.187411\n                           max_drawdown      -0.075024\n```\n\n----------------------------------------\n\nTITLE: Importing Analysis Modules\nDESCRIPTION: Imports specialized modules from QLib for analyzing models and positions, which provide visualization and evaluation capabilities.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.contrib.report import analysis_model, analysis_position\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib for China Stock Mode\nDESCRIPTION: Shows how to initialize Qlib for use with Chinese stock data, specifying the data provider and region.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.constant import REG_CN\nqlib.init(provider_uri='~/.qlib/qlib_data/cn_data', region=REG_CN)\n```\n\n----------------------------------------\n\nTITLE: Running CSI500 Benchmark with LightGBM\nDESCRIPTION: Commands to setup and run LightGBM model benchmarks on the CSI500 dataset. Shows how to create config files, modify benchmark settings, and execute single or multiple model runs.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/benchmarks/LightGBM\npip install -r requirements.txt\n\n# create new config and set the benchmark to csi500\ncp workflow_config_lightgbm_Alpha158.yaml workflow_config_lightgbm_Alpha158_csi500.yaml\nsed -i \"s/csi300/csi500/g\"  workflow_config_lightgbm_Alpha158_csi500.yaml\nsed -i \"s/SH000300/SH000905/g\"  workflow_config_lightgbm_Alpha158_csi500.yaml\n\n# you can either run the model once\nqrun workflow_config_lightgbm_Alpha158_csi500.yaml\n\n# or run it for multiple times automatically and get the summarized results.\ncd  ../../\npython run_all_model.py run 3 lightgbm Alpha158 csi500  # for models with randomness.  please run it for 20 times.\n```\n\n----------------------------------------\n\nTITLE: Implementing an Action Interpreter for Qlib RL in Python\nDESCRIPTION: Defines a 'SimpleActionInterpreter' class that converts the agent's discrete action into a continuous action for the simulator. It divides the simulator's value into N parts and maps the agent's integer action to a float value.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.rl.interpreter import ActionInterpreter\n\n\nclass SimpleActionInterpreter(ActionInterpreter[State, int, float]):\n    def __init__(self, n_value: int) -> None:\n        self.n_value = n_value\n\n    @property\n    def action_space(self) -> spaces.Discrete:\n        return spaces.Discrete(self.n_value + 1)\n\n    def interpret(self, simulator_state: State, action: int) -> float:\n        assert 0 <= action <= self.n_value\n        # simulator_state.value is used as the denominator\n        return simulator_state.value * (action / self.n_value)\n\n\naction_interpreter = SimpleActionInterpreter(n_value=10)\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with MongoDB Support\nDESCRIPTION: Code snippet demonstrating Qlib initialization with MongoDB configuration. This setup enables features like Task Management with high performance and clustered processing capabilities.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/initialization.rst#2025-04-07_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nqlib.init(provider_uri=provider_uri, region=REG_CN, mongo={\n    \"task_url\": \"mongodb://localhost:27017/\",  # your mongo url\n    \"task_db_name\": \"rolling_db\", # the database name of Task Management\n})\n```\n\n----------------------------------------\n\nTITLE: Running Backtest Analysis in PortAnaRecord\nDESCRIPTION: Example showing how to perform backtest analysis using TopkDropoutStrategy and risk analysis for a trading strategy, including configuration for backtest parameters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/recorder.rst#2025-04-07_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom qlib.contrib.strategy.strategy import TopkDropoutStrategy\nfrom qlib.contrib.evaluate import (\n    backtest as normal_backtest,\n    risk_analysis,\n)\n\n# backtest\nSTRATEGY_CONFIG = {\n    \"topk\": 50,\n    \"n_drop\": 5,\n}\nBACKTEST_CONFIG = {\n    \"limit_threshold\": 0.095,\n    \"account\": 100000000,\n    \"benchmark\": BENCHMARK,\n    \"deal_price\": \"close\",\n    \"open_cost\": 0.0005,\n    \"close_cost\": 0.0015,\n    \"min_cost\": 5,\n}\n\nstrategy = TopkDropoutStrategy(**STRATEGY_CONFIG)\nreport_normal, positions_normal = normal_backtest(pred_score, strategy=strategy, **BACKTEST_CONFIG)\n\n# analysis\nanalysis = dict()\nanalysis[\"excess_return_without_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"])\nanalysis[\"excess_return_with_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"] - report_normal[\"cost\"])\nanalysis_df = pd.concat(analysis)  # type: pd.DataFrame\nprint(analysis_df)\n```\n\n----------------------------------------\n\nTITLE: Creating a State Interpreter for Qlib RL in Python\nDESCRIPTION: Implements a 'SimpleStateInterpreter' class that converts the simulator's state into a format understood by the agent. It transforms the state value into a 1D Numpy array.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Tuple\nimport numpy as np\nfrom gym import spaces\nfrom qlib.rl.interpreter import StateInterpreter\n\n\nclass SimpleStateInterpreter(StateInterpreter[Tuple[float, float], np.ndarray]):\n    def interpret(self, state: State) -> np.ndarray:\n        # Convert state.value to a 1D Numpy array\n        # last_action is not used by agents.\n        return np.array([state.value], dtype=np.float32)\n\n    @property\n    def observation_space(self) -> spaces.Box:\n        return spaces.Box(0, np.inf, shape=(1,), dtype=np.float32)\n\n\nstate_interpreter = SimpleStateInterpreter()\n```\n\n----------------------------------------\n\nTITLE: Loading Experiment Recorder by ID\nDESCRIPTION: Retrieves the experiment recorder using the recorder ID and experiment name to access previously saved results.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# load recorder\nrecorder = R.get_recorder(recorder_id=rid, experiment_name=EXP_NAME)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Dataset for Qlib RL Training in Python\nDESCRIPTION: Implements a 'SimpleDataset' class that provides initial positions for creating multiple simulators. This allows for parallel training environments with different starting conditions.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom torch.utils.data import Dataset\n\n\nclass SimpleDataset(Dataset):\n    def __init__(self, positions: List[float]) -> None:\n        self.positions = positions\n\n    def __len__(self) -> int:\n        return len(self.positions)\n\n    def __getitem__(self, index: int) -> float:\n        return self.positions[index]\n\n\ndataset = SimpleDataset(positions=[10.0, 50.0, 100.0])\n```\n\n----------------------------------------\n\nTITLE: Initializing Backtesting Functions and Utilities\nDESCRIPTION: Sets up core backtesting functionality including data processing, metrics calculation and visualization settings. Includes functions for calculating performance metrics like MSE, MAE, IC and Sharpe ratio.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/Reports.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%matplotlib inline\nimport glob\nimport numpy as np\nimport pandas as pd\nimport json\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nsns.set(style=\"white\")\nmatplotlib.rcParams[\"pdf.fonttype\"] = 42\nmatplotlib.rcParams[\"ps.fonttype\"] = 42\n\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\n\n\ndef func(x, N=80):\n    ret = x.ret.copy()\n    x = x.rank(pct=True)\n    x[\"ret\"] = ret\n    diff = x.score.sub(x.label)\n    r = x.nlargest(N, columns=\"score\").ret.mean()\n    r -= x.nsmallest(N, columns=\"score\").ret.mean()\n    return pd.Series(\n        {\n            \"MSE\": diff.pow(2).mean(),\n            \"MAE\": diff.abs().mean(),\n            \"IC\": x.score.corr(x.label),\n            \"R\": r,\n        }\n    )\n\n\nret = pd.read_pickle(\"data/ret.pkl\").clip(-0.1, 0.1)\n\n\ndef backtest(fname, **kwargs):\n    pred = pd.read_pickle(fname).loc[\"2018-09-21\":\"2020-06-30\"]  # test period\n    pred[\"ret\"] = ret\n    dates = pred.index.unique(level=0)\n    res = Parallel(n_jobs=-1)(delayed(func)(pred.loc[d], **kwargs) for d in dates)\n    res = {dates[i]: res[i] for i in range(len(dates))}\n    res = pd.DataFrame(res).T\n    r = res[\"R\"].copy()\n    r.index = pd.to_datetime(r.index)\n    r = r.reindex(pd.date_range(r.index[0], r.index[-1])).fillna(0)  # paper use 365 days\n    return {\n        \"MSE\": res[\"MSE\"].mean(),\n        \"MAE\": res[\"MAE\"].mean(),\n        \"IC\": res[\"IC\"].mean(),\n        \"ICIR\": res[\"IC\"].mean() / res[\"IC\"].std(),\n        \"AR\": r.mean() * 365,\n        \"AV\": r.std() * 365**0.5,\n        \"SR\": r.mean() / r.std() * 365**0.5,\n        \"MDD\": (r.cumsum().cummax() - r.cumsum()).max(),\n    }, r\n\n\ndef fmt(x, p=3, scale=1, std=False):\n    _fmt = \"{:.%df}\" % p\n    string = _fmt.format((x.mean() if not isinstance(x, (float, np.floating)) else x) * scale)\n    if std and len(x) > 1:\n        string += \" (\" + _fmt.format(x.std() * scale) + \")\"\n    return string\n\n\ndef backtest_multi(files, **kwargs):\n    res = []\n    pnl = []\n    for fname in files:\n        metric, r = backtest(fname, **kwargs)\n        res.append(metric)\n        pnl.append(r)\n    res = pd.DataFrame(res)\n    pnl = pd.concat(pnl, axis=1)\n    return {\n        \"MSE\": fmt(res[\"MSE\"], std=True),\n        \"MAE\": fmt(res[\"MAE\"], std=True),\n        \"IC\": fmt(res[\"IC\"]),\n        \"ICIR\": fmt(res[\"ICIR\"]),\n        \"AR\": fmt(res[\"AR\"], scale=100, p=1) + \"%\",\n        \"VR\": fmt(res[\"AV\"], scale=100, p=1) + \"%\",\n        \"SR\": fmt(res[\"SR\"]),\n        \"MDD\": fmt(res[\"MDD\"], scale=100, p=1) + \"%\",\n    }, pnl\n```\n\n----------------------------------------\n\nTITLE: Checking Data Health for 1-Minute Data in Qlib\nDESCRIPTION: Runs a script to check the health of 1-minute interval stock data, including missing values and large step changes.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data_1min --freq 1min\n```\n\n----------------------------------------\n\nTITLE: Configuring Record Templates in Qlib\nDESCRIPTION: YAML configuration for Record templates in Qlib, including SignalRecord and PortAnaRecord classes. These templates are used for recording and analyzing trading signals and portfolio performance.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nrecord:\n    - class: SignalRecord\n      module_path: qlib.workflow.record_temp\n      kwargs: {}\n    - class: PortAnaRecord\n      module_path: qlib.workflow.record_temp\n      kwargs:\n        config: *port_analysis_config\n```\n\n----------------------------------------\n\nTITLE: Checking Data Health\nDESCRIPTION: Commands to verify the health and integrity of the Qlib dataset\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data\n\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20\n```\n\n----------------------------------------\n\nTITLE: Portfolio Analysis and Backtest Configuration Example\nDESCRIPTION: Configuration for backtest settings and trading strategy implementation, defining parameters for investment decisions and transaction costs.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_6\n\nLANGUAGE: YAML\nCODE:\n```\nport_analysis_config: &port_analysis_config\n    strategy:\n        class: TopkDropoutStrategy\n        module_path: qlib.contrib.strategy.strategy\n        kwargs:\n            topk: 50\n            n_drop: 5\n            signal: <PRED>\n    backtest:\n        limit_threshold: 0.095\n        account: 100000000\n```\n\n----------------------------------------\n\nTITLE: Loading Dynamic Instruments with Expression Filter in Qlib using Python\nDESCRIPTION: Use an ExpressionDFilter to dynamically filter instruments from a base market based on a custom expression. This example filters stocks with closing prices above 2000.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\nfrom qlib.data.filter import ExpressionDFilter\nexpressionDFilter = ExpressionDFilter(rule_expression='$close>2000')\ninstruments = D.instruments(market='csi300', filter_pipe=[expressionDFilter])\nD.list_instruments(instruments=instruments, start_time='2015-01-01', end_time='2016-02-15', as_list=True)\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib for US Stock Mode\nDESCRIPTION: Shows how to initialize Qlib for use with US stock data, specifying the data provider and region.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.config import REG_US\nqlib.init(provider_uri='~/.qlib/qlib_data/us_data', region=REG_US)\n```\n\n----------------------------------------\n\nTITLE: Loading Analysis Results from Recorder\nDESCRIPTION: Loads various analysis objects that were previously saved during backtesting, including predictions, reports, positions, and portfolio analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# load previous results\npred_df = recorder.load_object(\"pred.pkl\")\nreport_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\npositions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\nanalysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")\n```\n\n----------------------------------------\n\nTITLE: Loading Features for Specific Instruments in Qlib using Python\nDESCRIPTION: Retrieve features for a given set of instruments and fields within a specified time range and frequency using Qlib's Data module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\ninstruments = ['SH600000']\nfields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']\nD.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head().to_string()\n```\n\n----------------------------------------\n\nTITLE: Creating Data Handler Configuration\nDESCRIPTION: Sets up configuration for Alpha158 data handler with specific time ranges and market instruments.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nhandler_kwargs = {\n    \"start_time\": \"2008-01-01\",\n    \"end_time\": \"2020-08-01\",\n    \"fit_start_time\": \"2008-01-01\",\n    \"fit_end_time\": \"2014-12-31\",\n    \"instruments\": MARKET,\n}\nhandler_conf = {\n    \"class\": \"Alpha158\",\n    \"module_path\": \"qlib.contrib.data.handler\",\n    \"kwargs\": handler_kwargs,\n}\n```\n\n----------------------------------------\n\nTITLE: Running Qlib Workflow\nDESCRIPTION: Execute a complete quant research workflow using LightGBM model configuration\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/introduction/quick.rst#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd examples\nqrun benchmarks/LightGBM/workflow_config_lightgbm.yaml\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib for Data Retrieval in Python\nDESCRIPTION: Initialize Qlib with a specific data provider URI to access stock data. This step is necessary before performing any data retrieval operations.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nqlib.init(provider_uri='~/.qlib/qlib_data/cn_data')\n```\n\n----------------------------------------\n\nTITLE: Dumping Normalized Data to Qlib Format with Python\nDESCRIPTION: Python command to convert normalized CSV data into Qlib's binary format. It processes the data and stores it as numpy arrays, with one file per column and one directory per symbol.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython dump_bin.py dump_all --csv_path ~/.qlib/stock_data/source/cn_1d_nor --qlib_dir ~/.qlib/qlib_data/cn_data --freq day --exclude_fields date,symbol\n```\n\n----------------------------------------\n\nTITLE: Running TFT Benchmark Workflow in Python\nDESCRIPTION: Instructions for running the Temporal Fusion Transformers benchmark using the workflow_by_code_tft.py script. The code requires Python 3.6-3.7, CUDA 10.0, a GPU, and proper dataset registration in data_formatters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TFT/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda install anaconda cudatoolkit=10.0\nconda install cudnn\n```\n\n----------------------------------------\n\nTITLE: Retrieving Financial Data with qlib for Different Regions and Frequencies\nDESCRIPTION: This code demonstrates how to initialize qlib with different data providers and retrieve financial data for Chinese and US markets at daily and 1-minute frequencies. It shows how to access close prices for all instruments or a subset of instruments.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.data import D\n\n# 1d data cn\n# freq=day, freq default day\nqlib.init(provider_uri=\"~/.qlib/qlib_data/cn_data\", region=\"cn\")\ndf = D.features(D.instruments(\"all\"), [\"$close\"], freq=\"day\")\n\n# 1min data cn\n# freq=1min\nqlib.init(provider_uri=\"~/.qlib/qlib_data/cn_data_1min\", region=\"cn\")\ninst = D.list_instruments(D.instruments(\"all\"), freq=\"1min\", as_list=True)\n# get 100 symbols\ndf = D.features(inst[:100], [\"$close\"], freq=\"1min\")\n# get all symbol data\n# df = D.features(D.instruments(\"all\"), [\"$close\"], freq=\"1min\")\n\n# 1d data us\nqlib.init(provider_uri=\"~/.qlib/qlib_data/us_data\", region=\"us\")\ndf = D.features(D.instruments(\"all\"), [\"$close\"], freq=\"day\")\n\n# 1min data us\nqlib.init(provider_uri=\"~/.qlib/qlib_data/us_data_1min\", region=\"cn\")\ninst = D.list_instruments(D.instruments(\"all\"), freq=\"1min\", as_list=True)\n# get 100 symbols\ndf = D.features(inst[:100], [\"$close\"], freq=\"1min\")\n# get all symbol data\n# df = D.features(D.instruments(\"all\"), [\"$close\"], freq=\"1min\")\n```\n\n----------------------------------------\n\nTITLE: Normalizing Baostock Data\nDESCRIPTION: Normalizes the downloaded stock data using daily data reference and adjusts prices based on the first valid trading date.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/baostock_5min/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py normalize_data --qlib_data_1d_dir ~/.qlib/qlib_data/cn_data --source_dir ~/.qlib/stock_data/source/hs300_5min_original --normalize_dir ~/.qlib/stock_data/source/hs300_5min_nor --region HS300 --interval 5min\n```\n\n----------------------------------------\n\nTITLE: Parsing Market Name into Stock Pool Config in Qlib using Python\nDESCRIPTION: Convert a market name into a stock pool configuration using Qlib's instruments function. This example shows how to parse the 'all' market.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\nD.instruments(market='all')\n```\n\n----------------------------------------\n\nTITLE: Downloading Quarterly Chinese Stock Data\nDESCRIPTION: Downloads quarterly stock data from baostock.com for a specified time period. Includes option for full dataset or filtered by specific stock symbols.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/pit/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd qlib/scripts/data_collector/pit/\n# download from baostock.com\npython collector.py download_data --source_dir ~/.qlib/stock_data/source/pit --start 2000-01-01 --end 2020-01-01 --interval quarterly\n```\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py download_data --source_dir ~/.qlib/stock_data/source/pit --start 2000-01-01 --end 2020-01-01 --interval quarterly --symbol_regex \"^(600519|000725).*\"\n```\n\n----------------------------------------\n\nTITLE: Importing Example Data to MongoDB for Qlib Analysis\nDESCRIPTION: These Python commands initialize the libraries and import the downloaded data into MongoDB for further analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/orderbook_data/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython create_dataset.py initialize_library  # Initialization Libraries\npython create_dataset.py import_data  # Initialization Libraries\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Experiment Paths\nDESCRIPTION: Sets up file paths for different model experiments including Linear, LightGBM, MLP, SFM, ALSTM and Transformer variants. Uses glob patterns to collect multiple experiment runs.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/Reports.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nexps = {\n    \"Linear\": [\"output/Linear/pred.pkl\"],\n    \"LightGBM\": [\"output/GBDT/lr0.05_leaves128/pred.pkl\"],\n    \"MLP\": glob.glob(\"output/search/MLP/hs128_bs512_do0.3_lr0.001_seed*/pred.pkl\"),\n    \"SFM\": glob.glob(\"output/search/SFM/hs32_bs512_do0.5_lr0.001_seed*/pred.pkl\"),\n    \"ALSTM\": glob.glob(\"output/search/LSTM_Attn/hs256_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n    \"Trans.\": glob.glob(\"output/search/Transformer/head4_hs64_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n    \"ALSTM+TS\": glob.glob(\"output/LSTM_Attn_TS/hs256_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n    \"Trans.+TS\": glob.glob(\"output/Transformer_TS/head4_hs64_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n    \"ALSTM+TRA(Ours)\": glob.glob(\n        \"output/search/finetune/LSTM_Attn_tra/K10_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n    ),\n    \"Trans.+TRA(Ours)\": glob.glob(\n        \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb1.0_head4_hs64_bs512_do0.1_lr0.0005_seed*/pred.pkl\"\n    ),\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing a PPO Policy with a Simple Neural Network for Qlib RL\nDESCRIPTION: Defines a simple fully connected neural network and uses it to create a PPO (Proximal Policy Optimization) policy. This policy will be used by the agent to make decisions.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nimport torch\nfrom torch import nn\nfrom qlib.rl.order_execution import PPO\n\n\nclass SimpleFullyConnect(nn.Module):\n    def __init__(self, dims: List[int]) -> None:\n        super().__init__()\n\n        self.dims = [1] + dims\n        self.output_dim = dims[-1]\n\n        layers = []\n        for in_dim, out_dim in zip(self.dims[:-1], self.dims[1:]):\n            layers.append(nn.Linear(in_dim, out_dim))\n            layers.append(nn.ReLU())\n        self.fc = nn.Sequential(*layers)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.fc(x)\n\n\npolicy = PPO(\n    network=SimpleFullyConnect(dims=[16, 8]),\n    obs_space=state_interpreter.observation_space,\n    action_space=action_interpreter.action_space,\n    lr=0.01,\n)\n```\n\n----------------------------------------\n\nTITLE: Custom Data Health Check for 1-Minute Data in Qlib\nDESCRIPTION: Runs a data health check script with custom parameters for 1-minute interval stock data, allowing adjustment of thresholds for missing data and price/volume changes.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --freq 1min --missing_data_num 35806 --large_step_threshold_volume 3205452000000 --large_step_threshold_price 0.91\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Example\nDESCRIPTION: Example YAML configuration for training pipeline showing policy settings and checkpoint configuration\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl_order_execution/README.md#2025-04-07_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n...\npolicy:\n  class: PPO  # PPO, DQN\n  kwargs:\n    lr: 0.0001\n    weight_file: PATH/TO/CHECKPOINT\n  module_path: qlib.rl.order_execution.policy\n...\n```\n\n----------------------------------------\n\nTITLE: Equivalent Initialization in YAML and Python\nDESCRIPTION: Example showing how YAML configuration for model initialization is equivalent to Python code, demonstrating the init_instance_by_config design pattern.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_2\n\nLANGUAGE: YAML\nCODE:\n```\nmodel:\n    class: LGBModel\n    module_path: qlib.contrib.model.gbdt\n    kwargs:\n        loss: mse\n        colsample_bytree: 0.8879\n        learning_rate: 0.0421\n        subsample: 0.8789\n        lambda_l1: 205.6999\n        lambda_l2: 580.9768\n        max_depth: 8\n        num_leaves: 210\n        num_threads: 20\n```\n\nLANGUAGE: Python\nCODE:\n```\nfrom qlib.contrib.model.gbdt import LGBModel\nkwargs = {\n    \"loss\": \"mse\" ,\n    \"colsample_bytree\": 0.8879,\n    \"learning_rate\": 0.0421,\n    \"subsample\": 0.8789,\n    \"lambda_l1\": 205.6999,\n    \"lambda_l2\": 580.9768,\n    \"max_depth\": 8,\n    \"num_leaves\": 210,\n    \"num_threads\": 20,\n}\nLGBModel(kwargs)\n```\n\n----------------------------------------\n\nTITLE: Checking Data Health for Daily Data in Qlib\nDESCRIPTION: Runs a script to check the health of daily stock data, including missing values and large step changes.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data\n```\n\n----------------------------------------\n\nTITLE: Data Handler Configuration Example\nDESCRIPTION: Configuration for the DataHandler module that specifies time ranges for data and fitting, and the instruments to be included in the analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_4\n\nLANGUAGE: YAML\nCODE:\n```\ndata_handler_config: &data_handler_config\n    start_time: 2008-01-01\n    end_time: 2020-08-01\n    fit_start_time: 2008-01-01\n    fit_end_time: 2014-12-31\n    instruments: *market\n```\n\n----------------------------------------\n\nTITLE: Testing Custom Model with Qlib Command Line\nDESCRIPTION: Example of how to test a custom model integrated into Qlib using the qrun command. This command runs a workflow with the specified configuration file.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/integration.rst#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd examples  # Avoid running program under the directory contains `qlib`\nqrun benchmarks/LightGBM/workflow_config_lightgbm.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating a Prediction Score DataFrame Example in Python\nDESCRIPTION: Example of a prediction score DataFrame structure with datetime and instrument indices, containing score values for various stocks. This is typically the output of a Forecast Model in Qlib.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/strategy.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n  datetime instrument     score\n2019-01-04   SH600000 -0.505488\n2019-01-04   SZ002531 -0.320391\n2019-01-04   SZ000999  0.583808\n2019-01-04   SZ300569  0.819628\n2019-01-04   SZ001696 -0.137140\n             ...            ...\n2019-04-30   SZ000996 -1.027618\n2019-04-30   SH603127  0.225677\n2019-04-30   SH603126  0.462443\n2019-04-30   SH603133 -0.302460\n2019-04-30   SZ300760 -0.126383\n```\n\n----------------------------------------\n\nTITLE: Running Query Examples on Imported High-Frequency Data in Qlib\nDESCRIPTION: These pytest commands demonstrate how to run all examples or a specific example to create high-frequency features from the imported data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/orderbook_data/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npytest -s --disable-warnings example.py   # If you want run all examples\npytest -s --disable-warnings example.py::TestClass::test_exp_10  # If you want to run specific example\n```\n\n----------------------------------------\n\nTITLE: Implementing Local Attention Mechanism in Python\nDESCRIPTION: Defines the LocalAttention class, a custom attention mechanism for the Localformer model. It implements local self-attention with a specified window size.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Localformer/README.md#2025-04-07_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nclass LocalAttention(nn.Module):\n    def __init__(self, d_model, n_heads, window):\n        super(LocalAttention, self).__init__()\n        self.d_model = d_model\n        self.n_heads = n_heads\n        self.window = window\n        self.query = nn.Linear(d_model, d_model)\n        self.key = nn.Linear(d_model, d_model)\n        self.value = nn.Linear(d_model, d_model)\n        self.fc = nn.Linear(d_model, d_model)\n\n    def forward(self, x):\n        B, T, C = x.shape\n        H = self.n_heads\n\n        q = self.query(x).view(B, T, H, C // H).transpose(1, 2)\n        k = self.key(x).view(B, T, H, C // H).transpose(1, 2)\n        v = self.value(x).view(B, T, H, C // H).transpose(1, 2)\n\n        q = q.unfold(2, self.window, 1).contiguous()\n        k = k.unfold(2, self.window, 1).contiguous()\n        v = v.unfold(2, self.window, 1).contiguous()\n\n        out = F.scaled_dot_product_attention(q, k, v)\n        out = out.view(B, H, T, C // H).transpose(1, 2).contiguous().view(B, T, C)\n\n        return self.fc(out)\n```\n\n----------------------------------------\n\nTITLE: Downloading Pre-prepared Qlib Data using Python Script\nDESCRIPTION: This Python script downloads pre-prepared Qlib data from Yahoo Finance. It allows specifying parameters such as target directory, dataset version, time interval, region, and data handling options.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/get_data.py qlib_data\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib Data\nDESCRIPTION: Downloads and initializes Qlib data using the GetData API.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.tests.data import GetData\n\nGetData().qlib_data(exists_skip=True)\n```\n\n----------------------------------------\n\nTITLE: Calculating Model Performance Metrics in SigAnaRecord\nDESCRIPTION: Example code from SigAnaRecord showing how to calculate Information Coefficient (IC), Rank IC, and Long-Short Return using prediction and label data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/recorder.rst#2025-04-07_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nfrom qlib.contrib.eva.alpha import calc_ic, calc_long_short_return\n\nic, ric = calc_ic(pred.iloc[:, 0], label.iloc[:, 0])\nlong_short_r, long_avg_r = calc_long_short_return(pred.iloc[:, 0], label.iloc[:, 0])\n```\n\n----------------------------------------\n\nTITLE: Initializing Optuna Study for Alpha360\nDESCRIPTION: Creates an Optuna study named LGBM_360 and launches the Optuna dashboard for visualization on port 5000.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/hyperparameter/LightGBM/Readme.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\noptuna create-study --study LGBM_360 --storage sqlite:///db.sqlite3\noptuna-dashboard --port 5000 --host 0.0.0.0 sqlite:///db.sqlite3\n```\n\n----------------------------------------\n\nTITLE: Using Processed Fund Data with Qlib\nDESCRIPTION: Demonstrates how to initialize Qlib with the processed fund data and retrieve features using the D.features method. Specifies the data provider URI and required fields.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.data import D\n\nqlib.init(provider_uri=\"~/.qlib/qlib_data/cn_fund_data\")\ndf = D.features(D.instruments(market=\"all\"), [\"$DWJZ\", \"$LJJZ\"], freq=\"day\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Reward Function for Qlib RL in Python\nDESCRIPTION: Creates a 'SimpleReward' class that calculates the reward based on the proportion of the action to the current value. The larger the action, the larger the reward.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.rl.reward import Reward\n\n\nclass SimpleReward(Reward[State]):\n    def reward(self, simulator_state: State) -> float:\n        # Use last_action to calculate reward. This is why it should be in the state.\n        rew = simulator_state.last_action / simulator_state.value\n        return rew\n\n\nreward = SimpleReward()\n```\n\n----------------------------------------\n\nTITLE: Defining Market Constants\nDESCRIPTION: Sets up constant values for market analysis including market type, benchmark, and experiment name.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nMARKET = \"csi300\"\nBENCHMARK = \"SH000300\"\nEXP_NAME = \"tutorial_exp\"\n```\n\n----------------------------------------\n\nTITLE: Dumping and Loading High-Frequency Dataset in Python\nDESCRIPTION: This command executes a Python script to demonstrate dumping and loading a high-frequency dataset. It uses the 'workflow.py' file and calls the 'dump_and_load_dataset' function.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/highfreq/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py dump_and_load_dataset\n```\n\n----------------------------------------\n\nTITLE: Running TRA Using Python Script with Custom Parameters\nDESCRIPTION: Example command showing how to run TRA using a Python script for customized parameter settings. This approach provides more flexibility compared to using the command line interface.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython example.py --config_file configs/config_alstm.yaml\n```\n\n----------------------------------------\n\nTITLE: Specifying QLib Python Dependencies with Version Requirements\nDESCRIPTION: Lists the required Python packages with specific version constraints for the QLib project. The requirements include pandas 1.1.2, numpy 1.21.0, scikit-learn 0.23.2, and PyTorch 1.7.0, ensuring reproducible environments and compatibility between components.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TCTS/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Custom Data Health Check for Daily Data in Qlib\nDESCRIPTION: Runs a data health check script with custom parameters for daily stock data, allowing adjustment of thresholds for missing data and price/volume changes.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20\n```\n\n----------------------------------------\n\nTITLE: Verifying Qlib Installation\nDESCRIPTION: Python commands to verify successful installation by importing the library and checking its version.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/installation.rst#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> import qlib\n>>> qlib.__version__\n<LATEST VERSION>\n```\n\n----------------------------------------\n\nTITLE: Downloading Fund Data from East Money (CN)\nDESCRIPTION: Downloads fund data from eastmoney.com for a specified date range and region. Uses the collector.py script with the download_data command.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py download_data --source_dir ~/.qlib/fund_data/source/cn_data --region CN --start 2020-11-01 --end 2020-11-10 --delay 0.1 --interval 1d\n```\n\n----------------------------------------\n\nTITLE: QLib Instruments Query Example\nDESCRIPTION: Example showing how to query instruments after API changes in version 0.4.0, demonstrating the new method for getting instrument lists with time filters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/CHANGES.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\ninstruments = D.instruments(market='csi500')\nD.list_instruments(instruments=instruments, start_time='2015-01-01', end_time='2016-02-15', as_list=True)\n```\n\n----------------------------------------\n\nTITLE: Converting CSV to Qlib Binary Format\nDESCRIPTION: Command to convert CSV data into Qlib's binary format with specified fields\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/dump_bin.py dump_all --csv_path  ~/.qlib/csv_data/my_data --qlib_dir ~/.qlib/qlib_data/my_data --include_fields open,close,high,low,volume,factor\n```\n\n----------------------------------------\n\nTITLE: Downloading Community Dataset\nDESCRIPTION: Commands to download and extract the community-provided dataset for Qlib\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz\nmkdir -p ~/.qlib/qlib_data/cn_data\ntar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=2\nrm -f qlib_bin.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Checking Torch Version for CUDA Compatibility in Python\nDESCRIPTION: This snippet demonstrates how to check the installed version of PyTorch, which is crucial for ensuring CUDA compatibility. It's recommended to use CUDA 10.2 with PyTorch version 1.12.1 for optimal GPU usage.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/KRNN/README.md#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport torch\nprint(torch.__version__)\n```\n\n----------------------------------------\n\nTITLE: Getting Qlib Data via Module\nDESCRIPTION: Commands to download and prepare Qlib data using the module method for both daily and 1-minute intervals\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# get 1d data\npython -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n# get 1min data\npython -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n```\n\n----------------------------------------\n\nTITLE: Implementing Positional Encoding in Python\nDESCRIPTION: Defines the PositionalEncoding class, which adds positional information to the input tensor. This is crucial for the transformer architecture to understand sequence order.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Localformer/README.md#2025-04-07_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return x\n```\n\n----------------------------------------\n\nTITLE: Collecting and Parsing Stock Market Index Data\nDESCRIPTION: Commands for parsing instruments and saving new companies data from various stock indices (SP500, NASDAQ100, DJIA, SP400) into the qlib framework. The commands specify the index name and data directory location.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/us_index/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# parse instruments, using in qlib/instruments.\npython collector.py --index_name SP500 --qlib_dir ~/.qlib/qlib_data/us_data --method parse_instruments\n\n# parse new companies\npython collector.py --index_name SP500 --qlib_dir ~/.qlib/qlib_data/us_data --method save_new_companies\n\n# index_name support: SP500, NASDAQ100, DJIA, SP400\n# help\npython collector.py --help\n```\n\n----------------------------------------\n\nTITLE: Getting Qlib Data from Source\nDESCRIPTION: Commands to download and prepare Qlib data directly from source for both daily and 1-minute intervals\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# get 1d data\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n# get 1min data\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n```\n\n----------------------------------------\n\nTITLE: Running Rolling Retrain Benchmark with Default Linear Model\nDESCRIPTION: This command executes the rolling benchmark script with the default Linear forecasting model. It demonstrates how to run the RR framework using the basic configuration.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks_dynamic/baseline/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython rolling_benchmark.py run\n```\n\n----------------------------------------\n\nTITLE: Downloading Raw Baostock Data\nDESCRIPTION: Downloads raw stock market data from Baostock for a specified time period with 5-minute intervals for HS300 stocks.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/baostock_5min/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py download_data --source_dir ~/.qlib/stock_data/source/hs300_5min_original --start 2022-01-01 --end 2022-01-30 --interval 5min --region HS300\n```\n\n----------------------------------------\n\nTITLE: Running Rolling Retrain Benchmark with LightGBM Model\nDESCRIPTION: This command shows how to run the rolling benchmark using a LightGBM forecasting model instead of the default Linear model. It uses a specific configuration file for LightGBM with Alpha158 features.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks_dynamic/baseline/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython rolling_benchmark.py --conf_path=workflow_config_lightgbm_Alpha158.yaml run\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies List\nDESCRIPTION: List of required Python packages and build dependencies including Cython, CMake, scientific computing libraries (NumPy, SciPy, scikit-learn), data analysis tools (pandas), reinforcement learning framework (tianshou), and documentation tools (sphinx_rtd_theme).\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nCython\ncmake\nnumpy\nscipy\nscikit-learn\npandas\ntianshou\nsphinx_rtd_theme\n```\n\n----------------------------------------\n\nTITLE: Implementing __init__ Method for Custom Qlib Model\nDESCRIPTION: Example of implementing the initialization method for a custom model in Qlib. The method receives the loss function type and other parameters from the configuration file and initializes the model accordingly.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/integration.rst#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef __init__(self, loss='mse', **kwargs):\n    if loss not in {'mse', 'binary'}:\n        raise NotImplementedError\n    self._scorer = mean_squared_error if loss == 'mse' else roc_auc_score\n    self._params.update(objective=loss, **kwargs)\n    self._model = None\n```\n\n----------------------------------------\n\nTITLE: Running TRA with Qlib Command Line Interface\nDESCRIPTION: Command line example showing how to run TRA models using Qlib's qrun command with configuration files. This demonstrates the simplest way to execute the model with default parameters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nqrun configs/config_alstm.yaml\n```\n\n----------------------------------------\n\nTITLE: Implementing predict Method for Custom Qlib Model\nDESCRIPTION: Example of implementing the predict method for a custom model in Qlib. This method prepares the test dataset and uses the trained model to generate predictions, returning them as a pandas Series.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/integration.rst#2025-04-07_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef predict(self, dataset: DatasetH, **kwargs)-> pandas.Series:\n    if self.model is None:\n        raise ValueError(\"model is not fitted yet!\")\n    x_test = dataset.prepare(\"test\", col_set=\"feature\", data_key=DataHandlerLP.DK_I)\n    return pd.Series(self.model.predict(x_test.values), index=x_test.index)\n```\n\n----------------------------------------\n\nTITLE: Installing Qlib in Editable Mode for Development\nDESCRIPTION: This command installs Qlib in editable mode with development dependencies. It allows developers to make changes to Qlib that reflect immediately in their environment without reinstallation.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/code_standard_and_dev_guide.rst#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install -e \".[dev]\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo CSV Data\nDESCRIPTION: Commands to download demo data in CSV format for daily and 1-minute intervals\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/get_data.py download_data --file_name csv_data_cn.zip --target_dir ~/.qlib/csv_data/cn_data\n\npython scripts/data_collector/yahoo/collector.py download_data --source_dir ~/.qlib/stock_data/source/cn_1min --region CN --start 2021-05-20 --end 2021-05-23 --delay 0.1 --interval 1min --limit_nums 10\n```\n\n----------------------------------------\n\nTITLE: Using QLib Data in Python\nDESCRIPTION: Example of how to initialize QLib and load the processed cryptocurrency data into a DataFrame with price, volume, and market cap features\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crypto/README.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.data import D\n\nqlib.init(provider_uri=\"~/.qlib/qlib_data/crypto_data\")\ndf = D.features(D.instruments(market=\"all\"), [\"$prices\", \"$total_volumes\",\"$market_caps\"], freq=\"day\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Pre-commit Hooks for Qlib Development\nDESCRIPTION: These commands install Qlib in editable mode with development dependencies and set up pre-commit hooks. This ensures code is automatically formatted using black and flake8 before each commit.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/code_standard_and_dev_guide.rst#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -e .[dev]\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Setting Up Automatic Daily Updates with Crontab\nDESCRIPTION: Linux crontab command to set up automatic daily updates of stock data. It schedules the update script to run on weekdays.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n* * * * 1-5 python <script path> update_data_to_bin --qlib_data_1d_dir <user data dir>\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Online Serving\nDESCRIPTION: ReStructuredText documentation structure defining the layout and sections for Qlib's online serving documentation, including module references and image placement.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/online.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _online_serving:\n\n==============\nOnline Serving\n==============\n.. currentmodule:: qlib\n\n\nIntroduction\n============\n\n.. image:: ../_static/img/online_serving.png\n    :align: center\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with CN Data\nDESCRIPTION: Python code to initialize Qlib with downloaded Chinese market data. Requires setting the provider URI and region to CN.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.constant import REG_CN\n\nprovider_uri = \"~/.qlib/qlib_data/cn_data\"  # target_dir\nqlib.init(provider_uri=provider_uri, region=REG_CN)\n```\n\n----------------------------------------\n\nTITLE: Manual Data Update Command\nDESCRIPTION: Command for manually updating data between specified trading dates\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir <user data dir> --trading_date <start date> --end_date <end date>\n```\n\n----------------------------------------\n\nTITLE: Visualizing QlibRecorder Structure\nDESCRIPTION: ASCII diagram showing the hierarchical structure of QlibRecorder with ExperimentManager containing multiple Experiments, each with multiple Recorders.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/recorder.rst#2025-04-07_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nExperimentManager\n    - Experiment 1\n        - Recorder 1\n        - Recorder 2\n        - ...\n    - Experiment 2\n        - Recorder 1\n        - Recorder 2\n        - ...\n    - ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving High-Frequency Data using Python Script\nDESCRIPTION: This command runs a Python script to fetch high-frequency trading data. It utilizes the 'workflow.py' file and calls the 'get_data' function.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/highfreq/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py get_data\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow with qrun Command\nDESCRIPTION: Commands to execute a predefined workflow using the qrun utility in normal mode and debug mode.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nqrun configuration.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\npython -m pdb qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow with qrun Command\nDESCRIPTION: Commands to execute a predefined workflow using the qrun utility in normal mode and debug mode.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nqrun configuration.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\npython -m pdb qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\n----------------------------------------\n\nTITLE: Initializing Optuna Study for Alpha158\nDESCRIPTION: Creates an Optuna study named LGBM_158 and launches the Optuna dashboard for visualization on port 5000.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/hyperparameter/LightGBM/Readme.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\noptuna create-study --study LGBM_158 --storage sqlite:///db.sqlite3\noptuna-dashboard --port 5000 --host 0.0.0.0 sqlite:///db.sqlite3\n```\n\n----------------------------------------\n\nTITLE: Downloading Crowd Sourced Data\nDESCRIPTION: Commands to download and extract crowd sourced version of Qlib data from GitHub releases.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz\ntar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: Fixing Python SocketIO Version Compatibility for Qlib\nDESCRIPTION: Command to ensure python-socketio version in qlib matches the version in qlib-server, resolving the \"BadNamespaceError: / is not a connected namespace\" error during client-server communication.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/FAQ/FAQ.rst#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -U python-socketio==<qlib-server python-socketio version>\n```\n\n----------------------------------------\n\nTITLE: Training Execution Command for OPDS\nDESCRIPTION: Command to run the training workflow for Oracle Policy Distillation Strategy (OPDS) with backtest option\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl_order_execution/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m qlib.rl.contrib.train_onpolicy --config_path exp_configs/train_opds.yml --run_backtest\n```\n\n----------------------------------------\n\nTITLE: Clearing Redis Cache Keys to Fix QlibCacheException\nDESCRIPTION: Redis commands to resolve the \"qlib.data.cache.QlibCacheException\" error by clearing redis keys. These commands help when a redis lock key exists in the database preventing proper execution.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/FAQ/FAQ.rst#2025-04-07_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ redis-cli\n> select 1\n> flushdb\n```\n\n----------------------------------------\n\nTITLE: Running Alpha360 Optimization Script\nDESCRIPTION: Executes the Python script for Alpha360 hyperparameter optimization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/hyperparameter/LightGBM/Readme.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npython hyperparameter_360.py\n```\n\n----------------------------------------\n\nTITLE: Dumping Normalized Fund Data for Qlib\nDESCRIPTION: Dumps the normalized fund data into a format suitable for Qlib using the dump_bin.py script. Specifies input and output paths, frequency, date field name, and included fields.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd qlib/scripts\npython dump_bin.py dump_all --csv_path ~/.qlib/fund_data/source/cn_1d_nor --qlib_dir ~/.qlib/qlib_data/cn_fund_data --freq day --date_field_name FSRQ --include_fields DWJZ,LJJZ\n```\n\n----------------------------------------\n\nTITLE: Building Cython Extensions for Qlib\nDESCRIPTION: Command to compile Cython files and generate executable files for Qlib, resolving the \"ModuleNotFoundError: No module named 'qlib.data._libs.rolling'\" error that occurs when importing the qlib package.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/FAQ/FAQ.rst#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py build_ext --inplace\n```\n\n----------------------------------------\n\nTITLE: Importing Predefined Stock Pools in Qlib\nDESCRIPTION: Demonstrates how to import predefined stock pools (e.g., CSI300) using the collector script in Qlib.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py --index_name CSI300 --qlib_dir <user qlib data dir> --method parse_instruments\n```\n\n----------------------------------------\n\nTITLE: Importing QlibRecorder in Python\nDESCRIPTION: Shows how to import the QlibRecorder interface (R) from qlib.workflow to interact with the experiment management system.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/recorder.rst#2025-04-07_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom qlib.workflow import R\n```\n\n----------------------------------------\n\nTITLE: Manually Updating Qlib Data with Python\nDESCRIPTION: Python command for manually updating Qlib data. It allows specifying the data directory and end date for the update.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir <user data dir> --end_date <end date>\n```\n\n----------------------------------------\n\nTITLE: Dataset Configuration Example\nDESCRIPTION: Configuration for the Dataset module that handles data preprocessing and segmentation for training, validation, and testing phases.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/workflow.rst#2025-04-07_snippet_5\n\nLANGUAGE: YAML\nCODE:\n```\ndataset:\n    class: DatasetH\n    module_path: qlib.data.dataset\n    kwargs:\n        handler:\n            class: Alpha158\n            module_path: qlib.contrib.data.handler\n            kwargs: *data_handler_config\n        segments:\n            train: [2008-01-01, 2014-12-31]\n            valid: [2015-01-01, 2016-12-31]\n            test: [2017-01-01, 2020-08-01]\n```\n\n----------------------------------------\n\nTITLE: Loading Instruments for a Specific Stock Pool in Qlib using Python\nDESCRIPTION: Retrieve a list of instruments for a given stock pool (e.g., CSI300) within a specified time range using Qlib's Data module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\ninstruments = D.instruments(market='csi300')\nD.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6]\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with Custom Experiment Manager\nDESCRIPTION: Code snippet showing how to initialize Qlib with a custom experiment manager configuration. This setup uses MLflow for experiment tracking and management with a specific URI and experiment name.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/initialization.rst#2025-04-07_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nqlib.init(provider_uri=provider_uri, region=REG_CN, exp_manager= {\n    \"class\": \"MLflowExpManager\",\n    \"module_path\": \"qlib.workflow.expm\",\n    \"kwargs\": {\n        \"uri\": \"python_execution_path/mlruns\",\n        \"default_exp_name\": \"Experiment\",\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Installing Qlib from Source Code\nDESCRIPTION: Step-by-step installation of Qlib from source code, including required dependencies numpy and cython.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/installation.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install numpy\n$ pip install --upgrade cython\n$ git clone https://github.com/microsoft/qlib.git && cd qlib\n$ python setup.py install\n```\n\n----------------------------------------\n\nTITLE: Resolving Multiprocessing Bootstrap Error in Windows with Qlib\nDESCRIPTION: Solution for RuntimeError related to multiprocessing bootstrap phase in Windows. This code demonstrates the proper way to use Qlib's feature extraction functionality within the main module to avoid process bootstrapping issues.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/FAQ/FAQ.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.data import D\n\n\nif __name__ == \"__main__\":\n    qlib.init()\n    instruments = [\"SH600000\"]\n    fields = [\"$close\", \"$change\"]\n    df = D.features(instruments, fields, start_time='2010-01-01', end_time='2012-12-31')\n    print(df.head())\n```\n\n----------------------------------------\n\nTITLE: Downloading China Stock Data in Qlib Format\nDESCRIPTION: Commands to download daily and 1-minute interval China stock market data in Qlib's binary format\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# download 1d\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n# download 1min\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/qlib_cn_1min --region cn --interval 1min\n```\n\n----------------------------------------\n\nTITLE: Loading Trading Calendar in Qlib using Python\nDESCRIPTION: Retrieve the trading calendar for a specific time range and frequency using Qlib's Data module. This example fetches daily calendar data for a given period.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/getdata.rst#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\nD.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2]\n```\n\n----------------------------------------\n\nTITLE: Running High-Frequency Backtesting in Qlib\nDESCRIPTION: Command to start high-frequency backtesting with daily portfolio generation using DropoutTopkStrategy and minutely order execution using SBBStrategyEMA.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/nested_decision_execution/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py backtest_highfreq\n```\n\n----------------------------------------\n\nTITLE: Ignoring Specific Pylint Errors in Python\nDESCRIPTION: This code demonstrates how to ignore specific Pylint errors in Python code using inline comments. It's useful when Pylint's restrictions are not reasonable for a particular line of code.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/code_standard_and_dev_guide.rst#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nreturn -ICLoss()(pred, target, index)  # pylint: disable=E1130\n```\n\n----------------------------------------\n\nTITLE: Configuring Tuner Components in YAML for Qlib\nDESCRIPTION: This YAML snippet demonstrates the basic structure for configuring tuner components in Qlib, including class, space, and max evaluations.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nclass: TopkAmountStrategy\nspace: TopkAmountStrategySpace\nmax_evals: 2\n```\n\n----------------------------------------\n\nTITLE: Setting Up Automatic Data Updates with Crontab\nDESCRIPTION: Crontab configuration for automatically updating daily frequency data on weekdays\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/data.rst#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n* * * * 1-5 python <script path> update_data_to_bin --qlib_data_1d_dir <user data dir>\n```\n\n----------------------------------------\n\nTITLE: Preparing Risk Model Data - Python Command\nDESCRIPTION: Command to execute the risk data preparation script which sets up the Statistical Risk Model data required for portfolio optimization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/portfolio/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython prepare_riskdata.py\n```\n\n----------------------------------------\n\nTITLE: Tuner Pipeline Configuration\nDESCRIPTION: Example of configuring the tuner pipeline with model, trainer and strategy components\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ntuner_pipeline:\n  -\n    model:\n        class: SomeModel\n        space: SomeModelSpace\n    trainer:\n        class: RollingTrainer\n    strategy:\n```\n\n----------------------------------------\n\nTITLE: Retrieving Available QLib Report Types\nDESCRIPTION: Shows how to import and list all supported report types in QLib's contrib.report module. Returns a list of available graph types for analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/report.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>> import qlib.contrib.report as qcr\n>> print(qcr.GRAPH_NAME_LIST)\n```\n\n----------------------------------------\n\nTITLE: Optimization Criteria Configuration\nDESCRIPTION: Configuration for specifying which metrics to optimize during the tuning process\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\noptimization_criteria:\n    report_type: model\n    report_factor: model_pearsonr\n    optim_type: max\n```\n\n----------------------------------------\n\nTITLE: Downloading Stock Data with get_data.py Script\nDESCRIPTION: Command to download stock data from Yahoo Finance for the Chinese market. The script downloads data to the specified target directory which will be used for Qlib initialization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/start/initialization.rst#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n```\n\n----------------------------------------\n\nTITLE: Normalizing Stock Data\nDESCRIPTION: Normalizes the downloaded quarterly stock data and saves it to a specified directory.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/pit/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py normalize_data --interval quarterly --source_dir ~/.qlib/stock_data/source/pit --normalize_dir ~/.qlib/stock_data/source/pit_normalized\n```\n\n----------------------------------------\n\nTITLE: Experiment Configuration in YAML\nDESCRIPTION: Basic experiment configuration showing required and optional fields for the tuner setup\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nexperiment:\n    name: tuner_experiment\n    tuner_class: QLibTuner\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB for Task Management in Python\nDESCRIPTION: This snippet demonstrates how to configure MongoDB connection settings for Qlib's TaskManager. It sets the MongoDB URL and database name in the Qlib configuration.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/advanced/task_management.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.config import C\nC[\"mongo\"] = {\n    \"task_url\" : \"mongodb://localhost:27017/\", # your MongoDB url\n    \"task_db_name\" : \"rolling_db\" # database name\n}\n```\n\n----------------------------------------\n\nTITLE: Dumping and Reloading DatasetH in Python using Qlib\nDESCRIPTION: Example of serializing a DatasetH instance to disk and reloading it. Shows how to dump the dataset to a pickle file and then load it back into memory.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/advanced/serial.rst#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n##=============dump dataset=============\ndataset.to_pickle(path=\"dataset.pkl\") # dataset is an instance of qlib.data.dataset.DatasetH\n\n##=============reload dataset=============\nwith open(\"dataset.pkl\", \"rb\") as file_dataset:\n    dataset = pickle.load(file_dataset)\n```\n\n----------------------------------------\n\nTITLE: Normalizing Downloaded Fund Data\nDESCRIPTION: Normalizes the downloaded fund data using the collector.py script with the normalize_data command. Specifies source and destination directories, region, interval, and date field name.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py normalize_data --source_dir ~/.qlib/fund_data/source/cn_data --normalize_dir ~/.qlib/fund_data/source/cn_1d_nor --region CN --interval 1d --date_field_name FSRQ\n```\n\n----------------------------------------\n\nTITLE: Implementing a Simple Simulator in Python for Qlib RL\nDESCRIPTION: Defines a basic simulator class 'SimpleSimulator' that extends Qlib's Simulator class. It maintains an internal value and tracks the last action taken, running for a fixed number of steps.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl/simple_example.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom collections import namedtuple\nfrom typing import Any\nfrom qlib.rl.simulator import Simulator\n\nState = namedtuple(\"State\", [\"value\", \"last_action\"])\n\n\nclass SimpleSimulator(Simulator[float, State, float]):\n    def __init__(self, initial: float, nsteps: int, **kwargs: Any) -> None:\n        super().__init__(initial)\n\n        self.value = initial\n        self.last_action = 0.0\n        self.remain_steps = nsteps\n\n    def step(self, action: float) -> None:\n        assert 0.0 <= action <= self.value\n        self.last_action = action\n        self.remain_steps -= 1\n\n    def get_state(self) -> State:\n        return State(self.value, self.last_action)\n\n    def done(self) -> bool:\n        return self.remain_steps == 0\n```\n\n----------------------------------------\n\nTITLE: Importing Meta Model Classes in Python\nDESCRIPTION: This snippet shows the import statements for various Meta Model classes from the qlib.model.meta.model module. These classes include the general MetaModel, MetaTaskModel for interacting with task definitions, and MetaGuideModel for participating in the training process of base forecasting models.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/meta.rst#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.model.meta.model import MetaModel, MetaTaskModel, MetaGuideModel\n```\n\n----------------------------------------\n\nTITLE: Converting Data to QLib Binary Format\nDESCRIPTION: Converts normalized CSV data into QLib's binary format, organizing data by columns and symbols with 5-minute frequency.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/baostock_5min/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython dump_bin.py dump_all --csv_path ~/.qlib/stock_data/source/hs300_5min_nor --qlib_dir ~/.qlib/qlib_data/hs300_5min_bin --freq 5min --exclude_fields date,symbol\n```\n\n----------------------------------------\n\nTITLE: Importing Meta Task Class in Python\nDESCRIPTION: This snippet shows the import statement for the MetaTask class from the qlib.model.meta.task module. The MetaTask class is the basic element in the meta-learning framework, saving data for use in the Meta Model.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/meta.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.model.meta.task import MetaTask\n```\n\n----------------------------------------\n\nTITLE: Converting Data to PIT Format\nDESCRIPTION: Converts the normalized data into QLib's Point-in-Time (PIT) format for further analysis.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/pit/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd qlib/scripts\npython dump_pit.py dump --csv_path ~/.qlib/stock_data/source/pit_normalized --qlib_dir ~/.qlib/qlib_data/cn_data --interval quarterly\n```\n\n----------------------------------------\n\nTITLE: LSTM Reference Documentation in Markdown\nDESCRIPTION: Markdown documentation referencing the foundational LSTM paper published in MIT Press Neural Computation journal. Provides citation and link to the original research paper that introduced the LSTM architecture.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/LSTM/README.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Long Short-Term Memory (LSTM)\n* Paper: [Long Short-Term Memory](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext).\n```\n\n----------------------------------------\n\nTITLE: Return Calculation Formula - Setting 2\nDESCRIPTION: Mathematical formula for calculating stock return in the second experimental setting. It computes the return between the next day and k days ahead.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TCTS/README.md#2025-04-07_snippet_1\n\nLANGUAGE: latex\nCODE:\n```\nr_{i}^{t,k} = \\frac{price_i^{t+1+k}}{price_i^{t+1}}-1\n```\n\n----------------------------------------\n\nTITLE: Executing Python Script to Fill 1-Minute Data in Qlib\nDESCRIPTION: This command runs a Python script to fill missing symbols in 1-minute data using 1-day data. It specifies the paths for input 1-minute CSV data and 1-day Qlib data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/fill_cn_1min_data/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython fill_cn_1min_data.py --data_1min_dir ~/.qlib/csv_data/cn_data_1min --qlib_data_1d_dir ~/.qlib/qlib_data/cn_data\n```\n\n----------------------------------------\n\nTITLE: Analyzing Model Selection Case Study\nDESCRIPTION: Creates visualization for model selection behavior analysis, showing predictor loss and router selection over time for a specific stock code.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/Reports.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.read_pickle(\n    \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb0.0_head4_hs64_bs512_do0.1_lr0.0005_seed1000/pred.pkl\"\n)\ncode = \"SH600157\"\ndate = \"2018-09-28\"\nlookbackperiod = 50\n\nprob = df.iloc[:, -3:].loc(axis=0)[:, code].reset_index(level=1, drop=True).loc[date:].iloc[:lookbackperiod]\npred = (\n    df.loc[:, [\"score_0\", \"score_1\", \"score_2\", \"label\"]]\n    .loc(axis=0)[:, code]\n    .reset_index(level=1, drop=True)\n    .loc[date:]\n    .iloc[:lookbackperiod]\n)\ne_all = pred.iloc[:, :-1].sub(pred.iloc[:, -1], axis=0).pow(2)\ne_all = e_all.sub(e_all.min(axis=1), axis=0)\ne_all.columns = [r\"$\\theta_%d$\" % d for d in range(1, 4)]\nprob = pd.Series(np.argmax(prob.values, axis=1), index=prob.index).rolling(7).mean().round()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Data Collector Class\nDESCRIPTION: Base structure for implementing a custom data collector class that inherits from BaseCollector. Includes path setup and necessary imports.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/README.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nCUR_DIR = Path(__file__).resolve().parent\nsys.path.append(str(CUR_DIR.parent.parent))\nfrom data_collector.base import BaseCollector, BaseNormalize, BaseRun\nclass UserCollector(BaseCollector):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Building Stable Qlib Docker Image\nDESCRIPTION: Commands to build the stable version of the Qlib Docker image using pip install pyqlib. The IS_STABLE build argument is set to 'yes' by default.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker build --build-arg IS_STABLE=yes -t <image name> -f ./Dockerfile .\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t <image name> -f ./Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: Module Autoload for Online Strategy\nDESCRIPTION: RST directive to automatically load and display documentation for the Qlib online strategy module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/online.rst#2025-04-07_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: qlib.workflow.online.strategy\n    :members:\n    :noindex:\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom CLI Run Class\nDESCRIPTION: Template for implementing a command-line interface class that inherits from BaseRun for executing data collection tasks.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/README.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Run(BaseRun):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Module Autoload for Online Manager\nDESCRIPTION: RST directive to automatically load and display documentation for the Qlib online manager module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/online.rst#2025-04-07_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: qlib.workflow.online.manager\n    :members:\n    :noindex:\n```\n\n----------------------------------------\n\nTITLE: Defining ReStructuredText Table of Contents for RL in Quantitative Trading\nDESCRIPTION: This snippet defines the table of contents for the reinforcement learning documentation in quantitative trading using ReStructuredText markup. It includes sections for guidance, overall concepts, quick start guide, and framework details.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/rl/toctree.rst#2025-04-07_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _rl:\n\n========================================================================\nReinforcement Learning in Quantitative Trading\n========================================================================\n\n.. toctree::\n    Guidance <guidance>\n    Overall <overall>\n    Quick Start <quickstart>\n    Framework <framework>\n```\n\n----------------------------------------\n\nTITLE: Running Weekly-Daily Backtesting in Qlib\nDESCRIPTION: Command to start backtesting with weekly portfolio generation using DropoutTopkStrategy and daily order execution using SBBStrategyEMA.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/nested_decision_execution/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py backtest\n```\n\n----------------------------------------\n\nTITLE: Module Autoload for Updater\nDESCRIPTION: RST directive to automatically load and display documentation for the Qlib online updater module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/online.rst#2025-04-07_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: qlib.workflow.online.update\n    :members:\n    :noindex:\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Data for Qlib Non-Fixed Frequency Analysis\nDESCRIPTION: These commands download the example high-frequency orderbook data using gdown and unzip it to the current directory.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/orderbook_data/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/orderbook_data/\ngdown https://drive.google.com/uc?id=15nZF7tFT_eKVZAcMFL1qPS4jGyJflH7e  # Proxies may be necessary here.\npython ../../scripts/get_data.py _unzip --file_path highfreq_orderbook_example_data.zip --target_dir .\n```\n\n----------------------------------------\n\nTITLE: Running Qlib Scripts in Docker Container\nDESCRIPTION: Example commands for running Qlib scripts within the Docker container, including data retrieval and workflow execution.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n>>> python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn\n>>> python qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Alpha158 Dataset using Bash\nDESCRIPTION: This snippet provides commands to download the crowd-sourced version of the qlib data, extract it to the appropriate directory, and clean up the downloaded archive.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks_dynamic/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz\nmkdir -p ~/.qlib/qlib_data/cn_data\ntar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=2\nrm -f qlib_bin.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Running Alpha158 Optimization Script\nDESCRIPTION: Executes the Python script for Alpha158 hyperparameter optimization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/hyperparameter/LightGBM/Readme.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython hyperparameter_158.py\n```\n\n----------------------------------------\n\nTITLE: Downloading CSI300 Weight Data - Bash Commands\nDESCRIPTION: Commands to download and extract CSI300 weight data into the QLib data directory. This data is necessary for benchmark tracking in portfolio optimization.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/portfolio/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/SunsetWolf/qlib_dataset/releases/download/v0/csi300_weight.zip\nunzip -d ~/.qlib/qlib_data/cn_data csi300_weight.zip\nrm -f csi300_weight.zip\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with US Data\nDESCRIPTION: Python code to initialize Qlib with downloaded US market data. Requires setting the provider URI and region to US.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport qlib\nfrom qlib.config import REG_US\nprovider_uri = \"~/.qlib/qlib_data/us_data\"  # target_dir\nqlib.init(provider_uri=provider_uri, region=REG_US)\n```\n\n----------------------------------------\n\nTITLE: Downloading US Market Data with Bash\nDESCRIPTION: Command to download US market data using get_data.py script. The data is stored in the specified target directory under .qlib/qlib_data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython get_data.py qlib_data --target_dir ~/.qlib/qlib_data/us_data --region us\n```\n\n----------------------------------------\n\nTITLE: Downloading CN Market Data with Bash\nDESCRIPTION: Commands to download daily and 1-minute Chinese market data using get_data.py script. The data is stored in the specified target directory under .qlib/qlib_data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# daily data\npython get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n# 1min  data (Optional for running non-high-frequency strategies)\npython get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n```\n\n----------------------------------------\n\nTITLE: Normalizing YahooFinance Data with Python\nDESCRIPTION: Python command to normalize downloaded stock data. It adjusts prices using adjclose and normalizes them so that the first valid trading date's close price is 1.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py normalize_data --source_dir ~/.qlib/stock_data/source/cn_data --normalize_dir ~/.qlib/stock_data/source/cn_1d_nor --region CN --interval 1d\n```\n\n----------------------------------------\n\nTITLE: Citation Format for TRA and Qlib Research Papers\nDESCRIPTION: BibTeX citation formats for referencing the TRA paper 'Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport' and the Qlib framework paper in academic research.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{HengxuKDD2021,\n author = {Hengxu Lin and Dong Zhou and Weiqing Liu and Jiang Bian},\n title = {Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport},\n booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \\& Data Mining},\n series = {KDD '21},\n year = {2021},\n publisher = {ACM},\n}\n\n@article{yang2020qlib,\n  title={Qlib: An AI-oriented Quantitative Investment Platform},\n  author={Yang, Xiao and Liu, Weiqing and Zhou, Dong and Bian, Jiang and Liu, Tie-Yan},\n  journal={arXiv preprint arXiv:2009.11189},\n  year={2020}\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Rolling Process Data Workflow in Python\nDESCRIPTION: This command runs the Python script 'workflow.py' with the 'rolling_process' argument to execute the Rolling Process Data example.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rolling_process_data/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py rolling_process\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Qlib Data Usage (YAML)\nDESCRIPTION: YAML configuration for using local Qlib data files offline instead of online client-server framework.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/client.rst#2025-04-07_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nprovider_uri: /data/csdesign/qlib\ncalendar_provider: 'LocalCalendarProvider'\ninstrument_provider: 'LocalInstrumentProvider'\nfeature_provider: 'LocalFeatureProvider'\nexpression_provider: 'LocalExpressionProvider'\ndataset_provider: 'LocalDatasetProvider'\nprovider: 'LocalProvider'\ndataset_cache: 'SimpleDatasetCache'\nlocal_cache_path: '~/.cache/qlib/'\n```\n\n----------------------------------------\n\nTITLE: Fetching QLIB Market Data Command\nDESCRIPTION: Command to retrieve 5-minute interval market data for HS300 index using QLIB's data fetching module\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl_order_execution/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m qlib.run.get_data qlib_data qlib_data --target_dir ./data/bin --region hs300 --interval 5min\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies List\nDESCRIPTION: List of required Python packages including logging, CLI tools, HTTP requests, numerical processing, data manipulation, progress tracking, XML processing and cryptocurrency data access libraries.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crypto/requirement.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nloguru\nfire\nrequests\nnumpy\npandas\ntqdm\nlxml\npycoingecko\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib with Local Configuration (Python)\nDESCRIPTION: Example of initializing Qlib using a local YAML configuration file for offline data usage.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/client.rst#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> import qlib\n>>> qlib.init_from_yaml_conf('client_config_local.yml')\n>>> from qlib.data import D\n>>> D.features(['SH600001'], ['$close'], start_time='20180101', end_time='20190101').head()\n```\n\n----------------------------------------\n\nTITLE: Data Processing Pipeline Commands\nDESCRIPTION: Series of commands to generate and process pickle-format data and training orders\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl_order_execution/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/gen_pickle_data.py -c scripts/pickle_data_config.yml\npython scripts/gen_training_orders.py\npython scripts/merge_orders.py\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Qlib Data Collection\nDESCRIPTION: This command installs the necessary Python packages for collecting and processing Qlib data from Yahoo Finance.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/yahoo/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Directory Structure Example\nDESCRIPTION: Expected directory structure after data processing showing bin, orders, and pickle subdirectories\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/rl_order_execution/README.md#2025-04-07_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\ndata\n├── bin\n├── orders\n└── pickle\n```\n\n----------------------------------------\n\nTITLE: Return Calculation Formula - Setting 1\nDESCRIPTION: Mathematical formula for calculating stock return in the first experimental setting. It computes the return between consecutive days for k-step ahead prediction.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TCTS/README.md#2025-04-07_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\nr_{i}^{t,k} = \\frac{price_i^{t+k}}{price_i^{t+k-1}}-1\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Installs required packages for the data collection process\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crypto/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Collecting Data for Nested Decision Execution\nDESCRIPTION: Command to collect necessary data for the nested decision execution workflow.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/nested_decision_execution/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython workflow.py collect_data\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for QLib Data Collection\nDESCRIPTION: Installs the required dependencies for the data collection process from the requirements.txt file.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/pit/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for QLib Future Trading Date Collector\nDESCRIPTION: Command to install required dependencies via pip from the requirements.txt file before running the collector script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/future_trading_date_collector/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Module Autoload for Online Tool\nDESCRIPTION: RST directive to automatically load and display documentation for the Qlib online utilities module.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/online.rst#2025-04-07_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: qlib.workflow.online.utils\n    :members:\n    :noindex:\n```\n\n----------------------------------------\n\nTITLE: Resolving SocketIO and EngineIO Compatibility Issues\nDESCRIPTION: Installation commands to fix the \"TypeError: send() got an unexpected keyword argument 'binary'\" error by ensuring compatibility between python-engineio and python-socketio versions.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/FAQ/FAQ.rst#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install -U python-engineio==<compatible python-socketio version>\n# or\npip install -U python-socketio==3.1.2 python-engineio==3.13.2\n```\n\n----------------------------------------\n\nTITLE: Running Future Trading Date Collector Script for QLib\nDESCRIPTION: Command to execute the Python script that collects future trading dates. It specifies the QLib data directory and frequency parameter (day or 1min).\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/future_trading_date_collector/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# parse instruments, using in qlib/instruments.\npython future_trading_date_collector.py --qlib_dir ~/.qlib/qlib_data/cn_data --freq day\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Fund Data Collection\nDESCRIPTION: Installs the necessary dependencies listed in the requirements.txt file for the fund data collection process.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Generating Qlib Data Using Docker\nDESCRIPTION: Docker command to generate up-to-date Qlib binary data from Dolthub source. This method ensures access to the latest financial data updates.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crowd_source/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -v /<some output directory>:/output -it --rm chenditc/investment_data bash dump_qlib_bin.sh && cp ./qlib_bin.tar.gz /output/\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft Qlib\nDESCRIPTION: This code snippet defines the exact versions of Python packages required for the Microsoft Qlib project. It includes numpy 1.21.0, pandas 1.1.2, and xgboost 1.2.1.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/XGBoost/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nxgboost==1.2.1\n```\n\n----------------------------------------\n\nTITLE: Formatting Code with Black in Python\nDESCRIPTION: This snippet shows how to install and use the Black code formatter to align code with Qlib's standards. It sets the line length to 120 characters.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/code_standard_and_dev_guide.rst#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install black\npython -m black . -l 120\n```\n\n----------------------------------------\n\nTITLE: Running Flake8 with Ignored Errors for Qlib\nDESCRIPTION: This bash command runs Flake8 on the Qlib project, ignoring a specific set of error codes. It's used to check code style while allowing for project-specific exceptions.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/code_standard_and_dev_guide.rst#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nflake8 --ignore E501,F541,E402,F401,W503,E741,E266,E203,E302,E731,E262,F523,F821,F811,F841,E713,E265,W291,E712,E722,W293 qlib\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Version Constraints\nDESCRIPTION: Defines exact version requirements for three Python packages used in data science and machine learning: pandas 1.1.2 for data manipulation, numpy 1.21.0 for numerical computations, and lightgbm 3.1.0 for gradient boosting.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/DoubleEnsemble/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nlightgbm==3.1.0\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Qlib Non-Fixed Frequency Data Support\nDESCRIPTION: This snippet shows the commands to install necessary libraries for working with non-fixed frequency data in Qlib, including pytest, coverage, gdown, and arctic.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/orderbook_data/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install pytest coverage gdown\npip install arctic  # NOTE: pip may fail to resolve the right package dependency !!! Please make sure the dependency are satisfied.\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib Client on PAI (Python)\nDESCRIPTION: Example of initializing Qlib client on PAI with auto-mounting and specific provider URI.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/client.rst#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> import qlib\n>>> qlib.init(auto_mount=True, mount_path='/data/csdesign/qlib', provider_uri='172.23.233.89:/data2/gaochao/sync_qlib/qlib')\n>>> from qlib.data import D\n>>> D.features(['SH600000'], ['$close'], start_time='20080101', end_time='20090101').head()\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for CSI Indices Data Collection\nDESCRIPTION: This command installs the required Python packages listed in the requirements.txt file for the data collection script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/cn_index/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib Client on Windows (Python)\nDESCRIPTION: Example of initializing Qlib client on Windows with NFS features enabled and correct mount path.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/client.rst#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> import qlib\n>>> qlib.init(auto_mount=True, mount_path='H', provider_uri='172.23.233.89:/data2/gaochao/sync_qlib/qlib')\n>>> from qlib.data import D\n>>> D.features(['SH600000'], ['$close'], start_time='20080101', end_time='20090101').head()\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for QLib\nDESCRIPTION: This requirements file specifies the exact versions of Python packages needed for the QLib project to function properly. It includes pandas 1.1.2 for data manipulation, numpy 1.21.0 for numerical operations, scikit-learn 0.23.2 for machine learning algorithms, and PyTorch 1.7.0 for deep learning capabilities.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/GATs/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information for Collector Script\nDESCRIPTION: This command shows the help information for the collector.py script, providing details on available options and usage.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/cn_index/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py --help\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for IBOVESPA Data Collection\nDESCRIPTION: Command to install the required Python libraries listed in the requirements.txt file, which was generated using Python 3.8.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/br_index/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Qlib\nDESCRIPTION: Install required Python packages numpy and cython before installing Qlib\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/introduction/quick.rst#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install numpy\npip install --upgrade  cython\n```\n\n----------------------------------------\n\nTITLE: Running IBOVESPA Data Collection Scripts\nDESCRIPTION: Commands to execute the collector.py script for IBOVESPA index data. The first command parses instruments for use in qlib/instruments, and the second command saves information about new companies in the index.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/br_index/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# parse instruments, using in qlib/instruments.\npython collector.py --index_name IBOV --qlib_dir ~/.qlib/qlib_data/br_data --method parse_instruments\n\n# parse new companies\npython collector.py --index_name IBOV --qlib_dir ~/.qlib/qlib_data/br_data --method save_new_companies\n```\n\n----------------------------------------\n\nTITLE: Defining QLib Python Dependencies with Minimum Version Requirements\nDESCRIPTION: Specifies the core Python package dependencies for the QLib project with their minimum version requirements. Includes numpy 1.17.4 or higher, pandas 1.0.1 or higher, and scikit-learn 0.23.1 or higher.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Linear/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy>=1.17.4\npandas>=1.0.1\nscikit-learn>=0.23.1\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation Header for Dataset Tests\nDESCRIPTION: Markdown documentation explaining the purpose of tests in the current directory, specifically focused on testing Yahoo finance prepared datasets.\nSOURCE: https://github.com/microsoft/qlib/blob/main/tests/dataset_tests/README.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# About dataset tests\nTests in this folder are for testing the prepared dataset from Yahoo\n```\n\n----------------------------------------\n\nTITLE: Parsing Instruments for Qlib\nDESCRIPTION: This command runs the collector.py script to parse instruments for the CSI300 index. It specifies the index name, Qlib data directory, and the parsing method.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/cn_index/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py --index_name CSI300 --qlib_dir ~/.qlib/qlib_data/cn_data --method parse_instruments\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies List\nDESCRIPTION: List of Python package dependencies required for the project. Includes data processing libraries (pandas), web scraping tools (requests, lxml), stock market data APIs (baostock, yahooquery), and utility packages (loguru, tqdm, openpyxl).\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/cn_index/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nbaostock\nfire\nrequests\npandas\nlxml\nloguru\ntqdm\nyahooquery\nopenpyxl\n```\n\n----------------------------------------\n\nTITLE: Saving New Companies Data for CSI300\nDESCRIPTION: This command executes the collector.py script to save data for new companies in the CSI300 index. It specifies the index name, Qlib data directory, and the method for saving new company data.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/cn_index/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py --index_name CSI300 --qlib_dir ~/.qlib/qlib_data/cn_data --method save_new_companies\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for qlib\nDESCRIPTION: This snippet defines the required Python packages and their versions for the qlib project. It includes pandas 1.1.2, numpy 1.21.0, and catboost 0.24.3.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/CatBoost/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\ncatboost==0.24.3\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies for Microsoft QLib Project\nDESCRIPTION: A list of Python package dependencies required for the Microsoft QLib project. The dependencies include loguru for logging, fire for building command-line interfaces, requests for HTTP requests, numpy and pandas for data processing, tqdm for progress bars, lxml for XML/HTML processing, and yahooquery for Yahoo Finance data retrieval.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nloguru\nfire\nrequests\nnumpy\npandas\ntqdm\nlxml\nloguru\nyahooquery\n```\n\n----------------------------------------\n\nTITLE: Pulling and Running Qlib Docker Image\nDESCRIPTION: Commands for pulling the Qlib Docker image from Docker Hub and starting a new container. This allows users to run Qlib scripts in an isolated environment.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull pyqlib/qlib_image_stable:stable\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --name <container name> -v <Mounted local directory>:/app qlib_image_stable\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies for QLib Project\nDESCRIPTION: A list of Python package dependencies required for the QLib project. The dependencies include loguru for logging, fire for command-line interfaces, tqdm for progress bars, requests for HTTP requests, pandas for data manipulation, lxml for XML/HTML processing, baostock for Chinese stock data, yahooquery for Yahoo Finance data, and beautifulsoup4 for web scraping.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/pit/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nloguru\nfire\ntqdm\nrequests\npandas\nlxml\nloguru\nbaostock\nyahooquery\nbeautifulsoup4\n```\n\n----------------------------------------\n\nTITLE: Running Qlib Scripts in Docker Environment\nDESCRIPTION: Example commands for running Qlib scripts within the Docker container, including data retrieval and workflow execution.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n>>> python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn\n>>> python qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: Lists required Python packages with specific version constraints. Includes pandas 1.1.2, numpy 1.21.0, and lightgbm with no version specified.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/LightGBM/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plain\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nlightgbm\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Data Normalization Class\nDESCRIPTION: Template for implementing a custom data normalization class that inherits from BaseNormalize.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/README.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass UserNormalzie(BaseNormalize):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Managing Docker Containers for Qlib\nDESCRIPTION: Commands for exiting, restarting, stopping, and deleting Docker containers used for Qlib. These are essential for managing the Docker environment.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n>>> exit\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker start -i -a <container name>\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker stop <container name>\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker rm <container name>\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: Specifies the exact versions of Python packages required for the Microsoft QLib project. Includes core data science libraries like pandas, numpy, scikit-learn, and PyTorch.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/ADARNN/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Running Automated Quant Research Workflow with qrun\nDESCRIPTION: Commands for executing the qrun tool to run an automated quant research workflow using a LightGBM configuration. This includes options for debug mode.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd examples  # Avoid running program under the directory contains `qlib`\nqrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\npython -m pdb qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies\nDESCRIPTION: Defines exact version requirements for three essential Python packages: numpy for numerical computing, pandas for data manipulation, and PyTorch for deep learning.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Localformer/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\ntorch==1.2.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft Qlib\nDESCRIPTION: This code snippet defines the exact versions of key Python libraries required for the Microsoft Qlib project. It includes data manipulation, numerical computation, machine learning, and deep learning libraries.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/HIST/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Installing Qlib via pip\nDESCRIPTION: Basic pip installation command for the stable version of Qlib\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install pyqlib\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for QLib\nDESCRIPTION: This snippet specifies the exact versions of Python packages required for the QLib project. It includes NumPy 1.21.0 for numerical operations, pandas 1.1.2 for data manipulation, scikit-learn 0.23.2 for machine learning algorithms, and PyTorch 1.7.0 for deep learning capabilities.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/LSTM/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Installing Qlib Dependencies\nDESCRIPTION: Installation of required dependencies before installing Qlib from source\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install numpy\npip install --upgrade cython\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies\nDESCRIPTION: Specifies exact version requirements for NumPy (1.23.4) and Pandas (1.5.2) packages. These versions are pinned to ensure consistent behavior across different environments.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Sandwich/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.23.4\npandas==1.5.2\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft Qlib\nDESCRIPTION: This snippet defines the exact versions of Python packages required for the Microsoft Qlib project. It includes data manipulation, scientific computing, machine learning, and deep learning libraries.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/MLP/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Installing Qlib from Source\nDESCRIPTION: Steps to clone and install the latest development version of Qlib from GitHub\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/microsoft/qlib.git && cd qlib\npip install .\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft Qlib\nDESCRIPTION: This code snippet defines the exact versions of key Python packages required for the Microsoft Qlib project. It includes NumPy for numerical computing, pandas for data manipulation, scikit-learn for machine learning, and PyTorch for deep learning.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TCN/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Starting Qlib Docker Container\nDESCRIPTION: Command to start a new Docker container using the Qlib image, with a mounted local directory for data persistence.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --name <container name> -v <Mounted local directory>:/app <image name>\n```\n\n----------------------------------------\n\nTITLE: Importing Meta Dataset Class in Python\nDESCRIPTION: This snippet demonstrates the import statement for the MetaTaskDataset class from the qlib.model.meta.dataset module. The MetaTaskDataset class controls the meta-information generating process and provides data for training the Meta Model.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/component/meta.rst#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.model.meta.dataset import MetaTaskDataset\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Qlib\nDESCRIPTION: This snippet lists the required Python packages and their versions for the Qlib project. It includes pandas 1.1.2, numpy 1.21.0, scikit-learn 0.23.2, PyTorch 1.7.0, and seaborn (version unspecified).\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\nseaborn\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for QLib\nDESCRIPTION: Lists the exact versions of Python packages required for the QLib project to function properly, including data manipulation libraries (pandas, numpy), machine learning (scikit-learn), and deep learning (PyTorch).\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/SFM/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies with Version Requirements for QLib\nDESCRIPTION: This snippet defines the exact versions of essential Python libraries required by the QLib project. It includes numpy for numerical operations, pandas for data manipulation, and PyTorch for machine learning functionality.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/Transformer/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\ntorch==1.2.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Qlib\nDESCRIPTION: This requirements specification lists the exact versions of Python packages needed to run the Qlib project. It includes NumPy 1.21.0 for numerical computing, pandas 1.1.2 for data manipulation, scikit-learn 0.23.2 for machine learning algorithms, and PyTorch 1.7.0 for deep learning functionality.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/ADD/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Defining Qlib Documentation Structure in reStructuredText\nDESCRIPTION: This snippet defines the structure of the Qlib documentation using reStructuredText directives. It includes sections for getting started, main components, advanced topics, developer guides, and references. The structure is organized using toctree directives with specified depth and captions.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n======================\n``Qlib`` Documentation\n======================\n\n``Qlib`` is an AI-oriented quantitative investment platform, which aims to realize the potential, empower the research, and create the value of AI technologies in quantitative investment.\n\n.. _user_guide:\n\nDocument Structure\n====================\n\n.. toctree::\n   :hidden:\n\n   Home <self>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: GETTING STARTED:\n\n   Introduction <introduction/introduction.rst>\n   Quick Start <introduction/quick.rst>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: FIRST STEPS:\n\n   Installation <start/installation.rst>\n   Initialization <start/initialization.rst>\n   Data Retrieval <start/getdata.rst>\n   Custom Model Integration <start/integration.rst>\n\n\n.. toctree::\n   :maxdepth: 3\n   :caption: MAIN COMPONENTS:\n\n   Workflow: Workflow Management <component/workflow.rst>\n   Data Layer: Data Framework & Usage <component/data.rst>\n   Forecast Model: Model Training & Prediction <component/model.rst>\n   Portfolio Management and Backtest <component/strategy.rst>\n   Nested Decision Execution: High-Frequency Trading <component/highfreq.rst>\n   Meta Controller: Meta-Task & Meta-Dataset & Meta-Model <component/meta.rst>\n   Qlib Recorder: Experiment Management <component/recorder.rst>\n   Analysis: Evaluation & Results Analysis <component/report.rst>\n   Online Serving: Online Management & Strategy & Tool <component/online.rst>\n   Reinforcement Learning <component/rl/toctree>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: OTHER COMPONENTS/FEATURES/TOPICS:\n\n   Building Formulaic Alphas <advanced/alpha.rst>\n   Online & Offline mode <advanced/server.rst>\n   Serialization <advanced/serial.rst>\n   Task Management <advanced/task_management.rst>\n   Point-In-Time database <advanced/PIT.rst>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: FOR DEVELOPERS:\n\n   Code Standard & Development Guidance <developer/code_standard_and_dev_guide.rst>\n   How to build image <developer/how_to_build_image.rst>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: REFERENCE:\n\n   API <reference/api.rst>\n\n.. toctree::\n   :maxdepth: 3\n\n   FAQ <FAQ/FAQ.rst>\n\n.. toctree::\n   :maxdepth: 3\n   :caption: Change Log:\n\n   Change Log <changelog/changelog.rst>\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Dependencies for QLib\nDESCRIPTION: Defines version-specific Python package dependencies including Pandas, NumPy, LightGBM, and Optuna required for running QLib machine learning framework. Each package is pinned to a specific version to ensure compatibility.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/hyperparameter/LightGBM/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nlightgbm==3.1.0\noptuna==2.7.0\noptuna-dashboard==0.4.1\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies\nDESCRIPTION: Defines exact versions of required Python packages for the project. Includes numpy 1.23.4 and pandas 1.5.2 which are essential data manipulation libraries.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/KRNN/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.23.4\npandas==1.5.2\n```\n\n----------------------------------------\n\nTITLE: Finding TODO and FIXME Items in Qlib Codebase\nDESCRIPTION: A shell command to find imperfect implementations in the Qlib codebase that are marked with TODO or FIXME comments, which could be potential areas for contribution.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nrg 'TODO|FIXME' qlib\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies Configuration\nDESCRIPTION: Specifies exact versions of required Python packages including pandas, numpy, scikit-learn, and PyTorch. These dependencies are essential for data manipulation, numerical computing, machine learning, and deep learning functionality.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TabNet/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.1.2\nnumpy==1.21.0\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Data and Backtest for Qlib Tuner in YAML\nDESCRIPTION: This YAML snippet shows how to configure data sources and backtest parameters for Qlib tuner experiments, including data class, provider, date ranges, and filtering options.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ndata:\n    class: ALPHA360\n    provider_uri: /data/qlib\n    args:\n        start_date: 2005-01-01\n        end_date: 2018-04-30\n        dropna_label: True\n        dropna_feature: True\n        feature_label_config: /home/v-yindzh/v-yindzh/QLib/cfg/feature_config.yaml\n    filter:\n        market: csi500\n        filter_pipeline:\n          -\n            class: NameDFilter\n            module_path: qlib.filter\n            args:\n              name_rule_re: S(?!Z3)\n              fstart_time: 2018-01-01\n              fend_time: 2018-12-11\n          -\n            class: ExpressionDFilter\n            module_path: qlib.filter\n            args:\n              rule_expression: $open/$factor<=45\n              fstart_time: 2018-01-01\n              fend_time: 2018-12-11\nbacktest:\n    normal_backtest_args:\n        limit_threshold: 0.095\n        account: 500000\n        benchmark: SH000905\n        deal_price: vwap\n    long_short_backtest_args:\n        topk: 50\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for TensorFlow GPU and Pandas\nDESCRIPTION: Specifies the exact versions of TensorFlow GPU (1.15.0) and Pandas (1.1.0) required for the project. These package versions should be installed using pip or another Python package manager.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TFT/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntensorflow-gpu==1.15.0\npandas==1.1.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft Qlib\nDESCRIPTION: This snippet lists the required Python packages and their specific versions for the Microsoft Qlib project. It includes numpy 1.21.0, pandas 1.1.2, scikit-learn 0.23.2, and PyTorch 1.7.0. These dependencies are crucial for the proper functioning of the Qlib library.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/ALSTM/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Time Periods for Qlib Tuner Experiments in YAML\nDESCRIPTION: This YAML configuration sets up the time periods for training, validation, and testing in Qlib tuner experiments. It includes rolling period and date ranges for each phase.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ntime_period:\n    rolling_period: 360\n    train_start_date: 2005-01-01\n    train_end_date: 2014-12-31\n    validate_start_date: 2015-01-01\n    validate_end_date: 2016-06-30\n    test_start_date: 2016-07-01\n    test_end_date: 2018-04-30\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Microsoft QLib\nDESCRIPTION: This code snippet defines the exact versions of essential Python packages required for the Microsoft QLib project. It ensures compatibility and consistent behavior across different environments.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/benchmarks/GRU/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nnumpy==1.21.0\npandas==1.1.2\nscikit_learn==0.23.2\ntorch==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Python Project Dependencies List in Requirements Format\nDESCRIPTION: A requirements.txt file that lists all Python package dependencies with their specific versions required for the qlib project. The file includes libraries for data manipulation (pandas, numpy), API access (requests, yahooquery, pycoingecko), async operations (async-generator, trio), and utilities (loguru, tqdm).\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/br_index/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nasync-generator==1.10\nattrs==21.4.0\ncertifi==2022.12.7\ncffi==1.15.0\ncharset-normalizer==2.0.12\ncryptography==36.0.1\nfire==0.4.0\nh11==0.13.0\nidna==3.3\nloguru==0.6.0\nlxml==4.9.1\nmultitasking==0.0.10\nnumpy==1.22.2\noutcome==1.1.0\npandas==1.4.1\npycoingecko==2.2.0\npycparser==2.21\npyOpenSSL==22.0.0\nPySocks==1.7.1\npython-dateutil==2.8.2\npytz==2021.3\nrequests==2.27.1\nrequests-futures==1.0.0\nsix==1.16.0\nsniffio==1.2.0\nsortedcontainers==2.4.0\ntermcolor==1.1.0\ntqdm==4.63.0\ntrio==0.20.0\ntrio-websocket==0.9.2\nurllib3==1.26.19\nwget==3.2\nwsproto==1.1.0\nyahooquery==2.2.15\n```\n\n----------------------------------------\n\nTITLE: Basic Tuner Configuration in YAML\nDESCRIPTION: Example configuration showing the core structure for a tuner experiment, including experiment metadata, optimization criteria, and tuner pipeline setup.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nexperiment:\n    name: tuner_experiment\n    tuner_class: QLibTuner\nqlib_client:\n    auto_mount: False\n    logging_level: INFO\noptimization_criteria:\n    report_type: model\n    report_factor: model_score\n    optim_type: max\ntuner_pipeline:\n  -\n    model:\n        class: SomeModel\n        space: SomeModelSpace\n    trainer:\n        class: RollingTrainer\n    strategy:\n        class: TopkAmountStrategy\n        space: TopkAmountStrategySpace\n    max_evals: 2\n```\n\n----------------------------------------\n\nTITLE: Markdown Badges for Qlib Project Status\nDESCRIPTION: Collection of badges showing project status including Python versions, platform support, PyPI version, build status, documentation status, license and chat information.\nSOURCE: https://github.com/microsoft/qlib/blob/main/README.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[![Python Versions](https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&logoColor=white)](https://pypi.org/project/pyqlib/#files)\n[![Platform](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey)](https://pypi.org/project/pyqlib/#files)\n[![PypI Versions](https://img.shields.io/pypi/v/pyqlib)](https://pypi.org/project/pyqlib/#history)\n[![Upload Python Package](https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg)](https://pypi.org/project/pyqlib/)\n[![Github Actions Test Status](https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main)](https://github.com/microsoft/qlib/actions)\n[![Documentation Status](https://readthedocs.org/projects/qlib/badge/?version=latest)](https://qlib.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/pypi/l/pyqlib)](LICENSE)\n[![Join the chat at https://gitter.im/Microsoft/qlib](https://badges.gitter.im/Microsoft/qlib.svg)](https://gitter.im/Microsoft/qlib?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n```\n\n----------------------------------------\n\nTITLE: Running Tuner via Command Line\nDESCRIPTION: Example command to execute the tuner program using a configuration file\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/tuner.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n~/v-yindzh/Qlib/cfg$ tuner -c tuner_config.yaml\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib Client on Internal Server (Python)\nDESCRIPTION: Example of initializing Qlib client on internal servers 10.150.144.153 or 10.150.144.154 without auto-mounting.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/hidden/client.rst#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import qlib\n>>> qlib.init(auto_mount=False, mount_path='/data/csdesign/qlib')\n>>> from qlib.data import D\n>>> D.features(['SH600000'], ['$close'], start_time='20080101', end_time='20090101').head()\n```\n\n----------------------------------------\n\nTITLE: Managing Qlib Docker Container\nDESCRIPTION: Commands for exiting, restarting, stopping, and deleting the Qlib Docker container.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n>>> exit\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker start -i -a <container name>\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker stop -i -a <container name>\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker rm <container name>\n```\n\n----------------------------------------\n\nTITLE: Running Automated Qlib Docker Image Build Script\nDESCRIPTION: Command to run the automated build script for Qlib Docker images. The script prompts for version selection and whether to upload to Docker Hub.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsh build_docker_image.sh\n>>> Do you want to build the nightly version of the qlib image? (default is stable) (yes/no):\n>>> Is it uploaded to docker hub? (default is no) (yes/no):\n```\n\n----------------------------------------\n\nTITLE: Building Nightly Qlib Docker Image\nDESCRIPTION: Command to build the nightly version of the Qlib Docker image using the current source code. The IS_STABLE build argument is set to 'no'.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/developer/how_to_build_image.rst#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker build --build-arg IS_STABLE=no -t <image name> -f ./Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: Including CHANGES.rst File in reStructuredText Documentation\nDESCRIPTION: This directive includes the contents of the CHANGES.rst file located two directories up from the current file. It's commonly used in Sphinx documentation to incorporate changelog information.\nSOURCE: https://github.com/microsoft/qlib/blob/main/docs/changelog/changelog.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. include:: ../../CHANGES.rst\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Stock Data Collection\nDESCRIPTION: Command to install required dependencies from requirements.txt file for the data collection process.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/us_index/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information for Data Collection\nDESCRIPTION: Shows how to access the help information for the collector_data command in the collector.py script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/fund/README.md#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npythono collector.py collector_data --help\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information\nDESCRIPTION: Command to show help information for the get_data.py script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython get_data.py qlib_data --help\n```\n\n----------------------------------------\n\nTITLE: Downloading CN Simple Data with Bash\nDESCRIPTION: Command to download a simplified version of Chinese market data using get_data.py script.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --region cn\n```\n\n----------------------------------------\n\nTITLE: Initializing Qlib and Importing Dependencies in Python\nDESCRIPTION: This snippet sets up the environment by installing Qlib if not present, downloading necessary scripts, and importing required libraries. It also checks for and downloads financial data if not available locally.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport sys, site\nfrom pathlib import Path\n\ntry:\n    import qlib\nexcept ImportError:\n    # install qlib\n    ! pip install --upgrade numpy\n    ! pip install pyqlib\n    if \"google.colab\" in sys.modules:\n        # The Google colab environment is a little outdated. We have to downgrade the pyyaml to make it compatible with other packages\n        ! pip install pyyaml==5.4.1\n    # reload\n    site.main()\n\nscripts_dir = Path.cwd().parent.joinpath(\"scripts\")\nif not scripts_dir.joinpath(\"get_data.py\").exists():\n    # download get_data.py script\n    scripts_dir = Path(\"~/tmp/qlib_code/scripts\").expanduser().resolve()\n    scripts_dir.mkdir(parents=True, exist_ok=True)\n    import requests\n\n    with requests.get(\"https://raw.githubusercontent.com/microsoft/qlib/main/scripts/get_data.py\", timeout=10) as resp:\n        with open(scripts_dir.joinpath(\"get_data.py\"), \"wb\") as fp:\n            fp.write(resp.content)\n```\n\n----------------------------------------\n\nTITLE: Fetching Calendar Data\nDESCRIPTION: Demonstrates how to retrieve calendar data from Qlib's data source for a specific time range.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom qlib.data import D\n\nprint(D.calendar(start_time=\"2010-01-01\", end_time=\"2017-12-31\", freq=\"day\")[:2])\n```\n\n----------------------------------------\n\nTITLE: Preparing Label Data for Model Analysis\nDESCRIPTION: Prepares the ground truth label data from the test dataset to compare against model predictions for evaluation.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nlabel_df = dataset.prepare(\"test\", col_set=\"label\")\nlabel_df.columns = [\"label\"]\n```\n\n----------------------------------------\n\nTITLE: Importing Basic Dependencies\nDESCRIPTION: Imports fundamental Python libraries needed for data analysis and file handling.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/tutorial/detailed_workflow.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\nfrom pathlib import Path\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Introducing Data Module Examples in Markdown\nDESCRIPTION: This markdown snippet introduces a folder containing examples that demonstrate common usage of data-related modules in Qlib. It provides context for the purpose of the examples and their relevance to the Qlib project.\nSOURCE: https://github.com/microsoft/qlib/blob/main/examples/data_demo/README.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Introduction\nThe examples in this folder try to demonstrate some common usage of data-related modules of Qlib\n```\n\n----------------------------------------\n\nTITLE: Help Command\nDESCRIPTION: Command to display help information for the collector script\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/crypto/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython collector.py collector_data --help\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Qlib Data Processing\nDESCRIPTION: This command installs the required dependencies for the data filling script using pip and a requirements file.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/fill_cn_1min_data/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Downloading QLib Data using get_data.py\nDESCRIPTION: Downloads pre-prepared QLib data for HS300 index with 5-minute intervals into a specified target directory.\nSOURCE: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/baostock_5min/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/hs300_data_5min --region hs300 --interval 5min\n```"
  }
]