[
  {
    "owner": "openai",
    "repo": "openai-python",
    "content": "TITLE: Installing the OpenAI Python library with pip\nDESCRIPTION: Command to install the OpenAI Python library from PyPI using pip. This is the standard way to add the library to your Python environment.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# install from PyPI\npip install openai\n```\n\n----------------------------------------\n\nTITLE: Pydantic Model Parsing with OpenAI Chat Completions\nDESCRIPTION: Demonstrates how to use Pydantic models to automatically parse structured outputs from OpenAI chat completions. The example shows parsing a math problem solution into a defined data structure.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\nclass Step(BaseModel):\n    explanation: str\n    output: str\n\nclass MathResponse(BaseModel):\n    steps: List[Step]\n    final_answer: str\n\nclient = OpenAI()\ncompletion = client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"},\n        {\"role\": \"user\", \"content\": \"solve 8x + 31 = 2\"},\n    ],\n    response_format=MathResponse,\n)\n\nmessage = completion.choices[0].message\nif message.parsed:\n    print(message.parsed.steps)\n    print(\"answer: \", message.parsed.final_answer)\nelse:\n    print(message.refusal)\n```\n\n----------------------------------------\n\nTITLE: Using the Chat Completions API with OpenAI\nDESCRIPTION: Example of using the traditional Chat Completions API to generate text from an OpenAI model. It creates a client and sends a chat completion request with role-based messages.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"developer\", \"content\": \"Talk like a pirate.\"},\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I check if a Python object is an instance of a class?\",\n        },\n    ],\n)\n\nprint(completion.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Customizing OpenAI HTTP Client on a Per-Request Basis\nDESCRIPTION: Demonstrates how to customize the OpenAI client's HTTP settings for a specific request using the with_options() method, allowing for temporary configuration changes without modifying the base client.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nclient.with_options(http_client=DefaultHttpxClient(...))\n```\n\n----------------------------------------\n\nTITLE: Managing HTTP Resources with Context Manager in OpenAI Python Client\nDESCRIPTION: Shows how to properly manage HTTP resources in the OpenAI client using Python's context manager pattern. This ensures connections are properly closed when operations are completed.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nwith OpenAI() as client:\n  # make requests here\n  ...\n\n# HTTP client is now closed\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in OpenAI Python SDK\nDESCRIPTION: Demonstrates error handling with try-except blocks for various API errors including connection issues and different status codes returned by the OpenAI API.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ntry:\n    client.fine_tuning.jobs.create(\n        model=\"gpt-4o\",\n        training_file=\"file-abc123\",\n    )\nexcept openai.APIConnectionError as e:\n    print(\"The server could not be reached\")\n    print(e.__cause__)  # an underlying Exception, likely raised within httpx.\nexcept openai.RateLimitError as e:\n    print(\"A 429 status code was received; we should back off a bit.\")\nexcept openai.APIStatusError as e:\n    print(\"Another non-200-range status code was received\")\n    print(e.status_code)\n    print(e.response)\n```\n\n----------------------------------------\n\nTITLE: Async Streaming with OpenAI Chat Completions\nDESCRIPTION: Demonstrates how to use the async streaming API for chat completions. Shows usage of the context manager and event handling for streamed responses.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\nasync with client.beta.chat.completions.stream(\n    model='gpt-4o-2024-08-06',\n    messages=[...],\n) as stream:\n    async for event in stream:\n        if event.type == 'content.delta':\n            print(event.content, flush=True, end='')\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Client for API Interaction\nDESCRIPTION: Demonstrates how to set up and use the AzureOpenAI client to interact with Azure's OpenAI service. Includes setting the API version, endpoint, and creating a chat completion with a deployment model.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AzureOpenAI\n\n# gets the API Key from environment variable AZURE_OPENAI_API_KEY\nclient = AzureOpenAI(\n    # https://learn.microsoft.com/azure/ai-services/openai/reference#rest-api-versioning\n    api_version=\"2023-07-01-preview\",\n    # https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n    azure_endpoint=\"https://example-endpoint.openai.azure.com\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"deployment-name\",  # e.g. gpt-35-instant\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.to_json())\n```\n\n----------------------------------------\n\nTITLE: Configuring Retries in OpenAI Python SDK\nDESCRIPTION: Demonstrates how to configure retry behavior globally or per-request, either disabling retries or increasing the maximum number of retries.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # default is 2\n    max_retries=0,\n)\n\n# Or, configure per-request:\nclient.with_options(max_retries=5).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I get the name of the current day in JavaScript?\",\n        }\n    ],\n    model=\"gpt-4o\",\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Timeouts in OpenAI Python SDK\nDESCRIPTION: Shows how to configure request timeouts globally or per-request, including examples of simple timeout values and more granular timeout control.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # 20 seconds (default is 10 minutes)\n    timeout=20.0,\n)\n\n# More granular control:\nclient = OpenAI(\n    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),\n)\n\n# Override per-request:\nclient.with_options(timeout=5.0).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I list all files in a directory using Python?\",\n        }\n    ],\n    model=\"gpt-4o\",\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming responses with OpenAI\nDESCRIPTION: Example of streaming responses using Server Side Events (SSE). The code creates a stream and iterates through events as they arrive, providing real-time access to model outputs.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nstream = client.responses.create(\n    model=\"gpt-4o\",\n    input=\"Write a one-sentence bedtime story about a unicorn.\",\n    stream=True,\n)\n\nfor event in stream:\n    print(event)\n```\n\n----------------------------------------\n\nTITLE: Processing images with Vision API using URL\nDESCRIPTION: Example of using the Vision capabilities to analyze an image from a URL. The code sends both text prompt and image URL to the model to get a description of the image content.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"What is in this image?\"\nimg_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2023_06_08_Raccoon1.jpg/1599px-2023_06_08_Raccoon1.jpg\"\n\nresponse = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"input_text\", \"text\": prompt},\n                {\"type\": \"input_image\", \"image_url\": f\"{img_url}\"},\n            ],\n        }\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Using the Responses API with OpenAI\nDESCRIPTION: Example of using the Responses API to generate text from an OpenAI model. It creates a client, sets the API key, and sends a request to generate text based on instructions and input.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    instructions=\"You are a coding assistant that talks like a pirate.\",\n    input=\"How do I check if a Python object is an instance of a class?\",\n)\n\nprint(response.output_text)\n```\n\n----------------------------------------\n\nTITLE: Processing images with Vision API using base64 encoding\nDESCRIPTION: Example of using the Vision capabilities with a locally stored image. The code reads an image file, converts it to a base64 encoded string, and sends it to the model along with a text prompt.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport base64\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nprompt = \"What is in this image?\"\nwith open(\"path/to/image.png\", \"rb\") as image_file:\n    b64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nresponse = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"input_text\", \"text\": prompt},\n                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"},\n            ],\n        }\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Using the AsyncOpenAI client for asynchronous operations\nDESCRIPTION: Example of using the AsyncOpenAI client for asynchronous operations. It imports the AsyncOpenAI class, creates an async client, and demonstrates how to use it with async/await syntax.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI(\n    # This is the default and can be omitted\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n\n\nasync def main() -> None:\n    response = await client.responses.create(\n        model=\"gpt-4o\", input=\"Explain disestablishmentarianism to a smart five year old.\"\n    )\n    print(response.output_text)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Making Custom API Requests in OpenAI Python SDK\nDESCRIPTION: Demonstrates how to make requests to undocumented endpoints using HTTP verbs directly and how to send extra parameters that might not be covered in the SDK's typed interface.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\n\nresponse = client.post(\n    \"/foo\",\n    cast_to=httpx.Response,\n    body={\"my_param\": True},\n)\n\nprint(response.headers.get(\"x-foo\"))\n```\n\n----------------------------------------\n\nTITLE: Function Tool Calls with Pydantic Models\nDESCRIPTION: Shows how to use Pydantic models for automatic parsing of function tool calls. The example implements a database query builder with strict schema validation.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\nfrom typing import List, Union\nfrom pydantic import BaseModel\nimport openai\n\nclass Table(str, Enum):\n    orders = \"orders\"\n    customers = \"customers\"\n    products = \"products\"\n\nclass Column(str, Enum):\n    id = \"id\"\n    status = \"status\"\n    expected_delivery_date = \"expected_delivery_date\"\n    delivered_at = \"delivered_at\"\n    shipped_at = \"shipped_at\"\n    ordered_at = \"ordered_at\"\n    canceled_at = \"canceled_at\"\n\nclass Operator(str, Enum):\n    eq = \"=\"\n    gt = \">\"\n    lt = \"<\"\n    le = \"<=\"\n    ge = \">=\"\n    ne = \"!=\"\n\nclass OrderBy(str, Enum):\n    asc = \"asc\"\n    desc = \"desc\"\n\nclass DynamicValue(BaseModel):\n    column_name: str\n\nclass Condition(BaseModel):\n    column: str\n    operator: Operator\n    value: Union[str, int, DynamicValue]\n\nclass Query(BaseModel):\n    table_name: Table\n    columns: List[Column]\n    conditions: List[Condition]\n    order_by: OrderBy\n\nclient = openai.OpenAI()\ncompletion = client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant. The current date is August 6, 2024. You help users query for the data they are looking for by calling the query function.\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"look up all my orders in may of last year that were fulfilled but not delivered on time\",\n        },\n    ],\n    tools=[\n        openai.pydantic_function_tool(Query),\n    ],\n)\n\ntool_call = (completion.choices[0].message.tool_calls or [])[0]\nprint(tool_call.function)\nassert isinstance(tool_call.function.parsed_arguments, Query)\nprint(tool_call.function.parsed_arguments.table_name)\n```\n\n----------------------------------------\n\nTITLE: Assistant Methods in OpenAI Python SDK\nDESCRIPTION: This section lists convenience methods provided by the assistant streaming object, including methods to access current context and methods to get final run information.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef current_event() -> AssistantStreamEvent | None\ndef current_run() -> Run | None\ndef current_message_snapshot() -> Message | None\ndef current_run_step_snapshot() -> RunStep | None\n```\n\nLANGUAGE: python\nCODE:\n```\ndef get_final_run(self) -> Run\ndef get_final_run_steps(self) -> List[RunStep]\ndef get_final_messages(self) -> List[Message]\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Client with Custom Proxy and Transport in OpenAI Python Client\nDESCRIPTION: Shows how to configure the OpenAI client with a custom HTTP client using httpx. This example demonstrates setting a custom base URL, proxy, and transport configuration for specialized networking requirements.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nfrom openai import OpenAI, DefaultHttpxClient\n\nclient = OpenAI(\n    # Or use the `OPENAI_BASE_URL` env var\n    base_url=\"http://my.test.server.example.com:8083/v1\",\n    http_client=DefaultHttpxClient(\n        proxy=\"http://my.test.proxy.example.com\",\n        transport=httpx.HTTPTransport(local_address=\"0.0.0.0\"),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Using Nested Parameters with OpenAI Python SDK\nDESCRIPTION: Demonstrates how to use nested dictionary parameters with TypedDict in the OpenAI Python SDK to create a chat response with JSON formatting.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.responses.create(\n    input=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How much ?\",\n        }\n    ],\n    model=\"gpt-4o\",\n    response_format={\"type\": \"json_object\"},\n)\n```\n\n----------------------------------------\n\nTITLE: Using the Realtime API for text-based conversations\nDESCRIPTION: Example of using the beta Realtime API for text-based conversations. It establishes a WebSocket connection, updates the session to use text modality, and processes events in real-time as they arrive from the server.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def main():\n    client = AsyncOpenAI()\n\n    async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as connection:\n        await connection.session.update(session={'modalities': ['text']})\n\n        await connection.conversation.item.create(\n            item={\n                \"type\": \"message\",\n                \"role\": \"user\",\n                \"content\": [{\"type\": \"input_text\", \"text\": \"Say hello!\"}],\n            }\n        )\n        await connection.response.create()\n\n        async for event in connection:\n            if event.type == 'response.text.delta':\n                print(event.delta, flush=True, end=\"\")\n\n            elif event.type == 'response.text.done':\n                print()\n\n            elif event.type == \"response.done\":\n                break\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Accessing Request IDs in OpenAI Python SDK\nDESCRIPTION: Shows how to access request IDs from successful responses and from API error objects for debugging and reporting issues to OpenAI.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nresponse = await client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=\"Say 'this is a test'.\",\n)\nprint(response._request_id)  # req_123\n```\n\nLANGUAGE: python\nCODE:\n```\nimport openai\n\ntry:\n    completion = await client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}], model=\"gpt-4\"\n    )\nexcept openai.APIStatusError as exc:\n    print(exc.request_id)  # req_123\n    raise exc\n```\n\n----------------------------------------\n\nTITLE: Streaming responses with AsyncOpenAI\nDESCRIPTION: Example of streaming responses using the asynchronous client. It demonstrates how to create an async stream and process events in an asynchronous context.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\nasync def main():\n    stream = client.responses.create(\n        model=\"gpt-4o\",\n        input=\"Write a one-sentence bedtime story about a unicorn.\",\n        stream=True,\n    )\n\n    for event in stream:\n        print(event)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Handling errors in the Realtime API\nDESCRIPTION: Example of error handling with the Realtime API. It shows how to check for error events in the connection stream and extract error details such as type, code, event ID, and message.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclient = AsyncOpenAI()\n\nasync with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as connection:\n    ...\n    async for event in connection:\n        if event.type == 'error':\n            print(event.error.type)\n            print(event.error.code)\n            print(event.error.event_id)\n            print(event.error.message)\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses in OpenAI Python SDK\nDESCRIPTION: Shows how to stream response data using the with_streaming_response method in a context manager to efficiently process large responses.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nwith client.chat.completions.with_streaming_response.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        }\n    ],\n    model=\"gpt-4o\",\n) as response:\n    print(response.headers.get(\"X-My-Header\"))\n\n    for line in response.iter_lines():\n        print(line)\n```\n\n----------------------------------------\n\nTITLE: Working directly with paginated data in OpenAI API\nDESCRIPTION: Example of working directly with paginated data in the OpenAI API. It shows how to access the cursor for the next page and iterate through the current page's data items.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfirst_page = await client.fine_tuning.jobs.list(\n    limit=20,\n)\n\nprint(f\"next page cursor: {first_page.after}\")  # => \"next page cursor: ...\"\nfor job in first_page.data:\n    print(job.id)\n\n# Remove `await` for non-async usage.\n```\n\n----------------------------------------\n\nTITLE: Creating a Run and Subscribing to Events with Python OpenAI SDK\nDESCRIPTION: This snippet demonstrates how to create an event handler class and use it to stream responses from an Assistant run. It shows how to handle different types of events such as text creation, text delta, and tool calls.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler, OpenAI\nfrom openai.types.beta.threads import Text, TextDelta\nfrom openai.types.beta.threads.runs import ToolCall, ToolCallDelta\n\nclient = openai.OpenAI()\n\n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n\nclass EventHandler(AssistantEventHandler):\n  @override\n  def on_text_created(self, text: Text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n\n  @override\n  def on_text_delta(self, delta: TextDelta, snapshot: Text):\n    print(delta.value, end=\"\", flush=True)\n\n  @override\n  def on_tool_call_created(self, tool_call: ToolCall):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n\n  @override\n  def on_tool_call_delta(self, delta: ToolCallDelta, snapshot: ToolCall):\n    if delta.type == \"code_interpreter\" and delta.code_interpreter:\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n\n# Then, we use the `stream` SDK helper\n# with the `EventHandler` class to create the Run\n# and stream the response.\n\nwith client.beta.threads.runs.stream(\n  thread_id=\"thread_id\",\n  assistant_id=\"assistant_id\",\n  event_handler=EventHandler(),\n) as stream:\n  stream.until_done()\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Text Deltas in OpenAI Assistant API Stream\nDESCRIPTION: This snippet demonstrates how to iterate specifically over text deltas received from an Assistant run stream.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith client.beta.threads.runs.stream(\n  thread_id=thread.id,\n  assistant_id=assistant.id\n) as stream:\n    for text in stream.text_deltas:\n        print(text)\n```\n\n----------------------------------------\n\nTITLE: Creating Streams with OpenAI Python SDK\nDESCRIPTION: This section shows three helper methods for creating streams: streaming an existing run, creating a thread with a message and streaming the run, and submitting tool outputs to a run and streaming the response.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclient.beta.threads.runs.stream()\n```\n\nLANGUAGE: python\nCODE:\n```\nclient.beta.threads.create_and_run_stream()\n```\n\nLANGUAGE: python\nCODE:\n```\nclient.beta.threads.runs.submit_tool_outputs_stream()\n```\n\n----------------------------------------\n\nTITLE: Uploading Files with OpenAI Python SDK\nDESCRIPTION: Shows how to upload files to the OpenAI API using Path objects, bytes, or tuples of filename, contents, and media type.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nclient.files.create(\n    file=Path(\"input.jsonl\"),\n    purpose=\"fine-tune\",\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Chat Completion Types in Python\nDESCRIPTION: Imports comprehensive type definitions for the Chat Completions API, including message types, content parts, tool calls, and response formats for different chat interaction patterns.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.chat import (\n    ChatCompletion,\n    ChatCompletionAssistantMessageParam,\n    ChatCompletionAudio,\n    ChatCompletionAudioParam,\n    ChatCompletionChunk,\n    ChatCompletionContentPart,\n    ChatCompletionContentPartImage,\n    ChatCompletionContentPartInputAudio,\n    ChatCompletionContentPartRefusal,\n    ChatCompletionContentPartText,\n    ChatCompletionDeleted,\n    ChatCompletionDeveloperMessageParam,\n    ChatCompletionFunctionCallOption,\n    ChatCompletionFunctionMessageParam,\n    ChatCompletionMessage,\n    ChatCompletionMessageParam,\n    ChatCompletionMessageToolCall,\n    ChatCompletionModality,\n    ChatCompletionNamedToolChoice,\n    ChatCompletionPredictionContent,\n    ChatCompletionRole,\n    ChatCompletionStoreMessage,\n    ChatCompletionStreamOptions,\n    ChatCompletionSystemMessageParam,\n    ChatCompletionTokenLogprob,\n    ChatCompletionTool,\n    ChatCompletionToolChoiceOption,\n    ChatCompletionToolMessageParam,\n    ChatCompletionUserMessageParam,\n    ChatCompletionReasoningEffort,\n)\n```\n\n----------------------------------------\n\nTITLE: Asynchronous pagination with the OpenAI API\nDESCRIPTION: Example of using asynchronous auto-pagination with the OpenAI API. It demonstrates how to iterate through paginated results asynchronously using async for, automatically fetching more pages as needed.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\nasync def main() -> None:\n    all_jobs = []\n    # Iterate through items across all pages, issuing requests as needed.\n    async for job in client.fine_tuning.jobs.list(\n        limit=20,\n    ):\n        all_jobs.append(job)\n    print(all_jobs)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Pagination with the OpenAI API using auto-pagination\nDESCRIPTION: Example of using auto-pagination with the OpenAI API. The code iterates through all items across multiple pages, automatically fetching more pages as needed without manual pagination handling.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nall_jobs = []\n# Automatically fetches more pages as needed.\nfor job in client.fine_tuning.jobs.list(\n    limit=20,\n):\n    # Do something with job here\n    all_jobs.append(job)\nprint(all_jobs)\n```\n\n----------------------------------------\n\nTITLE: Manual pagination control with the OpenAI API\nDESCRIPTION: Example of manual pagination control with the OpenAI API. It demonstrates how to check if more pages exist, get information about the next page, and fetch the next page explicitly.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfirst_page = await client.fine_tuning.jobs.list(\n    limit=20,\n)\nif first_page.has_next_page():\n    print(f\"will fetch next page using these details: {first_page.next_page_info()}\")\n    next_page = await first_page.get_next_page()\n    print(f\"number of items we just fetched: {len(next_page.data)}\")\n\n# Remove `await` for non-async usage.\n```\n\n----------------------------------------\n\nTITLE: Importing Embedding Types in Python\nDESCRIPTION: Imports types related to the Embeddings API, which provides vector representations of text for use in machine learning applications and semantic search.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import CreateEmbeddingResponse, Embedding, EmbeddingModel\n```\n\n----------------------------------------\n\nTITLE: Adding New Voices for Realtime and Audio in Chat Completions\nDESCRIPTION: Feature addition to include new, expressive voices for Realtime and Audio in Chat Completions API.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# New voice options added for Realtime and Audio in Chat Completions API\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Events in OpenAI Assistant API Stream\nDESCRIPTION: This example shows how to iterate over all streamed events from an Assistant run, specifically printing text from text delta events.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith client.beta.threads.runs.stream(\n  thread_id=thread.id,\n  assistant_id=assistant.id\n) as stream:\n    for event in stream:\n        # Print the text from text delta events\n        if event.event == \"thread.message.delta\" and event.data.delta.content:\n            print(event.data.delta.content[0].text)\n```\n\n----------------------------------------\n\nTITLE: Determining Installed OpenAI Library Version\nDESCRIPTION: Shows how to check which version of the OpenAI Python library is currently installed and being used at runtime, which is useful for debugging and ensuring compatibility.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nprint(openai.__version__)\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw Response Data in OpenAI Python SDK\nDESCRIPTION: Demonstrates how to access raw HTTP response data including headers by using the with_raw_response method prefix.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.chat.completions.with_raw_response.create(\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Say this is a test\",\n    }],\n    model=\"gpt-4o\",\n)\nprint(response.headers.get('X-My-Header'))\n\ncompletion = response.parse()  # get the object that `chat.completions.create()` would have returned\nprint(completion)\n```\n\n----------------------------------------\n\nTITLE: Adding GPT-4O-2024-11-20 Model to API\nDESCRIPTION: Feature addition to include the new GPT-4O-2024-11-20 model in the API.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# New model GPT-4O-2024-11-20 added to the available models in the API\n```\n\n----------------------------------------\n\nTITLE: Assistant Events in OpenAI Python SDK\nDESCRIPTION: This section lists various event handlers available in the Assistant API, including general events, run step events, message events, text events, image file events, tool call events, and special events like stream end, timeout, and exceptions.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef on_event(self, event: AssistantStreamEvent)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_run_step_created(self, run_step: RunStep)\ndef on_run_step_delta(self, delta: RunStepDelta, snapshot: RunStep)\ndef on_run_step_done(self, run_step: RunStep)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_message_created(self, message: Message)\ndef on_message_delta(self, delta: MessageDelta, snapshot: Message)\ndef on_message_done(self, message: Message)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_text_created(self, text: Text)\ndef on_text_delta(self, delta: TextDelta, snapshot: Text)\ndef on_text_done(self, text: Text)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_image_file_done(self, image_file: ImageFile)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_tool_call_created(self, tool_call: ToolCall)\ndef on_tool_call_delta(self, delta: ToolCallDelta, snapshot: ToolCall)\ndef on_tool_call_done(self, tool_call: ToolCall)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_end(self)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_timeout(self)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef on_exception(self, exception: Exception)\n```\n\n----------------------------------------\n\nTITLE: Adding Support for Predicted Outputs in API\nDESCRIPTION: Feature addition to support predicted outputs in the API, including a new parameter across all methods.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# New 'prediction' parameter added to all API methods to support predicted outputs\n```\n\n----------------------------------------\n\nTITLE: Importing Audio Transcription Types in Python\nDESCRIPTION: Imports types specific to the Audio Transcriptions API, which converts speech to text including support for streaming, segmentation, and verbose output formats.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.audio import (\n    Transcription,\n    TranscriptionInclude,\n    TranscriptionSegment,\n    TranscriptionStreamEvent,\n    TranscriptionTextDeltaEvent,\n    TranscriptionTextDoneEvent,\n    TranscriptionVerbose,\n    TranscriptionWord,\n    TranscriptionCreateResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Detecting Null vs Missing Fields in OpenAI Python SDK\nDESCRIPTION: Shows how to differentiate between explicit null values and missing fields in API responses using the model_fields_set property.\nSOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nif response.my_field is None:\n  if 'my_field' not in response.model_fields_set:\n    print('Got json like {}, without a \"my_field\" key present at all.')\n  else:\n    print('Got json like {\"my_field\": null}.')\n```\n\n----------------------------------------\n\nTITLE: Importing OpenAI Shared Types in Python\nDESCRIPTION: Imports common type definitions used across multiple OpenAI API services, including models, filters, function definitions, and response format specifications.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import (\n    AllModels,\n    ChatModel,\n    ComparisonFilter,\n    CompoundFilter,\n    ErrorObject,\n    FunctionDefinition,\n    FunctionParameters,\n    Metadata,\n    Reasoning,\n    ReasoningEffort,\n    ResponseFormatJSONObject,\n    ResponseFormatJSONSchema,\n    ResponseFormatText,\n    ResponsesModel,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Image Generation Types in Python\nDESCRIPTION: Imports types for the Images API, which provides image generation, variation, and editing capabilities using DALL-E and other image generation models.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import Image, ImageModel, ImagesResponse\n```\n\n----------------------------------------\n\nTITLE: Importing Completion Types in Python\nDESCRIPTION: Imports type definitions specific to the Completions API, including the main Completion type and related choice and usage statistics types.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import Completion, CompletionChoice, CompletionUsage\n```\n\n----------------------------------------\n\nTITLE: Importing Fine-Tuning Job Types in Python\nDESCRIPTION: Imports the necessary types for working with fine-tuning jobs, including FineTuningJob, FineTuningJobEvent, and integration types for services like Weights & Biases.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.fine_tuning import (\n    FineTuningJob,\n    FineTuningJobEvent,\n    FineTuningJobWandbIntegration,\n    FineTuningJobWandbIntegrationObject,\n    FineTuningJobIntegration,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing ChatModel Type in Python\nDESCRIPTION: Imports the ChatModel type from the OpenAI types module, which represents models specifically designed for chat completion tasks.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import ChatModel\n```\n\n----------------------------------------\n\nTITLE: Importing Beta Assistant Types in Python\nDESCRIPTION: This snippet shows how to import various types related to the Beta Assistants API from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta import (\n    Assistant,\n    AssistantDeleted,\n    AssistantStreamEvent,\n    AssistantTool,\n    CodeInterpreterTool,\n    FileSearchTool,\n    FunctionTool,\n    MessageStreamEvent,\n    RunStepStreamEvent,\n    RunStreamEvent,\n    ThreadStreamEvent,\n)\n```\n\n----------------------------------------\n\nTITLE: Running Tests for OpenAI Python SDK\nDESCRIPTION: Executes the test suite for the OpenAI Python SDK. This requires the mock server to be running for most tests.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\n$ ./scripts/test\n```\n\n----------------------------------------\n\nTITLE: Importing Beta Thread Types in Python\nDESCRIPTION: This snippet demonstrates how to import various types related to the Beta Threads API from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta import (\n    AssistantResponseFormatOption,\n    AssistantToolChoice,\n    AssistantToolChoiceFunction,\n    AssistantToolChoiceOption,\n    Thread,\n    ThreadDeleted,\n)\n```\n\n----------------------------------------\n\nTITLE: Running Bootstrap Script for Rye Setup in OpenAI Python SDK\nDESCRIPTION: Initializes the development environment using the bootstrap script with Rye. This script automatically sets up a Python environment with the expected version and dependencies.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n$ ./scripts/bootstrap\n```\n\n----------------------------------------\n\nTITLE: Importing Run Types in Python\nDESCRIPTION: Import statements for thread run-related types including RequiredActionFunctionToolCall, Run, and RunStatus from the OpenAI beta threads module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.threads import RequiredActionFunctionToolCall, Run, RunStatus\n```\n\n----------------------------------------\n\nTITLE: Importing File Management Types in Python\nDESCRIPTION: Imports types for the Files API, which allows managing files for use with OpenAI services such as fine-tuning or as file attachments.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import FileContent, FileDeleted, FileObject, FilePurpose\n```\n\n----------------------------------------\n\nTITLE: Importing Message Types in Python\nDESCRIPTION: Import statements for message-related types including annotations, content blocks, and delta events from the OpenAI beta threads module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.threads import (\n    Annotation,\n    AnnotationDelta,\n    FileCitationAnnotation,\n    FileCitationDeltaAnnotation,\n    FilePathAnnotation,\n    FilePathDeltaAnnotation,\n    ImageFile,\n    ImageFileContentBlock,\n    ImageFileDelta,\n    ImageFileDeltaBlock,\n    ImageURL,\n    ImageURLContentBlock,\n    ImageURLDelta,\n    ImageURLDeltaBlock,\n    Message,\n    MessageContent,\n    MessageContentDelta,\n    MessageContentPartParam,\n    MessageDeleted,\n    MessageDelta,\n    MessageDeltaEvent,\n    RefusalContentBlock,\n    RefusalDeltaBlock,\n    Text,\n    TextContentBlock,\n    TextContentBlockParam,\n    TextDelta,\n    TextDeltaBlock,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Audio Model Types in Python\nDESCRIPTION: Imports core audio-related types for OpenAI's audio processing capabilities, including model specifications and response format options.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import AudioModel, AudioResponseFormat\n```\n\n----------------------------------------\n\nTITLE: Polling Helpers in OpenAI Python SDK\nDESCRIPTION: This section lists polling helper methods available in the SDK for handling asynchronous actions like starting a Run or adding files to vector stores. These methods poll the status until it reaches a terminal state and return the resulting object.\nSOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclient.beta.threads.create_and_run_poll(...)\nclient.beta.threads.runs.create_and_poll(...)\nclient.beta.threads.runs.submit_tool_outputs_and_poll(...)\nclient.beta.vector_stores.files.upload_and_poll(...)\nclient.beta.vector_stores.files.create_and_poll(...)\nclient.beta.vector_stores.file_batches.create_and_poll(...)\nclient.beta.vector_stores.file_batches.upload_and_poll(...)\n```\n\n----------------------------------------\n\nTITLE: Importing Audio Translation Types in Python\nDESCRIPTION: Imports types for the Audio Translations API, which translates speech from one language to text in another language, with support for verbose output.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.audio import Translation, TranslationVerbose, TranslationCreateResponse\n```\n\n----------------------------------------\n\nTITLE: Importing Realtime Types in Python\nDESCRIPTION: This snippet demonstrates how to import various types related to the Realtime API from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.realtime import (\n    ConversationCreatedEvent,\n    ConversationItem,\n    ConversationItemContent,\n    ConversationItemCreateEvent,\n    ConversationItemCreatedEvent,\n    ConversationItemDeleteEvent,\n    ConversationItemDeletedEvent,\n    ConversationItemInputAudioTranscriptionCompletedEvent,\n    ConversationItemInputAudioTranscriptionDeltaEvent,\n    ConversationItemInputAudioTranscriptionFailedEvent,\n    ConversationItemRetrieveEvent,\n    ConversationItemTruncateEvent,\n    ConversationItemTruncatedEvent,\n    ConversationItemWithReference,\n    ErrorEvent,\n    InputAudioBufferAppendEvent,\n    InputAudioBufferClearEvent,\n    InputAudioBufferClearedEvent,\n    InputAudioBufferCommitEvent,\n    InputAudioBufferCommittedEvent,\n    InputAudioBufferSpeechStartedEvent,\n    InputAudioBufferSpeechStoppedEvent,\n    RateLimitsUpdatedEvent,\n    RealtimeClientEvent,\n    RealtimeResponse,\n    RealtimeResponseStatus,\n    RealtimeResponseUsage,\n    RealtimeServerEvent,\n    ResponseAudioDeltaEvent,\n    ResponseAudioDoneEvent,\n    ResponseAudioTranscriptDeltaEvent,\n    ResponseAudioTranscriptDoneEvent,\n    ResponseCancelEvent,\n    ResponseContentPartAddedEvent,\n    ResponseContentPartDoneEvent,\n    ResponseCreateEvent,\n    ResponseCreatedEvent,\n    ResponseDoneEvent,\n    ResponseFunctionCallArgumentsDeltaEvent,\n    ResponseFunctionCallArgumentsDoneEvent,\n    ResponseOutputItemAddedEvent,\n    ResponseOutputItemDoneEvent,\n    ResponseTextDeltaEvent,\n    ResponseTextDoneEvent,\n    SessionCreatedEvent,\n    SessionUpdateEvent,\n    SessionUpdatedEvent,\n    TranscriptionSessionUpdate,\n    TranscriptionSessionUpdatedEvent,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Speech Synthesis Model Type in Python\nDESCRIPTION: Imports the SpeechModel type for the Speech API, which is used for text-to-speech synthesis capabilities.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.audio import SpeechModel\n```\n\n----------------------------------------\n\nTITLE: Importing Upload Types in Python\nDESCRIPTION: Import statement for the Upload type from the OpenAI types module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import Upload\n```\n\n----------------------------------------\n\nTITLE: Importing Moderation Types in Python\nDESCRIPTION: Imports types for the Moderations API, which analyzes text and images for potentially harmful content, supporting multimodal inputs and providing classification results.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import (\n    Moderation,\n    ModerationImageURLInput,\n    ModerationModel,\n    ModerationMultiModalInput,\n    ModerationTextInput,\n    ModerationCreateResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Upload Part Types in Python\nDESCRIPTION: Import statement for the UploadPart type from the OpenAI types uploads module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.uploads import UploadPart\n```\n\n----------------------------------------\n\nTITLE: Importing Model Management Types in Python\nDESCRIPTION: Imports types for the Models API, which provides information about available models and allows management of custom models including deletion operations.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import Model, ModelDeleted\n```\n\n----------------------------------------\n\nTITLE: Importing Eval Run Output Item Types in Python\nDESCRIPTION: This snippet shows the import statement for types related to output items in evaluation runs from the openai.types.evals.runs module. These types are used for retrieving and listing output items.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.evals.runs import OutputItemRetrieveResponse, OutputItemListResponse\n```\n\n----------------------------------------\n\nTITLE: Avoiding Runtime Error for Assistants Streaming in Pydantic v1\nDESCRIPTION: Bug fix to prevent a runtime error when using assistants streaming with Pydantic v1.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# No code snippet provided, but the fix involves changes to handle assistants streaming with Pydantic v1\n```\n\n----------------------------------------\n\nTITLE: Importing Checkpoint Permissions Types in Python\nDESCRIPTION: Imports the response types for permission operations on fine-tuning checkpoints, including create, retrieve, and delete responses.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.fine_tuning.checkpoints import (\n    PermissionCreateResponse,\n    PermissionRetrieveResponse,\n    PermissionDeleteResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Fine-Tuning Job Checkpoint Types in Python\nDESCRIPTION: Imports the FineTuningJobCheckpoint type for accessing checkpoint information of fine-tuning jobs.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.fine_tuning.jobs import FineTuningJobCheckpoint\n```\n\n----------------------------------------\n\nTITLE: Installing SDK from Git Repository\nDESCRIPTION: Installs the OpenAI Python SDK directly from the Git repository using pip. This is useful for accessing the latest unreleased changes.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n$ pip install git+ssh://git@github.com/openai/openai-python.git\n```\n\n----------------------------------------\n\nTITLE: Importing Vector Store Types in Python\nDESCRIPTION: Imports the types needed for vector store operations, including file chunking strategies and vector store operation responses.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import (\n    AutoFileChunkingStrategyParam,\n    FileChunkingStrategy,\n    FileChunkingStrategyParam,\n    OtherFileChunkingStrategyObject,\n    StaticFileChunkingStrategy,\n    StaticFileChunkingStrategyObject,\n    StaticFileChunkingStrategyObjectParam,\n    VectorStore,\n    VectorStoreDeleted,\n    VectorStoreSearchResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Building OpenAI Python SDK from Source\nDESCRIPTION: Builds distribution packages (.tar.gz and .whl) for the OpenAI Python SDK. This command uses Rye or Python's build module to create installable packages.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\n$ rye build\n# or\n$ python -m build\n```\n\n----------------------------------------\n\nTITLE: Importing Vector Store File Types in Python\nDESCRIPTION: Imports types for working with files in vector stores, including file operations responses and content retrieval.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.vector_stores import VectorStoreFile, VectorStoreFileDeleted, FileContentResponse\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Python SDK from Wheel File\nDESCRIPTION: Installs the OpenAI Python SDK from a locally built wheel file. This is useful for testing local changes before publishing.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\n$ pip install ./path-to-wheel-file.whl\n```\n\n----------------------------------------\n\nTITLE: Importing FileBatches Types in Python\nDESCRIPTION: This snippet shows how to import the VectorStoreFileBatch type from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.vector_stores import VectorStoreFileBatch\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mock Server for OpenAI Python SDK Tests\nDESCRIPTION: Runs a Prism mock server against the OpenAPI specification for testing. This is required for most tests to function correctly.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\n# you will need npm installed\n$ npx prism mock path/to/your/openapi.yml\n```\n\n----------------------------------------\n\nTITLE: Importing Realtime Session Types in Python\nDESCRIPTION: This snippet shows how to import Session and SessionCreateResponse types for the Realtime API from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.realtime import Session, SessionCreateResponse\n```\n\n----------------------------------------\n\nTITLE: Running Example Scripts in OpenAI Python SDK\nDESCRIPTION: Commands to make examples executable and run them against your API. This requires first setting the file as executable using chmod.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\n$ chmod +x examples/<your-example>.py\n# run the example against your api\n$ ./examples/<your-example>.py\n```\n\n----------------------------------------\n\nTITLE: Importing Realtime TranscriptionSession Type in Python\nDESCRIPTION: This snippet demonstrates how to import the TranscriptionSession type for the Realtime API from the OpenAI Python library.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.realtime import TranscriptionSession\n```\n\n----------------------------------------\n\nTITLE: Creating Example Files in OpenAI Python SDK\nDESCRIPTION: Template for creating new example Python scripts within the examples directory. The shebang line allows direct execution using Rye run.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_4\n\nLANGUAGE: py\nCODE:\n```\n#!/usr/bin/env -S rye run python\n\n```\n\n----------------------------------------\n\nTITLE: Syncing Dependencies with Rye in OpenAI Python SDK\nDESCRIPTION: Synchronizes all project dependencies using Rye's sync command with all features enabled. This is an alternative to using the bootstrap script after manually installing Rye.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n$ rye sync --all-features\n```\n\n----------------------------------------\n\nTITLE: Formatting OpenAI Python SDK Code\nDESCRIPTION: Automatically formats the codebase and fixes ruff issues. This ensures consistent code style throughout the project.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\n$ ./scripts/format\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment with Rye in OpenAI Python SDK\nDESCRIPTION: Shows how to enter a Rye shell or manually activate the virtual environment. This allows running Python scripts without prefixing commands with 'rye run'.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n$ rye shell\n# or manually activate - https://docs.python.org/3/library/venv.html#how-venvs-work\n$ source .venv/bin/activate\n\n# now you can omit the `rye run` prefix\n$ python script.py\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry\nDESCRIPTION: Changelog entries in markdown format documenting version changes, features, bug fixes and other updates to the OpenAI Python SDK\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Changelog\n\n## 1.76.0 (2025-04-23)\n\nFull Changelog: [v1.75.0...v1.76.0](https://github.com/openai/openai-python/compare/v1.75.0...v1.76.0)\n\n### Features\n\n* **api:** adding new image model support ([74d7692](https://github.com/openai/openai-python/commit/74d7692e94c9dca96db8793809d75631c22dbb87))\n\n\n### Bug Fixes\n\n* **pydantic v1:** more robust `ModelField.annotation` check ([#2163](https://github.com/openai/openai-python/issues/2163)) ([7351b12](https://github.com/openai/openai-python/commit/7351b12bc981f56632b92342d9ef26f6fb28d540))\n* **pydantic v1:** more robust ModelField.annotation check ([eba7856](https://github.com/openai/openai-python/commit/eba7856db55afb8cb44376a0248587549f7bc65f))\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies without Rye in OpenAI Python SDK\nDESCRIPTION: Installs development dependencies using pip with the requirements lock file. This is for developers who prefer not to use Rye for environment management.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n$ pip install -r requirements-dev.lock\n```\n\n----------------------------------------\n\nTITLE: Fixing Asyncify to Avoid Hanging Process\nDESCRIPTION: Bug fix to prevent the asyncify functionality from causing the process to hang under certain conditions.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Changes made to asyncify to prevent process hanging in specific scenarios\n```\n\n----------------------------------------\n\nTITLE: Importing Run Steps Types in Python\nDESCRIPTION: Import statements for various run step related types including tool calls, step details, and delta events from the OpenAI beta threads runs module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.beta.threads.runs import (\n    CodeInterpreterLogs,\n    CodeInterpreterOutputImage,\n    CodeInterpreterToolCall,\n    CodeInterpreterToolCallDelta,\n    FileSearchToolCall,\n    FileSearchToolCallDelta,\n    FunctionToolCall,\n    FunctionToolCallDelta,\n    MessageCreationStepDetails,\n    RunStep,\n    RunStepDelta,\n    RunStepDeltaEvent,\n    RunStepDeltaMessageDelta,\n    RunStepInclude,\n    ToolCall,\n    ToolCallDelta,\n    ToolCallDeltaObject,\n    ToolCallsStepDetails,\n)\n```\n\n----------------------------------------\n\nTITLE: Dropping Support for Python 3.7\nDESCRIPTION: Project update to remove support for Python 3.7, likely due to its end of life.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Project configuration updated to no longer support Python 3.7\n```\n\n----------------------------------------\n\nTITLE: Importing Batch Types in Python\nDESCRIPTION: Import statements for batch-related types including Batch, BatchError, and BatchRequestCounts from the OpenAI types module.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import Batch, BatchError, BatchRequestCounts\n```\n\n----------------------------------------\n\nTITLE: Adding GPT-4O-Audio-Preview Model for Chat Completions\nDESCRIPTION: Feature addition to include the new GPT-4O-Audio-Preview model for chat completions.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# New model GPT-4O-Audio-Preview added for use in chat completions\n```\n\n----------------------------------------\n\nTITLE: Importing Response Types in Python\nDESCRIPTION: This snippet shows the import statement for various response types from the openai.types.responses module. These types represent different components and events related to API responses.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.responses import (\n    ComputerTool,\n    EasyInputMessage,\n    FileSearchTool,\n    FunctionTool,\n    Response,\n    ResponseAudioDeltaEvent,\n    ResponseAudioDoneEvent,\n    ResponseAudioTranscriptDeltaEvent,\n    ResponseAudioTranscriptDoneEvent,\n    ResponseCodeInterpreterCallCodeDeltaEvent,\n    ResponseCodeInterpreterCallCodeDoneEvent,\n    ResponseCodeInterpreterCallCompletedEvent,\n    ResponseCodeInterpreterCallInProgressEvent,\n    ResponseCodeInterpreterCallInterpretingEvent,\n    ResponseCodeInterpreterToolCall,\n    ResponseCompletedEvent,\n    ResponseComputerToolCall,\n    ResponseComputerToolCallOutputItem,\n    ResponseComputerToolCallOutputScreenshot,\n    ResponseContent,\n    ResponseContentPartAddedEvent,\n    ResponseContentPartDoneEvent,\n    ResponseCreatedEvent,\n    ResponseError,\n    ResponseErrorEvent,\n    ResponseFailedEvent,\n    ResponseFileSearchCallCompletedEvent,\n    ResponseFileSearchCallInProgressEvent,\n    ResponseFileSearchCallSearchingEvent,\n    ResponseFileSearchToolCall,\n    ResponseFormatTextConfig,\n    ResponseFormatTextJSONSchemaConfig,\n    ResponseFunctionCallArgumentsDeltaEvent,\n    ResponseFunctionCallArgumentsDoneEvent,\n    ResponseFunctionToolCall,\n    ResponseFunctionToolCallItem,\n    ResponseFunctionToolCallOutputItem,\n    ResponseFunctionWebSearch,\n    ResponseInProgressEvent,\n    ResponseIncludable,\n    ResponseIncompleteEvent,\n    ResponseInput,\n    ResponseInputAudio,\n    ResponseInputContent,\n    ResponseInputFile,\n    ResponseInputImage,\n    ResponseInputItem,\n    ResponseInputMessageContentList,\n    ResponseInputMessageItem,\n    ResponseInputText,\n    ResponseItem,\n    ResponseOutputAudio,\n    ResponseOutputItem,\n    ResponseOutputItemAddedEvent,\n    ResponseOutputItemDoneEvent,\n    ResponseOutputMessage,\n    ResponseOutputRefusal,\n    ResponseOutputText,\n    ResponseReasoningItem,\n    ResponseReasoningSummaryPartAddedEvent,\n    ResponseReasoningSummaryPartDoneEvent,\n    ResponseReasoningSummaryTextDeltaEvent,\n    ResponseReasoningSummaryTextDoneEvent,\n    ResponseRefusalDeltaEvent,\n    ResponseRefusalDoneEvent,\n    ResponseStatus,\n    ResponseStreamEvent,\n    ResponseTextAnnotationDeltaEvent,\n    ResponseTextConfig,\n    ResponseTextDeltaEvent,\n    ResponseTextDoneEvent,\n    ResponseUsage,\n    ResponseWebSearchCallCompletedEvent,\n    ResponseWebSearchCallInProgressEvent,\n    ResponseWebSearchCallSearchingEvent,\n    Tool,\n    ToolChoiceFunction,\n    ToolChoiceOptions,\n    ToolChoiceTypes,\n    WebSearchTool,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing ResponseItemList in Python\nDESCRIPTION: This snippet shows the import statement for the ResponseItemList type from the openai.types.responses module. This type is used for handling lists of response items.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.responses import ResponseItemList\n```\n\n----------------------------------------\n\nTITLE: Importing Eval Types in Python\nDESCRIPTION: This snippet shows the import statement for various evaluation-related types from the openai.types module. These types are used for handling evaluation configurations, responses, and graders.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types import (\n    EvalCustomDataSourceConfig,\n    EvalLabelModelGrader,\n    EvalStoredCompletionsDataSourceConfig,\n    EvalStringCheckGrader,\n    EvalTextSimilarityGrader,\n    EvalCreateResponse,\n    EvalRetrieveResponse,\n    EvalUpdateResponse,\n    EvalListResponse,\n    EvalDeleteResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Eval Run Types in Python\nDESCRIPTION: This snippet shows the import statement for various types related to evaluation runs from the openai.types.evals module. These types are used for handling data sources, responses, and errors in evaluation runs.\nSOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.evals import (\n    CreateEvalCompletionsRunDataSource,\n    CreateEvalJSONLRunDataSource,\n    EvalAPIError,\n    RunCreateResponse,\n    RunRetrieveResponse,\n    RunListResponse,\n    RunDeleteResponse,\n    RunCancelResponse,\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Dict Handling in Transform Function\nDESCRIPTION: Bug fix to avoid using dictionaries as iterables in the transform function.\nSOURCE: https://github.com/openai/openai-python/blob/main/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Modification to transform function to handle dictionaries differently\n```\n\n----------------------------------------\n\nTITLE: Linting OpenAI Python SDK Code\nDESCRIPTION: Checks the codebase for style issues using ruff and black linters. This helps maintain code quality and consistency.\nSOURCE: https://github.com/openai/openai-python/blob/main/CONTRIBUTING.md#2025-04-23_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\n$ ./scripts/lint\n```"
  }
]