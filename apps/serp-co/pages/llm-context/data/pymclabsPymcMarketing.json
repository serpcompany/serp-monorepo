[
  {
    "owner": "pymc-labs",
    "repo": "pymc-marketing",
    "content": "TITLE: Initializing Marketing Mix Model with PyMC-Marketing in Python\nDESCRIPTION: This code sets up a Marketing Mix Model (MMM) with geometric adstock and logistic saturation functions. It loads example data from a CSV file and configures the model with channel columns, control columns, and seasonality parameters to account for advertising effects including diminishing returns and carry-over effects.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/quickstart/mmm/index.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nfrom pymc_marketing.mmm import (\n    GeometricAdstock,\n    LogisticSaturation,\n    MMM,\n)\n\ndata_url = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/mmm_example.csv\"\ndata = pd.read_csv(data_url, parse_dates=[\"date_week\"])\n\nmmm = MMM(\n    adstock=GeometricAdstock(l_max=8),\n    saturation=LogisticSaturation(),\n    date_column=\"date_week\",\n    channel_columns=[\"x1\", \"x2\"],\n    control_columns=[\n        \"event_1\",\n        \"event_2\",\n        \"t\",\n    ],\n    yearly_seasonality=2,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Marketing Mix Model with PyMC-Marketing\nDESCRIPTION: This snippet demonstrates how to import necessary components from pymc_marketing.mmm, load example data, and initialize a Marketing Mix Model (MMM) with geometric adstock, logistic saturation, and seasonality components.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/README.md#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nfrom pymc_marketing.mmm import (\n    GeometricAdstock,\n    LogisticSaturation,\n    MMM,\n)\n\ndata_url = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/mmm_example.csv\"\ndata = pd.read_csv(data_url, parse_dates=[\"date_week\"])\n\nmmm = MMM(\n    adstock=GeometricAdstock(l_max=8),\n    saturation=LogisticSaturation(),\n    date_column=\"date_week\",\n    channel_columns=[\"x1\", \"x2\"],\n    control_columns=[\n        \"event_1\",\n        \"event_2\",\n        \"t\",\n    ],\n    yearly_seasonality=2,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Customer Choice Analysis with Multivariate Interrupted Time Series\nDESCRIPTION: This code shows how to use the MVITS (Multivariate Interrupted Time Series) model for customer choice analysis to measure the impact of product launches on market shares, with visualization of causal impacts and counterfactuals.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/README.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom pymc_marketing.customer_choice import MVITS, plot_product\n\n# Define existing products\nexisting_products = [\"competitor\", \"own\"]\n\n# Create MVITS model\nmvits = MVITS(\n    existing_sales=existing_products,\n    saturated_market=True, # Set False for unsaturated markets\n)\n\n# Fit model\nmvits.fit(X, y)\n\n# Plot causal impact on market share\nmvits.plot_causal_impact_market_share()\n\n# Plot counterfactuals\nmvits.plot_counterfactual()\n```\n\n----------------------------------------\n\nTITLE: Implementing Beta-Geo/NBD Model for CLV Analysis in Python\nDESCRIPTION: This code demonstrates how to load customer data, initialize and fit a Beta-Geo/NBD model for Customer Lifetime Value analysis using the pymc_marketing library. The example loads data from a CSV file, assigns customer IDs, and fits the Beta-Geo model to predict future customer behavior.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/quickstart/clv/index.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom pymc_marketing import clv\n\ndata_url = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/clv_quickstart.csv\"\ndata = pd.read_csv(data_url)\ndata[\"customer_id\"] = data.index\n\nbeta_geo_model = clv.BetaGeoModel(data=data)\n\nbeta_geo_model.fit()\n```\n\n----------------------------------------\n\nTITLE: Performing Bayesian Inference on the CLV Model\nDESCRIPTION: Constructs a PyMC model to estimate the original parameters from the synthetic data. Uses appropriate prior distributions (Gamma for lambda and Beta for p) and samples from the posterior to recover the true parameter values.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model() as model:\n\n    λ = pm.Gamma(name=\"λ\", alpha=0.1, beta=0.1)\n    π = pm.Beta(name=\"π\", alpha=0.1, beta=0.1)\n    \n    cnc = ContNonContract(\n        name=\"cnc\",\n        lam=λ,\n        p=π,\n        T=T,\n        observed=prior_data\n    )\n    \n    trace = pm.sample(draws=1000, chains=1, tune=500)\n```\n\n----------------------------------------\n\nTITLE: Calculating Conditional Probability of Customer Being Alive in Python\nDESCRIPTION: Defines a function to calculate the conditional probability of a customer being alive based on their purchase history and time since last purchase.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef conditional_probability_alive_lifetimes(\n    frequency, \n    recency, \n    T\n):\n    log_div = (r + frequency) * np.log((alpha + T) / (alpha + recency)) + np.log(\n        a / (b + np.maximum(frequency, 1) - 1)\n    )\n\n    return np.atleast_1d(np.where(frequency == 0, 1.0, expit(-log_div)))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Posterior Distributions with Reference Values\nDESCRIPTION: Uses ArviZ to plot the posterior distributions of the estimated parameters, including reference lines for the true values of lambda and p to assess the accuracy of the inference.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n_ = az.plot_posterior(trace, ref_val=[lam, p])\nplt.tight_layout()\n```\n\n----------------------------------------\n\nTITLE: Implementing Customer Choice Analysis with MVITS in Python\nDESCRIPTION: This code snippet demonstrates the process of customer choice analysis using the Multivariate Interrupted Time Series (MVITS) model from pymc-marketing. It includes data generation, model building, parameter estimation, and result visualization.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/quickstart/customer_choice/index.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pymc_marketing.customer_choice import (\n    MVITS,\n    generate_saturated_data,\n    plot_product,\n)\n\n# Generate simulated data\nscenario = {\n    \"total_sales_mu\": 1000,\n    \"total_sales_sigma\": 5,\n    \"treatment_time\": 40,\n    \"n_observations\": 100,\n    \"market_shares_before\": [[0.7, 0.3, 0]],\n    \"market_shares_after\": [[0.65, 0.25, 0.1]],\n    \"market_share_labels\": [\"competitor\", \"own\", \"new\"],\n    \"random_seed\": rng,\n}\n\ndata = generate_saturated_data(**scenario)\n\n# Build a multivariate interrupted time series model\nmodel = MVITS(\n    existing_sales=[\"competitor\", \"own\"],\n    saturated_market=True,\n)\n\nmodel.inform_default_prior(\n    data=data.loc[: scenario1[\"treatment_time\"], [\"competitor\", \"own\"]]\n)\n\n# Parameter estimation\nmodel.sample(data[[\"competitor\", \"own\"]], data[\"new\"])\n\n# Visualize the results\nmodel.plot_fit();\n```\n\n----------------------------------------\n\nTITLE: Calculating Expected Number of Purchases with Sample Data in Python\nDESCRIPTION: Applies the expected_number_of_purchases function to the sample data to calculate expected purchases for different customer scenarios.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nexpected_number_of_purchases(t, frequency, recency, T)\n```\n\n----------------------------------------\n\nTITLE: Fitting a Marketing Mix Model and Visualizing Component Contributions\nDESCRIPTION: This code shows how to fit the previously created Marketing Mix Model to data and visualize the contributions of different components, which helps identify the impact of each marketing channel.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/README.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nX = data.drop(\"y\", axis=1)\ny = data[\"y\"]\nmmm.fit(X, y)\nmmm.plot_components_contributions()\n```\n\n----------------------------------------\n\nTITLE: Plotting Expected Purchases from Full Posterior\nDESCRIPTION: Visualizes expected purchases over time using the full posterior distributions from the Pareto/NBD model, providing uncertainty estimates.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases(\n    model=pnbd,\n    purchase_history=raw_trans,\n    customer_id_col=\"id\",\n    datetime_col=\"date\",\n    t=25*7,\n    datetime_format=\"%Y%m%d\",\n    time_unit=\"W\",\n    plot_cumulative=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Customer Lifetime Value (CLV) Analysis with BetaGeoModel\nDESCRIPTION: This snippet demonstrates how to import the CLV module, load customer data, and initialize a Beta-Geometric model for customer lifetime value analysis. This model is used for predicting future purchases and customer retention.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/README.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom pymc_marketing import clv\n\ndata_url = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/clv_quickstart.csv\"\ndata = pd.read_csv(data_url)\ndata[\"customer_id\"] = data.index\n\nbeta_geo_model = clv.BetaGeoModel(data=data)\n\nbeta_geo_model.fit()\n```\n\n----------------------------------------\n\nTITLE: Configuring and Building BGBB Model with Custom Priors\nDESCRIPTION: Creates a configuration dictionary with HalfFlat priors for all model parameters (alpha, beta, gamma, delta), initializes the BetaGeoBetaBinomModel with the data and configuration, and builds the model.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel_config = {\n    \"alpha\": Prior(\"HalfFlat\"),\n    \"beta\": Prior(\"HalfFlat\"),\n    \"gamma\": Prior(\"HalfFlat\"),\n    \"delta\": Prior(\"HalfFlat\"),\n}\n\nmodel = BetaGeoBetaBinomModel(data=data,model_config=model_config)\nmodel.build_model()\nmodel\n```\n\n----------------------------------------\n\nTITLE: Defining Conditional Probability Function with PyMC Trace in Python\nDESCRIPTION: Creates a function to calculate conditional probability of customers being alive using PyMC trace results and xarray DataArrays.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef conditional_probability_alive(frequency, recency, T, trace):\n\n    dims = (\"customer_id\",)\n    coords = {\"customer_id\": range(len(frequency))}\n    \n    to_xarray = lambda array: xr.DataArray(data=array, coords=coords, dims=dims)\n\n    frequency = to_xarray(frequency)\n    recency = to_xarray(recency)\n    T = to_xarray(T)\n    \n    a = trace.posterior[\"a\"]\n    b = trace.posterior[\"b\"]\n    alpha = trace.posterior[\"alpha\"]\n    r = trace.posterior[\"r\"]\n    \n    log_div = (r + frequency) * np.log((alpha + T) / (alpha + recency)) + np.log(\n        a / (b + np.maximum(frequency, 1) - 1)\n    )\n\n    return xr.where(frequency == 0, 1.0, expit(-log_div))\n```\n\n----------------------------------------\n\nTITLE: Calculating Expected Cumulative Transactions\nDESCRIPTION: Calculates the expected cumulative transactions over time for a fitted Pareto/NBD model, providing a basis for forecasting customer purchases.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf_cum = utils._expected_cumulative_transactions(\n    model=pnbd_split,\n    transactions=raw_trans,\n    customer_id_col=\"id\",\n    datetime_col=\"date\",\n    t=t,\n    datetime_format=\"%Y%m%d\",\n    time_unit=\"W\",\n    set_index_date=True,\n)\n\ndf_cum.head()\n```\n\n----------------------------------------\n\nTITLE: Defining Expected Number of Purchases Function in Python\nDESCRIPTION: Creates a function to calculate the expected number of purchases for customers based on their purchase history and time parameters.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef expected_number_of_purchases(t, frequency, recency, T):\n    numerator = 1 - ((alpha + T) / (alpha + T + t)) ** (r + frequency) * hyp2f1(\n        r + frequency,\n        b + frequency,\n        a + b + frequency - 1,\n        t / (alpha + T + t),\n    )\n    numerator *= (a + b + frequency - 1) / (a - 1)\n    denominator = 1 + (frequency > 0) * (a / (b + frequency - 1)) * (\n        (alpha + T) / (alpha + recency)\n    ) ** (r + frequency)\n    \n    return numerator/denominator\n```\n\n----------------------------------------\n\nTITLE: Creating RFM Summary for CLV Modeling\nDESCRIPTION: Processes transaction data into recency, frequency, monetary value format required for CLV modeling in the continuous, non-contractual domain.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrfm_df = utils.rfm_summary(\n    test_data, \n    customer_id_col = \"id\", \n    datetime_col = \"date\", \n    monetary_value_col = \"monetary_value\",\n    observation_period_end = \"2015-02-06\",\n    datetime_format = \"%Y-%m-%d\",\n    time_unit = \"W\",\n    include_first_transaction=True,\n)\n\nrfm_df.head()\n```\n\n----------------------------------------\n\nTITLE: Defining and Sampling PyMC Model\nDESCRIPTION: Constructs a Bayesian model using PyMC with Gamma and Beta priors for lambda and pi parameters, then performs MCMC sampling to obtain posterior distributions.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_contractual.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model() as model:\n\n    λ = pm.Gamma(name=\"λ\", alpha=1, beta=1)\n    π = pm.Beta(name=\"π\", alpha=1, beta=1)\n    \n    cont_contractual = ContContract(\n        name=\"continuous-contractual-clv\",\n        lam=λ,\n        p=π,\n        T=10,\n        T0=0,\n        observed=data,\n    )\n    \n    trace = pm.sample(draws=2000, chains=1, tune=1000)\n```\n\n----------------------------------------\n\nTITLE: Plotting Posterior Predictive Checks for MCMC Model\nDESCRIPTION: Visualizes posterior predictive checks for expected purchases from the MCMC-fitted model to assess how well it captures observed data patterns.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases_ppc(pnbd, ppc='posterior');\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data from Prior Distribution\nDESCRIPTION: Creates a ContNonContract distribution with the specified parameters and draws synthetic data samples to use for model validation. This generates 10,000 samples from the prior distribution with lambda=0.5 and p=0.3.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncnc = ContNonContract.dist(\n    lam=lam,\n    p=p,\n    T=T,\n)\n\nprior_data = pm.draw(cnc, draws=10000)\n```\n\n----------------------------------------\n\nTITLE: Plotting Expected Purchases Over Time\nDESCRIPTION: Visualizes expected purchases over time, which is useful for train/test splits or studying time interventions like marketing campaigns.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases_over_time(\n    model=pnbd_split,\n    purchase_history=raw_trans,\n    customer_id_col=\"id\",\n    datetime_col=\"date\",\n    t=t,\n    t_start_eval = t_start_eval,\n    datetime_format=\"%Y%m%d\",\n    time_unit=\"W\",\n    plot_cumulative=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting Customer Metrics from Synthetic CLV Data in Python\nDESCRIPTION: Extracts recency, frequency, and alive status from the generated synthetic customer lifetime value data.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrecency = data[..., 0]\nfrequency = data[..., 1]\nalive = 1 - data[..., 2]\n```\n\n----------------------------------------\n\nTITLE: Fitting BGBB Model with MAP Estimation\nDESCRIPTION: Fits the BetaGeoBetaBinomModel using Maximum A Posteriori (MAP) estimation, which is a point estimate approach that finds the mode of the posterior distribution.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit(fit_method='map')\n```\n\n----------------------------------------\n\nTITLE: Implementing BGBB Model with Lifetimes Package for Comparison\nDESCRIPTION: Creates and fits a BGBB model using the lifetimes package for comparison purposes, using the same data (frequency, recency, and observation period T) as the PyMC model.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbgbb = BetaGeoBetaBinomFitter().fit(data['frequency'].values,\n                             data['recency'].values,\n                             data['T'].values\n                                )\nbgbb\n```\n\n----------------------------------------\n\nTITLE: Splitting Data for Model Validation\nDESCRIPTION: Creates train/test splits of transaction data for model validation, useful for MAP fits, covariate models, and evaluating time-based marketing interventions.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_test = utils.rfm_train_test_split(\n    test_data, \n    customer_id_col = \"id\", \n    datetime_col = \"date\", \n    train_period_end = \"2015-02-01\",\n    monetary_value_col = \"monetary_value\",\n)\n\ntrain_test.head()\n```\n\n----------------------------------------\n\nTITLE: Calculating Highest Density Intervals for Frequency Distribution\nDESCRIPTION: Calculates highest density intervals (HDI) for the frequency distribution using ArviZ, which provides uncertainty bounds for the model predictions.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom arviz.stats import hdi\n\ncalc_hdi = hdi(\n    ary=prior_idata,\n    hdi_prob=.9, #param\n    group='prior_predictive', #posterior\n).sel(obs_var='frequency')\n\nhdi_lo = calc_hdi.sel(hdi='lower').to_array().squeeze()\nhdi_hi = calc_hdi.sel(hdi='higher').to_array().squeeze()\n\n# TODO: Join back to ppc_freq & obs var\nhdi_hi\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing CDNow Dataset for CLV Modeling\nDESCRIPTION: Loads the CDNow transaction dataset and prepares it for CLV modeling, including creating RFM summaries and train/test splits for evaluation.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nurl_cdnow = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/cdnow_transactions.csv\"\nraw_trans = pd.read_csv(url_cdnow)\n\nrfm_data = utils.rfm_summary(\n    raw_trans, \n    customer_id_col = \"id\", \n    datetime_col = \"date\", \n    datetime_format = \"%Y%m%d\",\n    time_unit = \"W\",\n    observation_period_end = \"19970930\",\n    #time_scaler = 7,\n)\n\nrfm_train_test = utils.rfm_train_test_split(\n    raw_trans, \n    customer_id_col = \"id\", \n    datetime_col = \"date\", \n    train_period_end = \"19970701\",\n    datetime_format = \"%Y%m%d\",\n    time_unit = \"W\",\n    test_period_end = \"19970930\",\n)\n\nt=rfm_data[\"T\"].max().astype(int)\nt_start_eval = rfm_train_test[\"T\"].max()\n\npnbd_split = ParetoNBDModel(data=rfm_data)\npnbd_split.fit()\n```\n\n----------------------------------------\n\nTITLE: Sampling from Customer Purchase Frequency Distribution\nDESCRIPTION: Samples from the distribution of new customer recency and frequency to examine expected behavior patterns of future customers.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# keep n_samples=1\npnbd.distribution_new_customer_recency_frequency(\n        random_seed=45,\n        n_samples=1,\n    ).sel(obs_var=\"frequency\")\n```\n\n----------------------------------------\n\nTITLE: Fitting Pareto/NBD Model with MCMC Sampling\nDESCRIPTION: Fits a Pareto/NBD model by sampling from the posterior distributions using PyMC's MCMC capabilities with the DEMetropolisZ sampler.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npnbd = ParetoNBDModel(data=rfm_data)\n\npnbd.build_model()\nwith pnbd.model:\n    pnbd.idata = pm.sample(\n        step=pm.DEMetropolisZ(),\n        tune=2500,\n        draws=3000,\n        idata_kwargs={\"log_likelihood\": True},\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating PyMC Model for CLV Analysis in Python\nDESCRIPTION: Sets up a PyMC model with normal priors for key parameters in the customer lifetime value analysis.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model() as model:\n    pm.Normal(\"a\", a, sigma=0.1)\n    pm.Normal(\"b\", b, sigma=0.1)\n    pm.Normal(\"alpha\", alpha, sigma=0.1)\n    pm.Normal(\"r\", r, sigma=0.1)\n    \n    trace = pm.sample(chains=2)\n```\n\n----------------------------------------\n\nTITLE: Displaying BGBB Model Fit Summary\nDESCRIPTION: Displays a summary of the fitted model parameters, which includes point estimates and potentially other statistical information about the fit.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel.fit_summary()\n```\n\n----------------------------------------\n\nTITLE: Fitting CLV Model with Nutpie Sampler\nDESCRIPTION: Demonstrates using the Rust-based Nutpie NUTS sampler for the Beta-Geometric model.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nidata_nutpie = model.fit(nuts_sampler=\"nutpie\", **sampler_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Setting Ground Truth Parameters for CLV Simulation\nDESCRIPTION: Establishes the ground truth parameter values for the CLV model simulation. Sets random seed for reproducibility, defines the time period T, and sets the lambda (transaction rate) and p (customer churn probability) parameters.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.RandomState(seed=34)\nT = 10\nT0 = 0\n\n# individual-level model\nlam = 0.5; p = 0.3\n```\n\n----------------------------------------\n\nTITLE: Plotting Posterior Distributions Comparison\nDESCRIPTION: Creates a visualization comparing the posterior distributions from different samplers for model parameters.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfig, axes = plt.subplots(\n    nrows=2, ncols=2, figsize=(12, 8), sharex=False, sharey=False, layout=\"constrained\"\n)\n\naxes = axes.ravel()\n\nfor i, var_name in enumerate([\"a\", \"b\", \"alpha\", \"r\"]):\n    for j, (idata, label) in enumerate(\n        zip(\n            [idata_blackjax, idata_nutpie, idata_numpyro],\n            [\"blackjax\", \"nutpie\", \"numpyro\"],\n            strict=False,\n        )\n    ):\n        az.plot_posterior(\n            data=idata,\n            var_names=[var_name],\n            color=f\"C{j}\",\n            point_estimate=None,\n            hdi_prob=\"hide\",\n            label=label,\n            ax=axes[i],\n        )\n\nfig.suptitle(\n    \"Posterior istributions of model parameters\",\n    fontsize=18,\n    fontweight=\"bold\",\n    y=1.05\n);\n```\n\n----------------------------------------\n\nTITLE: Displaying Fit Summary for Pareto/NBD Model\nDESCRIPTION: Displays a summary of the fitted Pareto/NBD model parameters and diagnostics to assess model quality.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npnbd.fit_summary()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Continuous Non-Contractual CLV Model\nDESCRIPTION: Sets up the necessary imports for implementing a Continuous Non-Contractual CLV model, including PyMC Marketing's ContNonContract distribution, NumPy for numerical operations, PyMC for Bayesian modeling, and visualization libraries.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pymc_marketing.clv.distributions import ContNonContract\n\nimport numpy as np\nimport pandas as pd\n\nimport pymc as pm\n\nimport matplotlib.pyplot as plt\nimport arviz as az\n```\n\n----------------------------------------\n\nTITLE: Fitting BGBB Model with NutPie NUTS Sampler\nDESCRIPTION: Fits the BGBB model using MCMC sampling with the NutPie NUTS sampler, which is noted to be about 3x faster than the default PyMC NUTS sampler.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# add warning supress here\nmcmc_model.fit(nuts_sampler=\"nutpie\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for PyMC Marketing CLV Analysis\nDESCRIPTION: Imports necessary packages for CLV modeling, including numpy, pandas, lifetimes for comparison, and pymc-marketing components including the BetaGeoBetaBinomModel and Prior class.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport nutpie\nimport pandas as pd\nfrom lifetimes import BetaGeoBetaBinomFitter\n\nimport pymc as pm\nfrom pymc_marketing.clv import BetaGeoBetaBinomModel\nfrom pymc_marketing.prior import Prior\n```\n\n----------------------------------------\n\nTITLE: Building Default BGBB Model for MCMC Sampling\nDESCRIPTION: Creates a new BetaGeoBetaBinomModel instance with default priors for MCMC sampling and visualizes its computational graph with graphviz.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmcmc_model = BetaGeoBetaBinomModel(data=data)\nmcmc_model.build_model()\npm.model_to_graphviz(mcmc_model.model)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Posterior Distributions\nDESCRIPTION: Creates visualization of the posterior distributions for model parameters using ArviZ, comparing against true parameter values.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_contractual.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n_ = az.plot_posterior(trace, ref_val=[lam, p_true])\n```\n\n----------------------------------------\n\nTITLE: Defining Random Number Generator Function for Contractual CLV Model in Python\nDESCRIPTION: Creates a function to generate random numbers for a continuous contractual customer lifetime value model.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef rng_fn(rng, a, b, r, alpha, T, T0, size):\n    p = rng.beta(a, b, size=size)\n    lam = rng.gamma(r, 1 / alpha, size=size)\n\n    return continuous_contractual.rng_fn(rng, lam, p, T, T0, size=size)\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic CLV Data in Python\nDESCRIPTION: Uses the previously defined random number generator function to create synthetic customer lifetime value data.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata = rng_fn(rng, a, b, r, alpha, T, 0, size=len(T))\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic CLV Data\nDESCRIPTION: Creates synthetic customer lifetime value data using the ContContract distribution with specified parameters for 1000 customers.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_contractual.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndist = ContContract.dist(lam, p_true, T, T0, shape=(1000,))\ndata = pm.draw(dist, random_seed=rng)\ndata[:5]\n```\n\n----------------------------------------\n\nTITLE: Loading BGBB Model Dataset\nDESCRIPTION: Loads a sample dataset for BGBB modeling from a GitHub repository and displays the first few rows using pandas.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = pd.read_csv(\"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/bgbb_donations.csv\") \ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Converting Multiple Arrays to xarray DataArrays in Python\nDESCRIPTION: Defines a function to convert multiple input arrays into xarray DataArrays with consistent dimensions and coordinates.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef to_xarray(*arrays):\n    num_customers = len(arrays[0])\n    dims = (\"customer_id\",)\n    coords = {\"customer_id\": range(num_customers)}\n\n    if len(arrays) == 1:\n        return xr.DataArray(data=arrays[0], coords=coords, dims=dims)\n\n    if any(len(array) != num_customers for array in arrays):\n        raise ValueError(\"The size of input arrays must be the same.\")\n\n    return (xr.DataArray(data=array, coords=coords, dims=dims) for array in arrays)\n\nfrequency, recency, T = to_xarray(frequency, recency, T)\n\nt = xr.DataArray(\n    range(20, 40, 2),\n    coords={\"times\": range(10)},\n    dims=(\"times\",),\n)\nexpected_number_of_purchases(t, frequency, recency, T)\n```\n\n----------------------------------------\n\nTITLE: Plotting Prior Predictive Checks for Expected Purchases\nDESCRIPTION: Visualizes prior predictive checks for expected purchases to assess the model's prior assumptions before fitting to data.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases_ppc(map_pnbd, ppc='prior');\n```\n\n----------------------------------------\n\nTITLE: Thinning MCMC Samples for Computational Efficiency\nDESCRIPTION: Thins the MCMC samples to reduce computational requirements while maintaining posterior representation by selecting every third draw.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# thin_fit_result is not supported with external sampler fits in `ParetoNBDModel`!\n#pnbd.idata = pnbd.thin_fit_result(keep_every=3)\n\npnbd.idata = pnbd.idata.isel(draw=slice(None, None, 3)).copy()\npnbd.idata\n```\n\n----------------------------------------\n\nTITLE: Calculating Mean of Posterior Distribution for Parameter 'a' in Python\nDESCRIPTION: Computes the mean value of the posterior distribution for the parameter 'a' from the PyMC trace.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntrace.posterior[\"a\"].mean()\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Data for Expected Purchases Calculation in Python\nDESCRIPTION: Generates sample data for frequency, recency, and T, and creates a time range for expected purchase calculations.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nto_xarray = lambda array: xr.DataArray(array,\n    coords={\"customer_id\": range(len(array))},\n    dims=(\"customer_id\",),\n)\nt = to_xarray(range(20, 40, 2))\nfrequency = to_xarray([1, 3, 5, 7, 9]*2)\nrecency = to_xarray([20, 30]*5)\nT = to_xarray([25, 35]*5)\n```\n\n----------------------------------------\n\nTITLE: Displaying the Generated Synthetic Data\nDESCRIPTION: Outputs the synthetic data generated from the ContNonContract distribution for inspection or further analysis.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_non_contractual.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprior_data\n```\n\n----------------------------------------\n\nTITLE: Plotting Posterior Predictive Checks for Expected Purchases\nDESCRIPTION: Visualizes posterior predictive checks for expected purchases to assess how well the fitted model captures the observed data patterns.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases_ppc(map_pnbd, ppc='posterior');\n```\n\n----------------------------------------\n\nTITLE: Plotting Histogram of Customer Alive Probabilities in Python\nDESCRIPTION: Creates a histogram of the conditional probabilities of customers being alive using matplotlib.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nplt.hist(conditional_probability_alive_lifetimes(frequency, recency, T), bins=40);\n```\n\n----------------------------------------\n\nTITLE: Plotting Purchase Frequency Distribution\nDESCRIPTION: Creates a bar plot to visualize the distribution of purchase frequencies from prior predictive samples.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nppc_df.reset_index()['proportion'].head(5).plot(kind='bar')\n```\n\n----------------------------------------\n\nTITLE: Sampling Prior Predictive Distribution\nDESCRIPTION: Uses the PyMC model context to sample from the prior predictive distribution, which helps assess the model's behavior before observing any data.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith mcmc_model.model:\n    prior_idata = pm.sample_prior_predictive()\n```\n\n----------------------------------------\n\nTITLE: Fitting CLV Model with Numpyro Sampler\nDESCRIPTION: Demonstrates fitting the Beta-Geometric model using the Numpyro NUTS sampler with specific sampling parameters.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsampler_kwargs = {\n    \"draws\": 2_000,\n    \"target_accept\": 0.9,\n    \"chains\": 5,\n    \"random_seed\": 42,\n}\n\nmodel = clv.BetaGeoModel(data=df)\nidata_numpyro = model.fit(nuts_sampler=\"numpyro\", **sampler_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Visualizing BGBB Model as Graphviz Diagram\nDESCRIPTION: Visualizes the constructed PyMC model's computational graph using graphviz, which helps understand the model's structure and variable relationships.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npm.model_to_graphviz(model.model)\n```\n\n----------------------------------------\n\nTITLE: Creating Customer Segments with RFM Scoring\nDESCRIPTION: Segments customers based on recency, frequency, and monetary value using a quartile-based RFM score approach, which is computationally efficient but subjective.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsegments = utils.rfm_segments(\n    test_data, \n    customer_id_col = \"id\", \n    datetime_col = \"date\", \n    monetary_value_col = \"monetary_value\",\n    observation_period_end = \"2015-02-06\",\n    datetime_format = \"%Y-%m-%d\",\n    time_unit = \"W\",\n)\n```\n\n----------------------------------------\n\nTITLE: Importing PyMC Marketing CLV Libraries\nDESCRIPTION: Imports the required libraries for PyMC Marketing CLV analysis, including NumPy, Pandas, PyMC, and the PyMC Marketing CLV module components.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\n\nimport pymc as pm\nimport xarray as xr\n\nfrom pymc_marketing.clv import utils\nfrom pymc_marketing.clv import ParetoNBDModel\nfrom pymc_marketing.prior import Prior\n\nfrom pymc_marketing.clv import utils, plotting\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for PyMC Marketing Analysis in Python\nDESCRIPTION: Imports necessary libraries for customer lifetime value analysis, including PyMC, NumPy, and custom marketing distributions.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pymc as pm\n\nfrom pymc_marketing.clv.distributions import continuous_contractual, continuous_non_contractual\n\nfrom lifetimes.datasets import load_cdnow_summary\n\nfrom scipy.special import expit, hyp2f1\n\nimport xarray as xr\n\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing CDNOW Dataset\nDESCRIPTION: Loads the CDNOW summary dataset and renames the ID column to customer_id for CLV analysis.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = (\n    load_cdnow_summary(index_col=[0])\n    .reset_index()\n    .rename(columns={\"ID\": \"customer_id\"})\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for PyMC CLV Modeling\nDESCRIPTION: Sets up the necessary Python libraries for Bayesian modeling including PyMC, NumPy, Pandas, and visualization tools Matplotlib and ArviZ.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_contractual.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\n\nimport pymc as pm\nimport pandas as pd\n\nfrom pymc_marketing.clv.distributions import ContContract\n\nimport matplotlib.pyplot as plt\nimport arviz as az\n```\n\n----------------------------------------\n\nTITLE: Plotting Prior Predictive Checks for MCMC Model\nDESCRIPTION: Visualizes prior predictive checks for expected purchases from the MCMC-fitted model to assess prior assumptions.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nplotting.plot_expected_purchases_ppc(pnbd, ppc='prior');\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Visualization Parameters\nDESCRIPTION: Sets up the required libraries and matplotlib configuration for data visualization. Includes ArviZ styling and display settings.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport matplotlib.pyplot as plt\nfrom lifetimes.datasets import load_cdnow_summary\n\nfrom pymc_marketing import clv\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.figsize\"] = [12, 7]\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%load_ext autoreload\n%autoreload 2\n%config InlineBackend.figure_format = \"retina\"\n```\n\n----------------------------------------\n\nTITLE: Formulating Multi-Product MV-ITS Model in LaTeX\nDESCRIPTION: Extended mathematical model that represents individual product sales rather than aggregated sales, using product-specific cannibalization parameters to determine which products are most affected by a new product release.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_1\n\nLANGUAGE: latex\nCODE:\n```\n\\begin{aligned}\n\\vec{sales}_1 \\sim & \\mathrm{Normal}(\\gamma_1 - \\beta_1 \\cdot \\vec{sales}_{new}, \\sigma_1)\\\\\n\\vec{sales}_2 \\sim & \\mathrm{Normal}(\\gamma_2 - \\beta_2 \\cdot \\vec{sales}_{new}, \\sigma_2)\\\\\n\\vdots \\\\\n\\vec{sales}_P \\sim & \\mathrm{Normal}(\\gamma_P - \\beta_P \\cdot \\vec{sales}_{new}, \\sigma_P)\n\\end{aligned}\n```\n\n----------------------------------------\n\nTITLE: Formulating the Basic MV-ITS Sales Model in LaTeX\nDESCRIPTION: Mathematical formulation of the simplest MV-ITS model for analyzing product incrementality using normal distributions to model sales data with cannibalization parameters.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n\\begin{aligned}\n\\vec{sales}_{your} \\sim & \\mathrm{Normal}(\\gamma_{your} - c \\cdot \\vec{sales}_{new}, \\sigma_{your})\\\\\n\\vec{sales}_{comp} \\sim & \\mathrm{Normal}(\\gamma_{comp} - (1-c) \\cdot \\vec{sales}_{new}, \\sigma_{comp})\n\\end{aligned}\n```\n\n----------------------------------------\n\nTITLE: Multivariate Normal Representation of the MV-ITS Model in LaTeX\nDESCRIPTION: Alternative formulation of the MV-ITS model using multivariate normal distribution to represent all product sales simultaneously with an independent error structure (diagonal covariance matrix).\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_3\n\nLANGUAGE: latex\nCODE:\n```\n\\begin{bmatrix}\n\\vec{sales}_1 \\\\\n\\vec{sales}_2 \\\\\n\\vdots \\\\\n\\vec{sales}_P\n\\end{bmatrix}\n\\sim \\mathrm{MultivariateNormal}\\left(\n\\begin{bmatrix}\n\\gamma_{1} - \\beta_1 \\cdot \\vec{sales}_{new} \\\\\n\\gamma_{2} - \\beta_2 \\cdot \\vec{sales}_{new} \\\\\n\\vdots \\\\\n\\gamma_{P} - \\beta_P \\cdot \\vec{sales}_{new}\n\\end{bmatrix},\n\\Sigma\n\\right)\n```\n\n----------------------------------------\n\nTITLE: Defining Dirichlet Distribution for Unsaturated Market Model\nDESCRIPTION: Mathematical formula for the Dirichlet distribution that includes parameters for existing products (β₁ to βₚ) plus an additional parameter (βₚ₊₁) representing market growth. This allows modeling scenarios where new product sales don't solely come from cannibalizing existing products.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_6\n\nLANGUAGE: mathematical notation\nCODE:\n```\n\\beta_1, \\beta_2, \\ldots, \\beta_P, \\beta_{P+1} \\sim \\mathrm{Dirichlet}(\\alpha_1, \\ldots, \\alpha_P, \\alpha_{P+1})\n```\n\n----------------------------------------\n\nTITLE: Diagonal Covariance Matrix Specification in LaTeX\nDESCRIPTION: Mathematical representation of the diagonal covariance matrix used in the multivariate normal model when assuming independence between product sales, with only variances on the diagonal.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_4\n\nLANGUAGE: latex\nCODE:\n```\n\\Sigma =\n\\begin{pmatrix}\n\\sigma_{1}^2 & 0 & \\cdots & 0 \\\\\n0 & \\sigma_{2}^2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\sigma_{P}^2\n\\end{pmatrix}\n```\n\n----------------------------------------\n\nTITLE: Generating Prior Predictive Samples for Customer Frequency\nDESCRIPTION: Generates prior predictive samples for customer purchase frequency and organizes them for analysis and visualization.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nimport pymc as pm\nimport xarray as xr\n\n# TODO: Add build_model() before a prior predictive check\npnbd.build_model()\nwith pnbd.model:\n    prior_idata = pm.sample_prior_predictive(random_seed=45, draws=100)\n\n# obs_var must be obtained from  prior_idata in case of an unfit model\nobs_freq = prior_idata.observed_data[\"recency_frequency\"].sel(obs_var=\"frequency\")\nppc_freq = prior_idata.prior_predictive[\"recency_frequency\"].sel(obs_var=\"frequency\")#.mean((\"chain\",\"draw\"))\n#ppc_freq = prior_idata.prior_predictive[\"recency_frequency\"].sel(obs_var=\"frequency\").mean((\"chain\",\"draw\"))#.rename({o\n\nppc_df = ppc_freq.to_dataframe()['recency_frequency'].value_counts(normalize=True).sort_index() * 100\n\n# Percentages are the only way to compare actual counts to chain*draw simulated counts\n# merged_xr.to_dataframe()[\"recency_frequency\"].value_counts(normalize=True) * 100\n# merged_xr.to_dataframe()[\"ppc_mean\"].value_counts(normalize=True) * 100\n```\n\n----------------------------------------\n\nTITLE: Installing PyMC-Marketing Using Conda\nDESCRIPTION: Commands for creating and activating a specialized Python environment for PyMC-Marketing using conda-forge. This installation method sets up all required dependencies for using the marketing analytics package.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/README.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -c conda-forge -n marketing_env pymc-marketing\nconda activate marketing_env\n```\n\n----------------------------------------\n\nTITLE: Full Covariance Matrix Specification in LaTeX\nDESCRIPTION: Mathematical representation of a full covariance matrix that models correlations between product sales, allowing for more realistic modeling of interdependencies between products in the market.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_5\n\nLANGUAGE: latex\nCODE:\n```\n\\Sigma =\n\\begin{pmatrix}\n\\sigma_{11}^2 & \\sigma_{12} & \\cdots & \\sigma_{1P} \\\\\n\\sigma_{21} & \\sigma_{22}^2 & \\cdots & \\sigma_{2P} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{P1} & \\sigma_{P2} & \\cdots & \\sigma_{PP}^2\n\\end{pmatrix}\n```\n\n----------------------------------------\n\nTITLE: Configuring Distributions Dictionary for Bayesian Priors\nDESCRIPTION: Code showing how to define a dictionary of probability distributions and their parameters for visualization. This dictionary maps distribution names to their required parameters for the Bayesian priors visualization.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/streamlit/mmm-explainer/README.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Specify the possible distributions and their paramaters you want to visualise\nDISTRIBUTIONS_DICT = {\n    \"Beta\": [\"alpha\", \"beta\"],\n    \"Bernoulli\": [\"p\"],\n    \"Exponential\": [\"lam\"],\n    \"Gamma\": [\"alpha\", \"beta\"],\n    \"HalfNormal\": [\"sigma\"],\n    \"LogNormal\": [\"mu\", \"sigma\"],\n    \"Normal\": [\"mu\", \"sigma\"],\n    \"Poisson\": [\"mu\"],\n    \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n    \"TruncatedNormal\": [\"mu\", \"sigma\", \"lower\", \"upper\"],\n    \"Uniform\": [\"lower\", \"upper\"],\n    \"Weibull\": [\"alpha\", \"beta\"],\n    \"MY_NEW_DIST\": [\"something\", \"something_else\"],\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Prior Predictive Samples\nDESCRIPTION: Displays the InferenceData object containing the prior predictive samples, which can be used for prior predictive checks.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/beta_geo_beta_binom.ipynb#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprior_idata\n```\n\n----------------------------------------\n\nTITLE: Importing Saturation Functions from pymc-marketing\nDESCRIPTION: Example code showing how to import saturation transformation functions from the pymc_marketing module. This is used when adding new saturation functions to the visualization app.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/streamlit/mmm-explainer/README.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pymc_marketing.mmm.transformers import (\n    logistic_saturation,\n    michaelis_menten,\n    tanh_saturation,\n    my_new_saturation_function\n)\n```\n\n----------------------------------------\n\nTITLE: Experimenting with XArray Grouping for Frequency Analysis\nDESCRIPTION: Experiments with XArray's grouping functionality for frequency analysis, demonstrating different approaches to count value occurrences.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom xarray.groupers import UniqueGrouper\n\n# This will do value counts for entire DataArray\n#ppc_freq.groupby(ppc_freq).count()\n#ppc_freq.groupby(chain=UniqueGrouper()).count()\n\n#value_counts = xr.DataArray(np.bincount(ppc_freq.values), dims=\"value\")\n#np.bincount(ppc_freq.values)\nxr.DataArray([1, 2, 2, 3, 3, 3], dims=\"x\")\n# but what about individual customers?\n# create a value count coordinate\n# prior_idata.prior_predictive.coords[\"value_counts\"] = ppc_freq.groupby(ppc_freq).count()[\"ppc_mean\"].values\n# ppc_freq = prior_idata.rename_vars({\"recency_frequency\":\"ppc_mean\"}).prior_predictive[\"ppc_mean\"]#.sel(obs_var=\"frequency\")#.mean((\"chain\",\"draw\"))\n# ppc_freq\n# prior_idata.prior_predictive.groupby(value_counts=UniqueGrouper()).count().sel(obs_var=\"frequency\")\n#prior_idata.prior_predictive.groupby(\"customer_id\").count()\n#prior_idata# \n#\n# #ppc_freq.coords[\"grouped_customer\"] \n#ppc_freq.groupby(draw=UniqueGrouper()).count()\n```\n\n----------------------------------------\n\nTITLE: Displaying PyMC Sampling Results in Python\nDESCRIPTION: Outputs the trace object containing the sampling results from the PyMC model.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntrace\n```\n\n----------------------------------------\n\nTITLE: Identifying First Transactions with _find_first_transactions\nDESCRIPTION: Demonstrates the use of the internal utility function that flags first transactions for each customer, which are typically excluded from modeling.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nutils._find_first_transactions(\n    transactions=test_data, \n    customer_id_col = \"id\", \n    datetime_col = \"date\",\n    #monetary_value_col = \"monetary_value\", \n    #datetime_format = \"%Y%m%d\",\n).reindex()\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for PyMC Marketing Project\nDESCRIPTION: A requirements.txt file listing all required Python packages with pinned version numbers. These dependencies include numpy and pandas for data manipulation, streamlit for web app creation, plotly for visualization, scikit-learn and scipy for machine learning capabilities, preliz for prior distributions, and pymc-marketing for Bayesian marketing models.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/streamlit/mmm-explainer/requirements.txt#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy==1.24.3\npandas==2.0.2\nstreamlit==1.25.0\nplotly==5.13.1\nscikit-learn==1.2.2\nscipy==1.11.0\npreliz==0.6.3\npymc-marketing==0.6.0\ntyping==3.7.4.3\n```\n\n----------------------------------------\n\nTITLE: Installing PyMC-Marketing with Conda\nDESCRIPTION: Creates and activates a conda environment named 'marketing_env' with PyMC-Marketing installed from conda-forge.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/installation/index.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -c conda-forge -n marketing_env pymc-marketing\nconda activate marketing_env\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing CDNOW Dataset for CLV Analysis in Python\nDESCRIPTION: Loads the CDNOW summary dataset and initializes parameters for customer lifetime value analysis.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\na = 0.8\nb = 2.5\nalpha = 3\nr = 4\n\nrng = np.random.default_rng(seed=34)\n\ndf = load_cdnow_summary(index_col=[0])\nT = df[\"T\"].values\n```\n\n----------------------------------------\n\nTITLE: Running the PyMC Marketing Docker Container\nDESCRIPTION: Command to run the Docker container with port mapping (8888) and volume mounting to connect the local project directory to the container workspace.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/scripts/docker/README.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd /path/to/your/project\ndocker run -it -p 8888:8888 -v $(pwd):/home/jovyan/work docker-pymc-marketing\n```\n\n----------------------------------------\n\nTITLE: Installing Development Version of PyMC-Marketing with Pip\nDESCRIPTION: Installs the latest development version of PyMC-Marketing directly from GitHub using pip.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/installation/index.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/pymc-labs/pymc-marketing.git\n```\n\n----------------------------------------\n\nTITLE: Setting Up PyMC-Marketing Development Environment\nDESCRIPTION: Commands for creating and activating a conda environment, installing the package in editable mode, and setting up pre-commit hooks.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/CONTRIBUTING.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda env create -f environment.yml\nconda activate pymc-marketing-dev\nmake init\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Creating Streamlit Tabs for Saturation Functions\nDESCRIPTION: Code snippet showing how to create separate tabs in Streamlit for different saturation function visualizations. Each tab will display plots for a specific saturation function.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/streamlit/mmm-explainer/README.md#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create tabs for plots\ntab1, tab2, tab3, tab4 = st.tabs([\"Logistic\", \"Tanh\", \"Michaelis-Menten\", \"My New Saturation\"])\n```\n\n----------------------------------------\n\nTITLE: Running Streamlit Application Locally\nDESCRIPTION: Command for running the Streamlit application locally after installing requirements. This command launches the visualization app with the main Visualise_Priors.py file.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/streamlit/mmm-explainer/README.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nstreamlit run Visualise_Priors.py\n```\n\n----------------------------------------\n\nTITLE: Setting Up JupyterLab Environment\nDESCRIPTION: Installs JupyterLab and launches it from within the 'marketing_env' conda environment.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/installation/index.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge jupyterlab\njupyter lab\n```\n\n----------------------------------------\n\nTITLE: Configuring PyTensor Compiler\nDESCRIPTION: Sets the C++ compiler for PyTensor to fix an open issue that could prevent proper model compilation.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pytensor\n\n#set flag to fix open issue\npytensor.config.cxx = '/usr/bin/clang++'\n```\n\n----------------------------------------\n\nTITLE: Committing and Pushing Changes to PyMC-Marketing\nDESCRIPTION: These commands demonstrate how to add, commit, and push changes to the forked repository, including synchronizing with the upstream repository.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit add modified_files\ngit commit -m \"Message summarizing commit changes\"\ngit fetch upstream\ngit rebase upstream/main\ngit push -u origin my-feature\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up PyMC-Marketing Repository\nDESCRIPTION: Instructions for cloning the PyMC-Marketing repository, adding the upstream remote, and creating a feature branch for development.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/CONTRIBUTING.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<your GitHub handle>/pymc-marketing.git\ncd pymc-marketing\ngit remote add upstream git@github.com:pymc-labs/pymc-marketing.git\ngit checkout -b my-feature\n```\n\n----------------------------------------\n\nTITLE: Initializing Model Parameters\nDESCRIPTION: Sets up random number generator and defines key model parameters including time horizon (T), starting time (T0), and true parameter values for lambda and probability.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/continuous_contractual.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.RandomState(seed=34)\nT = 10\nT0 = 0\n\n# individual-level model\nlam = 0.5; p_true = 0.2\n```\n\n----------------------------------------\n\nTITLE: Setting Up VS Code for PyMC-Marketing Development\nDESCRIPTION: Installs the ipykernel package required for using Jupyter notebooks in VS Code with the 'marketing_env' conda environment.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/installation/index.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge ipykernel\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up PyMC-Marketing Repository\nDESCRIPTION: These commands clone the forked PyMC-Marketing repository, navigate to the project directory, and add the upstream remote for synchronization.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<your GitHub handle>/pymc-marketing.git\ncd pymc-marketing\ngit remote add upstream git@github.com:pymc-labs/pymc-marketing.git\n```\n\n----------------------------------------\n\nTITLE: Building PyMC-Marketing Documentation Locally\nDESCRIPTION: These commands build the project documentation locally, allowing contributors to preview changes before submitting a pull request.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmake html\nmake cleandocs\n```\n\n----------------------------------------\n\nTITLE: Running PyMC-Marketing Linting Checks\nDESCRIPTION: These commands run linting checks on the codebase to ensure adherence to coding standards and identify potential issues.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmake check_lint\nmake lint\n```\n\n----------------------------------------\n\nTITLE: Committing Changes and Syncing with Upstream\nDESCRIPTION: Git commands for adding changes, committing them, syncing with the upstream repository, and pushing to the feature branch.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/CONTRIBUTING.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit add modified_files\ngit commit -m \"Message summarizing commit changes\"\ngit fetch upstream\ngit rebase upstream/main\ngit push -u origin my-feature\n```\n\n----------------------------------------\n\nTITLE: Installing Pre-commit Hooks for PyMC-Marketing\nDESCRIPTION: This command sets up pre-commit hooks to ensure code quality and consistency before committing changes to the repository.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Creating and Switching to a Feature Branch\nDESCRIPTION: This command creates a new feature branch and switches to it, allowing for isolated development of new features or bug fixes.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b my-feature\n```\n\n----------------------------------------\n\nTITLE: Loading Watermark Extension\nDESCRIPTION: Loads the watermark IPython extension for displaying environment information.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%load_ext watermark\n%watermark -n -u -v -iv -w -p blackjax,numpyro,nutpie,pymc\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for PyMC Marketing\nDESCRIPTION: Commands to navigate to the Docker script directory and build the Docker image with the tag 'docker-pymc-marketing'.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/scripts/docker/README.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd scripts/docker/\ndocker build -t docker-pymc-marketing .\n```\n\n----------------------------------------\n\nTITLE: Fitting CLV Model with Blackjax Sampler\nDESCRIPTION: Shows how to fit the Beta-Geometric model using the Blackjax NUTS sampler.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/general/other_nuts_samplers.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nidata_blackjax = model.fit(nuts_sampler=\"blackjax\", **sampler_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Structuring Documentation with toctree in Markdown for PyMC-Marketing\nDESCRIPTION: This snippet demonstrates how to organize documentation sections using the toctree directive in Markdown. It creates a hierarchical structure for the PyMC-Marketing documentation, dividing content into logical sections with proper navigation.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/index.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:caption: Benefits of PyMC-Marketing\n:maxdepth: 1\n\nbenefits/why_pymc_marketing\nbenefits/why_bayesian\nbenefits/why_open_source\nbenefits/model_deployment\n:::\n```\n\n----------------------------------------\n\nTITLE: Quickstart Guide Structure in RST\nDESCRIPTION: Toctree directive organizing quickstart guides for different marketing analysis tools including CLV, MMM, and customer choice modeling.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/index.md#2025-04-18_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n:::{toctree}\n:caption: Quickstart\n:maxdepth: 1\n\nquickstart/clv/index\nquickstart/mmm/index\nquickstart/customer_choice/index\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating Media Mix Models Section with toctree in Markdown\nDESCRIPTION: This snippet defines the Media Mix Models section in the documentation using the toctree directive. It creates a navigational structure for MMM-related content with a maximum depth of 1.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/index.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:caption: Media Mix Models\n:maxdepth: 1\n\nmmm/mmm_intro\nmmm/comparison\nmmm/resources\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Class Documentation Template in Jinja for Sphinx\nDESCRIPTION: This Jinja template defines the structure for class documentation in Sphinx. It outputs the class name as a header, includes the class docstring via autoclass, and conditionally displays methods and attributes sections with autosummary directives.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/_templates/autosummary/class.rst#2025-04-18_snippet_0\n\nLANGUAGE: jinja\nCODE:\n```\n{{ name | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n\n   {% block methods %}\n   {% if methods %}\n\n   .. rubric:: Methods\n\n   .. autosummary::\n      :toctree:\n\n   {% for item in methods %}\n      {{ objname }}.{{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block attributes %}\n   {% if attributes %}\n   .. rubric:: Attributes\n\n   .. autosummary::\n   {% for item in attributes %}\n      ~{{ name }}.{{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Executing Gallery Image Generation Script in Python\nDESCRIPTION: A command to run the Python script that generates placeholder thumbnail images for the gallery when specific images aren't provided. This script creates default thumbnails for notebooks that don't have custom visualizations.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/gallery/README.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython create_gallery_images.py\n```\n\n----------------------------------------\n\nTITLE: Setting Up Customer Lifetime Value Section with toctree in Markdown\nDESCRIPTION: This snippet creates the Customer Lifetime Value section in the documentation using the toctree directive. It organizes CLV-related content with appropriate navigation hierarchy.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/index.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:caption: Customer Lifetime Value\n:maxdepth: 1\n\nclv/clv_intro\n:::\n```\n\n----------------------------------------\n\nTITLE: Gallery Table of Contents Configuration\nDESCRIPTION: Basic toctree configuration for the gallery navigation structure.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/gallery/gallery.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:hidden:\n```\n\n----------------------------------------\n\nTITLE: Organizing Customer Choice Section with toctree in Markdown\nDESCRIPTION: This snippet defines the Customer Choice section in the documentation using the toctree directive. It structures content related to incrementality testing and multivariate interrupted time series.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/index.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:caption: Customer Choice\n:maxdepth: 1\n\ncustomer_choice/incrementality_intro\ncustomer_choice/mv_its_intro\n:::\n```\n\n----------------------------------------\n\nTITLE: Installation Documentation Structure in RST\nDESCRIPTION: Toctree directive configuring the installation documentation section with a single index page.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/getting_started/index.md#2025-04-18_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:::{toctree}\n:caption: Installation\n:maxdepth: 1\n\ninstallation/index\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating Test Transaction Dataset\nDESCRIPTION: Creates a sample transaction dataset for testing CLV modeling, containing customer IDs, transaction dates, and monetary values.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/utilities_plotting.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nd = [\n    [1, \"2015-01-01\", 1],\n    [1, \"2015-02-06\", 2],\n    [2, \"2015-01-01\", 2],\n    [3, \"2015-01-01\", 3],\n    [3, \"2015-01-02\", 1],\n    [3, \"2015-01-05\", 5],\n    [4, \"2015-01-16\", 6],\n    [4, \"2015-02-02\", 3],\n    [4, \"2015-02-05\", 3],\n    [4, \"2015-02-05\", 2],\n    [5, \"2015-01-16\", 3],\n    [5, \"2015-01-17\", 1],\n    [5, \"2015-01-18\", 8],\n    [6, \"2015-02-02\", 5],\n]\ntest_data = pd.DataFrame(d, columns=[\"id\", \"date\", \"monetary_value\"])\n```\n\n----------------------------------------\n\nTITLE: Sphinx Auto-Documentation Template with Jinja\nDESCRIPTION: Template for automatically generating documentation for Python objects using Sphinx and Jinja templating. The template creates an underlined heading from the object name and includes auto-documentation directives.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/_templates/autosummary/base.rst#2025-04-18_snippet_0\n\nLANGUAGE: jinja\nCODE:\n```\n{{ name | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. auto{{ objtype }}:: {{ objname }}\n```\n\n----------------------------------------\n\nTITLE: Converting CLV Data to xarray DataArrays in Python\nDESCRIPTION: Transforms customer lifetime value data (frequency, recency, T) into xarray DataArrays for efficient analysis.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndims = (\"customer_id\",)\ncoords = {\"customer_id\": range(len(frequency))}\n\nfrequency = xr.DataArray(\n    frequency, \n    dims=dims,\n    coords=coords,\n)\n\nrecency = xr.DataArray(\n    recency, \n    dims=dims,\n    coords=coords,\n)\n\nT = xr.DataArray(\n    T, \n    dims=dims,\n    coords=coords,\n)\n```\n\n----------------------------------------\n\nTITLE: Plotting Histogram of Averaged Conditional Probabilities in Python\nDESCRIPTION: Creates a histogram of the mean conditional probabilities of customers being alive, averaged across MCMC draws and chains.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/notebooks/clv/dev/conditional_probability_alive_dev.ipynb#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.hist(conditional_probability_alive(frequency, recency, T, trace).mean((\"draw\", \"chain\")), bins=40);\n```\n\n----------------------------------------\n\nTITLE: Defining Dirichlet Prior for Cannibalization Parameters in LaTeX\nDESCRIPTION: Specification of a Dirichlet prior distribution for the cannibalization parameters, ensuring they sum to 1 to reflect the saturated market assumption where new product sales must come from existing products.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/guide/customer_choice/mv_its_intro.md#2025-04-18_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\n\\beta_1, \\beta_2, \\ldots, \\beta_P \\sim \\mathrm{Dirichlet}(\\alpha_1, \\ldots, \\alpha_P)\n```\n\n----------------------------------------\n\nTITLE: Setting Up PyMC-Marketing Development Environment\nDESCRIPTION: These commands create and activate a Conda environment for PyMC-Marketing development, then install the package and its dependencies in editable mode.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nconda env create -f environment.yml\nconda activate pymc-marketing-dev\nmake init\n```\n\n----------------------------------------\n\nTITLE: Running PyMC-Marketing Tests and Code Style Checks\nDESCRIPTION: These commands run the project's test suite and check code formatting to ensure consistency and correctness.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nmake test\nmake check_format\nmake format\n```\n\n----------------------------------------\n\nTITLE: Running Linting and Formatting Checks\nDESCRIPTION: Make commands for checking and fixing linting errors, running tests, and checking/fixing code style.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/CONTRIBUTING.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake check_lint\nmake lint\nmake test\nmake check_format\nmake format\n```\n\n----------------------------------------\n\nTITLE: Forking PyMC-Marketing Repository Using GitHub CLI\nDESCRIPTION: This command uses the GitHub CLI to fork the PyMC-Marketing repository, simplifying the process of creating a personal copy of the project.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/contributing/index.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngh repo fork pymc-labs/pymc-marketing\n```\n\n----------------------------------------\n\nTITLE: Building Documentation Locally\nDESCRIPTION: Make commands for building the documentation locally and cleaning the build directory.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/CONTRIBUTING.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake html\nmake cleandocs\n```\n\n----------------------------------------\n\nTITLE: Generating PyMC Marketing API Documentation with reStructuredText Directives\nDESCRIPTION: This snippet uses reStructuredText's eval-rst directive with autosummary to automatically generate comprehensive documentation for all modules in the pymc_marketing library. It specifies recursive documentation generation with output placed in the 'generated/' directory.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/api/index.md#2025-04-18_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: pymc_marketing\n.. autosummary::\n  :recursive:\n  :toctree: generated/\n\n  clv\n  customer_choice\n  deserialize\n  hsgp_kwargs\n  metrics\n  mlflow\n  mmm\n  model_builder\n  model_config\n  model_graph\n  prior\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Template with Jinja2 for PyMC Marketing\nDESCRIPTION: A complete Sphinx documentation template using Jinja2 templating to generate structured API documentation. The template organizes documentation into sections for module attributes, functions, classes, exceptions, and submodules, with appropriate directives for autosummary generation.\nSOURCE: https://github.com/pymc-labs/pymc-marketing/blob/main/docs/source/_templates/autosummary/module.rst#2025-04-18_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ name | escape | underline}}\n\n.. automodule:: {{ fullname }}\n\n   {% block attributes %}\n   {% if attributes %}\n   .. rubric:: {{ _('Module Attributes') }}\n\n   .. autosummary::\n   {% for item in attributes %}\n      {{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block functions %}\n   {% if functions %}\n   .. rubric:: {{ _('Functions') }}\n\n   .. autosummary::\n      :toctree:\n\n   {% for item in functions %}\n      {{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block classes %}\n   {% if classes %}\n   .. rubric:: {{ _('Classes') }}\n\n   .. autosummary::\n      :toctree:\n\n   {% for item in classes %}\n      {{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block exceptions %}\n   {% if exceptions %}\n   .. rubric:: {{ _('Exceptions') }}\n\n   .. autosummary::\n   {% for item in exceptions %}\n      {{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n{% block modules %}\n{% if modules %}\n.. rubric:: Modules\n\n.. autosummary::\n   :toctree:\n   :recursive:\n{% for item in modules %}\n   {{ item }}\n{%- endfor %}\n{% endif %}\n{% endblock %}\n```"
  }
]