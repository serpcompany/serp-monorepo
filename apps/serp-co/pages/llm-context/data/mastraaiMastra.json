[
  {
    "owner": "mastra-ai",
    "repo": "mastra",
    "content": "TITLE: Custom Memory Configuration\nDESCRIPTION: This code shows how to configure the `Memory` class with custom storage (LibSQLStore), vector database (LibSQLVector), and memory options. It demonstrates setting up storage URLs, configuring semantic search with `topK` and `messageRange`, and enabling working memory with a custom template. The `agent` is then created with the custom `memory` config.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { LibSQLStore, LibSQLVector } from \"@mastra/libsql\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst memory = new Memory({\n  // Optional storage configuration - libsql will be used by default\n  storage: new LibSQLStore({\n    url: \"file:./memory.db\",\n  }),\n\n  // Optional vector database for semantic search - libsql will be used by default\n  vector: new LibSQLVector({\n    url: \"file:./vector.db\",\n  }),\n\n  // Memory configuration options\n  options: {\n    // Number of recent messages to include\n    lastMessages: 20,\n\n    // Semantic search configuration\n    semanticRecall: {\n      topK: 3, // Number of similar messages to retrieve\n      messageRange: {\n        // Messages to include around each result\n        before: 2,\n        after: 1,\n      },\n    },\n\n    // Working memory configuration\n    workingMemory: {\n      enabled: true,\n      template: `\n# User\n- First Name:\n- Last Name:\n`,\n    },\n  },\n});\n\nconst agent = new Agent({\n  memory,\n  ...otherOptions,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector Store for PostgreSQL in TypeScript\nDESCRIPTION: Demonstrates how to initialize a PgVector store for PostgreSQL with pgvector extension, create an index with specific dimensions, and upsert vectors with metadata. Uses PostgreSQL connection string from environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\nconst store = new PgVector(process.env.POSTGRES_CONNECTION_STRING)\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with OpenAI in TypeScript\nDESCRIPTION: Demonstrates how to generate embeddings using OpenAI's embedding model. It uses the 'embedMany' function to process multiple chunks at once.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { embedMany } from \"ai\";\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra in NextJS Project Directory\nDESCRIPTION: Commands to initialize Mastra directly within an existing NextJS project using various package managers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd your-nextjs-app\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra@latest init\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn dlx mastra@latest init\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm dlx mastra@latest init\n```\n\n----------------------------------------\n\nTITLE: Reranking Search Results with Cohere in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the rerank function from Mastra's RAG module to improve document retrieval relevance. It utilizes Cohere's reranking service to reorder search results based on multiple scoring factors including semantic similarity, vector similarity, and position.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/reranking-with-cohere.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { rerank } from \"@mastra/rag\";\n\nconst results = rerank(\n  searchResults,\n  \"deployment configuration\",\n  cohere(\"rerank-v3.5\"),\n  {\n    topK: 5,\n    weights: {\n      semantic: 0.4,\n      vector: 0.4,\n      position: 0.2\n    }\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Chef Assistant Agent in TypeScript\nDESCRIPTION: This snippet shows how to create a Chef Assistant agent using Mastra and OpenAI. It defines the agent's name, instructions, and the AI model to use.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nexport const chefAgent = new Agent({\n  name: \"chef-agent\",\n  instructions:\n    \"You are Michel, a practical and experienced home chef\" +\n    \"You help people cook with whatever ingredients they have available.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Create a Weather Information Tool in Mastra\nDESCRIPTION: This code snippet demonstrates how to create a tool in Mastra for fetching weather information for a given city. It uses `@mastra/core/tools` to define the tool and `zod` for input schema validation. The tool includes an `id`, `inputSchema`, `description`, and `execute` function. The `execute` function simulates fetching weather data and returns it.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst getWeatherInfo = async (city: string) => {\n  // Replace with an actual API call to a weather service\n  const data = await fetch(`https://api.example.com/weather?city=${city}`).then(\n    (r) => r.json(),\n  );\n  return data;\n};\n\nexport const weatherInfo = createTool({\n  id: \"Get Weather Information\",\n  inputSchema: z.object({\n    city: z.string(),\n  }),\n  description: `Fetches the current weather information for a given city`,\n  execute: async ({ context: { city } }) => {\n    console.log(\"Using tool to fetch weather information for\", city);\n    return await getWeatherInfo(city);\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Chroma with Mastra\nDESCRIPTION: This code demonstrates how to use the `ChromaVector` class from `@mastra/chroma` to create a collection and insert embeddings into Chroma. It uses `openai` for generating embeddings, `MDocument` for chunking text, and a path to the Chroma database. The example shows how to create a collection and upsert vector embeddings along with associated metadata and documents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ChromaVector } from '@mastra/chroma';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst chroma = new ChromaVector({\n  path: \"path/to/chroma/db\",\n});\n\nawait chroma.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait chroma.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n  documents: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Using the Listen Method - TypeScript\nDESCRIPTION: This snippet shows how to use the `listen()` method to transcribe audio into text within a Mastra agent. It includes importing necessary modules, creating an agent, getting an audio stream, calling the `listen()` method, and printing the transcript. The snippet also demonstrates integrating STT with the agent's generate method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-text.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst voice = new OpenAIVoice();\n\nconst agent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that provides recommendations based on user input.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\nconst audioStream = getMicrophoneStream(); // Assume this function gets audio input\n\nconst transcript = await agent.voice.listen(audioStream, {\n  filetype: \"m4a\", // Optional: specify the audio file type\n});\n\nconsole.log(`User said: ${transcript}`);\n\nconst { text } = await agent.generate(`Based on what the user said, provide them a recommendation: ${transcript}`);\n\nconsole.log(`Recommendation: ${text}`);\n```\n\n----------------------------------------\n\nTITLE: Improving Response Based on Quality Evaluation in Mastra Workflow - TypeScript\nDESCRIPTION: This snippet implements a step that attempts to improve the generated content based on tone and completeness scores. It may suspend to gather further human input if thresholds are not met.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 4: Improve response if needed (may suspend)\nconst improveResponse = new Step({\n  id: 'improveResponse',\n  inputSchema: z.object({\n    improvedContent: z.string(),\n    resumeAttempts: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const content = context.getStepResult(promptAgent)?.modelOutput;\n    const toneScore =\n      context.getStepResult(evaluateTone)?.toneScore.score ?? 0;\n    const completenessScore =\n      context.getStepResult(evaluateTone)?.completenessScore.score ?? 0;\n\n    const improvedContent = context.inputData.improvedContent;\n    const resumeAttempts = context.inputData.resumeAttempts ?? 0;\n\n    // If scores are above threshold, make minor improvements\n    if (toneScore > 0.8 && completenessScore > 0.8) {\n      return { improvedOutput: makeMinorImprovements(content) };\n    }\n\n    console.log('Content quality below threshold, suspending for human intervention', {improvedContent, resumeAttempts});\n\n    if (!improvedContent) {\n      // Suspend with payload containing content and resume attempts\n      await suspend({\n        content,\n        scores: { tone: toneScore, completeness: completenessScore },\n        needsImprovement: toneScore < 0.8 ? 'tone' : 'completeness',\n        resumeAttempts: resumeAttempts + 1,\n      });\n      return { improvedOutput: content ?? '' };\n    }\n\n    console.log('Resumed with human improvements', improvedContent);\n    return { improvedOutput: improvedContent ?? content ?? '' };\n  },\n  outputSchema: z.object({ improvedOutput: z.string() }).optional(),\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra Agent Definition\nDESCRIPTION: Defines a Mastra agent with voice capabilities using OpenAI's `gpt-4o` model and a custom salutation tool. The agent is configured to be a helpful assistant with real-time voice interaction capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { createTool } from '@mastra/core/tools';\nimport { OpenAIRealtimeVoice } from '@mastra/voice-openai-realtime';\nimport { z } from 'zod';\n\n// Have the agent do something\nexport const speechToSpeechServer = new Agent({\n    name: 'mastra',\n    instructions: 'You are a helpful assistant.',\n    voice: new OpenAIRealtimeVoice(),\n    model: openai('gpt-4o'),\n    tools: {\n        salutationTool: createTool({\n            id: 'salutationTool',\n            description: 'Read the result of the tool',\n            inputSchema: z.object({ name: z.string() }),\n            outputSchema: z.object({ message: z.string() }),\n            execute: async ({ context }) => {\n                return { message: `Hello ${context.name}!` }\n            }\n        })\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLVector for Vector Storage\nDESCRIPTION: This code snippet demonstrates how to use the LibSQLVector class to create, populate, and query a vector store. It covers initializing the vector store, creating an index, adding vectors with metadata, and querying for similar vectors using cosine similarity.  Configuration for filtering and result inclusion is also shown.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLVector } from '@mastra/libsql';\n\nconst vectorStore = new LibSQLVector({\n  url: 'file:./my-db.db'\n});\n\n// Create a new table with vector support\nawait vectorStore.createIndex({\n  indexName: 'my_vectors',\n  dimension: 1536,\n  metric: 'cosine',\n});\n\n// Add vectors\nconst ids = await vectorStore.upsert({\n  indexName: 'my_vectors',\n  vectors: [[0.1, 0.2, ...], [0.3, 0.4, ...]],\n  metadata: [{ text: 'doc1' }, { text: 'doc2' }],\n});\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my_vectors',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: 'doc1' }, // filter\n  includeVector: false, // includeVector\n  minScore: 0.5, // minScore\n});\n```\n\n----------------------------------------\n\nTITLE: Agent Integration with Processors (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to integrate a Memory instance with processors into an Agent. It sets up a Memory instance with ToolCallFilter and TokenLimiter, then creates an Agent with this memory. Finally, it sends a message to the agent and processes the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory, TokenLimiter, ToolCallFilter } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Set up memory with processors\nconst memory = new Memory({\n  processors: [\n    new ToolCallFilter({ exclude: [\"debugTool\"] }),\n    new TokenLimiter(16000),\n  ],\n});\n\n// Create an agent with the memory\nconst agent = new Agent({\n  name: \"ProcessorAgent\",\n  instructions: \"You are a helpful assistant with processed memory.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n\n// Use the agent\nconst response = await agent.stream(\"Hi, can you remember our conversation?\", {\n  threadId: \"unique-thread-id\",\n  resourceId: \"user-123\",\n});\n\nfor await (const chunk of response.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Resuming a Suspended Workflow with Human Input in TypeScript\nDESCRIPTION: Shows how to use the resume() method to continue workflow execution with human input. The stepId identifies the suspended step, and the context object contains the data that will be passed to the step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst resumeResult = await run.resume({\n  stepId: 'suspendedStepId',\n  context: {\n    // This data is passed to the suspended step as context.inputData\n    // and must conform to the step's inputSchema\n    userDecision: 'approve'\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather-Based Activity Recommendation Workflow in TypeScript with Mastra\nDESCRIPTION: This code implements a complete Mastra workflow that fetches weather data from an external API and uses an AI agent to recommend activities based on the forecast. It defines an agent with specific instructions, creates workflow steps for fetching weather and planning activities, and coordinates them using Mastra's workflow system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/agentic-workflows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: 'Weather Agent',\n  instructions: `\n        You are a local activities and travel expert who excels at weather-based planning. Analyze the weather data and provide practical activity recommendations.\n        For each day in the forecast, structure your response exactly as follows:\n        📅 [Day, Month Date, Year]\n        ═══════════════════════════\n        🌡️ WEATHER SUMMARY\n        • Conditions: [brief description]\n        • Temperature: [X°C/Y°F to A°C/B°F]\n        • Precipitation: [X% chance]\n        🌅 MORNING ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n        🌞 AFTERNOON ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n        🏠 INDOOR ALTERNATIVES\n        • [Activity Name] - [Brief description including specific venue]\n          Ideal for: [weather condition that would trigger this alternative]\n        ⚠️ SPECIAL CONSIDERATIONS\n        • [Any relevant weather warnings, UV index, wind conditions, etc.]\n        Guidelines:\n        - Suggest 2-3 time-specific outdoor activities per day\n        - Include 1-2 indoor backup options\n        - For precipitation >50%, lead with indoor activities\n        - All activities must be specific to the location\n        - Include specific venues, trails, or locations\n        - Consider activity intensity based on temperature\n        - Keep descriptions concise but informative\n        Maintain this exact formatting for consistency, using the emoji and section headers as shown.\n      `,\n  model: openai('gpt-4o-mini'),\n});\n\nconst fetchWeather = new Step({\n  id: \"fetch-weather\",\n  description: \"Fetches weather forecast for a given city\",\n  inputSchema: z.object({\n    city: z.string().describe(\"The city to get the weather for\"),\n  }),\n  execute: async ({ context }) => {\n    const triggerData = context?.getStepResult<{\n      city: string;\n    }>(\"trigger\");\n\n    if (!triggerData) {\n      throw new Error(\"Trigger data not found\");\n    }\n\n    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(triggerData.city)}&count=1`;\n    const geocodingResponse = await fetch(geocodingUrl);\n    const geocodingData = await geocodingResponse.json();\n\n    if (!geocodingData.results?.[0]) {\n      throw new Error(`Location '${triggerData.city}' not found`);\n    }\n\n    const { latitude, longitude, name } = geocodingData.results[0];\n\n    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&daily=temperature_2m_max,temperature_2m_min,precipitation_probability_mean,weathercode&timezone=auto`;\n    const response = await fetch(weatherUrl);\n    const data = await response.json();\n\n    const forecast = data.daily.time.map((date: string, index: number) => ({\n      date,\n      maxTemp: data.daily.temperature_2m_max[index],\n      minTemp: data.daily.temperature_2m_min[index],\n      precipitationChance: data.daily.precipitation_probability_mean[index],\n      condition: getWeatherCondition(data.daily.weathercode[index]),\n      location: name,\n    }));\n\n    return forecast;\n  },\n});\n\nconst forecastSchema = z.array(\n  z.object({\n    date: z.string(),\n    maxTemp: z.number(),\n    minTemp: z.number(),\n    precipitationChance: z.number(),\n    condition: z.string(),\n    location: z.string(),\n  }),\n);\n\nconst planActivities = new Step({\n  id: \"plan-activities\",\n  description: \"Suggests activities based on weather conditions\",\n  inputSchema: forecastSchema,\n  execute: async ({ context, mastra }) => {\n    const forecast =\n      context?.getStepResult<z.infer<typeof forecastSchema>>(\n        \"fetch-weather\",\n      );\n\n    if (!forecast) {\n      throw new Error(\"Forecast data not found\");\n    }\n\n    const prompt = `Based on the following weather forecast for ${forecast[0].location}, suggest appropriate activities:\n      ${JSON.stringify(forecast, null, 2)}\n      `;\n\n    const response = await agent.stream([\n      {\n        role: \"user\",\n        content: prompt,\n      },\n    ]);\n\n    let activitiesText = '';\n    \n    for await (const chunk of response.textStream) {\n      process.stdout.write(chunk);\n      activitiesText += chunk;\n    }\n\n    return {\n      activities: activitiesText,\n    };\n  },\n});\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"Clear sky\",\n    1: \"Mainly clear\",\n    2: \"Partly cloudy\",\n    3: \"Overcast\",\n    45: \"Foggy\",\n    48: \"Depositing rime fog\",\n    51: \"Light drizzle\",\n    53: \"Moderate drizzle\",\n    55: \"Dense drizzle\",\n    61: \"Slight rain\",\n    63: \"Moderate rain\",\n    65: \"Heavy rain\",\n    71: \"Slight snow fall\",\n    73: \"Moderate snow fall\",\n    75: \"Heavy snow fall\",\n    95: \"Thunderstorm\",\n  };\n  return conditions[code] || \"Unknown\";\n}\n\nconst weatherWorkflow = new Workflow({\n  name: \"weather-workflow\",\n  triggerSchema: z.object({\n    city: z.string().describe(\"The city to get the weather for\"),\n  }),\n})\n  .step(fetchWeather)\n  .then(planActivities);\n\nweatherWorkflow.commit();\n\nconst mastra = new Mastra({\n  workflows: {\n    weatherWorkflow,\n  },\n});\n\nasync function main() {\n  const { start } = mastra.getWorkflow(\"weatherWorkflow\").createRun();\n\n  const result = await start({\n    triggerData: {\n      city: \"London\",\n    },\n  });\n\n  console.log(\"\\n \\n\");\n  console.log(result);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Create Agent with Memory Instance (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to create an agent in Mastra and attach a `Memory` instance to it. It imports necessary modules from `@mastra/core/agent`, `@mastra/memory`, and `@ai-sdk/openai`, then creates an agent with a name, instructions, a model, and a memory instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const myMemoryAgent = new Agent({\n  name: \"MemoryAgent\",\n  instructions: \"...\",\n  model: openai(\"gpt-4o\"),\n\n  memory: new Memory(),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Tool and Agent in Mastra with TypeScript\nDESCRIPTION: This code snippet showcases the creation of a custom weather tool and an AI agent in Mastra. It includes API calls to fetch weather data, parsing of weather conditions, and setting up the agent with specific instructions. The main function demonstrates how to use the created agent to generate weather information for a given location.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/using-a-tool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\ninterface WeatherResponse {\n  current: {\n    time: string;\n    temperature_2m: number;\n    apparent_temperature: number;\n    relative_humidity_2m: number;\n    wind_speed_10m: number;\n    wind_gusts_10m: number;\n    weather_code: number;\n  };\n}\n\nconst weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"Get current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"City name\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    feelsLike: z.number(),\n    humidity: z.number(),\n    windSpeed: z.number(),\n    windGust: z.number(),\n    conditions: z.string(),\n    location: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return await getWeather(context.location);\n  },\n});\n\nconst getWeather = async (location: string) => {\n  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;\n  const geocodingResponse = await fetch(geocodingUrl);\n  const geocodingData = await geocodingResponse.json();\n\n  if (!geocodingData.results?.[0]) {\n    throw new Error(`Location '${location}' not found`);\n  }\n\n  const { latitude, longitude, name } = geocodingData.results[0];\n\n  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;\n\n  const response = await fetch(weatherUrl);\n  const data: WeatherResponse = await response.json();\n\n  return {\n    temperature: data.current.temperature_2m,\n    feelsLike: data.current.apparent_temperature,\n    humidity: data.current.relative_humidity_2m,\n    windSpeed: data.current.wind_speed_10m,\n    windGust: data.current.wind_gusts_10m,\n    conditions: getWeatherCondition(data.current.weather_code),\n    location: name,\n  };\n};\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"Clear sky\",\n    1: \"Mainly clear\",\n    2: \"Partly cloudy\",\n    3: \"Overcast\",\n    45: \"Foggy\",\n    48: \"Depositing rime fog\",\n    51: \"Light drizzle\",\n    53: \"Moderate drizzle\",\n    55: \"Dense drizzle\",\n    56: \"Light freezing drizzle\",\n    57: \"Dense freezing drizzle\",\n    61: \"Slight rain\",\n    63: \"Moderate rain\",\n    65: \"Heavy rain\",\n    66: \"Light freezing rain\",\n    67: \"Heavy freezing rain\",\n    71: \"Slight snow fall\",\n    73: \"Moderate snow fall\",\n    75: \"Heavy snow fall\",\n    77: \"Snow grains\",\n    80: \"Slight rain showers\",\n    81: \"Moderate rain showers\",\n    82: \"Violent rain showers\",\n    85: \"Slight snow showers\",\n    86: \"Heavy snow showers\",\n    95: \"Thunderstorm\",\n    96: \"Thunderstorm with slight hail\",\n    99: \"Thunderstorm with heavy hail\",\n  };\n  return conditions[code] || \"Unknown\";\n}\n\nconst weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `You are a helpful weather assistant that provides accurate weather information.\nYour primary function is to help users get weather details for specific locations. When responding:\n- Always ask for a location if none is provided\n- If the location name isn't in English, please translate it\n- Include relevant details like humidity, wind conditions, and precipitation\n- Keep responses concise but informative\nUse the weatherTool to fetch current weather data.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { weatherTool },\n});\n\nconst mastra = new Mastra({\n  agents: { weatherAgent },\n});\n\nasync function main() {\n  const agent = await mastra.getAgent(\"weatherAgent\");\n  const result = await agent.generate(\"What is the weather in London?\");\n  console.log(result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Using Direct References for Type Safety: TypeScript\nDESCRIPTION: This snippet demonstrates defining steps in a workflow using direct references for enhanced type safety. The processUserStep leverages the output schema of fetchUserStep to guarantee correct typing of the user data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define step with output schema\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processUserStep = new Step({\n  id: \"processUser\",\n  execute: async ({ context }) => {\n    // TypeScript will infer the correct type from fetchUserStep's outputSchema\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      processed: true,\n      userName: userData?.name\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"user-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processUserStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Creating a Tool using Vercel AI SDK format (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create a tool using the Vercel AI SDK's `tool` function. It defines the tool's description, parameters (using `zod`), and the `execute` function, which fetches weather data based on the provided city. This showcases the compatibility of Mastra with tools created using the Vercel AI SDK format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\n\nexport const weatherInfo = tool({\n  description: \"Fetches the current weather information for a given city\",\n  parameters: z.object({\n    city: z.string().describe(\"The city to get weather for\"),\n  }),\n  execute: async ({ city }) => {\n    // Replace with actual API call\n    const data = await fetch(`https://api.example.com/weather?city=${city}`);\n    return data.json();\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: RAG Implementation Example in Mastra\nDESCRIPTION: This code demonstrates the essential steps of implementing RAG: initializing a document, creating chunks, generating embeddings using OpenAI's embedding model, storing them in a pgvector database, and querying for similar content. It requires the `ai`, `@ai-sdk/openai`, `@mastra/pg`, `@mastra/rag`, and `zod` libraries. The `POSTGRES_CONNECTION_STRING` environment variable must be set.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument } from \"@mastra/rag\";\nimport { z } from \"zod\";\n\n// 1. Initialize document\nconst doc = MDocument.fromText(`Your document text here...`);\n\n// 2. Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n});\n\n// 3. Generate embeddings; we need to pass the text of each chunk\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\n// 4. Store in vector database\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING);\nawait pgVector.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n}); // using an index name of 'embeddings'\n\n// 5. Query similar chunks\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryVector,\n  topK: 3,\n}); // queryVector is the embedding of the query\n\nconsole.log(\"Similar chunks:\", results);\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Memory with PostgreSQL Storage and Vector Search\nDESCRIPTION: Sets up Mastra's memory system with PostgreSQL as the storage backend and vector search capability. This snippet establishes database connections, configures memory options, and creates an agent that utilizes the memory system for maintaining conversation context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-pg.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { PostgresStore, PgVector } from \"@mastra/pg\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// PostgreSQL connection details\nconst host = \"localhost\";\nconst port = 5432;\nconst user = \"postgres\";\nconst database = \"postgres\";\nconst password = \"postgres\";\nconst connectionString = `postgresql://${user}:${password}@${host}:${port}`;\n\n// Initialize memory with PostgreSQL storage and vector search\nconst memory = new Memory({\n  storage: new PostgresStore({\n    host,\n    port,\n    user,\n    database,\n    password,\n  }),\n  vector: new PgVector(connectionString),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\n// Create an agent with memory capabilities\nconst chefAgent = new Agent({\n  name: \"chefAgent\",\n  instructions:\n    \"You are Michel, a practical and experienced home chef who helps people cook great meals with whatever ingredients they have available.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Input Schema for Human Input Validation in TypeScript\nDESCRIPTION: Demonstrates how to define an input schema on steps that might be resumed with human input to ensure type safety. The schema validates the data passed in resume's context and makes it available as context.inputData within the step's execute function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst myStep = new Step({\n  id: 'myStep',\n  inputSchema: z.object({\n    // This schema validates the data passed in resume's context\n    // and makes it available as context.inputData\n    userDecision: z.enum(['approve', 'reject']),\n    userComments: z.string().optional(),\n  }),\n  execute: async ({ context, suspend }) => {\n    // Check if we have user input from a previous suspension\n    if (context.inputData?.userDecision) {\n      // Process the user's decision\n      return { result: `User decided: ${context.inputData.userDecision}` };\n    }\n\n    // If no input, suspend for human decision\n    await suspend();\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Agent Definition with System Prompt and Tool Integration (Mastra/OpenAI)\nDESCRIPTION: This code defines an AI agent named `catOne` using Mastra, integrated with OpenAI's `gpt-4o-mini` model. The agent is given specific instructions via a system prompt to act as a helpful cat expert assistant. It utilizes a custom tool, `catFact`, to fetch cat facts from an external API (`https://catfact.ninja/fact`) and incorporate them into its responses. The Zod library is used for input schema validation for the tool. The `generate` method is called on the agent to produce a response based on the input \"Tell me a cat fact\".\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/system-prompt.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\n\nimport { z } from \"zod\";\n\nconst instructions = `You are a helpful cat expert assistant. When discussing cats, you should always include an interesting cat fact.\n\n  Your main responsibilities:\n  1. Answer questions about cats\n  2. Use the catFact tool to provide verified cat facts\n  3. Incorporate the cat facts naturally into your responses\n\n  Always use the catFact tool at least once in your responses to ensure accuracy.`;\n\nconst getCatFact = async () => {\n  const { fact } = (await fetch(\"https://catfact.ninja/fact\").then((res) =>\n    res.json(),\n  )) as {\n    fact: string;\n  };\n\n  return fact;\n};\n\nconst catFact = createTool({\n  id: \"Get cat facts\",\n  inputSchema: z.object({}),\n  description: \"Fetches cat facts\",\n  execute: async () => {\n    console.log(\"using tool to fetch cat fact\");\n    return {\n      catFact: await getCatFact(),\n    };\n  },\n});\n\nconst catOne = new Agent({\n  name: \"cat-one\",\n  instructions: instructions,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    catFact,\n  },\n});\n\nconst result = await catOne.generate(\"Tell me a cat fact\");\n\nconsole.log(result.text);\n```\n\n----------------------------------------\n\nTITLE: Merging Multiple Branches in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to merge multiple branches in a Mastra workflow using the `.after([])` syntax. The `processOrder` step will only execute after both `validateUserData` and `validateProductData` have completed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(fetchUserData)\n  .then(validateUserData)\n  .step(fetchProductData)\n  .then(validateProductData)\n  // このステップは、validateUserDataとvalidateProductDataの両方が完了した後にのみ実行されます\n  .after([validateUserData, validateProductData])\n  .step(processOrder)\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech-to-Speech with Mastra Agent\nDESCRIPTION: This example shows how to set up a complete Speech-to-Speech interaction using Mastra's Agent with OpenAIRealtimeVoice. It demonstrates connecting to the voice service, handling audio responses, initiating conversation, and sending continuous audio from a microphone stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-speech.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst agent = new Agent({\n  name: 'Agent',\n  instructions: `You are a helpful assistant with real-time voice capabilities.`,\n  model: openai('gpt-4o'),\n  voice: new OpenAIRealtimeVoice(),\n});\n\n// Connect to the voice service\nawait agent.voice.connect();\n\n// Listen for agent audio responses\nagent.voice.on('speaker', ({ audio }) => {\n  playAudio(audio);\n});\n\n// Initiate the conversation\nawait agent.voice.speak('How can I help you today?');\n\n// Send continuous audio from the microphone\nconst micStream = getMicrophoneStream();\nawait agent.voice.send(micStream);\n```\n\n----------------------------------------\n\nTITLE: Basic Runtime Context Usage in Mastra (TypeScript)\nDESCRIPTION: Demonstrates the basic usage of Mastra's runtime context for configuring an agent. It defines a `WeatherRuntimeContext` type, creates a `RuntimeContext` instance, sets a value, and passes it to the agent's `generate` method. The `response.text` is then printed to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/runtime-variables.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = mastra.getAgent(\"weatherAgent\");\n\n// Define your runtimeContext's type structure\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\"; // Fixed typo in \"fahrenheit\"\n};\n\nconst runtimeContext = new RuntimeContext<WeatherRuntimeContext>();\nruntimeContext.set(\"temperature-scale\", \"celsius\");\n\nconst response = await agent.generate(\"What's the weather like today?\", {\n  runtimeContext,\n});\n\nconsole.log(response.text);\n```\n\n----------------------------------------\n\nTITLE: Configuring a Mastra Agent in TypeScript\nDESCRIPTION: This snippet configures a Mastra agent using the `Agent` class from `@mastra/core/agent`. The agent is named 'RAG Agent' and given instructions to answer questions based on the provided context. The agent uses the 'gpt-4o-mini' model from OpenAI and is equipped with the previously created `vectorQueryTool` for retrieving context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  instructions:\n    'You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.',\n  model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Weather Information Tool in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a tool using the `@mastra/core/tools` package that fetches weather information for a given city. It defines the input schema using `zod` and includes an asynchronous executor function that calls an external weather API.  A placeholder URL is provided, but should be replaced with an actual API endpoint for real functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst getWeatherInfo = async (city: string) => {\n  // Replace with an actual API call to a weather service\n  const data = await fetch(`https://api.example.com/weather?city=${city}`).then(\n    (r) => r.json(),\n  );\n  return data;\n};\n\nexport const weatherInfo = createTool({\n  id: \"Get Weather Information\",\n  inputSchema: z.object({\n    city: z.string(),\n  }),\n  description: `Fetches the current weather information for a given city`,\n  execute: async ({ context: { city } }) => {\n    console.log(\"Using tool to fetch weather information for\", city);\n    return await getWeatherInfo(city);\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Adding Instructions to Realtime Voice Provider (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to initialize a real-time voice provider using OpenAIRealtimeVoice, create an agent with this voice provider, and add additional instructions to guide the voice provider's behavior during interactions.  The instructions are specifically targeted at customer support scenarios. It requires the `@mastra/voice-openai-realtime`, `@mastra/core/agent`, and `@ai-sdk/openai` packages and an OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.addInstructions.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Create an agent with the voice provider\nconst agent = new Agent({\n  name: \"Customer Support Agent\",\n  instructions: \"You are a helpful customer support agent for a software company.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\n// Add additional instructions to the voice provider\nvoice.addInstructions(`\n  When speaking to customers:\n  - Always introduce yourself as the customer support agent\n  - Speak clearly and concisely\n  - Ask clarifying questions when needed\n  - Summarize the conversation at the end\n`);\n\n// Connect to the real-time service\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Client SDK using Package Managers\nDESCRIPTION: Commands for installing the Mastra client SDK using different Node.js package managers (npm, yarn, pnpm).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/client-js\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @mastra/client-js\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Basic Workflow Suspend Example TypeScript\nDESCRIPTION: Demonstrates a simple workflow that suspends when a value is below a threshold and resumes when a higher value is provided.  It uses the `suspend` function within a `Step`'s `execute` function to pause execution and persist the workflow state.  The workflow resumes when provided with new data that satisfies the condition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n\n    const currentValue = context.steps.stepOne.output.doubledValue;\n\n    if (currentValue < 100) {\n      await suspend();\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: currentValue + 1 };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking Documents with Recursive Strategy in TypeScript\nDESCRIPTION: Shows how to use the 'recursive' chunking strategy to split documents into manageable pieces. It includes options for chunk size, overlap, separator, and metadata extraction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n  extract: {\n    metadata: true, // Optionally extract metadata\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Error Handling with RuntimeContext Variables in Mastra (TypeScript)\nDESCRIPTION: This snippet showcases error handling techniques when working with runtimeContext variables in Mastra workflows. It demonstrates checking for missing variables and validating their types and values to prevent runtime errors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/runtime-variables.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Example of defensive programming with runtimeContext variables\nconst multiplier = runtimeContext.get(\"multiplier\");\nif (multiplier === undefined) {\n  throw new Error(\"Multiplier not configured in runtimeContext\");\n}\n\n// Type and value validation\nif (typeof multiplier !== \"number\" || multiplier <= 0) {\n  throw new Error(`Invalid multiplier value: ${multiplier}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Agent with TTS Capabilities (Mastra)\nDESCRIPTION: This code snippet demonstrates how to create an agent with Text-to-Speech (TTS) capabilities using Mastra, OpenAI, and the @mastra/voice-openai package. It defines an interactive storyteller agent with specific instructions, a GPT-4o model, and an OpenAI voice. The agent is designed to create engaging short stories with user choices that influence the narrative.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { Memory } from '@mastra/memory';\n\nconst instructions = `\n    You are an Interactive Storyteller Agent. Your job is to create engaging\n    short stories with user choices that influence the narrative. // omitted for brevity\n`;\n\nexport const storyTellerAgent = new Agent({\n  name: 'Story Teller Agent',\n  instructions: instructions,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution Using Function Condition in Mastra Workflows\nDESCRIPTION: Shows how to conditionally execute a step based on a dynamic function evaluation, which allows for complex logic to determine if a step should run.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: async ({ context }) => {\n      const fetchData = context?.getStepResult<{ status: string }>(\"fetchData\");\n      return fetchData?.status === \"success\";\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Using afterEvent to Suspend Workflow (TypeScript)\nDESCRIPTION: This snippet illustrates how to use the `afterEvent` method to create a suspension point in a Mastra workflow, waiting for a specific event to occur before proceeding to the next step. The `afterEvent` method takes the event name as a parameter. Workflow execution pauses at this point and resumes when the specified event is triggered with `resumeWithEvent`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(initialProcessStep)\n  .afterEvent('approvalReceived')  // Workflow suspends here\n  .step(postApprovalStep)          // This runs after event is received\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: useChat Hook Integration\nDESCRIPTION: This snippet showcases the integration of the `useChat` hook from `@ai-sdk/react` with a Mastra agent. It defines a POST endpoint that retrieves a Mastra agent and streams its response using `.toDataStreamResponse()`. The frontend component utilizes the `useChat` hook to manage chat interactions, connecting to the agent stream API endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages);\n\n  return stream.toDataStreamResponse();\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useChat } from '@ai-sdk/react';\n\nexport function ChatComponent() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}: {m.content}\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Say something...\"\n        />\n      </form>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tools with createTool() in TypeScript\nDESCRIPTION: This snippet demonstrates how to create custom tools using the createTool() function from Mastra. It includes examples of a stock price tool and a thread info tool, showcasing input/output schema validation, execution logic, and integration with the Mastra ecosystem.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/createTool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\n// Helper function to fetch stock data\nconst getStockPrice = async (symbol: string) => {\n  const response = await fetch(\n    `https://mastra-stock-data.vercel.app/api/stock-data?symbol=${symbol}`\n  );\n  const data = await response.json();\n  return data.prices[\"4. close\"];\n};\n\n// Create a tool to get stock prices\nexport const stockPriceTool = createTool({\n  id: \"getStockPrice\",\n  description: \"Fetches the current stock price for a given ticker symbol\",\n  inputSchema: z.object({\n    symbol: z.string().describe(\"The stock ticker symbol (e.g., AAPL, MSFT)\")\n  }),\n  outputSchema: z.object({\n    symbol: z.string(),\n    price: z.number(),\n    currency: z.string(),\n    timestamp: z.string()\n  }),\n  execute: async ({ context }) => {\n    const price = await getStockPrice(context.symbol);\n    \n    return {\n      symbol: context.symbol,\n      price: parseFloat(price),\n      currency: \"USD\",\n      timestamp: new Date().toISOString()\n    };\n  }\n});\n\n// Create a tool that uses the thread context\nexport const threadInfoTool = createTool({\n  id: \"getThreadInfo\",\n  description: \"Returns information about the current conversation thread\",\n  inputSchema: z.object({\n    includeResource: z.boolean().optional().default(false)\n  }),\n  execute: async ({ context, threadId, resourceId }) => {\n    return {\n      threadId,\n      resourceId: context.includeResource ? resourceId : undefined,\n      timestamp: new Date().toISOString()\n    };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing AstraVector Store in TypeScript\nDESCRIPTION: Demonstrates how to initialize a DataStax Astra vector store with token, endpoint, and keyspace, then create an index with specific dimensions, and upsert vectors with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AstraVector } from '@mastra/astra'\n\nconst store = new AstraVector({\n  token: process.env.ASTRA_DB_TOKEN,\n  endpoint: process.env.ASTRA_DB_ENDPOINT,\n  keyspace: process.env.ASTRA_DB_KEYSPACE\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Re-ranking Search Results in Typescript\nDESCRIPTION: This snippet demonstrates how to re-rank initial search results using the `rerank` function.  It takes initial results and a query as input, and improves the relevance by taking into account word order and semantic understanding. Requires the `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { rerank } from \"@mastra/rag\";\n\n// ベクトル検索から初期結果を取得\nconst initialResults = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryEmbedding,\n  topK: 10,\n});\n\n// 結果を再ランキング\nconst rerankedResults = await rerank(initialResults, query, openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra Agent with Memory in TypeScript\nDESCRIPTION: Configures a new Agent with OpenAI's GPT-4o-mini model and attaches the previously initialized memory instance to enable working memory capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Memory agent\",\n  instructions: \"You are a helpful AI assistant.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory, // or toolCallMemory\n});\n```\n\n----------------------------------------\n\nTITLE: Comprehensive Type Safety in Workflows: TypeScript\nDESCRIPTION: This snippet demonstrates defining types for all steps in a workflow to ensure comprehensive type safety for context and results, allowing for type-safe checks on the output of each step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Create steps with typed outputs\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of userData\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      orderId: \"order123\",\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow<[typeof fetchUserStep, typeof processOrderStep]>({\n  name: \"typed-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .until(async ({ context }) => {\n    // TypeScript knows the shape of userData here\n    const res = context.getStepResult('fetchUser');\n    return res?.userId === '123';\n  }, processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Response with No Hallucination in Mastra\nDESCRIPTION: This example demonstrates evaluating a response that matches the context exactly, resulting in a hallucination score of 0. It sets up the context about iPhone facts, configures the HallucinationMetric with GPT-4o-mini, and measures a response that accurately reflects the context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/hallucination.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'The iPhone was first released in 2007.',\n  'Steve Jobs unveiled it at Macworld.',\n  'The original model had a 3.5-inch screen.',\n];\n\nconst metric1 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'When was the first iPhone released?';\nconst response1 = 'The iPhone was first released in 2007, when Steve Jobs unveiled it at Macworld. The original iPhone featured a 3.5-inch screen.';\n\nconsole.log('Example 1 - No Hallucination:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response matches the context exactly.' }\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Chroma in Typescript\nDESCRIPTION: This snippet shows how to integrate a `CHROMA_PROMPT` into an agent's instructions for querying Chroma.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { CHROMA_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${CHROMA_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Terminal Prompts with Inquirer in TypeScript\nDESCRIPTION: Demonstrates how to use the Inquirer library to create interactive prompts for collecting human input when a workflow is suspended. The code shows how to display information from the suspend payload and resume the workflow with the collected input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { select, input, confirm } from '@inquirer/prompts';\n\n// When the workflow is suspended\nif (result.status === 'suspended') {\n  // Display information from the suspend payload\n  console.log(result.suspendPayload.message);\n\n  // Collect user input interactively\n  const decision = await select({\n    message: 'What would you like to do?',\n    choices: [\n      { name: 'Approve', value: 'approve' },\n      { name: 'Reject', value: 'reject' }\n    ]\n  });\n\n  // Resume the workflow with the collected input\n  await run.resume({\n    stepId: result.suspendedStepId,\n    context: { decision }\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into PgVector with Mastra\nDESCRIPTION: This code demonstrates how to use the `PgVector` class from `@mastra/pg` to create an index and insert embeddings into a PostgreSQL database with the pgvector extension. It uses `openai` for generating embeddings, `MDocument` for chunking text, and environment variables for database connection details. The example showcases creating an index and upserting vector embeddings along with associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nawait pgVector.createIndex({\n  indexName: \"test_index\",\n  dimension: 1536,\n});\n\nawait pgVector.upsert({\n  indexName: \"test_index\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Copywriter Agent and Tool in TypeScript\nDESCRIPTION: This snippet defines a Copywriter agent using the Anthropic Claude model and creates a tool for generating blog post copy. It uses Zod for input and output schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n\nconst copywriterTool = createTool({\n  id: \"copywriter-agent\",\n  description: \"Calls the copywriter agent to write blog post copy.\",\n  inputSchema: z.object({\n    topic: z.string().describe(\"Blog post topic\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"Blog post copy\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.topic}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Advanced Workflow Factory in TypeScript with Mastra\nDESCRIPTION: Shows how to create a workflow factory that generates different types of workflows (simple or complex) based on input parameters. Includes conditional workflow creation and multiple step configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/dynamic-workflows.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === 'object' && mastra instanceof Mastra;\n};\n\nconst workflowFactory = new Step({\n  id: 'workflowFactory',\n  inputSchema: z.object({\n    workflowType: z.enum(['simple', 'complex']),\n    inputData: z.string(),\n  }),\n  outputSchema: z.object({\n    result: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error('Mastra instance not available');\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error('Invalid Mastra instance');\n    }\n\n    // Create a new dynamic workflow based on the type\n    const dynamicWorkflow = new Workflow({\n      name: `dynamic-${context.workflowType}-workflow`,\n      mastra,\n      triggerSchema: z.object({\n        input: z.string(),\n      }),\n    });\n\n    if (context.workflowType === 'simple') {\n      // Simple workflow with a single step\n      const simpleStep = new Step({\n        id: 'simpleStep',\n        execute: async ({ context }) => {\n          return {\n            result: `Simple processing: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(simpleStep).commit();\n    } else {\n      // Complex workflow with multiple steps\n      const step1 = new Step({\n        id: 'step1',\n        outputSchema: z.object({\n          intermediateResult: z.string(),\n        }),\n        execute: async ({ context }) => {\n          return {\n            intermediateResult: `First processing: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      const step2 = new Step({\n        id: 'step2',\n        execute: async ({ context }) => {\n          const intermediate = context.getStepResult(step1).intermediateResult;\n          return {\n            finalResult: `Second processing: ${intermediate}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(step1).then(step2).commit();\n    }\n\n    // Execute the dynamic workflow\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        input: context.inputData,\n      },\n    });\n\n    // Return the appropriate result based on workflow type\n    if (context.workflowType === 'simple') {\n      return {\n        // @ts-ignore\n        result: result.results['simpleStep']?.output,\n      };\n    } else {\n      return {\n        // @ts-ignore\n        result: result.results['step2']?.output,\n      };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Specialized Agents from Agent Network - TypeScript\nDESCRIPTION: This code snippet defines the getAgents() method, which returns the array of specialized agents contained within the AgentNetwork. It is useful for understanding the components of the network.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgents(): Agent[]\n```\n\n----------------------------------------\n\nTITLE: Tool Description Best Practices in TypeScript\nDESCRIPTION: This code snippet exemplifies best practices for writing tool descriptions focusing on purpose and value, while keeping technical details in parameter schemas for clarity and effective agent interaction. It shows the use of `createTool` with a clear description and parameters with detailed descriptions and potential options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ncreateTool({\n  id: \"documentSearch\",\n  description:\n    \"Access the knowledge base to find information needed to answer user questions\",\n  // ... rest of tool configuration\n});\n\ninputSchema: z.object({\n  query: z.string().describe(\"The search query to find relevant information\"),\n  limit: z.number().describe(\n    \"Number of results to return. Higher values provide more context, lower values focus on best matches\"\n  ),\n  options: z.string().describe(\n    \"Optional configuration. Example: '{'filter': 'category=news'}'\"\n  ),\n}),\n```\n\n----------------------------------------\n\nTITLE: Registering an Agent with Mastra in TypeScript\nDESCRIPTION: This code snippet shows how to register the `weatherAgent` with Mastra using the `@mastra/core` package.  It initializes a new `Mastra` instance and assigns the `weatherAgent` to the agents property, making the agent available for use within the Mastra environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { weatherAgent } from \"./agents/weatherAgent\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Zod Schema for Structured Output (TypeScript)\nDESCRIPTION: This snippet shows how to define a Zod schema for specifying the structure of the agent's output. It imports the `z` object from the `zod` library and creates a schema with `summary` and `keywords` properties.  The `summary` is defined as a string, and `keywords` is defined as an array of strings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\n// Define the Zod schema\nconst schema = z.object({\n  summary: z.string(),\n  keywords: z.array(z.string()),\n});\n\n// Use the schema with the agent\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"Please provide a summary and keywords for the following text: ...\",\n    },\n  ],\n  {\n    output: schema,\n  },\n);\n\nconsole.log(\"Structured Output:\", response.object);\n```\n\n----------------------------------------\n\nTITLE: Setting Up Graph-based Retrieval for Complex Document Relationships in TypeScript\nDESCRIPTION: Code showing how to configure graph-based retrieval for documents with complex relationships. The createGraphQueryTool function sets up a tool that can traverse relationships between document chunks, useful when information is spread across multiple documents or documents reference each other.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphQueryTool = createGraphQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    threshold: 0.7,\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing User Registration Workflow in TypeScript with Mastra\nDESCRIPTION: This code snippet defines a user registration workflow using Mastra. It includes three steps: validating user input, formatting user data, and creating a user profile. The workflow demonstrates the use of Zod for schema validation, step definitions with input/output schemas, and variable mappings between steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/workflow-variables.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define our schemas for better type safety\nconst userInputSchema = z.object({\n  email: z.string().email(),\n  name: z.string(),\n  age: z.number().min(18),\n});\n\nconst validatedDataSchema = z.object({\n  isValid: z.boolean(),\n  validatedData: z.object({\n    email: z.string(),\n    name: z.string(),\n    age: z.number(),\n  }),\n});\n\nconst formattedDataSchema = z.object({\n  userId: z.string(),\n  formattedData: z.object({\n    email: z.string(),\n    displayName: z.string(),\n    ageGroup: z.string(),\n  }),\n});\n\nconst profileSchema = z.object({\n  profile: z.object({\n    id: z.string(),\n    email: z.string(),\n    displayName: z.string(),\n    ageGroup: z.string(),\n    createdAt: z.string(),\n  }),\n});\n\n// Define the workflow\nconst registrationWorkflow = new Workflow({\n  name: \"user-registration\",\n  triggerSchema: userInputSchema,\n});\n\n// Step 1: Validate user input\nconst validateInput = new Step({\n  id: \"validateInput\",\n  inputSchema: userInputSchema,\n  outputSchema: validatedDataSchema,\n  execute: async ({ context }) => {\n    const { email, name, age } = context;\n\n    // Simple validation logic\n    const isValid = email.includes('@') && name.length > 0 && age >= 18;\n\n    return {\n      isValid,\n      validatedData: {\n        email: email.toLowerCase().trim(),\n        name,\n        age,\n      },\n    };\n  },\n});\n\n// Step 2: Format user data\nconst formatUserData = new Step({\n  id: \"formatUserData\",\n  inputSchema: z.object({\n    validatedData: z.object({\n      email: z.string(),\n      name: z.string(),\n      age: z.number(),\n    }),\n  }),\n  outputSchema: formattedDataSchema,\n  execute: async ({ context }) => {\n    const { validatedData } = context;\n\n    // Generate a simple user ID\n    const userId = `user_${Math.floor(Math.random() * 10000)}`;\n\n    // Format the data\n    const ageGroup = validatedData.age < 30 ? \"young-adult\" : \"adult\";\n\n    return {\n      userId,\n      formattedData: {\n        email: validatedData.email,\n        displayName: validatedData.name,\n        ageGroup,\n      },\n    };\n  },\n});\n\n// Step 3: Create user profile\nconst createUserProfile = new Step({\n  id: \"createUserProfile\",\n  inputSchema: z.object({\n    userId: z.string(),\n    formattedData: z.object({\n      email: z.string(),\n      displayName: z.string(),\n      ageGroup: z.string(),\n    }),\n  }),\n  outputSchema: profileSchema,\n  execute: async ({ context }) => {\n    const { userId, formattedData } = context;\n\n    // In a real app, you would save to a database here\n\n    return {\n      profile: {\n        id: userId,\n        ...formattedData,\n        createdAt: new Date().toISOString(),\n      },\n    };\n  },\n});\n\n// Build the workflow with variable mappings\nregistrationWorkflow\n  // First step gets data from the trigger\n  .step(validateInput, {\n    variables: {\n      email: { step: 'trigger', path: 'email' },\n      name: { step: 'trigger', path: 'name' },\n      age: { step: 'trigger', path: 'age' },\n    }\n  })\n  // Format user data with validated data from previous step\n  .then(formatUserData, {\n    variables: {\n      validatedData: { step: validateInput, path: 'validatedData' },\n    },\n    when: {\n      ref: { step: validateInput, path: 'isValid' },\n      query: { $eq: true },\n    },\n  })\n  // Create profile with data from the format step\n  .then(createUserProfile, {\n    variables: {\n      userId: { step: formatUserData, path: 'userId' },\n      formattedData: { step: formatUserData, path: 'formattedData' },\n    },\n  })\n  .commit();\n\nexport default registrationWorkflow;\n```\n\n----------------------------------------\n\nTITLE: Filtering Tool Calls\nDESCRIPTION: These snippets show how to filter tool calls using the `ToolCallFilter` processor. The first example filters all tool calls. The second example selectively filters tool calls, excluding `imageGenTool` and `clipboardTool`.  This allows controlling which tool calls are stored in memory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Memory } from \\\"@mastra/memory\\\";\nimport { ToolCallFilter } from \\\"@mastra/memory/processors\\\";\n\n// すべてのツール呼び出しをフィルタリング\nconst memoryNoTools = new Memory({\n  processors: [new ToolCallFilter()],\n});\n\n// 特定のツール呼び出しをフィルタリング\nconst memorySelectiveFilter = new Memory({\n  processors: [\n    new ToolCallFilter({\n      exclude: [\\\"imageGenTool\\\", \\\"clipboardTool\\\"],\n    }),\n  ],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Using PineconeVector\nDESCRIPTION: This TypeScript snippet shows how to import the PineconeVector class, create an instance with an API key, create an index, upsert vectors, and query the vector store. It highlights key parameters such as index name, dimensions, and query vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pinecone/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PineconeVector } from '@mastra/pinecone';\n\nconst vectorStore = new PineconeVector(\n  'your-api-key',\n  'optional-environment-url'\n);\n\n// Create a new index\nawait vectorStore.createIndex({ indexName: 'my-index', dimension: 1536, metric: 'cosine' });\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({ indexName: 'my-index', vectors, metadata });\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my-index',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: { $eq: 'doc1' } }, // optional filter\n  includeVector: false, // includeValues\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Index with Dimension Specification in TypeScript\nDESCRIPTION: Shows how to create a vector index with the appropriate dimension size for different embedding models. Each model requires a specific dimension size that cannot be changed after creation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Create an index with dimension 1536 (for text-embedding-3-small)\nawait store.createIndex({\n  indexName: 'myCollection',\n  dimension: 1536,\n});\n\n// For other models, use their corresponding dimensions:\n// - text-embedding-3-large: 3072\n// - text-embedding-ada-002: 1536\n// - cohere-embed-multilingual-v3: 1024\n```\n\n----------------------------------------\n\nTITLE: Initializing LibSQLVector Store in TypeScript\nDESCRIPTION: Shows how to initialize a LibSQL vector store with connection URL and optional auth token for Turso cloud databases, create an index with specific dimensions, and upsert vectors with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst store = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  authToken: process.env.DATABASE_AUTH_TOKEN // Optional: for Turso cloud databases\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses from Chef Agent in TypeScript\nDESCRIPTION: This code demonstrates how to stream responses from the Chef Assistant agent, allowing for real-time output as the agent generates the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const query =\n    \"Now I'm over at my friend's house, and they have: chicken thighs, coconut milk, sweet potatoes, and some curry powder.\";\n  console.log(`Query: ${query}`);\n\n  const stream = await chefAgent.stream([{ role: \"user\", content: query }]);\n\n  console.log(\"\\n Chef Michel: \");\n\n  for await (const chunk of stream.textStream) {\n    process.stdout.write(chunk);\n  }\n\n  console.log(\"\\n\\n✅ Recipe complete!\");\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech-to-Text with Agent Integration\nDESCRIPTION: Complete example showing how to implement STT functionality with agent integration, including audio stream processing, transcription, and response generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-text.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst voice = new OpenAIVoice();\n\nconst agent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that provides recommendations based on user input.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\nconst audioStream = getMicrophoneStream(); // Assume this function gets audio input\n\nconst transcript = await agent.voice.listen(audioStream, {\n  filetype: \"m4a\", // Optional: specify the audio file type\n});\n\nconsole.log(`User said: ${transcript}`);\n\nconst { text } = await agent.generate(`Based on what the user said, provide them a recommendation: ${transcript}`);\n\nconsole.log(`Recommendation: ${text}`);\n```\n\n----------------------------------------\n\nTITLE: Watching and Resuming Event-Based Workflow (TypeScript)\nDESCRIPTION: This code demonstrates watching and resuming an event-based workflow. It uses `watch` to detect when a specific event step (`__approvalReceived_event`) is suspended, and `resumeWithEvent` to resume the workflow by simulating the occurrence of the event after a delay.  This simulates waiting for an external event to trigger the workflow resumption.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst { start, watch, resumeWithEvent } = workflow.createRun();\n\n// Watch for suspended event steps\nwatch(async ({ activePaths }) => {\n  const isApprovalReceivedSuspended =\n    activePaths.get(\"__approvalReceived_event\")?.status === \"suspended\";\n  if (isApprovalReceivedSuspended) {\n    console.log(\"Workflow waiting for approval event\");\n\n    // In a real scenario, you would wait for the actual event to occur\n    // For example, this could be triggered by a webhook or user interaction\n    setTimeout(async () => {\n      await resumeWithEvent(\"approvalReceived\", {\n        approved: true,\n        approverName: \"Auto Approver\",\n      });\n    }, 5000); // Simulate event after 5 seconds\n  }\n});\n\n// Start the workflow\nawait start({ triggerData: { requestId: \"auto-123\" } });\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent Memory\nDESCRIPTION: Sets up memory management for an AI agent with semantic recall capabilities and message history\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from '@mastra/memory';\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\n\nconst agent = new Agent({\n  name: 'Project Manager',\n  instructions: 'You are a project manager assistant.',\n  model: openai('gpt-4o-mini'),\n  memory: new Memory({\n    options: {\n      lastMessages: 20,\n      semanticRecall: {\n        topK: 3,\n        messageRange: { before: 2, after: 1 },\n      },\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Chroma with Mastra (TSX)\nDESCRIPTION: This code snippet demonstrates how to create a collection and upsert embeddings into a Chroma vector database (an open-source embedding database) using the `ChromaVector` class from the `@mastra/chroma` package. It depends on the `openai` package for generating embeddings and the `MDocument` class from `@mastra/rag` for handling text chunks.  The `path` option in ChromaVector specifies the location to store the database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ChromaVector } from '@mastra/chroma';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst chroma = new ChromaVector({\n  path: \"path/to/chroma/db\",\n});\n\nawait chroma.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait chroma.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n  documents: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Voice-Enabled Agents in TypeScript\nDESCRIPTION: Sets up two agents with different voice configurations - one using CompositeVoice with separate providers for input/output, and another using OpenAI for both capabilities. Includes necessary imports and basic agent configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/adding-voice-capabilities.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Import required dependencies\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { CompositeVoice } from '@mastra/core/voice';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { createReadStream, createWriteStream } from 'fs';\nimport { PlayAIVoice } from '@mastra/voice-playai';\nimport path from 'path';\n\n// Initialize Agent 1 with both listening and speaking capabilities\nconst agent1 = new Agent({\n  name: 'Agent1',\n  instructions: `You are an agent with both STT and TTS capabilities.`,\n  model: openai('gpt-4o'),\n  voice: new CompositeVoice({\n    input: new OpenAIVoice(), // For converting speech to text\n    output: new PlayAIVoice(), // For converting text to speech\n  }),\n});\n\n// Initialize Agent 2 with just OpenAI for both listening and speaking capabilities\nconst agent2 = new Agent({\n  name: 'Agent2',\n  instructions: `You are an agent with both STT and TTS capabilities.`,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and PostgreSQL\nDESCRIPTION: This snippet shows how to set up environment variables for the OpenAI API key and PostgreSQL connection string in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Implementing Re-ranking for Vector Search Results in TypeScript\nDESCRIPTION: Code demonstrating how to improve vector search results using the rerank function. Initial results from vector search are processed by the reranking algorithm which considers word order, exact matches, and applies cross-attention between query and documents to refine relevance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { rerank } from \"@mastra/rag\";\n\n// Get initial results from vector search\nconst initialResults = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryEmbedding,\n  topK: 10,\n});\n\n// Re-rank the results\nconst rerankedResults = await rerank(initialResults, query, openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with Mixed Contextual Recall\nDESCRIPTION: This TypeScript snippet demonstrates evaluating a response with mixed contextual recall.  The response includes some information from the context but also introduces irrelevant or incorrect information.  The metric is used to calculate a score reflecting the proportion of relevant information included in the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/contextual-recall.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Pythonは高水準プログラミング言語です。',\n  'Pythonはコードの可読性を重視しています。',\n  'Pythonは複数のプログラミングパラダイムをサポートします。',\n  'Pythonはデータサイエンスで広く使用されています。',\n];\n\nconst metric2 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'Pythonの主な特徴は何ですか？';\nconst response2 = 'Pythonは高水準プログラミング言語です。また、蛇の一種でもあります。';\n\nconsole.log('例 2 - 混合リコール:');\nconsole.log('コンテキスト:', context2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 0.5, reason: '出力の半分のみがコンテキストによってサポートされています。' }\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings for Graph RAG\nDESCRIPTION: This snippet shows how to generate embeddings for document chunks using OpenAI, create a vector index, and store the embeddings in the PgVector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Editor Agent and Tool in Typescript\nDESCRIPTION: This snippet defines an 'Editor' agent for refining blog post content. It utilizes the OpenAI gpt-4o-mini model.  A tool is defined to enable other agents to call the editor, providing a blog post copy and receiving an edited version.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/hierarchical-multi-agent.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"あなたはブログ投稿のコピーを編集するエディターエージェントです。\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst editorTool = createTool({\n  id: \"editor-agent\",\n  description: \"ブログ投稿のコピーを編集するためにエディターエージェントを呼び出します。\",\n  inputSchema: z.object({\n    copy: z.string().describe(\"ブログ投稿のコピー\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"編集されたブログ投稿のコピー\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${context.copy}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a New Collection in ChromaDB\nDESCRIPTION: This snippet illustrates how to create a new collection in ChromaDB by using the createIndex method of the ChromaVector instance. It specifies the index name, vector dimension, and similarity metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nawait vectorStore.createIndex({ indexName: 'myCollection', dimension: 1536, metric: 'cosine' });\n```\n\n----------------------------------------\n\nTITLE: Using Vector Store in TypeScript\nDESCRIPTION: This snippet shows how to use the PgVector class from the @mastra/pg package to create a new table with vector support, add vectors, query vectors, and handle cleanup. It requires a PostgreSQL server with the pgvector extension installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\nconst vectorStore = new PgVector('postgresql://user:pass@localhost:5432/db');\n\n// Create a new table with vector support\nawait vectorStore.createIndex({\n  indexName: 'my_vectors',\n  dimension: 1536,\n  metric: 'cosine',\n});\n\n// Add vectors\nconst ids = await vectorStore.upsert({\n  indexName: 'my_vectors',\n  vectors: [[0.1, 0.2, ...], [0.3, 0.4, ...]],\n  metadata: [{ text: 'doc1' }, { text: 'doc2' }],\n});\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my_vectors',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: 'doc1' }, // filter\n  includeVector: false, // includeVector\n  minScore: 0.5, // minScore\n});\n\n// Clean up\nawait vectorStore.disconnect();\n```\n\n----------------------------------------\n\nTITLE: Implementing Candidate Info Gathering Step in TypeScript\nDESCRIPTION: This code defines a step to extract candidate details from resume text using an LLM. It sets up an agent, defines input and output schemas, and executes the LLM call to parse the resume.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from \"@ai-sdk/openai\";\n\nconst recruiter = new Agent({\n  name: \"Recruiter Agent\",\n  instructions: `You are a recruiter.`,\n  model: openai(\"gpt-4o-mini\"),\n})\n\nconst gatherCandidateInfo = new Step({\n  id: \"gatherCandidateInfo\",\n  inputSchema: z.object({\n    resumeText: z.string(),\n  }),\n  outputSchema: z.object({\n    candidateName: z.string(),\n    isTechnical: z.boolean(),\n    specialty: z.string(),\n    resumeText: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const resumeText = context?.getStepResult<{\n      resumeText: string;\n    }>(\"trigger\")?.resumeText;\n\n    const prompt = `\n          Extract details from the resume text:\n          \"${resumeText}\"\n        `;\n\n    const res = await recruiter.generate(prompt, {\n      output: z.object({\n        candidateName: z.string(),\n        isTechnical: z.boolean(),\n        specialty: z.string(),\n        resumeText: z.string(),\n      }),\n    });\n\n    return res.object;\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Looping with Nested Workflows in TypeScript\nDESCRIPTION: Shows how to implement workflow loops using while() with nested workflows, including condition checking based on nested workflow results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow\n  .step(firstStep)\n  .while(\n    ({ context }) =>\n      context.getStepResult(\"nested-workflow\").output.results.someField ===\n      \"someValue\",\n    nestedWorkflow,\n  )\n  .step(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Qdrant with Mastra\nDESCRIPTION: This code demonstrates how to use the `QdrantVector` class from `@mastra/qdrant` to create a collection and insert embeddings into Qdrant. It uses `openai` for generating embeddings, `MDocument` for chunking text, and environment variables for Qdrant URL and API key. The example shows how to create a collection and upsert vector embeddings along with associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { QdrantVector } from '@mastra/qdrant';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n  maxRetries: 3,\n});\n\nconst qdrant = new QdrantVector(\n  process.env.QDRANT_URL,\n  process.env.QDRANT_API_KEY,\n);\n\nawait qdrant.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait qdrant.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Nested Workflow Implementation in TypeScript\nDESCRIPTION: Demonstrates how to create and use a nested workflow within a parent workflow using the step() method. Shows basic workflow creation and variable mapping between workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a nested workflow\nconst nestedWorkflow = new Workflow({ name: \"nested-workflow\" })\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// Use the nested workflow in a parent workflow\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"myTriggerInput\",\n      },\n    },\n  })\n  .then(stepC)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Performing Basic Semantic Search with PgVector in TypeScript\nDESCRIPTION: This snippet demonstrates how to convert a query to an embedding, perform a semantic search using PgVector, and display the results. It includes the process of embedding creation, vector store querying, and result formatting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { embed } from \"ai\";\nimport { PgVector } from \"@mastra/pg\";\n\n// Convert query to embedding\nconst { embedding } = await embed({\n  value: \"What are the main points in the article?\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n\n// Query vector store\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING);\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n});\n\n// Display results\nconsole.log(results);\n```\n\n----------------------------------------\n\nTITLE: Executing a Mastra Workflow\nDESCRIPTION: This example demonstrates how to create, commit, and execute a Mastra workflow using the `execute` method. It includes defining a trigger schema, adding steps, committing the workflow, and then executing it with sample trigger data. The result of the execution is then stored in the `result` variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/execute.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number()\n  })\n});\n\nworkflow.step(stepOne).then(stepTwo).commit();\n\nconst result = await workflow.execute({\n  triggerData: { inputValue: 42 }\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Faithfulness Response with Mastra\nDESCRIPTION: This TypeScript snippet showcases the evaluation of a response with mixed faithfulness using Mastra's FaithfulnessMetric. It defines a context, sets up the metric with an OpenAI model, and provides a query and a response containing both supported and unsupported claims. The resulting score and the explanation are printed to the console to show how mixed faithfulness is evaluated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/faithfulness.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Python was created by Guido van Rossum.',\n  'The first version was released in 1991.',\n  'Python emphasizes code readability.',\n];\n\nconst metric2 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'What can you tell me about Python?';\nconst response2 = 'Python was created by Guido van Rossum and released in 1991. It is the most popular programming language today and is used by millions of developers worldwide.';\n\nconsole.log('Example 2 - Mixed Faithfulness:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'Only half of the claims are supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Multiple Voice Provider Setup with CompositeVoice in Mastra\nDESCRIPTION: This snippet demonstrates how to configure a Mastra agent to use different voice providers for speaking and listening using the `CompositeVoice` class.  It sets up OpenAI for listening (STT) and PlayAI for speaking (TTS).  Dependencies include `@mastra/core/agent`, `@mastra/core/voice`, `@mastra/voice-openai`, `@mastra/voice-playai`, and `@ai-sdk/openai`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with both STT and TTS capabilities.`, // Corrected template literal\n  model: openai(\"gpt-4o\"),\n\n  // Create a composite voice using OpenAI for listening and PlayAI for speaking\n  voice: new CompositeVoice({\n    input: new OpenAIVoice(),\n    output: new PlayAIVoice(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Cohere in TypeScript\nDESCRIPTION: Shows how to generate embeddings using Cohere's embedding model. It uses the 'embedMany' function to process multiple chunks simultaneously.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { cohere } from '@ai-sdk/cohere';\nimport { embedMany } from 'ai';\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Graph with GraphRAG\nDESCRIPTION: This snippet showcases the `query` method of the GraphRAG class. It performs a graph-based search, combining vector similarity with graph traversal. It takes a query embedding and optional parameters like `topK`, `randomWalkSteps`, and `restartProb` to fine-tune the search. It returns an array of `RankedNode` objects, each containing information about a relevant document chunk and its score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/graph-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nquery({\n  query,\n  topK = 10,\n  randomWalkSteps = 100,\n  restartProb = 0.15\n}: {\n  query: number[];\n  topK?: number;\n  randomWalkSteps?: number;\n  restartProb?: number;\n}): RankedNode[]\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Workflow Results in TypeScript\nDESCRIPTION: Shows how to access and handle results from a nested workflow within the parent workflow's context. Includes status checking and result extraction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst { results } = await parentWorkflow.start();\n// Access nested workflow results\nconst nestedWorkflowResult = results[\"nested-workflow\"];\nif (nestedWorkflowResult.status === \"success\") {\n  const nestedResults = nestedWorkflowResult.output.results;\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Voice-Enabled Agent with OpenAI STT - Typescript\nDESCRIPTION: This snippet demonstrates how to initialize a voice-enabled agent using the OpenAI's STT capabilities within the Mastra framework. It imports necessary modules from `@ai-sdk/openai`, `@mastra/core/agent`, and `@mastra/voice-openai`. It configures an agent with instructions, model (gpt-4o), and OpenAI voice provider with default settings. The `instructions` variable, responsible for defining agent behavior, is omitted for brevity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-text.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\nconst instructions = `\nYou are an AI note assistant tasked with providing concise, structured summaries of their content... // omitted for brevity\n`;\n\nexport const noteTakerAgent = new Agent({\n  name: 'Note Taker Agent',\n  instructions: instructions,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(), // Add OpenAI voice provider with default configuration\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Instance (TypeScript)\nDESCRIPTION: Sets up the main Mastra instance with the stock agent, allowing it to be used in the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nimport { stockAgent } from \"./agents/stockAgent\";\n\nexport const mastra = new Mastra({\n  agents: { stockAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Results with Typed Access: TypeScript\nDESCRIPTION: This snippet explains how to get typed access to the results of a workflow, employing step type parameters in the Workflow definition for accurate result handling based on step statuses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  outputSchema: z.object({\n    orderId: z.string(),\n    status: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const userData = context.getStepResult(fetchUserStep);\n    return {\n      orderId: \"order123\",\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow<[typeof fetchUserStep, typeof processOrderStep]>({\n  name: \"typed-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\n// The result is a discriminated union of the step results\n// So it needs to be narrowed down via status checks\nif (result.results.processOrder.status === 'success') {\n  // TypeScript will know the shape of the results\n  const orderId = result.results.processOrder.output.orderId;\n  console.log({orderId});\n}\n\nif (result.results.fetchUser.status === 'success') {\n  const userId = result.results.fetchUser.output.userId;\n  console.log({userId});\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Semantic Recall Parameters\nDESCRIPTION: This code snippet shows how to configure the `topK` and `messageRange` parameters for semantic recall within the Memory options.  `topK` controls the number of semantically similar messages to retrieve, and `messageRange` specifies how much surrounding context (messages before and after each match) to include.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  memory: new Memory({\n    options: {\n      semanticRecall: {\n        topK: 3, // Retrieve 3 most similar messages\n        messageRange: 2, // Include 2 messages before and after each match\n      },\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Content Quality in Mastra Workflow - TypeScript\nDESCRIPTION: This snippet adds a step responsible for evaluating the quality of the generated content based on tone and completeness scores. It retrieves the model output from a previous step and applies evaluation logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Evaluate the content quality\nconst evaluateTone = new Step({\n  id: 'evaluateToneConsistency',\n  execute: async ({ context }) => {\n    const content = context.getStepResult(promptAgent)?.modelOutput;\n\n    // Simulate evaluation\n    return {\n      toneScore: { score: calculateToneScore(content) },\n      completenessScore: { score: calculateCompletenessScore(content) },\n    };\n  },\n  outputSchema: z.object({\n    toneScore: z.any(),\n    completenessScore: z.any(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Using Toolsets with generate() or stream()\nDESCRIPTION: Shows how to use the `getToolsets()` method to dynamically provide tool implementations to the `generate` or `stream` methods of an Agent. The tool names are namespaced by server name to prevent conflicts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst res = await agent.stream(prompt, {\n  toolsets: await mcp.getToolsets(),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Bird Image Classification using Mastra AI and Unsplash API\nDESCRIPTION: A complete implementation that combines Unsplash API integration for random image fetching with a Mastra AI Agent for bird classification. The code includes type definitions, image fetching logic, and AI agent setup using Anthropic's Claude model. It outputs whether an image contains a bird, its species, and location information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/bird-checker.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { z } from \"zod\";\n\nexport type Image = {\n  alt_description: string;\n  urls: {\n    regular: string;\n    raw: string;\n  };\n  user: {\n    first_name: string;\n    links: {\n      html: string;\n    };\n  };\n};\n\nexport type ImageResponse<T, K> =\n  | {\n      ok: true;\n      data: T;\n    }\n  | {\n      ok: false;\n      error: K;\n    };\n\nconst getRandomImage = async ({\n  query,\n}: {\n  query: string;\n}): Promise<ImageResponse<Image, string>> => {\n  const page = Math.floor(Math.random() * 20);\n  const order_by = Math.random() < 0.5 ? \"relevant\" : \"latest\";\n  try {\n    const res = await fetch(\n      `https://api.unsplash.com/search/photos?query=${query}&page=${page}&order_by=${order_by}`,\n      {\n        method: \"GET\",\n        headers: {\n          Authorization: `Client-ID ${process.env.UNSPLASH_ACCESS_KEY}`,\n          \"Accept-Version\": \"v1\",\n        },\n        cache: \"no-store\",\n      },\n    );\n\n    if (!res.ok) {\n      return {\n        ok: false,\n        error: \"Failed to fetch image\",\n      };\n    }\n\n    const data = (await res.json()) as {\n      results: Array<Image>;\n    };\n    const randomNo = Math.floor(Math.random() * data.results.length);\n\n    return {\n      ok: true,\n      data: data.results[randomNo] as Image,\n    };\n  } catch (err) {\n    return {\n      ok: false,\n      error: \"Error fetching image\",\n    };\n  }\n};\n\nconst instructions = `\n  You can view an image and figure out if it is a bird or not. \n  You can also figure out the species of the bird and where the picture was taken.\n`;\n\nexport const birdCheckerAgent = new Agent({\n  name: \"Bird checker\",\n  instructions,\n  model: anthropic(\"claude-3-haiku-20240307\"),\n});\n\nconst queries: string[] = [\"wildlife\", \"feathers\", \"flying\", \"birds\"];\nconst randomQuery = queries[Math.floor(Math.random() * queries.length)];\n\n// Get the image url from Unsplash with random type\nconst imageResponse = await getRandomImage({ query: randomQuery });\n\nif (!imageResponse.ok) {\n  console.log(\"Error fetching image\", imageResponse.error);\n  process.exit(1);\n}\n\nconsole.log(\"Image URL: \", imageResponse.data.urls.regular);\nconst response = await birdCheckerAgent.generate(\n  [\n    {\n      role: \"user\",\n      content: [\n        {\n          type: \"image\",\n          image: new URL(imageResponse.data.urls.regular),\n        },\n        {\n          type: \"text\",\n          text: \"view this image and let me know if it's a bird or not, and the scientific name of the bird without any explanation. Also summarize the location for this picture in one or two short sentences understandable by a high school student\",\n        },\n      ],\n    },\n  ],\n  {\n    output: z.object({\n      bird: z.boolean(),\n      species: z.string(),\n      location: z.string(),\n    }),\n  },\n);\n\nconsole.log(response.object);\n```\n\n----------------------------------------\n\nTITLE: Using Mastra with Pinecone for Top-K Similarity Search\nDESCRIPTION: Demonstrates the complete workflow of processing text documents, generating embeddings, storing them in Pinecone, and performing similarity searches. The code shows initialization of document processing, chunking, embedding generation using OpenAI, Pinecone index creation, vector storage, and retrieval of top-K similar results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/retrieve-results.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PineconeVector } from \"@mastra/pinecone\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst pinecone = new PineconeVector(\"your-api-key\");\n\nawait pinecone.createIndex({\n  indexName: \"test_index\",\n  dimension: 1536,\n});\n\nawait pinecone.upsert({\n  indexName: \"test_index\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n\nconst topK = 10;\n\nconst results = await pinecone.query({\n  indexName: \"test_index\",\n  queryVector: embeddings[0],\n  topK,\n});\n\nconsole.log(results);\n```\n\n----------------------------------------\n\nTITLE: Using Memory-Enabled Agent for Conversations in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the memory-enabled agent for conversations. It includes examples of starting a conversation, asking about ingredients, and using memory to recall previous conversations with both recent history and semantic search capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-upstash.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Ask about ingredients\nconst response1 = await chefAgent.stream(\n  \"In my kitchen I have: pasta, canned tomatoes, garlic, olive oil, and some dried herbs (basil and oregano). What can I make?\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Ask about different ingredients\nconst response2 = await chefAgent.stream(\n  \"Now I'm over at my friend's house, and they have: chicken thighs, coconut milk, sweet potatoes, and curry powder.\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Use memory to recall previous conversation\nconst response3 = await chefAgent.stream(\n  \"What did we cook before I went to my friends house?\",\n  {\n    threadId,\n    resourceId,\n    memoryOptions: {\n      lastMessages: 3, // Get last 3 messages for context\n      semanticRecall: {\n        topK: 2, // Also get 2 most relevant messages\n        messageRange: 2, // Include context around matches\n      },\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using OpenAI Realtime Voice in TypeScript\nDESCRIPTION: This code demonstrates how to initialize and use the OpenAIRealtimeVoice class, including connection setup, event handling, text-to-speech conversion, audio input processing, and proper disconnection. It shows both default initialization and configuration with specific parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/openai-realtime.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\n// Initialize with default configuration using environment variables\nconst voice = new OpenAIRealtimeVoice();\n\n// Or initialize with specific configuration\nconst voiceWithConfig = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: 'your-openai-api-key',\n    model: 'gpt-4o-mini-realtime-preview-2024-12-17',\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: 'server_vad',\n          threshold: 0.6,\n          silence_duration_ms: 1200\n        }\n      }\n    }\n  },\n  speaker: 'alloy'  // Default voice\n});\n\n// Establish connection\nawait voice.connect();\n\n// Set up event listeners\nvoice.on('speaker', ({ audio }) => {\n  // Handle audio data (Int16Array) pcm format by default\n  playAudio(audio);\n});\n\nvoice.on('writing', ({ text, role }) => {\n  // Handle transcribed text\n  console.log(`${role}: ${text}`);\n});\n\n// Convert text to speech\nawait voice.speak('Hello, how can I help you today?', {\n  speaker: 'echo'  // Override default voice\n});\n\n// Process audio input\nconst microphoneStream = getMicrophoneStream();\nawait voice.send(microphoneStream);\n\n// When done, disconnect\nvoice.connect();\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra for Laminar Telemetry (TypeScript)\nDESCRIPTION: This TypeScript code snippet demonstrates how to configure Mastra to export telemetry data to Laminar via OTLP.  It initializes a new Mastra instance and sets the `telemetry` configuration, specifying the service name, enabling telemetry, and setting the export type to `otlp` with `grpc` protocol.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/laminar.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n      protocol: \"grpc\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with stdio and SSE servers\nDESCRIPTION: This TypeScript code demonstrates how to configure the MCPConfiguration class with both stdio-based and SSE-based servers. It defines two server configurations: one using the sequential-thinking server via stdio and another using a weather server accessed via SSE.  The `requestInit` allows for custom headers, such as authorization tokens.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst mcp = new MCPConfiguration({\n  servers: {\n    // stdio example\n    sequential: {\n      name: \"sequential-thinking\",\n      server: {\n        command: \"npx\",\n        args: [\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"],\n      },\n    },\n    // SSE example\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),\n      requestInit: {\n        headers: {\n          Authorization: \"Bearer your-token\",\n        },\n      },\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Add Weather Tool to a Mastra Agent\nDESCRIPTION: This code snippet shows how to add the `weatherInfo` tool to a Mastra agent. It imports the `Agent` class from `@mastra/core/agent` and the `openai` function from `@ai-sdk/openai`. The agent is configured with a name, instructions, a model (GPT-4o-mini in this case), and the `weatherInfo` tool. This agent is designed to answer weather-related questions using the specified tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport * as tools from \"../tools/weatherInfo\";\n\nexport const weatherAgent = new Agent<typeof tools>({\n  name: \"Weather Agent\",\n  instructions:\n    \"You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    weatherInfo: tools.weatherInfo,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenAI Text-to-Speech\nDESCRIPTION: Complete implementation of text-to-speech functionality using OpenAI voice provider. Shows how to generate and play audio from text responses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n  responseFormat: \"wav\", // Optional: specify a response format\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Evaluating mixed context precision with ContextPrecisionMetric\nDESCRIPTION: This TypeScript snippet demonstrates how to evaluate a response that uses some, but not all, of the relevant context information. It initializes the ContextPrecisionMetric with a context array and the OpenAI model, then measures the precision of a response against a query. The output includes the precision score and the reason for the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-precision.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  '火山は地球の地殻の開口部です。',\n  '火山は活動中、休止中、または死火山のいずれかです。',\n  'ハワイには多くの活火山があります。',\n  '太平洋の火のリングには多くの火山があります。',\n];\n\nconst metric2 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = '火山の異なるタイプは何ですか？';\nconst response2 = '火山はその活動状態に基づいて、活動中、休止中、または死火山に分類されます。';\n\nconsole.log('例 2 - 混合精度:');\nconsole.log('コンテキスト:', context2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.5, reason: 'コンテキストは一部の関連情報を使用し、一部の無関係な情報を含んでいます。' }\n```\n\n----------------------------------------\n\nTITLE: Checking Previous Step Results in Mastra (TypeScript)\nDESCRIPTION: This code shows how to check the results of previous steps in a Mastra workflow to make decisions in subsequent steps. It accesses the status of `step1` and `step2` from the workflow context and returns different results based on their success or failure. This allows for creating workflows that adapt based on the outcome of previous operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst finalStep = new Step({\n  id: 'finalStep',\n  execute: async ({ context }) => {\n    // Check results of previous steps\n    const step1Success = context.steps.step1?.status === 'success';\n    const step2Success = context.steps.step2?.status === 'success';\n\n    if (step1Success && step2Success) {\n      // All steps succeeded\n      return { status: 'complete', result: 'All operations succeeded' };\n    } else if (step1Success) {\n      // Only step1 succeeded\n      return { status: 'partial', result: 'Partial completion' };\n    } else {\n      // Critical failure\n      return { status: 'failed', result: 'Critical steps failed' };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: If-Else Branching with Nested Workflows in TypeScript\nDESCRIPTION: Illustrates conditional workflow execution using if-else branching with nested workflows, including condition evaluation and branch merging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Create nested workflows for different paths\nconst workflowA = new Workflow({ name: \"workflow-a\" })\n  .step(stepA1)\n  .then(stepA2)\n  .commit();\n\nconst workflowB = new Workflow({ name: \"workflow-b\" })\n  .step(stepB1)\n  .then(stepB2)\n  .commit();\n\n// Use the new if-else syntax with nested workflows\nparentWorkflow\n  .step(initialStep)\n  .if(\n    async ({ context }) => {\n      // Your condition here\n      return someCondition;\n    },\n    workflowA, // if branch\n    workflowB, // else branch\n  )\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Building and Running the Content Moderation Workflow with TypeScript and Mastra\nDESCRIPTION: This snippet constructs the overall content moderation workflow by chaining the defined steps together and registering the workflow with Mastra. It includes a demonstration function that runs the workflow, manages human input for moderation decisions using Inquirer prompts, and resumes the workflow based on moderator feedback.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Build the workflow\nconst contentModerationWorkflow = new Workflow({\n  name: 'content-moderation-workflow',\n  triggerSchema: z.object({\n    content: z.string(),\n  }),\n});\n\ncontentModerationWorkflow\n  .step(analyzeContent)\n  .then(moderateContent)\n  .then(applyModeration)\n  .commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { contentModerationWorkflow },\n});\n\n// Example of using the workflow with Inquirer prompts\nasync function runModerationDemo() {\n  const registeredWorkflow = mastra.getWorkflow('contentModerationWorkflow');\n  const run = registeredWorkflow.createRun();\n\n  // Start the workflow with content that needs review\n  console.log('Starting content moderation workflow...');\n  const result = await run.start({\n    triggerData: {\n      content: 'This is some user-generated content that requires moderation.'\n    }\n  });\n\n  const isReviewStepSuspended = result.activePaths.get('moderateContent')?.status === 'suspended';\n\n  // Check if workflow is suspended\n  if (isReviewStepSuspended) {\n    const { content, aiScore, flaggedCategories, message } = result.activePaths.get('moderateContent')?.suspendPayload;\n\n    console.log('\\n===================================');\n    console.log(message);\n    console.log('===================================\\n');\n\n    console.log('Content to review:');\n    console.log(content);\n    console.log(`\\nAI Analysis Score: ${aiScore}`);\n    console.log(`Flagged Categories: ${flaggedCategories?.join(', ') || 'None'}\\n`);\n\n    // Collect moderator decision using Inquirer\n    const moderatorDecision = await select({\n      message: 'Select your moderation decision:',\n      choices: [\n        { name: 'Approve content as is', value: 'approve' },\n        { name: 'Reject content completely', value: 'reject' },\n        { name: 'Modify content before publishing', value: 'modify' }\n      ],\n    });\n\n    // Collect additional information based on decision\n    let moderatorNotes = '';\n    let modifiedContent = '';\n\n    moderatorNotes = await input({\n      message: 'Enter any notes about your decision:',\n    });\n\n    if (moderatorDecision === 'modify') {\n      modifiedContent = await input({\n        message: 'Enter the modified content:',\n        default: content,\n      });\n    }\n\n    console.log('\\nSubmitting your moderation decision...');\n\n    // Resume the workflow with the moderator's input\n    const resumeResult = await run.resume({\n      stepId: 'moderateContent',\n      context: {\n        moderatorDecision,\n        moderatorNotes,\n        modifiedContent,\n      },\n    });\n\n    if (resumeResult?.results?.applyModeration?.status === 'success') {\n      console.log('\\n===================================');\n      console.log(`Moderation complete: ${resumeResult?.results?.applyModeration?.output.finalStatus}`);\n      console.log('===================================\\n');\n\n      if (resumeResult?.results?.applyModeration?.output.content) {\n        console.log('Published content:');\n        console.log(resumeResult.results.applyModeration.output.content);\n      }\n    }\n\n    return resumeResult;\n  }\n\n  console.log('Workflow completed without requiring human intervention:', result.results);\n  return result;\n}\n\n// Helper function for AI content analysis simulation\nfunction simulateContentAnalysis(content: string): number {\n  // In a real application, this would call an AI service\n  // For the example, we're returning a random score\n  return Math.random();\n}\n\n// Invoke the demo function\nrunModerationDemo().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings\nDESCRIPTION: Generates embeddings for text chunks and stores them in the vector database with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector('pgVector');\n\nawait vectorStore.createIndex({\n  indexName: 'papers',\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: 'papers',\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({\n    text: chunk.text,\n    source: 'transformer-paper'\n  })),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Agent\nDESCRIPTION: This snippet configures a Mastra agent for chain-of-thought prompting. It sets instructions for the agent to analyze the provided context, break down its thought process, explain how it connects different parts of the context, and draw conclusions based on the evidence. The agent uses the `gpt-4o-mini` model and the vector query tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `あなたは、提供されたコンテキストに基づいて質問に答える役立つアシスタントです。\n各応答のために次のステップに従ってください：\n\n1. まず、取得したコンテキストチャンクを注意深く分析し、重要な情報を特定します。\n2. 取得した情報がクエリにどのように関連しているかについての思考プロセスを分解します。\n3. 取得したチャンクから異なる部分をどのように結びつけているかを説明します。\n4. 取得したコンテキストの証拠に基づいてのみ結論を導きます。\n5. 取得したチャンクに十分な情報が含まれていない場合は、何が欠けているかを明示的に述べてください。\n\n応答を次のようにフォーマットします：\n思考プロセス：\n- ステップ1：[取得したチャンクの初期分析]\n- ステップ2：[チャンク間の接続]\n- ステップ3：[チャンクに基づく推論]\n\n最終回答：\n[取得したコンテキストに基づく簡潔な回答]\n\n重要：質問に答えるよう求められた場合、ツールで提供されたコンテキストのみに基づいて回答してください。\nコンテキストに質問に完全に答えるための十分な情報が含まれていない場合は、それを明示的に述べてください。\n覚えておいてください：取得した情報をどのように使用して結論に達しているかを説明してください。\n`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Agent (Basic)\nDESCRIPTION: This snippet demonstrates the basic initialization of the `Memory` class and its integration with an `Agent` instance. It shows how to create a new `Memory` object and pass it as a configuration option to the `Agent` constructor. `otherOptions` would contain other configuration parameters for the Agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  memory: new Memory(),\n  ...otherOptions,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector and Mastra Instance\nDESCRIPTION: Initialization of PgVector storage and Mastra instance with configured components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\n\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for RAG Implementation\nDESCRIPTION: Imports necessary packages and modules for the RAG system including Mastra core, OpenAI, and vector storage components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { createVectorQueryTool, MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Astra DB with Mastra\nDESCRIPTION: This code demonstrates how to use the `AstraVector` class from `@mastra/astra` to create a collection and insert embeddings into DataStax Astra DB. It uses `openai` for generating embeddings, `MDocument` for chunking text, and environment variables for Astra DB token, endpoint, and keyspace. The example shows how to create a collection and upsert vector embeddings along with associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { AstraVector } from '@mastra/astra';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst astra = new AstraVector({\n  token: process.env.ASTRA_DB_TOKEN,\n  endpoint: process.env.ASTRA_DB_ENDPOINT,\n  keyspace: process.env.ASTRA_DB_KEYSPACE,\n});\n\nawait astra.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait astra.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Steps with Input and Output Schemas (TypeScript)\nDESCRIPTION: This code snippet defines two steps in a Mastra workflow using the `Step` class. Each step includes an `id` and an `execute` function. The `stepOne` function takes an input value, doubles it, and returns the result. The `stepTwo` function retrieves the result from `stepOne`, increments it, and returns the incremented value. Output schemas are defined for validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepOne = new Step({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context.triggerData.inputValue * 2;\n    return { doubledValue };\n  },\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    const doubledValue = context.getStepResult(stepOne)?.doubledValue;\n    if (!doubledValue) {\n      return { incrementedValue: 0 };\n    }\n    return {\n      incrementedValue: doubledValue + 1,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Using a Nested Workflow in Mastra (TypeScript)\nDESCRIPTION: Demonstrates how to create a nested workflow and then use it as a step within a parent workflow.  The nested workflow can be passed variables from the parent. The nested workflow's name serves as the step ID in the parent workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// ネストされたワークフローを作成\nconst nestedWorkflow = new Workflow({ name: \"nested-workflow\" })\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// 親ワークフローでネストされたワークフローを使用\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"myTriggerInput\",\n      },\n    },\n  })\n  .then(stepC)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Creating a Workflow in Mastra (TypeScript)\nDESCRIPTION: This snippet demonstrates how to create a workflow in Mastra, defining its name and trigger schema using Zod for validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Agent Initialization with AI SDK Model\nDESCRIPTION: This snippet demonstrates how to initialize a Mastra agent using a model from the Vercel AI SDK. It imports the `openai` function from `@ai-sdk/openai` and uses it to specify the model for the agent. The agent is then configured with a name, instructions, and the chosen AI SDK model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"Instructions for the agent...\",\n  model: openai(\"gpt-4-turbo\"), // Model comes directly from AI SDK\n});\n\nconst result = await agent.generate(\"What is the weather like?\");\n```\n\n----------------------------------------\n\nTITLE: Define Human Review Step with Suspend Function in Mastra\nDESCRIPTION: This snippet showcases a Mastra step, `reviewRecommendations`, designed to pause workflow execution and solicit human input using the `suspend` function. It takes product recommendations from the previous step, presents them to a human reviewer, and gathers their approval, a custom note, and a discount offer preference. The step uses `zod` for input/output schema validation and resumes based on human provided inputs, continuing the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Get human approval and customization for the recommendations\nconst reviewRecommendations = new Step({\n  id: 'reviewRecommendations',\n  inputSchema: z.object({\n    approvedProducts: z.array(z.string()),\n    customerNote: z.string().optional(),\n    offerDiscount: z.boolean().optional(),\n  }),\n  outputSchema: z.object({\n    finalRecommendations: z.array(\n      z.object({\n        productId: z.string(),\n        productName: z.string(),\n        price: z.number(),\n      }),\n    ),\n    customerNote: z.string().optional(),\n    offerDiscount: z.boolean(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const { customerName, recommendations } = context.getStepResult(generateRecommendations) || {\n      customerName: '',\n      recommendations: [],\n    };\n\n    // Check if we have input from a resumed workflow\n    const reviewInput = {\n      approvedProducts: context.inputData?.approvedProducts || [],\n      customerNote: context.inputData?.customerNote,\n      offerDiscount: context.inputData?.offerDiscount,\n    };\n\n    // If we don't have agent input yet, suspend for human review\n    if (!reviewInput.approvedProducts.length) {\n      console.log(`Generating recommendations for customer: ${customerName}`);\n      await suspend({\n        customerName,\n        recommendations,\n        message: 'Please review these product recommendations before sending to the customer',\n      });\n\n      // Placeholder return (won't be reached due to suspend)\n      return {\n        finalRecommendations: [],\n        customerNote: '',\n        offerDiscount: false,\n      };\n    }\n\n    // Process the agent's product selections\n    const finalRecommendations = recommendations\n      .filter(product => reviewInput.approvedProducts.includes(product.productId))\n      .map(product => ({\n        productId: product.productId,\n        productName: product.productName,\n        price: product.price,\n      }));\n\n    return {\n      finalRecommendations,\n      customerNote: reviewInput.customerNote || '',\n      offerDiscount: reviewInput.offerDiscount || false,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Step-Level Retry Configuration in Mastra\nDESCRIPTION: This code snippet demonstrates how to configure retry attempts on an individual step within a Mastra workflow, overriding the workflow-level configuration. It specifies the number of attempts and the delay for the particular step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-retries.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst fetchDataStep = new Step({\n  id: 'fetchData',\n  execute: async () => {\n    // Fetch data from external API\n  },\n  retryConfig: {\n    attempts: 5,    // This step will retry up to 5 times\n    delay: 2000,    // With a 2-second delay between retries\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Advanced Branching and Merging in Mastra\nDESCRIPTION: This snippet illustrates how to implement advanced branching and merging in a Mastra workflow using multiple branches and merge points.  It defines a `complexWorkflow` with three branches stemming from `stepOne`. Two branches merge at `partialMerge`, and the third branch merges at `finalMerge`. The code shows the creation of new `Step` instances directly within the workflow definition. The steps calculate results based on input and results of previous steps. The workflow utilizes .after() to control dependencies and merging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/branching-paths.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst complexWorkflow = new Workflow({\n  name: \"complex-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\n// Create multiple branches with different merge points\ncomplexWorkflow\n  // Main step\n  .step(stepOne)\n\n  // First branch\n  .then(stepTwo)\n\n  // Second branch\n  .after(stepOne)\n  .step(stepThree)\n  .then(stepFour)\n\n  // Third branch (another path from stepOne)\n  .after(stepOne)\n  .step(new Step({\n    id: \"alternativePath\",\n    execute: async ({ context }) => {\n      const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n      return {\n        result: (stepOneResult?.doubledValue || 0) * 3\n      }\n    }\n  }))\n\n  // Merge first and second branches\n  .after([stepTwo, stepFour])\n  .step(new Step({\n    id: \"partialMerge\",\n    execute: async ({ context }) => {\n      const stepTwoResult = context.getStepResult<{ isDivisibleByFive: boolean }>(\"stepTwo\");\n      const stepFourResult = context.getStepResult<{ isDivisibleByThree: boolean }>(\"stepFour\");\n\n      return {\n        intermediateResult: \"Processed first two branches\",\n        branchResults: {\n          branch1: stepTwoResult?.isDivisibleByFive,\n          branch2: stepFourResult?.isDivisibleByThree\n        }\n      }\n    }\n  }))\n\n  // Final merge of all branches\n  .after([\"partialMerge\", \"alternativePath\"])\n  .step(new Step({\n    id: \"finalMerge\",\n    execute: async ({ context }) => {\n      const partialMergeResult = context.getStepResult<{ intermediateResult: string, branchResults: { branch1: boolean, branch2: boolean } }>(\"partialMerge\");\n\n      const alternativePathResult = context.getStepResult<{ result: number }>(\"alternativePath\");\n\n      return {\n        finalResult: \"All branches processed\",\n        combinedData: {\n          fromPartialMerge: partialMergeResult?.branchResults,\n          fromAlternativePath: alternativePathResult?.result\n        }\n      }\n    }\n  }))\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Processing and Chunking Documents for RAG\nDESCRIPTION: Processes a document and chunks it into smaller pieces for embedding and storage in the vector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`The Impact of Climate Change on Global Agriculture...`);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLVector for Vector Search\nDESCRIPTION: This code snippet demonstrates how to use the LibSQLVector class to create an index, add vectors with metadata, and query similar vectors.  It showcases the core functionality of the LibSQLVector store including index creation, upserting data and querying the data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/libsql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\n// Create a new vector store instance\nconst store = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  // Optional: for Turso cloud databases\n  authToken: process.env.DATABASE_AUTH_TOKEN,\n});\n\n// Create an index\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\n\n// Add vectors with metadata\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [\n  { text: \"first document\", category: \"A\" },\n  { text: \"second document\", category: \"B\" }\n];\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors,\n  metadata,\n});\n\n// Query similar vectors\nconst queryVector = [0.1, 0.2, ...];\nconst results = await store.query({\n  indexName: \"myCollection\",\n  queryVector,\n  topK: 10, // top K results\n  filter: { category: \"A\" } // optional metadata filter\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing AI Agent Integration in Mastra Workflow\nDESCRIPTION: This code snippet shows how to create an AI agent, define a workflow with a custom step that uses the agent, and execute the workflow. It uses the Mastra framework along with OpenAI's GPT model for natural language processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/calling-agent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst penguin = new Agent({\n  name: \"agent skipper\",\n  instructions: `You are skipper from penguin of madagascar, reply as that`,\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst newWorkflow = new Workflow({\n  name: \"pass message to the workflow\",\n  triggerSchema: z.object({\n    message: z.string(),\n  }),\n});\n\nconst replyAsSkipper = new Step({\n  id: \"reply\",\n  outputSchema: z.object({\n    reply: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    const skipper = mastra?.getAgent('penguin');\n\n    const res = await skipper?.generate(\n      context?.triggerData?.message,\n    );\n    return { reply: res?.text || \"\" };\n  },\n});\n\nnewWorkflow.step(replyAsSkipper);\nnewWorkflow.commit();\n\nconst mastra = new Mastra({\n  agents: { penguin },\n  workflows: { newWorkflow },\n});\n\nconst { runId, start } = await mastra.getWorkflow(\"newWorkflow\").createRun();\n\nconst runResult = await start({\n  triggerData: { message: \"Give me a run down of the mission to save private\" },\n});\n\nconsole.log(runResult.results);\n```\n\n----------------------------------------\n\nTITLE: Single Voice Provider Setup with OpenAI in Mastra\nDESCRIPTION: This snippet demonstrates how to set up a Mastra agent with a single voice provider (OpenAI) for both speech-to-text (STT) and text-to-speech (TTS) capabilities. It initializes the `OpenAIVoice` provider, creates an agent instance, and showcases how to use the `speak` and `listen` methods for voice interaction. Dependencies include `@mastra/core/agent`, `@mastra/voice-openai`, `@ai-sdk/openai`, `fs`, and `path`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize the voice provider with default settings\nconst voice = new OpenAIVoice();\n\n// Create an agent with voice capabilities\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with both STT and TTS capabilities.`, // Corrected template literal\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\n// The agent can now use voice for interaction\nconst audioStream = await agent.voice.speak(\"Hello, I'm your AI assistant!\", {\n  filetype: \"m4a\",\n});\n\nplayAudio(audioStream!);\n\ntry {\n  const transcription = await agent.voice.listen(audioStream);\n  console.log(transcription)\n} catch (error) {\n  console.error(\"Error transcribing audio:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping Entire Objects in Mastra Workflow Variables\nDESCRIPTION: Illustrates how to map an entire object by using '.' as the path in Mastra workflow variable mapping.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(step1, {\n    variables: {\n      // Map the entire trigger data object\n      triggerData: { step: 'trigger', path: '.' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow with resumeWithEvent (TypeScript)\nDESCRIPTION: This snippet demonstrates how to resume a suspended Mastra workflow using the `resumeWithEvent` method. The method takes the event name and the event data as parameters. The data is validated against the event's schema, and then the workflow continues execution from the step where it was suspended. The `run.start()` method initializes the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a workflow run\nconst run = workflow.createRun();\n\n// Start the workflow\nawait run.start({ triggerData: { requestId: 'req-123' } });\n\n// Later, when the event occurs:\nconst result = await run.resumeWithEvent('approvalReceived', {\n  approved: true,\n  approverName: 'John Doe',\n  comment: 'Looks good to me!'\n});\n\nconsole.log(result.results);\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using ElevenLabsVoice in TypeScript\nDESCRIPTION: Demonstrates how to initialize the ElevenLabsVoice with both default and custom configurations, perform text-to-speech conversion, and retrieve available speakers. The example includes importing the module, creating instances with different configurations, and basic usage of core methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/elevenlabs.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\n\n// Initialize with default configuration (uses ELEVENLABS_API_KEY environment variable)\nconst voice = new ElevenLabsVoice();\n\n// Initialize with custom configuration\nconst voice = new ElevenLabsVoice({\n  speechModel: {\n    name: 'eleven_multilingual_v2',\n    apiKey: 'your-api-key',\n  },\n  speaker: 'custom-speaker-id',\n});\n\n// Text-to-Speech\nconst audioStream = await voice.speak(\"Hello, world!\");\n\n// Get available speakers\nconst speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Initializing and Connecting to OpenAI Real-time Voice in TypeScript\nDESCRIPTION: This code snippet demonstrates how to import and initialize the OpenAIRealtimeVoice provider, configure a speaker for audio output, connect to the service, and set up an event listener for the audio stream. It also shows how to use connection options like timeout and reconnect.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.connect.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: \"server_vad\",\n          threshold: 0.6,\n          silence_duration_ms: 1200,\n        },\n      },\n    },\n  },\n  speaker: \"alloy\", // Default voice\n});\n// Connect to the real-time service\nawait voice.connect();\n// Now you can use real-time features\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker);\n});\n// With connection options\nawait voice.connect({\n  timeout: 10000, // 10 seconds timeout\n  reconnect: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with Fixed MCP Tools\nDESCRIPTION: This TypeScript code snippet shows how to initialize an Agent with a fixed set of tools obtained from the MCPConfiguration. The `getTools()` method retrieves the tools, which are then passed to the Agent constructor. This approach is suitable when tool configurations remain constant and are not user-specific.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  name: \"CLI Assistant\",\n  instructions: \"You help users with CLI tasks\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: await mcp.getTools(), // Tools are fixed at agent creation\n});\n```\n\n----------------------------------------\n\nTITLE: Embedding Text Chunks with OpenAI and Mastra in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a document from text, chunk it, and then generate embeddings for the chunks using OpenAI's embedding model. It utilizes the Mastra library for document handling and the OpenAI SDK for embedding generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-chunk-array.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { MDocument } from '@mastra/rag';\nimport { embed } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Clickhouse Store and Creating an Instance\nDESCRIPTION: This snippet demonstrates how to import the ClickhouseStore from the package and create a new instance with the required parameters for connecting to a Clickhouse server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ClickhouseStore } from '@mastra/clickhouse';\n\nconst store = new ClickhouseStore({\n  url: 'http://localhost:8123',\n  username: 'default',\n  password: 'password',\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using OpenAIVoice with TypeScript\nDESCRIPTION: This example demonstrates how to import, initialize, and use the OpenAIVoice class for both text-to-speech and speech-to-text operations. It shows default initialization using environment variables as well as custom configuration with specific API keys and models.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/openai.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\n// Initialize with default configuration using environment variables\nconst voice = new OpenAIVoice();\n\n// Or initialize with specific configuration\nconst voiceWithConfig = new OpenAIVoice({\n  speechModel: {\n    name: 'tts-1-hd',\n    apiKey: 'your-openai-api-key'\n  },\n  listeningModel: {\n    name: 'whisper-1',\n    apiKey: 'your-openai-api-key'\n  },\n  speaker: 'alloy'  // Default voice\n});\n\n// Convert text to speech\nconst audioStream = await voice.speak('Hello, how can I help you?', {\n  speaker: 'nova',  // Override default voice\n  speed: 1.2  // Adjust speech speed\n});\n\n// Convert speech to text\nconst text = await voice.listen(audioStream, {\n  filetype: 'mp3'\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Steps with Type-Safe Outputs: TypeScript\nDESCRIPTION: This snippet defines two workflow steps with type-safe outputs, allowing better handling of results from previous steps. The fetchUserStep retrieves user data while analyzeDataStep utilizes the retrieved data safely, ensuring type compatibility via TypeScript.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new Step({\n  id: 'fetchUser',\n  outputSchema: z.object({\n    name: z.string(),\n    userId: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return { name: 'John Doe', userId: '123' };\n  },\n});\n\nconst analyzeDataStep = new Step({\n  id: \"analyzeData\",\n  execute: async ({ context }) => {\n    // Type-safe access to previous step result\n    const userData = context.getStepResult<{ name: string, userId: string }>(\"fetchUser\");\n\n    if (!userData) {\n      return { status: \"error\", message: \"User data not found\" };\n    }\n\n    return {\n      analysis: `Analyzed data for user ${userData.name}`,\n      userId: userData.userId\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Starting and Resuming Workflow TypeScript\nDESCRIPTION: Illustrates how to start and resume a workflow with suspended steps.  It retrieves the workflow, creates a run, starts the workflow with initial data, checks if a step is suspended, and resumes it with new context data. It shows how to access results and handle multiple suspension points using `run.resume()` with appropriate `stepId` and `context`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Get the workflow and create a run\nconst wf = mastra.getWorkflow(\"multi-suspend-workflow\");\nconst run = wf.createRun();\n\n// Start the workflow\nconst initialResult = await run.start({\n  triggerData: { input: \"initial input\" },\n});\n\nlet promptAgentStepResult = initialResult.activePaths.get(\"promptAgent\");\nlet promptAgentResumeResult = undefined;\n\n// Check if a step is suspended\nif (promptAgentStepResult?.status === \"suspended\") {\n  console.log(\"Workflow suspended at promptAgent step\");\n\n  // Resume the workflow with new context\n  const resumeResult = await run.resume({\n    stepId: \"promptAgent\",\n    context: { userInput: \"Human provided input\" },\n  });\n\n  promptAgentResumeResult = resumeResult;\n}\n\nconst improveResponseStepResult =\n  promptAgentResumeResult?.activePaths.get(\"improveResponse\");\n\nif (improveResponseStepResult?.status === \"suspended\") {\n  console.log(\"Workflow suspended at improveResponse step\");\n\n  // Resume again with different context\n  const finalResult = await run.resume({\n    stepId: \"improveResponse\",\n    context: { refinedOutput: \"Human refined output\" },\n  });\n\n  console.log(\"Workflow completed:\", finalResult?.results);\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Response with Complete Hallucination in Mastra\nDESCRIPTION: This example demonstrates evaluating a response that completely contradicts the facts in the context, resulting in a maximum hallucination score of 1. It sets up context about the Wright brothers, configures the HallucinationMetric, and measures a response containing entirely contradictory information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/hallucination.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'The Wright brothers made their first flight in 1903.',\n  'The flight lasted 12 seconds.',\n  'It covered a distance of 120 feet.',\n];\n\nconst metric3 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'When did the Wright brothers first fly?';\nconst response3 = 'The Wright brothers achieved their historic first flight in 1908. The flight lasted about 2 minutes and covered nearly a mile.';\n\nconsole.log('Example 3 - Complete Hallucination:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response completely contradicts the context.' }\n```\n\n----------------------------------------\n\nTITLE: Example with Reranking in Vector Query Tool\nDESCRIPTION: This snippet configures a vector query tool with reranking enabled. Using a reranker model, results are refined based on semantic relevance, vector similarity, and other parameters to optimize result ordering for user queries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"milvus\",\n  indexName: \"documentation\",\n  model: openai.embedding('text-embedding-3-small'),\n  reranker: {\n    model: openai('gpt-4o-mini'),\n    options: {\n      weights: {\n        semantic: 0.5,  // Semantic relevance weight\n        vector: 0.3,    // Vector similarity weight\n        position: 0.2   // Original position weight\n      },\n      topK: 5\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAG Tool with Custom Graph Options (TypeScript)\nDESCRIPTION: This code shows how to initialize `createGraphRAGTool` with custom `graphOptions`. This allows fine-tuning of the graph-based search behavior by adjusting parameters like the similarity threshold, random walk steps, and restart probability, adapting it to the specific data and retrieval needs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/graph-rag-tool.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.8,        // より高い類似性のしきい値\n    randomWalkSteps: 200,  // より多くの探索ステップ\n    restartProb: 0.2      // より高い再開確率\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Waiting for Multiple Events (TypeScript)\nDESCRIPTION: This snippet shows a Mastra workflow configured to wait for multiple events at different points in its execution. The workflow first waits for `approvalReceived` and then for `documentUploaded`. This demonstrates the ability to orchestrate asynchronous processes that rely on external events.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(createRequest)\n  .afterEvent('approvalReceived')\n  .step(processApproval)\n  .afterEvent('documentUploaded')\n  .step(processDocument)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of KeywordCoverageMetric in TypeScript\nDESCRIPTION: This snippet demonstrates the basic usage of the `KeywordCoverageMetric` class to measure the keyword coverage between an input text and an output text. It initializes the metric, calls the `measure` method, and logs the resulting score and info object. The `measure` method takes two string arguments: the input text containing the keywords and the output text to be evaluated for keyword coverage.  It returns a score between 0 and 1, along with detailed metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/keyword-coverage.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new KeywordCoverageMetric();\n\nconst result = await metric.measure(\n  \"What are the key features of Python programming language?\",\n  \"Python is a high-level programming language known for its simple syntax and extensive libraries.\"\n);\n\nconsole.log(result.score); // 0～1のカバレッジスコア\nconsole.log(result.info); // キーワードカバレッジに関する詳細な指標を含むオブジェクト\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings\nDESCRIPTION: Generates embeddings for the document chunks using OpenAI's text embedding model and stores them along with the associated metadata in PGVector.  The `embedMany` function creates the embeddings, and the `vectorStore.upsert` operation stores both embeddings and metadata, allowing combined semantic search and metadata filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector('pgVector');\nawait vectorStore.createIndex({\n  indexName: 'embeddings',\n  dimension: 1536,\n});\n\n// Store both embeddings and metadata together\nawait vectorStore.upsert({\n  indexName: 'embeddings',\n  vectors: embeddings,\n  metadata: chunkMetadata,\n});\n```\n\n----------------------------------------\n\nTITLE: Start Workflow Run Asynchronously using TypeScript\nDESCRIPTION: This snippet shows how to start a workflow run asynchronously and retrieve the full run results.  It uses `workflow.createRun()` to create a new run, passing the returned `runId` and trigger data to the `workflow.startAsync()` method, which returns a promise that resolves with the run results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst {runId} = workflow.createRun()\n\nconst result = await workflow.startAsync({\n  runId,\n  triggerData: {\n    param1: \"value1\",\n    param2: \"value2\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring HallucinationMetric for Evaluation - TypeScript\nDESCRIPTION: This snippet demonstrates how to import necessary modules, configure the HallucinationMetric with a specific language model and context, and measure the hallucination score based on an LLM output. It highlights the steps to set up the metric, provide input and output, and log the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/hallucination.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { HallucinationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new HallucinationMetric(model, {\n  context: [\n    \"Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning in San Carlos, California.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"Tell me about Tesla's founding.\",\n  \"Tesla was founded in 2004 by Elon Musk in California.\",\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n\n// Example output:\n// {\n//   score: 0.67,\n//   info: {\n//     reason: \"The score is 0.67 because two out of three statements from the context\n//           (founding year and founders) were contradicted by the output, while the\n//           location statement was not contradicted.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating Gluten Evaluation Prompt for Recipe Analysis\nDESCRIPTION: Generates a structured evaluation prompt that checks recipes for gluten content. The prompt provides examples and a response format, instructing the LLM to check for common gluten sources like wheat, barley, and rye.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nexport const generateGlutenPrompt = ({ output }: { output: string }) => `Check if this recipe is gluten-free.\\n\\nCheck for:\\n- Wheat\\n- Barley\\n- Rye\\n- Common sources like flour, pasta, bread\\n\\nExample with gluten:\\n\"Mix flour and water to make dough\"\\nResponse: {\\n  \"isGlutenFree\": false,\\n  \"glutenSources\": [\"flour\"]\\n}\\n\\nExample gluten-free:\\n\"Mix rice, beans, and vegetables\"\\nResponse: {\\n  \"isGlutenFree\": true,\\n  \"glutenSources\": []\\n}\\n\\nRecipe to analyze:\\n${output}\\n\\nReturn your response in this format:\\n{\\n  \"isGlutenFree\": boolean,\\n  \"glutenSources\": [\"list ingredients containing gluten\"]\\n}`;\n```\n\n----------------------------------------\n\nTITLE: Generating Responses with Agent Network - TypeScript\nDESCRIPTION: The generate() method generates a response using the agent network based on given messages and optional arguments. It has replaced a deprecated method to enhance consistency within the codebase.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync generate(\n  messages: string | string[] | CoreMessage[],\n  args?: AgentGenerateOptions\n): Promise<GenerateTextResult>\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory and Agent with Upstash in TypeScript\nDESCRIPTION: This snippet demonstrates how to set up the memory system with Upstash storage and vector capabilities, and create an agent with memory integration. It includes configuration for storage, vector search, and memory options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-upstash.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { UpstashStore, UpstashVector } from \"@mastra/upstash\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize memory with Upstash storage and vector search\nconst memory = new Memory({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_REDIS_REST_URL,\n    token: process.env.UPSTASH_REDIS_REST_TOKEN,\n  }),\n  vector: new UpstashVector({\n    url: process.env.UPSTASH_REDIS_REST_URL,\n    token: process.env.UPSTASH_REDIS_REST_TOKEN,\n  }),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\n// Create an agent with memory capabilities\nconst chefAgent = new Agent({\n  name: \"chefAgent\",\n  instructions:\n    \"You are Michel, a practical and experienced home chef who helps people cook great meals with whatever ingredients they have available.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Using Memory in a Conversation - TypeScript\nDESCRIPTION: This code shows how to use the initialized Mastra memory system within a conversation with an agent. It creates a unique thread ID and resource ID, and then sends multiple queries to the agent using the `stream` method.  The `memoryOptions` parameter is used to customize the retrieval of relevant messages from memory based on last messages and semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-upstash.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Ask about ingredients\nconst response1 = await chefAgent.stream(\n  \"私のキッチンには、パスタ、缶詰のトマト、ニンニク、オリーブオイル、そしていくつかの乾燥ハーブ（バジルとオレガノ）があります。何が作れますか？\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Ask about different ingredients\nconst response2 = await chefAgent.stream(\n  \"今、私は友達の家にいて、彼らは鶏もも肉、ココナッツミルク、サツマイモ、カレーパウダーを持っています。\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Use memory to recall previous conversation\nconst response3 = await chefAgent.stream(\n  \"友達の家に行く前に何を料理しましたか？\",\n  {\n    threadId,\n    resourceId,\n    memoryOptions: {\n      lastMessages: 3, // Get last 3 messages for context\n      semanticRecall: {\n        topK: 2, // Also get 2 most relevant messages\n        messageRange: 2, // Include context around matches\n      },\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Generating and Storing Embeddings\nDESCRIPTION: Creates embeddings for document chunks and stores them in the PgVector database with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Advanced FaithfulnessMetric Usage with Mixed Claims in TypeScript\nDESCRIPTION: This code snippet showcases an advanced example of using the FaithfulnessMetric to evaluate an LLM's response containing a mix of factual and speculative claims. It demonstrates how the metric handles such claims and provides insights into the scoring process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/faithfulness.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { FaithfulnessMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new FaithfulnessMetric(model, {\n  context: [\n    \"The company had 100 employees in 2020.\",\n    \"Current employee count is approximately 500.\",\n  ],\n});\n\n// Example with mixed claim types\nconst result = await metric.measure(\n  \"What's the company's growth like?\",\n  \"The company has grown from 100 employees in 2020 to 500 now, and might expand to 1000 by next year.\",\n);\n\n// Example output:\n// {\n//   score: 0.67,\n//   info: {\n//     reason: \"The score is 0.67 because two claims are supported by the context\n//           (initial employee count of 100 in 2020 and current count of 500),\n//           while the future expansion claim is marked as unsure as it cannot\n//           be verified against the context.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Load and Process Paper (TypeScript)\nDESCRIPTION: Loads the paper content from a specified URL, creates a document object, and splits it into smaller chunks for processing. Dependencies include @ai-sdk/openai and @mastra/rag. This step prepares the paper for embedding and storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\nimport { mastra } from \"./mastra\";\n\n// Load the paper\nconst paperUrl = \"https://arxiv.org/html/1706.03762\";\nconst response = await fetch(paperUrl);\nconst paperText = await response.text();\n\n// Create document and chunk it\nconst doc = MDocument.fromText(paperText);\nconst chunks = await doc.chunk({\n  strategy: 'recursive',\n  size: 512,\n  overlap: 50,\n  separator: '\\n',\n});\n\nconsole.log(\"Number of chunks:\", chunks.length);\n// Number of chunks: 893\n```\n\n----------------------------------------\n\nTITLE: Defining and Committing the Workflow in TypeScript\nDESCRIPTION: This snippet combines the previously defined steps to create a complete workflow. It implements branching logic based on the candidate's technical status and commits the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst candidateWorkflow = new Workflow({\n  name: \"candidate-workflow\",\n  triggerSchema: z.object({\n    resumeText: z.string(),\n  }),\n});\n\ncandidateWorkflow\n  .step(gatherCandidateInfo)\n  .then(askAboutSpecialty, {\n    when: { \"gatherCandidateInfo.isTechnical\": true },\n  })\n  .after(gatherCandidateInfo)\n  .step(askAboutRole, {\n    when: { \"gatherCandidateInfo.isTechnical\": false },\n  });\n\ncandidateWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Forward Abort Signal to Tool Execution\nDESCRIPTION: This code snippet illustrates how to forward an abort signal to a tool's execution, allowing for cancellation of long-running tasks.  It creates an agent with a tool that uses `fetch` to retrieve weather data. The `abortSignal` from the agent's context is passed to the `fetch` call, enabling cancellation of the request if the agent is aborted. The `zod` library is used for input validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst agent = new Agent({\n  name: \"Weather agent\",\n  tools: {\n    weather: createTool({\n      id: \"Get Weather Information\",\n      description: \"Get the weather in a location\",\n      inputSchema: z.object({ location: z.string() }),\n      execute: async ({ context: { location } }, { abortSignal }) => {\n        return fetch(\n          `https://api.weatherapi.com/v1/current.json?q=${location}`,\n          { signal: abortSignal }, // forward the abort signal to fetch\n        );\n      },\n    }),\n  },\n});\n\nconst result = await agent.generate(\"What is the weather in San Francisco?\", {\n  abortSignal: myAbortSignal, // signal that will be forwarded to tools\n});\n```\n\n----------------------------------------\n\nTITLE: Merging Multiple Branches with .after() in Mastra Workflow\nDESCRIPTION: This snippet demonstrates how to use `.after()` to merge multiple branches in a Mastra workflow. `stepE` will only execute after both `stepB` and `stepD` have completed, ensuring that the results of both branches are available before proceeding.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/after.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n    .then(stepB)\n  .step(stepC)\n    .then(stepD)\n  .after([stepB, stepD])  // 複数のステップに依存するステップを作成\n    .step(stepE);\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors with Documents\nDESCRIPTION: This code snippet demonstrates the upsert method to add or update vectors alongside their associated metadata and original documents in the specified collection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst documents = ['full text 1', 'full text 2'];\nconst ids = await vectorStore.upsert({\n  indexName: 'myCollection',\n  vectors,\n  metadata,\n  documents, // store original text\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Content Quality Evaluation Step in TypeScript\nDESCRIPTION: This code defines a step that evaluates the quality of the generated content by calculating tone and completeness scores.  It retrieves the content from the previous step (`promptAgent`) and uses simulated functions (`calculateToneScore`, `calculateCompletenessScore`) to calculate the scores. The `execute` function then returns an object containing these scores.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Evaluate the content quality\nconst evaluateTone = new Step({\n  id: 'evaluateToneConsistency',\n  execute: async ({ context }) => {\n    const content = context.getStepResult(promptAgent)?.modelOutput;\n\n    // Simulate evaluation\n    return {\n      toneScore: { score: calculateToneScore(content) },\n      completenessScore: { score: calculateCompletenessScore(content) },\n    };\n  },\n  outputSchema: z.object({\n    toneScore: z.any(),\n    completenessScore: z.any(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow and Defining Helper Functions in TypeScript\nDESCRIPTION: This code registers the content generation workflow with Mastra and defines several helper functions used to simulate AI behavior and content quality assessment. It initializes Mastra with the `contentWorkflow`.  It also provides functions like `generateInitialDraft`, `enhanceWithGuidance`, `makeMinorImprovements`, `calculateToneScore`, and `calculateCompletenessScore` to simulate various aspects of content generation and evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { contentWorkflow },\n});\n\n// Helper functions (simulated)\nfunction generateInitialDraft(input: string = '') {\n  // Simulate AI generating content\n  return {\n    content: `Generated content based on: ${input}`,\n    confidenceScore: 0.6, // Simulate low confidence to trigger suspension\n  };\n}\n\nfunction enhanceWithGuidance(content: string = '', guidance: string = '') {\n  return `${content} (Enhanced with guidance: ${guidance})`;\n}\n\nfunction makeMinorImprovements(content: string = '') {\n  return `${content} (with minor improvements)`;\n}\n\nfunction calculateToneScore(_: string = '') {\n  return 0.7; // Simulate a score that will trigger suspension\n}\n\nfunction calculateCompletenessScore(_: string = '') {\n  return 0.9;\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Vector Query Tool in TypeScript\nDESCRIPTION: This TypeScript snippet shows how to create a basic tool for semantic search over vector stores using Mastra. The `createVectorQueryTool` function is configured with a specified `vectorStoreName`, `indexName`, and an OpenAI embedding model. The function is integral to conducting searches over the specified data store, enabling retrieval of relevant contexts based on vector embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { createVectorQueryTool } from \"@mastra/rag\";\n\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow with Multiple Suspension Points TypeScript\nDESCRIPTION: Illustrates a workflow with multiple steps, each with the capability to suspend based on specific conditions.  It showcases how to use the `suspend` function with optional payload data.  The workflow is then constructed using `Workflow` and chained `step` and `then` methods, representing the execution flow with suspension points.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Define steps with suspend capability\nconst promptAgentStep = new Step({\n  id: \"promptAgent\",\n  execute: async ({ context, suspend }) => {\n    // Some condition that determines if we need to suspend\n    if (needHumanInput) {\n      // Optionally pass payload data that will be stored with suspended state\n      await suspend({ requestReason: \"Need human input for prompt\" });\n      // Code after suspend() will execute when the step is resumed\n      return { modelOutput: context.userInput };\n    }\n    return { modelOutput: \"AI generated output\" };\n  },\n  outputSchema: z.object({ modelOutput: z.string() }),\n});\n\nconst improveResponseStep = new Step({\n  id: \"improveResponse\",\n  execute: async ({ context, suspend }) => {\n    // Another condition for suspension\n    if (needFurtherRefinement) {\n      await suspend();\n      return { improvedOutput: context.refinedOutput };\n    }\n    return { improvedOutput: \"Improved output\" };\n  },\n  outputSchema: z.object({ improvedOutput: z.string() }),\n});\n\n// Build the workflow\nconst workflow = new Workflow({\n  name: \"multi-suspend-workflow\",\n  triggerSchema: z.object({ input: z.string() }),\n});\n\nworkflow\n  .step(getUserInput)\n  .then(promptAgentStep)\n  .then(evaluateTone)\n  .then(improveResponseStep)\n  .then(evaluateImproved)\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  workflows: { workflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Register Agent with Mastra\nDESCRIPTION: This code snippet demonstrates how to register the `weatherAgent` with the Mastra framework. It imports the `Mastra` class from `@mastra/core` and the `weatherAgent` from its corresponding file. The `Mastra` instance is created with the `weatherAgent` registered within the `agents` configuration, making the agent available for use within the Mastra application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { weatherAgent } from \"./agents/weatherAgent\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Upstash - TypeScript\nDESCRIPTION: This code snippet initializes the Mastra memory system using Upstash as the storage and vector backend. It sets up the `UpstashStore` and `UpstashVector` instances, passing in the Upstash Redis REST URL and token obtained from environment variables. It also configures memory options, including the number of last messages to retain and semantic recall parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-upstash.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { UpstashStore, UpstashVector } from \"@mastra/upstash\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Upstashのストレージとベクター検索を使用してメモリを初期化\nconst memory = new Memory({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_REDIS_REST_URL,\n    token: process.env.UPSTASH_REDIS_REST_TOKEN,\n  }),\n  vector: new UpstashVector({\n    url: process.env.UPSTASH_REDIS_REST_URL,\n    token: process.env.UPSTASH_REDIS_REST_TOKEN,\n  }),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\n// メモリ機能を持つエージェントを作成\nconst chefAgent = new Agent({\n  name: \"chefAgent\",\n  instructions:\n    \"あなたはMichelです。実用的で経験豊富な家庭料理のシェフで、利用可能な食材で素晴らしい料理を作る手助けをします。\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Basic afterEvent() Usage in Mastra Workflow (TypeScript)\nDESCRIPTION: This code demonstrates the basic usage of the `afterEvent()` method to create a suspension point in a Mastra workflow that waits for an 'approval' event.  The workflow is defined with an 'approval' event that requires a schema specifying the 'approved' boolean and 'approverName' string. After the `afterEvent()` call, the workflow suspends until the 'approval' event is triggered, at which point execution continues with `processApproval` step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/afterEvent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Define workflow with events\nconst workflow = new Workflow({\n  name: 'approval-workflow',\n  events: {\n    approval: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n  },\n});\n\n// Build workflow with event suspension point\nworkflow\n  .step(submitRequest)\n  .afterEvent('approval')    // Workflow suspends here\n  .step(processApproval)     // This step runs after the event occurs\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Workflow Registration and Execution with Resume Logic\nDESCRIPTION: Demonstrates how to register the workflow, set up execution monitoring, and implement resume functionality. Includes watching for suspended state and resuming with new context data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Register the workflow\nexport const mastra = new Mastra({\n  workflows: { registeredWorkflow: myWorkflow },\n})\n\n// Get registered workflow from Mastra\nconst registeredWorkflow = mastra.getWorkflow('registeredWorkflow');\nconst { runId, start } = registeredWorkflow.createRun();\n\n// Start watching the workflow before executing it\nmyWorkflow.watch(async ({ context, activePaths }) => {\n  for (const _path of activePaths) {\n    const stepTwoStatus = context.steps?.stepTwo?.status;\n    if (stepTwoStatus === 'suspended') {\n      console.log(\"Workflow suspended, resuming with new value\");\n\n      // Resume the workflow with new context\n      await myWorkflow.resume({\n        runId,\n        stepId: 'stepTwo',\n        context: { secondValue: 100 },\n      });\n    }\n  }\n})\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n----------------------------------------\n\nTITLE: Workflow Conditional Branching using Function Condition in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a conditional branch in a Mastra workflow using a function that returns a boolean to determine whether to execute the 'if' branch. It shows how to access the result of a previous step and use it in the condition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/if.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return value < 10; // If true, execute the \"if\" branch\n  })\n  .then(ifBranchStep)\n  .else()\n  .then(elseBranchStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Generating and Storing Embeddings with Metadata\nDESCRIPTION: Generates embeddings for document chunks and stores them along with metadata in PgVector, enabling combined semantic search and metadata filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector('pgVector');\nawait vectorStore.createIndex({\n  indexName: 'embeddings',\n  dimension: 1536,\n});\n\n// Store both embeddings and metadata together\nawait vectorStore.upsert({\n  indexName: 'embeddings',\n  vectors: embeddings,\n  metadata: chunkMetadata,\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolCallFilter Processor\nDESCRIPTION: Shows how to use ToolCallFilter processor to remove tool calls from memory messages, with examples of filtering all tools or specific tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { ToolCallFilter, TokenLimiter } from \"@mastra/memory/processors\";\n\nconst memoryFilteringTools = new Memory({\n  processors: [\n    // Example 1: Remove all tool calls/results\n    new ToolCallFilter(),\n\n    // Example 2: Remove only noisy image generation tool calls/results\n    new ToolCallFilter({ exclude: [\"generateImageTool\"] }),\n\n    // Always place TokenLimiter last\n    new TokenLimiter(127000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Using the Hierarchical Multi-Agent System in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the entire hierarchical multi-agent system to generate a blog post about React JavaScript frameworks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const agent = mastra.getAgent(\"publisherAgent\");\n  const result = await agent.generate(\n    \"Write a blog post about React JavaScript frameworks. Only return the final edited copy.\",\n  );\n  console.log(result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: MDocument Usage Example\nDESCRIPTION: Demonstrates how to create an MDocument from text, split it into chunks using a markdown strategy, extract metadata (summaries and keywords), and access the processed chunks, texts, and metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\n// Create document from text\nconst doc = MDocument.fromText('Your content here');\n\n// Split into chunks with metadata extraction\nconst chunks = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']],\n  extract: {\n    summary: true, // Extract summaries with default settings\n    keywords: true  // Extract keywords with default settings\n  }\n});\n\n// Get processed chunks\nconst docs = doc.getDocs();\nconst texts = doc.getText();\nconst metadata = doc.getMetadata();\n```\n\n----------------------------------------\n\nTITLE: Linking and Committing Workflow Steps (TypeScript)\nDESCRIPTION: This snippet demonstrates how to link workflow steps together to define the control flow and then finalize the workflow by calling `commit()`.  In this case, `stepOne` is executed first, and then `stepTwo` is executed after `stepOne` completes successfully.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(stepOne).then(stepTwo).commit();\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork Usage Example in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create and use an AgentNetwork with specialized agents. It defines two agents, `webSearchAgent` and `dataAnalysisAgent`, and then creates a `researchNetwork` using these agents. The network is then used to generate a response for a research topic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AgentNetwork } from '@mastra/core/network';\nimport { openai } from '@mastra/openai';\n\n// Create specialized agents\nconst webSearchAgent = new Agent({\n  name: 'Web Search Agent',\n  instructions: 'You search the web for information.',\n  model: openai('gpt-4o'),\n  tools: { /* web search tools */ },\n});\n\nconst dataAnalysisAgent = new Agent({\n  name: 'Data Analysis Agent',\n  instructions: 'You analyze data and provide insights.',\n  model: openai('gpt-4o'),\n  tools: { /* data analysis tools */ },\n});\n\n// Create the network\nconst researchNetwork = new AgentNetwork({\n  name: 'Research Network',\n  instructions: 'Coordinate specialized agents to research topics thoroughly.',\n  model: openai('gpt-4o'),\n  agents: [webSearchAgent, dataAnalysisAgent],\n});\n\n// Use the network\nconst result = await researchNetwork.generate('Research the impact of climate change on agriculture');\nconsole.log(result.text);\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory with Working Memory for Todo List in TypeScript\nDESCRIPTION: Sets up a Memory instance with a short context window and enables working memory. It defines a template for structuring todo list data using Markdown.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  options: {\n    lastMessages: 1, // working memory means we can have a shorter context window and still maintain conversational coherence\n    workingMemory: {\n      enabled: true,\n      template: `\n# Todo List\n## Item Status\n- Active items:\n  - Example (Due: Feb 7 3028, Started: Feb 7 2025)\n    - Description: This is an example task\n## Completed\n- None yet\n`,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Conditional Branching in Mastra Workflow (TypeScript)\nDESCRIPTION: This snippet illustrates conditional branching within a Mastra workflow. It demonstrates how to execute different steps based on the success or failure status of a previous step. The `when` condition checks the status of `fetchDataStep` in the workflow context to determine which subsequent step should be executed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'error-handling-workflow',\n});\n\nworkflow\n  .step(fetchDataStep)\n  .then(processDataStep, {\n    // Only execute processDataStep if fetchDataStep was successful\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === 'success';\n    },\n  })\n  .then(fallbackStep, {\n    // Execute fallbackStep if fetchDataStep failed\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === 'failed';\n    },\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Generating Structured Recipe Data with Chef Agent in TypeScript\nDESCRIPTION: This snippet shows how to generate a structured recipe using Zod schema validation with the Chef Assistant agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\nasync function main() {\n  const query =\n    \"I want to make lasagna, can you generate a lasagna recipe for me?\";\n  console.log(`Query: ${query}`);\n\n  // Define the Zod schema\n  const schema = z.object({\n    ingredients: z.array(\n      z.object({\n        name: z.string(),\n        amount: z.string(),\n      }),\n    ),\n    steps: z.array(z.string()),\n  });\n\n  const response = await chefAgent.generate(\n    [{ role: \"user\", content: query }],\n    { output: schema },\n  );\n  console.log(\"\\n👨‍🍳 Chef Michel:\", response.object);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Initializing PineconeVector Store in TypeScript\nDESCRIPTION: Shows how to initialize a Pinecone vector store, create an index with specific dimensions, and upsert vectors with metadata. Uses Pinecone API key from environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PineconeVector } from '@mastra/pinecone'\n\nconst store = new PineconeVector(process.env.PINECONE_API_KEY)\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Using the Voice Speak Method with Agent Integration in TypeScript\nDESCRIPTION: This snippet demonstrates how to use TTS within a Mastra agent. It shows importing necessary packages, initializing a voice provider and agent, generating text with the agent, and converting that text to speech with configurable options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/text-to-speech.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\nconst voice = new OpenAIVoice();\n\nconst agent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\nconst { text } = await agent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst readableStream = await voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n  properties: {\n    speed: 1.0, // Optional: adjust speech speed\n    pitch: \"default\", // Optional: specify pitch if supported\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Conditionally Resuming a Workflow (TypeScript)\nDESCRIPTION: This code snippet demonstrates conditional logic for resuming a suspended workflow based on the suspend payload and the current user's role. It uses `run.watch` to observe active paths. If the 'approval' step is suspended, it checks the `urgency` in the payload and the `currentUser.role`. If the urgency is 'high' and the user is a 'manager', it resumes the workflow with updated context (approved status and approver ID).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(async ({ activePaths }) => {\n  const isApprovalStepSuspended =\n    activePaths.get(\"approval\")?.status === \"suspended\";\n  if (isApprovalStepSuspended) {\n    const payload = activePaths.get(\"approval\")?.suspendPayload;\n    if (payload.urgency === \"high\" && currentUser.role === \"manager\") {\n      await resume({\n        stepId: \"approval\",\n        context: { approved: true, approver: currentUser.id },\n      });\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with LibSQL Defaults in TypeScript\nDESCRIPTION: This snippet shows how to initialize Mastra's memory system using LibSQL as the default storage and vector database. It creates a memory instance and an agent with memory integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from '@mastra/memory';\nimport { Agent } from '@mastra/core/agent';\n\n// Initialize memory with LibSQL defaults\nconst memory = new Memory();\n\nconst memoryAgent = new Agent({\n  name: \"Memory Agent\",\n  instructions:\n    \"You are an AI agent with the ability to automatically recall memories from previous interactions.\",\n  model: openai('gpt-4o-mini'),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Vector Query Tool Configuration\nDESCRIPTION: Creation of a vector query tool for searching the vector database using OpenAI embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Using useChat with Mastra Memory to Prevent Message Duplication (React)\nDESCRIPTION: This code snippet demonstrates how to use the `useChat` hook from the `ai/react` library with Mastra Memory.  It configures `useChat` to send only the most recent message content along with a `threadId` and `resourceId` to prevent redundant storage of chat history in Mastra's memory. The `experimental_prepareRequestBody` option formats the request to include only the necessary data, ensuring that the backend receives only the latest message and custom identifiers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/use-chat.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// components/Chat.tsx (React Example)\nimport { useChat } from \"ai/react\";\n\nexport function Chat({ threadId, resourceId }) {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: \"/api/chat\", // Your backend endpoint\n    // Pass only the latest message and custom IDs\n    experimental_prepareRequestBody: (request) => {\n      // Ensure messages array is not empty and get the last message\n      const lastMessage = request.messages.length > 0 ? request.messages[request.messages.length - 1] : null;\n\n      // Return the structured body for your API route\n      return {\n        message: lastMessage, // Send only the most recent message content/role\n        threadId,\n        resourceId,\n      };\n    },\n    // Optional: Initial messages if loading history from backend\n    // initialMessages: loadedMessages,\n  });\n\n  // ... rest of your chat UI component\n  return (\n    <div>\n      {/* Render messages */}\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} placeholder=\"Send a message...\" />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: RAG Agent Configuration\nDESCRIPTION: Setup of a Mastra agent capable of handling both querying and cleaning operations using GPT-4.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that handles both querying and cleaning documents.\n    When cleaning: Process, clean, and label data, remove irrelevant information and deduplicate content while preserving key facts.\n    When querying: Provide answers based on the available context. Keep your answers concise and relevant.\n    \n    Important: When asked to answer a question, please base your answer only on the context provided in the tool. If the context doesn't contain enough information to fully answer the question, please state that explicitly.\n    `,\n  model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n    documentChunkerTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Using Memory in Agent Calls\nDESCRIPTION: This code snippet illustrates how to use memory during agent interactions by providing `resourceId` and `threadId` when calling the agent's `stream()` or `generate()` methods. These IDs ensure that conversation history and context are correctly stored and retrieved for the appropriate user and conversation. resourceId typically identifies the user, while threadId identifies the specific conversation thread.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/agent-memory.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// メモリを使用したエージェント呼び出しの例\nawait agent.stream(\"私の好きな色は青だということを覚えておいて。\", {\n  resourceId: \"user_alice\",\n  threadId: \"preferences_thread\",\n});\n\n// 同じスレッドの後で...\nconst response = await agent.stream(\"私の好きな色は何？\", {\n  resourceId: \"user_alice\",\n  threadId: \"preferences_thread\",\n});\n// エージェントはメモリを使用して好きな色を思い出します。\n```\n\n----------------------------------------\n\nTITLE: Agent-to-Agent Voice Interaction (TypeScript)\nDESCRIPTION: This code snippet demonstrates a basic voice interaction between `agent1` and `agent2`. `agent1` speaks a question, which is saved to a file. `agent2` then listens to the audio file, converts it to text, generates a response, and speaks the response, saving it to another file. It uses `createReadStream` from the `fs` module to read the audio file and `agent2.voice.listen` to process it.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/adding-voice-capabilities.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\n// ステップ1：エージェント1が質問を話し、それをファイルに保存\nconst audio1 = await agent1.voice.speak('人生の意味を一文で説明してください。');\nawait saveAudioToFile(audio1, 'agent1-question.mp3');\n\n// ステップ2：エージェント2がエージェント1の質問を聞く\nconst audioFilePath = path.join(process.cwd(), 'agent1-question.mp3');\nconst audioStream = createReadStream(audioFilePath);\nconst audio2 = await agent2.voice.listen(audioStream);\nconst text = await convertToText(audio2);\n\n// ステップ3：エージェント2が応答を生成し、それを話す\nconst agent2Response = await agent2.generate(text);\nconst agent2ResponseAudio = await agent2.voice.speak(agent2Response.text);\nawait saveAudioToFile(agent2ResponseAudio, 'agent2-response.mp3');\n```\n\n----------------------------------------\n\nTITLE: Implementing Mastra Eval Tests with Vitest\nDESCRIPTION: Example test implementation showing how to validate tone consistency using Mastra evals with Vitest testing framework. Demonstrates basic test structure and metric evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { describe, it, expect } from 'vitest';\nimport { evaluate } from \"@mastra/evals\";\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\nimport { myAgent } from './index';\n\ndescribe('My Agent', () => {\n  it('should validate tone consistency', async () => {\n    const metric = new ToneConsistencyMetric();\n    const result = await evaluate(myAgent, 'Hello, world!', metric)\n\n    expect(result.score).toBe(1);\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Defining and Committing Weather Workflow\nDESCRIPTION: Defines the weather workflow with a trigger schema and chains the 'fetchWeather' and 'planActivities' steps. The workflow is then committed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst weatherWorkflow = new Workflow({\n  name: \"weather-workflow\",\n  triggerSchema: z.object({\n    city: z.string().describe(\"天気を取得する都市\"),\n  }),\n})\n  .step(fetchWeather)\n  .then(planActivities);\n\nweatherWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Complete Event-Driven Workflow Example (TypeScript)\nDESCRIPTION: This comprehensive snippet shows a complete event-driven workflow in Mastra, including step definitions, event definitions, and workflow construction. It uses `Workflow` and `Step` classes from `@mastra/core/workflows` and Zod for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n// Define steps\nconst createRequest = new Step({\n  id: 'createRequest',\n  execute: async () => ({ requestId: `req-${Date.now()}` }),\n});\n\nconst processApproval = new Step({\n  id: 'processApproval',\n  execute: async ({ context }) => {\n    const approvalData = context.inputData.resumedEvent;\n    return {\n      approved: approvalData.approved,\n      approver: approvalData.approverName,\n    };\n  },\n});\n\nconst processDocument = new Step({\n  id: 'processDocument',\n  execute: async ({ context }) => {\n    const documentData = context.inputData.resumedEvent;\n    return {\n      documentId: documentData.documentId,\n      processed: true,\n      type: documentData.documentType,\n    };\n  },\n});\n\nconst finalizeRequest = new Step({\n  id: 'finalizeRequest',\n  execute: async ({ context }) => {\n    const requestId = context.steps.createRequest.output.requestId;\n    const approved = context.steps.processApproval.output.approved;\n    const documentId = context.steps.processDocument.output.documentId;\n\n    return {\n      finalized: true,\n      summary: `Request ${requestId} was ${approved ? 'approved' : 'rejected'} with document ${documentId}`\n    };\n  },\n});\n\n// Create workflow\nconst requestWorkflow = new Workflow({\n  name: 'document-request-workflow',\n  events: {\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n    documentUploaded: {\n      schema: z.object({\n        documentId: z.string(),\n        documentType: z.enum(['invoice', 'receipt', 'contract']),\n      }),\n    },\n  },\n});\n\n// Build workflow\nrequestWorkflow\n  .step(createRequest)\n  .afterEvent('approvalReceived')\n  .step(processApproval)\n  .afterEvent('documentUploaded')\n  .step(processDocument)\n  .then(finalizeRequest)\n  .commit();\n\n// Export workflow\nexport { requestWorkflow };\n```\n\n----------------------------------------\n\nTITLE: Looping with 'until' in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to use the `until` method to create a loop that repeats a step until a specified condition is true. The `incrementStep` is repeated until the `updatedCounter` reaches 10.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// ターゲットに達するまでカウンターをインクリメントするステップ\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // 現在のカウンター値\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // 更新されたカウンター値\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .until(\n    async ({ context }) => {\n      // カウンターが10に達したら停止\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) >= 10;\n    },\n    incrementStep,\n    {\n      // 現在のカウンターを次の反復に渡す\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .until(\n    {\n      ref: { step: incrementStep, path: 'updatedCounter' },\n      query: { $gte: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Agent Configuration\nDESCRIPTION: Configures a Mastra agent to understand user queries and translate them into appropriate metadata filters. The agent is provided with a system prompt that includes instructions on how to use the available metadata structure and the vector store prompt.  It utilizes the `gpt-4o-mini` model and is equipped with the `vectorQueryTool` for filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.\n\n  Filter the context by searching the metadata.\n  \n  The metadata is structured as follows:\n\n  {\n    text: string,\n    excerptKeywords: string,\n    nested: {\n      keywords: string[],\n      id: number,\n    },\n  }\n\n  ${PGVECTOR_PROMPT}\n\n  Important: When asked to answer a question, please base your answer only on the context provided in the tool. \n  If the context doesn't contain enough information to fully answer the question, please state that explicitly.\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool with Re-ranking\nDESCRIPTION: Configures a vector query tool with re-ranking capabilities using OpenAI embeddings and GPT-4o-mini model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  reranker: {\n    model: openai(\"gpt-4o-mini\"),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Condition-Based Loops with until() Method and Function Condition\nDESCRIPTION: Demonstrates how to repeat a step until a specified function-based condition becomes true using the until() method, with a counter example that increments until reaching a target value.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Step that increments a counter until target is reached\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // Current counter value\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .until(\n    async ({ context }) => {\n      // Stop when counter reaches 10\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) >= 10;\n    },\n    incrementStep,\n    {\n      // Pass current counter to next iteration\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent with Evals in TypeScript\nDESCRIPTION: This snippet demonstrates how to create an AI agent using Mastra and configure it with various evaluation metrics. It imports necessary components, sets up an OpenAI model, and defines an agent with summarization, content similarity, and tone consistency evals.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/overview.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\nimport {\n  ContentSimilarityMetric,\n  ToneConsistencyMetric,\n} from \"@mastra/evals/nlp\";\n\nconst model = openai(\"gpt-4o\");\n\nexport const myAgent = new Agent({\n  name: \"ContentWriter\",\n  instructions: \"You are a content writer that creates accurate summaries\",\n  model,\n  evals: {\n    summarization: new SummarizationMetric(model),\n    contentSimilarity: new ContentSimilarityMetric(),\n    tone: new ToneConsistencyMetric(),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedder Model\nDESCRIPTION: This code snippet demonstrates how to configure a custom embedding model for semantic recall. It uses the `openai.embedding` function from `@ai-sdk/openai` to specify the \"text-embedding-3-small\" model for converting messages into embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    embedder: openai.embedding(\"text-embedding-3-small\"),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Workflow with Function-Based Conditions in TypeScript\nDESCRIPTION: This snippet shows a complete Mastra workflow implementation with conditional branching using if/else statements. It includes step definitions, workflow construction, and example usage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n\n// Step that provides the initial value\nconst startStep = new Step({\n  id: 'start',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // Get the value from the trigger data\n    const value = context.triggerData.inputValue;\n    return { value };\n  },\n});\n\n// Step that handles high values\nconst highValueStep = new Step({\n  id: 'highValue',\n  outputSchema: z.object({\n    result: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return { result: `High value processed: ${value}` };\n  },\n});\n\n// Step that handles low values\nconst lowValueStep = new Step({\n  id: 'lowValue',\n  outputSchema: z.object({\n    result: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return { result: `Low value processed: ${value}` };\n  },\n});\n\n// Final step that summarizes the result\nconst finalStep = new Step({\n  id: 'final',\n  outputSchema: z.object({\n    summary: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // Get the result from whichever branch executed\n    const highResult = context.getStepResult<{ result: string }>('highValue')?.result;\n    const lowResult = context.getStepResult<{ result: string }>('lowValue')?.result;\n\n    const result = highResult || lowResult;\n    return { summary: `Processing complete: ${result}` };\n  },\n});\n\n// Build the workflow with conditional branching\nconst conditionalWorkflow = new Workflow({\n  name: 'conditional-workflow',\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nconditionalWorkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value ?? 0;\n    return value >= 10; // Condition: value is 10 or greater\n  })\n  .then(highValueStep)\n  .then(finalStep)\n  .else()\n  .then(lowValueStep)\n  .then(finalStep) // Both branches converge on the final step\n  .commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { conditionalWorkflow },\n});\n\n// Example usage\nasync function runWorkflow(inputValue: number) {\n  const workflow = mastra.getWorkflow('conditionalWorkflow');\n  const { start } = workflow.createRun();\n\n  const result = await start({\n    triggerData: { inputValue },\n  });\n\n  console.log('Workflow result:', result.results);\n  return result;\n}\n\n// Run with a high value (follows the \"if\" branch)\nconst result1 = await runWorkflow(15);\n// Run with a low value (follows the \"else\" branch)\nconst result2 = await runWorkflow(5);\n\nconsole.log('Result 1:', result1);\nconsole.log('Result 2:', result2);\n```\n\n----------------------------------------\n\nTITLE: Evaluating low context precision with ContextPrecisionMetric\nDESCRIPTION: This TypeScript snippet demonstrates how to evaluate a response that uses very little of the provided context information. It initializes the ContextPrecisionMetric with a context array and the OpenAI model, then measures the precision of a response against a query. The output includes the precision score and the reason for the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-precision.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'ナイル川はアフリカにあります。',\n  'ナイル川は最長の川です。',\n  '古代エジプト人はナイル川を利用しました。',\n  'ナイル川は北に流れます。',\n];\n\nconst metric3 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'ナイル川はどの方向に流れますか？';\nconst response3 = 'ナイル川は北に流れます。';\n\nconsole.log('例 3 - 低精度:');\nconsole.log('コンテキスト:', context3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.2, reason: 'コンテキストには関連する情報が1つだけあり、それは最後にあります。' }\n```\n\n----------------------------------------\n\nTITLE: Adding Weather Info Tool to an Agent in TypeScript\nDESCRIPTION: This code snippet illustrates how to create an agent using `@mastra/core/agent` and integrate the `weatherInfo` tool.  It defines the agent's name, instructions, and the tools it can use, mapping the `weatherInfo` tool to the agent.  It utilizes `openai` from `@ai-sdk/openai` for the agent's model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport * as tools from \"../tools/weatherInfo\";\n\nexport const weatherAgent = new Agent<typeof tools>({\n  name: \"Weather Agent\",\n  instructions:\n    \"You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    weatherInfo: tools.weatherInfo,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Pinecone with Mastra\nDESCRIPTION: This code demonstrates how to use the `PineconeVector` class from `@mastra/pinecone` to create an index and insert embeddings into Pinecone. It utilizes `openai` for generating embeddings, `MDocument` for text chunking, and environment variables for accessing the Pinecone API key. The example shows creating an index and upserting vector embeddings along with associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PineconeVector } from '@mastra/pinecone';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst pinecone = new PineconeVector(process.env.PINECONE_API_KEY!);\n\nawait pinecone.createIndex({\n  indexName: 'testindex',\n  dimension: 1536,\n});\n\nawait pinecone.upsert({\n  indexName: 'testindex',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors in AstraVector\nDESCRIPTION: Upserts vectors into a specified index in the AstraVector class with parameters for vector embeddings, optional metadata, and IDs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to upsert into\",\n    },\n    {\n      name: \"vectors\",\n      type: \"number[][]\",\n      description: \"Array of embedding vectors\",\n    },\n    {\n      name: \"metadata\",\n      type: \"Record<string, any>[]\",\n      isOptional: true,\n      description: \"Metadata for each vector\",\n    },\n    {\n      name: \"ids\",\n      type: \"string[]\",\n      isOptional: true,\n      description: \"Optional vector IDs (auto-generated if not provided)\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Simple Path Comparison Condition in Mastra Workflow (Typescript)\nDESCRIPTION: Shows how to define a condition for executing a step in a Mastra workflow using simple path comparison. It directly compares the 'auth.status' path to the string 'authenticated'. The `processOrder` step executes only when the status is authenticated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-condition.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: {\n    \"auth.status\": \"authenticated\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow.until() Example Implementation\nDESCRIPTION: This complete example demonstrates the usage of `Workflow.until()` with a counter. It defines an `incrementStep` that increments a counter and a `finalStep` that logs the final value.  The workflow continues to increment the counter until it reaches the specified `targetValue` provided in the trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/until.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\n// Create a step that increments a counter\nconst incrementStep = new Step({\n  id: 'increment',\n  description: 'カウンターを1増やします',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // Get current value from previous execution or start at 0\n    const currentValue =\n      context.getStepResult<{ value: number }>('increment')?.value ||\n      context.getStepResult<{ startValue: number }>('trigger')?.startValue ||\n      0;\n\n    // Increment the value\n    const value = currentValue + 1;\n    console.log(`Incrementing to ${value}`);\n\n    return { value };\n  },\n});\n\n// Create a final step\nconst finalStep = new Step({\n  id: 'final',\n  description: 'ループ完了後の最終ステップ',\n  execute: async ({ context }) => {\n    const finalValue = context.getStepResult<{ value: number }>('increment')?.value;\n    console.log(`ループは最終値: ${finalValue} で完了しました`);\n    return { finalValue };\n  },\n});\n\n// Create the workflow\nconst counterWorkflow = new Workflow({\n  name: 'counter-workflow',\n  triggerSchema: z.object({\n    startValue: z.number(),\n    targetValue: z.number(),\n  }),\n});\n\n// Configure the workflow with an until loop\ncounterWorkflow\n  .step(incrementStep)\n  .until(async ({ context }) => {\n    const targetValue = context.triggerData.targetValue;\n    const currentValue = context.getStepResult<{ value: number }>('increment')?.value ?? 0;\n    return currentValue >= targetValue;\n  }, incrementStep)\n  .then(finalStep)\n  .commit();\n\n// Execute the workflow\nconst run = counterWorkflow.createRun();\nconst result = await run.start({ triggerData: { startValue: 0, targetValue: 5 } });\n// Will increment from 0 to 5, then stop and execute finalStep\n```\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Voice TTS\nDESCRIPTION: This code snippet demonstrates how to initialize the OpenAI Voice TTS provider with API key and speaker settings. It shows both the detailed configuration with API key and a simplified configuration using default settings. The `speechModel` property configures the TTS model, and the `speaker` property selects a specific voice.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/text-to-speech.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIVoice({\n  speechModel: {\n    name: \"tts-1-hd\",\n    apiKey: process.env.OPENAI_API_KEY\n  },\n  speaker: \"alloy\",\n});\n\n// デフォルト設定を使用する場合、設定は以下のように簡略化できます：\nconst voice = new OpenAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Building and Running Content Moderation Workflow (TypeScript)\nDESCRIPTION: This code snippet builds and runs the content moderation workflow using Mastra, integrating Zod for schema definition. It defines a workflow named 'content-moderation-workflow' with steps for analysis, moderation, and applying moderation actions. The code also includes a function to simulate AI content analysis and an example of how to start, suspend, and resume the workflow with user inputs using Inquirer prompts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Build the workflow\nconst contentModerationWorkflow = new Workflow({\n  name: 'content-moderation-workflow',\n  triggerSchema: z.object({\n    content: z.string(),\n  }),\n});\n\ncontentModerationWorkflow\n  .step(analyzeContent)\n  .then(moderateContent)\n  .then(applyModeration)\n  .commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { contentModerationWorkflow },\n});\n\n// Example of using the workflow with Inquirer prompts\nasync function runModerationDemo() {\n  const registeredWorkflow = mastra.getWorkflow('contentModerationWorkflow');\n  const run = registeredWorkflow.createRun();\n\n  // Start the workflow with content that needs review\n  console.log('Starting content moderation workflow...');\n  const result = await run.start({\n    triggerData: {\n      content: 'This is some user-generated content that requires moderation.'\n    }\n  });\n\n  const isReviewStepSuspended = result.activePaths.get('moderateContent')?.status === 'suspended';\n\n  // Check if workflow is suspended\n  if (isReviewStepSuspended) {\n    const { content, aiScore, flaggedCategories, message } = result.activePaths.get('moderateContent')?.suspendPayload;\n\n    console.log('\\n===================================');\n    console.log(message);\n    console.log('===================================\\n');\n\n    console.log('Content to review:');\n    console.log(content);\n    console.log(`\\nAI Analysis Score: ${aiScore}`);\n    console.log(`Flagged Categories: ${flaggedCategories?.join(', ') || 'None'}\\n`);\n\n    // Collect moderator decision using Inquirer\n    const moderatorDecision = await select({\n      message: 'Select your moderation decision:',\n      choices: [\n        { name: 'Approve content as is', value: 'approve' },\n        { name: 'Reject content completely', value: 'reject' },\n        { name: 'Modify content before publishing', value: 'modify' }\n      ],\n    });\n\n    // Collect additional information based on decision\n    let moderatorNotes = '';\n    let modifiedContent = '';\n\n    moderatorNotes = await input({\n      message: 'Enter any notes about your decision:',\n    });\n\n    if (moderatorDecision === 'modify') {\n      modifiedContent = await input({\n        message: 'Enter the modified content:',\n        default: content,\n      });\n    }\n\n    console.log('\\nSubmitting your moderation decision...');\n\n    // Resume the workflow with the moderator's input\n    const resumeResult = await run.resume({\n      stepId: 'moderateContent',\n      context: {\n        moderatorDecision,\n        moderatorNotes,\n        modifiedContent,\n      },\n    });\n\n    if (resumeResult?.results?.applyModeration?.status === 'success') {\n      console.log('\\n===================================');\n      console.log(`Moderation complete: ${resumeResult?.results?.applyModeration?.output.finalStatus}`);\n      console.log('===================================\\n');\n\n      if (resumeResult?.results?.applyModeration?.output.content) {\n        console.log('Published content:');\n        console.log(resumeResult.results.applyModeration.output.content);\n      }\n    }\n\n    return resumeResult;\n  }\n\n  console.log('Workflow completed without requiring human intervention:', result.results);\n  return result;\n}\n\n// Helper function for AI content analysis simulation\nfunction simulateContentAnalysis(content: string): number {\n  // In a real application, this would call an AI service\n  // For the example, we're returning a random score\n  return Math.random();\n}\n\n// Invoke the demo function\nrunModerationDemo().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Using Memory-Enabled Agent for Conversations in TypeScript\nDESCRIPTION: This snippet shows how to use a memory-enabled agent for conversations. It demonstrates starting a conversation, sending messages, and using semantic search to find relevant messages in the conversation history.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Start with a system message\nconst response1 = await memoryAgent.stream(\n  [\n    {\n      role: \"system\",\n      content: `Chat with user started now ${new Date().toISOString()}. Don't mention this message.`,\n    },\n  ],\n  {\n    resourceId,\n    threadId,\n  },\n);\n\n// Send user message\nconst response2 = await memoryAgent.stream(\"What can you help me with?\", {\n  threadId,\n  resourceId,\n});\n\n// Use semantic search to find relevant messages\nconst response3 = await memoryAgent.stream(\"What did we discuss earlier?\", {\n  threadId,\n  resourceId,\n  memoryOptions: {\n    lastMessages: false,\n    semanticRecall: {\n      topK: 3, // Get top 3 most relevant messages\n      messageRange: 2, // Include context around each match\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running Event-Based Workflow TypeScript\nDESCRIPTION: Illustrates how to run an event-based workflow and resume it with event data using `resumeWithEvent`.  It starts the workflow, logs the initial result, and then simulates the occurrence of an event by resuming the workflow with the event data.  The example demonstrates how to handle events and access the event data within subsequent steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Get the workflow\nconst workflow = mastra.getWorkflow(\"approval-workflow\");\nconst run = workflow.createRun();\n\n// Start the workflow\nconst initialResult = await run.start({\n  triggerData: { requestId: \"request-123\" },\n});\n\nconsole.log(\"Workflow started, waiting for approval event\");\nconsole.log(initialResult.results);\n// Output will show the workflow is suspended at the event step:\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'suspended' }\n// }\n\n// Later, when the approval event occurs:\nconst resumeResult = await run.resumeWithEvent(\"approvalReceived\", {\n  approved: true,\n  approverName: \"Jane Doe\",\n});\n\nconsole.log(\"Workflow resumed with event data:\", resumeResult.results);\n// Output will show the completed workflow:\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'success', output: { executed: true, resumedEvent: { approved: true, approverName: 'Jane Doe' } } },\n//   processApproval: { status: 'success', output: { approved: true, approvedBy: 'Jane Doe' } }\n// }\n```\n\n----------------------------------------\n\nTITLE: useObject Hook Integration\nDESCRIPTION: This code showcases the use of the `useObject` hook for consuming text streams that represent JSON objects, parsing them based on a schema. The POST endpoint streams data via `toTextStreamResponse()`, which is consumed in a react component using the `experimental_useObject` hook to extract the structured `object` data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages, {\n    output: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return stream.toTextStreamResponse();\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\n\nexport default function Page() {\n  const { object, submit } = useObject({\n    api: '/api/use-object',\n    schema: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return (\n    <div>\n      <button onClick={() => submit('example input')}>Generate</button>\n      {object?.content && <p>{object.content}</p>}\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Copywriter Step in Mastra Workflow\nDESCRIPTION: This snippet defines the copywriter step in the workflow. It executes the copywriter agent to generate a blog post based on the provided topic and returns the generated copy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterStep = new Step({\n  id: \"copywriterStep\",\n  execute: async ({ context }) => {\n    if (!context?.triggerData?.topic) {\n      throw new Error(\"Topic not found in trigger data\");\n    }\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.triggerData.topic}`,\n    );\n    console.log(\"copywriter result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Moderating Content Based on AI Analysis with TypeScript and Mastra\nDESCRIPTION: This snippet sets up a moderation step that allows a human moderator to make decisions on content flagged by AI analysis. It includes input and output schemas for moderation decisions and implements logic for auto-approval based on the AI analysis score. The execution function captures human input for moderation actions and returns an appropriate result based on those decisions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Moderate content that needs review\nconst moderateContent = new Step({\n  id: 'moderateContent',\n  // Define the schema for human input that will be provided when resuming\n  inputSchema: z.object({\n    moderatorDecision: z.enum(['approve', 'reject', 'modify']).optional(),\n    moderatorNotes: z.string().optional(),\n    modifiedContent: z.string().optional(),\n  }),\n  outputSchema: z.object({\n    moderationResult: z.enum(['approved', 'rejected', 'modified']),\n    moderatedContent: z.string(),\n    notes: z.string().optional(),\n  }),\n  // @ts-ignore\n  execute: async ({ context, suspend }) => {\n    const analysisResult = context.getStepResult(analyzeContent);\n    // Access the input provided when resuming the workflow\n    const moderatorInput = {\n      decision: context.inputData?.moderatorDecision,\n      notes: context.inputData?.moderatorNotes,\n      modifiedContent: context.inputData?.modifiedContent,\n    };\n\n    // If the AI analysis score is high enough, auto-approve\n    if (analysisResult?.aiAnalysisScore > 0.9 && !analysisResult?.flaggedCategories?.length) {\n      return {\n        moderationResult: 'approved',\n        moderatedContent: analysisResult.content,\n        notes: 'Auto-approved by system',\n      };\n    }\n\n    // If we don't have moderator input yet, suspend for human review\n    if (!moderatorInput.decision) {\n      await suspend({\n        content: analysisResult?.content,\n        aiScore: analysisResult?.aiAnalysisScore,\n        flaggedCategories: analysisResult?.flaggedCategories,\n        message: 'Please review this content and make a moderation decision',\n      });\n\n      // Placeholder return\n      return {\n        moderationResult: 'approved',\n        moderatedContent: '',\n      };\n    }\n\n    // Process the moderator's decision\n    switch (moderatorInput.decision) {\n      case 'approve':\n        return {\n          moderationResult: 'approved',\n          moderatedContent: analysisResult?.content || '',\n          notes: moderatorInput.notes || 'Approved by moderator',\n        };\n\n      case 'reject':\n        return {\n          moderationResult: 'rejected',\n          moderatedContent: '',\n          notes: moderatorInput.notes || 'Rejected by moderator',\n        };\n\n      case 'modify':\n        return {\n          moderationResult: 'modified',\n          moderatedContent: moderatorInput.modifiedContent || analysisResult?.content || '',\n          notes: moderatorInput.notes || 'Modified by moderator',\n        };\n\n      default:\n        return {\n          moderationResult: 'rejected',\n          moderatedContent: '',\n          notes: 'Invalid moderator decision',\n        };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running Mastra Workflow with Inquirer for Interactive Input\nDESCRIPTION: This snippet demonstrates how to run the Mastra workflow with interactive terminal input using the Inquirer library. It handles the suspension for human review and collects input from the user to resume the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Example of using the workflow with Inquirer prompts\nasync function runRecommendationWorkflow() {\n  const registeredWorkflow = mastra.getWorkflow('recommendationWorkflow');\n  const run = registeredWorkflow.createRun();\n\n  console.log('Starting product recommendation workflow...');\n  const result = await run.start({\n    triggerData: {\n      customerName: 'Jane Smith',\n    },\n  });\n\n  const isReviewStepSuspended = result.activePaths.get('reviewRecommendations')?.status === 'suspended';\n\n  // Check if workflow is suspended for human review\n  if (isReviewStepSuspended) {\n    const { customerName, recommendations, message } = result.activePaths.get('reviewRecommendations')?.suspendPayload;\n\n    console.log('\\n===================================');\n    console.log(message);\n    console.log(`Customer: ${customerName}`);\n    console.log('===================================\\n');\n\n    // Use Inquirer to collect input from the sales agent in the terminal\n    console.log('Available product recommendations:');\n    recommendations.forEach((product, index) => {\n      console.log(`${index + 1}. ${product.productName} - $${product.price.toFixed(2)}`);\n      console.log(`   ${product.description}\\n`);\n    });\n\n    // Let the agent select which products to recommend\n    const approvedProducts = await checkbox({\n      message: 'Select products to recommend to the customer:',\n      choices: recommendations.map(product => ({\n        name: `${product.productName} ($${product.price.toFixed(2)})`,\n        value: product.productId,\n      })),\n    });\n\n    // Let the agent add a personal note\n    const includeNote = await confirm({\n      message: 'Would you like to add a personal note?',\n      default: false,\n    });\n\n    let customerNote = '';\n    if (includeNote) {\n      customerNote = await input({\n        message: 'Enter your personalized note for the customer:',\n      });\n    }\n\n    // Ask if a discount should be offered\n    const offerDiscount = await confirm({\n      message: 'Offer a 10% discount to this customer?',\n      default: false,\n    });\n\n    console.log('\\nSubmitting your review...');\n\n    // Resume the workflow with the agent's input\n    const resumeResult = await run.resume({\n      stepId: 'reviewRecommendations',\n      context: {\n        approvedProducts,\n        customerNote,\n        offerDiscount,\n      },\n    });\n\n    console.log('\\n===================================');\n    console.log('Workflow completed!');\n    console.log('Email content:');\n    console.log('===================================\\n');\n    console.log(resumeResult?.results?.sendRecommendations || 'No email content generated');\n\n    return resumeResult;\n  }\n\n  return result;\n}\n\n// Invoke the workflow with interactive terminal input\nrunRecommendationWorkflow().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with Memory\nDESCRIPTION: This code snippet demonstrates how to initialize an Agent with Memory in Mastra. The Agent is configured with a name, instructions, an OpenAI model (gpt-4o), and a Memory instance.  The Memory component enables the agent to maintain context across long-term conversations using semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/semantic-recall.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"SupportAgent\",\n  instructions: \"You are a helpful support agent.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory(),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Processor (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to create a custom MemoryProcessor. The RecentMessagesProcessor keeps only the most recent messages, up to a specified limit.  It extends the MemoryProcessor class and overrides the process method to filter the messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { CoreMessage } from \"@mastra/core\";\nimport { MemoryProcessor } from \"@mastra/core/memory\";\nimport { Memory } from \"@mastra/memory\";\n\n// Simple processor that keeps only the most recent messages\nclass RecentMessagesProcessor extends MemoryProcessor {\n  private limit: number;\n\n  constructor(limit: number = 10) {\n    super();\n    this.limit = limit;\n  }\n\n  process(messages: CoreMessage[]): CoreMessage[] {\n    // Keep only the most recent messages\n    return messages.slice(-this.limit);\n  }\n}\n\n// Use the custom processor\nconst memory = new Memory({\n  processors: [\n    new RecentMessagesProcessor(5), // Keep only the last 5 messages\n    new TokenLimiter(16000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating response without hallucination (TypeScript)\nDESCRIPTION: This snippet demonstrates how to evaluate a response that accurately matches the provided context using the HallucinationMetric. It initializes the metric with a context array and uses it to measure the hallucination score of a given query and response. The expected output is a score of 0, indicating no hallucination.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/hallucination.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'iPhoneは2007年に初めて発売されました。',\n  'スティーブ・ジョブズがMacworldで発表しました。',\n  'オリジナルモデルは3.5インチの画面を持っていました。',\n];\n\nconst metric1 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = '最初のiPhoneはいつ発売されましたか？';\nconst response1 = 'iPhoneは2007年に初めて発売され、スティーブ・ジョブズがMacworldで発表しました。オリジナルのiPhoneは3.5インチの画面を備えていました。';\n\nconsole.log('例1 - ハルシネーションなし:');\nconsole.log('コンテキスト:', context1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 0, reason: '応答はコンテキストに正確に一致します。' }\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareVoice with Configuration in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the CloudflareVoice class with specific configurations for the speech model (including API key and account ID) and a default speaker. The snippet shows the basic setup required to utilize Cloudflare's text-to-speech service within the Mastra framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/cloudflare.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CloudflareVoice } from '@mastra/voice-cloudflare';\n\n// Initialize with configuration\nconst voice = new CloudflareVoice({\n  speechModel: {\n    name: '@cf/meta/m2m100-1.2b',\n    apiKey: 'your-cloudflare-api-token',\n    accountId: 'your-cloudflare-account-id'\n  },\n  speaker: 'en-US-1'  // Default voice\n});\n```\n\n----------------------------------------\n\nTITLE: Embedding a Single Text Using AI SDK in TypeScript\nDESCRIPTION: Demonstrates embedding a single text input with the `embed` function from the AI SDK. It requires an embedding model like `openai.embedding('text-embedding-3-small')`. Key parameters include the text to embed and optional settings for retries, abort signals, and additional headers. Outputs a vector embedding for the input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/embeddings.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed } from 'ai';\n\nconst result = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: \"Your text to embed\",\n  maxRetries: 2  // optional, defaults to 2\n});\n```\n\n----------------------------------------\n\nTITLE: Fetching Agent Details in Mastra AI (TypeScript)\nDESCRIPTION: This snippet illustrates how to retrieve detailed information about a specific agent using the agent instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await agent.details();\n```\n\n----------------------------------------\n\nTITLE: Function Condition in Mastra Workflow (Typescript)\nDESCRIPTION: Demonstrates how to use a function to define a condition for executing a step in a Mastra workflow. The function receives a context object, allowing access to results from previous steps.  The step `processOrder` executes only if the 'auth' step's result has a status of 'authenticated'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-condition.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: async ({ context }) => {\n    const auth = context?.getStepResult<{status: string}>(\"auth\");\n    return auth?.status === \"authenticated\";\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Complete Document Processing and Embedding Pipeline in TypeScript\nDESCRIPTION: Provides a comprehensive example of document processing and embedding generation using both OpenAI and Cohere providers. It includes document initialization, chunking, embedding generation, and storing embeddings in a vector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { cohere } from \"@ai-sdk/cohere\";\n\nimport { MDocument } from \"@mastra/rag\";\n\n// Initialize document\nconst doc = MDocument.fromText(`\n  Climate change poses significant challenges to global agriculture.\n  Rising temperatures and changing precipitation patterns affect crop yields.\n`);\n\n// Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n});\n\n// Generate embeddings with OpenAI\nconst { embeddings: openAIEmbeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\n// OR\n\n// Generate embeddings with Cohere\nconst { embeddings: cohereEmbeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n\n// Store embeddings in your vector database\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n});\n```\n\n----------------------------------------\n\nTITLE: Using Zod Schema for Structured Output in TypeScript\nDESCRIPTION: This code demonstrates how to use a Zod schema to enforce a structured output from the agent. It defines a schema for a summary and keywords, then uses the `.generate()` method with the `output` option to validate the agent's response against the schema. The schema defines the expected structure of the agent's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\n// Zodスキーマを定義する\nconst schema = z.object({\n  summary: z.string(),\n  keywords: z.array(z.string()),\n});\n\n// エージェントでスキーマを使用する\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"Please provide a summary and keywords for the following text: ...\",\n    },\n  ],\n  {\n    output: schema,\n  },\n);\n\nconsole.log(\"Structured Output:\", response.object);\n```\n\n----------------------------------------\n\nTITLE: Advanced GraphRAG usage in Typescript\nDESCRIPTION: This snippet provides an advanced example that shows how to use the GraphRAG class with custom parameters.  It initializes the GraphRAG class with a dimension of 1536 and a higher similarity threshold of 0.8. Then, it queries the graph with specific topK, randomWalkSteps, and restartProb values.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/graph-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphRag = new GraphRAG({\n  dimension: 1536,\n  threshold: 0.8  // より厳しい類似性の閾値\n});\n\n// チャンクと埋め込みからグラフを作成\ngraphRag.createGraph(documentChunks, embeddings);\n\n// カスタムパラメータでクエリ\nconst results = await graphRag.query({\n  query: queryEmbedding,\n  topK: 5,\n  randomWalkSteps: 200,\n  restartProb: 0.2\n});\n```\n\n----------------------------------------\n\nTITLE: Processing Documents into Chunks\nDESCRIPTION: Creates and processes a document into smaller chunks for embedding generation using recursive strategy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(\n  `The Impact of Climate Change on Global Agriculture...`,\n);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Pinecone in TypeScript\nDESCRIPTION: This code snippet initializes PineconeVector with an API key, creates an index, and upserts embeddings with metadata. It requires the @mastra/pinecone package and assumes you have embeddings and chunks data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PineconeVector } from '@mastra/pinecone'\n\nconst store = new PineconeVector(process.env.PINECONE_API_KEY)\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up D1Store with Workers Binding in TypeScript\nDESCRIPTION: This TypeScript code initializes a D1Store using a Workers binding. Requires a configured Worker environment with D1 binding. Optionally, a table prefix can be specified for naming consistency.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare-d1/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { D1Store } from '@mastra/cloudflare-d1';\n\nconst store = new D1Store({\n  binding: env.DB, // D1Database binding from Worker environment\n  tablePrefix: 'mastra_', // optional\n});\n```\n\n----------------------------------------\n\nTITLE: Defining RAG Workflow with Trigger Schema\nDESCRIPTION: Creates a new Workflow instance for the RAG system with a trigger schema defining the input query.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragWorkflow = new Workflow({\n  name: \"rag-workflow\",\n  triggerSchema: z.object({\n    query: z.string(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Inline Steps in a Mastra Workflow\nDESCRIPTION: This snippet demonstrates how to create steps directly within a workflow using .step() and .then() methods. It shows defining a workflow with a trigger schema, creating steps with execution logic, and linking them in sequence. Each step validates its output using Zod schemas.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/steps.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\nexport const myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow\n  .step(\n    new Step({\n      id: \"stepOne\",\n      outputSchema: z.object({\n        doubledValue: z.number(),\n      }),\n      execute: async ({ context }) => ({\n        doubledValue: context.triggerData.inputValue * 2,\n      }),\n    }),\n  )\n  .then(\n    new Step({\n      id: \"stepTwo\",\n      outputSchema: z.object({\n        incrementedValue: z.number(),\n      }),\n      execute: async ({ context }) => {\n        if (context.steps.stepOne.status !== \"success\") {\n          return { incrementedValue: 0 };\n        }\n\n        return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 };\n      },\n    }),\n  ).commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { myWorkflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Agent Stream Call with Resource and Thread IDs\nDESCRIPTION: This code demonstrates how to call the agent's stream method with resourceId and threadId.  These IDs are essential for associating the message with the correct memory thread. The resourceId identifies the user or entity owning the thread, and the threadId identifies the specific conversation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myMemoryAgent.stream(\"Hello, my name is Alice.\", {\n  resourceId: \"user_alice\",\n  threadId: \"conversation_123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Generate and Store Embeddings (TypeScript)\nDESCRIPTION: Generates embeddings for each chunk of text and stores them in the vector database.  It creates a vector store index and upserts the embeddings with associated metadata (original text and source information).  Dependencies include @ai-sdk/openai, ai, and references the `mastra` instance. The `showLineNumbers{23}` highlights line 23 of the code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Generate embeddings\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\n// Get the vector store instance from Mastra\nconst vectorStore = mastra.getVector('pgVector');\n\n// Create an index for our paper chunks\nawait vectorStore.createIndex({\n  indexName: 'papers',\n  dimension: 1536,\n});\n\n// Store embeddings\nawait vectorStore.upsert({\n  indexName: 'papers',\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({\n    text: chunk.text,\n    source: 'transformer-paper'\n  })),\n});\n```\n\n----------------------------------------\n\nTITLE: Using Variables in Loops in Mastra Workflow (TypeScript)\nDESCRIPTION: Demonstrates how to pass variables between iterations within a `while` loop in a Mastra workflow. This example shows an increment step that updates a counter, and the updated value is passed to the next iteration of the loop. Requires `@mastra/core` and `zod`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// カウンターをインクリメントするステップ\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // 前回のイテレーションからの値\n    prevValue: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // 更新されたカウンターの値\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { prevValue = 0 } = context.inputData;\n    return { updatedCounter: prevValue + 1 };\n  },\n});\n\nconst workflow = new Workflow({\n  name: 'counter'\n});\n\nworkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      // カウンターが10未満の間続行\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) < 10;\n    },\n    incrementStep,\n    {\n      // 次のイテレーションに前回の値を渡す\n      prevValue: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  );\n```\n\n----------------------------------------\n\nTITLE: Looping with Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Shows how to use `.while()` loops with nested workflows.  The nested workflow will execute repeatedly as long as the specified condition is true.  The example shows a loop condition based on the result of the nested workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow\n  .step(firstStep)\n  .while(\n    ({ context }) =>\n      context.getStepResult(\"nested-workflow\").output.results.someField ===\n      \"someValue\",\n    nestedWorkflow,\n  )\n  .step(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Configuring and Executing Mastra Multi-Agent Workflow\nDESCRIPTION: This code configures the workflow with a trigger schema, adds the copywriter and editor steps sequentially, and executes the workflow with a sample topic. It demonstrates how to create and start a workflow run in Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    topic: z.string(),\n  }),\n});\n\n// Run steps sequentially.\nmyWorkflow.step(copywriterStep).then(editorStep).commit();\n\nconst { runId, start } = myWorkflow.createRun();\n\nconst res = await start({\n  triggerData: { topic: \"React JavaScript frameworks\" },\n});\nconsole.log(\"Results: \", res.results);\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Snapshot Metadata\nDESCRIPTION: Example of adding custom metadata when suspending a workflow, providing context that can be used when resuming. The metadata is saved with the snapshot and available upon resumption.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/snapshots.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nawait suspend({\n  reason: \"顧客の承認待ち\",\n  requiredApprovers: [\"manager\", \"finance\"],\n  requestedBy: currentUser,\n  urgency: \"high\",\n  expires: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000),\n});\n```\n\n----------------------------------------\n\nTITLE: Processing Initial Documents\nDESCRIPTION: This code snippet processes the initial documents by chunking them, creating embeddings, and storing them in the vector store. It uses the `doc.chunk` method to split the document into chunks, `embedMany` to create embeddings, and `vectorStore.upsert` to store the embeddings and metadata in the PgVector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n  separator: \"\\n\",\n});\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Saving Messages to a Thread\nDESCRIPTION: This snippet saves multiple messages associated with a specific thread. It utilizes the saveMessages method, which accepts an array of message objects with details including id, threadId, role, type, content, and timestamps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nawait store.saveMessages([\n  {\n    id: 'msg-789',\n    threadId: 'thread-123',\n    role: 'user',\n    type: 'text',\n    content: [{ type: 'text', text: 'Hello' }],\n    createdAt: new Date(),\n  },\n]);\n```\n\n----------------------------------------\n\nTITLE: Using PromptAlignmentMetric\nDESCRIPTION: Demonstrates basic usage of the PromptAlignmentMetric in TypeScript. It configures the model, defines instructions, creates a metric instance, and measures the alignment score for a given input and output. The example prints the score and the reasoning behind the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/prompt-alignment.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PromptAlignmentMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst instructions = [\n  \"Start sentences with capital letters\",\n  \"End each sentence with a period\",\n  \"Use present tense\",\n];\n\nconst metric = new PromptAlignmentMetric(model, {\n  instructions,\n  scale: 1,\n});\n\nconst result = await metric.measure(\n  \"describe the weather\",\n  \"The sun is shining. Clouds float in the sky. A gentle breeze blows.\",\n);\n\nconsole.log(result.score); // Alignment score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Basic Workflow RuntimeContext Usage in Mastra (TypeScript)\nDESCRIPTION: This snippet demonstrates the basic usage of Mastra's RuntimeContext to pass runtime configuration variables to workflows. It includes defining the runtimeContext's type structure, setting a value, and starting the workflow execution with the runtimeContext.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/runtime-variables.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { runId, start, resume } = myWorkflow.createRun();\n\n// Define your runtimeContext's type structure\ntype WorkflowRuntimeContext = {\n  multiplier: number;\n};\n\nconst runtimeContext = new RuntimeContext<WorkflowRuntimeContext>();\nruntimeContext.set(\"multiplier\", 5);\n\n// Start the workflow execution with runtimeContext\nawait start({\n  triggerData: { inputValue: 45 },\n  runtimeContext,\n});\n```\n\n----------------------------------------\n\nTITLE: Executing RAG Queries with Re-ranking\nDESCRIPTION: Demonstrates query execution with the RAG system, showing different query examples and response handling.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = 'explain technical trading analysis';\nconst answerOne = await agent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'explain trading card valuation';\nconst answerTwo = await agent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'how do you analyze market resistance';\nconst answerThree = await agent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Applying Moderation Actions in Mastra Workflow (TypeScript)\nDESCRIPTION: This step applies the final moderation actions based on the results of content analysis and moderation. It creates an audit log containing information about the original content, moderation result, AI score, and timestamp. Based on the moderation result (approved, modified, or rejected), it returns the final status, content (if applicable), and the audit log.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Apply moderation actions\nconst applyModeration = new Step({\n  id: 'applyModeration',\n  outputSchema: z.object({\n    finalStatus: z.string(),\n    content: z.string().optional(),\n    auditLog: z.object({\n      originalContent: z.string(),\n      moderationResult: z.string(),\n      aiScore: z.number(),\n      timestamp: z.string(),\n    }),\n  }),\n  execute: async ({ context }) => {\n    const analysisResult = context.getStepResult(analyzeContent);\n    const moderationResult = context.getStepResult(moderateContent);\n\n    // Create audit log\n    const auditLog = {\n      originalContent: analysisResult?.content || '',\n      moderationResult: moderationResult?.moderationResult || 'unknown',\n      aiScore: analysisResult?.aiAnalysisScore || 0,\n      timestamp: new Date().toISOString(),\n    };\n\n    // Apply moderation action\n    switch (moderationResult?.moderationResult) {\n      case 'approved':\n        return {\n          finalStatus: 'Content published',\n          content: moderationResult.moderatedContent,\n          auditLog,\n        };\n\n      case 'modified':\n        return {\n          finalStatus: 'Content modified and published',\n          content: moderationResult.moderatedContent,\n          auditLog,\n        };\n\n      case 'rejected':\n        return {\n          finalStatus: 'Content rejected',\n          auditLog,\n        };\n\n      default:\n        return {\n          finalStatus: 'Error in moderation process',\n          auditLog,\n        };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating mixed recall response using Contextual Recall metric in TypeScript\nDESCRIPTION: This example shows how to evaluate a response that includes some context information using the Contextual Recall metric. It sets up a new context, creates a metric instance, and measures the recall score for a partially correct response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Python is a high-level programming language.',\n  'Python emphasizes code readability.',\n  'Python supports multiple programming paradigms.',\n  'Python is widely used in data science.',\n];\n\nconst metric2 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'What are Python\\'s key characteristics?';\nconst response2 = 'Python is a high-level programming language. It is also a type of snake.';\n\nconsole.log('Example 2 - Mixed Recall:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'Only half of the output is supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: TTS with PlayAI Voice Agent\nDESCRIPTION: This code demonstrates how to use an Agent with PlayAI voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using PlayAI's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new PlayAIVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Workflow Calling Agent Example (Mastra)\nDESCRIPTION: This TypeScript snippet demonstrates how to create a workflow in Mastra that calls an AI agent (penguin) to process a message. The agent is configured with specific instructions and a language model. The workflow defines a step that retrieves the agent, passes the input message to the agent for generation, and returns the generated response. It includes setting up the agent, defining the workflow with a trigger schema, creating a step to execute the agent, committing the workflow, initializing Mastra, creating a run, and logging the results. Dependencies include `@ai-sdk/openai`, `@mastra/core`, and `zod`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/calling-agent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst penguin = new Agent({\n  name: \"agent skipper\",\n  instructions: `You are skipper from penguin of madagascar, reply as that`,\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst newWorkflow = new Workflow({\n  name: \"pass message to the workflow\",\n  triggerSchema: z.object({\n    message: z.string(),\n  }),\n});\n\nconst replyAsSkipper = new Step({\n  id: \"reply\",\n  outputSchema: z.object({\n    reply: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    const skipper = mastra?.getAgent('penguin');\n\n    const res = await skipper?.generate(\n      context?.triggerData?.message,\n    );\n    return { reply: res?.text || \"\" };\n  },\n});\n\nnewWorkflow.step(replyAsSkipper);\nnewWorkflow.commit();\n\nconst mastra = new Mastra({\n  agents: { penguin },\n  workflows: { newWorkflow },\n});\n\nconst { runId, start } = await mastra.getWorkflow(\"newWorkflow\").createRun();\n\nconst runResult = await start({\n  triggerData: { message: \"Give me a run down of the mission to save private\" },\n});\n\nconsole.log(runResult.results);\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow Programmatically in Mastra (TypeScript)\nDESCRIPTION: This code demonstrates how to execute a Mastra workflow programmatically, retrieving the workflow, creating a run, and starting it with trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\n// Get the workflow\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { runId, start } = myWorkflow.createRun();\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n----------------------------------------\n\nTITLE: Initializing Document Chunker Tool in TypeScript\nDESCRIPTION: The snippet demonstrates how to import and use the `createDocumentChunkerTool` from the Mastra library to split a document into chunks. It includes setting up a document with metadata, configuring chunking parameters like strategy, size, overlap, and separator, and executing the chunker to get the chunks. Prerequisite is the `@mastra/rag` package, and inputs are a document and optional chunking parameters. Outputs are an array of document chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/document-chunker-tool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createDocumentChunkerTool, MDocument } from \"@mastra/rag\";\n\nconst document = new MDocument({\n  text: \"Your document content here...\",\n  metadata: { source: \"user-manual\" }\n});\n\nconst chunker = createDocumentChunkerTool({\n  doc: document,\n  params: {\n    strategy: \"recursive\",\n    size: 512,\n    overlap: 50,\n    separator: \"\\n\"\n  }\n});\n\nconst { chunks } = await chunker.execute();\n```\n\n----------------------------------------\n\nTITLE: Initializing Toxicity Metric with OpenAI Client\nDESCRIPTION: This TypeScript snippet initializes the `ToxicityMetric` with an OpenAI client configured to use the `gpt-4o-mini` model. This metric will then be used to evaluate the toxicity of different responses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ToxicityMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Dynamic Workflow in TypeScript with Mastra\nDESCRIPTION: Demonstrates the basic implementation of a dynamic workflow creator step that generates and executes a new workflow at runtime. Includes type checking, error handling, and workflow execution patterns.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/dynamic-workflows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra, Step, Workflow } from '@mastra/core';\nimport { z } from 'zod';\n\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === 'object' && mastra instanceof Mastra;\n};\n\n// Step that creates and runs a dynamic workflow\nconst createDynamicWorkflow = new Step({\n  id: 'createDynamicWorkflow',\n  outputSchema: z.object({\n    dynamicWorkflowResult: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error('Mastra instance not available');\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error('Invalid Mastra instance');\n    }\n\n    const inputData = context.triggerData.inputData;\n\n    // Create a new dynamic workflow\n    const dynamicWorkflow = new Workflow({\n      name: 'dynamic-workflow',\n      mastra, // Pass the mastra instance to the new workflow\n      triggerSchema: z.object({\n        dynamicInput: z.string(),\n      }),\n    });\n\n    // Define steps for the dynamic workflow\n    const dynamicStep = new Step({\n      id: 'dynamicStep',\n      execute: async ({ context }) => {\n        const dynamicInput = context.triggerData.dynamicInput;\n        return {\n          processedValue: `Processed: ${dynamicInput}`,\n        };\n      },\n    });\n\n    // Build and commit the dynamic workflow\n    dynamicWorkflow.step(dynamicStep).commit();\n\n    // Create a run and execute the dynamic workflow\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        dynamicInput: inputData,\n      },\n    });\n\n    let dynamicWorkflowResult;\n\n    if (result.results['dynamicStep']?.status === 'success') {\n      dynamicWorkflowResult = result.results['dynamicStep']?.output.processedValue;\n    } else {\n      throw new Error('Dynamic workflow failed');\n    }\n\n    // Return the result from the dynamic workflow\n    return {\n      dynamicWorkflowResult,\n    };\n  },\n});\n\n// Main workflow that uses the dynamic workflow creator\nconst mainWorkflow = new Workflow({\n  name: 'main-workflow',\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n  mastra: new Mastra(),\n});\n\nmainWorkflow.step(createDynamicWorkflow).commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  workflows: { mainWorkflow },\n});\n\nconst run = mainWorkflow.createRun();\nconst result = await run.start({\n  triggerData: {\n    inputData: 'test',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Cat Expert AI Agent with System Prompt in TypeScript\nDESCRIPTION: Creates an AI agent specialized in cat-related information using Mastra. The agent is configured with specific instructions and a custom tool to fetch verified cat facts from an external API. It uses OpenAI's GPT-4 model and implements input validation using Zod schema.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/system-prompt.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\n\nimport { z } from \"zod\";\n\nconst instructions = `You are a helpful cat expert assistant. When discussing cats, you should always include an interesting cat fact.\n\n  Your main responsibilities:\n  1. Answer questions about cats\n  2. Use the catFact tool to provide verified cat facts\n  3. Incorporate the cat facts naturally into your responses\n\n  Always use the catFact tool at least once in your responses to ensure accuracy.`;\n\nconst getCatFact = async () => {\n  const { fact } = (await fetch(\"https://catfact.ninja/fact\").then((res) =>\n    res.json(),\n  )) as {\n    fact: string;\n  };\n\n  return fact;\n};\n\nconst catFact = createTool({\n  id: \"Get cat facts\",\n  inputSchema: z.object({}),\n  description: \"Fetches cat facts\",\n  execute: async () => {\n    console.log(\"using tool to fetch cat fact\");\n    return {\n      catFact: await getCatFact(),\n    };\n  },\n});\n\nconst catOne = new Agent({\n  name: \"cat-one\",\n  instructions: instructions,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    catFact,\n  },\n});\n\nconst result = await catOne.generate(\"Tell me a cat fact\");\n\nconsole.log(result.text);\n```\n\n----------------------------------------\n\nTITLE: Configure Mastra Instance and Vector Store (TypeScript)\nDESCRIPTION: Initializes a Mastra instance with a PgVector store and the research agent. Requires a PostgreSQL connection string from the environment variables. Dependencies include @mastra/core and @mastra/pg.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { PgVector } from '@mastra/pg';\n\nimport { researchAgent } from './agents/researchAgent';\n\n// Initialize Mastra instance\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\nexport const mastra = new Mastra({\n  agents: { researchAgent },\n  vectors: { pgVector },\n});\n```\n\n----------------------------------------\n\nTITLE: Telemetry Configuration Options (TypeScript)\nDESCRIPTION: This TypeScript code defines the type `OtelConfig`, outlining the available configuration options for telemetry within Mastra. It includes properties for service name, enabling/disabling telemetry, controlling trace sampling, and specifying the telemetry data export settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/tracing.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntype OtelConfig = {\n  // Name to identify your service in traces (optional)\n  serviceName?: string;\n\n  // Enable/disable telemetry (defaults to true)\n  enabled?: boolean;\n\n  // Control how many traces are sampled\n  sampling?: {\n    type: \"ratio\" | \"always_on\" | \"always_off\" | \"parent_based\";\n    probability?: number; // For ratio sampling\n    root?: {\n      probability: number; // For parent_based sampling\n    };\n  };\n\n  // Where to send telemetry data\n  export?: {\n    type: \"otlp\" | \"console\";\n    endpoint?: string;\n    headers?: Record<string, string>;\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Full Word Inclusion Example Typescript\nDESCRIPTION: Demonstrates a usage example where all words are present in the output. It initializes a `WordInclusionMetric` with a set of fruits, provides an input and an output containing all specified fruits, and then measures the inclusion, logging the resulting score and information about total and matched words.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/word-inclusion.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst words1 = ['apple', 'banana', 'orange'];\nconst metric1 = new WordInclusionMetric(words1);\n\nconst input1 = 'List some fruits';\nconst output1 = 'Here are some fruits: apple, banana, and orange.';\n\nconst result1 = await metric1.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: result1.info,\n});\n// Example Output:\n// Metric Result: { score: 1, info: { totalWords: 3, matchedWords: 3 } }\n```\n\n----------------------------------------\n\nTITLE: Adding Memory Instance to Agent\nDESCRIPTION: This code demonstrates how to integrate the created Memory instance (either in text-stream or tool-call mode) into an Agent. The `memory` property of the Agent configuration is assigned the Memory instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Memory agent\",\n  instructions: \"You are a helpful AI assistant.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory, // or toolCallMemory\n});\n```\n\n----------------------------------------\n\nTITLE: Executing RAG Workflow\nDESCRIPTION: Demonstrates how to execute the RAG workflow with a sample query and process the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nconst query = 'What are the main adaptation strategies for farmers?';\n\nconsole.log('\\nQuery:', query);\nconst prompt = `\n    Please answer the following question:\n    ${query}\n\n    Please base your answer only on the context provided in the tool. If the context doesn't contain enough information to fully answer the question, please state that explicitly.\n    `;\n\nconst { runId, start } = ragWorkflow.createRun();\n\nconsole.log('Run:', runId);\n\nconst workflowResult = await start({\n  triggerData: {\n    query: prompt,\n  },\n});\nconsole.log('\\nThought Process:');\nconsole.log(workflowResult.results);\n```\n\n----------------------------------------\n\nTITLE: Error Handling with run.watch() in TypeScript\nDESCRIPTION: This snippet demonstrates how to handle errors during a Mastra workflow execution using `run.watch()`. It checks the status of the 'processDocument' step and logs an error message if the step fails. This enables implementing error recovery logic based on the workflow's state.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/watch.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(({results, activePaths}) => {\n  if (activePaths.get('processDocument')?.status === 'failed') {\n    console.error('Document processing failed:', results['processDocument'].error);\n    // Implement error recovery logic\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Conditional Workflow with Reference - TypeScript\nDESCRIPTION: This example demonstrates a reference-based conditional workflow in Mastra. It uses the `ref` and `query` properties to define a condition based on the output of a previous step.  The workflow branches based on whether the 'value' from the 'startStep' is greater than or equal to 10. Requires `@mastra/core` and `zod` dependencies, and the `startStep`, `highValueStep`, and `finalStep` definitions from the previous example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/conditional-branching.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// 関数の代わりに参照ベースの条件を使用\nconditionalWorkflow\n  .step(startStep)\n  .if({\n    ref: { step: startStep, path: 'value' },\n    query: { $gte: 10 }, // 条件: 値が10以上\n  })\n  .then(highValueStep)\n  .then(finalStep)\n  .else()\n  .then(lowValueStep)\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Registering an Agent with Mastra (TypeScript)\nDESCRIPTION: This snippet shows how to register an agent with Mastra using the `Mastra` class from `@mastra/core`. It imports both the `Mastra` class and the previously defined `myAgent`, then instantiates a `Mastra` instance with the agent registered within the `agents` property. This enables logging and access to tools and integrations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { myAgent } from \"./agents\";\n\nexport const mastra = new Mastra({\n  agents: { myAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Real-time Speech-to-Speech with OpenAI\nDESCRIPTION: Implements real-time voice conversation capabilities using OpenAI's streaming voice API. Handles continuous microphone input and provides immediate voice responses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { playAudio, getMicrophoneStream } from '@mastra/node-audio';\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIRealtimeVoice(),\n});\n\n// Listen for agent audio responses\nvoiceAgent.voice.on('speaker', ({ audio }) => {\n  playAudio(audio);\n});\n\n// Initiate the conversation\nawait voiceAgent.voice.speak('How can I help you today?');\n\n// Send continuous audio from the microphone\nconst micStream = getMicrophoneStream();\nawait voiceAgent.voice.send(micStream);\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAIVoice with Specific Configuration | TypeScript\nDESCRIPTION: Initializes the PlayAIVoice class with a specific speech model (PlayDialog) and default speaker (Angelo). It uses the `PLAYAI_API_KEY` and `PLAYAI_USER_ID` environment variables for authentication but can be overridden in the configuration object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/playai.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\n// Initialize with default configuration\nconst voice = new PlayAIVoice({\n  speechModel: {\n    name: 'PlayDialog',\n    apiKey: process.env.PLAYAI_API_KEY,\n    userId: process.env.PLAYAI_USER_ID\n  },\n  speaker: 'Angelo'  // Default voice\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Abort Signals in Tool Execution (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to handle abort signals during tool execution.  The `execute` function receives an `abortSignal` as the second parameter, which can be forwarded to asynchronous operations like `fetch` to cancel them if the agent's execution is aborted. This allows for graceful cancellation of long-running tasks within tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst agent = new Agent({\n  name: \"Weather agent\",\n  tools: {\n    weather: createTool({\n      id: \"Get Weather Information\",\n      description: \"Get the weather in a location\",\n      inputSchema: z.object({ location: z.string() }),\n      execute: async ({ context: { location } }, { abortSignal }) => {\n        return fetch(\n          `https://api.weatherapi.com/v1/current.json?q=${location}`,\n          { signal: abortSignal }, // forward the abort signal to fetch\n        );\n      },\n    }),\n  },\n});\n\nconst result = await agent.generate(\"What is the weather in San Francisco?\", {\n  abortSignal: myAbortSignal, // signal that will be forwarded to tools\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Tools with Runtime Context Variables in Mastra (TypeScript)\nDESCRIPTION: Shows how to create tools that access runtime context variables in Mastra. It uses `createTool` from `@mastra/core/tools` and `zod` for input schema validation. The `execute` function demonstrates type-safe access to runtime context variables via `runtimeContext.get(\"temperature-scale\")` and uses it to fetch weather information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/runtime-variables.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const weatherTool = createTool({\n  id: \"getWeather\",\n  description: \"Get the current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"The location to get weather for\"),\n  }),\n  execute: async ({ context, runtimeContext }) => {\n    // Type-safe access to runtimeContext variables\n    const temperatureUnit = runtimeContext.get(\"temperature-scale\");\n\n    const weather = await fetchWeather(context.location, {\n      temperatureUnit,\n    });\n\n    return { result: weather };\n  },\n});\n\nasync function fetchWeather(\n  location: string,\n  { temperatureUnit }: { temperatureUnit: \"celsius\" | \"fahrenheit\" },\n): Promise<WeatherResponse> {\n  // Implementation of weather API call\n  const response = await weatherApi.fetch(location, temperatureUnit);\n\n  return {\n    location,\n    temperature: \"72°F\",\n    conditions: \"Sunny\",\n    unit: temperatureUnit,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Nested Workflows with TypeScript\nDESCRIPTION: This code demonstrates the creation of nested workflows using TypeScript. It defines schemas for workflows and maps data between them using a consistent pattern for variable handling. Dependencies include the zod library for schema definitions. Inputs are typically city names and outputs are activity results for each city. Key functionalities include data mapping, workflow steps definition, and result aggregation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_8\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst workflowA = new Workflow({\n  name: \"workflow-a\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst workflowB = new Workflow({\n  name: \"workflow-b\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst weatherWorkflow = new Workflow({\n  name: \"weather-workflow\",\n  triggerSchema: z.object({\n    cityA: z.string().describe(\"The city to get the weather for\"),\n    cityB: z.string().describe(\"The city to get the weather for\"),\n  }),\n  result: {\n    schema: z.object({\n      activitiesA: z.string(),\n      activitiesB: z.string(),\n    }),\n    mapping: {\n      activitiesA: {\n        step: workflowA,\n        path: \"result.activities\",\n      },\n      activitiesB: {\n        step: workflowB,\n        path: \"result.activities\",\n      },\n    },\n  },\n})\n  .step(workflowA, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityA\",\n      },\n    },\n  })\n  .step(workflowB, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityB\",\n      },\n    },\n  });\n\nweatherWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Gender Bias Example in TypeScript\nDESCRIPTION: Demonstrates evaluation of a response with high gender bias using the Bias metric. It includes query, response, and result logging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What makes someone a good leader?';\nconst response1 =\n  'Men naturally make better leaders due to their assertiveness and decisiveness. Women tend to be too emotional and collaborative, which can slow down decision-making processes.';\n\nconsole.log('Example 1 - High Bias:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response contains strong gender stereotypes and assumptions about leadership abilities.' }\n```\n\n----------------------------------------\n\nTITLE: Defining the rerank Function in TypeScript\nDESCRIPTION: The `rerank` function in TypeScript utilizes vector search results, a search query, a language model, and optional reranking options to return a promised array of ranked results. It integrates various models from Vercel AI SDK including OpenAI and Cohere, and leverages semantic relevance, vector similarity, and positional scoring in its reranking process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/rerank.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction rerank(\n  results: QueryResult[],\n  query: string,\n  modelConfig: ModelConfig,\n  options?: RerankerFunctionOptions\n): Promise<RerankResult[]>\n```\n\n----------------------------------------\n\nTITLE: Example with Filters in Vector Query Tool\nDESCRIPTION: This TypeScript example demonstrates how to enable filters when creating a vector query tool with Mastra. By setting `enableFilters` to true, the tool processes the user's query requirements into metadata filters, enhancing the search capabilities beyond simple semantic matches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  enableFilters: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Using RuntimeContext with REST API in Mastra (TypeScript)\nDESCRIPTION: This snippet illustrates how to integrate Mastra's RuntimeContext with a REST API to dynamically set a multiplier value from an HTTP header. It showcases middleware implementation to parse, validate, and set the multiplier value in the runtimeContext before executing the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/runtime-variables.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { workflow as myWorkflow } from \"./workflows\";\n\n// Define runtimeContext type with clear, descriptive types\ntype WorkflowRuntimeContext = {\n  multiplier: number;\n};\n\nexport const mastra = new Mastra({\n  workflows: {\n    myWorkflow,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const multiplier = c.req.header(\"x-multiplier\");\n        const runtimeContext = c.get<WorkflowRuntimeContext>(\"runtimeContext\");\n\n        // Parse and validate the multiplier value\n        const multiplierValue = parseInt(multiplier || \"1\", 10);\n        if (isNaN(multiplierValue)) {\n          throw new Error(\"Invalid multiplier value\");\n        }\n\n        runtimeContext.set(\"multiplier\", multiplierValue);\n\n        await next(); // Don't forget to call next()\n      },\n    ],\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Index in ChromaVector\nDESCRIPTION: Creates a new index in the ChromaDB, specifying the index name, vector dimension, and optional distance metric for similarity search.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to create\",\n    },\n    {\n      name: \"dimension\",\n      type: \"number\",\n      description: \"Vector dimension (must match your embedding model)\",\n    },\n    {\n      name: \"metric\",\n      type: \"'cosine' | 'euclidean' | 'dotproduct'\",\n      isOptional: true,\n      defaultValue: \"cosine\",\n      description: \"Distance metric for similarity search\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Importing and Configuring OtelConfig in Mastra TypeScript\nDESCRIPTION: This TypeScript code snippet demonstrates how to configure the OtelConfig object for controlling OpenTelemetry instrumentation, tracing, and exporting within Mastra. It includes setup for service name, sampling strategy, and export endpoint, with authentication headers. Dependencies include the Mastra library and a running instance configured to accept OpenTelemetry settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/otel-config.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from 'mastra';\n\nconst otelConfig: OtelConfig = {\n  serviceName: 'my-awesome-service',\n  enabled: true,\n  sampling: {\n    type: 'ratio',\n    probability: 0.5,\n  },\n  export: {\n    type: 'otlp',\n    endpoint: 'https://otel-collector.example.com/v1/traces',\n    headers: {\n      Authorization: 'Bearer YOUR_TOKEN_HERE',\n    },\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Using Variables in Loops in Mastra Workflow\nDESCRIPTION: Demonstrates how to use variables in 'while' and 'until' loops in a Mastra workflow, useful for passing data between iterations or from outside steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Step that increments a counter\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // Previous value from last iteration\n    prevValue: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { prevValue = 0 } = context.inputData;\n    return { updatedCounter: prevValue + 1 };\n  },\n});\n\nconst workflow = new Workflow({\n  name: 'counter'\n});\n\nworkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      // Continue while counter is less than 10\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) < 10;\n    },\n    incrementStep,\n    {\n      // Pass previous value to next iteration\n      prevValue: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  );\n```\n\n----------------------------------------\n\nTITLE: Configuring Answer Relevancy Metric with Custom Parameters in TypeScript\nDESCRIPTION: Set up the Answer Relevancy metric with custom parameters including uncertainty weight and scale for the final score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new AnswerRelevancyMetric(openai('gpt-4o-mini'), {\n  uncertaintyWeight: 0.3, // Weight for 'unsure' verdicts\n  scale: 1, // Scale for the final score\n});\n```\n\n----------------------------------------\n\nTITLE: Building and Running Content Workflow in Mastra - TypeScript\nDESCRIPTION: This snippet creates a content generation workflow and registers it within the Mastra framework. It demonstrates how to handle the workflow execution and manage state transitions during the content generation process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Build the workflow\nconst contentWorkflow = new Workflow({\n  name: 'content-generation-workflow',\n  triggerSchema: z.object({ input: z.string() }),\n});\n\ncontentWorkflow\n  .step(getUserInput)\n  .then(promptAgent)\n  .then(evaluateTone)\n  .then(improveResponse)\n  .then(evaluateImproved)\n  .commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { contentWorkflow },\n});\n\n// Helper functions (simulated)\nfunction generateInitialDraft(input: string = '') {\n  // Simulate AI generating content\n  return {\n    content: `Generated content based on: ${input}`,\n    confidenceScore: 0.6, // Simulate low confidence to trigger suspension\n  };\n}\n\nfunction enhanceWithGuidance(content: string = '', guidance: string = '') {\n  return `${content} (Enhanced with guidance: ${guidance})`;\n}\n\nfunction makeMinorImprovements(content: string = '') {\n  return `${content} (with minor improvements)`;\n}\n\nfunction calculateToneScore(_: string = '') {\n  return 0.7; // Simulate a score that will trigger suspension\n}\n\nfunction calculateCompletenessScore(_: string = '') {\n  return 0.9;\n}\n\n// Usage example\nasync function runWorkflow() {\n  const workflow = mastra.getWorkflow('contentWorkflow');\n  const { runId, start } = workflow.createRun();\n\n  let finalResult: any;\n\n  // Start the workflow\n  const initialResult = await start({\n    triggerData: { input: 'Create content about sustainable energy' },\n  });\n\n  console.log('Initial workflow state:', initialResult.results);\n\n  const promptAgentStepResult = initialResult.activePaths.get('promptAgent');\n\n  // Check if promptAgent step is suspended\n  if (promptAgentStepResult?.status === 'suspended') {\n    console.log('Workflow suspended at promptAgent step');\n    console.log('Suspension payload:', promptAgentStepResult?.suspendPayload);\n\n    // Resume with human guidance\n    const resumeResult1 = await workflow.resume({\n      runId,\n      stepId: 'promptAgent',\n      context: {\n        guidance: 'Focus more on solar and wind energy technologies',\n      },\n    });\n\n    console.log('Workflow resumed and continued to next steps');\n\n    let improveResponseResumeAttempts = 0;\n    let improveResponseStatus = resumeResult1?.activePaths.get('improveResponse')?.status;\n\n    // Check if improveResponse step is suspended\n    while (improveResponseStatus === 'suspended') {\n      console.log('Workflow suspended at improveResponse step');\n      console.log('Suspension payload:', resumeResult1?.activePaths.get('improveResponse')?.suspendPayload);\n\n      const improvedContent =\n        improveResponseResumeAttempts < 3\n          ? undefined\n          : 'Completely revised content about sustainable energy focusing on solar and wind technologies';\n\n      // Resume with human improvements\n      finalResult = await workflow.resume({\n        runId,\n        stepId: 'improveResponse',\n        context: {\n          improvedContent,\n          resumeAttempts: improveResponseResumeAttempts,\n        },\n      });\n\n      improveResponseResumeAttempts =\n        finalResult?.activePaths.get('improveResponse')?.suspendPayload?.resumeAttempts ?? 0;\n      improveResponseStatus = finalResult?.activePaths.get('improveResponse')?.status;\n\n      console.log('Improved response result:', finalResult?.results);\n    }\n  }\n  return finalResult;\n}\n\n// Run the workflow\nconst result = await runWorkflow();\nconsole.log('Workflow completed');\nconsole.log('Final workflow result:', result);\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retries with Step Override in Mastra\nDESCRIPTION: This code snippet demonstrates how to use workflow-level retries in conjunction with step-level overrides in a Mastra workflow. It shows how to set a default retry configuration for the workflow and then override it for specific steps, including disabling retries for one step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-retries.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\n\n// Create a workflow with default retry configuration\nconst workflow = new Workflow({\n  name: 'multi-retry-workflow',\n  retryConfig: {\n    attempts: 2,  // All steps will retry twice by default\n    delay: 1000,  // With a 1-second delay\n  },\n});\n\n// This step uses the workflow's default retry configuration\nconst standardStep = new Step({\n  id: 'standardStep',\n  execute: async () => {\n    // Some operation that might fail\n  },\n});\n\n// This step overrides the workflow's retry configuration\nconst criticalStep = new Step({\n  id: 'criticalStep',\n  execute: async () => {\n    // Critical operation that needs more retry attempts\n  },\n  retryConfig: {\n    attempts: 5,  // Override with 5 retry attempts\n    delay: 5000,  // And a longer 5-second delay\n  },\n});\n\n// This step disables retries\nconst noRetryStep = new Step({\n  id: 'noRetryStep',\n  execute: async () => {\n    // Operation that should not retry\n  },\n  retryConfig: {\n    attempts: 0,  // Explicitly disable retries\n  },\n});\n\nworkflow\n  .step(standardStep)\n  .then(criticalStep)\n  .then(noRetryStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Implementing Research Assistant Agent in TypeScript\nDESCRIPTION: Creates a RAG-enabled research assistant agent using Vector Query Tool and GPT-4o-mini for processing queries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { createVectorQueryTool } from '@mastra/rag';\n\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'papers',\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nexport const researchAgent = new Agent({\n  name: 'Research Assistant',\n  instructions: \n    `You are a helpful research assistant that analyzes academic papers and technical documents.\n    Use the provided vector query tool to find relevant information from your knowledge base, \n    and provide accurate, well-supported answers based on the retrieved content.\n    Focus on the specific content available in the tool and acknowledge if you cannot find sufficient information to answer a question.\n    Base your responses only on the content provided, not on general knowledge.`,\n  model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Ask About Specialty Step - TypeScript\nDESCRIPTION: Defines a step to ask a technical candidate about how they got into their specialty. It retrieves the candidate's information, crafts a question about their specialty using the resume text as context, and generates a question string. It relies on the `gatherCandidateInfo` step and returns an object containing the generated question.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ninterface CandidateInfo {\n  candidateName: string;\n  isTechnical: boolean;\n  specialty: string;\n  resumeText: string;\n}\n\nconst askAboutSpecialty = new Step({\n  id: \"askAboutSpecialty\",\n  outputSchema: z.object({\n    question: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const candidateInfo = context?.getStepResult<CandidateInfo>(\n      \"gatherCandidateInfo\",\n    );\n\n    const prompt = `\n          You are a recruiter. Given the resume below, craft a short question\n          for ${candidateInfo?.candidateName} about how they got into \"${candidateInfo?.specialty}\".\n          Resume: ${candidateInfo?.resumeText}\n        `;\n    const res = await recruiter.generate(prompt);\n\n    return { question: res?.text?.trim() || \"\" };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Conditional Branching using Reference Condition in TypeScript\nDESCRIPTION: This snippet shows how to use a reference-based condition with comparison operators to create a conditional branch. It uses a query object with the `$lt` operator to check if a value from a previous step is less than 10.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/if.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if({\n    ref: { step: startStep, path: 'value' },\n    query: { $lt: 10 }, // Execute \"if\" branch when value is less than 10\n  })\n  .then(ifBranchStep)\n  .else()\n  .then(elseBranchStep);\n```\n\n----------------------------------------\n\nTITLE: Performing Graph-Based Queries with Mastra Agent\nDESCRIPTION: This code demonstrates how to use the configured Mastra agent to perform various graph-based queries on the processed and embedded document data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = \"What are the direct and indirect effects of early railway decisions on Riverdale Heights' current state?\";\nconst answerOne = await ragAgent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'How have changes in transportation infrastructure affected different generations of local businesses and community spaces?';\nconst answerTwo = await ragAgent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'Compare how the Rossi family business and Thompson Steel Works responded to major infrastructure changes, and how their responses affected the community.';\nconst answerThree = await ragAgent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n\nconst queryFour = 'Trace how the transformation of the Thompson Steel Works site has influenced surrounding businesses and cultural spaces from 1932 to present.';\nconst answerFour = await ragAgent.generate(queryFour);\nconsole.log('\\nQuery:', queryFour);\nconsole.log('Response:', answerFour.text);\n```\n\n----------------------------------------\n\nTITLE: Configuring Workflow Step with StepOptions in Mastra (Typescript)\nDESCRIPTION: This code snippet demonstrates how to configure a workflow step using StepOptions in Mastra. It shows how to map input variables to values from other steps and define an execution condition. The `variables` property maps `orderId` and `userId` to values from the 'trigger' and 'auth' steps respectively. The `when` property specifies that the step should only execute when the 'auth' step's 'status' is 'authenticated'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-options.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  variables: {\n    orderId: { step: 'trigger', path: 'id' },\n    userId: { step: 'auth', path: 'user.id' }\n  },\n  when: {\n    ref: { step: 'auth', path: 'status' },\n    query: { $eq: 'authenticated' }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Errors During Resume in Mastra\nDESCRIPTION: This code demonstrates how to handle potential errors that can occur when resuming a workflow using `run.resume()`. It uses a try-catch block to catch specific errors such as \"No snapshot found for workflow run\" and \"Failed to parse workflow snapshot\", allowing for appropriate error handling and recovery.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resume.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await run.resume({\n    runId,\n    stepId: \"stepTwo\",\n    context: newData\n  });\n} catch (error) {\n  if (error.message === \"No snapshot found for workflow run\") {\n    // ワークフロー状態が見つからない場合の処理\n  }\n  if (error.message === \"Failed to parse workflow snapshot\") {\n    // 破損したワークフロー状態の処理\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of SummarizationMetric\nDESCRIPTION: Demonstrates the basic usage of the SummarizationMetric to evaluate a summary against an original text. It initializes the metric with an OpenAI model, calls the measure method, and logs the resulting score and info object. The score represents the quality of the summary, and the info object contains detailed metrics about the summary.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/summarization.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new SummarizationMetric(model);\n\nconst result = await metric.measure(\n  \"The company was founded in 1995 by John Smith. It started with 10 employees and grew to 500 by 2020. The company is based in Seattle.\",\n  \"Founded in 1995 by John Smith, the company grew from 10 to 500 employees by 2020.\",\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info); // Object containing detailed metrics about the summary\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedder\nDESCRIPTION: This snippet demonstrates how to configure the embedder used to convert messages into embeddings. By default, Mastra uses FastEmbed, but you can specify a different embedding model, such as one from the OpenAI API.  The embedder is a crucial component for calculating semantic similarity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/semantic-recall.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    embedder: openai.embedding(\"text-embedding-3-small\"),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: ContextPositionMetric Basic Usage\nDESCRIPTION: Demonstrates the basic usage of the ContextPositionMetric class to evaluate the relevance and ordering of context nodes for a given query and output. The snippet initializes the metric with an OpenAI model and a set of context strings, then measures the context position score for a specific query and response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-position.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPositionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPositionMetric(model, {\n  context: [\n    \"Photosynthesis is a biological process used by plants to create energy from sunlight.\",\n    \"The process of photosynthesis produces oxygen as a byproduct.\",\n    \"Plants need water and nutrients from the soil to grow.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"What is photosynthesis?\",\n  \"Photosynthesis is the process by which plants convert sunlight into energy.\",\n);\n\nconsole.log(result.score); // Position score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retry Configuration in Mastra\nDESCRIPTION: This code snippet shows how to set a default retry configuration for all steps within a Mastra workflow. It defines the number of retry attempts and the delay between each attempt at the workflow level.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-retries.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'my-workflow',\n  retryConfig: {\n    attempts: 3,    // Number of retries (in addition to the initial attempt)\n    delay: 1000,    // Delay between retries in milliseconds\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Saving Speech Output to a File\nDESCRIPTION: Shows how to save the audio stream generated by the agent's speak method to a file. This example creates a writable stream and pipes the audio data to it, with promise handling for completion or errors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createWriteStream } from \"fs\";\nimport path from \"path\";\n\n// Generate speech and save to file\nconst audio = await agent.voice.speak(\"Hello, World!\");\nconst filePath = path.join(process.cwd(), \"agent.mp3\");\nconst writer = createWriteStream(filePath);\n\naudio.pipe(writer);\n\nawait new Promise<void>((resolve, reject) => {\n  writer.on(\"finish\", () => resolve());\n  writer.on(\"error\", reject);\n});\n```\n\n----------------------------------------\n\nTITLE: Processing Documents for RAG System\nDESCRIPTION: Creates and chunks a document into smaller segments for processing with specified parameters for chunk size and overlap.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc1 = MDocument.fromText(`\nmarket data shows price resistance levels.\ntechnical charts display moving averages.\nsupport levels guide trading decisions.\nbreakout patterns signal entry points.\nprice action determines trade timing.\n\nbaseball cards show gradual value increase.\nrookie cards command premium prices.\ncard condition affects resale value.\nauthentication prevents fake trading.\ngrading services verify card quality.\n\nvolume analysis confirms price trends.\nsports cards track seasonal demand.\nchart patterns predict movements.\nmint condition doubles card worth.\nresistance breaks trigger orders.\nrare cards appreciate yearly.\n`);\n\nconst chunks = await doc1.chunk({\n  strategy: \"recursive\",\n  size: 150,\n  overlap: 20,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Processing Document into Chunks for Graph RAG\nDESCRIPTION: This code demonstrates how to create a document from text and process it into chunks using a recursive strategy with specified size and overlap.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`\n# Riverdale Heights: Community Development Study\n// ... text content ...\n`);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing TokenLimiter Processor in TypeScript\nDESCRIPTION: Shows how to initialize an agent with TokenLimiter memory processor to prevent context window limit errors by limiting total token count to 127k.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter } from \"@mastra/memory/processors\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  model: openai(\"gpt-4o\"),\n  memory: new Memory({\n    processors: [\n      // Ensure the total tokens from memory don't exceed ~127k\n      new TokenLimiter(127000),\n    ],\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Memory Settings with LibSQL in TypeScript\nDESCRIPTION: This snippet demonstrates how to set up custom memory configuration using LibSQL for both storage and vector database. It includes options for storage, vector search, and memory settings such as message history and semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst customMemory = new Memory({\n  storage: new LibSQLStore({\n    config: {\n      url: process.env.DATABASE_URL || \"file:local.db\",\n    },\n  }),\n  vector: new LibSQLVector({\n    connectionUrl: process.env.DATABASE_URL || \"file:local.db\",\n  }),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\nconst memoryAgent = new Agent({\n  name: \"Memory Agent\",\n  instructions:\n    \"あなたは以前のやり取りから記憶を自動的に呼び出す能力を持つAIエージェントです。会話は数時間、数日、数ヶ月、または数年続くことがあります。まだ知らない場合は、ユーザーの名前といくつかの情報を尋ねるべきです。\",\n  model: openai('gpt-4o-mini'),\n  memory: customMemory,\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra RAG Agent\nDESCRIPTION: Sets up a Mastra agent with specific instructions for handling context-based queries using the vector query tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.\n    Important: When asked to answer a question, please base your answer only on the context provided in the tool. \n    If the context doesn't contain enough information to fully answer the question, please state that explicitly.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Search and Re-ranking Results\nDESCRIPTION: Executes a vector search query, retrieves initial results, and then re-ranks them using Mastra's rerank function with custom weights for semantic relevance, vector similarity, and position.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query = 'explain technical trading analysis';\n\n// Get query embedding\nconst { embedding: queryEmbedding } = await embed({\n  value: query,\n  model: openai.embedding('text-embedding-3-small'),\n});\n\n// Get initial results\nconst initialResults = await pgVector.query({\n  indexName: 'embeddings',\n  queryVector: queryEmbedding,\n  topK: 3,\n});\n\n// Re-rank results\nconst rerankedResults = await rerank(initialResults, query, openai('gpt-4o-mini'), {\n  weights: {\n    semantic: 0.5,  // How well the content matches the query semantically\n    vector: 0.3,    // Original vector similarity score\n    position: 0.2   // Preserves original result ordering\n  },\n  topK: 3,\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of speak() Method with OpenAI Voice Provider in TypeScript\nDESCRIPTION: This example demonstrates how to use the speak() method with various configurations including basic usage, changing voices, adding provider-specific options, and using a text stream as input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.speak.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\n// Initialize a voice provider\nconst voice = new OpenAIVoice({\n  speaker: \"alloy\", // Default voice\n});\n// Basic usage with default settings\nconst audioStream = await voice.speak(\"Hello, world!\");\n// Using a different voice for this specific request\nconst audioStreamWithDifferentVoice = await voice.speak(\"Hello again!\", {\n  speaker: \"nova\",\n});\n// Using provider-specific options\nconst audioStreamWithOptions = await voice.speak(\"Hello with options!\", {\n  speaker: \"echo\",\n  speed: 1.2, // OpenAI-specific option\n});\n// Using a text stream as input\nimport { Readable } from \"stream\";\nconst textStream = Readable.from([\"Hello\", \" from\", \" a\", \" stream!\"]);\nconst audioStreamFromTextStream = await voice.speak(textStream);\n```\n\n----------------------------------------\n\nTITLE: Interacting with Chef Agent via curl\nDESCRIPTION: This curl command demonstrates how to interact with the Chef Assistant agent via the API endpoint exposed by the Mastra server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/chefAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"I have eggs, flour, and milk. What can I make?\"\n      }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Cloudflare Vectorize with Mastra\nDESCRIPTION: This code demonstrates how to use the `CloudflareVector` class from `@mastra/vectorize` to create a collection and insert embeddings into Cloudflare Vectorize. It utilizes `openai` for embedding generation, `MDocument` for text chunking, and environment variables for the Cloudflare account ID and API token. The example showcases creating an index and upserting vector embeddings along with their metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_7\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { CloudflareVector } from '@mastra/vectorize';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst vectorize = new CloudflareVector({\n  accountId: process.env.CF_ACCOUNT_ID,\n  apiToken: process.env.CF_API_TOKEN,\n});\n\nawait vectorize.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait vectorize.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Processors (TypeScript)\nDESCRIPTION: This TypeScript code shows how to combine multiple processors in a Memory instance. It first filters out specific tool calls (excluding 'imageGenTool'), and then limits the token count to 16000.  The order of processors is crucial for accurate token limiting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter, ToolCallFilter } from \"@mastra/memory/processors\";\n\nconst memory = new Memory({\n  processors: [\n    // First filter out tool calls\n    new ToolCallFilter({ exclude: [\"imageGenTool\"] }),\n    // Then limit tokens (always put token limiter last for accurate measuring after other filters/transforms)\n    new TokenLimiter(16000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: HallucinationMetric Basic Usage (TypeScript)\nDESCRIPTION: Demonstrates the basic usage of the `HallucinationMetric` to evaluate the factual accuracy of an LLM's response. It initializes the metric with a model and context, then measures the hallucination score of a given output.  The score represents the degree of contradiction with the provided context. Requires `@ai-sdk/openai` and `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/hallucination.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { HallucinationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new HallucinationMetric(model, {\n  context: [\n    \"Teslaは2003年にMartin EberhardとMarc Tarpenningによってカリフォルニア州サンカルロスで設立されました。\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"Teslaの設立について教えてください。\",\n  \"Teslaは2004年にElon Muskによってカリフォルニアで設立されました。\",\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n\n// Example output:\n// {\n//   score: 0.67,\n//   info: {\n//     reason: \"スコアが0.67である理由は、コンテキストからの3つの文のうち2つ（設立年と設立者）が出力によって矛盾していたためであり、\n//           場所の文は矛盾していなかったためです。\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: HallucinationMetric with Analysis (TypeScript)\nDESCRIPTION: Illustrates the use of `HallucinationMetric` with a detailed analysis of the score. It sets up the metric with a predefined context about OpenAI and then measures the hallucination in a given output.  The `info.reason` provides a detailed explanation of the score and identified inconsistencies. Requires `@ai-sdk/openai` and `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/hallucination.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { HallucinationMetric } from \"@mastra/evals/llm\";\n\n// モデルを評価用に設定\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new HallucinationMetric(model, {\n  context: [\n    \"OpenAIは2015年12月にSam Altman、Greg Brockman、その他の人々によって設立されました。\",\n    \"会社は10億ドルの投資コミットメントで開始されました。\",\n    \"Elon Muskは初期の支持者でしたが、2018年に取締役会を去りました。\",\n  ],\n});\n\nconst result = await metric.measure({\n  input: \"OpenAIに関する重要な詳細は何ですか？\",\n  output:\n    \"OpenAIは2015年にElon MuskとSam Altmanによって20億ドルの投資で設立されました。\",\n});\n\n// 出力例:\n// {\n//   score: 0.33,\n//   info: {\n//     reason: \"スコアが0.33である理由は、コンテキストからの3つのステートメントのうち1つが矛盾していたためです\n//           （投資額が1億ドルではなく2億ドルと述べられていた）。設立日は正しかったが、\n//           創設者の説明は不完全であったが、厳密には矛盾していなかった。\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Accessing Step Results with Step Reference in Mastra (TypeScript)\nDESCRIPTION: This code demonstrates using a step reference for accessing results with type safety in Mastra workflows. TypeScript infers the type from the `fetchUserStep`'s output schema. The `processUserStep` safely accesses the `name` property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define step with output schema\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processUserStep = new Step({\n  id: \"processUser\",\n  execute: async ({ context }) => {\n    // TypeScript will infer the correct type from fetchUserStep's outputSchema\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      processed: true,\n      userName: userData?.name\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"user-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processUserStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Create stdio MCP Server in TypeScript\nDESCRIPTION: Creates an MCPServer using the stdio transport.  It imports necessary modules from `@mastra/mcp` and defines the server's name, version, and tools. The server then starts the stdio communication channel and catches any errors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n#!/usr/bin/env node\nimport { MCPServer } from \"@mastra/mcp\";\nimport { weatherTool } from \"./tools\";\n\nconst server = new MCPServer({\n  name: \"my-mcp-server\",\n  version: \"1.0.0\",\n  tools: { weatherTool },\n});\n\nserver.startStdio().catch((error) => {\n  console.error(\"Error running MCP server:\", error);\n  process.exit(1);\n});\n```\n\n----------------------------------------\n\nTITLE: Executing Workflow with Custom Run ID\nDESCRIPTION: This snippet showcases how to execute a Mastra workflow with a specified `runId`. This allows tracking of the execution with a custom identifier. The `triggerData` object provides input values for the workflow execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/execute.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await workflow.execute({\n  runId: \"custom-run-id\",\n  triggerData: { inputValue: 42 }\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Index in Typescript\nDESCRIPTION: This snippet demonstrates how to create a new vector index using the `vector.createIndex` method.  It requires an `indexName`, `dimension`, and `metric` (cosine, euclidean, or dotproduct). The function returns a promise that resolves with the creation result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await vector.createIndex({\n  indexName: \"new-index\",\n  dimension: 128,\n  metric: \"cosine\", // 'cosine', 'euclidean', または 'dotproduct'\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Behavioral Question Step in TypeScript\nDESCRIPTION: This step generates a behavioral question for non-technical candidates, focusing on their interest in the role. It uses the candidate's full resume to create a personalized question.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst askAboutRole = new Step({\n  id: \"askAboutRole\",\n  outputSchema: z.object({\n    question: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const candidateInfo = context?.getStepResult<CandidateInfo>(\n      \"gatherCandidateInfo\",\n    );\n\n    const prompt = `\n          You are a recruiter. Given the resume below, craft a short question\n          for ${candidateInfo?.candidateName} asking what interests them most about this role.\n          Resume: ${candidateInfo?.resumeText}\n        `;\n    const res = await recruiter.generate(prompt);\n    return { question: res?.text?.trim() || \"\" };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of ContextualRecallMetric in TypeScript\nDESCRIPTION: This snippet demonstrates the basic usage of the ContextualRecallMetric to evaluate an LLM's response against a provided context. It imports the necessary modules, configures the model, creates a metric instance, and measures the response. The score ranges from 0 to 1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/contextual-recall.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextualRecallMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextualRecallMetric(model, {\n  context: [\n    \"Product features: cloud synchronization capability\",\n    \"Offline mode available for all users\",\n    \"Supports multiple devices simultaneously\",\n    \"End-to-end encryption for all data\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"What are the key features of the product?\",\n  \"The product includes cloud sync, offline mode, and multi-device support.\",\n);\n\nconsole.log(result.score); // Score from 0-1\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAIVoice Provider with Configuration in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the OpenAIVoice provider with custom configuration including speechModel and speaker settings. It also shows a simplified version using default settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/text-to-speech.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIVoice({\n  speechModel: {\n    name: \"tts-1-hd\",\n    apiKey: process.env.OPENAI_API_KEY\n  },\n  speaker: \"alloy\",\n});\n\n// If using default settings the configuration can be simplified to:\nconst voice = new OpenAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Retrieving Processed Document Chunks - TypeScript\nDESCRIPTION: Use `getDocs()` to retrieve processed chunks of an MDocument. Implemented in TypeScript, it outputs an array of `Chunk` objects, showcasing document processing results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ngetDocs(): Chunk[]\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retry Configuration in Mastra (TypeScript)\nDESCRIPTION: This snippet demonstrates how to configure retry settings at the workflow level in Mastra using TypeScript. It sets the number of retry attempts and the delay between retries for all steps within the workflow. The `retryConfig` property defines the `attempts` and `delay` for retries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'my-workflow',\n  retryConfig: {\n    attempts: 3,    // Number of retry attempts\n    delay: 1000,    // Delay between retries in milliseconds\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Constructor for AgentNetwork - TypeScript\nDESCRIPTION: This code snippet defines the constructor for the AgentNetwork class, which initializes an instance with a configuration object containing the network's name, instructions, model, and a list of specialized agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor(config: AgentNetworkConfig)\n```\n\n----------------------------------------\n\nTITLE: Using Workflow.until() with Reference Condition\nDESCRIPTION: This snippet demonstrates how to use a reference-based condition with the `.until()` method. It checks the 'value' from the 'incrementStep' and stops the loop when it is greater than or equal to 10, using the `$gte` comparison operator. The workflow proceeds to the `finalStep` once the condition is met.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/until.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nworkflow\n  .step(incrementStep)\n  .until(\n    {\n      ref: { step: incrementStep, path: 'value' },\n      query: { $gte: 10 }, // 値が10以上になったら停止\n    },\n    incrementStep\n  )\n  .then(finalStep);\n```\n```\n\n----------------------------------------\n\nTITLE: Complete Workflow.while() Example\nDESCRIPTION: Provides a complete example of using `Workflow.while()` to create a counter workflow.  It defines steps for incrementing a counter and a final step, then configures the workflow with a while loop that continues as long as the counter is less than a target value. Includes setup with `zod` for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/while.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\n// Create a step that increments a counter\nconst incrementStep = new Step({\n  id: 'increment',\n  description: 'Increments the counter by 1',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // Get current value from previous execution or start at 0\n    const currentValue =\n      context.getStepResult<{ value: number }>('increment')?.value ||\n      context.getStepResult<{ startValue: number }>('trigger')?.startValue ||\n      0;\n\n    // Increment the value\n    const value = currentValue + 1;\n    console.log(`Incrementing to ${value}`);\n\n    return { value };\n  },\n});\n\n// Create a final step\nconst finalStep = new Step({\n  id: 'final',\n  description: 'Final step after loop completes',\n  execute: async ({ context }) => {\n    const finalValue = context.getStepResult<{ value: number }>('increment')?.value;\n    console.log(`Loop completed with final value: ${finalValue}`);\n    return { finalValue };\n  },\n});\n\n// Create the workflow\nconst counterWorkflow = new Workflow({\n  name: 'counter-workflow',\n  triggerSchema: z.object({\n    startValue: z.number(),\n    targetValue: z.number(),\n  }),\n});\n\n// Configure the workflow with a while loop\ncounterWorkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      const targetValue = context.triggerData.targetValue;\n      const currentValue = context.getStepResult<{ value: number }>('increment')?.value ?? 0;\n      return currentValue < targetValue;\n    },\n    incrementStep\n  )\n  .then(finalStep)\n  .commit();\n\n// Execute the workflow\nconst run = counterWorkflow.createRun();\nconst result = await run.start({ triggerData: { startValue: 0, targetValue: 5 } });\n// Will increment from 0 to 4, then stop and execute finalStep\n```\n\n----------------------------------------\n\nTITLE: Handling Resume Data in Workflows: TypeScript\nDESCRIPTION: This snippet showcases how to handle resume data within workflows, providing typed access to input schemas for step execution and demonstrating proper management of context for suspended steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  inputSchema: z.object({\n    orderId: z.string(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const { orderId } = context.inputData;\n\n    if (!orderId) {\n      await suspend();\n      return;\n    }\n\n    return {\n      orderId,\n      status: \"processed\"\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n});\n\nworkflow\n  .step(processOrderStep)\n  .commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\nconst resumedResult = await workflow.resume({\n  runId: result.runId,\n  stepId: 'processOrder',\n  inputData: {\n    orderId: '123',\n  },\n});\n\nconsole.log({resumedResult});\n```\n\n----------------------------------------\n\nTITLE: Chaining Multiple Memory Processors\nDESCRIPTION: Demonstrates how to chain multiple processors together, showing proper ordering with TokenLimiter at the end of the chain.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { ToolCallFilter, TokenLimiter } from \"@mastra/memory/processors\";\n// Assume a hypothetical 'PIIFilter' custom processor exists\n// import { PIIFilter } from './custom-processors';\n\nconst memoryWithMultipleProcessors = new Memory({\n  processors: [\n    // 1. Filter specific tool calls first\n    new ToolCallFilter({ exclude: [\"verboseDebugTool\"] }),\n    // 2. Apply custom filtering (e.g., remove hypothetical PII - use with caution)\n    // new PIIFilter(),\n    // 3. Apply token limiting as the final step\n    new TokenLimiter(127000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Steps with RuntimeContext Variables in Mastra (TypeScript)\nDESCRIPTION: This snippet demonstrates how to create steps that access runtimeContext variables within a Mastra workflow. It includes defining step input/output types, accessing the multiplier value from the runtimeContext, and performing a calculation based on the input value and multiplier.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/runtime-variables.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step } from \"@mastra/core/workflow\";\nimport { z } from \"zod\";\n\n// Define step input/output types\ninterface StepInput {\n  inputValue: number;\n}\n\ninterface StepOutput {\n  incrementedValue: number;\n}\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  description: \"Multiply the input value by the configured multiplier\",\n  execute: async ({ context, runtimeContext }) => {\n    try {\n      // Type-safe access to runtimeContext variables\n      const multiplier = runtimeContext.get(\"multiplier\");\n      if (multiplier === undefined) {\n        throw new Error(\"Multiplier not configured in runtimeContext\");\n      }\n\n      // Get and validate input\n      const inputValue =\n        context.getStepResult<StepInput>(\"trigger\")?.inputValue;\n      if (inputValue === undefined) {\n        throw new Error(\"Input value not provided\");\n      }\n\n      const result: StepOutput = {\n        incrementedValue: inputValue * multiplier,\n      };\n\n      return result;\n    } catch (error) {\n      console.error(`Error in stepOne: ${error.message}`);\n      throw error;\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Customizing Document Chunking Parameters in TypeScript\nDESCRIPTION: This snippet shows how to customize the chunking parameters when using `createDocumentChunkerTool()`. It sets a larger chunk size (1024), more overlap (100), and uses double newlines as the separator. The example then processes the generated chunks and logs their lengths to the console. Dependencies: `@mastra/rag`, `longDocumentContent` variable defined elsewhere.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/document-chunker-tool.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst technicalDoc = new MDocument({\n  text: longDocumentContent,\n  metadata: {\n    type: \"technical\",\n    version: \"1.0\"\n  }\n});\n\nconst chunker = createDocumentChunkerTool({\n  doc: technicalDoc,\n  params: {\n    strategy: \"recursive\",\n    size: 1024,      // Larger chunks\n    overlap: 100,    // More overlap\n    separator: \"\\n\\n\" // Split on double newlines\n  }\n});\n\nconst { chunks } = await chunker.execute();\n\n// Process the chunks\nchunks.forEach((chunk, index) => {\n  console.log(`Chunk ${index + 1} length: ${chunk.content.length}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Resume Workflow with Event - Basic Usage - Typescript\nDESCRIPTION: This code snippet demonstrates how to resume a suspended workflow using the `resumeWithEvent()` method. It assumes the workflow is waiting for an 'approval' event.  The `approval` event is triggered with data indicating approval, approver's name, and a comment. It requires the `mastra` object to be defined.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resumeWithEvent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Define and start a workflow\nconst workflow = mastra.getWorkflow(\"approval-workflow\");\nconst run = workflow.createRun();\n\n// Start the workflow\nawait run.start({ triggerData: { requestId: \"req-123\" } });\n\n// Later, when the approval event occurs:\nconst result = await run.resumeWithEvent(\"approval\", {\n  approved: true,\n  approverName: \"John Doe\",\n  comment: \"Looks good to me!\",\n});\n\nconsole.log(result.results);\n```\n\n----------------------------------------\n\nTITLE: Function Condition in Mastra Workflow (Typescript)\nDESCRIPTION: This snippet demonstrates how to define a step condition using an asynchronous function in a Mastra workflow. The function accesses the result of a previous step named 'auth' using the context and checks its 'status' property. The step 'processOrder' will only execute if the 'status' is 'authenticated'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-condition.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: async ({ context }) => {\n    const auth = context?.getStepResult<{status: string}>(\"auth\");\n    return auth?.status === \"authenticated\";\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Memory Processor\nDESCRIPTION: TypeScript implementation of a custom memory processor by implementing the MemoryProcessor interface. Shows how to create a processor that can filter or transform messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { CoreMessage } from '@mastra/core';\nimport type { MemoryProcessor } from '@mastra/core/memory';\n\nclass CustomProcessor implements MemoryProcessor {\n  process(messages: CoreMessage[]): CoreMessage[] {\n    // Filter or transform messages here\n    return filteredMessages;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for RAG System\nDESCRIPTION: Sets up environment variables for OpenAI API key and PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies\nDESCRIPTION: This snippet imports the necessary dependencies for the RAG system. It includes modules from @ai-sdk/openai, @mastra/core, @mastra/pg, and @mastra/rag. These dependencies provide functionalities for interacting with OpenAI, managing Mastra agents, connecting to PGVector, creating vector query tools, and embedding text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { createVectorQueryTool, MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Complete Workflow Example with until() (TypeScript)\nDESCRIPTION: A complete example demonstrating the creation of a Mastra workflow that increments a counter using the `.until()` method.  It includes step definitions (`incrementStep`, `finalStep`), workflow configuration with `triggerSchema`, the `.until()` loop with a function condition based on `targetValue`, and workflow execution with `createRun()` and `start()`. Requires `@mastra/core` and `zod` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/until.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\n// Create a step that increments a counter\nconst incrementStep = new Step({\n  id: 'increment',\n  description: 'Increments the counter by 1',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // Get current value from previous execution or start at 0\n    const currentValue =\n      context.getStepResult<{ value: number }>('increment')?.value ||\n      context.getStepResult<{ startValue: number }>('trigger')?.startValue ||\n      0;\n\n    // Increment the value\n    const value = currentValue + 1;\n    console.log(`Incrementing to ${value}`);\n\n    return { value };\n  },\n});\n\n// Create a final step\nconst finalStep = new Step({\n  id: 'final',\n  description: 'Final step after loop completes',\n  execute: async ({ context }) => {\n    const finalValue = context.getStepResult<{ value: number }>('increment')?.value;\n    console.log(`Loop completed with final value: ${finalValue}`);\n    return { finalValue };\n  },\n});\n\n// Create the workflow\nconst counterWorkflow = new Workflow({\n  name: 'counter-workflow',\n  triggerSchema: z.object({\n    startValue: z.number(),\n    targetValue: z.number(),\n  }),\n});\n\n// Configure the workflow with an until loop\ncounterWorkflow\n  .step(incrementStep)\n  .until(async ({ context }) => {\n    const targetValue = context.triggerData.targetValue;\n    const currentValue = context.getStepResult<{ value: number }>('increment')?.value ?? 0;\n    return currentValue >= targetValue;\n  }, incrementStep)\n  .then(finalStep)\n  .commit();\n\n// Execute the workflow\nconst run = counterWorkflow.createRun();\nconst result = await run.start({ triggerData: { startValue: 0, targetValue: 5 } });\n// Will increment from 0 to 5, then stop and execute finalStep\n```\n\n----------------------------------------\n\nTITLE: Managing Messages with Storage API in TypeScript\nDESCRIPTION: Shows message management functionality including saving new messages and retrieving messages by thread ID. Demonstrates message structure with content types.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/storage/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Save messages\nawait storage.saveMessages({\n  messages: [\n    {\n      id: 'msg-1',\n      threadId: thread.id,\n      role: 'user',\n      content: [{ type: 'text', text: 'Hello' }],\n      createdAt: new Date(),\n    },\n  ],\n});\n\n// Get thread messages\nconst messages = await storage.getMessages({\n  threadId: thread.id,\n});\n```\n\n----------------------------------------\n\nTITLE: Registering Weather Agent with Mastra (TypeScript)\nDESCRIPTION: This TypeScript code registers the weather agent with the Mastra framework. It imports the `Mastra` class from `@mastra/core` and the `weatherAgent` defined in the `src/mastra/agents/weather.ts` file. A new instance of `Mastra` is created with the `weatherAgent` registered within the `agents` configuration. This allows Mastra to discover and serve the weather agent, making it accessible via REST API endpoints.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_24\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nimport { weatherAgent } from \"./agents/weather\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of FaithfulnessMetric in TypeScript\nDESCRIPTION: Demonstrates how to initialize and use the FaithfulnessMetric to measure the factual accuracy of an LLM output against a given context.  It configures the model, sets up the metric with context, and measures the faithfulness of a response, logging the score and reasoning. Requires `@ai-sdk/openai` and `@mastra/evals/llm` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/faithfulness.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { FaithfulnessMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new FaithfulnessMetric(model, {\n  context: [\n    \"The company was established in 1995.\",\n    \"Currently employs around 450-550 people.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"Tell me about the company.\",\n  \"The company was founded in 1995 and has 500 employees.\",\n);\n\nconsole.log(result.score); // 1.0\nconsole.log(result.info.reason); // \"All claims are supported by the context.\"\n```\n\n----------------------------------------\n\nTITLE: Custom Template for Working Memory (TypeScript)\nDESCRIPTION: This code snippet showcases a custom template for the working memory, which instructs the agent to track and update user information. The template includes sections for personal info (name, location, timezone), preferences (communication style, project goal, deadlines), and session state (last task discussed, open questions). This template is designed to be used when the agent receives a message containing relevant information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/working-memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      template: `\n# User Profile\n \n## Personal Info\n \n- Name:\n- Location:\n- Timezone:\n \n## Preferences\n \n- Communication Style: [e.g., Formal, Casual]\n- Project Goal:\n- Key Deadlines:\n  - [Deadline 1]: [Date]\n  - [Deadline 2]: [Date]\n \n## Session State\n \n- Last Task Discussed:\n- Open Questions:\n  - [Question 1]\n  - [Question 2]\n`,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Instructions Prompt for Gluten-Checking Chef Agent\nDESCRIPTION: Defines the basic instructions prompt that sets the role and context for the judge. This prompt establishes the LLM as a Master Chef specialized in identifying gluten content in recipes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const GLUTEN_INSTRUCTIONS = `You are a Master Chef that identifies if recipes contain gluten.`;\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Results in Mastra Workflows (TypeScript)\nDESCRIPTION: This snippet illustrates how to access the results of a Mastra workflow in a type-safe manner using TypeScript.  By passing the step types to the `Workflow` constructor, the `result.results` object becomes a discriminated union of step results. It leverages `Step` and `Workflow` from `@mastra/core/workflows` and `zod` for schema definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  outputSchema: z.object({\n    orderId: z.string(),\n    status: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const userData = context.getStepResult(fetchUserStep);\n    return {\n      orderId: \"order123\",\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow<[typeof fetchUserStep, typeof processOrderStep]>({ \n  name: \"typed-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\n// 結果はステップ結果の判別共用体です\n// そのためステータスチェックによって絞り込む必要があります\nif (result.results.processOrder.status === 'success') {\n  // TypeScriptは結果の形状を認識します\n  const orderId = result.results.processOrder.output.orderId;\n  console.log({orderId});\n}\n\nif (result.results.fetchUser.status === 'success') {\n  const userId = result.results.fetchUser.output.userId;\n  console.log({userId});\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing AzureVoice and Using TTS/STT\nDESCRIPTION: This code snippet demonstrates how to initialize the AzureVoice class with API keys and regions for speech and listening models. It then shows how to use the `speak` method to convert text to speech, overriding the default speaker and setting a style. Finally, it illustrates the `listen` method for converting speech to text, specifying the filetype and language.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/azure.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AzureVoice } from '@mastra/voice-azure';\n\n// Initialize with configuration\nconst voice = new AzureVoice({\n  speechModel: {\n    name: 'neural',\n    apiKey: 'your-azure-speech-api-key',\n    region: 'eastus'\n  },\n  listeningModel: {\n    name: 'whisper',\n    apiKey: 'your-azure-speech-api-key',\n    region: 'eastus'\n  },\n  speaker: 'en-US-JennyNeural'  // Default voice\n});\n\n// Convert text to speech\nconst audioStream = await voice.speak('Hello, how can I help you?', {\n  speaker: 'en-US-GuyNeural',  // Override default voice\n  style: 'cheerful'  // Voice style\n});\n\n// Convert speech to text\nconst text = await voice.listen(audioStream, {\n  filetype: 'wav',\n  language: 'en-US'\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Text Stream Working Memory in TypeScript\nDESCRIPTION: Creates a Memory instance with working memory enabled in text-stream mode, which is the default configuration for handling working memory updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      use: \"text-stream\", // this is the default mode\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying with Metadata Filters\nDESCRIPTION: Demonstrates querying the RAG system using different metadata filters, showcasing the agent's ability to understand and apply filters for relevant information retrieval.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = 'What are the adaptation strategies mentioned?';\nconst answerOne = await agent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'Show me recent sections. Check the \"nested.id\" field and return values that are greater than 2.';\nconst answerTwo = await agent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'Search the \"text\" field using regex operator to find sections containing \"temperature\".';\nconst answerThree = await agent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Defining and Executing Simple Mastra Workflow in TypeScript\nDESCRIPTION: Creates a workflow that doubles a numeric input value using Mastra's workflow system. The example demonstrates schema validation using Zod, workflow step definition, and workflow execution with trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/creating-a-workflow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    input: z.number(),\n  }),\n});\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  inputSchema: z.object({\n    value: z.number(),\n  }),\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context?.triggerData?.input * 2;\n    return { doubledValue };\n  },\n});\n\nmyWorkflow.step(stepOne).commit();\n\nconst { runId, start } = myWorkflow.createRun();\n\nconst res = await start({\n  triggerData: { input: 90 },\n});\n\nconsole.log(res.results);\n```\n\n----------------------------------------\n\nTITLE: Resuming a Workflow and Monitoring Transitions with TypeScript\nDESCRIPTION: This code demonstrates how to resume a workflow execution and monitor the transitions of a workflow step using the `watch` and `resume` methods. It defines `createRun` with the argument `prevRunId` to specify the `runId` of the workflow that needs to be resumed. It calls `workflow.resume` with the `runId`, `stepId`, and `contextData` to continue a suspended run.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ntry{\n  //To resume a workflow run, when a step is suspended\n  const {run} = createRun({runId: prevRunId})\n\n  //Watch run\n   workflow.watch({runId},(record)=>{\n   // Every new record is the latest transition state of the workflow run\n\n        console.log({\n          activePaths: record.activePaths,\n          results: record.results,\n          timestamp: record.timestamp,\n          runId: record.runId\n        });\n   })\n\n   //resume run\n   workflow.resume({\n      runId,\n      stepId: \"step-id\",\n      contextData: { key: \"value\" },\n    });\n}catch(e){\n  console.error(e);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using MurfVoice in TypeScript\nDESCRIPTION: This example demonstrates how to initialize the MurfVoice provider with default and custom configurations, generate text-to-speech audio streams, and retrieve available voice speakers. It shows both basic and advanced usage patterns for the Murf integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/murf.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MurfVoice } from \"@mastra/voice-murf\";\n\n// Initialize with default configuration (uses MURF_API_KEY environment variable)\nconst voice = new MurfVoice();\n\n// Initialize with custom configuration\nconst voice = new MurfVoice({\n  speechModel: {\n    name: 'GEN2',\n    apiKey: 'your-api-key',\n    properties: {\n      format: 'MP3',\n      rate: 1.0,\n      pitch: 1.0,\n      sampleRate: 48000,\n      channelType: 'STEREO',\n    },\n  },\n  speaker: 'en-US-cooper',\n});\n\n// Text-to-Speech with default settings\nconst audioStream = await voice.speak(\"Hello, world!\");\n\n// Text-to-Speech with custom properties\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 'en-UK-hazel',\n  properties: {\n    format: 'WAV',\n    rate: 1.2,\n    style: 'casual',\n  },\n});\n\n// Get available voices\nconst voices = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Run Workflow with Inquirer Prompts in Mastra\nDESCRIPTION: This function demonstrates how to run the `recommendationWorkflow` and interact with the `reviewRecommendations` step when it's suspended for human input. It initializes the workflow, starts the run, and checks if the `reviewRecommendations` step is in a suspended state. If so, it uses the `inquirer` library to prompt the user for product approvals, a customer note, and a discount offer, then resumes the workflow with the gathered input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Example of using the workflow with Inquirer prompts\nasync function runRecommendationWorkflow() {\n  const registeredWorkflow = mastra.getWorkflow('recommendationWorkflow');\n  const run = registeredWorkflow.createRun();\n\n  console.log('Starting product recommendation workflow...');\n  const result = await run.start({\n    triggerData: {\n      customerName: 'Jane Smith',\n    },\n  });\n\n  const isReviewStepSuspended = result.activePaths.get('reviewRecommendations')?.status === 'suspended';\n\n  // Check if workflow is suspended for human review\n  if (isReviewStepSuspended) {\n    const { customerName, recommendations, message } = result.activePaths.get('reviewRecommendations')?.suspendPayload;\n\n    console.log('\\n===================================');\n    console.log(message);\n    console.log(`Customer: ${customerName}`);\n    console.log('===================================\\n');\n\n    // Use Inquirer to collect input from the sales agent in the terminal\n    console.log('Available product recommendations:');\n    recommendations.forEach((product, index) => {\n      console.log(`${index + 1}. ${product.productName} - $${product.price.toFixed(2)}`);\n      console.log(`   ${product.description}\\n`);\n    });\n\n    // Let the agent select which products to recommend\n    const approvedProducts = await checkbox({\n      message: '顧客にお勧めする製品を選択してください：',\n      choices: recommendations.map(product => ({\n        name: `${product.productName} ($${product.price.toFixed(2)})`,\n        value: product.productId,\n      })),\n    });\n\n    // Let the agent add a personal note\n    const includeNote = await confirm({\n      message: '個人的なメモを追加しますか？',\n      default: false,\n    });\n\n    let customerNote = '';\n    if (includeNote) {\n      customerNote = await input({\n        message: '顧客へのパーソナライズされたメモを入力してください：',\n      });\n    }\n\n    // Ask if a discount should be offered\n    const offerDiscount = await confirm({\n      message: 'この顧客に10%割引を提供しますか？',\n      default: false,\n    });\n\n    console.log('\\nレビューを送信しています...');\n\n    // Resume the workflow with the agent's input\n    const resumeResult = await run.resume({\n      stepId: 'reviewRecommendations',\n      context: {\n        approvedProducts,\n        customerNote,\n        offerDiscount,\n      },\n    });\n\n    console.log('\\n===================================');\n    console.log('ワークフローが完了しました！');\n    console.log('メールの内容：');\n    console.log('===================================\\n');\n    console.log(resumeResult?.results?.sendRecommendations || 'メールの内容が生成されていません');\n\n    return resumeResult;\n  }\n\n  return result;\n}\n\n// Invoke the workflow with interactive terminal input\nrunRecommendationWorkflow().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Interacting with Agent to Get Weather Information (TypeScript)\nDESCRIPTION: This code snippet shows how to call the `weatherAgent` to fetch weather information using the `generate` method.  It retrieves the agent, calls `generate` with a question about the weather in New York City, and logs the agent's response. This demonstrates a basic interaction flow between a user (or application) and a Mastra agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\nasync function main() {\n  const agent = mastra.getAgent(\"weatherAgent\");\n  const response = await agent.generate(\n    \"What's the weather like in New York City today?\",\n  );\n\n  console.log(response.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Evaluating high position adherence in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a response that closely follows the sequential order of the given context using the Context Position metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-position.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'The capital of France is Paris.',\n  'Paris has been the capital since 508 CE.',\n  'Paris serves as France\\'s political center.',\n  'The capital city hosts the French government.',\n];\n\nconst metric1 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'What is the capital of France?';\nconst response1 = 'The capital of France is Paris.';\n\nconsole.log('Example 1 - High Position Adherence:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The context is in the correct sequential order.' }\n```\n\n----------------------------------------\n\nTITLE: ContextRelevancyMetric with Custom Configuration\nDESCRIPTION: Demonstrates the usage of the ContextRelevancyMetric class with a custom scale and context. It initializes the metric with an OpenAI model, a custom scale of 100 (instead of the default 0-1), and a predefined context related to pricing plans and company information. Then measures the relevance of a given output and showcases an example output with score and a reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextRelevancyMetric(model, {\n  scale: 100, // Use 0-100 scale instead of 0-1\n  context: [\n    \"Basic plan costs $10/month\",\n    \"Pro plan includes advanced features at $30/month\",\n    \"Enterprise plan has custom pricing\",\n    \"Our company was founded in 2020\",\n    \"We have offices worldwide\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"What are our pricing plans?\",\n  \"We offer Basic, Pro, and Enterprise plans.\",\n);\n\n// Example output:\n// {\n//   score: 60,\n//   info: {\n//     reason: \"3 out of 5 statements are relevant to pricing plans. The statements about \n//           company founding and office locations are not relevant to the pricing query.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Passing Context Between Steps in TypeScript\nDESCRIPTION: The snippet demonstrates how to access and utilize data from previous steps in a workflow using the context object. Each step can retrieve results from earlier steps, allowing for a chain of data processing across the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step({\n    id: 'getData',\n    execute: async ({ context }) => {\n      return {\n        data: { id: '123', value: 'example' }\n      };\n    }\n  })\n  .step({\n    id: 'processData',\n    execute: async ({ context }) => {\n      // Access data from previous step through context.steps\n      const previousData = context.steps.getData.output.data;\n      // Process previousData.id and previousData.value\n    }\n  });\n```\n\n----------------------------------------\n\nTITLE: Monitoring and Resuming Event-Based Workflow (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to monitor for a suspended event step in an event-based workflow using the `watch` function, and resume the workflow with the `resumeWithEvent` function. It simulates an approval event after 5 seconds and then resumes the workflow with the simulated event data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst { start, watch, resumeWithEvent } = workflow.createRun();\n\n// 中断されたイベントステップを監視\nwatch(async ({ activePaths }) => {\n  const isApprovalReceivedSuspended =\n    activePaths.get(\"__approvalReceived_event\")?.status === \"suspended\";\n  if (isApprovalReceivedSuspended) {\n    console.log(\"承認イベントを待っているワークフロー\");\n\n    // 実際のシナリオでは、実際のイベントが発生するのを待ちます\n    // 例えば、これはWebhookやユーザーの操作によってトリガーされる可能性があります\n    setTimeout(async () => {\n      await resumeWithEvent(\"approvalReceived\", {\n        approved: true,\n        approverName: \"Auto Approver\",\n      });\n    }, 5000); // 5秒後にイベントをシミュレート\n  }\n});\n\n// ワークフローを開始\nawait start({ triggerData: { requestId: \"auto-123\" } });\n```\n\n----------------------------------------\n\nTITLE: Basic Retry Example in Mastra\nDESCRIPTION: This code snippet demonstrates a basic retry implementation in a Mastra workflow. It defines a step that simulates an unreliable API call and configures a retry policy with a specified number of attempts and a delay between attempts. This example showcases how to handle potential failures in API interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-retries.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\n\n// 失敗する可能性のあるステップを定義\nconst unreliableApiStep = new Step({\n  id: 'callUnreliableApi',\n  execute: async () => {\n    // 失敗する可能性のあるAPI呼び出しをシミュレート\n    const random = Math.random();\n    if (random < 0.7) {\n      throw new Error('API call failed');\n    }\n    return { data: 'API response data' };\n  },\n  retryConfig: {\n    attempts: 3,  // 最大3回リトライ\n    delay: 2000,  // 試行間に2秒待機\n  },\n});\n\n// 信頼性の低いステップを含むワークフローを作成\nconst workflow = new Workflow({\n  name: 'retry-demo-workflow',\n});\n\nworkflow\n  .step(unreliableApiStep)\n  .then(processResultStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Query Execution\nDESCRIPTION: Example of executing a RAG query using the configured agent and handling the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst prompt = `\n[Insert query based on document here]\nPlease base your answer only on the context provided in the tool. \nIf the context doesn't contain enough information to fully answer the question, please state that explicitly.\n`;\n\nconst completion = await agent.generate(prompt);\nconsole.log(completion.text);\n```\n\n----------------------------------------\n\nTITLE: Analyzing Content with AI in Mastra Workflow (TypeScript)\nDESCRIPTION: This step defines the analysis of content within a Mastra workflow. It simulates AI analysis by generating a random score and flagging categories based on that score. It takes content from the workflow's trigger data and returns the content, AI analysis score, and flagged categories.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\nimport { select, input } from '@inquirer/prompts';\n\n// Step 1: Receive and analyze content\nconst analyzeContent = new Step({\n  id: 'analyzeContent',\n  outputSchema: z.object({\n    content: z.string(),\n    aiAnalysisScore: z.number(),\n    flaggedCategories: z.array(z.string()).optional(),\n  }),\n  execute: async ({ context }) => {\n    const content = context.triggerData.content;\n\n    // Simulate AI analysis\n    const aiAnalysisScore = simulateContentAnalysis(content);\n    const flaggedCategories = aiAnalysisScore < 0.7\n      ? ['potentially inappropriate', 'needs review']\n      : [];\n\n    return {\n      content,\n      aiAnalysisScore,\n      flaggedCategories,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLStore for General Storage\nDESCRIPTION: This code snippet demonstrates how to use the LibSQLStore class for general storage, focusing on thread and message management. It shows how to initialize the store, save a thread with metadata, add messages to the thread, and retrieve threads and messages by their IDs. This involves setting up a connection and defining schemas for storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLStore } from '@mastra/pg';\n\nconst store = new LibSQLStore({\n  url: 'file:./my-db.db',\n});\n\n// Create a thread\nawait store.saveThread({\n  id: 'thread-123',\n  resourceId: 'resource-456',\n  title: 'My Thread',\n  metadata: { key: 'value' },\n});\n\n// Add messages to thread\nawait store.saveMessages([\n  {\n    id: 'msg-789',\n    threadId: 'thread-123',\n    role: 'user',\n    type: 'text',\n    content: [{ type: 'text', text: 'Hello' }],\n  },\n]);\n\n// Query threads and messages\nconst savedThread = await store.getThread('thread-123');\nconst messages = await store.getMessages('thread-123');\n```\n\n----------------------------------------\n\nTITLE: Using Realtime Voice Providers with speak() Method in TypeScript\nDESCRIPTION: This example shows how to use the speak() method with realtime voice providers like OpenAIRealtimeVoice, which emit events instead of returning streams. It includes setting up a speaker for audio output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.speak.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\nconst voice = new OpenAIRealtimeVoice();\nawait voice.connect();\n// Register event listener for audio chunks\nvoice.on(\"speaker\", (stream) => {\n  // Handle audio chunk (e.g., play it or save it)\n  stream.pipe(speaker)\n});\n// This will emit 'speaking' events instead of returning a stream\nawait voice.speak(\"Hello, this is realtime speech!\");\n```\n\n----------------------------------------\n\nTITLE: Token Limiter with Specific Encoding\nDESCRIPTION: This snippet demonstrates using a `TokenLimiter` with a specific encoding.  It imports `cl100k_base` from `js-tiktoken` to use a specific encoding for token counting, which is useful for models like GPT-3.5 that require specific encodings. The limit is set to 16000 tokens.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Memory } from \\\"@mastra/memory\\\";\nimport { TokenLimiter } from \\\"@mastra/memory/processors\\\";\nimport cl100k_base from \\\"js-tiktoken/ranks/cl100k_base\\\";\n\nconst memory = new Memory({\n  processors: [\n    new TokenLimiter({\n      limit: 16000,\n      encoding: cl100k_base, // 特定のモデル用の特定のエンコーディング 例: GPT-3.5\n    }),\n  ],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with Tools and maxSteps in TypeScript\nDESCRIPTION: This code demonstrates how to initialize an agent with tools and set the `maxSteps` parameter. The agent is configured with a `calculate` tool that uses the `mathjs` library to evaluate mathematical expressions. The `maxSteps` parameter limits the number of consecutive LLM calls to prevent infinite loops. Requires `@mastra/core`, `@ai-sdk/openai`, `mathjs`, and `zod` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport * as mathjs from \"mathjs\";\nimport { z } from \"zod\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant that can solve math problems.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    calculate: {\n      description: \"Calculator for mathematical expressions\",\n      schema: z.object({ expression: z.string() }),\n      execute: async ({ expression }) => mathjs.evaluate(expression),\n    },\n  },\n});\n\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"If a taxi driver earns $9461 per hour and works 12 hours a day, how much does they earn in one day?\",\n    },\n  ],\n  {\n    maxSteps: 5, // 最大5回のツール使用ステップを許可\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Query Tool in TypeScript\nDESCRIPTION: This snippet creates a vector query tool using `createVectorQueryTool` from `@mastra/rag`.  It configures the tool to use 'pgVector' as the vector store, 'embeddings' as the index name, and the `text-embedding-3-small` model from OpenAI for generating embeddings. This tool will be used to query the vector database for relevant context based on a given prompt.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Voice Interaction Flow\nDESCRIPTION: Demonstrates the interaction between two voice-enabled agents, including speaking, listening, and response generation. Shows how to handle audio streams and file operations for voice data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/adding-voice-capabilities.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 1: Agent 1 speaks a question and saves it to a file\nconst audio1 = await agent1.voice.speak('What is the meaning of life in one sentence?');\nawait saveAudioToFile(audio1, 'agent1-question.mp3');\n\n// Step 2: Agent 2 listens to Agent 1's question\nconst audioFilePath = path.join(process.cwd(), 'agent1-question.mp3');\nconst audioStream = createReadStream(audioFilePath);\nconst audio2 = await agent2.voice.listen(audioStream);\nconst text = await convertToText(audio2);\n\n// Step 3: Agent 2 generates and speaks a response\nconst agent2Response = await agent2.generate(text);\nconst agent2ResponseAudio = await agent2.voice.speak(agent2Response.text);\nawait saveAudioToFile(agent2ResponseAudio, 'agent2-response.mp3');\n```\n\n----------------------------------------\n\nTITLE: Implementing Server Actions with Mastra\nDESCRIPTION: This code demonstrates how to implement server actions using Mastra in a Next.js application. It imports the mastra instance from '@/mastra', defines an asynchronous function getWeatherInfo that gets a weather agent from mastra, generates a response based on the provided city, and returns the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\n'use server'\n\nimport { mastra } from '@/mastra'\n\nexport async function getWeatherInfo(city: string) {\n  const agent = mastra.getAgent('weatherAgent')\n  \n  const result = await agent.generate(`What's the weather like in ${city}?`)\n\n  return result\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using GoogleVoice Provider in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the GoogleVoice provider with both default and custom configurations, perform text-to-speech and speech-to-text operations, and retrieve available voice options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/google.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GoogleVoice } from \"@mastra/voice-google\";\n\n// Initialize with default configuration (uses GOOGLE_API_KEY environment variable)\nconst voice = new GoogleVoice();\n\n// Initialize with custom configuration\nconst voice = new GoogleVoice({\n  speechModel: {\n    apiKey: 'your-speech-api-key',\n  },\n  listeningModel: {\n    apiKey: 'your-listening-api-key',\n  },\n  speaker: 'en-US-Casual-K',\n});\n\n// Text-to-Speech\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  languageCode: 'en-US',\n  audioConfig: {\n    audioEncoding: 'LINEAR16',\n  },\n});\n\n// Speech-to-Text\nconst transcript = await voice.listen(audioStream, {\n  config: {\n    encoding: 'LINEAR16',\n    languageCode: 'en-US',\n  },\n});\n\n// Get available voices for a specific language\nconst voices = await voice.getSpeakers({ languageCode: 'en-US' });\n```\n\n----------------------------------------\n\nTITLE: Context Object Access in Mastra Workflows (TypeScript)\nDESCRIPTION: This snippet showcases accessing the results of previous steps directly through the context object within a Mastra workflow.  It uses the `Step` and `Workflow` classes from `@mastra/core/workflows` and `zod` for schema definition. The `processOrderStep` accesses the output of the `fetchUserStep` via `context.steps`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new Step({\n  id: 'processOrder',\n  execute: async ({ context }) => {\n    // Access data from a previous step\n    let userData: { name: string, userId: string };\n    if (context.steps['fetchUser']?.status === 'success') {\n      userData = context.steps.fetchUser.output;\n    } else {\n      throw new Error('User data not found');\n    }\n\n    return {\n      orderId: 'order123',\n      userId: userData.userId,\n      status: 'processing',\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Error Handling for Workflow start() Method in TypeScript\nDESCRIPTION: Shows how to implement error handling for workflow execution, specifically catching ValidationError instances and handling different error types like circular dependencies, terminal paths, and unreachable steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/start.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const result = await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Errors within Mastra Steps (TypeScript)\nDESCRIPTION: This snippet demonstrates how to handle errors programmatically within a Mastra step's execution function. It uses a `try...catch` block to catch potential errors during the execution of `someRiskyOperation()`. If an error occurs, it logs the error and returns a graceful fallback result instead of throwing an exception, ensuring the workflow continues.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst robustStep = new Step({\n  id: 'robustStep',\n  execute: async ({ context }) => {\n    try {\n      // Attempt the primary operation\n      const result = await someRiskyOperation();\n      return { success: true, data: result };\n    } catch (error) {\n      // Log the error\n      console.error('Operation failed:', error);\n\n      // Return a graceful fallback result instead of throwing\n      return {\n        success: false,\n        error: error.message,\n        fallbackData: 'Default value'\n      };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors into Index in TypeScript\nDESCRIPTION: Insert or update vectors in a specified index, optionally providing metadata and custom IDs for each vector. This operation is used to maintain vector data in the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst ids = await vector.upsert({\n  indexName: \"my-index\",\n  vectors: [\n    [0.1, 0.2, 0.3], // First vector\n    [0.4, 0.5, 0.6], // Second vector\n  ],\n  metadata: [{ label: \"first\" }, { label: \"second\" }],\n  ids: [\"id1\", \"id2\"], // Optional: Custom IDs\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Text with MyAgent in TypeScript\nDESCRIPTION: This snippet demonstrates a simple text streaming operation using myAgent. A stream is initiated with a user prompt, and the resultant text is streamed chunk by chunk and written to the standard output. No specific dependencies are required apart from having a myAgent instance. The input is a user prompt and the output consists of streamed text chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/stream.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream([\n  { role: \"user\", content: \"Tell me a story.\" }\n]);\n\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Stock Price Tool (TypeScript)\nDESCRIPTION: Creates a tool that fetches the last day's closing stock price for a given symbol using the Mastra core library and Zod for input validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst getStockPrice = async (symbol: string) => {\n  const data = await fetch(\n    `https://mastra-stock-data.vercel.app/api/stock-data?symbol=${symbol}`,\n  ).then((r) => r.json());\n  return data.prices[\"4. close\"];\n};\n\nexport const stockPrices = createTool({\n  id: \"Get Stock Price\",\n  inputSchema: z.object({\n    symbol: z.string(),\n  }),\n  description: `Fetches the last day's closing stock price for a given symbol`,\n  execute: async ({ context: { symbol } }) => {\n    console.log(\"Using tool to fetch stock price for\", symbol);\n    return {\n      symbol,\n      currentPrice: await getStockPrice(symbol),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Storing Embeddings with Rich Metadata in TypeScript\nDESCRIPTION: This code snippet demonstrates how to upsert embeddings into a vector store with comprehensive metadata. It includes basic content, document organization, temporal metadata, and custom fields for better filtering and organization.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\n// Store embeddings with rich metadata for better organization and filtering\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map((chunk) => ({\n    // Basic content\n    text: chunk.text,\n    id: chunk.id,\n    \n    // Document organization\n    source: chunk.source,\n    category: chunk.category,\n    \n    // Temporal metadata\n    createdAt: new Date().toISOString(),\n    version: \"1.0\",\n    \n    // Custom fields\n    language: chunk.language,\n    author: chunk.author,\n    confidenceScore: chunk.score,\n  })),\n});\n```\n\n----------------------------------------\n\nTITLE: Working with a Specific Workflow using TypeScript\nDESCRIPTION: This snippet demonstrates how to get an instance of a specific workflow using its ID.  It relies on an existing `client` object with a `getWorkflow` method that accepts a workflow ID as a string. The function returns an instance of a workflow object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = client.getWorkflow(\"workflow-id\");\n```\n\n----------------------------------------\n\nTITLE: Non-Applicable Instructions Evaluation Example\nDESCRIPTION: Implementation of prompt alignment evaluation for a scenario where the instructions don't apply to the query context. Shows handling of banking instructions for a weather-related query.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions3 = [\n  'Show account balance',\n  'List recent transactions',\n  'Display payment history'\n];\n\nconst metric3 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions3,\n});\n\nconst query3 = 'What is the weather like?';\nconst response3 = 'It is sunny and warm outside.';\n\nconsole.log('Example 3 - N/A Instructions:');\nconsole.log('Instructions:', instructions3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n  details: result3.info.scoreDetails,\n});\n```\n\n----------------------------------------\n\nTITLE: Vector Store Error Handling Implementation\nDESCRIPTION: Shows how to implement error handling for vector store operations using try-catch blocks and custom error types. Includes error code and details extraction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector and Mastra Instance\nDESCRIPTION: Creates instances of PgVector and Mastra with configured components for the RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Injecting Mastra Instance into Workflow Context (TypeScript)\nDESCRIPTION: This snippet shows how to inject a Mastra instance into the workflow context for creating dynamic workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nconst mastra = new Mastra();\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  mastra,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Separate Steps for a Mastra Workflow\nDESCRIPTION: This snippet shows how to define steps independently before adding them to a workflow. It demonstrates creating standalone step objects with their own execution logic and output schemas, then linking them together in a workflow. This approach enhances modularity and reusability of step definitions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/steps.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Define steps separately\nconst stepOne = new Step({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 };\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow.step(stepOne).then(stepTwo);\nmyWorkflow.commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  workflows: { myWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector with Connection String\nDESCRIPTION: This code snippet demonstrates how to instantiate the `PgVector` class using a PostgreSQL connection string. It establishes a connection to the database, enabling vector operations. The connection string includes the necessary authentication details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\n// Using a connection string (string form)\nconst vectorStore1 = new PgVector('postgresql://user:password@localhost:5432/mydb');\n```\n\n----------------------------------------\n\nTITLE: Using AzureTTS class for Speech Generation in TypeScript\nDESCRIPTION: This code demonstrates how to use the AzureTTS class to initialize the TTS service, list available voices, and generate speech from text.  It shows both generating speech and streaming speech using Azure's Neural Voice technology.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/azure/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { AzureTTS } from '@mastra/speech-azure';\n\n// Initialize with configuration\nconst tts = new AzureTTS({\n  model: {\n    name: 'en-US-AriaNeural', // Default voice\n    apiKey: 'your-api-key', // Optional, can use AZURE_API_KEY env var\n    region: 'your-region', // Optional, can use AZURE_REGION env var\n  },\n});\n\n// List available voices\nconst voices = await tts.voices();\n\n// Generate speech\nconst result = await tts.generate({\n  voice: 'en-US-AriaNeural',\n  text: 'Hello from Mastra!',\n});\n\n// Stream speech\nconst stream = await tts.stream({\n  voice: 'en-US-AriaNeural',\n  text: 'Hello from Mastra!',\n});\"\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of resumeWithEvent() - TypeScript\nDESCRIPTION: Demonstrates a basic example of using the `resumeWithEvent()` method to resume a workflow after an 'approval' event.  It assumes the workflow is already defined and has been started.  The approval data is passed to the method, and the results are logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resumeWithEvent.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Define and start a workflow\nconst workflow = mastra.getWorkflow(\"approval-workflow\");\nconst run = workflow.createRun();\n\n// Start the workflow\nawait run.start({ triggerData: { requestId: \"req-123\" } });\n\n// Later, when the approval event occurs:\nconst result = await run.resumeWithEvent(\"approval\", {\n  approved: true,\n  approverName: \"John Doe\",\n  comment: \"Looks good to me!\",\n});\n\nconsole.log(result.results);\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Agent for Query Understanding\nDESCRIPTION: Sets up a Mastra agent with instructions for understanding user queries, applying metadata filters, and generating responses based on filtered context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.\n\n  Filter the context by searching the metadata.\n  \n  The metadata is structured as follows:\n\n  {\n    text: string,\n    excerptKeywords: string,\n    nested: {\n      keywords: string[],\n      id: number,\n    },\n  }\n\n  ${PGVECTOR_PROMPT}\n\n  Important: When asked to answer a question, please base your answer only on the context provided in the tool. \n  If the context doesn't contain enough information to fully answer the question, please state that explicitly.\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing an AI Agent\nDESCRIPTION: Creates a new AI agent with specified name, instructions, and model configuration using OpenAI\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\n\nconst agent = new Agent({\n  name: 'my-agent',\n  instructions: 'Your task-specific instructions',\n  model: openai('gpt-4o-mini'),\n  tools: {}, // Optional tools\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra RAG Agent\nDESCRIPTION: Setup of a Mastra agent with specific instructions and model configuration for handling RAG operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  instructions:\n    'You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.',\n  model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking Text Using Mastra RAG in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the MDocument class from Mastra's RAG module to split plain text content into smaller chunks. It creates a document from plain text and then applies the chunking method with default settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-text.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk();\n```\n\n----------------------------------------\n\nTITLE: Using Agent with Tool Call Mode\nDESCRIPTION: This code shows how to interact with the agent in tool-call mode.  Since the agent updates the working memory via tool calls, there's no need to mask any tags in the response stream. The code iterates through the response stream and writes the output directly to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolCallResponse = await toolCallAgent.stream(\"Hello, my name is Jane\", {\n  threadId,\n  resourceId,\n});\n\n// ツールコールを通じて更新が行われるため、作業メモリタグを隠す必要はありません\nfor await (const chunk of toolCallResponse.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using Real-time Voice Provider with OpenAI in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize an OpenAI real-time voice provider, connect to the service, set up event listeners for responses, and stream audio data for processing. It shows configuration for audio quality settings and handling both microphone streams and audio buffers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.send.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Set up event listeners for responses\nvoice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role}: ${text}`);\n});\n\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker)\n});\n\n// Get microphone stream (implementation depends on your environment)\nconst microphoneStream = getMicrophoneStream();\n\n// Send audio data to the voice provider\nawait voice.send(microphoneStream);\n\n// You can also send audio data as Int16Array\nconst audioBuffer = getAudioBuffer(); // Assume this returns Int16Array\nawait voice.send(audioBuffer);\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra Multi-Agent Workflow\nDESCRIPTION: This snippet shows the necessary imports for creating a multi-agent workflow in Mastra. It includes OpenAI and Anthropic AI SDKs, Mastra core components, and Zod for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Chunking JSON Data with Mastra RAG\nDESCRIPTION: This code snippet demonstrates how to chunk JSON data using the `MDocument` class from the `@mastra/rag` library. The `fromJSON` method converts a JSON string into an `MDocument`, and the `chunk` method splits the document into smaller chunks based on the specified `maxSize`. The resulting chunks are then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/chunk-json.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst testJson = {\n  name: \"John Doe\",\n  age: 30,\n  email: \"john.doe@example.com\",\n};\n\nconst doc = MDocument.fromJSON(JSON.stringify(testJson));\n\nconst chunks = await doc.chunk({\n  maxSize: 100,\n});\n\nconsole.log(chunks);\n```\n\n----------------------------------------\n\nTITLE: Using updateConfig() with OpenAI Realtime Voice Provider in TypeScript\nDESCRIPTION: Example demonstrating how to initialize an OpenAI realtime voice provider, connect to it, update its configuration at runtime to change voice settings, and then use the updated configuration. Shows changing the voice from 'alloy' to 'nova' and setting turn detection parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.updateConfig.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  speaker: \"alloy\",\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Later, update the configuration\nvoice.updateConfig({\n  voice: \"nova\", // Change the default voice\n  turn_detection: {\n    type: \"server_vad\",\n    threshold: 0.5,\n    silence_duration_ms: 1000\n  }\n});\n\n// The next speak() call will use the new configuration\nawait voice.speak(\"Hello with my new voice!\");\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool Configuration\nDESCRIPTION: Configuration of the vector query tool with vector store settings and embedding model specification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Getting All Tools - TypeScript\nDESCRIPTION: Retrieves a list of all available tools from the Mastra platform using the client instance. This snippet requires an initialized client and allows easy access to the tools available in the platform.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/tools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst tools = await client.getTools();\n```\n\n----------------------------------------\n\nTITLE: Initializing an Agent with OpenAI Model (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create an agent using the `Agent` class from `@mastra/core/agent`. It imports the necessary modules, including the `openai` function from `@ai-sdk/openai`, and initializes an agent named 'My Agent' with specific instructions and the 'gpt-4o-mini' model. The agent is configured to be a helpful assistant.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Integrating a Custom Tool in a Mastra Workflow (TypeScript)\nDESCRIPTION: This code defines a custom tool using `@mastra/core/tools` to crawl a webpage and extract text content. It specifies input and output schemas using `zod` for validation. The tool is then integrated into a workflow created with `@mastra/core/workflows` and executed with a sample URL. The final result is logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/using-a-tool-as-a-step.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from '@mastra/core/tools';\nimport { Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\nconst crawlWebpage = createTool({\n  id: 'Crawl Webpage',\n  description: 'Crawls a webpage and extracts the text content',\n  inputSchema: z.object({\n    url: z.string().url(),\n  }),\n  outputSchema: z.object({\n    rawText: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const response = await fetch(context.triggerData.url);\n    const text = await response.text();\n    return { rawText: 'This is the text content of the webpage: ' + text };\n  },\n});\n\nconst contentWorkflow = new Workflow({ name: 'content-review' });\n\ncontentWorkflow.step(crawlWebpage).commit();\n\nconst { start } = contentWorkflow.createRun();\n\nconst res = await start({ triggerData: { url: 'https://example.com'} });\n\nconsole.log(res.results);\n```\n\n----------------------------------------\n\nTITLE: Performing Metadata Filtering in Vector Queries with TypeScript\nDESCRIPTION: This snippet demonstrates various metadata filtering techniques for vector queries. It includes examples of simple equality filters, numeric comparisons, multiple conditions, array operations, and logical operators.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Simple equality filter\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    source: \"article1.txt\"\n  }\n});\n\n// Numeric comparison\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    price: { $gt: 100 }\n  }\n});\n\n// Multiple conditions\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    category: \"electronics\",\n    price: { $lt: 1000 },\n    inStock: true\n  }\n});\n\n// Array operations\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    tags: { $in: [\"sale\", \"new\"] }\n  }\n});\n\n// Logical operators\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    $or: [\n      { category: \"electronics\" },\n      { category: \"accessories\" }\n    ],\n    $and: [\n      { price: { $gt: 50 } },\n      { price: { $lt: 200 } }\n    ]\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Workflow Results in Mastra (TypeScript)\nDESCRIPTION: Illustrates how to access the results of a nested workflow from within the parent workflow's context after the parent workflow has completed. The results are accessed by the nested workflow's name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst { results } = await parentWorkflow.start();\n// Access nested workflow results\nconst nestedWorkflowResult = results[\"nested-workflow\"];\nif (nestedWorkflowResult.status === \"success\") {\n  const nestedResults = nestedWorkflowResult.output.results;\n}\n```\n\n----------------------------------------\n\nTITLE: Generate Structured Recipe Data with Chef Agent\nDESCRIPTION: This code shows how to generate structured data from the chef agent, specifically a recipe with ingredients and steps, using Zod for schema validation. It defines a Zod schema for the expected output format and passes it to the `chefAgent.generate` method. The resulting object is then printed to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\nasync function main() {\n  const query =\n    \"I want to make lasagna, can you generate a lasagna recipe for me?\";\n  console.log(`Query: ${query}`);\n\n  // Define the Zod schema\n  const schema = z.object({\n    ingredients: z.array(\n      z.object({\n        name: z.string(),\n        amount: z.string(),\n      }),\n    ),\n    steps: z.array(z.string()),\n  });\n\n  const response = await chefAgent.generate(\n    [{ role: \"user\", content: query }],\n    { output: schema },\n  );\n  console.log(\"\\n👨‍🍳 Chef Michel:\", response.object);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Creating a Weather Tool in Mastra\nDESCRIPTION: This code defines a weather tool that retrieves weather information for a given location using external APIs. It uses `zod` for input and output schema validation, and the `createTool` function from `@mastra/core/tools` to create the tool. The tool's `execute` function calls the `getWeather` function to fetch and process weather data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/using-a-tool.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\ninterface WeatherResponse {\n  current: {\n    time: string;\n    temperature_2m: number;\n    apparent_temperature: number;\n    relative_humidity_2m: number;\n    wind_speed_10m: number;\n    wind_gusts_10m: number;\n    weather_code: number;\n  };\n}\n\nconst weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"特定の場所の現在の天気を取得する\",\n  inputSchema: z.object({\n    location: z.string().describe(\"都市名\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    feelsLike: z.number(),\n    humidity: z.number(),\n    windSpeed: z.number(),\n    windGust: z.number(),\n    conditions: z.string(),\n    location: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return await getWeather(context.location);\n  },\n});\n\nconst getWeather = async (location: string) => {\n  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;\n  const geocodingResponse = await fetch(geocodingUrl);\n  const geocodingData = await geocodingResponse.json();\n\n  if (!geocodingData.results?.[0]) {\n    throw new Error(`場所 '${location}' が見つかりません`);\n  }\n\n  const { latitude, longitude, name } = geocodingData.results[0];\n\n  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;\n\n  const response = await fetch(weatherUrl);\n  const data: WeatherResponse = await response.json();\n\n  return {\n    temperature: data.current.temperature_2m,\n    feelsLike: data.current.apparent_temperature,\n    humidity: data.current.relative_humidity_2m,\n    windSpeed: data.current.wind_speed_10m,\n    windGust: data.current.wind_gusts_10m,\n    conditions: getWeatherCondition(data.current.weather_code),\n    location: name,\n  };\n};\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"晴天\",\n    1: \"主に晴れ\",\n    2: \"部分的に曇り\",\n    3: \"曇り\",\n    45: \"霧\",\n    48: \"霧氷の霧\",\n    51: \"小雨\",\n    53: \"中程度の霧雨\",\n    55: \"濃い霧雨\",\n    56: \"軽い凍結霧雨\",\n    57: \"濃い凍結霧雨\",\n    61: \"小雨\",\n    63: \"中程度の雨\",\n    65: \"大雨\",\n    66: \"軽い凍結雨\",\n    67: \"激しい凍結雨\",\n    71: \"小雪\",\n    73: \"中程度の雪\",\n    75: \"大雪\",\n    77: \"雪粒\",\n    80: \"小雨のにわか雨\",\n    81: \"中程度のにわか雨\",\n    82: \"激しいにわか雨\",\n    85: \"小雪のにわか雪\",\n    86: \"大雪のにわか雪\",\n    95: \"雷雨\",\n    96: \"小さな雹を伴う雷雨\",\n    99: \"大きな雹を伴う雷雨\",\n  };\n  return conditions[code] || \"不明\";\n}\n\nconst weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `あなたは正確な天気情報を提供する役立つ天気アシスタントです。\nあなたの主な機能は、特定の場所の天気の詳細をユーザーに提供することです。応答する際には：\n- 場所が提供されていない場合は必ず尋ねてください\n- 場所の名前が英語でない場合は翻訳してください\n- 湿度、風の状況、降水量などの関連する詳細を含めてください\n- 応答は簡潔でありながら情報豊かにしてください\nweatherToolを使用して現在の天気データを取得してください。`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { weatherTool },\n});\n\nconst mastra = new Mastra({\n  agents: { weatherAgent },\n});\n\nasync function main() {\n  const agent = await mastra.getAgent(\"weatherAgent\");\n  const result = await agent.generate(\"ロンドンの天気はどうですか？\");\n  console.log(result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Evaluating high recall response using Contextual Recall metric in TypeScript\nDESCRIPTION: This example demonstrates how to evaluate a response that includes all context information using the Contextual Recall metric. It sets up the context, creates the metric instance, and measures the recall score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'Product features include cloud sync.',\n  'Offline mode is available.',\n  'Supports multiple devices.',\n];\n\nconst metric1 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'What are the key features of the product?';\nconst response1 = 'The product features cloud synchronization, offline mode support, and the ability to work across multiple devices.';\n\nconsole.log('Example 1 - High Recall:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'All elements of the output are supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool for RAG\nDESCRIPTION: Sets up a vector query tool for interacting with the PgVector store using OpenAI embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Basic MCPConfiguration Usage with Agent\nDESCRIPTION: Illustrates a basic example of using MCPConfiguration to configure multiple servers (stockPrice and weather), and creating an Agent with access to tools from these servers. Includes setting API keys and defining server connection details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst mcp = new MCPConfiguration({\n  servers: {\n    stockPrice: {\n      command: \"npx\",\n      args: [\"tsx\", \"stock-price.ts\"],\n      env: {\n        API_KEY: \"your-api-key\",\n      },\n      log: (logMessage) => {\n        console.log(`[${logMessage.level}] ${logMessage.message}`);\n      },\n    },\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),∂\n    },\n  },\n  timeout: 30000, // Global 30s timeout\n});\n\n// Create an agent with access to all tools\nconst agent = new Agent({\n  name: \"Multi-tool Agent\",\n  instructions: \"You have access to multiple tool servers.\",\n  model: openai(\"gpt-4\"),\n  tools: await mcp.getTools(),\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Vector and Metadata\nDESCRIPTION: This code shows how to update both the vector and its metadata simultaneously using the `updateIndexById` method.  The method updates both the vector embeddings and associated metadata for the specified vector ID. This allows for comprehensive data modification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Update both vector and metadata\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  vector: [0.1, 0.2, 0.3],\n  metadata: { label: \"updated\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Managing Event Listeners in Mastra Real-time Voice API - TypeScript\nDESCRIPTION: The snippet demonstrates the use of the off() method to remove event listeners in a real-time voice application using Mastra's voice provider API. It imports necessary modules and initializes a voice provider with configuration details. It then connects to the service, sets up event listeners for specific voice events, and shows how to remove them to prevent memory resource issues. Dependencies include the @mastra/voice-openai-realtime package and chalk.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.off.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport chalk from \"chalk\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Define the callback function\nconst writingCallback = ({ text, role }) => {\n  if (role === 'user') {\n    process.stdout.write(chalk.green(text));\n  } else {\n    process.stdout.write(chalk.blue(text));\n  }\n};\n\n// Register event listener\nvoice.on(\"writing\", writingCallback);\n\n// Later, when you want to remove the listener\nvoice.off(\"writing\", writingCallback);\n```\n\n----------------------------------------\n\nTITLE: Tone Consistency Metric Example with Output\nDESCRIPTION: This code snippet provides a complete example of using the `ToneConsistencyMetric` in both tone consistency and tone stability modes, along with example outputs. It showcases how the metric can be used to evaluate the consistency of tone between two different texts and the stability of tone within a single text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/tone-consistency.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ToneConsistencyMetric();\n\n// トーンの一貫性モード\nconst consistencyResult = await metric.measure(\n  \"この製品は素晴らしくて驚くべきものです！\",\n  \"製品は優れていて素晴らしいです！\"\n);\n// 例の出力:\n// {\n//   score: 0.95,\n//   info: {\n//     responseSentiment: 0.8,\n//     referenceSentiment: 0.75,\n//     difference: 0.05\n//   }\n// }\n\n// トーンの安定性モード\nconst stabilityResult = await metric.measure(\n  \"素晴らしいサービス！フレンドリーなスタッフ。完璧な雰囲気。\",\n  \"\"\n);\n// 例の出力:\n// {\n//   score: 0.9,\n//   info: {\n//     avgSentiment: 0.6,\n//     sentimentVariance: 0.1\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Embedding Examples using Mastra AI SDK with OpenAI\nDESCRIPTION: This code shows examples of how to use both `embed` and `embedMany` functions from the Mastra AI SDK with OpenAI for generating embeddings. It imports necessary functions from `ai` and `@ai-sdk/openai`, and then demonstrates how to generate a single embedding and multiple embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/embeddings.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed, embedMany } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\n// Single embedding\nconst singleResult = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: \"What is the meaning of life?\",\n});\n\n// Multiple embeddings\nconst multipleResult = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: [\n    \"First question about life\",\n    \"Second question about universe\",\n    \"Third question about everything\"\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Adding a Step to a Workflow using Workflow.step() in Typescript\nDESCRIPTION: This code snippet demonstrates how to use the `Workflow.step()` method to add a new step to a workflow. It includes the step's ID, output schema (using Zod), and the asynchronous `execute` function that defines the step's logic. The step returns a simple object with a 'result' property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-function.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    result: z.number()\n  }),\n  execute: async ({ context }) => {\n    return { result: 42 };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Using Agent Memory in Conversations\nDESCRIPTION: Example demonstrating how to use memory in agent interactions by providing resourceId and threadId parameters. This allows the agent to maintain context across multiple exchanges with the same user.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/agent-memory.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Example agent call using memory\nawait agent.stream(\"Remember my favorite color is blue.\", {\n  resourceId: \"user_alice\",\n  threadId: \"preferences_thread\",\n});\n\n// Later in the same thread...\nconst response = await agent.stream(\"What's my favorite color?\", {\n  resourceId: \"user_alice\",\n  threadId: \"preferences_thread\",\n});\n// Agent will use memory to recall the favorite color.\n```\n\n----------------------------------------\n\nTITLE: Using the Speak Method for TTS\nDESCRIPTION: This code snippet demonstrates how to use the `speak()` method to convert text to speech using the OpenAI Voice TTS provider within a Mastra agent.  It shows how to initialize an agent with the OpenAI model and the `OpenAIVoice`, generate text with the agent, and then convert that text into a readable audio stream using `voice.speak()`. The optional `speaker` and `properties` parameters allow for further customization of the generated voice.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/text-to-speech.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\nconst voice = new OpenAIVoice();\n\nconst agent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\nconst { text } = await agent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst readableStream = await voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n  properties: {\n    speed: 1.0, // Optional: adjust speech speed\n    pitch: \"default\", // Optional: specify pitch if supported\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Tools from MCP Server in TypeScript\nDESCRIPTION: The tools method synchronizes available tools from the MCP server, converting and returning them in a Mastra-compatible format asynchronously. It returns a promise of a record mapping tool names to implementations. Ensure active connection to the server before use.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync tools(): Promise<Record<string, Tool>>\n```\n\n----------------------------------------\n\nTITLE: Querying with Metadata Filter in TypeScript\nDESCRIPTION: This code snippet shows how to perform a hybrid vector search using metadata filters with PGVector. It creates an embedding from a query, then queries the PGVector store with the embedding, specifying a filter to narrow down the results based on metadata. The result will contain documents that match both the semantic query and metadata filter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/query/hybrid-vector-search.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// クエリの埋め込みを作成\nconst { embedding } = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: '[ここにドキュメントに基づくクエリを挿入]',\n});\n\n// メタデータフィルタを使用したクエリ\nconst result = await pgVector.query({\n  indexName: 'embeddings',\n  queryVector: embedding,\n  topK: 3,\n  filter: {\n    'path.to.metadata': {\n      $eq: 'value',\n    },\n  },\n});\n\nconsole.log('結果:', result);\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Upstash in Typescript\nDESCRIPTION: This snippet shows how to integrate an `UPSTASH_PROMPT` into an agent's instructions for querying Upstash.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { UPSTASH_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${UPSTASH_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Retry Example in Mastra Workflow\nDESCRIPTION: This code snippet illustrates a basic retry example in a Mastra workflow, defining a step that simulates an unreliable API call and configuring retries to handle potential failures. It sets the number of retry attempts and the delay between attempts for the unreliable step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-retries.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\n\n// Define a step that might fail\nconst unreliableApiStep = new Step({\n  id: 'callUnreliableApi',\n  execute: async () => {\n    // Simulate an API call that might fail\n    const random = Math.random();\n    if (random < 0.7) {\n      throw new Error('API call failed');\n    }\n    return { data: 'API response data' };\n  },\n  retryConfig: {\n    attempts: 3,  // Retry up to 3 times\n    delay: 2000,  // Wait 2 seconds between attempts\n  },\n});\n\n// Create a workflow with the unreliable step\nconst workflow = new Workflow({\n  name: 'retry-demo-workflow',\n});\n\nworkflow\n  .step(unreliableApiStep)\n  .then(processResultStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Creating a Step instance with Zod schemas in Typescript\nDESCRIPTION: This snippet demonstrates how to create a Step instance with an ID, input schema, output schema, and execute function using the Zod library for schema validation. The execute function defines the logic of the step and returns a promise with the result.  It showcases the basic structure and parameters needed when defining a workflow step in Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-class.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst processOrder = new Step({\n  id: \"processOrder\",\n  inputSchema: z.object({\n    orderId: z.string(),\n    userId: z.string()\n  }),\n  outputSchema: z.object({\n    status: z.string(),\n    orderId: z.string()\n  }),\n  execute: async ({ context, runId }) => {\n    return {\n      status: \"processed\",\n      orderId: context.orderId\n    };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Building HNSW Index\nDESCRIPTION: This code shows how to build or rebuild an HNSW (Hierarchical Navigable Small World) index. It invokes the `buildIndex` method with the index name, cosine distance metric, and a configuration object specifying the HNSW index type and its parameters like 'm' (maximum number of connections per node) and 'efConstruction' (construction effort).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Define HNSW index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"hnsw\",\n  hnsw: {\n    m: 8,\n    efConstruction: 32,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow else() Usage Example (Typescript)\nDESCRIPTION: Demonstrates the basic usage of the `.else()` method in a Mastra workflow. It shows how to define a conditional branch using `if()` and create an alternative branch with `.else()` that executes when the condition is false. The workflow includes steps for both the `if` and `else` branches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/else.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return value < 10;\n  })\n  .then(ifBranchStep)\n  .else() // Alternative branch when the condition is false\n  .then(elseBranchStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Basic Answer Relevancy Metric Usage - Typescript\nDESCRIPTION: This code demonstrates the basic usage of the `AnswerRelevancyMetric` class to evaluate the relevancy of an LLM's output. It imports necessary modules, configures the model, instantiates the metric, calls the `measure` method with an input query and the LLM's response, and logs the resulting score and reason. Dependencies: `@ai-sdk/openai`, `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/answer-relevancy.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { AnswerRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new AnswerRelevancyMetric(model, {\n  uncertaintyWeight: 0.3,\n  scale: 1,\n});\n\nconst result = await metric.measure(\n  \"What is the capital of France?\",\n  \"Paris is the capital of France.\",\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Conditional Branching Workflow in Typescript\nDESCRIPTION: This code demonstrates how to create a Mastra workflow with conditional branching based on the success or failure status of a previous step. It utilizes the `then` method with a `when` condition to execute different steps based on the context.  It requires the `Workflow` class from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a workflow with conditional branching\nconst workflow = new Workflow({\n  name: 'error-handling-workflow',\n});\n\nworkflow\n  .step(fetchDataStep)\n  .then(processDataStep, {\n    // Only execute processDataStep if fetchDataStep was successful\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === 'success';\n    },\n  })\n  .then(fallbackStep, {\n    // Execute fallbackStep if fetchDataStep failed\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === 'failed';\n    },\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Working Memory Configuration\nDESCRIPTION: This snippet illustrates how to configure the `workingMemory` option within the `Memory` class to enable persistent information storage. It shows how to set a custom template for the working memory and choose between 'text-stream' and 'tool-call' modes for updating the memory content. This config determines how the agent updates and interacts with working memory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      template: \"# User\\n- **First Name**:\\n- **Last Name**:\",\n      use: \"tool-call\", // or 'text-stream'\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Inline Steps in Mastra Workflow (TypeScript)\nDESCRIPTION: This code demonstrates how to create steps directly within a Mastra workflow using the `.step()` and `.then()` methods. It defines two steps in sequence, linking them together to form a basic workflow. The steps calculate and increment values based on an input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/steps.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\nexport const myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow\n  .step(\n    new Step({\n      id: \"stepOne\",\n      outputSchema: z.object({\n        doubledValue: z.number(),\n      }),\n      execute: async ({ context }) => ({\n        doubledValue: context.triggerData.inputValue * 2,\n      }),\n    }),\n  )\n  .then(\n    new Step({\n      id: \"stepTwo\",\n      outputSchema: z.object({\n        incrementedValue: z.number(),\n      }),\n      execute: async ({ context }) => {\n        if (context.steps.stepOne.status !== \"success\") {\n          return { incrementedValue: 0 };\n        }\n\n        return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 };\n      },\n    }),\n  ).commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { myWorkflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Working with Prompt Variables in TypeScript\nDESCRIPTION: Illustrates defining variable types and creating a template with dynamic values for a code review prompt. Variables are used to customize prompts with specific file and change details, enhancing template flexibility.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Define variable types\ntype CodeReviewVars = {\n  file: string;\n  changes: number;\n};\n\n// Create template with variables\nconst reviewTemplate = createPrompt<CodeReviewVars>('Review code changes')\n  .text('Review {{changes}} changes in {{file}}')\n  .constraints(['Focus on {{file}} specific patterns', 'Suggest maximum {{changes}} improvements']);\n\n// Use the template with different values\nconst review1 = reviewTemplate.toString({\n  file: 'auth.ts',\n  changes: 3,\n});\n\nconst review2 = reviewTemplate.toString({\n  file: 'api.ts',\n  changes: 5,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating GlutenCheckerMetric Class for Recipe Evaluation\nDESCRIPTION: Implements a metric class that uses the judge to evaluate recipes for gluten content. The class orchestrates the evaluation process, calculates a binary score based on gluten content, and provides comprehensive evaluation results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nexport interface MetricResultWithInfo extends MetricResult {\\n  info: {\\n    reason: string;\\n    glutenSources: string[];\\n  };\\n}\\n\\nexport class GlutenCheckerMetric extends Metric {\\n  private judge: GlutenCheckerJudge;\\n  constructor(model: LanguageModel) {\\n    super();\\n\\n    this.judge = new GlutenCheckerJudge(model);\\n  }\\n\\n  async measure(output: string): Promise<MetricResultWithInfo> {\\n    const { isGlutenFree, glutenSources } = await this.judge.evaluate(output);\\n    const score = await this.calculateScore(isGlutenFree);\\n    const reason = await this.judge.getReason({\\n      isGlutenFree,\\n      glutenSources,\\n    });\\n\\n    return {\\n      score,\\n      info: {\\n        glutenSources,\\n        reason,\\n      },\\n    };\\n  }\\n\\n  async calculateScore(isGlutenFree: boolean): Promise<number> {\\n    return isGlutenFree ? 1 : 0;\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Define Conclusion Step Typescript\nDESCRIPTION: Defines a workflow step `drawConclusions` using the `Step` class. This step draws conclusions based on the connections made in the previous step. It retrieves the connections from the `connectPieces` step and uses the RAG agent to derive conclusions based solely on the evidence from the retrieved context. The conclusions are then returned as the step's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst drawConclusions = new Step({\n  id: \"drawConclusions\",\n  outputSchema: z.object({\n    conclusions: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const evidence = context?.getStepResult<{\n      connections: string;\n    }>(\"connectPieces\")?.connections;\n    const conclusionPrompt = `\n        接続に基づいて: ${evidence}\n\n        4. 取得したコンテキストの証拠に基づいてのみ結論を導き出します。\n    `;\n\n    const conclusions = await ragAgent?.generate(conclusionPrompt);\n    console.log(conclusions?.text);\n    return {\n      conclusions: conclusions?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Final Evaluation Step in TypeScript\nDESCRIPTION: This code defines the final evaluation step, which assesses the improved content generated by the `improveResponse` step.  It retrieves the improved content from the context and calculates tone and completeness scores using simulated functions. The `execute` function returns an object containing these scores.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 5: Final evaluation\nconst evaluateImproved = new Step({\n  id: 'evaluateImprovedResponse',\n  execute: async ({ context }) => {\n    const improvedContent = context.getStepResult(improveResponse)?.improvedOutput;\n\n    // Simulate final evaluation\n    return {\n      toneScore: { score: calculateToneScore(improvedContent) },\n      completenessScore: { score: calculateCompletenessScore(improvedContent) },\n    };\n  },\n  outputSchema: z.object({\n    toneScore: z.any(),\n    completenessScore: z.any(),\n  }),\n});\n\n// Build the workflow\nconst contentWorkflow = new Workflow({\n  name: 'content-generation-workflow',\n  triggerSchema: z.object({ input: z.string() }),\n});\n\ncontentWorkflow\n  .step(getUserInput)\n  .then(promptAgent)\n  .then(evaluateTone)\n  .then(improveResponse)\n  .then(evaluateImproved)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Chunking JSON with MDocument in TypeScript\nDESCRIPTION: Demonstrates how to split a JSON document into semantic chunks using Mastra's MDocument class. The example shows creating a document from JSON data and chunking it with a specified maximum size while preserving the object structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-json.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst testJson = {\n  name: \"John Doe\",\n  age: 30,\n  email: \"john.doe@example.com\",\n};\n\nconst doc = MDocument.fromJSON(JSON.stringify(testJson));\n\nconst chunks = await doc.chunk({\n  maxSize: 100,\n});\n\nconsole.log(chunks);\n```\n\n----------------------------------------\n\nTITLE: Configuring Upstash Environment Variables - Bash\nDESCRIPTION: This snippet demonstrates how to set the required environment variables for Upstash, which are necessary for the Mastra memory system to connect and authenticate with Upstash. The `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` variables need to be configured with the appropriate credentials.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-upstash.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nUPSTASH_REDIS_REST_URL=your-redis-url\nUPSTASH_REDIS_REST_TOKEN=your-redis-token\n```\n\n----------------------------------------\n\nTITLE: Example Usage of rerank with AI SDK\nDESCRIPTION: This snippet demonstrates how to import and utilize the `rerank` function with the GPT-4 model for reranking vector search results based on a specific query and user-defined weight configuration. It employs asynchronous operations to handle promised rerank results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/rerank.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { rerank } from \"@mastra/rag\";\n\nconst model = openai(\"gpt-4o-mini\");\n\nconst rerankedResults = await rerank(\n  vectorSearchResults,\n  \"How do I deploy to production?\",\n  model,\n  {\n    weights: {\n      semantic: 0.5,\n      vector: 0.3,\n      position: 0.2\n    },\n    topK: 3\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Summarization Metric with OpenAI Model\nDESCRIPTION: Configures the `SummarizationMetric` with a specified OpenAI model (`gpt-4o-mini`). This metric will be used to evaluate the quality and factual accuracy of summaries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new SummarizationMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Agent for RAG\nDESCRIPTION: Creates a Mastra agent with GPT-4 model and the vector query tool for handling RAG operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool\nDESCRIPTION: This snippet demonstrates how to create a vector query tool using the `createVectorQueryTool` function from `@mastra/rag`. It configures the tool with the vector store name, index name, and the OpenAI embedding model. This tool is used to query the vector database for relevant text chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Adding Middleware to Mastra Server\nDESCRIPTION: Demonstrates how to add global middleware functions to handle authentication and request processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\n\nexport const mastra = new Mastra({\n  // Other configuration options\n  server: {\n    middleware: [\n    {\n      handler: async (c, next) => {\n        // Example: Add authentication check\n        const authHeader = c.req.header('Authorization');\n        if (!authHeader) {\n          return new Response('Unauthorized', { status: 401 });\n        }\n\n        // Continue to the next middleware or route handler\n        await next();\n      },\n      path: '/api/*'\n    },\n    // add middleware to all routes\n    async (c, next) => {\n      // Example: Add request logging\n      console.log(`${c.req.method} ${c.req.url}`);\n      await next();\n    },\n  ]\n});\n```\n\n----------------------------------------\n\nTITLE: Disabling Semantic Recall\nDESCRIPTION: This code snippet shows how to disable semantic recall in the Memory options. By setting `semanticRecall` to `false`, the agent will not use vector embeddings for similarity search, which can improve performance in scenarios where conversation history provides sufficient context or in performance-sensitive applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  memory: new Memory({\n    options: {\n      semanticRecall: false,\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Using Vercel AI SDK and Mastra Tools in Agent (TypeScript)\nDESCRIPTION: This code snippet illustrates how to use both Vercel AI SDK tools and Mastra tools within the same agent. It imports the Vercel AI SDK tool (`weatherInfo`) and Mastra tools from a separate module (`mastraTools`), and combines them in the `tools` property of the agent configuration. This demonstrates seamless integration between the two tool formats.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { weatherInfo } from \"../tools/vercelTool\";\nimport * as mastraTools from \"../tools/mastraTools\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions:\n    \"You are a helpful assistant that provides weather information.\",\n  model: openai(\"gpt-4\"),\n  tools: {\n    weatherInfo, // Vercel tool\n    ...mastraTools, // Mastra tools\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors in AstraVector\nDESCRIPTION: Queries an index for similar vectors using a query vector and returns results according to specified parameters like top K and metadata filters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to query\",\n    },\n    {\n      name: \"queryVector\",\n      type: \"number[]\",\n      description: \"Query vector to find similar vectors\",\n    },\n    {\n      name: \"topK\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"10\",\n      description: \"Number of results to return\",\n    },\n    {\n      name: \"filter\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"Metadata filters for the query\",\n    },\n    {\n      name: \"includeVector\",\n      type: \"boolean\",\n      isOptional: true,\n      defaultValue: \"false\",\n      description: \"Whether to include vectors in the results\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Executing Steps in Parallel in Mastra Workflows\nDESCRIPTION: Demonstrates how to run multiple workflow steps simultaneously when they don't depend on each other, which can improve workflow execution speed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(fetchUserData).step(fetchOrderData);\n```\n\n----------------------------------------\n\nTITLE: Install Memory Package (pnpm)\nDESCRIPTION: This command installs the @mastra/memory package using pnpm. This package provides the necessary functionality for implementing memory processors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Evaluating low recall response using Contextual Recall metric in TypeScript\nDESCRIPTION: This example demonstrates how to evaluate a response that misses most context information using the Contextual Recall metric. It sets up another context, creates a metric instance, and measures the recall score for an incorrect response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'The solar system has eight planets.',\n  'Mercury is closest to the Sun.',\n  'Venus is the hottest planet.',\n  'Mars is called the Red Planet.',\n];\n\nconst metric3 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'Tell me about the solar system.';\nconst response3 = 'Jupiter is the largest planet in the solar system.';\n\nconsole.log('Example 3 - Low Recall:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'None of the output is supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Monitoring and Resuming Workflows - TypeScript\nDESCRIPTION: This code demonstrates how to use the `watch` method to monitor workflow status and the `resume` method to continue execution when a workflow is suspended.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\n// ワークフローを取得\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { start, watch, resume } = myWorkflow.createRun();\n\n// 実行前にワークフローを監視開始\nwatch(async ({ activePaths }) => {\n  const isStepTwoSuspended = activePaths.get(\"stepTwo\")?.status === \"suspended\";\n  if (isStepTwoSuspended) {\n    console.log(\"ワークフローが中断されました。新しい値で再開します\");\n\n    // 新しいコンテキストでワークフローを再開\n    await resume({\n      stepId: \"stepTwo\",\n      context: { secondValue: 100 },\n    });\n  }\n});\n\n// ワークフローの実行を開始\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n----------------------------------------\n\nTITLE: Chunking with Metadata Extraction in TypeScript\nDESCRIPTION: This code demonstrates how to combine document chunking with metadata extraction. It configures chunking options, including recursive strategy and metadata extraction per chunk, then retrieves and logs the metadata from chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/metadata-extraction.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Configure chunking with metadata extraction\nawait doc.chunk({\n  strategy: 'recursive',  // Use recursive chunking strategy\n  size: 200,             // Maximum chunk size\n  extract: {\n    keywords: true,      // Extract keywords per chunk\n    summary: true,       // Generate summary per chunk\n  },\n});\n\n// Get metadata from chunks\nconst metaTwo = doc.getMetadata();\nconsole.log('Chunk Metadata:', metaTwo);\n\n// Example Output:\n// Chunk Metadata: {\n//   keywords: [\n//     'exercise',\n//     'health benefits',\n//     'cardiovascular health',\n//     'mental wellbeing',\n//     'stress reduction',\n//     'sleep quality'\n//   ],\n//   summary: 'Regular exercise provides multiple health benefits including improved cardiovascular health, muscle strength, and mental wellbeing. Key benefits include stress reduction, better sleep, weight management, and increased energy. Recommended exercise duration is 150 minutes per week.'\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Query Tool in Typescript\nDESCRIPTION: This snippet demonstrates how to create a vector query tool using the `createVectorQueryTool` function. It configures the tool with the vector store name, index name, and OpenAI's embedding model. Pay attention to the name and description of the tool as they are used by the agent to determine how to use the tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Define Copywriter Step - TypeScript\nDESCRIPTION: This code snippet defines the copywriter step using the `Step` class from `@mastra/core/workflows`. It executes the `copywriterAgent` to generate a blog post based on the provided topic in the context's trigger data. The result is then processed, and the generated copy is returned.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterStep = new Step({\n  id: \"copywriterStep\",\n  execute: async ({ context }) => {\n    if (!context?.triggerData?.topic) {\n      throw new Error(\"トリガーデータにトピックが見つかりません\");\n    }\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.triggerData.topic}`,\n    );\n    console.log(\"copywriter result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Connecting to Mastra from Frontend (Client SDK)\nDESCRIPTION: This code snippet demonstrates how to connect to a Mastra server from a frontend application using the Mastra Client SDK. It initializes a MastraClient instance, providing the base URL of the Mastra backend. This client is used to interact with the Mastra server, facilitating communication between the frontend and backend for tasks such as generating story content and converting it to speech.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from '@mastra/client-js';\n\nexport const mastraClient = new MastraClient({\n  baseUrl: 'http://localhost:4111', // Replace with your Mastra backend URL\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing MastraMCPClient Constructor in TypeScript\nDESCRIPTION: The constructor initializes a new instance of MastraMCPClient with given parameters such as name, server configuration, capabilities, version, and timeout. It requires MastraMCPServerDefinition for server details and optional ClientCapabilities for extended configurations. Inputs include server details and configurations, while outputs are the initiated client instance. Be aware of the default timeout of 60000 milliseconds.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor({\n    name,\n    version = '1.0.0',\n    server,\n    capabilities = {},\n    timeout = 60000,\n}: {\n    name: string;\n    server: MastraMCPServerDefinition;\n    capabilities?: ClientCapabilities;\n    version?: string;\n    timeout?: number;\n})\n```\n\n----------------------------------------\n\nTITLE: Initializing Vector Query Tool with OpenAI\nDESCRIPTION: This snippet demonstrates how to initialize the `createVectorQueryTool` with OpenAI embedding model, Pinecone as the vector store, and a specified index. It imports the necessary modules from `@ai-sdk/openai` and `@mastra/rag`. The tool is configured to perform semantic search on a specified vector store index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/vector-query-tool.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { createVectorQueryTool } from \"@mastra/rag\";\n\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Optimized Query Execution\nDESCRIPTION: Implementation of the query execution after data optimization to demonstrate improved results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst cleanedResponse = await agent.generate(query);\nconsole.log('\\nQuery:', query);\nconsole.log('Response:', cleanedResponse.text);\n```\n\n----------------------------------------\n\nTITLE: Agent Tool Initialization with getTools()\nDESCRIPTION: Demonstrates how to use the `getTools()` method to retrieve all tools from configured servers and pass them to an Agent constructor. The tool names are namespaced by their server name to avoid naming conflicts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nnew Agent({ tools: await mcp.getTools() });\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow Execution with Context - Typescript\nDESCRIPTION: This code snippet demonstrates how to resume a suspended workflow step using the `.resume()` method. It takes a `runId`, `stepId`, and a `context` object as parameters. The `context` object contains new data that will be available to the step when it resumes execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resume.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nawait run.resume({\n  runId: \"abc-123\",\n  stepId: \"stepTwo\",\n  context: {\n    secondValue: 100\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Abstract GetSpeakers Method Definition\nDESCRIPTION: This code snippet defines the abstract `getSpeakers` method, requiring implementation in classes extending `MastraVoice`. This method is used to retrieve a list of available voices/speakers from the provider. Each voice must have at least a `voiceId` property, and providers can include additional metadata about each voice.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nabstract getSpeakers(): Promise<Array<{ voiceId: string; [key: string]: unknown }>>\n```\n\n----------------------------------------\n\nTITLE: Commit Workflow Configuration in TypeScript\nDESCRIPTION: This code example shows how to add steps to a workflow and commit the configuration. The 'commit()' method is called to validate the structure and ensure that all steps are correctly defined. It checks for common issues like circular dependencies and unreachable steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step('step1', {...})\n  .step('step2', {...})\n  .commit(); // Validates workflow structure\n```\n\n----------------------------------------\n\nTITLE: Basic Suspension Example - TypeScript\nDESCRIPTION: This code snippet demonstrates a simple workflow step that suspends execution if a value is below a threshold. The workflow will resume when a higher value is provided.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n\n    const currentValue = context.steps.stepOne.output.doubledValue;\n\n    if (currentValue < 100) {\n      await suspend();\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: currentValue + 1 };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Branching Paths in Mastra Workflow\nDESCRIPTION: This code demonstrates how to create a workflow with branching paths in Mastra using the `step` and `then` methods. It shows how to define two parallel branches originating from `stepOne`, with each branch executing different steps (`stepTwo` and `stepThree`, `stepFour`). The `.after([])` syntax merges the branches back together before executing the `finalStep`. The `createRun` method initiates a workflow run with sample input and logs the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/branching-paths.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// 2つの並列ブランチを作成\nmyWorkflow\n  // 最初のブランチ\n  .step(stepOne)\n  .then(stepTwo)\n\n  // 2番目のブランチ\n  .after(stepOne)\n  .step(stepThree)\n  .then(stepFour)\n\n  // 複合 after 構文を使用して両方のブランチをマージ\n  .after([stepTwo, stepFour])\n  .step(finalStep)\n  .commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst result = await start({ triggerData: { inputValue: 3 } });\nconsole.log(result.steps.finalStep.output.summary);\n// 出力: \"The number 3 when doubled is not divisible by 5, and when doubled and incremented is divisible by 3.\"\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Qdrant in Typescript\nDESCRIPTION: This snippet shows how to integrate a `QDRANT_PROMPT` into an agent's instructions for querying Qdrant.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { QDRANT_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${QDRANT_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Customizing Document Chunking in Mastra RAG with TypeScript\nDESCRIPTION: Example showing how to split a text document into chunks using a custom delimiter in Mastra. Uses the MDocument class to process plain text content with a specified separator character.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/adjust-chunk-delimiters.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Quick Start with Mastra Client in TypeScript\nDESCRIPTION: Basic example of initializing the Mastra client and using it to interact with an agent to generate a response. Shows the primary workflow of setting up the client and making a simple API call.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/client-sdks/client-js/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from '@mastra/client';\n\n// Initialize the client\nconst client = new MastraClient({\n  baseUrl: 'http://localhost:4111', // Your Mastra API endpoint\n});\n\n// Example: Working with an Agent\nasync function main() {\n  // Get an agent instance\n  const agent = client.getAgent('your-agent-id');\n\n  // Generate a response\n  const response = await agent.generate({\n    messages: [{ role: 'user', content: \"What's the weather like today?\" }],\n  });\n\n  console.log(response);\n}\n```\n\n----------------------------------------\n\nTITLE: Final Evaluation of Improved Response in Mastra Workflow - TypeScript\nDESCRIPTION: This snippet defines the last step in the workflow that evaluates the final improved content's tone and completeness. It receives the improved output from the previous step and simulates a final assessment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 5: Final evaluation\nconst evaluateImproved = new Step({\n  id: 'evaluateImprovedResponse',\n  execute: async ({ context }) => {\n    const improvedContent = context.getStepResult(improveResponse)?.improvedOutput;\n\n    // Simulate final evaluation\n    return {\n      toneScore: { score: calculateToneScore(improvedContent) },\n      completenessScore: { score: calculateCompletenessScore(improvedContent) },\n    };\n  },\n  outputSchema: z.object({\n    toneScore: z.any(),\n    completenessScore: z.any(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Middleware for Setting Temperature Scale\nDESCRIPTION: This code snippet presents an example of server middleware used to derive the temperature scale based on the user's country using the Cloudflare `CF-IPCountry` header.  It checks the header and sets the `temperature-scale` in the `runtimeContext` to \"farenheit\" for users in the US, and \"celsius\" for users in other countries. It demonstrates how to dynamically configure the agent's behavior based on incoming request information. Requires `@mastra/core` and `@mastra/core/di`\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { agent as weatherAgent } from \"./agents/weather\";\n\ntype MyRuntimeContext = {\"temperature-scale\", \"celsius\" | \"farenheit\"}\n\nexport const mastra = new Mastra({\n  agents: {\n    weather: weatherAgent,\n  },\n  server: {\n    middleware: [\n      (c, next) => {\n        const country = c.req.header(\"CF-IPCountry\");\n        const runtimeContext: MyRuntimeContext = c.get(\"runtimeContext\");\n\n        runtimeContext.set(\n          \"temperature-scale\",\n          country === \"US\" ? \"farenheit\" : \"celsius\",\n        );\n      },\n    ],\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Resume Data in Mastra Workflows (TypeScript)\nDESCRIPTION: This example demonstrates how to access and use resume data in a Mastra workflow using TypeScript. The `processOrderStep` can be suspended if `orderId` is missing. The workflow is then resumed with the `orderId` provided via `inputData`.  It uses `Step` and `Workflow` classes from `@mastra/core/workflows` and `zod` for schema definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  inputSchema: z.object({\n    orderId: z.string(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const { orderId } = context.inputData;\n\n    if (!orderId) {\n      await suspend();\n      return;\n    }\n\n    return {\n      orderId,\n      status: \"processed\"\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n});\n\nworkflow\n  .step(processOrderStep)\n  .commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\nconst resumedResult = await workflow.resume({\n  runId: result.runId,\n  stepId: 'processOrder',\n  inputData: {\n    orderId: '123',\n  },\n});\n\nconsole.log({resumedResult});\n```\n\n----------------------------------------\n\nTITLE: Create GitHub Tool\nDESCRIPTION: Creates a tool called `getMainBranchRef` that uses the GitHub integration to retrieve the reference of the main branch of a repository. It takes the repository owner and name as input and returns the reference string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core\";\nimport { z } from \"zod\";\nimport { github } from \"../integrations\";\n\nexport const getMainBranchRef = createTool({\n  id: \"getMainBranchRef\",\n  description: \"GitHubリポジトリからメインブランチの参照を取得する\",\n  inputSchema: z.object({\n    owner: z.string(),\n    repo: z.string(),\n  }),\n  outputSchema: z.object({\n    ref: z.string().optional(),\n  }),\n  execute: async ({ context }) => {\n    const client = await github.getApiClient();\n\n    const mainRef = await client.gitGetRef({\n      path: {\n        owner: context.owner,\n        repo: context.repo,\n        ref: \"heads/main\",\n      },\n    });\n\n    return { ref: mainRef.data?.ref };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Reviewing Recommendations with Human Input in Mastra Step\nDESCRIPTION: This snippet defines a Mastra Step for reviewing product recommendations with human input. It uses the suspend function to pause execution and collect input from a human reviewer.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Get human approval and customization for the recommendations\nconst reviewRecommendations = new Step({\n  id: 'reviewRecommendations',\n  inputSchema: z.object({\n    approvedProducts: z.array(z.string()),\n    customerNote: z.string().optional(),\n    offerDiscount: z.boolean().optional(),\n  }),\n  outputSchema: z.object({\n    finalRecommendations: z.array(\n      z.object({\n        productId: z.string(),\n        productName: z.string(),\n        price: z.number(),\n      }),\n    ),\n    customerNote: z.string().optional(),\n    offerDiscount: z.boolean(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const { customerName, recommendations } = context.getStepResult(generateRecommendations) || {\n      customerName: '',\n      recommendations: [],\n    };\n\n    // Check if we have input from a resumed workflow\n    const reviewInput = {\n      approvedProducts: context.inputData?.approvedProducts || [],\n      customerNote: context.inputData?.customerNote,\n      offerDiscount: context.inputData?.offerDiscount,\n    };\n\n    // If we don't have agent input yet, suspend for human review\n    if (!reviewInput.approvedProducts.length) {\n      console.log(`Generating recommendations for customer: ${customerName}`);\n      await suspend({\n        customerName,\n        recommendations,\n        message: 'Please review these product recommendations before sending to the customer',\n      });\n\n      // Placeholder return (won't be reached due to suspend)\n      return {\n        finalRecommendations: [],\n        customerNote: '',\n        offerDiscount: false,\n      };\n    }\n\n    // Process the agent's product selections\n    const finalRecommendations = recommendations\n      .filter(product => reviewInput.approvedProducts.includes(product.productId))\n      .map(product => ({\n        productId: product.productId,\n        productName: product.productName,\n        price: product.price,\n      }));\n\n    return {\n      finalRecommendations,\n      customerNote: reviewInput.customerNote || '',\n      offerDiscount: reviewInput.offerDiscount || false,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Environment Setup with API Key and Connection String\nDESCRIPTION: Sets up the environment variables needed for the example, including the OpenAI API key and the PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/hybrid-vector-search.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Creating and Using a Custom Tool in Mastra Workflow\nDESCRIPTION: This code snippet shows how to create a custom tool for crawling a webpage, define its input/output schemas, and integrate it into a Mastra workflow. It also demonstrates how to execute the workflow with sample input data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/using-a-tool-as-a-step.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from '@mastra/core/tools';\nimport { Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\nconst crawlWebpage = createTool({\n  id: 'Crawl Webpage',\n  description: 'Crawls a webpage and extracts the text content',\n  inputSchema: z.object({\n    url: z.string().url(),\n  }),\n  outputSchema: z.object({\n    rawText: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const response = await fetch(context.triggerData.url);\n    const text = await response.text();\n    return { rawText: 'This is the text content of the webpage: ' + text };\n  },\n});\n\nconst contentWorkflow = new Workflow({ name: 'content-review' });\n\ncontentWorkflow.step(crawlWebpage).commit();\n\nconst { start } = contentWorkflow.createRun();\n\nconst res = await start({ triggerData: { url: 'https://example.com'} });\n\nconsole.log(res.results);\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Upstash with Mastra\nDESCRIPTION: This code demonstrates how to use the `UpstashVector` class from `@mastra/upstash` to create a collection and insert embeddings into Upstash Vector. It uses `openai` for generating embeddings, `MDocument` for chunking text, and environment variables for the Upstash URL and token. The example shows how to create a collection and upsert vector embeddings along with associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_6\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { UpstashVector } from '@mastra/upstash';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst upstash = new UpstashVector({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN,\n});\n\nawait upstash.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait upstash.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Implement New Operations for MastraVector Interface for Chroma Store (Minor)\nDESCRIPTION: This update adds new operation implementations to the MastraVector interface specifically for the Chroma vector store.  This enhancement expands the capabilities of the Chroma integration by supporting a wider range of vector operations, likely including things like filtering or custom similarity metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_8\n\n\n\n----------------------------------------\n\nTITLE: HTML Markdown Token Chunking Strategy Examples in TypeScript\nDESCRIPTION: This snippet provides examples for using different chunking strategies—HTML, Markdown, and Token—in Mastra. It shows how strategy-specific options are passed directly at the top level of the configuration object. Includes options like different header and section selectors for HTML, header stripping for Markdown, and token encoding for Token strategy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chunk.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// HTML strategy example\nconst chunks = await doc.chunk({\n  strategy: 'html',\n  headers: [['h1', 'title'], ['h2', 'subtitle']], // HTML-specific option\n  sections: [['div.content', 'main']], // HTML-specific option\n  size: 500 // general option\n});\n\n// Markdown strategy example\nconst chunks = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']], // Markdown-specific option\n  stripHeaders: true, // Markdown-specific option\n  overlap: 50 // general option\n});\n\n// Token strategy example\nconst chunks = await doc.chunk({\n  strategy: 'token',\n  encodingName: 'gpt2', // Token-specific option\n  modelName: 'gpt-3.5-turbo', // Token-specific option\n  size: 1000 // general option\n});\n```\n\n----------------------------------------\n\nTITLE: Configure RAG Agent Typescript\nDESCRIPTION: Configures a Mastra agent named 'RAG Agent' using the `Agent` class from `@mastra/core/agent`.  The agent is designed to answer questions based on the provided context. It uses the `gpt-4o-mini` model from OpenAI for generating responses and is equipped with a `vectorQueryTool` to retrieve relevant context from the vector store.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Query Tool for Agent-Driven Retrieval in TypeScript\nDESCRIPTION: This snippet shows how to create a Vector Query Tool that allows an AI agent to directly query a vector database. It demonstrates the basic setup for integrating the tool with an embedding model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a ToDo List Agent\nDESCRIPTION: This snippet demonstrates how to create an agent that utilizes the defined memory system. The agent's instructions define how it interacts with the user and manages the ToDo list. The agent uses the `gpt-4o-mini` model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory-advanced.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst todoAgent = new Agent({\n  name: \"TODO Agent\",\n  instructions:\n    \"あなたは役に立つToDoリストAIエージェントです。ユーザーがToDoリストを管理するのを手伝ってください。まだリストがない場合は、何を追加するか尋ねてください！リストがある場合は、チャットが始まるときに常にそれを表示してください。各アイテムには絵文字、日付、タイトル（1から始まるインデックス番号付き）、説明、ステータスを追加してください。各情報の左に絵文字を追加してください。また、ボックス内に箇条書きでサブタスクリストをサポートしてください。各タスクの時間をどのくらいかかるかを尋ねて、ユーザーが時間を区切るのを手伝ってください。\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Using AstraVector for Vector Search\nDESCRIPTION: This code demonstrates how to use the AstraVector class to create an index, upsert vectors with metadata, and perform a similarity query. It requires an Astra DB token and endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/astra/README.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AstraVector } from '@mastra/astra';\n\nconst vectorStore = new AstraVector({\n  token: 'your-astra-token',\n  endpoint: 'your-astra-endpoint',\n  keyspace: 'your-keyspace' // optional\n});\n\n// Create a new collection\nawait vectorStore.createIndex({ indexName: 'myCollection', dimension: 1536, metric: 'cosine' });\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({ indexName: 'myCollection', vectors, metadata });\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'myCollection',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: { $eq: 'doc1' } }, // optional filter\n  includeVector: false // includeVectors\n});\n```\n\n----------------------------------------\n\nTITLE: Install Dependencies\nDESCRIPTION: Installs the necessary npm packages required to run the application. This command should be executed in the project's root directory after setting up the environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech with a Specific Voice | TypeScript\nDESCRIPTION: Converts the input text \"Hello, world!\" to speech using a specific voice identified by its S3 manifest ID.  This overrides the default speaker configured during initialization. The `voice.speak()` method returns a Promise that resolves to a NodeJS.ReadableStream containing the audio data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/playai.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Convert text to speech with a specific voice\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 's3://voice-cloning-zero-shot/b27bc13e-996f-4841-b584-4d35801aea98/original/manifest.json' // Dexter voice\n});\n```\n\n----------------------------------------\n\nTITLE: Using MastraMCPClient with Stdio Server Example in TypeScript\nDESCRIPTION: The example demonstrates initializing MastraMCPClient with stdio server configurations using Docker. It covers client initialization, connection, tool retrieval, and usage with a Mastra Agent for data fetching. Handle process exits for proper cleanup.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { MastraMCPClient } from \"@mastra/mcp\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize the MCP client using mcp/fetch as an example\nconst fetchClient = new MastraMCPClient({\n  name: \"fetch\",\n  server: {\n    command: \"docker\",\n    args: [\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n    logger: (logMessage) => {\n      console.log(`[${logMessage.level}] ${logMessage.message}`);\n    },\n  },\n});\n\n// Create a Mastra Agent\nconst agent = new Agent({\n  name: \"Fetch agent\",\n  instructions:\n    \"You are able to fetch data from URLs on demand and discuss the response data with the user.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\ntry {\n  // Connect to the MCP server\n  await fetchClient.connect();\n\n  // Gracefully handle process exits so the docker subprocess is cleaned up\n  process.on(\"exit\", () => {\n    fetchClient.disconnect();\n  });\n\n  // Get available tools\n  const tools = await fetchClient.tools();\n\n  // Use the agent with the MCP tools\n  const response = await agent.generate(\n    \"Tell me about mastra.ai/docs. Tell me generally what this page is and the content it includes.\",\n    {\n      toolsets: {\n        fetch: tools,\n      },\n    },\n  );\n\n  console.log(\"\\n\\n\" + response.text);\n} catch (error) {\n  console.error(\"Error:\", error);\n} finally {\n  // Always disconnect when done\n  await fetchClient.disconnect();\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Technical Question Step in TypeScript\nDESCRIPTION: This step generates a technical follow-up question for candidates identified as technical. It uses the candidate's specialty and full resume text to craft a relevant question.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ninterface CandidateInfo {\n  candidateName: string;\n  isTechnical: boolean;\n  specialty: string;\n  resumeText: string;\n}\n\nconst askAboutSpecialty = new Step({\n  id: \"askAboutSpecialty\",\n  outputSchema: z.object({\n    question: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const candidateInfo = context?.getStepResult<CandidateInfo>(\n      \"gatherCandidateInfo\",\n    );\n\n    const prompt = `\n          You are a recruiter. Given the resume below, craft a short question\n          for ${candidateInfo?.candidateName} about how they got into \"${candidateInfo?.specialty}\".\n          Resume: ${candidateInfo?.resumeText}\n        `;\n    const res = await recruiter.generate(prompt);\n\n    return { question: res?.text?.trim() || \"\" };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Voice Provider Configuration in TypeScript\nDESCRIPTION: Shows how to configure a voice provider (OpenAI) with listening model settings including model name and API key. Also demonstrates simplified default configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-text.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// If using default settings the configuration can be simplified to:\nconst voice = new OpenAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Workflow in Mastra\nDESCRIPTION: This code defines a simple workflow named 'my-workflow' with a single step. It utilizes the `@mastra/core/workflows` library for defining the workflow and step. The `zod` library is used for schema validation of input and output data. The workflow takes a number as input, doubles it in the step, and returns the doubled value. The `createRun` function is then used to run the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/creating-a-workflow.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    input: z.number(),\n  }),\n});\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  inputSchema: z.object({\n    value: z.number(),\n  }),\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context?.triggerData?.input * 2;\n    return { doubledValue };\n  },\n});\n\nmyWorkflow.step(stepOne).commit();\n\nconst { runId, start } = myWorkflow.createRun();\n\nconst res = await start({\n  triggerData: { input: 90 },\n});\n\nconsole.log(res.results);\n```\n\n----------------------------------------\n\nTITLE: Initialize ToneConsistencyMetric in TypeScript\nDESCRIPTION: This code snippet initializes an instance of the ToneConsistencyMetric class.  This instance will be used to measure tone consistency in subsequent examples. It has no dependencies beyond the import.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/tone-consistency.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ToneConsistencyMetric();\n```\n\n----------------------------------------\n\nTITLE: Configuring Working Memory Template in TypeScript\nDESCRIPTION: Demonstrates how to create a custom working memory template for tracking user information including personal details, preferences, and session state. The template is structured in Markdown format and guides the agent on what information to maintain.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/working-memory.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      template: `\n# User Profile\n \n## Personal Info\n \n- Name:\n- Location:\n- Timezone:\n \n## Preferences\n \n- Communication Style: [e.g., Formal, Casual]\n- Project Goal:\n- Key Deadlines:\n  - [Deadline 1]: [Date]\n  - [Deadline 2]: [Date]\n \n## Session State\n \n- Last Task Discussed:\n- Open Questions:\n  - [Question 1]\n  - [Question 2]\n`,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra for Graph RAG\nDESCRIPTION: This snippet shows how to instantiate PgVector with a connection string and create a Mastra instance with the configured agent and vector store.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Initializing First Workflow Step in TypeScript\nDESCRIPTION: Defines the first step of a workflow that takes an input value and doubles it. Uses Zod for output schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\nconst stepOne = new Step({\n  id: 'stepOne',\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context.triggerData.inputValue * 2;\n    return { doubledValue };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Complete AI Workflow Implementation in TypeScript\nDESCRIPTION: Complete example showing a workflow system that uses two AI agents (copywriter and editor) to create and edit blog posts. The workflow processes a given topic through multiple steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n\nconst copywriterStep = new Step({\n  id: \"copywriterStep\",\n  execute: async ({ context }) => {\n    if (!context?.triggerData?.topic) {\n      throw new Error(\"Topic not found in trigger data\");\n    }\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.triggerData.topic}`,\n    );\n    console.log(\"copywriter result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst editorStep = new Step({\n  id: \"editorStep\",\n  execute: async ({ context }) => {\n    const copy = context?.getStepResult<{ copy: number }>(\n      \"copywriterStep\",\n    )?.copy;\n\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${copy}`,\n    );\n    console.log(\"editor result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    topic: z.string(),\n  }),\n});\n\n// Run steps sequentially.\nmyWorkflow.step(copywriterStep).then(editorStep).commit();\n\nconst { runId, start } = myWorkflow.createRun();\n\nconst res = await start({\n  triggerData: { topic: \"React JavaScript frameworks\" },\n});\nconsole.log(\"Results: \", res.results);\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with Semantic Recall\nDESCRIPTION: This code snippet demonstrates how to initialize an Agent with semantic recall enabled by default using the Memory class. It imports the necessary modules from `@mastra/core/agent`, `@mastra/memory`, and `@ai-sdk/openai`. The Agent is configured with a name, instructions, an OpenAI model, and a Memory instance, implicitly enabling semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"SupportAgent\",\n  instructions: \"You are a helpful support agent.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory(),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing a Mastra Agent with a Single Voice Provider\nDESCRIPTION: Shows how to create a Mastra agent with voice capabilities using a single provider (OpenAI) for both speaking and listening functions. The example demonstrates initializing the voice provider, creating the agent, and using it to speak and listen.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize the voice provider with default settings\nconst voice = new OpenAIVoice();\n\n// Create an agent with voice capabilities\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with both STT and TTS capabilities.`,\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\n// The agent can now use voice for interaction\nconst audioStream = await agent.voice.speak(\"Hello, I'm your AI assistant!\", {\n  filetype: \"m4a\",\n});\n\nplayAudio(audioStream!);\n\ntry {\n  const transcription = await agent.voice.listen(audioStream);\n  console.log(transcription)\n} catch (error) {\n  console.error(\"Error transcribing audio:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index in AstraVector\nDESCRIPTION: Creates an index in the AstraVector class with specified parameters including index name, vector dimension, and optional metric for similarity search.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to create\",\n    },\n    {\n      name: \"dimension\",\n      type: \"number\",\n      description: \"Vector dimension (must match your embedding model)\",\n    },\n    {\n      name: \"metric\",\n      type: \"'cosine' | 'euclidean' | 'dotproduct'\",\n      isOptional: true,\n      defaultValue: \"cosine\",\n      description:\n        \"Distance metric for similarity search (maps to dot_product for dotproduct)\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Monitoring Specific Step Completion in Typescript\nDESCRIPTION: This code snippet demonstrates how to monitor for the completion of a specific step within a Mastra workflow using the `run.watch()` function. It checks the status of the 'processDocument' step within the `activePaths` and logs the output of the step if it has completed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/watch.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(({results, activePaths}) => {\n  if (activePaths.get('processDocument')?.status === 'completed') {\n    console.log('Document processing output:', results['processDocument'].output);\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: useChat Hook Implementation - TypeScript (API Route)\nDESCRIPTION: This code shows the implementation of an API route for handling chat requests using the `useChat` hook.  It imports the `mastra` instance, retrieves a specific agent, streams the agent's response based on the received messages, and returns the stream as a data stream response using `toDataStreamResponse()`. This is designed to be the backend endpoint for a chat component using the AI SDK's `useChat` hook.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages);\n\n  return stream.toDataStreamResponse();\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Text Streaming Example TypeScript\nDESCRIPTION: Illustrates how to use the `stream()` method to stream text responses from a Mastra agent. The code initializes a stream and then iterates over the `textStream` property to print each chunk to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/stream.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream([\n  { role: \"user\", content: \"Tell me a story.\" }\n]);\n\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Delegating voice.listen() with CompositeVoice\nDESCRIPTION: This example illustrates how `voice.listen()` delegates to the configured listening provider when using `CompositeVoice`.  It initializes `CompositeVoice` with `OpenAIVoice` as the `listenProvider` and `PlayAIVoice` as the `speakProvider`. Then, calling `voice.listen()` transcribes the `audioStream` using `OpenAIVoice`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.listen.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\nconst voice = new CompositeVoice({\n  listenProvider: new OpenAIVoice(),\n  speakProvider: new PlayAIVoice(),\n});\n\n// This will use the OpenAIVoice provider\nconst transcript = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Agents in Mastra AI (TypeScript)\nDESCRIPTION: This snippet demonstrates how to retrieve a list of all available agents using the Mastra AI client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst agents = await client.getAgents();\n```\n\n----------------------------------------\n\nTITLE: Playing Text-to-Speech Audio (React useEffect)\nDESCRIPTION: This code snippet demonstrates how to handle text-to-speech audio playback in a React component using the useEffect hook. It monitors for new audio data, creates a browser-playable URL from the audio blob, assigns it to an audio element, and attempts to play it automatically. It also includes cleanup logic to pause the audio, revoke the URL, and prevent memory leaks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nuseEffect(() => {\n  if (!audioRef.current || !audioData) return;\n\n  // Store a reference to the HTML audio element\n  const currentAudio = audioRef.current;\n\n  // Convert the Blob/File audio data from Mastra into a URL the browser can play\n  const url = URL.createObjectURL(audioData);\n\n  const playAudio = async () => {\n    try {\n      currentAudio.src = url;\n      await currentAudio.load();\n      await currentAudio.play();\n      setIsPlaying(true);\n    } catch (error) {\n      console.error('Auto-play failed:', error);\n    }\n  };\n\n  playAudio();\n\n  return () => {\n    if (currentAudio) {\n      currentAudio.pause();\n      currentAudio.src = '';\n      URL.revokeObjectURL(url);\n    }\n  };\n}, [audioData]);\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareVector Store in TypeScript\nDESCRIPTION: Shows how to initialize a Cloudflare Vectorize store with account ID and API token, create an index with specific dimensions, and upsert vectors with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CloudflareVector } from '@mastra/vectorize'\n\nconst store = new CloudflareVector({\n  accountId: process.env.CF_ACCOUNT_ID,\n  apiToken: process.env.CF_API_TOKEN\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Result Schema and Mapping for Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Demonstrates how to define result schemas and mappings for nested workflows.  This allows you to ensure type safety and data transformation for the output of nested workflows before it's used in the parent workflow.  Uses `z.object` from the `zod` library to define the schemas.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a nested workflow with result schema and mapping\nconst nestedWorkflow = new Workflow({\n  name: \"nested-workflow\",\n  result: {\n    schema: z.object({\n      total: z.number(),\n      items: z.array(\n        z.object({\n          id: z.string(),\n          value: z.number(),\n        }),\n      ),\n    }),\n    mapping: {\n      // Map values from step results using variables syntax\n      total: { step: \"step-a\", path: \"count\" },\n      items: { step: \"step-b\", path: \"items\" },\n    },\n  },\n})\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// Use in parent workflow with type-safe results\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow)\n  .then(async ({ context }) => {\n    const result = context.getStepResult(\"nested-workflow\");\n    // TypeScript knows the structure of result\n    console.log(result.total); // number\n    console.log(result.items); // Array<{ id: string, value: number }>\n    return { success: true };\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Configuring Branching Paths in Mastra Workflow\nDESCRIPTION: This snippet shows how to configure a workflow with branching paths using Mastra. It demonstrates creating parallel branches, chaining steps within each branch, and merging the branches using the compound .after([]) syntax. The example also includes executing the workflow and logging the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/branching-paths.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Create two parallel branches\nmyWorkflow\n  // First branch\n  .step(stepOne)\n  .then(stepTwo)\n\n  // Second branch\n  .after(stepOne)\n  .step(stepThree)\n  .then(stepFour)\n\n  // Merge both branches using compound after syntax\n  .after([stepTwo, stepFour])\n  .step(finalStep)\n  .commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst result = await start({ triggerData: { inputValue: 3 } });\nconsole.log(result.steps.finalStep.output.summary);\n// Output: \"The number 3 when doubled is not divisible by 5, and when doubled and incremented is divisible by 3.\"\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into LibSQL with Mastra\nDESCRIPTION: This code demonstrates how to use the `LibSQLVector` class from `@mastra/core/vector/libsql` to create a collection and insert embeddings into LibSQL. It utilizes `openai` for generating embeddings, `MDocument` for text chunking, and environment variables for the database URL and authentication token. The example illustrates how to create an index and upsert vector embeddings with corresponding metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#2025-04-22_snippet_5\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map((chunk) => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst libsql = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  authToken: process.env.DATABASE_AUTH_TOKEN, // Optional: for Turso cloud databases\n});\n\nawait libsql.createIndex({\n  indexName: \"test_collection\",\n  dimension: 1536,\n});\n\nawait libsql.upsert({\n  indexName: \"test_collection\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Custom Configuration of ContextualRecallMetric in TypeScript\nDESCRIPTION: This snippet demonstrates a custom configuration of the ContextualRecallMetric, allowing to adjust the scale and providing security measures as context. It uses a scale from 0-100 instead of the default 0-1.  It then evaluates an LLM response summarizing company security measures.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/contextual-recall.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextualRecallMetric } from \"@mastra/evals/llm\";\n\n// モデルを評価用に設定\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextualRecallMetric(\n  model,\n  {\n    scale: 100, // 0-1の代わりに0-100のスケールを使用\n    context: [\n      \"すべてのデータは保存時および転送時に暗号化されます\",\n      \"二要素認証（2FA）は必須です\",\n      \"定期的なセキュリティ監査が実施されます\",\n      \"インシデント対応チームが24/7で利用可能です\"\n    ]\n  }\n);\n\nconst result = await metric.measure(\n  \"会社のセキュリティ対策を要約してください\",\n  \"会社はデータ保護のために暗号化を実施し、すべてのユーザーに2FAを要求しています。\",\n);\n\n// 出力例:\n// {\n//   score: 50, // セキュリティ対策の半分しか言及されていません\n//   info: {\n//     reason: \"スコアが50である理由は、応答でセキュリティ対策の半分しか言及されていないためです。応答には定期的なセキュリティ監査とインシデント対応チームの情報が欠けています。\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with LibSQL Storage (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to initialize a Mastra workflow using LibSQL as the storage engine. It showcases different LibSQL configuration options, including in-memory, file-based, and remote databases. The `url` parameter specifies the database location, and `authToken` is used for authenticated connections.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { LibSQLStore } from \"@mastra/libsql\";\n\nconst mastra = new Mastra({\n  storage: new LibSQLStore({\n    url: \"file:./storage.db\", // Local file-based database for development\n    // For production, use a persistent URL:\n    // url: process.env.DATABASE_URL,\n    // authToken: process.env.DATABASE_AUTH_TOKEN, // Optional for authenticated connections\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Bias Example\nDESCRIPTION: This snippet shows how to evaluate a response with high gender bias using the BiasMetric. It includes the query, biased response, and the measurement using the metric. The score and the reason for the score are logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What makes someone a good leader?';\nconst response1 =\n  'Men naturally make better leaders due to their assertiveness and decisiveness. Women tend to be too emotional and collaborative, which can slow down decision-making processes.';\n\nconsole.log('Example 1 - High Bias:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response contains strong gender stereotypes and assumptions about leadership abilities.' }\n```\n\n----------------------------------------\n\nTITLE: Type Safety in Mastra Workflow Variable Mapping\nDESCRIPTION: Illustrates how Mastra provides type safety for variable mappings when using TypeScript, demonstrating the use of schemas and typed contexts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Define schemas for better type safety\nconst triggerSchema = z.object({\n  inputValue: z.string(),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\n// Step with typed context\nconst step1 = new Step({\n  id: \"step1\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of triggerData\n    const triggerData = context.getStepResult<TriggerType>('trigger');\n\n    return {\n      nested: {\n        value: `processed-${triggerData?.inputValue}`\n      }\n    };\n  },\n});\n\n// Create the workflow with the schema\nconst workflow = new Workflow({\n  name: \"type-safe-workflow\",\n  triggerSchema,\n});\n\nworkflow.step(step1).commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Migrating code from MurfTTS to MurfVoice\nDESCRIPTION: This code demonstrates how to update the code when migrating from `@mastra/speech-murf` to `@mastra/voice-murf`. It shows the changes needed for initializing the voice object, fetching voices/speakers, and generating speech using the new API, which includes changes to the configuration and function names.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/murf/README.md#2025-04-22_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n- const tts = new MurfTTS({\n-   model: {\n-     name: 'GEN2',\n-     voice: 'en-US-natalie',\n-   }\n- });\n+ const voice = new MurfVoice({\n+   speechModel: {\n+     name: 'GEN2',\n+   },\n+   speaker: 'en-US-natalie'\n+ });\n\n- const voices = await tts.voices();\n+ const speakers = await voice.getSpeakers();\n\n- const { audioResult } = await tts.generate({ text: 'Hello' });\n+ const stream = await voice.speak('Hello');\n```\n\n----------------------------------------\n\nTITLE: Creating a Todo List Agent with Working Memory in TypeScript\nDESCRIPTION: Initializes an Agent instance for managing a todo list. It uses the previously configured memory system and defines instructions for the agent's behavior.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst todoAgent = new Agent({\n  name: \"TODO Agent\",\n  instructions:\n    \"You are a helpful todolist AI agent. Help the user manage their todolist. If there is no list yet ask them what to add! If there is a list always print it out when the chat starts. For each item add emojis, dates, titles (with an index number starting at 1), descriptions, and statuses. For each piece of info add an emoji to the left of it. Also support subtask lists with bullet points inside a box. Help the user timebox each task by asking them how long it will take.\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Memory with Token Limiter\nDESCRIPTION: This snippet showcases how to configure a `Memory` instance with a `TokenLimiter` to constrain the number of tokens used. The `TokenLimiter` helps ensure that the memory remains within the model's context window. The example sets a limit of 127000 tokens, suitable for models like GPT-4o.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Memory } from \\\"@mastra/memory\\\";\nimport { TokenLimiter } from \\\"@mastra/memory/processors\\\";\n\n// トークン制限を設定してメモリをセットアップ\nconst memory = new Memory({\n  processors: [\n    // 約12700トークンに制限 (GPT-4o用)\n    new TokenLimiter(127000),\n  ],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Using onStepFinish Callback (TypeScript)\nDESCRIPTION: This code snippet shows how to use the `onStepFinish` callback to monitor the progress of a multi-step agent operation.  The callback is triggered after each step is completed, providing information about the current step, including text, tool calls, and tool results.  It's useful for debugging and providing progress updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myAgent.generate(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onStepFinish: ({ text, toolCalls, toolResults }) => {\n      console.log(\"Step completed:\", { text, toolCalls, toolResults });\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Voice Agent with OpenAI\nDESCRIPTION: Basic setup for creating a voice-enabled agent using OpenAI voice capabilities. Demonstrates the initialization of an agent with voice features.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\n\n// Initialize OpenAI voice for TTS\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Saving a Thread\nDESCRIPTION: This code snippet saves a new thread to the Clickhouse store. It uses the saveThread method, which takes an object containing thread details such as id, resourceId, title, and timestamps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nawait store.saveThread({\n  id: 'thread-123',\n  resourceId: 'resource-456',\n  title: 'My Thread',\n  metadata: { key: 'value' },\n  createdAt: new Date(),\n  updatedAt: new Date(),\n});\n```\n\n----------------------------------------\n\nTITLE: Injecting Runtime Context into Tools (TypeScript)\nDESCRIPTION: This code snippet shows how to inject runtime context into tools using the `runtimeContext` parameter in the `execute` function. This allows for passing request or user-specific variables to tools at runtime.  The example demonstrates changing the temperature scale between Fahrenheit and Celsius based on a value set in the `runtimeContext`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-tools.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const agent = new Agent({\n  name: \"Weather agent\",\n  tools: {\n    weather: createTool({\n      id: \"Get Weather Information\",\n      description: \"Get the weather in a location\",\n      inputSchema: z.object({ location: z.string() }),\n      execute: async ({ context: { location }, runtimeContext }) => {\n        const scale = runtimeContext.get(\"temperature-scale\");\n\n        const result = await fetch(\n          `https://api.weatherapi.com/v1/current.json?q=${location}`,\n        );\n\n        const json = await result.json();\n\n        return {\n          temperature: scale === \"celsius\" ? json.temp_c : json.temp_f,\n        };\n      },\n    }),\n  },\n});\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { agent } from \"./agents/weather\";\n\ntype MyRuntimeContext = {\"temperature-scale\", \"celsius\" | \"farenheit\"}\n\nconst runtimeContext = new RuntimeContext<MyRuntimeContext>();\nruntimeContext.set(\"temperature-scale\", \"celsius\");\n\nconst result = await agent.generate(\"What is the weather in San Francisco?\", {\n  runtimeContext,\n});\n```\n\n----------------------------------------\n\nTITLE: Type Safety with Variables in Mastra Workflow (TypeScript)\nDESCRIPTION: Demonstrates how to use TypeScript and Zod schemas to ensure type safety when mapping variables in a Mastra workflow. This example defines schemas for both the trigger and the step, allowing TypeScript to provide type checking and autocompletion. Requires `@mastra/core` and `zod`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Define schemas for better type safety\nconst triggerSchema = z.object({\n  inputValue: z.string(),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\n// Step with typed context\nconst step1 = new Step({\n  id: \"step1\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of triggerData\n    const triggerData = context.getStepResult<TriggerType>('trigger');\n\n    return {\n      nested: {\n        value: `processed-${triggerData?.inputValue}`\n      }\n    };\n  },\n});\n\n// Create the workflow with the schema\nconst workflow = new Workflow({\n  name: \"type-safe-workflow\",\n  triggerSchema,\n});\n\nworkflow.step(step1).commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Query Object Condition in Mastra Workflow (Typescript)\nDESCRIPTION: Illustrates using a query object to define a condition for executing a step in a Mastra workflow. It references the 'status' property of the 'auth' step's output and uses the `$eq` operator to check if it equals 'authenticated'. The `processOrder` step is only executed if this condition is true.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step-condition.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: {\n    ref: { step: 'auth', path: 'status' },\n    query: { $eq: 'authenticated' }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Import and Basic Chunking with Mastra in TypeScript\nDESCRIPTION: This snippet demonstrates how to import the MDocument class and perform basic document chunking using the Mastra library. It first imports a markdown document, then chunks it using the default settings and a markdown-specific strategy. Required dependency: @mastra/rag library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chunk.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\nconst doc = MDocument.fromMarkdown(`\n# Introduction\nThis is a sample document that we want to split into chunks.\n\n## Section 1\nHere is the first section with some content.\n\n## Section 2 \nHere is another section with different content.\n`);\n\n// Basic chunking with defaults\nconst chunks = await doc.chunk();\n\n// Markdown-specific chunking with header extraction\nconst chunksWithMetadata = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']],\n  extract: {\n    summary: true, // Extract summaries with default settings\n    keywords: true  // Extract keywords with default settings\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Inaccurate Summary\nDESCRIPTION: Evaluates an inaccurate summary that contains factual errors and misrepresentations using the `SummarizationMetric`. The example demonstrates how the `measure` method assesses a summary with a score of 0 due to factual inaccuracies, illustrating the impact of incorrect information on the overall evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = `The World Wide Web was invented by Tim Berners-Lee in 1989 while working at CERN. \nHe published the first website in 1991. Berners-Lee made the Web freely available, with no patent \nand no royalties due.`;\n\nconst output3 = `The Internet was created by Tim Berners-Lee at MIT in the early 1990s, and he went \non to commercialize the technology through patents.`;\n\nconsole.log('Example 3 - Inaccurate Summary:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    reason: result3.info.reason,\n    alignmentScore: result3.info.alignmentScore,\n    coverageScore: result3.info.coverageScore,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0,\n//   info: {\n//     reason: \"The score is 0 because the summary contains multiple factual errors and misrepresentations of key details from the source text, despite covering some of the basic information.\",\n//     alignmentScore: 0,\n//     coverageScore: 0.6\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Registering Agent with Mastra\nDESCRIPTION: This code snippet demonstrates how to register a pre-defined agent (storyTellerAgent) with a Mastra instance. It imports necessary modules from '@mastra/core' and the local agent definition. It then creates a new Mastra instance, registering the agent within the 'agents' configuration and setting up a logger for the Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger } from '@mastra/core/logger';\nimport { Mastra } from '@mastra/core/mastra';\nimport { storyTellerAgent } from './agents';\n\nexport const mastra = new Mastra({\n  agents: { storyTellerAgent },\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Workflows with Multiple Branches in Mastra\nDESCRIPTION: This snippet demonstrates how to create more complex workflows with multiple branches and merge points using Mastra. It includes creating three separate branches from a main step, partial merging of branches, and a final merge step that combines results from all branches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/branching-paths.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst complexWorkflow = new Workflow({\n  name: \"complex-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\n// Create multiple branches with different merge points\ncomplexWorkflow\n  // Main step\n  .step(stepOne)\n\n  // First branch\n  .then(stepTwo)\n\n  // Second branch\n  .after(stepOne)\n  .step(stepThree)\n  .then(stepFour)\n\n  // Third branch (another path from stepOne)\n  .after(stepOne)\n  .step(new Step({\n    id: \"alternativePath\",\n    execute: async ({ context }) => {\n      const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n      return {\n        result: (stepOneResult?.doubledValue || 0) * 3\n      }\n    }\n  }))\n\n  // Merge first and second branches\n  .after([stepTwo, stepFour])\n  .step(new Step({\n    id: \"partialMerge\",\n    execute: async ({ context }) => {\n      const stepTwoResult = context.getStepResult<{ isDivisibleByFive: boolean }>(\"stepTwo\");\n      const stepFourResult = context.getStepResult<{ isDivisibleByThree: boolean }>(\"stepFour\");\n\n      return {\n        intermediateResult: \"Processed first two branches\",\n        branchResults: {\n          branch1: stepTwoResult?.isDivisibleByFive,\n          branch2: stepFourResult?.isDivisibleByThree\n        }\n      }\n    }\n  }))\n\n  // Final merge of all branches\n  .after([\"partialMerge\", \"alternativePath\"])\n  .step(new Step({\n    id: \"finalMerge\",\n    execute: async ({ context }) => {\n      const partialMergeResult = context.getStepResult<{\n        intermediateResult: string,\n        branchResults: { branch1: boolean, branch2: boolean }\n      }>(\"partialMerge\");\n\n      const alternativePathResult = context.getStepResult<{ result: number }>(\"alternativePath\");\n\n      return {\n        finalResult: \"All branches processed\",\n        combinedData: {\n          fromPartialMerge: partialMergeResult?.branchResults,\n          fromAlternativePath: alternativePathResult?.result\n        }\n      }\n    }\n  }))\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Getting Agent History from Agent Network - TypeScript\nDESCRIPTION: The getAgentHistory() method retrieves the history of interactions for a particular agent specified by its ID. This information can provide insights into past communications and activities of the agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentHistory(agentId: string): Array<{\n  input: string;\n  output: string;\n  timestamp: string;\n}>\n```\n\n----------------------------------------\n\nTITLE: Using MCP Toolsets with User-Specific Configuration\nDESCRIPTION: This TypeScript code demonstrates how to use MCP toolsets for scenarios requiring per-request tool configuration, such as multi-user environments. The code initializes MCP with a server, retrieves toolsets using `getToolsets()`, and then passes the toolsets to the agent's `stream` method. This allows for dynamic and user-specific tool configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    example: {\n      command: \"npx\",\n      args: [\"-y\", \"@example/fakemcp\"],\n      env: {\n        API_KEY: \"your-api-key\",\n      },\n    },\n  },\n});\n\n// Get the current toolsets configured for this user\nconst toolsets = await mcp.getToolsets();\n\n// Use the agent with user-specific tool configurations\nconst response = await agent.stream(\n  \"What's new in Mastra and how's the weather?\",\n  {\n    toolsets,\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Call the Agent to Generate a Response\nDESCRIPTION: This code snippet illustrates how to call a Mastra agent to generate a response. It retrieves the `weatherAgent` from the Mastra instance and then calls the `generate` method with a user query. The response text is then logged to the console.  This assumes `mastra` is properly initialized and contains a weatherAgent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\nasync function main() {\n  const agent = mastra.getAgent(\"weatherAgent\");\n  const response = await agent.generate(\n    \"What's the weather like in New York City today?\",\n  );\n\n  console.log(response.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Handling Workflow Status Updates in TypeScript\nDESCRIPTION: This snippet illustrates the handling of different workflow states using the 'watch()' method. It allows monitoring the workflow status and executing corresponding actions based on whether the workflow is suspended, completed, or failed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start, watch } = workflow.createRun();\n\nwatch(async ({ status }) => {\n  switch (status) {\n    case \"SUSPENDED\":\n      // Handle suspended state\n      break;\n    case \"COMPLETED\":\n      // Process results\n      break;\n    case \"FAILED\":\n      // Handle error state\n      break;\n  }\n});\n\nawait start({ triggerData: data });\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech with OpenAI\nDESCRIPTION: Illustrates how to use the `speak` method of the OpenAIVoice class to convert text into an audio stream. It shows how to override the default speaker and adjust the speech speed using options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/openai.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// テキストを音声に変換\nconst audioStream = await voice.speak('こんにちは、どのようにお手伝いできますか？', {\n  speaker: 'nova',  // デフォルトの声を上書き\n  speed: 1.2  // 音声速度を調整\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables\nDESCRIPTION: This snippet shows how to define environment variables, which are required to authenticate with OpenAI and connect to the Postgres database. The `OPENAI_API_KEY` variable stores the OpenAI API key, and `POSTGRES_CONNECTION_STRING` stores the database connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Token Chunking with Strategy Specific Options in Typescript\nDESCRIPTION: This code snippet demonstrates how to use `.chunk()` function with Token-specific options. It configures the chunking process to use a specific token encoding and model name, along with a general size parameter for chunking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Token戦略の例\nconst chunks = await doc.chunk({\n  strategy: 'token',\n  encodingName: 'gpt2', // Token固有のオプション\n  modelName: 'gpt-3.5-turbo', // Token固有のオプション\n  size: 1000 // 一般的なオプション\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Context Precision Metric with GPT-4o-Mini\nDESCRIPTION: Demonstrates configuring the ContextPrecisionMetric class using OpenAI's GPT-4o-mini model to evaluate the relevance and precision of specific context nodes. Key dependencies include the '@ai-sdk/openai' and '@mastra/evals/llm' packages. The metric.measure function requires an input query and expected output, returning a precision score and explanatory information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-precision.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPrecisionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPrecisionMetric(model, {\n  context: [\n    \"Photosynthesis is a biological process used by plants to create energy from sunlight.\",\n    \"Plants need water and nutrients from the soil to grow.\",\n    \"The process of photosynthesis produces oxygen as a byproduct.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"What is photosynthesis?\",\n  \"Photosynthesis is the process by which plants convert sunlight into energy.\",\n);\n\nconsole.log(result.score); // Precision score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Creating Separate Steps in Mastra Workflow (TypeScript)\nDESCRIPTION: This code illustrates how to define Mastra workflow steps as separate entities and then add them to a workflow. It shows the creation of two distinct steps, `stepOne` and `stepTwo`, which are then linked within the `myWorkflow` workflow. It highlights modularity and organization in defining workflow logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/steps.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Define steps separately\nconst stepOne = new Step({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 };\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow.step(stepOne).then(stepTwo);\nmyWorkflow.commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  workflows: { myWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Authentication Middleware Example - TypeScript\nDESCRIPTION: This middleware function demonstrates how to implement authentication by checking for a valid Authorization header. If the header is missing or doesn't start with 'Bearer ', it returns an 'Unauthorized' response. Otherwise, it extracts the token, validates it, and proceeds to the next middleware or route handler.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    const authHeader = c.req.header('Authorization');\n    if (!authHeader || !authHeader.startsWith('Bearer ')) {\n      return new Response('Unauthorized', { status: 401 });\n    }\n\n    const token = authHeader.split(' ')[1];\n    // ここでトークンを検証\n\n    await next();\n  },\n  path: '/api/*',\n}\n```\n\n----------------------------------------\n\nTITLE: Workflow Validation on Execution in Typescript\nDESCRIPTION: This code snippet shows how data validation occurs during workflow execution using the `start` method in Typescript. It demonstrates the validation of trigger data against the trigger schema and highlights how an invalid email address would cause validation to fail.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start } = workflow.createRun();\n\n// トリガーデータをスキーマに対して検証\nawait start({\n  triggerData: {\n    orderId: \"123\",\n    customer: {\n      id: \"cust_123\",\n      email: \"invalid-email\", // 検証に失敗します\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Text with an Agent (TypeScript)\nDESCRIPTION: This code demonstrates how to generate text using the `generate` method of a Mastra agent. It sends a user message to the agent and logs the agent's text response to the console. The `generate` method takes an array of messages as input, where each message includes a `role` (e.g., 'user') and `content`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myAgent.generate([\n  { role: \"user\", content: \"Hello, how can you assist me today?\" },\n]);\n\nconsole.log(\"Agent:\", response.text);\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings with OpenAI and PGVector\nDESCRIPTION: Generates embeddings for document chunks using OpenAI and stores them in a PostgreSQL database using PGVector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\nawait pgVector.createIndex({\n  indexName: 'embeddings',\n  dimension: 1536,\n});\nawait pgVector.upsert({\n  indexName: 'embeddings',\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Embedding Multiple Texts Using AI SDK in TypeScript\nDESCRIPTION: Shows how to use the `embedMany` function from the AI SDK to embed multiple text inputs simultaneously. This requires a model and an array of text values or objects. It accepts similar optional parameters like retry limits and HTTP headers. Outputs an array of embedding vectors for each input text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/embeddings.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from 'ai';\n\nconst result = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: [\"First text\", \"Second text\", \"Third text\"],\n  maxRetries: 2  // optional, defaults to 2\n});\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text Difference and Metrics with TextualDifferenceMetric\nDESCRIPTION: This example demonstrates the use of TextualDifferenceMetric to analyze the difference between two input strings and to retrieve related metrics such as confidence, ratio, changes and length difference.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/textual-difference.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new TextualDifferenceMetric();\n\nconst result = await metric.measure(\n  \"Hello world! How are you?\",\n  \"Hello there! How is it going?\"\n);\n\n// Example output:\n// {\n//   score: 0.65,\n//   info: {\n//     confidence: 0.95,\n//     ratio: 0.65,\n//     changes: 2,\n//     lengthDiff: 0.05\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text\nDESCRIPTION: This TypeScript snippet illustrates how to convert a text string into speech audio using the AzureVoice instance's speak method. It allows for overriding the default voice with an optional speaker parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst audioStream = await voice.speak('Hello from Mastra!', {\n  speaker: 'en-US-JennyNeural', // Optional: override default voice\n});\n```\n\n----------------------------------------\n\nTITLE: Registering STT-Enabled Agent with Mastra - Typescript\nDESCRIPTION: This snippet illustrates how to register the STT-enabled agent with a Mastra instance. It imports the necessary modules from `@mastra/core/logger` and `@mastra/core/mastra`, along with the previously defined `noteTakerAgent`. The `Mastra` instance is created with the agent registered under the `agents` property and a logger configured with the name 'Mastra' and level 'info'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-text.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger } from '@mastra/core/logger';\nimport { Mastra } from '@mastra/core/mastra';\n\nimport { noteTakerAgent } from './agents';\n\nexport const mastra = new Mastra({\n  agents: { noteTakerAgent }, // Register the note taker agent\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Dependency Patterns with Multiple after() Calls\nDESCRIPTION: Demonstrates how to create more sophisticated dependency patterns by combining multiple .after([]) calls to synchronize the execution of steps across multiple branches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  // First branch\n  .step(stepA)\n  .then(stepB)\n  .then(stepC)\n\n  // Second branch\n  .step(stepD)\n  .then(stepE)\n\n  // Third branch\n  .step(stepF)\n  .then(stepG)\n\n  // This step depends on the completion of multiple branches\n  .after([stepC, stepE, stepG])\n  .step(finalStep)\n```\n\n----------------------------------------\n\nTITLE: Define Chef Agent with Mastra and OpenAI\nDESCRIPTION: This code defines the chef agent using Mastra, configuring it with OpenAI's gpt-4o-mini model. It sets the agent's name and instructions, providing context for its role as a helpful home chef capable of creating recipes based on available ingredients. The agent leverages the `@ai-sdk/openai` and `@mastra/core` libraries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nexport const chefAgent = new Agent({\n  name: \"chef-agent\",\n  instructions:\n    \"You are Michel, a practical and experienced home chef\" +\n    \"You help people cook with whatever ingredients they have available.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Partial Coverage Summary Evaluation Example\nDESCRIPTION: Example demonstrating evaluation of a summary with perfect factual accuracy but incomplete information coverage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = `The Python programming language was created by Guido van Rossum and was first released \nin 1991. It emphasizes code readability with its notable use of significant whitespace. Python is \ndynamically typed and garbage-collected. It supports multiple programming paradigms, including \nstructured, object-oriented, and functional programming.`;\n\nconst output2 = `Python, created by Guido van Rossum, is a programming language known for its readable \ncode and use of whitespace. It was released in 1991.`;\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    reason: result2.info.reason,\n    alignmentScore: result2.info.alignmentScore,\n    coverageScore: result2.info.coverageScore,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Using a Memory-Enabled Agent across Multiple Conversations\nDESCRIPTION: Demonstrates how to use a memory-enabled agent across multiple conversation turns. This example shows creating a thread, interacting with the agent, and retrieving context from previous interactions using memory options to maintain conversational continuity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-pg.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Ask about ingredients\nconst response1 = await chefAgent.stream(\n  \"In my kitchen I have: pasta, canned tomatoes, garlic, olive oil, and some dried herbs (basil and oregano). What can I make?\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Ask about different ingredients\nconst response2 = await chefAgent.stream(\n  \"Now I'm over at my friend's house, and they have: chicken thighs, coconut milk, sweet potatoes, and curry powder.\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Use memory to recall previous conversation\nconst response3 = await chefAgent.stream(\n  \"What did we cook before I went to my friends house?\",\n  {\n    threadId,\n    resourceId,\n    memoryOptions: {\n      lastMessages: 3, // Get last 3 messages for context\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Evaluating Moderate Similarity Text in Mastra\nDESCRIPTION: Shows how to compare texts with similar meaning but different wording. This example demonstrates a more significant variation of the fox and dog sentence, resulting in a moderate similarity score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst text2 = 'A brown fox quickly leaps across a sleeping dog.';\nconst reference2 = 'The quick brown fox jumps over the lazy dog.';\n\nconsole.log('Example 2 - Moderate Similarity:');\nconsole.log('Text:', text2);\nconsole.log('Reference:', reference2);\n\nconst result2 = await metric.measure(reference2, text2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    similarity: result2.info.similarity,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.40540540540540543,\n//   info: { similarity: 0.40540540540540543 }\n// }\n```\n\n----------------------------------------\n\nTITLE: Using voice.answer() with OpenAIRealtimeVoice in a Node.js Application\nDESCRIPTION: This example demonstrates how to use the answer() method with OpenAIRealtimeVoice to create a speech-to-speech conversation flow. It shows initialization of the voice provider, connecting to the service, handling audio responses, sending user input, and triggering AI responses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.answer.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  speaker: \"alloy\", // Default voice\n});\n// Connect to the real-time service\nawait voice.connect();\n// Register event listener for responses\nvoice.on(\"speaker\", (stream) => {\n  // Handle audio response\n  stream.pipe(speaker);\n});\n// Send user audio input\nconst microphoneStream = getMicrophoneStream();\nawait voice.send(microphoneStream);\n// Trigger the AI to respond\nawait voice.answer();\n```\n\n----------------------------------------\n\nTITLE: Performing Speech-to-Text with DeepgramVoice\nDESCRIPTION: This code snippet demonstrates how to use the `listen` method of the DeepgramVoice class to convert audio to text.  It takes a Node.js ReadableStream as input and returns a promise that resolves to a string containing the transcribed text.  The stream must contain audio data. The `transcript` will hold the transcribed text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/deepgram.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Speech-to-Text\nconst transcript = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Planning Activities Based on Weather\nDESCRIPTION: Defines a step to plan activities based on the fetched weather forecast. It uses the agent to suggest activities based on the weather conditions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst planActivities = new Step({\n  id: \"plan-activities\",\n  description: \"天気条件に基づいてアクティビティを提案します\",\n  inputSchema: forecastSchema,\n  execute: async ({ context, mastra }) => {\n    const forecast =\n      context?.getStepResult<z.infer<typeof forecastSchema>>(\n        \"fetch-weather\",\n      );\n\n    if (!forecast) {\n      throw new Error(\"予報データが見つかりません\");\n    }\n\n    const prompt = `次の天気予報に基づいて、${forecast[0].location}で適切なアクティビティを提案してください:\\n      ${JSON.stringify(forecast, null, 2)}\n      `;\n\n    const response = await agent.stream([\n      {\n        role: \"user\",\n        content: prompt,\n      },\n    ]);\n\n    let activitiesText = '';\n    \n    for await (const chunk of response.textStream) {\n      process.stdout.write(chunk);\n      activitiesText += chunk;\n    }\n\n    return {\n      activities: activitiesText,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Testing the Agent with cURL (Bash)\nDESCRIPTION: cURL command to test the stock agent's endpoint by sending a POST request with a sample user message asking for Apple's stock price.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/stockAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"What is the current stock price of Apple (AAPL)?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Turbopuffer Vector Store Operations | TypeScript\nDESCRIPTION: This snippet demonstrates how to handle errors in vector store operations using try-catch, specifically catching instances of VectorStoreError and logging error details such as code and context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution Using Simple Path Comparison in Mastra Workflows\nDESCRIPTION: Shows the simplest approach to conditionally execute a step using a direct path-based comparison, which is concise and suitable for straightforward equality checks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      \"fetchData.status\": \"success\",\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Using console logger in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a Logger instance using the `createLogger()` function and log messages at different severity levels. The example shows that debug messages won't be logged when the logging level is set to info.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/logger.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Using a console logger\nconst logger = createLogger({ name: 'Mastra', level: 'info' });\n\nlogger.debug('Debug message'); // Won't be logged because level is INFO\nlogger.info({ message: 'User action occurred', destinationPath: 'user-actions', type: 'AGENT' }); // Logged\nlogger.error('An error occurred'); // Logged as ERROR\n```\n\n----------------------------------------\n\nTITLE: Creating Conversation Thread - Mastra TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a new conversation thread using the Mastra memory system in TypeScript. The 'createThread' function requires the 'Memory' class from '@mastra/memory' and a configuration object, which includes parameters such as 'resourceId', 'title', and 'metadata'. The function returns an object with an ID, resource ID, title, creation timestamp, update timestamp, and additional metadata. It requires installation of the '@mastra/memory' package and expects parameters like 'resourceId' as a string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/createThread.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({ /* config */ });\nconst thread = await memory.createThread({\n  resourceId: \"user-123\",\n  title: \"Support Conversation\",\n  metadata: {\n    category: \"support\",\n    priority: \"high\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra\nDESCRIPTION: Creates instances of PgVector for vector storage and Mastra with the configured agent and vector components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Using MCP toolsets for dynamic configuration in TypeScript\nDESCRIPTION: This TypeScript code shows how to use toolsets with the MCPConfiguration class, allowing for dynamic tool configuration. This is useful when tool settings need to be adjusted on a per-request basis or for multi-user environments. The code retrieves the toolsets using `mcp.getToolsets()` and passes them to the agent during execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    example: {\n      command: \"npx\",\n      args: [\"-y\", \"@example/fakemcp\"],\n      env: {\n        API_KEY: \"your-api-key\",\n      },\n    },\n  },\n});\n\n// このユーザー用に設定された現在のツールセットを取得\nconst toolsets = await mcp.getToolsets();\n\n// ユーザー固有のツール設定でエージェントを使用\nconst response = await agent.stream(\n  \"What's new in Mastra and how's the weather?\",\n  {\n    toolsets,\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Vector Store with Qdrant in TypeScript\nDESCRIPTION: The provided TypeScript code demonstrates how to create and manage a vector store using the @mastra/qdrant SDK. Dependencies include URL of the Qdrant instance and optionally, an API key. The usage example shows index creation, vector upsertion, and querying operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { QdrantVector } from '@mastra/qdrant';\n\nconst vectorStore = new QdrantVector(\n  'http://localhost:6333', // url\n  'optional-api-key',      // optional\n  false                    // https (optional)\n);\n\n// Create a new collection\nawait vectorStore.createIndex({ indexName: 'myCollection', dimension: 1536, metric: 'cosine' });\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({ indexName: 'myCollection', vectors, metadata });\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'myCollection',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: { $eq: 'doc1' } }, // optional filter\n  includeVector: false // includeVector\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Constructor Options for ChromaVector\nDESCRIPTION: Defines the properties required to initialize a ChromaVector instance, specifying the URL path to the ChromaDB instance and optional authentication configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"path\",\n      type: \"string\",\n      description: \"URL path to ChromaDB instance\",\n    },\n    {\n      name: \"auth\",\n      type: \"object\",\n      isOptional: true,\n      description: \"Authentication configuration\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Saving messages using CloudflareStore (TypeScript)\nDESCRIPTION: Saves multiple messages to the Cloudflare KV store using the saveMessages method. Each message includes an ID, thread ID, content, role, and creation timestamp.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n// Add messages\nawait store.saveMessages({\n  messages: [\n    {\n      id: 'msg-1',\n      threadId: 'thread-123',\n      content: 'Hello Cloudflare!',\n      role: 'user',\n      createdAt: new Date(),\n    },\n  ],\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Creating the Graph in GraphRAG\nDESCRIPTION: This snippet showcases the `createGraph` method of the GraphRAG class. It takes an array of document chunks (`GraphChunk[]`) and corresponding embeddings (`GraphEmbedding[]`) as input, constructing a knowledge graph where nodes represent documents and edges represent semantic relationships based on a similarity threshold.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/graph-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ncreateGraph(chunks: GraphChunk[], embeddings: GraphEmbedding[]): void\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Agent with Chain of Thought Instructions\nDESCRIPTION: Sets up a Mastra agent with detailed instructions for chain-of-thought reasoning and context-based response generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context.\nFollow these steps for each response:\n\n1. First, carefully analyze the retrieved context chunks and identify key information.\n2. Break down your thinking process about how the retrieved information relates to the query.\n3. Explain how you're connecting different pieces from the retrieved chunks.\n4. Draw conclusions based only on the evidence in the retrieved context.\n5. If the retrieved chunks don't contain enough information, explicitly state what's missing.\n\nFormat your response as:\nTHOUGHT PROCESS:\n- Step 1: [Initial analysis of retrieved chunks]\n- Step 2: [Connections between chunks]\n- Step 3: [Reasoning based on chunks]\n\nFINAL ANSWER:\n[Your concise answer based on the retrieved context]\n\nImportant: When asked to answer a question, please base your answer only on the context provided in the tool. \nIf the context doesn't contain enough information to fully answer the question, please state that explicitly.\nRemember: Explain how you're using the retrieved information to reach your conclusions.\n`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Story and Converting to Speech in TypeScript\nDESCRIPTION: This code snippet demonstrates how to generate story content and convert it to speech using a Mastra agent. It retrieves the 'storyTellerAgent' from the Mastra client, constructs a message based on user input, calls the `generate` method to create the story, and then calls the `voice.speak` method to convert the generated text into audio. It also handles the audio stream and sets the audio blob for playback. Error handling is included.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/text-to-speech.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst handleInitialSubmit = async (formData: FormData) => {\n  setIsLoading(true);\n  try {\n    const agent = mastraClient.getAgent('storyTellerAgent');\n    const message = `Current phase: BEGINNING. Story genre: ${formData.genre}, Protagonist name: ${formData.protagonistDetails.name}, Protagonist age: ${formData.protagonistDetails.age}, Protagonist gender: ${formData.protagonistDetails.gender}, Protagonist occupation: ${formData.protagonistDetails.occupation}, Story Setting: ${formData.setting}`;\n    const storyResponse = await agent.generate({\n      messages: [{ role: 'user', content: message }],\n      threadId: storyState.threadId,\n      resourceId: storyState.resourceId,\n    });\n\n    const storyText = storyResponse.text;\n\n    const audioResponse = await agent.voice.speak(storyText);\n\n    if (!audioResponse.body) {\n      throw new Error('No audio stream received');\n    }\n\n    const audio = await readStream(audioResponse.body);\n\n    setStoryState(prev => ({\n      phase: 'beginning',\n      threadId: prev.threadId,\n      resourceId: prev.resourceId,\n      content: {\n        ...prev.content,\n        beginning: storyText,\n      },\n    }));\n\n    setAudioBlob(audio);\n    return audio;\n  } catch (error) {\n    console.error('Error generating story beginning:', error);\n  } finally {\n    setIsLoading(false);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Advanced Metadata Extraction Configuration in TypeScript\nDESCRIPTION: This snippet demonstrates an advanced use case of the Mastra framework's MDocument class for extracting titles, summaries, questions, and keywords with custom configuration settings for each extraction type.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/extract-params.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(text);\nconst chunks = await doc.chunk({\n  extract: {\n    // Title extraction with custom settings\n    title: {\n      nodes: 2,  // Extract 2 title nodes\n      nodeTemplate: \"Generate a title for this: {context}\",\n      combineTemplate: \"Combine these titles: {context}\"\n    },\n\n    // Summary extraction with custom settings\n    summary: {\n      summaries: [\"self\"],  // Generate summaries for current chunk\n      promptTemplate: \"Summarize this: {context}\"\n    },\n\n    // Question generation with custom settings\n    questions: {\n      questions: 3,  // Generate 3 questions\n      promptTemplate: \"Generate {numQuestions} questions about: {context}\",\n      embeddingOnly: false\n    },\n\n    // Keyword extraction with custom settings\n    keywords: {\n      keywords: 5,  // Extract 5 keywords\n      promptTemplate: \"Extract {maxKeywords} key terms from: {context}\"\n    }\n  }\n});\n\n// Example output:\n// chunks[0].metadata = {\n//   documentTitle: \"AI in Modern Computing\",\n//   sectionSummary: \"Overview of AI concepts and their applications in computing\",\n//   questionsThisExcerptCanAnswer: \"1. What is machine learning?\\n2. How do neural networks work?\",\n//   excerptKeywords: \"1. Machine learning\\n2. Neural networks\\n3. Training data\"\n// }\n```\n\n----------------------------------------\n\nTITLE: Working Memory Tool Call Removal\nDESCRIPTION: This code change removes working memory tool calls from the thread history after the working memory has been updated. It aims to prevent updates from polluting the context history and confusing agents by ensuring they only see the most recent copy of working memory. It also makes the memory.getWorkingMemory() method public for testing, debugging, and UI building.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Basic Variable Mapping in Mastra Workflow\nDESCRIPTION: Demonstrates how to use the 'variables' property to map data from trigger inputs to step inputs and between steps in a Mastra workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'data-mapping-workflow',\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\nworkflow\n  .step(step1, {\n    variables: {\n      // Map trigger data to step input\n      inputData: { step: 'trigger', path: 'inputData' }\n    }\n  })\n  .then(step2, {\n    variables: {\n      // Map output from step1 to input for step2\n      previousValue: { step: step1, path: 'outputField' }\n    }\n  })\n  .commit();\n\n// Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Memory Package\nDESCRIPTION: This command installs the `@mastra/memory` package using npm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Chunk Markdown with Mastra\nDESCRIPTION: This snippet demonstrates how to chunk a Markdown document using Mastra. It imports the `MDocument` class from the `@mastra/rag` package and uses the `fromMarkdown` method to create a document object from Markdown content. Then, it calls the `chunk` method to split the document into smaller parts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/chunk-markdown.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromMarkdown(\"# Your markdown content...\");\n\nconst chunks = await doc.chunk();\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent with Integration Tools\nDESCRIPTION: Example of configuring an agent with GitHub integration tools\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { getMainBranchRef } from \"../tools\";\n\nexport const codeReviewAgent = new Agent({\n  name: \"Code Review Agent\",\n  instructions:\n    \"An agent that reviews code repositories and provides feedback.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    getMainBranchRef,\n    // other tools...\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining WorkflowRunState Interface in TypeScript\nDESCRIPTION: This TypeScript interface defines the structure of a workflow run state snapshot. It includes core state information, workflow context (step results, trigger data, retry attempts, input data), active execution paths, metadata (run ID, timestamp), and information about child workflows and suspended steps.  All data within is serializable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nexport interface WorkflowRunState {\n  // Core state info\n  value: Record<string, string>; // Current state machine value\n  context: {\n    // Workflow context\n    steps: Record<\n      string,\n      {\n        // Step execution results\n        status: \"success\" | \"failed\" | \"suspended\" | \"waiting\" | \"skipped\";\n        payload?: any; // Step-specific data\n        error?: string; // Error info if failed\n      }\n    >;\n    triggerData: Record<string, any>; // Initial trigger data\n    attempts: Record<string, number>; // Remaining retry attempts\n    inputData: Record<string, any>; // Initial input data\n  };\n\n  activePaths: Array<{\n    // Currently active execution paths\n    stepPath: string[];\n    stepId: string;\n    status: string;\n  }>;\n\n  // Metadata\n  runId: string; // Unique run identifier\n  timestamp: number; // Time snapshot was created\n\n  // For nested workflows and suspended steps\n  childStates?: Record<string, WorkflowRunState>; // Child workflow states\n  suspendedSteps?: Record<string, string>; // Mapping of suspended steps\n}\n```\n\n----------------------------------------\n\nTITLE: RAG Implementation Example TypeScript\nDESCRIPTION: This code demonstrates a basic RAG implementation: initializing a document, creating chunks using a recursive strategy, generating embeddings using OpenAI's embedding model, storing them in a PgVector database, and querying for similar chunks. It requires the 'ai', '@ai-sdk/openai', '@mastra/pg', '@mastra/rag', and 'zod' dependencies, as well as a PostgreSQL connection string in the environment variables. The code returns similar chunks from the vector database based on a query vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument } from \"@mastra/rag\";\nimport { z } from \"zod\";\n\n// 1. Initialize document\nconst doc = MDocument.fromText(`Your document text here...`);\n\n// 2. Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n});\n\n// 3. Generate embeddings; we need to pass the text of each chunk\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\n// 4. Store in vector database\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING);\nawait pgVector.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n}); // using an index name of 'embeddings'\n\n// 5. Query similar chunks\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryVector,\n  topK: 3,\n}); // queryVector is the embedding of the query\n\nconsole.log(\"Similar chunks:\", results);\n```\n\n----------------------------------------\n\nTITLE: Creating Condition-Based Loops with while() Method and Reference Condition\nDESCRIPTION: Shows how to use the while() method with a reference-based condition to repeat a step while a specific data value meets the required criteria, using query operators for comparison.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(\n    {\n      ref: { step: incrementStep, path: 'updatedCounter' },\n      query: { $lt: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Define Editor Agent - TypeScript\nDESCRIPTION: This code snippet defines an editor agent using the `Agent` class. It sets the agent's name to 'Editor' and instructs it to edit blog post copy. The model used is 'gpt-4o-mini' from the OpenAI AI SDK.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"あなたはブログ投稿のコピーを編集するエディターエージェントです。\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating an API Route with Mastra\nDESCRIPTION: This code demonstrates how to create an API route using Mastra in a Next.js application. It imports the mastra instance from '@/mastra' and NextResponse from 'next/server', defines an asynchronous POST function that retrieves the city from the request body, gets a weather agent from mastra, streams a response based on the provided city, and returns the data stream response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from '@/mastra'\nimport { NextResponse } from 'next/server'\n\nexport async function POST(req: Request) {\n  const { city } = await req.json()\n  const agent = mastra.getAgent('weatherAgent')\n\n  const result = await agent.stream(`What's the weather like in ${city}?`)\n\n  return result.toDataStreamResponse()\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing a Voice Provider Class in TypeScript\nDESCRIPTION: A comprehensive example demonstrating how to extend the MastraVoice abstract base class to create a custom voice provider implementation. It includes constructor configuration, required abstract method implementations, and optional speech-to-speech methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraVoice } from \"@mastra/core/voice\";\n\n// Create a voice provider implementation\nclass MyVoiceProvider extends MastraVoice {\n  constructor(config: { \n    speechModel?: BuiltInModelConfig; \n    listeningModel?: BuiltInModelConfig; \n    speaker?: string;\n    realtimeConfig?: {\n      model?: string;\n      apiKey?: string;\n      options?: unknown;\n    };\n  }) {\n    super({\n      speechModel: config.speechModel,\n      listeningModel: config.listeningModel,\n      speaker: config.speaker,\n      realtimeConfig: config.realtimeConfig\n    });\n  }\n\n  // Implement required abstract methods\n  async speak(input: string | NodeJS.ReadableStream, options?: { speaker?: string }): Promise<NodeJS.ReadableStream | void> {\n    // Implement text-to-speech conversion\n  }\n\n  async listen(audioStream: NodeJS.ReadableStream, options?: unknown): Promise<string | NodeJS.ReadableStream | void> {\n    // Implement speech-to-text conversion\n  }\n\n  async getSpeakers(): Promise<Array<{ voiceId: string; [key: string]: unknown }>> {\n    // Return list of available voices\n  }\n  \n  // Optional speech-to-speech methods\n  async connect(): Promise<void> {\n    // Establish WebSocket connection for speech-to-speech communication\n  }\n  \n  async send(audioData: NodeJS.ReadableStream | Int16Array): Promise<void> {\n    // Stream audio data in speech-to-speech\n  }\n  \n  async answer(): Promise<void> {\n    // Trigger voice provider to respond\n  }\n  \n  addTools(tools: Array<unknown>): void {\n    // Add tools for the voice provider to use\n  }\n  \n  close(): void {\n    // Close WebSocket connection\n  }\n  \n  on(event: string, callback: (data: unknown) => void): void {\n    // Register event listener\n  }\n  \n  off(event: string, callback: (data: unknown) => void): void {\n    // Remove event listener\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Suspending Workflow Execution with a Message Payload in TypeScript\nDESCRIPTION: Demonstrates how to pause a workflow and pass relevant data to provide context for human decision-making. The suspend function takes a payload object containing a message and data for the human reviewer.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nawait suspend({\n  messageForHuman: 'Please review this data',\n  data: someImportantData\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing BiasMetric with OpenAI in Typescript\nDESCRIPTION: This code snippet demonstrates how to initialize the `BiasMetric` with an OpenAI model and use it to measure bias in an LLM's output. It imports the necessary modules, configures the model, and calls the `measure` method to evaluate the bias. The output is the bias score, ranging from 0 to 1, where higher scores indicate more bias.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/bias.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { BiasMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new BiasMetric(model, {\n  scale: 1\n});\n\nconst result = await metric.measure(\n  \"Describe leadership qualities in the workplace\",\n  \"Strong leaders are typically men who can make tough decisions...\"\n);\n\nconsole.log(result.score); // Score from 0-1, higher means more biased\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with DefaultStorage (LibSQL) TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize a Mastra instance with the `DefaultStorage` provider, which uses LibSQL. It shows the necessary imports and the configuration object for the storage, including the database URL. This setup is suitable for local development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/storage/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { DefaultStorage } from \"@mastra/core/storage/libsql\";\n\nconst mastra = new Mastra({\n  storage: new DefaultStorage({\n    config: {\n      url: \"file:.mastra/mastra.db\",\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Advanced Metadata Extraction with Custom Settings\nDESCRIPTION: This example demonstrates advanced metadata extraction using custom settings for title, summary, questions, and keywords. It configures parameters like `nodes`, `nodeTemplate`, `summaries`, `promptTemplate`, `questions`, and `keywords` within the `extract` object. Requires @mastra/rag package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/extract-params.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(text);\nconst chunks = await doc.chunk({\n  extract: {\n    // Title extraction with custom settings\n    title: {\n      nodes: 2,  // Extract 2 title nodes\n      nodeTemplate: \"Generate a title for this: {context}\",\n      combineTemplate: \"Combine these titles: {context}\"\n    },\n\n    // Summary extraction with custom settings\n    summary: {\n      summaries: [\"self\"],  // Generate summaries for current chunk\n      promptTemplate: \"Summarize this: {context}\"\n    },\n\n    // Question generation with custom settings\n    questions: {\n      questions: 3,  // Generate 3 questions\n      promptTemplate: \"Generate {numQuestions} questions about: {context}\",\n      embeddingOnly: false\n    },\n\n    // Keyword extraction with custom settings\n    keywords: {\n      keywords: 5,  // Extract 5 keywords\n      promptTemplate: \"Extract {maxKeywords} key terms from: {context}\"\n    }\n  }\n});\n\n// Example output:\n// chunks[0].metadata = {\n//   documentTitle: \"AI in Modern Computing\",\n//   sectionSummary: \"Overview of AI concepts and their applications in computing\",\n//   questionsThisExcerptCanAnswer: \"1. What is machine learning?\\n2. How do neural networks work?\",\n//   excerptKeywords: \"1. Machine learning\\n2. Neural networks\\n3. Training data\"\n// }\n```\n\n----------------------------------------\n\nTITLE: Event-Based Workflow Execution - TypeScript\nDESCRIPTION: This code shows how to start an event-based workflow and then resume it with the `resumeWithEvent` method after the expected event occurs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// ワークフローを取得\nconst workflow = mastra.getWorkflow(\"approval-workflow\");\nconst run = workflow.createRun();\n\n// ワークフローを開始\nconst initialResult = await run.start({\n  triggerData: { requestId: \"request-123\" },\n});\n\nconsole.log(\"ワークフローが開始され、承認イベントを待っています\");\nconsole.log(initialResult.results);\n// 出力はワークフローがイベントステップで一時停止していることを示します：\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'suspended' }\n// }\n\n// 後で、承認イベントが発生したとき：\nconst resumeResult = await run.resumeWithEvent(\"approvalReceived\", {\n  approved: true,\n  approverName: \"Jane Doe\",\n});\n\nconsole.log(\"イベントデータでワークフローが再開されました:\", resumeResult.results);\n// 出力は完了したワークフローを示します：\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'success', output: { executed: true, resumedEvent: { approved: true, approverName: 'Jane Doe' } } },\n//   processApproval: { status: 'success', output: { approved: true, approvedBy: 'Jane Doe' } }\n// }\n```\n\n----------------------------------------\n\nTITLE: Build and Register Workflow in Mastra\nDESCRIPTION: This code constructs a Mastra workflow named `product-recommendation-workflow`. It defines a trigger schema requiring a `customerName` and then chains the `generateRecommendations`, `reviewRecommendations`, and `sendRecommendations` steps together. Finally, it registers this workflow with a Mastra instance, making it available for execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Build the workflow\nconst recommendationWorkflow = new Workflow({\n  name: 'product-recommendation-workflow',\n  triggerSchema: z.object({\n    customerName: z.string(),\n  }),\n});\n\nrecommendationWorkflow\n.step(generateRecommendations)\n.then(reviewRecommendations)\n.then(sendRecommendations)\n.commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { recommendationWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Executing the Workflow in TypeScript\nDESCRIPTION: This code demonstrates how to set up Mastra with the defined workflow and execute it. It creates a run, starts it with trigger data, and logs the final output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst mastra = new Mastra({\n  workflows: {\n    candidateWorkflow,\n  },\n});\n\n(async () => {\n  const { runId, start } = mastra.getWorkflow(\"candidateWorkflow\").createRun();\n\n  console.log(\"Run\", runId);\n\n  const runResult = await start({\n    triggerData: { resumeText: \"Simulated resume content...\" },\n  });\n\n  console.log(\"Final output:\", runResult.results);\n})();\n```\n\n----------------------------------------\n\nTITLE: Grouping Document Chunks for Title Extraction in TypeScript\nDESCRIPTION: This snippet illustrates how to group multiple document chunks for title extraction in Mastra, utilizing a shared docId in the metadata field to ensure consistent title extraction across related chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/extract-params.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = new MDocument({\n  docs: [\n    { text: \"chunk 1\", metadata: { docId: \"docA\" } },\n    { text: \"chunk 2\", metadata: { docId: \"docA\" } },\n    { text: \"chunk 3\", metadata: { docId: \"docB\" } },\n  ],\n  type: \"text\",\n});\n\nawait doc.extractMetadata({ title: true });\n// The first two chunks will share a title, while the third chunk will be assigned a separate title.\n```\n\n----------------------------------------\n\nTITLE: Multiple Dependencies Workflow with .after() in Typescript\nDESCRIPTION: This snippet demonstrates a workflow where `processOrder` is executed after both `validateUserData` and `validateProductData` complete, showcasing multiple dependencies using `.after()`. It merges two branches before processing the order.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/after.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(fetchUserData)\n  .then(validateUserData)\n  .step(fetchProductData)\n  .then(validateProductData)\n  .after([validateUserData, validateProductData])  // Wait for both validations to complete\n  .step(processOrder);\n```\n\n----------------------------------------\n\nTITLE: CompositeVoice Usage Example in TypeScript\nDESCRIPTION: This code demonstrates how to use the CompositeVoice class to combine OpenAI for speech-to-text and PlayAI for text-to-speech. It initializes the voice providers, creates a CompositeVoice instance, and performs speech-to-text and text-to-speech conversions. The example requires the @mastra/core/voice, @mastra/voice-openai, and @mastra/voice-playai packages to be installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/composite-voice.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\n// Create voice providers\nconst openai = new OpenAIVoice();\nconst playai = new PlayAIVoice();\n\n// Use OpenAI for listening (speech-to-text) and PlayAI for speaking (text-to-speech)\nconst voice = new CompositeVoice({\n  input: openai,\n  output: playai\n});\n\n// Convert speech to text using OpenAI\nconst text = await voice.listen(audioStream);\n\n// Convert text to speech using PlayAI\nconst audio = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Complete Document Processing Pipeline\nDESCRIPTION: Presents a complete example of document processing, including document initialization, chunking, and embedding generation using both OpenAI and Cohere. This showcases the entire workflow from start to finish.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { cohere } from \"@ai-sdk/cohere\";\n\nimport { MDocument } from \"@mastra/rag\";\n\n// Initialize document\nconst doc = MDocument.fromText(`\n  Climate change poses significant challenges to global agriculture.\n  Rising temperatures and changing precipitation patterns affect crop yields.\n`);\n\n// Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n});\n\n// Generate embeddings with OpenAI\nconst { embeddings: openAIEmbeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\n// OR\n\n// Generate embeddings with Cohere\nconst { embeddings: cohereEmbeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n\n// Store embeddings in your vector database\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Memory Processor\nDESCRIPTION: Shows how to create a custom memory processor by extending the MemoryProcessor class, implementing a conversation-only filter as an example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory, CoreMessage } from \"@mastra/memory\";\nimport { MemoryProcessor, MemoryProcessorOpts } from \"@mastra/core/memory\";\n\nclass ConversationOnlyFilter extends MemoryProcessor {\n  constructor() {\n    // Provide a name for easier debugging if needed\n    super({ name: \"ConversationOnlyFilter\" });\n  }\n\n  process(\n    messages: CoreMessage[],\n    _opts: MemoryProcessorOpts = {}, // Options passed during memory retrieval, rarely needed here\n  ): CoreMessage[] {\n    // Filter messages based on role\n    return messages.filter(\n      (msg) => msg.role === \"user\" || msg.role === \"assistant\",\n    );\n  }\n}\n\n// Use the custom processor\nconst memoryWithCustomFilter = new Memory({\n  processors: [\n    new ConversationOnlyFilter(),\n    new TokenLimiter(127000), // Still apply token limiting\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAG in Typescript\nDESCRIPTION: This snippet shows the basic usage of the GraphRAG class. It initializes the class with a dimension of 1536 and a similarity threshold of 0.7. It then creates a graph from document chunks and their corresponding embeddings and queries the graph using an embedding.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/graph-rag.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GraphRAG } from \"@mastra/rag\";\n\nconst graphRag = new GraphRAG({\n  dimension: 1536,\n  threshold: 0.7\n});\n\n// チャンクと埋め込みからグラフを作成\ngraphRag.createGraph(documentChunks, embeddings);\n\n// 埋め込みでグラフをクエリ\nconst results = await graphRag.query({\n  query: queryEmbedding,\n  topK: 10,\n  randomWalkSteps: 100,\n  restartProb: 0.15\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Defining Steps for Parallel Workflow - TypeScript\nDESCRIPTION: Defines four steps (stepOne, stepTwo, stepThree, stepFour) with asynchronous execute functions. Each step performs a simple calculation or conditional logic based on input data and the status/output of other steps. Uses `@mastra/core/workflows` for Step and Workflow and `zod` for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/parallel-steps.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 }\n  },\n});\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) => ({\n    tripledValue: context.triggerData.inputValue * 3,\n  }),\n});\n\nconst stepFour = new Step({\n  id: \"stepFour\",\n  execute: async ({ context }) => {\n    if (context.steps.stepThree.status !== \"success\") {\n      return { isEven: false }\n    }\n\n    return { isEven: context.steps.stepThree.output.tripledValue % 2 === 0 }\n  },\n});\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Trigger Data in Mastra Workflows (TypeScript)\nDESCRIPTION: This snippet shows how to access the original trigger data that initiated a Mastra workflow, ensuring type safety. It defines a `triggerSchema` using `zod` and accesses the data using `context.getStepResult<TriggerType>('trigger')`.  It uses `Step` and `Workflow` classes from `@mastra/core/workflows`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define trigger schema\nconst triggerSchema = z.object({\n  customerId: z.string(),\n  orderItems: z.array(z.string()),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // Access trigger data with type safety\n    const triggerData = context.getStepResult<TriggerType>('trigger');\n\n    return {\n      customerId: triggerData?.customerId,\n      itemCount: triggerData?.orderItems.length || 0,\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n  triggerSchema,\n});\n\nworkflow\n  .step(processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Querying with Reranking\nDESCRIPTION: This code demonstrates how to query the agent using different queries and displays the responses. The `agent.generate` method is used to generate answers based on the context retrieved by the vector query tool, which includes reranking to enhance the relevance of the results. The queries and responses are then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = 'explain technical trading analysis';\nconst answerOne = await agent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'explain trading card valuation';\nconst answerTwo = await agent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'how do you analyze market resistance';\nconst answerThree = await agent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Relevancy Context in Mastra\nDESCRIPTION: Demonstrates evaluating a response where all context about Einstein is relevant to the query about his achievements, using the ContextRelevancyMetric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'Einstein won the Nobel Prize for his discovery of the photoelectric effect.',\n  'He published his theory of relativity in 1905.',\n  'His work revolutionized modern physics.',\n];\n\nconst metric1 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'What were some of Einstein\\'s achievements?';\nconst response1 = 'Einstein won the Nobel Prize for discovering the photoelectric effect and published his groundbreaking theory of relativity.';\n\nconsole.log('Example 1 - High Relevancy:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The context uses all relevant information and does not include any irrelevant information.' }\n```\n\n----------------------------------------\n\nTITLE: Mapping Data Between Steps (TypeScript)\nDESCRIPTION: Shows how to map data from the output of one step (`generateData`) to the input of another step (`processData`).  The `previousValue` input of `processData` is populated with the `nested.value` property from the output of `generateData`. Requires `@mastra/core` and `zod`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// ステップ1: データを生成\nconst generateData = new Step({\n  id: \"generateData\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async () => {\n    return {\n      nested: {\n        value: \"step1-data\"\n      }\n    };\n  },\n});\n\n// ステップ2: ステップ1からのデータを処理\nconst processData = new Step({\n  id: \"processData\",\n  inputSchema: z.object({\n    previousValue: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // previousValueは変数マッピングのために利用可能になります\n    const { previousValue } = context.inputData;\n\n    return {\n      result: `Processed: ${previousValue}`\n    };\n  },\n});\n\n// ワークフローを作成\nconst workflow = new Workflow({\n  name: \"step-mapping\",\n});\n\n// ステップ1からステップ2へのデータをマッピング\nworkflow\n  .step(generateData)\n  .then(processData, {\n    variables: {\n      // generateDataの出力からnested.valueプロパティをマッピング\n      previousValue: { step: generateData, path: 'nested.value' },\n    }\n  })\n  .commit();\n\n  // Mastraにワークフローを登録\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Get All Agents with TypeScript\nDESCRIPTION: Retrieves a list of all available agents from the Mastra AI platform. This function uses the client object to call the `getAgents` method, which returns a promise that resolves to an array of agent objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst agents = await client.getAgents();\n```\n\n----------------------------------------\n\nTITLE: Resume Workflow Run Asynchronously using TypeScript\nDESCRIPTION: This snippet demonstrates how to resume a suspended workflow step asynchronously and await the full run result. It leverages a `createRun` function and the `workflow.resumeAsync` method, which takes the `runId`, `stepId`, and `contextData` as parameters and returns a promise that resolves with the run result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst {runId} = createRun({runId: prevRunId})\n\nconst result = await workflow.resumeAsync({\n  runId,\n  stepId: \"step-id\",\n  contextData: { key: \"value\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Default Storage in TypeScript\nDESCRIPTION: Demonstrates basic setup of Memory class which automatically uses DefaultStorage if no storage is provided. Configures memory options including message limits and semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/storage/README.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from '@mastra/memory';\n\nconst memory = new Memory({\n  options: {\n    lastMessages: 10,\n    semanticRecall: true,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Merging Workflow Branches with .after() in Typescript\nDESCRIPTION: This snippet demonstrates how to merge multiple branches in a Mastra workflow using the `.after()` method. Step E is executed only after both Step B and Step D complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/after.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n    .then(stepB)\n  .step(stepC)\n    .then(stepD)\n  .after([stepB, stepD])  // Create a step that depends on multiple steps\n    .step(stepE);\n```\n\n----------------------------------------\n\nTITLE: Updating Index Vector Only by ID\nDESCRIPTION: This snippet demonstrates updating a vector in the index by its ID, modifying only the vector value. It calls the `updateIndexById` method with the index name, ID, and a partial update object containing the new vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// ベクトルのみを更新\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  vector: [0.1, 0.2, 0.3],\n});\n```\n\n----------------------------------------\n\nTITLE: Create Vector Query Tool Typescript\nDESCRIPTION: Creates a vector query tool using the `createVectorQueryTool` function from `@mastra/rag`.  This tool is configured to interact with a vector store named 'pgVector' and index named 'embeddings'. It uses the `text-embedding-3-small` model from OpenAI for generating embeddings to facilitate vector queries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Using Mastra Client for Agent Interaction\nDESCRIPTION: Example demonstrating how to interact with an AI agent using the MastraClient, including message generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Get a reference to your local agent\nconst agent = client.getAgent(\"dev-agent-id\");\n\n// Generate responses\nconst response = await agent.generate({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Hello, I'm testing the local development setup!\"\n    }\n  ]\n});\n```\n\n----------------------------------------\n\nTITLE: Executing a Tool with Arguments\nDESCRIPTION: This snippet demonstrates how to execute a tool with specified arguments using the `tool.execute()` method. It also includes optional threadId and resourceId parameters for context. The method returns a promise that resolves to the result of the tool execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/tools.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await tool.execute({\n  args: {\n    param1: \"value1\",\n    param2: \"value2\",\n  },\n  threadId: \"thread-1\", // オプション: スレッドコンテキスト\n  resourceid: \"resource-1\", // オプション: リソース識別子\n});\n```\n\n----------------------------------------\n\nTITLE: Memory Setup with Token Limit (TypeScript)\nDESCRIPTION: This TypeScript snippet initializes a Memory instance with a TokenLimiter. The TokenLimiter is configured to restrict memory usage to approximately 127000 tokens, which is suitable for the GPT-4o model. This helps prevent context window overflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter } from \"@mastra/memory/processors\";\n\n// Set up memory with a token limit\nconst memory = new Memory({\n  processors: [\n    // Limit to approximately 12700 tokens (for GPT-4o)\n    new TokenLimiter(127000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Storing Rich Metadata with Embeddings in TypeScript\nDESCRIPTION: This code demonstrates how to store embeddings with rich metadata for filtering and organization. The metadata can include arbitrary JSON-serializable fields, but it is crucial to maintain consistent field names to avoid unexpected query results. At a minimum, the original text should always be included as metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\n// より良い整理とフィルタリングのためにリッチなメタデータで埋め込みを保存\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map((chunk) => ({\n    // 基本的な内容\n    text: chunk.text,\n    id: chunk.id,\n    \n    // ドキュメントの整理\n    source: chunk.source,\n    category: chunk.category,\n    \n    // 時間的メタデータ\n    createdAt: new Date().toISOString(),\n    version: \"1.0\",\n    \n    // カスタムフィールド\n    language: chunk.language,\n    author: chunk.author,\n    confidenceScore: chunk.score,\n  })),\n});\n```\n\n----------------------------------------\n\nTITLE: Filtering Tool Calls (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to use the ToolCallFilter to remove tool calls from memory. The first example filters all tool calls, while the second example filters only specific tool calls ('imageGenTool' and 'clipboardTool').\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { ToolCallFilter } from \"@mastra/memory/processors\";\n\n// Filter out all tool calls\nconst memoryNoTools = new Memory({\n  processors: [new ToolCallFilter()],\n});\n\n// Filter specific tool calls\nconst memorySelectiveFilter = new Memory({\n  processors: [\n    new ToolCallFilter({\n      exclude: [\"imageGenTool\", \"clipboardTool\"],\n    }),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Listing All Vector Indexes in TypeScript\nDESCRIPTION: Retrieve a list of all available vector indexes using the Vectors API. This provides an overview of existing indexes for management or further operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst indexes = await vector.getIndexes();\n```\n\n----------------------------------------\n\nTITLE: Creating an Editor Agent in Mastra\nDESCRIPTION: This code creates an Editor agent using the OpenAI GPT-4 model. The agent is instructed to edit blog post copy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Start and Resume - TypeScript\nDESCRIPTION: This code demonstrates how to start a workflow, check if a step has been suspended, and resume the workflow with new context data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// ワークフローを取得し、実行を作成\nconst wf = mastra.getWorkflow(\"multi-suspend-workflow\");\nconst run = wf.createRun();\n\n// ワークフローを開始\nconst initialResult = await run.start({\n  triggerData: { input: \"初期入力\" },\n});\n\nlet promptAgentStepResult = initialResult.activePaths.get(\"promptAgent\");\nlet promptAgentResumeResult = undefined;\n\n// ステップが中断されているか確認\nif (promptAgentStepResult?.status === \"suspended\") {\n  console.log(\"ワークフローはpromptAgentステップで中断されました\");\n\n  // 新しいコンテキストでワークフローを再開\n  const resumeResult = await run.resume({\n    stepId: \"promptAgent\",\n    context: { userInput: \"人間が提供した入力\" },\n  });\n\n  promptAgentResumeResult = resumeResult;\n}\n\nconst improveResponseStepResult =\n  promptAgentResumeResult?.activePaths.get(\"improveResponse\");\n\nif (improveResponseStepResult?.status === \"suspended\") {\n  console.log(\"ワークフローはimproveResponseステップで中断されました\");\n\n  // 異なるコンテキストで再度再開\n  const finalResult = await run.resume({\n    stepId: \"improveResponse\",\n    context: { refinedOutput: \"人間が改善した出力\" },\n  });\n\n  console.log(\"ワークフローが完了しました:\", finalResult?.results);\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Content with AI and Human Guidance in Mastra Workflow - TypeScript\nDESCRIPTION: This snippet defines a step that generates content based on user input, potentially suspending for human guidance if the confidence in the generated content is low. It utilizes the async/await pattern to manage the workflow state effectively.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Generate content with AI (may suspend for human guidance)\nconst promptAgent = new Step({\n  id: 'promptAgent',\n  inputSchema: z.object({\n    guidance: z.string(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const userInput = context.getStepResult(getUserInput)?.userInput;\n    console.log(`Generating content based on: ${userInput}`);\n\n    const guidance = context.inputData?.guidance;\n\n    // Simulate AI generating content\n    const initialDraft = generateInitialDraft(userInput);\n\n    // If confidence is high, return the generated content directly\n    if (initialDraft.confidenceScore > 0.7) {\n      return { modelOutput: initialDraft.content };\n    }\n\n    console.log('Low confidence in generated content, suspending for human guidance', {guidance});\n\n    // If confidence is low, suspend for human guidance\n    if (!guidance) {\n      // only suspend if no guidance is provided\n      await suspend();\n      return undefined;\n    }\n\n    // This code runs after resume with human guidance\n    console.log('Resumed with human guidance');\n\n    // Use the human guidance to improve the output\n    return {\n      modelOutput: enhanceWithGuidance(initialDraft.content, guidance),\n    };\n  },\n  outputSchema: z.object({ modelOutput: z.string() }).optional(),\n});\n```\n\n----------------------------------------\n\nTITLE: Configure Conversation History Length (TypeScript)\nDESCRIPTION: This TypeScript code configures the conversation history length for a Memory instance.  It initializes a `Memory` object and sets the `lastMessages` option to 10, limiting the number of recent messages included in each request.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    lastMessages: 10,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing an Agent with OpenAI Model in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create an agent using the `Agent` class from `@mastra/core/agent` and integrates it with the OpenAI model from `@ai-sdk/openai`. It initializes the agent with a name, instructions, and the specified model. Ensure that `@mastra/core` and `@ai-sdk/openai` are installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SpeechifyVoice in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the SpeechifyVoice class from the @mastra/voice-speechify package with both default and custom configurations. It also shows how to convert text to speech using the speak method, with options to override the default voice.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/speechify.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SpeechifyVoice } from \"@mastra/voice-speechify\";\n\n// Initialize with default configuration (uses SPEECHIFY_API_KEY environment variable)\nconst voice = new SpeechifyVoice();\n\n// Initialize with custom configuration\nconst voice = new SpeechifyVoice({\n  speechModel: {\n    name: 'simba-english',\n    apiKey: 'your-api-key'\n  },\n  speaker: 'george'  // Default voice\n});\n\n// Convert text to speech\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 'henry',  // Override default voice\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Upstash with Mastra (TSX)\nDESCRIPTION: This code snippet illustrates how to create a collection and upsert embeddings into Upstash Vector, a serverless vector database, using the `UpstashVector` class from the `@mastra/upstash` package.  It utilizes the `openai` package for creating embeddings and `MDocument` from `@mastra/rag` for text handling.  The `UPSTASH_URL` and `UPSTASH_TOKEN` environment variables are needed for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_6\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { UpstashVector } from '@mastra/upstash';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst upstash = new UpstashVector({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN,\n});\n\nawait upstash.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait upstash.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Copywriter Agent and Tool in Typescript\nDESCRIPTION: This snippet defines a 'Copywriter' agent responsible for creating initial blog post content. It uses the Anthropic Claude model. A corresponding tool is created to allow other agents to call the copywriter with a specific topic and receive a blog post copy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/hierarchical-multi-agent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"あなたはブログ投稿のコピーを書くコピーライターエージェントです。\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n\nconst copywriterTool = createTool({\n  id: \"copywriter-agent\",\n  description: \"ブログ投稿のコピーを書くためにコピーライターエージェントを呼び出します。\",\n  inputSchema: z.object({\n    topic: z.string().describe(\"ブログ投稿のトピック\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"ブログ投稿のコピー\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.topic}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Enabling Working Memory in an Agent (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create an agent with working memory enabled. It imports necessary modules from `@mastra/core`, `@mastra/memory`, and `@ai-sdk/openai`. It then instantiates an `Agent` with working memory configured to use the 'tool-call' approach. The agent uses OpenAI's gpt-4o model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/working-memory.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create agent with working memory enabled\nconst agent = new Agent({\n  name: \"PersonalAssistant\",\n  instructions: \"You are a helpful personal assistant.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory({\n    options: {\n      workingMemory: {\n        enabled: true,\n        use: \"tool-call\", // Recommended setting\n      },\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing LibSQLStore for Persistent Database\nDESCRIPTION: This TypeScript snippet shows how to initialize the LibSQLStore for a persistent database using an environment variable. The `url` parameter reads the database URL from `process.env.DATABASE_URL`. This configuration is recommended for production environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/libsql.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLStore } from \"@mastra/libsql\";\n\n// Persistent database (production)\nconst storage = new LibSQLStore({\n  url: process.env.DATABASE_URL,\n});\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search in Messages Using TypeScript\nDESCRIPTION: This snippet shows how to perform a semantic search for messages in a thread by passing a search string to find semantically similar messages. It also utilizes thread configuration options for enhanced search capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/query.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst { messages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    vectorSearchString: \"What was discussed about deployment?\",\n  },\n  threadConfig: {\n    historySearch: true,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Set Environment Variables Bash\nDESCRIPTION: Sets the environment variables required for OpenAI API key and PostgreSQL connection string. These variables are essential for authenticating with the OpenAI service and connecting to the PostgreSQL database for vector storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Generating Speech and Saving to File\nDESCRIPTION: This TypeScript snippet demonstrates how to generate speech from a text string using the Sarvam Voice agent and save the audio output to a .wav file using Node.js streams.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst audio = await agent.voice.speak(\"Hello, I'm your AI assistant!\");\nconst filePath = path.join(process.cwd(), 'agent.wav');\nconst writer = createWriteStream(filePath);\n\naudio.pipe(writer);\n\nawait new Promise<void>((resolve, reject) => {\n  writer.on('finish', () => resolve());\n  writer.on('error', reject);\n});\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech in ElevenLabsVoice\nDESCRIPTION: This snippet outlines how to use the speak method in the ElevenLabsVoice class to convert input text or a readable stream into speech. The method returns a readable stream of audio data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nspeak(input: string | NodeJS.ReadableStream, options?: { speaker?: string })\n```\n\n----------------------------------------\n\nTITLE: Initializing Vector Query Tool with Reranking\nDESCRIPTION: This snippet illustrates how to initialize the `createVectorQueryTool` with reranking enabled.  Reranking improves search result quality by combining semantic relevance, vector similarity, positional bias, and query analysis. The reranker processes initial vector search results and returns a reordered list optimized for relevance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/vector-query-tool.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"milvus\",\n  indexName: \"documentation\",\n  model: openai.embedding('text-embedding-3-small'),\n  reranker: {\n    model: openai('gpt-4o-mini'),\n    options: {\n      weights: {\n        semantic: 0.5,  // セマンティック関連性の重み\n        vector: 0.3,    // ベクトル類似性の重み\n        position: 0.2   // 元の位置の重み\n      },\n      topK: 5\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Toxicity Evaluation in TypeScript\nDESCRIPTION: Imports the required dependencies from OpenAI SDK and Mastra evals library for toxicity evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ToxicityMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Example Usage of Agent and Metric (TypeScript)\nDESCRIPTION: Demonstrates how to use the configured `chefAgent` and the `GlutenCheckerMetric` to evaluate a recipe. It generates a recipe based on a user input, measures the gluten content using the metric, and logs the results, including the score, gluten sources, and a detailed reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from './mastra';\n\nconst chefAgent = mastra.getAgent('chefAgent');\nconst metric = chefAgent.evals.glutenChecker;\n\n// 例: レシピを評価する\nconst input = 'ご飯と豆を素早く作る方法は？';\nconst response = await chefAgent.generate(input);\nconst result = await metric.measure(input, response.text);\n\nconsole.log('メトリック結果:', {\n  score: result.score,\n  glutenSources: result.info.glutenSources,\n  reason: result.info.reason,\n});\n\n// 出力例:\n// メトリック結果: { score: 1, glutenSources: [], reason: 'このレシピはグルテンを含む成分が含まれていないため、グルテンフリーです。' }\n```\n\n----------------------------------------\n\nTITLE: Resume Workflow with Event - Error Handling - Typescript\nDESCRIPTION: This code snippet demonstrates how to handle potential errors when resuming a workflow with the `resumeWithEvent()` method. It wraps the call in a try-catch block to catch exceptions that might occur due to invalid event data or other issues. It assumes the workflow is waiting for a 'paymentReceived' event.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resumeWithEvent.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const result = await run.resumeWithEvent(\"paymentReceived\", {\n    amount: 100.5,\n    transactionId: \"tx-456\",\n    paymentMethod: \"credit-card\",\n  });\n\n  console.log(\"Workflow resumed successfully:\", result.results);\n} catch (error) {\n  console.error(\"Failed to resume workflow with event:\", error);\n  // Handle error - could be invalid event data, workflow not suspended, etc.\n}\n```\n\n----------------------------------------\n\nTITLE: Create Agent with Memory Instance\nDESCRIPTION: This code snippet demonstrates how to create a Mastra agent with a Memory instance. The Memory instance is initialized and assigned to the memory property of the Agent configuration. It imports necessary modules from @mastra/core/agent, @mastra/memory, and @ai-sdk/openai.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const myMemoryAgent = new Agent({\n  name: \"MemoryAgent\",\n  instructions: \"...\",\n  model: openai(\"gpt-4o\"),\n\n  memory: new Memory(),\n});\n```\n\n----------------------------------------\n\nTITLE: Example Usage of Context Precision Metric with Analysis\nDESCRIPTION: Provides an example of using the ContextPrecisionMetric to evaluate context related to exercise benefits. The code measures the precision of context nodes using a sample input and expected output, illustrating how relevant and precise context is assessed. Dependencies include '@ai-sdk/openai' and '@mastra/evals/llm'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-precision.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPrecisionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPrecisionMetric(model, {\n  context: [\n    \"Exercise strengthens the heart and improves blood circulation.\",\n    \"A balanced diet is important for health.\",\n    \"Regular physical activity reduces stress and anxiety.\",\n    \"Exercise equipment can be expensive.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"What are the benefits of exercise?\",\n  \"Regular exercise improves cardiovascular health and mental wellbeing.\",\n);\n\n// Example output:\n// {\n//   score: 0.75,\n//   info: {\n//     reason: \"The score is 0.75 because the first and third contexts are highly relevant\n//           to the benefits mentioned in the output, while the second and fourth contexts\n//           are not directly related to exercise benefits. The relevant contexts are well-positioned\n//           at the beginning and middle of the sequence.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedding Dimensions with Google\nDESCRIPTION: Illustrates how to configure embedding dimensions when using the Google text embedding model. This example sets the output dimensionality to 256.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: google.textEmbeddingModel('text-embedding-004', {\n    outputDimensionality: 256  // 末尾から過剰な値を切り捨て\n  }),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Gather Candidate Info Step - TypeScript\nDESCRIPTION: Defines a step to extract candidate details from resume text using an LLM. It initializes a recruiter agent, defines input and output schemas using Zod, and uses the agent to generate a structured JSON with candidate information such as name, technical status, specialty, and resume text. It expects `resumeText` in the trigger data and returns a structured JSON object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from \"@ai-sdk/openai\";\n\nconst recruiter = new Agent({\n  name: \"Recruiter Agent\",\n  instructions: `You are a recruiter.`,\n  model: openai(\"gpt-4o-mini\"),\n})\n\nconst gatherCandidateInfo = new Step({\n  id: \"gatherCandidateInfo\",\n  inputSchema: z.object({\n    resumeText: z.string(),\n  }),\n  outputSchema: z.object({\n    candidateName: z.string(),\n    isTechnical: z.boolean(),\n    specialty: z.string(),\n    resumeText: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const resumeText = context?.getStepResult<{resumeText: string;}>(\"trigger\")?.resumeText;\n\n    const prompt = `\n          Extract details from the resume text:\n          \"${resumeText}\"\n        `;\n\n    const res = await recruiter.generate(prompt, {\n      output: z.object({\n        candidateName: z.string(),\n        isTechnical: z.boolean(),\n        specialty: z.string(),\n        resumeText: z.string(),\n      }),\n    });\n\n    return res.object;\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up API keys in environment variables\nDESCRIPTION: Example of how to configure the .env file with OpenAI and Pinecone API keys for the embedding insertion process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPINECONE_API_KEY=your-pinecone-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Creating Document from JSON - TypeScript\nDESCRIPTION: Method `fromJSON` is a static method used for creating an MDocument from JSON content alongside optional metadata. Utilizes TypeScript and requires JSON content provided as a string. It optionally takes a `metadata` parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromJSON(json: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Generating Code with Verification in TypeScript\nDESCRIPTION: This snippet develops a prompt for generating code while ensuring self-verification of the generated output. It outlines the necessary steps for verification, input requirements, and constraints for robust code generation tailored for various programming languages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ntype CodeGenerationVars = {\n  requirements: string;\n  language: 'typescript' | 'python' | 'javascript';\n  testCases?: string[];\n};\n\nconst codeGenPrompt = createPrompt<CodeGenerationVars>('Generate code with verification', {\n  persona: 'Senior Software Engineer',\n  outputFormat: 'markdown',\n})\n  .text('Generate {{language}} code that meets these requirements:\\n\\n{{requirements}}')\n  .thinking({\n    steps: [\n      'Analyze requirements',\n      'Plan implementation approach',\n      'Write initial code',\n      'Add error handling',\n      'Implement input validation',\n    ],\n  })\n  .verificationSteps([\n    'Check if implementation meets all requirements',\n    'Run test cases: {{testCases}}',\n    'Verify edge case handling',\n    'Validate error handling',\n    'Check input validation',\n    'Assess code quality',\n    'Identify potential improvements',\n  ])\n  .constraints([\n    'Must handle all edge cases',\n    'Include input validation',\n    'Add error handling',\n    'Follow {{language}} best practices',\n  ]);\n\n// Usage example\nconst implementation = codeGenPrompt.toString({\n  requirements: 'Create a function that validates email addresses',\n  language: 'typescript',\n  testCases: ['valid email', 'missing @', 'multiple @', 'invalid domain'],\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool\nDESCRIPTION: Configures the vector query tool for searching the vector database using OpenAI embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Using CompositeVoice with listen() Method\nDESCRIPTION: This snippet illustrates how to use the `CompositeVoice` class, which allows combining different voice providers.  The `listen()` method is delegated to the configured `listenProvider`, in this case, an `OpenAIVoice` instance. This means that audio transcription will be handled by the OpenAI provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.listen.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\nconst voice = new CompositeVoice({\n  listenProvider: new OpenAIVoice(),\n  speakProvider: new PlayAIVoice(),\n});\n\n// これはOpenAIVoiceプロバイダーを使用します\nconst transcript = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Complete Workflow Example with Approval and Document Upload (TypeScript)\nDESCRIPTION: This snippet presents a complete Mastra workflow example that requires both approval and document upload. It defines the steps for creating a request, processing approval, processing the document, and finalizing the request.  The workflow uses `afterEvent` to pause execution until both events are received, and then resumes to complete the request processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n// Define steps\nconst createRequest = new Step({\n  id: 'createRequest',\n  execute: async () => ({ requestId: `req-${Date.now()}` }),\n});\n\nconst processApproval = new Step({\n  id: 'processApproval',\n  execute: async ({ context }) => {\n    const approvalData = context.inputData.resumedEvent;\n    return {\n      approved: approvalData.approved,\n      approver: approvalData.approverName,\n    };\n  },\n});\n\nconst processDocument = new Step({\n  id: 'processDocument',\n  execute: async ({ context }) => {\n    const documentData = context.inputData.resumedEvent;\n    return {\n      documentId: documentData.documentId,\n      processed: true,\n      type: documentData.documentType,\n    };\n  },\n});\n\nconst finalizeRequest = new Step({\n  id: 'finalizeRequest',\n  execute: async ({ context }) => {\n    const requestId = context.steps.createRequest.output.requestId;\n    const approved = context.steps.processApproval.output.approved;\n    const documentId = context.steps.processDocument.output.documentId;\n\n    return {\n      finalized: true,\n      summary: `Request ${requestId} was ${approved ? 'approved' : 'rejected'} with document ${documentId}`\n    };\n  },\n});\n\n// Create workflow\nconst requestWorkflow = new Workflow({\n  name: 'document-request-workflow',\n  events: {\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n    documentUploaded: {\n      schema: z.object({\n        documentId: z.string(),\n        documentType: z.enum(['invoice', 'receipt', 'contract']),\n      }),\n    },\n  },\n});\n\n// Build workflow\nrequestWorkflow\n  .step(createRequest)\n  .afterEvent('approvalReceived')\n  .step(processApproval)\n  .afterEvent('documentUploaded')\n  .step(processDocument)\n  .then(finalizeRequest)\n  .commit();\n\n// Export workflow\nexport { requestWorkflow };\n```\n\n----------------------------------------\n\nTITLE: Initializing Voice-Enabled Agent with OpenAI STT - TypeScript\nDESCRIPTION: This snippet shows how to initialize a voice-enabled agent with OpenAI's STT capabilities using `@ai-sdk/openai` and `@mastra/voice-openai`. The agent is configured with instructions and a default OpenAI voice provider. The `openai('gpt-4o')` part initializes the OpenAI model, and `new OpenAIVoice()` adds the voice provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/speech-to-text.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\nconst instructions = `\nYou are an AI note assistant tasked with providing concise, structured summaries of their content... // omitted for brevity\n`;\n\nexport const noteTakerAgent = new Agent({\n  name: 'Note Taker Agent',\n  instructions: instructions,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(), // Add OpenAI voice provider with default configuration\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses with Agent Network - TypeScript\nDESCRIPTION: This code snippet outlines the stream() method of the AgentNetwork class. It is used to stream a response from the network based on specified messages and optional streaming options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync stream(\n  messages: string | string[] | CoreMessage[],\n  args?: AgentStreamOptions\n): Promise<StreamTextResult>\n```\n\n----------------------------------------\n\nTITLE: Using CompletenessMetric for Text Analysis in TypeScript\nDESCRIPTION: Demonstrates the basic usage of the CompletenessMetric class from the @mastra/evals/nlp package. It initializes the metric, measures the completeness of an LLM's output against a given input, and logs the resulting score and information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/completeness.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new CompletenessMetric();\n\nconst result = await metric.measure(\n  \"Explain how photosynthesis works in plants using sunlight, water, and carbon dioxide.\",\n  \"Plants use sunlight to convert water and carbon dioxide into glucose through photosynthesis.\"\n);\n\nconsole.log(result.score); // 0-1の範囲のカバレッジスコア\nconsole.log(result.info); // 要素カバレッジに関する詳細なメトリクスを含むオブジェクト\n```\n\n----------------------------------------\n\nTITLE: Retrieving Vector Index Details in TypeScript\nDESCRIPTION: Fetch detailed information about a particular vector index. This requires specifying the index name and is typically used to understand the index's properties or status.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await vector.details(\"index-name\");\n```\n\n----------------------------------------\n\nTITLE: Create New Memory Thread (TypeScript)\nDESCRIPTION: Creates a new memory thread with the specified title, metadata, resource ID, and agent ID. Requires a title, metadata (optional), resourceid, and agentId. Returns the created thread object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst thread = await client.createMemoryThread({\n  title: \"New Conversation\",\n  metadata: { category: \"support\" },\n  resourceid: \"resource-1\",\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Executing Chain-of-Thought Queries\nDESCRIPTION: Demonstrates querying the RAG system with different questions to showcase the chain-of-thought reasoning process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst answerOne = await agent.generate('What are the main adaptation strategies for farmers?');\nconsole.log('\\nQuery:', 'What are the main adaptation strategies for farmers?');\nconsole.log('Response:', answerOne.text);\n\nconst answerTwo = await agent.generate('Analyze how temperature affects crop yields.');\nconsole.log('\\nQuery:', 'Analyze how temperature affects crop yields.');\nconsole.log('Response:', answerTwo.text);\n\nconst answerThree = await agent.generate('What connections can you draw between climate change and food security?');\nconsole.log('\\nQuery:', 'What connections can you draw between climate change and food security?');\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Running the Example Workflow (TypeScript)\nDESCRIPTION: This snippet demonstrates how to run the complete workflow example. It imports the defined workflow, creates a run, starts the workflow, and then simulates the occurrence of the `approvalReceived` and `documentUploaded` events by calling `resumeWithEvent` with appropriate data. The console logs show the results after each step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { requestWorkflow } from './workflows';\nimport { mastra } from './mastra';\n\nasync function runWorkflow() {\n  // Get the workflow\n  const workflow = mastra.getWorkflow('document-request-workflow');\n  const run = workflow.createRun();\n\n  // Start the workflow\n  const initialResult = await run.start();\n  console.log('Workflow started:', initialResult.results);\n\n  // Simulate receiving approval\n  const afterApprovalResult = await run.resumeWithEvent('approvalReceived', {\n    approved: true,\n    approverName: 'Jane Smith',\n  });\n  console.log('After approval:', afterApprovalResult.results);\n\n  // Simulate document upload\n  const finalResult = await run.resumeWithEvent('documentUploaded', {\n    documentId: 'doc-456',\n    documentType: 'invoice',\n  });\n  console.log('Final result:', finalResult.results);\n}\n\nrunWorkflow().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Using Workflow.until() with Function Condition\nDESCRIPTION: This code snippet illustrates using a function as the condition for the `.until()` method in a Mastra workflow. The function checks if the 'value' from the 'increment' step's result is greater than or equal to 10. If the condition is met, the loop terminates; otherwise, the `incrementStep` is repeated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/until.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nworkflow\n  .step(incrementStep)\n  .until(async ({ context }) => {\n    const result = context.getStepResult<{ value: number }>('increment');\n    return (result?.value ?? 0) >= 10; // 値が10に達するか超えたら停止\n  }, incrementStep)\n  .then(finalStep);\n```\n```\n\n----------------------------------------\n\nTITLE: Managing Threads with Storage API in TypeScript\nDESCRIPTION: Demonstrates thread management operations including creation, retrieval, and updates. Shows how to work with thread metadata and properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/storage/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a new thread\nconst thread = await storage.createThread({\n  resourceId: 'resource-123',\n  title: 'My Thread',\n  metadata: { key: 'value' },\n});\n\n// Get thread by ID\nconst retrievedThread = await storage.getThreadById({\n  threadId: thread.id,\n});\n\n// Update thread\nawait storage.updateThread({\n  id: thread.id,\n  title: 'Updated Title',\n  metadata: { newKey: 'newValue' },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Starting a Workflow Run in TypeScript\nDESCRIPTION: Demonstrates basic usage of workflow.createRun() to initialize and start a new workflow run instance. Returns a runId for tracking and a start function to begin execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/createRun.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start, watch } = workflow.createRun();\n\nconst result = await start();\n```\n\n----------------------------------------\n\nTITLE: Generating Reasoning Prompt (TypeScript)\nDESCRIPTION: Generates a prompt for providing a detailed explanation of why a recipe is considered gluten-free or not. It takes the results of the gluten evaluation (isGlutenFree and glutenSources) as input and constructs a prompt that asks the LLM to generate a human-readable reason in JSON format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const generateReasonPrompt = ({\\n  isGlutenFree,\\n  glutenSources,\\n}: {\\n  isGlutenFree: boolean;\\n  glutenSources: string[];\\n}) => `Explain why this recipe is${isGlutenFree ? '' : ' not'} gluten-free.\\n\n${glutenSources.length > 0 ? `Sources of gluten: ${glutenSources.join(', ')}` : 'No gluten-containing ingredients found'}\n\nReturn your response in this format:\\n{\n  \"reason\": \"This recipe is [gluten-free/contains gluten] because [explanation]\"\n}`;\n```\n\n----------------------------------------\n\nTITLE: Bird Classification with AI Agent in TypeScript\nDESCRIPTION: This TypeScript code fetches a random image from Unsplash based on predefined queries (wildlife, feathers, flying, birds) and uses a Mastra AI Agent to determine if the image contains a bird. The agent utilizes the Anthropic Claude-3-Haiku model. It defines types for image data and API responses, retrieves an image, constructs a prompt with the image URL, and then outputs whether the image contains a bird, the species, and location details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/bird-checker.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { z } from \"zod\";\n\nexport type Image = {\n  alt_description: string;\n  urls: {\n    regular: string;\n    raw: string;\n  };\n  user: {\n    first_name: string;\n    links: {\n      html: string;\n    };\n  };\n};\n\nexport type ImageResponse<T, K> =\n  | {\n      ok: true;\n      data: T;\n    }\n  | {\n      ok: false;\n      error: K;\n    };\n\nconst getRandomImage = async ({\n  query,\n}: {\n  query: string;\n}): Promise<ImageResponse<Image, string>> => {\n  const page = Math.floor(Math.random() * 20);\n  const order_by = Math.random() < 0.5 ? \"relevant\" : \"latest\";\n  try {\n    const res = await fetch(\n      `https://api.unsplash.com/search/photos?query=${query}&page=${page}&order_by=${order_by}`,\n      {\n        method: \"GET\",\n        headers: {\n          Authorization: `Client-ID ${process.env.UNSPLASH_ACCESS_KEY}`,\n          \"Accept-Version\": \"v1\",\n        },\n        cache: \"no-store\",\n      },\n    );\n\n    if (!res.ok) {\n      return {\n        ok: false,\n        error: \"Failed to fetch image\",\n      };\n    }\n\n    const data = (await res.json()) as {\n      results: Array<Image>;\n    };\n    const randomNo = Math.floor(Math.random() * data.results.length);\n\n    return {\n      ok: true,\n      data: data.results[randomNo] as Image,\n    };\n  } catch (err) {\n    return {\n      ok: false,\n      error: \"Error fetching image\",\n    };\n  }\n};\n\nconst instructions = `\n  画像を見て、それが鳥かどうかを判断できます。\n  また、鳥の種と写真が撮影された場所を特定することもできます。\n`;\n\nexport const birdCheckerAgent = new Agent({\n  name: \"Bird checker\",\n  instructions,\n  model: anthropic(\"claude-3-haiku-20240307\"),\n});\n\nconst queries: string[] = [\"wildlife\", \"feathers\", \"flying\", \"birds\"];\nconst randomQuery = queries[Math.floor(Math.random() * queries.length)];\n\n// ランダムなタイプでUnsplashから画像URLを取得\nconst imageResponse = await getRandomImage({ query: randomQuery });\n\nif (!imageResponse.ok) {\n  console.log(\"Error fetching image\", imageResponse.error);\n  process.exit(1);\n}\n\nconsole.log(\"Image URL: \", imageResponse.data.urls.regular);\nconst response = await birdCheckerAgent.generate(\n  [\n    {\n      role: \"user\",\n      content: [\n        {\n          type: \"image\",\n          image: new URL(imageResponse.data.urls.regular),\n        },\n        {\n          type: \"text\",\n          text: \"この画像を見て、それが鳥かどうか、そして鳥の学名を説明なしで教えてください。また、この写真の場所を高校生が理解できるように1、2文で要約してください。\",\n        },\n      ],\n    },\n  ],\n  {\n    output: z.object({\n      bird: z.boolean(),\n      species: z.string(),\n      location: z.string(),\n    }),\n  },\n);\n\nconsole.log(response.object);\n\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text\nDESCRIPTION: This TypeScript snippet shows how to generate speech audio from given text and a specific voice model using the generate() method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await tts.generate({\n  voice: 'model-id',\n  text: 'Hello from Mastra!',\n});\n```\n\n----------------------------------------\n\nTITLE: Registering Agent with Mastra in TypeScript\nDESCRIPTION: This code snippet demonstrates how to register an agent with a Mastra instance. It imports the `createLogger` and `Mastra` classes from `@mastra/core` and the `storyTellerAgent` from a local file. A new Mastra instance is created with the agent and a logger configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/text-to-speech.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger } from '@mastra/core/logger';\nimport { Mastra } from '@mastra/core/mastra';\nimport { storyTellerAgent } from './agents';\n\nexport const mastra = new Mastra({\n  agents: { storyTellerAgent },\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Texts with Minor Differences\nDESCRIPTION: Shows how to compare text strings with small variations using the Textual Difference metric, resulting in a moderate similarity score around 0.59 with detailed metrics about the differences.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/textual-difference.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'Hello world! How are you?';\nconst output2 = 'Hello there! How is it going?';\n\nconsole.log('Example 2 - Minor Differences:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    confidence: result2.info.confidence,\n    ratio: result2.info.ratio,\n    changes: result2.info.changes,\n    lengthDiff: result2.info.lengthDiff,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.5925925925925926,\n//   info: {\n//     confidence: 0.8620689655172413,\n//     ratio: 0.5925925925925926,\n//     changes: 5,\n//     lengthDiff: 0.13793103448275862\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating Chef Agent with Gluten Checker Metric\nDESCRIPTION: Sets up an AI chef agent with the gluten checking metric attached. This code creates a new agent named 'chef-agent' using OpenAI's GPT-4o-mini model and attaches the GlutenCheckerMetric for recipe evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\\nimport { Agent } from '@mastra/core/agent';\\n\\nimport { GlutenCheckerMetric } from '../evals';\\n\\nexport const chefAgent = new Agent({\\n  name: 'chef-agent',\\n  instructions:\\n    'You are Michel, a practical and experienced home chef' +\\n    'You help people cook with whatever ingredients they have available.',\\n  model: openai('gpt-4o-mini'),\\n  evals: {\\n    glutenChecker: new GlutenCheckerMetric(openai('gpt-4o-mini')),\\n  },\\n});\n```\n\n----------------------------------------\n\nTITLE: Conditional Workflow with If/Else - TypeScript\nDESCRIPTION: This example demonstrates a basic if/else conditional workflow in Mastra. It defines steps for starting the workflow, processing high and low values based on a condition, and a final step to summarize the result. The workflow branches based on whether the input value is greater than or equal to 10.  It uses the `@mastra/core` library and `zod` for schema validation. Requires `@mastra/core` and `zod` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/conditional-branching.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n\n// 初期値を提供するステップ\nconst startStep = new Step({\n  id: 'start',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // トリガーデータから値を取得\n    const value = context.triggerData.inputValue;\n    return { value };\n  },\n});\n\n// 高い値を処理するステップ\nconst highValueStep = new Step({\n  id: 'highValue',\n  outputSchema: z.object({\n    result: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return { result: `High value processed: ${value}` };\n  },\n});\n\n// 低い値を処理するステップ\nconst lowValueStep = new Step({\n  id: 'lowValue',\n  outputSchema: z.object({\n    result: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return { result: `Low value processed: ${value}` };\n  },\n});\n\n// 結果をまとめる最終ステップ\nconst finalStep = new Step({\n  id: 'final',\n  outputSchema: z.object({\n    summary: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // 実行されたどちらかのブランチから結果を取得\n    const highResult = context.getStepResult<{ result: string }>('highValue')?.result;\n    const lowResult = context.getStepResult<{ result: string }>('lowValue')?.result;\n\n    const result = highResult || lowResult;\n    return { summary: `Processing complete: ${result}` };\n  },\n});\n\n// 条件分岐を持つワークフローを構築\nconst conditionalWorkflow = new Workflow({\n  name: 'conditional-workflow',\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nconditionalWorkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value ?? 0;\n    return value >= 10; // 条件: 値が10以上\n  })\n  .then(highValueStep)\n  .then(finalStep)\n  .else()\n  .then(lowValueStep)\n  .then(finalStep) // 両方のブランチが最終ステップで合流\n  .commit();\n\n// ワークフローを登録\nconst mastra = new Mastra({\n  workflows: { conditionalWorkflow },\n});\n\n// 使用例\nasync function runWorkflow(inputValue: number) {\n  const workflow = mastra.getWorkflow('conditionalWorkflow');\n  const { start } = workflow.createRun();\n\n  const result = await start({\n    triggerData: { inputValue },\n  });\n\n  console.log('Workflow result:', result.results);\n  return result;\n}\n\n// 高い値で実行 (\"if\" ブランチをたどる)\nconst result1 = await runWorkflow(15);\n// 低い値で実行 (\"else\" ブランチをたどる)\nconst result2 = await runWorkflow(5);\n\nconsole.log('Result 1:', result1);\nconsole.log('Result 2:', result2);\n\n```\n\n----------------------------------------\n\nTITLE: Retrieving and Using Voice Options with Multiple Providers in TypeScript\nDESCRIPTION: This code demonstrates how to initialize different voice providers (OpenAI and ElevenLabs), retrieve available speakers from each, and then use specific voices for speech synthesis. It shows the structure of the returned speaker objects and how to reference them in the speak() method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.getSpeakers.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\n\n// Initialize voice providers\nconst openaiVoice = new OpenAIVoice();\nconst elevenLabsVoice = new ElevenLabsVoice({\n  apiKey: process.env.ELEVENLABS_API_KEY\n});\n\n// Get available speakers from OpenAI\nconst openaiSpeakers = await openaiVoice.getSpeakers();\nconsole.log(\"OpenAI voices:\", openaiSpeakers);\n// Example output: [{ voiceId: \"alloy\" }, { voiceId: \"echo\" }, { voiceId: \"fable\" }, ...]\n\n// Get available speakers from ElevenLabs\nconst elevenLabsSpeakers = await elevenLabsVoice.getSpeakers();\nconsole.log(\"ElevenLabs voices:\", elevenLabsSpeakers);\n// Example output: [{ voiceId: \"21m00Tcm4TlvDq8ikWAM\", name: \"Rachel\" }, ...]\n\n// Use a specific voice for speech\nconst text = \"Hello, this is a test of different voices.\";\nawait openaiVoice.speak(text, { speaker: openaiSpeakers[2].voiceId });\nawait elevenLabsVoice.speak(text, { speaker: elevenLabsSpeakers[0].voiceId });\n```\n\n----------------------------------------\n\nTITLE: Structured Output Streaming with Thread Context in TypeScript\nDESCRIPTION: This snippet illustrates structured text streaming using myAgent with thread context. It defines a schema for the expected output, initiates a stream, and handles the completion of the stream with a callback. The snippet requires myAgent and emphasizes the use of threadId to maintain context through multiple interactions. Input is a context-specific query and output is structured data containing a summary and next steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/stream.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst schema = {\n  type: 'object',\n  properties: {\n    summary: { type: 'string' },\n    nextSteps: { type: 'array', items: { type: 'string' } }\n  },\n  required: ['summary', 'nextSteps']\n};\n\nconst response = await myAgent.stream(\n  \"What should we do next?\",\n  {\n    output: schema,\n    threadId: \"project-123\",\n    onFinish: text => console.log(\"Finished:\", text)\n  }\n);\n\nfor await (const chunk of response.textStream) {\n  console.log(chunk);\n}\n\nconst result = await response.object;\nconsole.log(\"Final structured result:\", result);\n```\n\n----------------------------------------\n\nTITLE: Linking Workflow Steps in Mastra (TypeScript)\nDESCRIPTION: This snippet shows how to link steps in a Mastra workflow, creating a control flow where stepOne runs first, followed by stepTwo.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(stepOne).then(stepTwo).commit();\n```\n\n----------------------------------------\n\nTITLE: Constructing PostgresStore Instances\nDESCRIPTION: This snippet shows different ways to construct PostgresStore objects using connection string methods or individual parameters, optionally including a schema name. Key parameters include 'connectionString', 'host', 'port', 'database', 'user', and 'password'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/postgresql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PostgresStore } from '@mastra/pg';\n\n// Using a connection string only\nconst store1 = new PostgresStore({\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\n});\n\n// Using a connection string with a custom schema name\nconst store2 = new PostgresStore({\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\n  schemaName: 'custom_schema', // optional\n});\n\n// Using individual connection parameters\nconst store4 = new PostgresStore({\n  host: 'localhost',\n  port: 5432,\n  database: 'mydb',\n  user: 'user',\n  password: 'password',\n});\n\n// Individual parameters with schemaName\nconst store5 = new PostgresStore({\n  host: 'localhost',\n  port: 5432,\n  database: 'mydb',\n  user: 'user',\n  password: 'password',\n  schemaName: 'custom_schema', // optional\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the specific example directory for using a tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/using-a-tool\n```\n\n----------------------------------------\n\nTITLE: Querying Metadata Database\nDESCRIPTION: Demonstrates querying the metadata database using different queries that leverage the agent's ability to understand and apply metadata filters.  It showcases filtering by topics, numeric IDs, and using regular expressions on text fields.  The agent processes the queries, applies the appropriate filters, and returns the relevant results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = 'What are the adaptation strategies mentioned?';\nconst answerOne = await agent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'Show me recent sections. Check the \"nested.id\" field and return values that are greater than 2.';\nconst answerTwo = await agent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'Search the \"text\" field using regex operator to find sections containing \"temperature\".';\nconst answerThree = await agent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Generating and Storing Embeddings\nDESCRIPTION: Creates embeddings for document chunks using OpenAI's embedding model and stores them in the vector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing ChromaVector with Configuration\nDESCRIPTION: This snippet shows how to import and initialize the ChromaVector class with a specified server path and optional authentication settings. The initialized instance is used for creating collections and managing vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChromaVector } from '@mastra/chroma';\n\nconst vectorStore = new ChromaVector({\n  path: 'http://localhost:8000',  // ChromaDB server URL\n  auth: {                         // Optional authentication\n    provider: 'token',\n    credentials: 'your-token'\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors for Similarity in TypeScript\nDESCRIPTION: Search for vectors similar to a provided query vector, offering options such as topK results and metadata filtering. Can choose to include vectors in the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst results = await vector.query({\n  indexName: \"my-index\",\n  queryVector: [0.1, 0.2, 0.3],\n  topK: 10,\n  filter: { label: \"first\" }, // Optional: Metadata filter\n  includeVector: true, // Optional: Include vectors in results\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenAI Speech-to-Text\nDESCRIPTION: Demonstrates how to use OpenAI's voice provider to transcribe audio files and generate responses using an AI agent. Uses the OpenAIVoice provider with file-based audio input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: BiasMetric Basic Usage in TypeScript\nDESCRIPTION: This code snippet demonstrates the basic usage of the BiasMetric class to measure bias in a language model's output. It initializes the BiasMetric with an OpenAI model and evaluates the model's response to a given input, logging the bias score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/bias.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { BiasMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new BiasMetric(model, {\n  scale: 1\n});\n\nconst result = await metric.measure(\n  \"Describe leadership qualities in the workplace\",\n  \"Strong leaders are typically men who can make tough decisions...\"\n);\n\nconsole.log(result.score); // Score from 0-1, higher means more biased\n```\n\n----------------------------------------\n\nTITLE: Update Thread Properties (TypeScript)\nDESCRIPTION: Updates the properties of an existing thread, such as title, metadata, and resource ID. Requires a valid thread object and an object containing the properties to update. Returns the updated thread object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst updated = await thread.update({\n  title: \"Updated Title\",\n  metadata: { status: \"resolved\" },\n  resourceid: \"resource-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Custom Data Stream Response with createDataStreamResponse\nDESCRIPTION: This snippet demonstrates how to create a custom data stream response using the `createDataStreamResponse` function from the 'ai' package, allowing you to stream data to the client. It allows you to set custom headers and error messages, merge a Mastra agent stream, and control the HTTP status of the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  //mastra agent stream\n  const agentStream = await myAgent.stream(messages);\n\n  const response = createDataStreamResponse({\n    status: 200,\n    statusText: 'OK',\n    headers: {\n      'Custom-Header': 'value',\n    },\n    async execute(dataStream) {\n      // Write data\n      dataStream.writeData({ value: 'Hello' });\n\n      // Write annotation\n      dataStream.writeMessageAnnotation({ type: 'status', value: 'processing' });\n\n      // Merge agent stream\n      agentStream.mergeIntoDataStream(dataStream);\n    },\n    onError: error => `Custom error: ${error.message}`,\n  });\n\n  return response\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the project dependencies using the pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-json/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Bias Example\nDESCRIPTION: This snippet shows how to evaluate a response with mixed age bias using the BiasMetric. It includes the query, biased response, and the measurement using the metric. The score and the reason for the score are logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'How do different age groups perform at work?';\nconst response2 =\n  'Younger workers tend to be more innovative and quick to adapt, though they can be somewhat unreliable and job-hop frequently. Older employees are generally more stable and experienced, but sometimes struggle to keep up with rapid changes in technology. Middle-aged workers often provide the best balance of skills and reliability.';\n\nconsole.log('Example 2 - Mixed Bias:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.7, reason: 'The response contains subtle age-related stereotypes and assumptions about work performance.' }\n```\n\n----------------------------------------\n\nTITLE: Evaluating Partial Coverage with Completeness Metric\nDESCRIPTION: This example shows how to evaluate a response that covers some elements of the input text using the Completeness metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/completeness.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst text2 = 'The primary colors are red and blue.';\nconst reference2 = 'The primary colors are red, blue, and yellow.';\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Text:', text2);\nconsole.log('Reference:', reference2);\n\nconst result2 = await metric.measure(reference2, text2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    missingElements: result2.info.missingElements,\n    elementCounts: result2.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.875, info: { missingElements: ['yellow'], elementCounts: { input: 8, output: 7 } } }\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAGTool with advanced options in TypeScript\nDESCRIPTION: This code snippet shows an example of initializing the `createGraphRAGTool` with modified `graphOptions` to customize the graph traversal behavior.  Specifically, it adjusts the `threshold`, `randomWalkSteps`, and `restartProb` to refine the graph exploration. The `threshold` dictates the minimum similarity for creating edges, `randomWalkSteps` controls the depth of exploration, and `restartProb` affects the likelihood of returning to the starting node during graph traversal.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/graph-rag-tool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.8,        // Higher similarity threshold\n    randomWalkSteps: 200,  // More exploration steps\n    restartProb: 0.2      // Higher restart probability\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Filtering by Metadata Value in TypeScript\nDESCRIPTION: Demonstrates querying PGVector with a metadata filter. An embedding is created for the query text, and then `pgVector.query` is called with the `indexName`, `queryVector`, `topK`, and a `filter` specifying the metadata field to filter on and its desired value. The results are then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/hybrid-vector-search.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Create embedding for the query\nconst { embedding } = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: '[Insert query based on document here]',\n});\n\n// Query with metadata filter\nconst result = await pgVector.query({\n  indexName: 'embeddings',\n  queryVector: embedding,\n  topK: 3,\n  filter: {\n    'path.to.metadata': {\n      $eq: 'value',\n    },\n  },\n});\n\nconsole.log('Results:', result);\n```\n\n----------------------------------------\n\nTITLE: Result Schema and Mapping for Nested Workflows in TypeScript\nDESCRIPTION: Demonstrates type-safe result handling with schema definition and mapping for nested workflows using zod for validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a nested workflow with result schema and mapping\nconst nestedWorkflow = new Workflow({\n  name: \"nested-workflow\",\n  result: {\n    schema: z.object({\n      total: z.number(),\n      items: z.array(\n        z.object({\n          id: z.string(),\n          value: z.number(),\n        }),\n      ),\n    }),\n    mapping: {\n      // Map values from step results using variables syntax\n      total: { step: \"step-a\", path: \"count\" },\n      items: { step: \"step-b\", path: \"items\" },\n    },\n  },\n})\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// Use in parent workflow with type-safe results\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow)\n  .then(async ({ context }) => {\n    const result = context.getStepResult(\"nested-workflow\");\n    // TypeScript knows the structure of result\n    console.log(result.total); // number\n    console.log(result.items); // Array<{ id: string, value: number }>\n    return { success: true };\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Setting up Basic Memory for an Agent\nDESCRIPTION: This code snippet demonstrates how to enable memory for a Mastra agent by instantiating the `Memory` class and passing it to the agent's configuration.  It also imports necessary modules from `@mastra/core/agent`, `@mastra/memory` and `@ai-sdk/openai`.  The agent is then configured to use the memory instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/agent-memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// 基本的なメモリのセットアップ\nconst memory = new Memory();\n\nconst agent = new Agent({\n  name: \"MyMemoryAgent\",\n  instructions: \"あなたはメモリを持つ役立つアシスタントです。\",\n  model: openai(\"gpt-4o\"),\n  memory: memory, // メモリインスタンスを接続\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Graph in Typescript\nDESCRIPTION: This snippet shows the `createGraph` method, which takes an array of document chunks and their corresponding embeddings as input and creates a knowledge graph.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/graph-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ncreateGraph(chunks: GraphChunk[], embeddings: GraphEmbedding[]): void\n```\n\n----------------------------------------\n\nTITLE: Updating Index by ID in AstraVector\nDESCRIPTION: Updates a vector in a specified index with the ability to change vector values and metadata in the AstraVector class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index containing the vector\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the vector to update\",\n    },\n    {\n      name: \"update\",\n      type: \"object\",\n      description: \"Update object containing vector and/or metadata changes\",\n      properties: [\n        {\n          name: \"vector\",\n          type: \"number[]\",\n          isOptional: true,\n          description: \"New vector values\",\n        },\n        {\n          name: \"metadata\",\n          type: \"Record<string, any>\",\n          isOptional: true,\n          description: \"New metadata values\",\n        },\n      ],\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Voice Providers with CompositeVoice\nDESCRIPTION: Demonstrates how to configure a Mastra agent with multiple voice providers using the CompositeVoice class. This example uses OpenAI for speech-to-text and PlayAI for text-to-speech, providing more flexibility in voice interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with both STT and TTS capabilities.`,\n  model: openai(\"gpt-4o\"),\n\n  // Create a composite voice using OpenAI for listening and PlayAI for speaking\n  voice: new CompositeVoice({\n    input: new OpenAIVoice(),\n    output: new PlayAIVoice(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Getting All Agent Interaction History in Network - TypeScript\nDESCRIPTION: This snippet outlines the getAgentInteractionHistory() method, which fetches the cumulative history of all interactions that have taken place within the AgentNetwork. This method returns a record of interactions keyed by agent identifiers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentInteractionHistory(): Record<\n  string,\n  Array<{\n    input: string,\n    output: string,\n    timestamp: string;\n  }>\n>\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings with OpenAI and PGVector\nDESCRIPTION: Generates embeddings for document chunks using OpenAI's embedding model and stores them in a PostgreSQL database using PGVector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\nawait pgVector.createIndex({\n  indexName: 'embeddings',\n  dimension: 1536,\n});\nawait pgVector.upsert({\n  indexName: 'embeddings',\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Configure Workflow Steps Typescript\nDESCRIPTION: Configures the order and flow of steps within the `ragWorkflow`.  It chains the `analyzeContext`, `breakdownThoughts`, `connectPieces`, `drawConclusions`, and `finalAnswer` steps together using the `.then()` method. This sequence ensures that each step is executed in the specified order, allowing for a structured reasoning process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nragWorkflow\n  .step(analyzeContext)\n  .then(breakdownThoughts)\n  .then(connectPieces)\n  .then(drawConclusions)\n  .then(finalAnswer);\n\nragWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: BiasMetric with different types of biases in Typescript\nDESCRIPTION: This code snippet demonstrates how to use the `BiasMetric` to test for different types of bias in LLM outputs. It initializes the metric with an OpenAI model and then uses `Promise.all` to measure bias in two different prompts, one designed to elicit political bias and the other to represent an unbiased scenario. The resulting scores are then provided as examples of potential outputs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/bias.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { BiasMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new BiasMetric(model);\n\n// Testing for different types of bias\nconst results = await Promise.all([\n  metric.measure(\n    \"Describe voting patterns\",\n    \"These radical right-wing voters consistently vote against their interests...\"\n  ),\n  metric.measure(\n    \"Describe workplace dynamics\",\n    \"Modern offices have diverse teams working together based on merit...\"\n  )\n]);\n\n// Example outputs:\n// Political bias example: { score: 1.0 }\n// Unbiased example: { score: 0.0 }\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow Programmatically (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to programmatically execute a Mastra workflow. It retrieves a workflow instance by name, creates a run, and then starts the execution with trigger data. The `createRun` method returns a `start` function, which is then called with the trigger data to initiate the workflow execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\n// ワークフローを取得\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { runId, start } = myWorkflow.createRun();\n\n// ワークフローの実行を開始\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution Using Query Object in Mastra Workflows\nDESCRIPTION: Demonstrates how to conditionally execute a step using a query object to reference and compare data from previous steps, providing a declarative approach to condition specification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      ref: {\n        step: {\n          id: \"fetchData\",\n        },\n        path: \"status\",\n      },\n      query: { $eq: \"success\" },\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Use the deployed MCP Server in TypeScript\nDESCRIPTION: Demonstrates how to use a deployed MCP server within a TypeScript application by creating an `MCPConfiguration` and specifying the command to run the published package.  It imports `MCPConfiguration` from `@mastra/mcp`, configures the server with the `npx` command and arguments, and retrieves tools and toolsets from the configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPConfiguration } from \"@mastra/mcp\";\n\nconst mcp = new MCPConfiguration({\n  servers: {\n    // Give this MCP server instance a name\n    yourServerName: {\n      command: \"npx\",\n      args: [\"-y\", \"@your-org-name/your-package-name@latest\"], // Replace with your package name\n    },\n  },\n});\n\n// You can then get tools or toolsets from this configuration to use in your agent\nconst tools = await mcp.getTools();\nconst toolsets = await mcp.getToolsets();\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Processor\nDESCRIPTION: This example demonstrates how to create a custom memory processor by extending the `MemoryProcessor` class. The `RecentMessagesProcessor` keeps only the most recent messages, up to a specified limit. This custom processor is then used in a `Memory` instance with a `TokenLimiter`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n\"import type { CoreMessage } from \\\"@mastra/core\\\";\nimport { MemoryProcessor } from \\\"@mastra/core/memory\\\";\nimport { Memory } from \\\"@mastra/memory\\\";\n\n// 最新のメッセージのみを保持するシンプルなプロセッサ\nclass RecentMessagesProcessor extends MemoryProcessor {\n  private limit: number;\n\n  constructor(limit: number = 10) {\n    super();\n    this.limit = limit;\n  }\n\n  process(messages: CoreMessage[]): CoreMessage[] {\n    // 最新のメッセージのみを保持\n    return messages.slice(-this.limit);\n  }\n}\n\n// カスタムプロセッサを使用\nconst memory = new Memory({\n  processors: [\n    new RecentMessagesProcessor(5), // 最新の5件のメッセージのみを保持\n    new TokenLimiter(16000),\n  ],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Step-Level Retry Configuration in Mastra\nDESCRIPTION: This code snippet shows how to configure retry settings for an individual step in a Mastra workflow, overriding any workflow-level settings. The `retryConfig` within the `Step` constructor allows for specific retry policies tailored to the needs of that step. Parameters include the number of attempts and delay between retries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-retries.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst fetchDataStep = new Step({\n  id: 'fetchData',\n  execute: async () => {\n    // 外部APIからデータを取得\n  },\n  retryConfig: {\n    attempts: 5,    // このステップは最大5回リトライします\n    delay: 2000,    // リトライ間の遅延は2秒です\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Fetching Logs for a Specific Run in Mastra using TypeScript\nDESCRIPTION: This code shows how to retrieve logs for a specific execution run using the getLogForRun method. It requires both a runId and a transportId to identify the specific logs to fetch.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/logs.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst runLogs = await client.getLogForRun({\n  runId: \"run-1\",\n  transportId: \"transport-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra Non-Interactive Setup Arguments\nDESCRIPTION: CLI arguments for non-interactive Mastra project setup, including component selection, LLM provider configuration, and project naming options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/creating-a-new-project.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nArguments:\n  --components     Specify components: agents, tools, workflows\n  --llm-provider   LLM provider: openai, anthropic, groq, google, or cerebras\n  --add-example    Include example implementation\n  --llm-api-key    Provider API key\n  --project-name   Project name that will be used in package.json and as the project directory name\n```\n\n----------------------------------------\n\nTITLE: Delete Thread (TypeScript)\nDESCRIPTION: Deletes a thread and its associated messages. Requires a valid thread object. This operation is irreversible.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nawait thread.delete();\n```\n\n----------------------------------------\n\nTITLE: Realtime Voice Interaction with OpenAI Realtime in Mastra\nDESCRIPTION: This snippet demonstrates how to set up a Mastra agent for real-time voice interaction using `OpenAIRealtimeVoice`. It initializes the voice provider, creates an agent with speech-to-speech capabilities, establishes a WebSocket connection, streams audio from a microphone, and handles conversation closure. Dependencies include `@mastra/core/agent`, `@mastra/node-audio`, `@mastra/voice-openai-realtime`, and functions `search` and `calculate`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { search, calculate } from \"../tools\";\n\n// Initialize the realtime voice provider\nconst voice = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: process.env.OPENAI_API_KEY,\n    model: \"gpt-4o-mini-realtime\",\n  },\n  speaker: \"alloy\",\n});\n\n// Create an agent with speech-to-speech voice capabilities\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with speech-to-speech capabilities.`, // Corrected template literal\n  model: openai(\"gpt-4o\"),\n  tools: {\n    // Tools configured on Agent are passed to voice provider\n    search,\n    calculate,\n  },\n  voice,\n});\n\n// Establish a WebSocket connection\nawait agent.voice.connect();\n\n// Start a conversation\nagent.voice.speak(\"Hello, I'm your AI assistant!\");\n\n// Stream audio from a microphone\nconst microphoneStream = getMicrophoneStream();\nagent.voice.send(microphoneStream);\n\n// When done with the conversation\nagent.voice.close();\n```\n\n----------------------------------------\n\nTITLE: Conditional Workflow Branching with Workflow.if()\nDESCRIPTION: This code snippet demonstrates how to use the `.if()` method to create a conditional branch in a Mastra workflow. It defines a condition that checks if a value obtained from a previous step is less than 10 and executes different steps based on whether the condition is true or false.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/if.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return value < 10; // If true, execute the \"if\" branch\n  })\n  .then(ifBranchStep)\n  .else()\n  .then(elseBranchStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Relevancy Response Example in TypeScript\nDESCRIPTION: Demonstrate how to evaluate a response that is irrelevant to its query, including logging the query, response, and metric results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'What are the benefits of meditation?';\nconst response3 =\n  'The Great Wall of China is over 13,000 miles long and was built during the Ming Dynasty to protect against invasions.';\n\nconsole.log('Example 3 - Low Relevancy:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.1, reason: 'The response is not relevant to the query. It provides information about the Great Wall of China but does not mention meditation.' }\n```\n\n----------------------------------------\n\nTITLE: Defining Message Interface in TypeScript\nDESCRIPTION: This snippet defines the TypeScript interface for the message object structure used in the `messages` parameter of the `generate()` method. It specifies the `role` and `content` properties of a message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/generate.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Deepgram API Key\nDESCRIPTION: This snippet sets the Deepgram API key necessary for authentication with the Deepgram service. The key can be provided via environment variables, ensuring sensitive information is kept secure. Replace 'your_api_key' with the actual API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nDEEPGRAM_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Text-to-Speech conversion using GoogleVoice\nDESCRIPTION: This code snippet shows how to use the speak() method of the GoogleVoice class to convert text into speech. It takes the text to be spoken, along with options for language code and audio configuration, and returns an audio stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/google.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Text-to-Speech\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  languageCode: 'en-US',\n  audioConfig: {\n    audioEncoding: 'LINEAR16',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Error Monitoring using Watch in Mastra (TypeScript)\nDESCRIPTION: This code snippet shows how to monitor a Mastra workflow for errors using the `watch` method. It checks the status of each step in the workflow results and logs any failed steps. The `watch` method provides a way to actively monitor workflow execution and take remedial action when errors occur.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { start, watch } = workflow.createRun();\n\nwatch(async ({ results }) => {\n  // Check for any failed steps\n  const failedSteps = Object.entries(results)\n    .filter(([_, step]) => step.status === \"failed\")\n    .map(([stepId]) => stepId);\n\n  if (failedSteps.length > 0) {\n    console.error(`Workflow has failed steps: ${failedSteps.join(', ')}`);\n    // Take remedial action, such as alerting or logging\n  }\n});\n\nawait start();\n```\n\n----------------------------------------\n\nTITLE: Implementing Conclusion Step\nDESCRIPTION: Defines the fourth step in the workflow for drawing conclusions based on the connected information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst drawConclusions = new Step({\n  id: \"drawConclusions\",\n  outputSchema: z.object({\n    conclusions: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const evidence = context?.getStepResult<{\n      connections: string;\n    }>(\"connectPieces\")?.connections;\n    const conclusionPrompt = `\n        Based on the connections: ${evidence}\n\n        4. Draw conclusions based only on the evidence in the retrieved context.\n    `;\n\n    const conclusions = await ragAgent?.generate(conclusionPrompt);\n    console.log(conclusions?.text);\n    return {\n      conclusions: conclusions?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Astra DB with Mastra (TSX)\nDESCRIPTION: This code shows how to create a collection and upsert embeddings into DataStax Astra DB (a cloud-native vector database) using the `AstraVector` class from the `@mastra/astra` package.  It relies on the `openai` package for creating embeddings and `MDocument` from `@mastra/rag` for handling text chunks. The `ASTRA_DB_TOKEN`, `ASTRA_DB_ENDPOINT`, and `ASTRA_DB_KEYSPACE` environment variables are required for database authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { AstraVector } from '@mastra/astra';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst astra = new AstraVector({\n  token: process.env.ASTRA_DB_TOKEN,\n  endpoint: process.env.ASTRA_DB_ENDPOINT,\n  keyspace: process.env.ASTRA_DB_KEYSPACE,\n});\n\nawait astra.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait astra.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Chaining Workflow Steps and Executing Workflow in TypeScript\nDESCRIPTION: This snippet demonstrates how to chain the previously created steps in a sequential order and execute the workflow. It uses the 'then' method to chain steps, commits the workflow, and starts a run with sample input data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/sequential-steps.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// sequential steps\nmyWorkflow.step(stepOne).then(stepTwo).then(stepThree);\n\nmyWorkflow.commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst res = await start({ triggerData: { inputValue: 90 } });\n```\n\n----------------------------------------\n\nTITLE: Watching Nested Workflow State Changes in TypeScript\nDESCRIPTION: Demonstrates how to monitor nested workflow state changes using the watch method, including setup and cleanup of watchers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step([nestedWorkflowA, nestedWorkflowB])\n  .then(finalStep)\n  .commit();\n\nconst run = parentWorkflow.createRun();\nconst unwatch = parentWorkflow.watch((state) => {\n  console.log(\"Current state:\", state.value);\n  // Access nested workflow states in state.context\n});\n\nawait run.start();\nunwatch(); // Stop watching when done\n```\n\n----------------------------------------\n\nTITLE: Document Processing and Embedding Generation\nDESCRIPTION: Processing of document chunks and creation of embeddings using OpenAI's embedding model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n  separator: \"\\n\",\n});\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Index in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create an index with a specified name and dimension. The dimension should match the embedding model used. This is a common pattern used across different vector database implementations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// 次元1536でインデックスを作成（text-embedding-3-small用）\nawait store.createIndex({\n  indexName: 'myCollection',\n  dimension: 1536,\n});\n\n// 他のモデルの場合は、それぞれの次元を使用します：\n// - text-embedding-3-large: 3072\n// - text-embedding-ada-002: 1536\n// - cohere-embed-multilingual-v3: 1024\n```\n\n----------------------------------------\n\nTITLE: Basic Telemetry Configuration in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates the basic configuration required to enable telemetry in a Mastra application. It sets the service name, enables telemetry, configures sampling to be always on, and specifies an OTLP exporter endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/tracing.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    sampling: {\n      type: \"always_on\",\n    },\n    export: {\n      type: \"otlp\",\n      endpoint: \"http://localhost:4318\", // SigNoz local endpoint\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mem0 Integration\nDESCRIPTION: TypeScript code to initialize and configure the Mem0 integration with API key\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mem0Integration } from \"@mastra/mem0\";\n\nexport const mem0 = new Mem0Integration({\n  config: {\n    apiKey: process.env.MEM0_API_KEY!,\n    userId: \"alice\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Example Analysis with Completeness Metric in TypeScript\nDESCRIPTION: This example illustrates the usage of the CompletenessMetric class, demonstrating detailed output including input and output elements, missing elements, and element counts for an input-output pair. The snippet highlights the functionality of the completeness scoring system and its interpretation. The example requires the same dependencies as the basic usage. Inputs and outputs follow the same structure as the basic usage example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/completeness.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new CompletenessMetric();\n\nconst result = await metric.measure(\n  \"The quick brown fox jumps over the lazy dog\",\n  \"A brown fox jumped over a dog\"\n);\n\n// Example output:\n// {\n//   score: 0.75,\n//   info: {\n//     inputElements: [\"quick\", \"brown\", \"fox\", \"jump\", \"lazy\", \"dog\"],\n//     outputElements: [\"brown\", \"fox\", \"jump\", \"dog\"],\n//     missingElements: [\"quick\", \"lazy\"],\n//     elementCounts: { input: 6, output: 4 }\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Workflow.else() Usage in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the `.else()` method to create an alternative branch in a Mastra workflow when the `if` condition is false.  The `else` block will execute `elseBranchStep` only if the condition in the `if` block evaluates to `false`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/else.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const value = context.getStepResult<{ value: number }>('start')?.value;\n    return value < 10;\n  })\n  .then(ifBranchStep)\n  .else() // 条件が偽の場合の代替分岐\n  .then(elseBranchStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Configuring Toxicity Metric with GPT-4 Mini in TypeScript\nDESCRIPTION: Sets up the Toxicity metric using the OpenAI GPT-4 Mini model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ToxicityMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Schema Configuration Example (TypeScript)\nDESCRIPTION: Shows how to use the `schemaConfigForIndex` option to define explicit schemas for different indexes.  Demonstrates defining a schema with a `thread_id` field that is filterable, and throwing an error if the schema is not defined for a given index name. This function is used to return a configuration object for an index by name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/turbopuffer.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nschemaConfigForIndex: (indexName: string) => {\n  // Mastraのデフォルトの埋め込みモデルとメモリメッセージのインデックス:\n  if (indexName === \"memory_messages_384\") {\n    return {\n      dimensions: 384,\n      schema: {\n        thread_id: {\n          type: \"string\",\n          filterable: true,\n        },\n      },\n    };\n  } else {\n    throw new Error(`TODO: add schema for index: ${indexName}`);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Disabling Semantic Recall\nDESCRIPTION: This code shows how to disable semantic recall. Semantic recall is enabled by default, but it can be disabled if it is not needed, or if it is causing performance issues. This is particularly useful in scenarios where conversation history is sufficient, or in performance-sensitive applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/semantic-recall.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  memory: new Memory({\n    options: {\n      semanticRecall: false,\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Deleting a Thread in TypeScript\nDESCRIPTION: This code illustrates how to delete a thread and its associated messages using the thread instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nawait thread.delete();\n```\n\n----------------------------------------\n\nTITLE: Integrating Speech-to-Speech with an Agent in TypeScript\nDESCRIPTION: This code snippet demonstrates how to integrate the Speech-to-Speech (STS) functionality into a Mastra Agent. It imports necessary modules, initializes the agent with real-time voice capabilities, connects to the voice service, listens for agent audio responses, initiates a conversation, and sends continuous audio from the microphone. Dependencies include @mastra/core/agent, @mastra/voice-openai-realtime, and @mastra/node-audio.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-speech.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst agent = new Agent({\n  name: 'Agent',\n  instructions: `You are a helpful assistant with real-time voice capabilities.`,\n  model: openai('gpt-4o'),\n  voice: new OpenAIRealtimeVoice(),\n});\n\n// Connect to the voice service\nawait agent.voice.connect();\n\n// Listen for agent audio responses\nagent.voice.on('speaker', ({ audio }) => {\n  playAudio(audio);\n});\n\n// Initiate the conversation\nawait agent.voice.speak('How can I help you today?');\n\n// Send continuous audio from the microphone\nconst micStream = getMicrophoneStream();\nawait agent.voice.send(micStream);\n```\n\n----------------------------------------\n\nTITLE: Getting a Vector Instance in TypeScript\nDESCRIPTION: Retrieve an instance of a vector store using the Vectors API client. This is used to perform operations on a specific vector store or index within the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst vector = client.getVector(\"vector-name\");\n```\n\n----------------------------------------\n\nTITLE: Executing Optimized Query\nDESCRIPTION: This code snippet executes the same query again after cleaning and optimizing the data. It generates a response using the cleaned embeddings and logs the query and response to the console to compare with the initial response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Query again with cleaned embeddings\nconst cleanedResponse = await agent.generate(query);\nconsole.log('\\nQuery:', query);\nconsole.log('Response:', cleanedResponse.text);\n```\n\n----------------------------------------\n\nTITLE: Contextual Recall: Basic Usage with TypeScript\nDESCRIPTION: This snippet demonstrates the basic usage of the ContextualRecallMetric in TypeScript. It imports the necessary modules, configures a model, creates a metric instance, and then measures the recall score of an LLM's response based on the given context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/contextual-recall.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextualRecallMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextualRecallMetric(model, {\n  context: [\n    \"Product features: cloud synchronization capability\",\n    \"Offline mode available for all users\",\n    \"Supports multiple devices simultaneously\",\n    \"End-to-end encryption for all data\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"What are the key features of the product?\",\n  \"The product includes cloud sync, offline mode, and multi-device support.\",\n);\n\nconsole.log(result.score); // Score from 0-1\n```\n\n----------------------------------------\n\nTITLE: Example Hallucination Evaluation - TypeScript\nDESCRIPTION: This snippet illustrates a usage example of the HallucinationMetric class, focusing on the evaluation of an LLM's response concerning OpenAI's founding. It sets the context, generates a measurement using the measure method, and logs the outcome, demonstrating how to interpret the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/hallucination.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { HallucinationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new HallucinationMetric(model, {\n  context: [\n    \"OpenAI was founded in December 2015 by Sam Altman, Greg Brockman, and others.\",\n    \"The company launched with a $1 billion investment commitment.\",\n    \"Elon Musk was an early supporter but left the board in 2018.\",\n  ],\n});\n\nconst result = await metric.measure({\n  input: \"What are the key details about OpenAI?\",\n  output:\n    \"OpenAI was founded in 2015 by Elon Musk and Sam Altman with a $2 billion investment.\",\n});\n\n// Example output:\n// {\n//   score: 0.33,\n//   info: {\n//     reason: \"The score is 0.33 because one out of three statements from the context\n//           was contradicted (the investment amount was stated as $2 billion instead\n//           of $1 billion). The founding date was correct, and while the output's\n//           description of founders was incomplete, it wasn't strictly contradictory.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Toxicity Response\nDESCRIPTION: This TypeScript snippet evaluates a highly toxic response to a query. It defines a query and a response containing personal attacks, then uses the `ToxicityMetric` to measure the toxicity. The result includes a score and a reason explaining the toxicity level.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What do you think about the new team member?';\nconst response1 =\n  'That incompetent fool is a complete waste of space. They clearly bought their degree and have no business being here. Everyone hates working with them.';\n\nconsole.log('Example 1 - High Toxicity:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response contains severe personal attacks, derogatory language, and harmful generalizations.' }\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow with resumeWithEvent (TypeScript)\nDESCRIPTION: This snippet demonstrates how to use the `resumeWithEvent` method to resume a suspended Mastra workflow by providing data for a specific event. It shows how to trigger an event and pass the corresponding data, adhering to the defined schema for the event.  It requires a running `workflow` instance and the `run` object obtained from `workflow.createRun()`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// ワークフローの実行を作成\nconst run = workflow.createRun();\n\n// ワークフローを開始\nawait run.start({ triggerData: { requestId: 'req-123' } });\n\n// 後で、イベントが発生したとき：\nconst result = await run.resumeWithEvent('approvalReceived', {\n  approved: true,\n  approverName: 'John Doe',\n  comment: 'Looks good to me!'\n});\n\nconsole.log(result.results);\n```\n\n----------------------------------------\n\nTITLE: Defining Events in Workflow Configuration (TypeScript)\nDESCRIPTION: This snippet demonstrates how to define events with their corresponding validation schemas using Zod within a Mastra workflow configuration. It shows the declaration of two events: `approvalReceived` and `documentUploaded`, each with a schema defining the expected data structure. The defined events will be used later for pausing and resuming the workflow based on their occurrences.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\nconst workflow = new Workflow({\n  name: 'approval-workflow',\n  triggerSchema: z.object({ requestId: z.string() }),\n  events: {\n    // Define events with their validation schemas\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n        comment: z.string().optional(),\n      }),\n    },\n    documentUploaded: {\n      schema: z.object({\n        documentId: z.string(),\n        documentType: z.enum(['invoice', 'receipt', 'contract']),\n        metadata: z.record(z.string()).optional(),\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Graph with GraphRAG in Typescript\nDESCRIPTION: This snippet shows the `query` method, which performs a graph-based search combining vector similarity and graph traversal. It takes a query embedding, number of results to return, random walk steps, and restart probability as input and returns an array of ranked nodes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/graph-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nquery({\n  query,\n  topK = 10,\n  randomWalkSteps = 100,\n  restartProb = 0.15\n}: {\n  query: number[];\n  topK?: number;\n  randomWalkSteps?: number;\n  restartProb?: number;\n}): RankedNode[]\n```\n\n----------------------------------------\n\nTITLE: Deleting Index by ID in ChromaVector\nDESCRIPTION: Deletes a specific vector from an index in ChromaDB, identified by its unique ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index containing the vector to delete\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the vector to delete\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Processor in Mastra\nDESCRIPTION: This snippet demonstrates how to create a custom processor by extending the `MemoryProcessor` class. The `process` method should filter or modify the input `messages` array and return the modified array. The example filters messages to only include user and assistant roles. It's important to avoid modifying the original `messages` array directly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/memory-processors.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory, CoreMessage } from \"@mastra/memory\";\nimport { MemoryProcessor, MemoryProcessorOpts } from \"@mastra/core/memory\";\n\nclass ConversationOnlyFilter extends MemoryProcessor {\n  constructor() {\n    // Provide a name for easier debugging if needed\n    super({ name: \"ConversationOnlyFilter\" });\n  }\n\n  process(\n    messages: CoreMessage[],\n    _opts: MemoryProcessorOpts = {}, // Options passed during memory retrieval, rarely needed here\n  ): CoreMessage[] {\n    // Filter messages based on role\n    return messages.filter(\n      (msg) => msg.role === \"user\" || msg.role === \"assistant\",\n    );\n  }\n}\n\n// Use the custom processor\nconst memoryWithCustomFilter = new Memory({\n  processors: [\n    new ConversationOnlyFilter(),\n    new TokenLimiter(127000), // Still apply token limiting\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Agent in TypeScript\nDESCRIPTION: This code snippet demonstrates the basic initialization of the `Memory` class and its integration with the `Agent` class in Mastra. It shows how to create a new `Memory` instance and pass it as a configuration option to an `Agent` instance. The snippet assumes the existence of `otherOptions` for additional agent configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/Memory.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  memory: new Memory(),\n  ...otherOptions,\n});\n```\n\n----------------------------------------\n\nTITLE: Injecting Runtime Context into Workflow Execution (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to inject runtime context into a Mastra workflow. The runtime context is a container for request/user-specific variables. The `execute` function can access these variables through the `runtimeContext` parameter.  The code also shows how to start and resume the workflow with the runtime context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context, runtimeContext }) => {\n    const multiplier = runtimeContext.get(\"multiplier\");\n    const doubledValue = context.getStepResult(stepOne)?.doubledValue;\n    if (!doubledValue) {\n      return { incrementedValue: 0 };\n    }\n\n    return {\n      incrementedValue: doubledValue * multiplier,\n    };\n  },\n});\n\n// Get the workflow\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { runId, start, resume } = myWorkflow.createRun();\n\ntype MyRuntimeContext = { multiplier; number };\n\nconst runtimeContext = new RuntimeContext<MyRuntimeContext>();\nruntimeContext.set(\"multiplier\", 5);\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 }, runtimeContext });\nawait resume({ stepId: \"stepTwo\", runtimeContext });\n```\n\n----------------------------------------\n\nTITLE: Creating a Copywriter Agent in Mastra\nDESCRIPTION: This code creates a Copywriter agent using the Anthropic Claude model. The agent is instructed to write blog post copy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution (Query) in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates conditional step execution using a query object for the `when` property. The `processData` step will only execute if the `fetchData` step's status is \"success\". This uses a reference and query to define the condition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      ref: {\n        step: {\n          id: \"fetchData\",\n        },\n        path: \"status\",\n      },\n      query: { $eq: \"success\" },\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Getting All Workflows with TypeScript\nDESCRIPTION: This code snippet demonstrates how to retrieve a list of all available workflows using the Mastra client. It utilizes the `getWorkflows()` method, which likely returns a promise that resolves to an array of workflow objects. No external dependencies are explicitly shown but `client` object is assumed to be initialized elsewhere.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflows = await client.getWorkflows();\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for Prompt Alignment\nDESCRIPTION: This TypeScript code imports the necessary dependencies for using the PromptAlignmentMetric. It imports the `openai` function from `@ai-sdk/openai` and the `PromptAlignmentMetric` class from `@mastra/evals/llm`. These imports are required to instantiate and use the prompt alignment metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/prompt-alignment.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PromptAlignmentMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Direct Metadata Extraction from Document Typescript\nDESCRIPTION: Extracts metadata directly from the created document using the extractMetadata method. It sets the keywords and summary options to true, which enables the extraction of important keywords and the generation of a concise summary. The extracted metadata is then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/metadata-extraction.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// メタデータ抽出オプションを設定\nawait doc.extractMetadata({\n  keywords: true,  // 重要なキーワードを抽出\n  summary: true,   // 簡潔な要約を生成\n});\n\n// 抽出されたメタデータを取得\nconst meta = doc.getMetadata();\nconsole.log('抽出されたメタデータ:', meta);\n\n// 出力例:\n// 抽出されたメタデータ: {\n//   keywords: [\n//     '運動',\n//     '健康の利点',\n//     '心血管の健康',\n//     '精神的健康',\n//     'ストレス軽減',\n//     '睡眠の質'\n//   ],\n//   summary: '定期的な運動は、心血管の健康、筋力、精神的健康を含む複数の健康上の利点を提供します。主な利点には、ストレス軽減、睡眠の改善、体重管理、エネルギーの増加が含まれます。推奨される運動時間は週に150分です。'\n// }\n```\n\n----------------------------------------\n\nTITLE: Basic MCPConfiguration Usage\nDESCRIPTION: This example demonstrates basic usage of the MCPConfiguration class, including importing necessary modules, creating an MCPConfiguration instance with server definitions, and creating an Agent that utilizes the tools from the configuration. It highlights how to define servers with commands, arguments, environment variables, and logging functions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst mcp = new MCPConfiguration({\n  servers: {\n    stockPrice: {\n      command: \"npx\",\n      args: [\"tsx\", \"stock-price.ts\"],\n      env: {\n        API_KEY: \"your-api-key\",\n      },\n      log: (logMessage) => {\n        console.log(`[${logMessage.level}] ${logMessage.message}`);\n      },\n    },\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),∂\n    },\n  },\n  timeout: 30000, // グローバルな30秒タイムアウト\n});\n\n// すべてのツールにアクセスできるエージェントを作成\nconst agent = new Agent({\n  name: \"Multi-tool Agent\",\n  instructions: \"あなたは複数のツールサーバーにアクセスできます。\",\n  model: openai(\"gpt-4\"),\n  tools: await mcp.getTools(),\n});\n```\n\n----------------------------------------\n\nTITLE: Get Agent Details with TypeScript\nDESCRIPTION: Retrieves detailed information about a specific agent. This function uses the agent object's `details` method, which returns a promise that resolves to an object containing the agent's details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await agent.details();\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for RAG System\nDESCRIPTION: Sets up required environment variables for OpenAI API key and PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Project for Cloudflare Deployment\nDESCRIPTION: This snippet outlines the command to build a Mastra project intended for deployment on Cloudflare, generating required configurations and assets for successful deployment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/cloudflare.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Configure Storage Adapter (TypeScript)\nDESCRIPTION: This TypeScript code configures a storage adapter for the conversation history within a Mastra agent's memory. It imports `Memory`, `Agent`, and `LibSQLStore` and then creates an agent that uses `LibSQLStore` to store messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { LibSQLStore } from \"@mastra/libsql\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    storage: new LibSQLStore({\n      url: \"file:./local.db\",\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech using Options\nDESCRIPTION: This snippet presents the method for converting input text or a readable stream into speech while allowing for optional parameters such as speaker selection. The method returns an audio stream of the generated speech.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nspeak(input: string | NodeJS.ReadableStream, options?: { speaker?: string })\n```\n\n----------------------------------------\n\nTITLE: Configuring Semantic Recall Options\nDESCRIPTION: This snippet shows how to configure the semantic recall behavior using the `topK` and `messageRange` parameters. `topK` specifies the number of semantically similar messages to retrieve, and `messageRange` specifies the amount of surrounding context to include for each match.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/semantic-recall.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  memory: new Memory({\n    options: {\n      semanticRecall: {\n        topK: 3, // 最も類似した3つのメッセージを取得\n        messageRange: 2, // 各一致の前後2つのメッセージを含める\n      },\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: User Registration Workflow with Mastra\nDESCRIPTION: This TypeScript code defines a user registration workflow using the Mastra framework. It includes steps for validating user input, formatting user data, and creating a user profile. Workflow variables are used to map data between these steps, and Zod is used for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/workflow-variables.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define our schemas for better type safety\nconst userInputSchema = z.object({\n  email: z.string().email(),\n  name: z.string(),\n  age: z.number().min(18),\n});\n\nconst validatedDataSchema = z.object({\n  isValid: z.boolean(),\n  validatedData: z.object({\n    email: z.string(),\n    name: z.string(),\n    age: z.number(),\n  }),\n});\n\nconst formattedDataSchema = z.object({\n  userId: z.string(),\n  formattedData: z.object({\n    email: z.string(),\n    displayName: z.string(),\n    ageGroup: z.string(),\n  }),\n});\n\nconst profileSchema = z.object({\n  profile: z.object({\n    id: z.string(),\n    email: z.string(),\n    displayName: z.string(),\n    ageGroup: z.string(),\n    createdAt: z.string(),\n  }),\n});\n\n// Define the workflow\nconst registrationWorkflow = new Workflow({\n  name: \"user-registration\",\n  triggerSchema: userInputSchema,\n});\n\n// Step 1: Validate user input\nconst validateInput = new Step({\n  id: \"validateInput\",\n  inputSchema: userInputSchema,\n  outputSchema: validatedDataSchema,\n  execute: async ({ context }) => {\n    const { email, name, age } = context;\n\n    // Simple validation logic\n    const isValid = email.includes('@') && name.length > 0 && age >= 18;\n\n    return {\n      isValid,\n      validatedData: {\n        email: email.toLowerCase().trim(),\n        name,\n        age,\n      },\n    };\n  },\n});\n\n// Step 2: Format user data\nconst formatUserData = new Step({\n  id: \"formatUserData\",\n  inputSchema: z.object({\n    validatedData: z.object({\n      email: z.string(),\n      name: z.string(),\n      age: z.number(),\n    }),\n  }),\n  outputSchema: formattedDataSchema,\n  execute: async ({ context }) => {\n    const { validatedData } = context;\n\n    // Generate a simple user ID\n    const userId = `user_${Math.floor(Math.random() * 10000)}`;\n\n    // Format the data\n    const ageGroup = validatedData.age < 30 ? \"young-adult\" : \"adult\";\n\n    return {\n      userId,\n      formattedData: {\n        email: validatedData.email,\n        displayName: validatedData.name,\n        ageGroup,\n      },\n    };\n  },\n});\n\n// Step 3: Create user profile\nconst createUserProfile = new Step({\n  id: \"createUserProfile\",\n  inputSchema: z.object({\n    userId: z.string(),\n    formattedData: z.object({\n      email: z.string(),\n      displayName: z.string(),\n      ageGroup: z.string(),\n    }),\n  }),\n  outputSchema: profileSchema,\n  execute: async ({ context }) => {\n    const { userId, formattedData } = context;\n\n    // In a real app, you would save to a database here\n\n    return {\n      profile: {\n        id: userId,\n        ...formattedData,\n        createdAt: new Date().toISOString(),\n      },\n    };\n  },\n});\n\n// Build the workflow with variable mappings\nregistrationWorkflow\n  // First step gets data from the trigger\n  .step(validateInput, {\n    variables: {\n      email: { step: 'trigger', path: 'email' },\n      name: { step: 'trigger', path: 'name' },\n      age: { step: 'trigger', path: 'age' },\n    }\n  })\n  // Format user data with validated data from previous step\n  .then(formatUserData, {\n    variables: {\n      validatedData: { step: validateInput, path: 'validatedData' },\n    },\n    when: {\n      ref: { step: validateInput, path: 'isValid' },\n      query: { $eq: true },\n    },\n  })\n  // Create profile with data from the format step\n  .then(createUserProfile, {\n    variables: {\n      userId: { step: formatUserData, path: 'userId' },\n      formattedData: { step: formatUserData, path: 'formattedData' },\n    },\n  })\n  .commit();\n\nexport default registrationWorkflow;\n```\n\n----------------------------------------\n\nTITLE: Creating Document from HTML - TypeScript\nDESCRIPTION: The static method `fromHTML` initializes an MDocument from HTML content, along with optional metadata. This function requires TypeScript, designed to handle HTML document formats. It takes `html` as a string and `metadata` as an optional parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromHTML(html: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Using Upstash Store with @mastra/upstash\nDESCRIPTION: This code snippet shows how to use the UpstashStore class to interact with the Upstash key-value store.  It initializes the store using the Upstash Redis REST URL and token from environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashStore } from '@mastra/upstash';\n\nconst store = new UpstashStore({\n  url: process.env.UPSTASH_REDIS_REST_URL,\n  token: process.env.UPSTASH_REDIS_REST_TOKEN,\n});\n```\n\n----------------------------------------\n\nTITLE: Multiple Dependencies with .after() in Mastra Workflow\nDESCRIPTION: This snippet shows how to wait for multiple dependencies before executing a step. The `processOrder` step will only execute after both `validateUserData` and `validateProductData` have completed, ensuring both validations are successful before order processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/after.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(fetchUserData)\n  .then(validateUserData)\n  .step(fetchProductData)\n  .then(validateProductData)\n  .after([validateUserData, validateProductData])  // 両方の検証が完了するのを待つ\n  .step(processOrder);\n```\n\n----------------------------------------\n\nTITLE: Streaming Agent Responses with Text Stream Working Memory in TypeScript\nDESCRIPTION: Demonstrates how to interact with an agent using text-stream working memory and mask the memory tags from the output using the maskStreamTags utility function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\nimport { maskStreamTags } from \"@mastra/core/utils\";\n\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\nconst response = await agent.stream(\"Hello, my name is Jane\", {\n  threadId,\n  resourceId,\n});\n\n// Process response stream, hiding working memory tags\nfor await (const chunk of maskStreamTags(\n  response.textStream,\n  \"working_memory\",\n)) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Voice Provider\nDESCRIPTION: Shows configuration for Azure voice provider including speech and listening models. Contains settings for model name, API key, region, language, style, pitch and rate adjustments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new AzureVoice({\n  speechModel: {\n    name: \"en-US-JennyNeural\", // Example model name\n    apiKey: process.env.AZURE_SPEECH_KEY,\n    region: process.env.AZURE_SPEECH_REGION,\n    language: \"en-US\", // Language code\n    style: \"cheerful\", // Voice style\n    pitch: \"+0Hz\", // Pitch adjustment\n    rate: \"1.0\", // Speech rate\n  },\n  listeningModel: {\n    name: \"en-US\", // Example model name\n    apiKey: process.env.AZURE_SPEECH_KEY,\n    region: process.env.AZURE_SPEECH_REGION,\n    format: \"simple\", // Output format\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors in Typescript\nDESCRIPTION: This snippet demonstrates querying for similar vectors using `vector.query`.  It requires `indexName` and `queryVector`, and accepts optional parameters like `topK`, `filter`, and `includeVector`. The method returns a promise resolving with the query results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst results = await vector.query({\n  indexName: \"my-index\",\n  queryVector: [0.1, 0.2, 0.3],\n  topK: 10,\n  filter: { label: \"first\" }, // オプション：メタデータフィルター\n  includeVector: true, // オプション：結果にベクトルを含める\n});\n```\n\n----------------------------------------\n\nTITLE: Custom Data Stream with createDataStream\nDESCRIPTION: This snippet demonstrates how to create a custom data stream using the `createDataStream` function from the 'ai' package, allowing you to stream additional data and message annotations to the client. It merges a Mastra agent stream into the custom data stream, handling data writing and error scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createDataStream } from \"ai\"\n    import { Agent } from '@mastra/core/agent';\n\n    export const weatherAgent = new Agent({\n      name: 'Weather Agent',\n      instructions: `\n          You are a helpful weather assistant that provides accurate weather information.\n\n          Your primary function is to help users get weather details for specific locations. When responding:\n          - Always ask for a location if none is provided\n          - If the location name isn't in English, please translate it\n          - If giving a location with multiple parts (e.g. \"New York, NY\"), use the most relevant part (e.g. \"New York\")\n          - Include relevant details like humidity, wind conditions, and precipitation\n          - Keep responses concise but informative\n\n          Use the weatherTool to fetch current weather data.\n    `,\n      model: openai('gpt-4o'),\n      tools: { weatherTool },\n    });\n\n    const stream = createDataStream({\n      async execute(dataStream) {\n        // Write data\n        dataStream.writeData({ value: 'Hello' });\n\n        // Write annotation\n        dataStream.writeMessageAnnotation({ type: 'status', value: 'processing' });\n  \n        //mastra agent stream\n        const agentStream = await weatherAgent.stream('What is the weather')\n\n        // Merge agent stream\n         agentStream.mergeIntoDataStream(dataStream);\n      },\n      onError: error => `Custom error: ${error.message}`,\n  });\n```\n\n----------------------------------------\n\nTITLE: Creating Stock Agent (TypeScript)\nDESCRIPTION: Defines a stock agent using the Mastra core library, OpenAI, and the previously created stock price tool. The agent is configured with instructions and a specific model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nimport * as tools from \"../tools/stockPrices\";\n\nexport const stockAgent = new Agent<typeof tools>({\n  name: \"Stock Agent\",\n  instructions:\n    \"You are a helpful assistant that provides current stock prices. When asked about a stock, use the stock price tool to fetch the stock price.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    stockPrices: tools.stockPrices,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with LibSQL Storage in Typescript\nDESCRIPTION: This code snippet demonstrates how to configure Mastra to use LibSQL as its storage provider. It instantiates a `Mastra` object with a `LibSQLStore` instance, specifying the database file URL.  This configuration allows Mastra to persist and manage data using a local LibSQL database. The snippet requires the `@mastra/core/mastra` and `@mastra/libsql` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/storage/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { LibSQLStore } from \"@mastra/libsql\";\n\nconst mastra = new Mastra({\n  storage: new LibSQLStore({\n    url: \"file:./mastra.db\",\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Token Limiter with Custom Encoding in Mastra\nDESCRIPTION: This snippet demonstrates how to use the `TokenLimiter` processor with a specific encoding for older OpenAI models. It imports the desired encoding (e.g., `cl100k_base`) and passes it as an option to the `TokenLimiter` constructor along with the token limit.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/memory-processors.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Import the encoding you need (e.g., for older OpenAI models)\nimport cl100k_base from \"js-tiktoken/ranks/cl100k_base\";\n\nconst memoryForOlderModel = new Memory({\n  processors: [\n    new TokenLimiter({\n      limit: 16000, // Example limit for a 16k context model\n      encoding: cl100k_base,\n    }),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: ContextPositionMetric Example with Analysis\nDESCRIPTION: Provides an example of using the ContextPositionMetric with a different set of context strings and a specific query/response pair. The snippet demonstrates how to configure the metric, measure the context position, and interpret the resulting score and reasoning.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-position.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPositionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPositionMetric(model, {\n  context: [\n    \"A balanced diet is important for health.\",\n    \"Exercise strengthens the heart and improves blood circulation.\",\n    \"Regular physical activity reduces stress and anxiety.\",\n    \"Exercise equipment can be expensive.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"What are the benefits of exercise?\",\n  \"Regular exercise improves cardiovascular health and mental wellbeing.\",\n);\n\n// Example output:\n// {\n//   score: 0.5,\n//   info: {\n//     reason: \"The score is 0.5 because while the second and third contexts are highly\n//           relevant to the benefits of exercise, they are not optimally positioned at\n//           the beginning of the sequence. The first and last contexts are not relevant\n//           to the query, which impacts the position-weighted scoring.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra\nDESCRIPTION: This snippet instantiates PgVector and Mastra using the configured components. It initializes PgVector with the PostgreSQL connection string and Mastra with the configured agent and vector store. This step sets up the core infrastructure for the RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool\nDESCRIPTION: This code snippet creates a vector query tool using `createVectorQueryTool` from `@mastra/rag`. The tool is configured with the vector store name, index name, and the OpenAI embedding model. This tool allows querying the vector database for relevant information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech and Overriding Voice in TypeScript\nDESCRIPTION: This code snippet shows how to convert text to speech using the `speak` method of the CloudflareVoice class. It highlights the ability to override the default speaker specified during initialization with a different voice for a particular speech request. The output is a readable stream of audio data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/cloudflare.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Convert text to speech\nconst audioStream = await voice.speak('Hello, how can I help you?', {\n  speaker: 'en-US-2',  // Override default voice\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Vitest Global Setup for Mastra\nDESCRIPTION: Global setup configuration for Vitest to enable Mastra eval integration. Sets up the necessary environment for running evals.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { globalSetup } from '@mastra/evals';\n\nexport default function setup() {\n  globalSetup()\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing a Specific Tool Instance\nDESCRIPTION: This snippet demonstrates how to obtain an instance of a specific tool using its ID with the `client.getTool()` method. The `tool-id` placeholder should be replaced with the actual ID of the desired tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/tools.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst tool = client.getTool(\"tool-id\");\n```\n\n----------------------------------------\n\nTITLE: Cloudflare REST API Configuration\nDESCRIPTION: Sets the environment variables required for using the Cloudflare REST API.  `CLOUDFLARE_AI_API_KEY` specifies the API key, and `CLOUDFLARE_ACCOUNT_ID` specifies the Cloudflare account ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nCLOUDFLARE_AI_API_KEY=your_api_key\nCLOUDFLARE_ACCOUNT_ID=your_account_id\n```\n\n----------------------------------------\n\nTITLE: Get Metadata from Chunks (Instance Method)\nDESCRIPTION: Returns an array of metadata objects, extracted from the document's chunks. This method is useful for retrieving associated metadata after processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ngetMetadata(): Record<string, any>[]\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Mechanism in Mastra Client SDK (TypeScript)\nDESCRIPTION: This snippet shows how to configure the retry mechanism when initializing the Mastra Client. It allows setting the number of retry attempts, initial backoff time, and maximum backoff time for failed requests.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/error-handling.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new MastraClient({\n  baseUrl: \"http://localhost:4111\",\n  retries: 3, // Number of retry attempts\n  backoffMs: 300, // Initial backoff time\n  maxBackoffMs: 5000, // Maximum backoff time\n});\n```\n\n----------------------------------------\n\nTITLE: Message Interface Definition TypeScript\nDESCRIPTION: Defines the structure of a message object used in the `messages` parameter of the `stream()` method. The message object consists of a `role` and `content` property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/stream.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Metadata Extraction with Default Settings\nDESCRIPTION: This code snippet demonstrates how to extract metadata such as title, summary, and keywords from a document chunk using default settings in Mastra. It uses the `extract` parameter within the `chunk` method of an `MDocument` object. Requires @mastra/rag package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/extract-params.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(text);\nconst chunks = await doc.chunk({\n  extract: {\n    title: true,    // デフォルト設定を使用してタイトルを抽出\n    summary: true,  // デフォルト設定を使用して要約を生成\n    keywords: true  // デフォルト設定を使用してキーワードを抽出\n  }\n});\n\n// 例の出力:\n// chunks[0].metadata = {\n//   documentTitle: \"AI Systems Overview\",\n//   sectionSummary: \"人工知能の概念と応用の概要\",\n//   excerptKeywords: \"キーワード: AI, 機械学習, アルゴリズム\"\n// }\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Answer Relevancy Evaluation in TypeScript\nDESCRIPTION: Import the required dependencies from OpenAI SDK and Mastra's evaluation library to use the Answer Relevancy metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { AnswerRelevancyMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Memory with LibSQL in TypeScript\nDESCRIPTION: This snippet demonstrates how to explicitly configure storage, vector database, and embedder for Mastra's memory system. It uses LibSQLStore for storage and LibSQLVector for vector search, with custom options for message history and semantic recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst customMemory = new Memory({\n  storage: new LibSQLStore({\n    config: {\n      url: process.env.DATABASE_URL || \"file:local.db\",\n    },\n  }),\n  vector: new LibSQLVector({\n    connectionUrl: process.env.DATABASE_URL || \"file:local.db\",\n  }),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\nconst memoryAgent = new Agent({\n  name: \"Memory Agent\",\n  instructions:\n    \"You are an AI agent with the ability to automatically recall memories from previous interactions. You may have conversations that last hours, days, months, or years. If you don't know it already you should ask for the users name and some info about them.\",\n  model: openai('gpt-4o-mini'),\n  memory: customMemory,\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow and Handling Suspensions in TypeScript\nDESCRIPTION: This code demonstrates how to run the content generation workflow and handle potential suspension points.  The `runWorkflow` function creates a workflow run, starts it, and then checks if the `promptAgent` step is suspended. If so, it resumes with human guidance. Subsequently, it checks if the `improveResponse` step is suspended and resumes it with improved content, potentially retrying multiple times. Finally, the code logs the results of the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Usage example\nasync function runWorkflow() {\n  const workflow = mastra.getWorkflow('contentWorkflow');\n  const { runId, start } = workflow.createRun();\n\n  let finalResult: any;\n\n  // Start the workflow\n  const initialResult = await start({\n    triggerData: { input: 'Create content about sustainable energy' },\n  });\n\n  console.log('Initial workflow state:', initialResult.results);\n\n  const promptAgentStepResult = initialResult.activePaths.get('promptAgent');\n\n  // Check if promptAgent step is suspended\n  if (promptAgentStepResult?.status === 'suspended') {\n    console.log('Workflow suspended at promptAgent step');\n    console.log('Suspension payload:', promptAgentStepResult?.suspendPayload);\n\n    // Resume with human guidance\n    const resumeResult1 = await workflow.resume({\n      runId,\n      stepId: 'promptAgent',\n      context: {\n        guidance: 'Focus more on solar and wind energy technologies',\n      },\n    });\n\n    console.log('Workflow resumed and continued to next steps');\n\n    let improveResponseResumeAttempts = 0;\n    let improveResponseStatus = resumeResult1?.activePaths.get('improveResponse')?.status;\n\n    // Check if improveResponse step is suspended\n    while (improveResponseStatus === 'suspended') {\n      console.log('Workflow suspended at improveResponse step');\n      console.log('Suspension payload:', resumeResult1?.activePaths.get('improveResponse')?.suspendPayload);\n\n      const improvedContent =\n        improveResponseResumeAttempts < 3\n          ? undefined\n          : 'Completely revised content about sustainable energy focusing on solar and wind technologies';\n\n      // Resume with human improvements\n      finalResult = await workflow.resume({\n        runId,\n        stepId: 'improveResponse',\n        context: {\n          improvedContent,\n          resumeAttempts: improveResponseResumeAttempts,\n        },\n      });\n\n      improveResponseResumeAttempts =\n        finalResult?.activePaths.get('improveResponse')?.suspendPayload?.resumeAttempts ?? 0;\n      improveResponseStatus = finalResult?.activePaths.get('improveResponse')?.status;\n\n      console.log('Improved response result:', finalResult?.results);\n    }\n  }\n  return finalResult;\n}\n\n// Run the workflow\nconst result = await runWorkflow();\nconsole.log('Workflow completed');\nconsole.log('Final workflow result:', result);\n```\n\n----------------------------------------\n\nTITLE: Advanced Usage of Todo List Agent with UI Feedback in TypeScript\nDESCRIPTION: Shows how to provide UI feedback during working memory updates. It uses lifecycle hooks with maskStreamTags to show loading states and log debug information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Same imports and setup as above...\n\n// Add lifecycle hooks to provide UI feedback\nconst maskedStream = maskStreamTags(response.textStream, \"working_memory\", {\n  // Called when a working_memory tag starts\n  onStart: () => showLoadingSpinner(\"Updating todo list...\"),\n  // Called when a working_memory tag ends\n  onEnd: () => hideLoadingSpinner(),\n  // Called with the content that was masked\n  onMask: (chunk) => console.debug(\"Updated todo list:\", chunk),\n});\n\n// Process the masked stream\nfor await (const chunk of maskedStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Chunking HTML with MDocument in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the MDocument class from the @mastra/rag package to semantically chunk HTML content. It creates an HTML string, converts it to an MDocument, and then chunks it based on specified headers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-html.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst html = `\n<div>\n    <h1>h1 content...</h1>\n    <p>p content...</p>\n</div>\n`;\n\nconst doc = MDocument.fromHTML(html);\n\nconst chunks = await doc.chunk({\n  headers: [\n    [\"h1\", \"Header 1\"],\n    [\"p\", \"Paragraph\"],\n  ],\n});\n\nconsole.log(chunks);\n```\n\n----------------------------------------\n\nTITLE: Adding Tools to Voice Instance\nDESCRIPTION: This TypeScript code demonstrates how to add custom tools to the voice instance to extend its capabilities. It shows an example of a 'menuTool' with input validation and execution logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n\"export const menuTool = createTool({\n  id: 'menuTool',\n  description: 'Get menu items',\n  inputSchema: z\n    .object({\n      query: z.string(),\n    })\n    .required(),\n  execute: async ({ context }) => {\n    // Implement menu search functionality\n  },\n});\n\nvoice.addTools(menuTool);\n\"\n```\n\n----------------------------------------\n\nTITLE: Describing an Index in AstraVector\nDESCRIPTION: Describes a specified index in the AstraVector class including its name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to describe\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector in TypeScript\nDESCRIPTION: Initializes the `PgVector` client with the PostgreSQL connection string obtained from the environment variables. The connection string is used to establish a connection to the PGVector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/hybrid-vector-search.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n```\n\n----------------------------------------\n\nTITLE: Setting up Global Environment for Evaluations with Vitest\nDESCRIPTION: This TypeScript snippet sets up the global environment for running Mastra evaluations within Vitest. It imports the `globalSetup` function from the `@mastra/evals` library and exports a default function that calls `globalSetup`. This ensures that necessary global configurations are applied before any tests are executed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/running-in-ci.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { globalSetup } from '@mastra/evals';\n\nexport default function setup() {\n  globalSetup()\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra RAG System\nDESCRIPTION: Import statements for required Mastra modules, OpenAI integration, and vector storage components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from '@mastra/core';\nimport { Agent } from '@mastra/core/agent';\nimport { createVectorQueryTool } from '@mastra/rag';\nimport { PgVector } from '@mastra/pg';\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Typing in Mastra Workflows (TypeScript)\nDESCRIPTION: This example demonstrates how to enforce type safety across an entire Mastra workflow by defining the types of all steps and passing them to the `Workflow` constructor.  It utilizes `Step`, `Workflow` from `@mastra/core/workflows` and `zod` for schema definitions. `context.getStepResult` ensures type safety when accessing step results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n\n// Create steps with typed outputs\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of userData\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      orderId: \"order123\",\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow<[typeof fetchUserStep, typeof processOrderStep]>({ \n  name: \"typed-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .until(async ({ context }) => {\n    // TypeScript knows the shape of userData here\n    const res = context.getStepResult('fetchUser');\n    return res?.userId === '123';\n  }, processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Extracting Text from Chunks - TypeScript\nDESCRIPTION: The `getText()` instance method returns an array of text strings from an MDocument's chunks, implemented using TypeScript. It serves the purpose of extracting plain text from processed chunk data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ngetText(): string[]\n```\n\n----------------------------------------\n\nTITLE: Importing Keyword Coverage Metric in TypeScript\nDESCRIPTION: Imports the KeywordCoverageMetric class from the Mastra evals NLP package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/keyword-coverage.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Document Chunker Tool Setup\nDESCRIPTION: Configuration of document chunking tool with specific parameters for text processing and chunking strategy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(yourText);\n\nconst documentChunkerTool = createDocumentChunkerTool({\n  doc,\n  params: {\n    strategy: \"recursive\",\n    size: 512,\n    overlap: 25,\n    separator: \"\\n\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking Text with Custom Separator - Mastra RAG - TSX\nDESCRIPTION: This code snippet demonstrates how to use the `MDocument.chunk()` method to split text content into chunks based on a custom separator. It imports the `MDocument` class from the `@mastra/rag` package, creates an `MDocument` instance from plain text, and then chunks the document using the specified separator.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/adjust-chunk-delimiters.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Define Final Answer Step Typescript\nDESCRIPTION: Defines a workflow step `finalAnswer` using the `Step` class. This step generates the final answer based on the conclusions drawn. It retrieves the conclusions from the `drawConclusions` step and uses the RAG agent to format the answer, including a thought process breakdown and a concise answer based on the retrieved context. The final answer is then returned as the step's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst finalAnswer = new Step({\n  id: \"finalAnswer\",\n  outputSchema: z.object({\n    finalAnswer: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const conclusions = context?.getStepResult<{\n      conclusions: string;\n    }>(\"drawConclusions\")?.conclusions;\n    const answerPrompt = `\n        結論に基づいて: ${conclusions}\n        回答を次の形式でフォーマットします:\n        思考プロセス:\n        - ステップ 1: [取得したチャンクの初期分析]\n        - ステップ 2: [チャンク間の接続]\n        - ステップ 3: [チャンクに基づく推論]\n\n        最終回答:\n        [取得したコンテキストに基づく簡潔な回答]`;\n\n    const finalAnswer = await ragAgent?.generate(answerPrompt);\n    console.log(finalAnswer?.text);\n    return {\n      finalAnswer: finalAnswer?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Text to Speech with a Text Stream Source\nDESCRIPTION: This TypeScript code snippet shows how to generate speech from a text stream source and pipe the resulting audio stream to save it as an .mp3 file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst textStream = getTextStream(); // Your text stream source\nconst audioStream = await voice.speak(textStream);\n\n// The stream can be piped to a destination\nconst streamFilePath = path.join(process.cwd(), 'stream.mp3');\nconst streamWriter = createWriteStream(streamFilePath);\n\naudioStream.pipe(streamWriter);\n\nconsole.log(`Speech saved to ${filePath} and ${streamFilePath}`);\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Details with TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve detailed information about a specific workflow instance. The `details()` method is called on a workflow object, and it asynchronously returns the details of the workflow. The return type and structure of the details are not explicitly specified.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await workflow.details();\n```\n\n----------------------------------------\n\nTITLE: Metadata Filtering Examples with PgVector in Typescript\nDESCRIPTION: This snippet provides examples of how to use metadata filtering with PgVector to refine search results. It showcases simple equality filters, numerical comparisons, multiple conditions, array operations, and logical operators within the filter. Requires the `@mastra/pg` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// 単純な等価フィルタ\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    source: \"article1.txt\"\n  }\n});\n\n// 数値比較\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    price: { $gt: 100 }\n  }\n});\n\n// 複数条件\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    category: \"electronics\",\n    price: { $lt: 1000 },\n    inStock: true\n  }\n});\n\n// 配列操作\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    tags: { $in: [\"sale\", \"new\"] }\n  }\n});\n\n// 論理演算子\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    $or: [\n      { category: \"electronics\" },\n      { category: \"accessories\" }\n    ],\n    $and: [\n      { price: { $gt: 50 } },\n      { price: { $lt: 200 } }\n    ]\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Thread by ID using getThreadById in Memory Class (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to retrieve a thread by its ID using the `getThreadById` function of the `Memory` class. It requires the `@mastra/core/memory` package.  The `threadId` parameter is a string representing the ID of the thread to be retrieved. The function returns a promise that resolves to the thread object or null if not found.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/getThreadById.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/core/memory\";\n\nconst memory = new Memory(config);\n\nconst thread = await memory.getThreadById({ threadId: \"thread-123\" });\n```\n\n----------------------------------------\n\nTITLE: Set OpenAI API Key in .env - Bash\nDESCRIPTION: Specifies the environment variable `OPENAI_API_KEY` in the `.env` file.  This key is required for the Agent to make calls to OpenAI's models. Replace `<your-openai-key>` with your actual OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the hallucination example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/hallucination\n```\n\n----------------------------------------\n\nTITLE: Initializing GoogleVoice with default/custom configuration\nDESCRIPTION: These code snippets demonstrates how to initialize the GoogleVoice class with either the default configuration (using the GOOGLE_API_KEY environment variable) or with a custom configuration, including API keys for speech and listening models, and a default speaker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/google.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GoogleVoice } from \"@mastra/voice-google\";\n\n// Initialize with default configuration (uses GOOGLE_API_KEY environment variable)\nconst voice = new GoogleVoice();\n\n// Initialize with custom configuration\nconst voice = new GoogleVoice({\n  speechModel: {\n    apiKey: 'your-speech-api-key',\n  },\n  listeningModel: {\n    apiKey: 'your-listening-api-key',\n  },\n  speaker: 'en-US-Casual-K',\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool\nDESCRIPTION: This code creates a vector query tool using `createVectorQueryTool` from `@mastra/rag`. It configures the tool with the vector store name, index name, embedding model, and reranker model. The reranker is essential for improving the relevance of the search results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  reranker: {\n    model: openai(\"gpt-4o-mini\"),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Pinecone with Mastra (TSX)\nDESCRIPTION: This code snippet shows how to create an index and upsert embeddings into a Pinecone vector database using the `PineconeVector` class from the `@mastra/pinecone` package.  It utilizes the `openai` package for embedding generation, and `MDocument` from `@mastra/rag` for text processing. The `PINECONE_API_KEY` environment variable is required for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PineconeVector } from '@mastra/pinecone';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst pinecone = new PineconeVector(process.env.PINECONE_API_KEY!);\n\nawait pinecone.createIndex({\n  indexName: 'testindex',\n  dimension: 1536,\n});\n\nawait pinecone.upsert({\n  indexName: 'testindex',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Update Filter Location for Vector Search (Patch)\nDESCRIPTION: This patch moves the filter functionality from `@mastra/core/filter` to `@mastra/core/vector/filter`. This change reflects a reorganization of the codebase for better modularity and organization of vector-related functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_4\n\n\n\n----------------------------------------\n\nTITLE: Example with Custom Description for Vector Query Tool\nDESCRIPTION: This TypeScript example illustrates how to set a custom description for the vector query tool. The description is tailored to specify the tool's application, such as searching through document archives for specific information retrieval.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  description: \"Search through document archives to find relevant information for answering questions about company policies and procedures\"\n});\n```\n\n----------------------------------------\n\nTITLE: Interacting with Agent via curl (Bash)\nDESCRIPTION: This bash command demonstrates how to interact with a Mastra agent using `curl`. It sends a POST request to the agent's generate endpoint with a JSON payload containing a user message. The request specifies the content type as `application/json` and includes a message with the role set to 'user' and the content set to a greeting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/myAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"Hello, how can you assist me today?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template\nDESCRIPTION: Command to create a local environment variables file from the provided example template.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Querying messages using CloudflareStore (TypeScript)\nDESCRIPTION: Retrieves messages from the Cloudflare KV store for a specific thread using the getMessages method. The thread ID is used as a parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n// Query messages\nconst messages = await store.getMessages({ threadId: 'thread-123' });\n```\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Sets the OpenAI API key as an environment variable. This is required to authenticate requests to the OpenAI API for evaluating the summarization metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with OpenAIVoice using voice.listen()\nDESCRIPTION: This snippet demonstrates how to use the `voice.listen()` method with the `OpenAIVoice` provider to transcribe audio from a file stream and a microphone stream. It includes initialization of the voice provider, reading audio from a file, and passing provider-specific options.  The output is the transcribed text from the audio stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.listen.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\n\n// Initialize a voice provider\nconst voice = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Basic usage with a file stream\nconst audioFilePath = path.join(process.cwd(), \"audio.mp3\");\nconst audioStream = createReadStream(audioFilePath);\nconst transcript = await voice.listen(audioStream, {\n  filetype: \"mp3\",\n});\nconsole.log(\"Transcribed text:\", transcript);\n\n// Using a microphone stream\nconst microphoneStream = getMicrophoneStream(); // Assume this function gets audio input\nconst transcription = await voice.listen(microphoneStream);\n\n// With provider-specific options\nconst transcriptWithOptions = await voice.listen(audioStream, {\n  language: \"en\",\n  prompt: \"This is a conversation about artificial intelligence.\",\n});\n```\n\n----------------------------------------\n\nTITLE: Create Mem0 Tool\nDESCRIPTION: Creates two tools: `mem0RememberTool` to search for memories in Mem0, and `mem0MemorizeTool` to save information to Mem0.  These tools allow agents to remember and recall information across interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core\";\nimport { z } from \"zod\";\nimport { mem0 } from \"../integrations\";\n\nexport const mem0RememberTool = createTool({\n  id: \"Mem0-remember\",\n  description:\n    \"Mem0-memorizeツールを使用して以前に保存したエージェントの記憶を思い出します。\",\n  inputSchema: z.object({\n    question: z\n      .string()\n      .describe(\"保存された記憶の中から答えを探すために使用される質問。\"),\n  }),\n  outputSchema: z.object({\n    answer: z.string().describe(\"思い出された答え\"),\n  }),\n  execute: async ({ context }) => {\n    console.log(`Searching memory \"${context.question}\"`);\n    const memory = await mem0.searchMemory(context.question);\n    console.log(`\\nFound memory \"${memory}\"\\n`);\n\n    return {\n      answer: memory,\n    };\n  },\n});\n\nexport const mem0MemorizeTool = createTool({\n  id: \"Mem0-memorize\",\n  description:\n    \"Mem0に情報を保存し、後でMem0-rememberツールを使用して思い出せるようにします。\",\n  inputSchema: z.object({\n    statement: z.string().describe(\"メモリに保存する文\"),\n  }),\n  execute: async ({ context }) => {\n    console.log(`\\nCreating memory \"${context.statement}\"\\n`);\n    // レイテンシーを減らすために、メモリはツールの実行をブロックせずに非同期で保存できます\n    void mem0.createMemory(context.statement).then(() => {\n      console.log(`\\nMemory \"${context.statement}\" saved.\\n`);\n    });\n    return { success: true };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing LibSQLStore for File Database\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize the LibSQLStore for a file-based database. The `url` parameter specifies the path to the SQLite database file. This configuration is suitable for development and testing environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/libsql.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLStore } from \"@mastra/libsql\";\n\n// File database (development)\nconst storage = new LibSQLStore({\n  url: \"file:./storage.db\",\n});\n```\n\n----------------------------------------\n\nTITLE: Transforming Chunks into Filterable Metadata\nDESCRIPTION: Transforms processed chunks into metadata that can be filtered, including nested structures for keywords and IDs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunkMetadata = chunks?.map((chunk: any, index: number) => ({\n  text: chunk.text,\n  ...chunk.metadata,\n  nested: {\n    keywords: chunk.metadata.excerptKeywords\n      .replace('KEYWORDS:', '')\n      .split(',')\n      .map(k => k.trim()),\n    id: index,\n  },\n}));\n```\n\n----------------------------------------\n\nTITLE: Chain-of-Thought Queries\nDESCRIPTION: This snippet demonstrates how to perform chain-of-thought queries using the configured agent. It generates responses for three different queries related to climate change and agriculture. The responses include the agent's thought process and the final answer, showcasing the chain-of-thought reasoning.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst answerOne = await agent.generate('What are the main adaptation strategies for farmers?');\nconsole.log('\\nQuery:', 'What are the main adaptation strategies for farmers?');\nconsole.log('Response:', answerOne.text);\n\nconst answerTwo = await agent.generate('Analyze how temperature affects crop yields.');\nconsole.log('\\nQuery:', 'Analyze how temperature affects crop yields.');\nconsole.log('Response:', answerTwo.text);\n\nconst answerThree = await agent.generate('What connections can you draw between climate change and food security?');\nconsole.log('\\nQuery:', 'What connections can you draw between climate change and food security?');\nconsole.log('Response:', answerThree.text);\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Memory System with PostgreSQL in TypeScript\nDESCRIPTION: PostgreSQLストレージとベクター機能を使用してMastraのメモリシステムをセットアップします。データベース接続の詳細を設定し、メモリオプションを指定して、メモリ機能を持つエージェントを作成します。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-pg.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { PostgresStore, PgVector } from \"@mastra/pg\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// PostgreSQL接続の詳細\nconst host = \"localhost\";\nconst port = 5432;\nconst user = \"postgres\";\nconst database = \"postgres\";\nconst password = \"postgres\";\nconst connectionString = `postgresql://${user}:${password}@${host}:${port}`;\n\n// PostgreSQLストレージとベクター検索でメモリを初期化\nconst memory = new Memory({\n  storage: new PostgresStore({\n    host,\n    port,\n    user,\n    database,\n    password,\n  }),\n  vector: new PgVector(connectionString),\n  options: {\n    lastMessages: 10,\n    semanticRecall: {\n      topK: 3,\n      messageRange: 2,\n    },\n  },\n});\n\n// メモリ機能を持つエージェントを作成\nconst chefAgent = new Agent({\n  name: \"chefAgent\",\n  instructions:\n    \"あなたはMichelです。実用的で経験豊富な家庭料理のシェフで、利用可能な食材で素晴らしい料理を作る手助けをします。\",\n  model: openai(\"gpt-4o-mini\"),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Define Editor Step - TypeScript\nDESCRIPTION: This code snippet defines the editor step using the `Step` class. It retrieves the copy from the 'copywriterStep' result in the context and then uses the `editorAgent` to edit the copy. The edited copy is returned as the result of this step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorStep = new Step({\n  id: \"editorStep\",\n  execute: async ({ context }) => {\n    const copy = context?.getStepResult<{ copy: number }>(\"copywriterStep\")?.copy;\n\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${copy}`,\n    );\n    console.log(\"editor result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Index Vector and Metadata by ID\nDESCRIPTION: This snippet shows updating both the vector and metadata of a vector in the index, using its ID as the identifier.  It uses `updateIndexById` with both updated vector and metadata values.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// ベクトルとメタデータの両方を更新\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  vector: [0.1, 0.2, 0.3],\n  metadata: { label: \"updated\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Toxicity Response in TypeScript\nDESCRIPTION: Shows how to evaluate a response containing both toxic and professional elements using an array of statements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'How was the meeting discussion?';\nconst response2 = [\n  'Half the meeting was just listening to the marketing team ramble on with their usual clueless suggestions.',\n  \"At least the engineering team's presentation was focused and had some solid technical solutions we can actually use.\"\n];\n\nconsole.log('Example 2 - Mixed Toxicity:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'The response shows a mix of dismissive language towards the marketing team while maintaining professional discourse about the engineering team.' }\n```\n\n----------------------------------------\n\nTITLE: Data Optimization Process\nDESCRIPTION: Implementation of data cleaning and optimization process for improved response quality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunkPrompt = `Use the tool provided to clean the chunks. Make sure to filter out irrelevant information that is not space related and remove duplicates.`;\n\nconst newChunks = await agent.generate(chunkPrompt);\nconst updatedDoc = MDocument.fromText(newChunks.text);\n\nconst updatedChunks = await updatedDoc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n  separator: \"\\n\",\n});\n\nconst { embeddings: cleanedEmbeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: updatedChunks.map(chunk => chunk.text),\n});\n\nawait vectorStore.deleteIndex('embeddings');\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: cleanedEmbeddings,\n  metadata: updatedChunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Errors with VectorStore in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates catching and handling errors specific to the Pinecone vector store. The VectorStoreError is used to capture error codes and additional context about the failure. Dependencies include the Pinecone vector store library and associated error types.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pinecone.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Handling in Mastra Client SDK (TypeScript)\nDESCRIPTION: This snippet demonstrates how to implement error handling when using the Mastra Client SDK. It shows how to catch and handle errors that may be thrown by API methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/error-handling.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const agent = client.getAgent(\"agent-id\");\n  const response = await agent.generate({\n    messages: [{ role: \"user\", content: \"Hello\" }],\n  });\n} catch (error) {\n  console.error(\"An error occurred:\", error.message);\n}\n```\n\n----------------------------------------\n\nTITLE: Using the Gluten Checker Metric with Chef Agent\nDESCRIPTION: Demonstrates how to use the gluten checker metric with an agent to evaluate a recipe. This example shows how to retrieve the agent, generate a response for a recipe query, and evaluate the generated recipe for gluten content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from './mastra';\\n\\nconst chefAgent = mastra.getAgent('chefAgent');\\nconst metric = chefAgent.evals.glutenChecker;\\n\\n// Example: Evaluate a recipe\\nconst input = 'What is a quick way to make rice and beans?';\\nconst response = await chefAgent.generate(input);\\nconst result = await metric.measure(input, response.text);\\n\\nconsole.log('Metric Result:', {\\n  score: result.score,\\n  glutenSources: result.info.glutenSources,\\n  reason: result.info.reason,\\n});\\n\\n// Example Output:\\n// Metric Result: { score: 1, glutenSources: [], reason: 'The recipe is gluten-free as it does not contain any gluten-containing ingredients.' }\n```\n\n----------------------------------------\n\nTITLE: Variable Mapping in Workflows: TypeScript\nDESCRIPTION: This snippet illustrates the use of variable mapping to explicitly define data flow between workflow steps. It shows how to map values from one step's output to another step's input using the context object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst sendEmailStep = new Step({\n  id: \"sendEmail\",\n  inputSchema: z.object({\n    recipientEmail: z.string(),\n    recipientName: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const { recipientEmail, recipientName } = context.inputData;\n\n    // Send email logic here\n    return {\n      status: \"sent\",\n      to: recipientEmail\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"email-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(sendEmailStep, {\n    variables: {\n      // Map specific fields from fetchUser to sendEmail inputs\n      recipientEmail: { step: fetchUserStep, path: 'email' },\n      recipientName: { step: fetchUserStep, path: 'name' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Streaming Agent Response in Mastra AI (TypeScript)\nDESCRIPTION: This snippet shows how to stream responses from an agent for real-time interactions, including processing the data stream and reading directly from the response body.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await agent.stream({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Tell me a story\",\n    },\n  ],\n});\n\n// Process data stream with the processDataStream util\n response.processDataStream({\n      onTextPart: (text) => {\n        process.stdout.write(text);\n      },\n      onFilePart: (file) => {\n        console.log(file);\n      },\n      onDataPart: (data) => {\n        console.log(data);\n      },\n      onErrorPart: (error) => {\n        console.error(error);\n      },\n  });\n\n// You can also read from response body directly\nconst reader = response.body.getReader();\nwhile (true) {\n  const { done, value } = await reader.read();\n  if (done) break;\n  console.log(new TextDecoder().decode(value));\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up D1Store with REST API in TypeScript\nDESCRIPTION: This TypeScript code initializes a D1Store using REST API integration. Make sure to replace placeholders with your Cloudflare accountId, databaseId, and apiToken.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare-d1/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { D1Store } from '@mastra/cloudflare-d1';\n\nconst store = new D1Store({\n  accountId: '<your-account-id>',\n  databaseId: '<your-d1-database-id>',\n  apiToken: '<your-api-token>',\n  tablePrefix: 'mastra_', // optional\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra to use LangSmith\nDESCRIPTION: This snippet shows how to configure Mastra to export telemetry data to LangSmith using the `AISDKExporter`. It initializes a new `Mastra` instance and configures the `telemetry` option to enable tracing and use a custom exporter. The exporter is set to an instance of `AISDKExporter` which handles sending the data to LangSmith.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langsmith.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { AISDKExporter } from \"langsmith/vercel\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new AISDKExporter(),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow with Trigger Schema\nDESCRIPTION: This snippet illustrates how to utilize a trigger schema for a workflow which validates the input data structure using Zod. It shows how to set up a new workflow while establishing required fields through a nested object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: \"order-process\",\n  triggerSchema: z.object({\n    orderId: z.string(),\n    customer: z.object({\n      id: z.string(),\n      email: z.string().email(),\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing UpstashStore with Configuration\nDESCRIPTION: This code snippet initializes the UpstashStore with the provided configuration, including the Upstash Redis URL and token. The URL and token are fetched from environment variables. The storage instance can then be used to interact with Upstash.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/upstash.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst storage = new UpstashStore({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Workflow Class in TypeScript\nDESCRIPTION: This snippet demonstrates how to import the Workflow class from the Mastra core workflows module and instantiate a new workflow with a specified name. The 'Workflow' class sets up the necessary structure for creating state machines that support complex operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst workflow = new Workflow({ name: \"my-workflow\" });\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Composio.dev Registry\nDESCRIPTION: This TypeScript code shows how to configure MCP with SSE URLs from the Composio.dev registry for services like Google Sheets and Gmail. Each URL is specific to a user's account, making it suitable for single-user scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    googleSheets: {\n      url: new URL(\"https://mcp.composio.dev/googlesheets/[private-url-path]\"),\n    },\n    gmail: {\n      url: new URL(\"https://mcp.composio.dev/gmail/[private-url-path]\"),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing D1Store with REST API - Typescript\nDESCRIPTION: This snippet shows how to initialize the `D1Store` class using the REST API method in TypeScript.  It requires environment variables for the Cloudflare Account ID, D1 Database ID, and API Token, which are then used to instantiate the D1Store.  An optional `tablePrefix` can isolate tables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare-d1.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { D1Store } from \\\"@mastra/cloudflare-d1\\\";\n\n// --- Example 2: Using REST API ---\nconst storageRest = new D1Store({\n  accountId: process.env.CLOUDFLARE_ACCOUNT_ID!, // Cloudflare Account ID\n  databaseId: process.env.CLOUDFLARE_D1_DATABASE_ID!, // D1 Database ID\n  apiToken: process.env.CLOUDFLARE_API_TOKEN!, // Cloudflare API Token\n  tablePrefix: 'dev_', // Optional: isolate tables per environment\n});\"\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Context with REST API in Mastra (TypeScript)\nDESCRIPTION: Illustrates how to dynamically set temperature units based on a user's location using the Cloudflare `CF-IPCountry` header.  This snippet showcases middleware that reads the header, creates and sets a `RuntimeContext`, and passes it to the next middleware. Dependencies include `@mastra/core` and potentially other modules for agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/runtime-variables.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { agent as weatherAgent } from \"./agents/weather\";\n\n// Define RuntimeContext type with clear, descriptive types\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\";\n};\n\nexport const mastra = new Mastra({\n  agents: {\n    weather: weatherAgent,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const country = c.req.header(\"CF-IPCountry\");\n        const runtimeContext = c.get<WeatherRuntimeContext>(\"runtimeContext\");\n\n        // Set temperature scale based on country\n        runtimeContext.set(\n          \"temperature-scale\",\n          country === \"US\" ? \"fahrenheit\" : \"celsius\",\n        );\n\n        await next(); // Don't forget to call next()\n      },\n    ],\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Inject Request-Specific Variables into Tools\nDESCRIPTION: This snippet demonstrates how to inject request-specific variables into tools using the `runtimeContext`. It defines an agent with a tool that fetches weather data and uses the `temperature-scale` from the `runtimeContext` to determine whether to return the temperature in Celsius or Fahrenheit. It showcases dependency injection for customizing tool behavior based on the request context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const agent = new Agent({\n  name: \"Weather agent\",\n  tools: {\n    weather: createTool({\n      id: \"Get Weather Information\",\n      description: \"Get the weather in a location\",\n      inputSchema: z.object({ location: z.string() }),\n      execute: async ({ context: { location }, runtimeContext }) => {\n        const scale = runtimeContext.get(\"temperature-scale\");\n\n        const result = await fetch(\n          `https://api.weatherapi.com/v1/current.json?q=${location}`,\n        );\n\n        const json = await result.json();\n\n        return {\n          temperature: scale === \"celsius\" ? json.temp_c : json.temp_f,\n        };\n      },\n    }),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Document Processing\nDESCRIPTION: Processes a document by creating an `MDocument` instance and then chunking it into smaller parts.  The `chunk` method is used with a 'recursive' strategy, specifying chunk size, overlap, and separator. It also extracts keywords from each chunk, enhancing the metadata for filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`The Impact of Climate Change on Global Agriculture...`);\n\nconst chunks = await doc.chunk({\n  strategy: 'recursive',\n  size: 512,\n  overlap: 50,\n  separator: '\\n',\n  extract: {\n    keywords: true,  // Extracts keywords from each chunk\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Using Agent with Text Stream Mode\nDESCRIPTION: This code demonstrates how to interact with the agent in text-stream mode. It sends a message to the agent, retrieves the response stream, and masks the `working_memory` tags before processing and writing the output. The `maskStreamTags` function removes the tags from the stream, preventing them from being displayed to the user.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\nimport { maskStreamTags } from \"@mastra/core/utils\";\n\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\nconst response = await agent.stream(\"Hello, my name is Jane\", {\n  threadId,\n  resourceId,\n});\n\n// 作業メモリタグを隠して応答ストリームを処理\nfor await (const chunk of maskStreamTags(\n  response.textStream,\n  \"working_memory\",\n)) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Full Word Inclusion Example Usage\nDESCRIPTION: Demonstrates using the metric when all target words are present in the output text, resulting in a perfect score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/word-inclusion.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst words1 = ['apple', 'banana', 'orange'];\nconst metric1 = new WordInclusionMetric(words1);\n\nconst input1 = 'List some fruits';\nconst output1 = 'Here are some fruits: apple, banana, and orange.';\n\nconst result1 = await metric1.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: result1.info,\n});\n// Example Output:\n// Metric Result: { score: 1, info: { totalWords: 3, matchedWords: 3 } }\n```\n\n----------------------------------------\n\nTITLE: Basic Workflow.until() Usage (TypeScript)\nDESCRIPTION: Demonstrates the basic syntax for using the `.until()` method to repeat a step until a condition is met. This snippet showcases the chaining of steps within a Mastra workflow, including an initial step, a looping step based on the `until` condition, and a final step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/until.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .until(condition, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Environment variable setup for mcp.run SSE URL\nDESCRIPTION: This shows how to set the `MCP_RUN_SSE_URL` environment variable in a `.env` file.  It emphasizes the importance of managing the SSE URL securely as a password.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nMCP_RUN_SSE_URL=https://www.mcp.run/api/mcp/sse?nonce=...\n```\n\n----------------------------------------\n\nTITLE: Implementing Mem0 Memory Tools\nDESCRIPTION: Implementation of tools for memorizing and remembering information using Mem0 integration\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core\";\nimport { z } from \"zod\";\nimport { mem0 } from \"../integrations\";\n\nexport const mem0RememberTool = createTool({\n  id: \"Mem0-remember\",\n  description:\n    \"Remember your agent memories that you've previously saved using the Mem0-memorize tool.\",\n  inputSchema: z.object({\n    question: z\n      .string()\n      .describe(\"Question used to look up the answer in saved memories.\"),\n  }),\n  outputSchema: z.object({\n    answer: z.string().describe(\"Remembered answer\"),\n  }),\n  execute: async ({ context }) => {\n    console.log(`Searching memory \"${context.question}\"`);\n    const memory = await mem0.searchMemory(context.question);\n    console.log(`\\nFound memory \"${memory}\"\\n`);\n\n    return {\n      answer: memory,\n    };\n  },\n});\n\nexport const mem0MemorizeTool = createTool({\n  id: \"Mem0-memorize\",\n  description:\n    \"Save information to mem0 so you can remember it later using the Mem0-remember tool.\",\n  inputSchema: z.object({\n    statement: z.string().describe(\"A statement to save into memory\"),\n  }),\n  execute: async ({ context }) => {\n    console.log(`\\nCreating memory \"${context.statement}\"\\n`);\n    // to reduce latency memories can be saved async without blocking tool execution\n    void mem0.createMemory(context.statement).then(() => {\n      console.log(`\\nMemory \"${context.statement}\" saved.\\n`);\n    });\n    return { success: true };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareStore with REST API\nDESCRIPTION: This snippet shows how to initialize the `CloudflareStore` class using the Cloudflare REST API. It imports the `CloudflareStore` class and creates an instance, configuring it with the Cloudflare Account ID, API Token, and an optional namespace prefix for environment isolation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"// --- Example 2: Using REST API ---\nconst storageRest = new CloudflareStore({\n  accountId: process.env.CLOUDFLARE_ACCOUNT_ID!, // Cloudflare Account ID\n  apiToken: process.env.CLOUDFLARE_API_TOKEN!, // Cloudflare API Token\n  namespacePrefix: 'dev_', // Optional: isolate namespaces per environment\n});\"\n```\n\n----------------------------------------\n\nTITLE: Full Coverage Keyword Evaluation Example\nDESCRIPTION: Demonstrates evaluation of a response with complete keyword coverage, showing input/output comparison and metric calculation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/keyword-coverage.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'JavaScript frameworks like React and Vue';\nconst output1 = 'Popular JavaScript frameworks include React and Vue for web development';\n\nconsole.log('Example 1 - Full Coverage:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    totalKeywords: result1.info.totalKeywords,\n    matchedKeywords: result1.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 1, info: { totalKeywords: 4, matchedKeywords: 4 } }\n```\n\n----------------------------------------\n\nTITLE: Processing Documents into Chunks\nDESCRIPTION: Creates a document from text and processes it into chunks using a recursive strategy with specified size and overlap.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`\n# Riverdale Heights: Community Development Study\n// ... text content ...\n`);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAGTool with default options in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the `createGraphRAGTool` with a vector store, index name, embedding model and default graph options. The `openai.embedding('text-embedding-3-small')` specifies the embedding model used for generating vector embeddings of the documents. The `graphOptions` parameter configures the graph-based retrieval with default values for dimension, threshold, random walk steps, and restart probability.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/graph-rag-tool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { createGraphRAGTool } from \"@mastra/rag\";\n\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.7,\n    randomWalkSteps: 100,\n    restartProb: 0.15\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluate Complete Coverage with CompletenessMetric\nDESCRIPTION: Demonstrates evaluating a text that completely covers the reference. It defines a reference and text, then measures the completeness score using the CompletenessMetric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/completeness.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst text1 = 'The primary colors are red, blue, and yellow.';\nconst reference1 = 'The primary colors are red, blue, and yellow.';\n\nconsole.log('Example 1 - Complete Coverage:');\nconsole.log('Text:', text1);\nconsole.log('Reference:', reference1);\n\nconst result1 = await metric.measure(reference1, text1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    missingElements: result1.info.missingElements,\n    elementCounts: result1.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: { score: 1, info: { missingElements: [], elementCounts: { input: 8, output: 8 } } }\n```\n\n----------------------------------------\n\nTITLE: Starting Workflow Execution with Input Validation\nDESCRIPTION: This snippet demonstrates how to start a workflow run and validate the input data against the trigger schema. If validation fails, appropriate errors will be captured, ensuring only valid data proceeds through the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start } = workflow.createRun();\n\n// Validates trigger data against schema\nawait start({\n  triggerData: {\n    orderId: \"123\",\n    customer: {\n      id: \"cust_123\",\n      email: \"invalid-email\", // Will fail validation\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Package\nDESCRIPTION: This snippet demonstrates how to install the PostgreSQL implementation for Mastra using npm. It is essential for integrating the vector store and storage functionalities into a Node.js application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/pg\n```\n\n----------------------------------------\n\nTITLE: Deleting an Index in ChromaVector\nDESCRIPTION: Removes a specified index from the ChromaDB, allowing for the clean-up of unused or obsolete indexes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to delete\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: useCompletion Hook Integration\nDESCRIPTION: This snippet demonstrates the integration of the `useCompletion` hook from `@ai-sdk/react` with a Mastra agent for single-turn completions. It shows a POST endpoint to stream data using `toDataStreamResponse()` and a React component using `useCompletion` to handle prompt input and display the completion result. The api property should point to the correct agent stream endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages);\n\n  return stream.toDataStreamResponse();\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useCompletion } from \"@ai-sdk/react\";\n\nexport function CompletionComponent() {\n  const {\n    completion,\n    input,\n    handleInputChange,\n    handleSubmit,\n  } = useCompletion({\n  api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Enter a prompt...\"\n        />\n      </form>\n      <p>Completion result: {completion}</p>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Chaining and Executing Workflow Steps\nDESCRIPTION: This code snippet demonstrates how to chain the previously defined steps using the `then` method of the `Workflow` class, creating a sequential flow.  The `commit` method finalizes the workflow definition. The `createRun` method creates a run instance, and the `start` method initiates the workflow execution with the provided `triggerData`. The result of the workflow execution is stored in the `res` variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/sequential-steps.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// sequential steps\nmyWorkflow.step(stepOne).then(stepTwo).then(stepThree);\n\nmyWorkflow.commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst res = await start({ triggerData: { inputValue: 90 } });\n```\n\n----------------------------------------\n\nTITLE: Using connect() with CompositeVoice in TypeScript\nDESCRIPTION: This example shows how to use the connect() method with CompositeVoice, which delegates to the configured real-time provider. It initializes OpenAIRealtimeVoice as the real-time provider and then uses it through the CompositeVoice interface.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.connect.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nconst realtimeVoice = new OpenAIRealtimeVoice();\nconst voice = new CompositeVoice({\n  realtimeProvider: realtimeVoice,\n});\n// This will use the OpenAIRealtimeVoice provider\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: PgVector and Mastra Instance Creation\nDESCRIPTION: Initialization of PgVector database connection and Mastra instance with configured components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Example Filter for Metadata Queries in TypeScript\nDESCRIPTION: This snippet provides an example of a filter query for metadata using various operators. It can be used in queries with the vector store to refine search results based on specific criteria.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  $and: [{ age: { $gt: 25 } }, { tags: { $in: ['tag1', 'tag2'] } }];\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Relevancy Context in Mastra\nDESCRIPTION: Shows evaluation of a response about solar eclipses where some context items are relevant to the query while others are not, resulting in a mid-range relevancy score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Solar eclipses occur when the Moon blocks the Sun.',\n  'The Moon moves between the Earth and Sun during eclipses.',\n  'The Moon is visible at night.',\n  'The Moon has no atmosphere.',\n];\n\nconst metric2 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'What causes solar eclipses?';\nconst response2 = 'Solar eclipses happen when the Moon moves between Earth and the Sun, blocking sunlight.';\n\nconsole.log('Example 2 - Mixed Relevancy:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'The context uses some relevant information and includes some irrelevant information.' }\n```\n\n----------------------------------------\n\nTITLE: Query Pinecone for Top-K Results with Mastra\nDESCRIPTION: This code snippet demonstrates how to query a Pinecone vector database for the top K most similar chunks to a given embedding using Mastra. It initializes an OpenAI embedding model, creates a Pinecone index, upserts embeddings and metadata, and then queries the index using the `query` method with a specified `topK` value. Dependencies include `@ai-sdk/openai`, `@mastra/pinecone`, `@mastra/rag`, and `ai`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/query/retrieve-results.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PineconeVector } from \"@mastra/pinecone\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst pinecone = new PineconeVector(\"your-api-key\");\n\nawait pinecone.createIndex({\n  indexName: \"test_index\",\n  dimension: 1536,\n});\n\nawait pinecone.upsert({\n  indexName: \"test_index\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n\nconst topK = 10;\n\nconst results = await pinecone.query({\n  indexName: \"test_index\",\n  queryVector: embeddings[0],\n  topK,\n});\n\nconsole.log(results);\n```\n\n----------------------------------------\n\nTITLE: Creating Condition-Based Loops with until() Method and Reference Condition\nDESCRIPTION: Shows how to use the until() method with a reference-based condition to repeat a step until a specific data value meets the required criteria, using query operators for comparison.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .until(\n    {\n      ref: { step: incrementStep, path: 'updatedCounter' },\n      query: { $gte: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Reranking Search Results with Cohere in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the rerank function from Mastra's RAG module to improve search results. It utilizes Cohere's reranking service to consider multiple scoring factors, including semantic, vector, and position weights.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/reranking-with-cohere.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { rerank } from \"@mastra/rag\";\n\nconst results = rerank(\n  searchResults,\n  \"deployment configuration\",\n  cohere(\"rerank-v3.5\"),\n  {\n    topK: 5,\n    weights: {\n      semantic: 0.4,\n      vector: 0.4,\n      position: 0.2\n    }\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Connecting and Listing MCP Servers - TypeScript\nDESCRIPTION: This snippet connects to the initialized registry client and lists all available MCP servers along with their details. It prints the registry directory name and homepage, as well as iterates over the servers to display their names and descriptions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst directory = await registry.connect()\nconsole.log(\"Connected to registry:\", directory.name, directory.homepage)\n\nconst allServers = await registry.listServers()\nconsole.log(\"\\nAvailable servers:\")\n\nallServers.forEach((server) => {\n\tconsole.log(`- ${server.name} (${server.id}): ${server.description}`)\n})\n\nconst stripeServer = await registry.getServerDefinition({ id: \"stripe\" })\n```\n\n----------------------------------------\n\nTITLE: Connecting with CompositeVoice\nDESCRIPTION: This snippet shows how to use `connect()` with `CompositeVoice`. The `connect()` method is delegated to the configured real-time provider, in this case, `OpenAIRealtimeVoice`. This allows you to manage multiple voice providers through a single `CompositeVoice` instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.connect.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nconst realtimeVoice = new OpenAIRealtimeVoice();\nconst voice = new CompositeVoice({\n  realtimeProvider: realtimeVoice,\n});\n// これはOpenAIRealtimeVoiceプロバイダーを使用します\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra for Laminar Telemetry\nDESCRIPTION: This TypeScript snippet shows how to configure a Mastra instance to export telemetry data to Laminar using the OpenTelemetry (OTLP) protocol. The `serviceName`, `enabled`, `type`, and `protocol` parameters within the `telemetry.export` configuration determine how Mastra sends data to Laminar.  The protocol is set to gRPC.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/laminar.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n      protocol: \"grpc\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Minimal Coverage with Completeness Metric\nDESCRIPTION: This example illustrates how to evaluate a response that covers very few elements of the input text using the Completeness metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/completeness.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst text3 = 'The seasons include summer.';\nconst reference3 = 'The four seasons are spring, summer, fall, and winter.';\n\nconsole.log('Example 3 - Minimal Coverage:');\nconsole.log('Text:', text3);\nconsole.log('Reference:', reference3);\n\nconst result3 = await metric.measure(reference3, text3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    missingElements: result3.info.missingElements,\n    elementCounts: result3.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.3333333333333333,\n//   info: {\n//     missingElements: [ 'four', 'spring', 'winter', 'be', 'fall', 'and' ],\n//     elementCounts: { input: 9, output: 4 }\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool with Metadata Filtering\nDESCRIPTION: Creates a vector query tool using createVectorQueryTool from @mastra/rag, enabling metadata filtering for efficient retrieval.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  id: 'vectorQueryTool',\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n  enableFilter: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server (Bash)\nDESCRIPTION: These bash commands start the Mastra development server. The first command, `npm run dev`, assumes a script named `dev` is defined in the `package.json` file to start the server. The second command, `mastra dev`, uses the Mastra CLI to start the development server, automatically discovering and serving registered agents via REST API endpoints. This allows developers to test and iterate on their agents locally.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Creating GraphRAG Tool with OpenAI Embeddings\nDESCRIPTION: This snippet demonstrates how to create a GraphRAG tool using the createGraphRAGTool function, configuring it with PgVector and OpenAI embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphRagTool = createGraphRAGTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.7,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Imports for ElevenLabs Voice\nDESCRIPTION: This code snippet demonstrates how to update import statements when switching from the deprecated @mastra/speech-elevenlabs to the new @mastra/voice-elevenlabs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/elevenlabs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n- import { ElevenLabsTTS } from '@mastra/speech-elevenlabs'\n+ import { ElevenLabsVoice } from '@mastra/voice-elevenlabs'\n```\n\n----------------------------------------\n\nTITLE: Registering STT-Enabled Agent with Mastra - TypeScript\nDESCRIPTION: This code snippet demonstrates how to register a STT-enabled agent within a Mastra instance. It imports the necessary Mastra modules and the previously defined `noteTakerAgent`, then registers it with Mastra.  A logger is also created and configured within the Mastra instance for monitoring purposes. Dependencies include `@mastra/core/mastra` and `@mastra/core/logger`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/speech-to-text.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger } from '@mastra/core/logger';\nimport { Mastra } from '@mastra/core/mastra';\n\nimport { noteTakerAgent } from './agents';\n\nexport const mastra = new Mastra({\n  agents: { noteTakerAgent }, // Register the note taker agent\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Audio Utility Functions Implementation\nDESCRIPTION: Helper functions for handling audio operations including saving audio streams to files and converting various input formats to text. Includes error handling and stream processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/adding-voice-capabilities.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * Saves an audio stream to a file\n */\nasync function saveAudioToFile(audio: NodeJS.ReadableStream, filename: string): Promise<void> {\n  const filePath = path.join(process.cwd(), filename);\n  const writer = createWriteStream(filePath);\n  audio.pipe(writer);\n  return new Promise<void>((resolve, reject) => {\n    writer.on('finish', resolve);\n    writer.on('error', reject);\n  });\n}\n\n/**\n * Converts either a string or a readable stream to text\n */\nasync function convertToText(input: string | NodeJS.ReadableStream): Promise<string> {\n  if (typeof input === 'string') {\n    return input;\n  }\n\n  const chunks: Buffer[] = [];\n  return new Promise<string>((resolve, reject) => {\n    input.on('data', chunk => chunks.push(Buffer.from(chunk)));\n    input.on('error', err => reject(err));\n    input.on('end', () => resolve(Buffer.concat(chunks).toString('utf-8')));\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating full alignment with PromptAlignmentMetric (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to evaluate a response that fully adheres to a set of instructions using the `PromptAlignmentMetric`. It defines an array of instructions, creates a `PromptAlignmentMetric` instance with the OpenAI GPT-4o-mini model, sets a query, and a response. It then measures the alignment between the query, response, and instructions, and logs the metric results, including the score, reason, and score details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/prompt-alignment.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions1 = [\n  '完全な文を使用する',\n  '摂氏で温度を含める',\n  '風の状況を言及する',\n  '降水確率を述べる',\n];\n\nconst metric1 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions1,\n});\n\nconst query1 = '天気はどうですか？';\nconst response1 =\n  '温度は摂氏22度で、北西からの穏やかな風があります。雨の確率は30％です。';\n\nconsole.log('例 1 - 完全な整合性:');\nconsole.log('指示:', instructions1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n  details: result1.info.scoreDetails,\n});\n// 例の出力:\n// メトリック結果: { score: 1, reason: '応答はすべての指示に従っています。' }\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of ContextRelevancyMetric in TypeScript\nDESCRIPTION: This code snippet demonstrates the basic usage of the ContextRelevancyMetric class for evaluating context relevance. It initializes the metric with a specified model and context, then measures the relevance of the output against a given input query. The result includes a score and a reason explaining the relevancy assessment. Requires `@ai-sdk/openai` and `@mastra/evals/llm` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-relevancy.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextRelevancyMetric(model, {\n  context: [\n    \"すべてのデータは保存時および転送時に暗号化されます\",\n    \"二要素認証は必須です\",\n    \"プラットフォームは複数の言語をサポートしています\",\n    \"私たちのオフィスはサンフランシスコにあります\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"私たちの製品のセキュリティ機能は何ですか？\",\n  \"私たちの製品は暗号化を使用し、2FAを要求します。\",\n  );\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the relevancy assessment\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with Working Memory in TypeScript\nDESCRIPTION: Sets up a basic agent with working memory enabled using the Mastra core library. The agent is configured with a name, instructions, GPT-4 model, and memory settings with working memory enabled in tool-call mode.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/working-memory.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create agent with working memory enabled\nconst agent = new Agent({\n  name: \"PersonalAssistant\",\n  instructions: \"You are a helpful personal assistant.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory({\n    options: {\n      workingMemory: {\n        enabled: true,\n        use: \"tool-call\", // Recommended setting\n      },\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors with Document Filtering\nDESCRIPTION: This snippet illustrates how to query vectors from a specific collection with additional filtering based on metadata and document content. It shows how to request the top K similar vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst results = await vectorStore.query({\n  indexName: 'myCollection',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10, // topK\n  filter: { text: { $eq: 'doc1' } }, // metadata filter\n  includeVector: false, // includeVector\n  documentFilter: { $contains: 'specific text' } // document content filter\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAIRealtimeVoice with Configuration TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the OpenAIRealtimeVoice class with a custom configuration, including the OpenAI API key, model ID, and session configuration. It also sets the default voice ID for speech synthesis. The configuration allows fine-grained control over the real-time voice interaction settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-speech.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: 'your-openai-api-key',\n    model: 'gpt-4o-mini-realtime',\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: 'server_vad',\n          threshold: 0.6,\n          silence_duration_ms: 1200,\n        },\n      },\n    },\n  },\n  speaker: 'alloy', // デフォルトボイス\n});\n\n// デフォルト設定を使用する場合、設定は以下のように簡略化できます：\nconst voice = new OpenAIRealtimeVoice();\n```\n\n----------------------------------------\n\nTITLE: Initializing PostgresStore\nDESCRIPTION: This code snippet demonstrates how to initialize the PostgresStore class from the @mastra/pg package. It requires a connection string to connect to the PostgreSQL database.  The DATABASE_URL environment variable should contain a valid PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/postgresql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { PostgresStore } from \\\"@mastra/pg\\\";\\n\\nconst storage = new PostgresStore({\\n  connectionString: process.env.DATABASE_URL,\\n});\"\n```\n\n----------------------------------------\n\nTITLE: Using Turbopuffer SDK to Manage Vectors in TypeScript\nDESCRIPTION: Illustrates the use of the Turbopuffer SDK to handle vector store operations, such as creating an index, adding vectors, and querying them. Key parameters include 'apiKey' for authentication, and 'baseUrl' for API endpoint configuration. The code expects dimension and metric specifications for indices and provides options for query filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/turbopuffer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TurbopufferVector } from '@mastra/turbopuffer';\n\nconst vectorStore = new TurbopufferVector({\n  apiKey: 'your-api-key',\n  baseUrl: 'https://gcp-us-central1.turbopuffer.com',\n});\n\n// Create a new index\nawait vectorStore.createIndex({ indexName: 'my-index', dimension: 1536, metric: 'cosine' });\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({ indexName: 'my-index', vectors, metadata });\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my-index',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10,\n  filter: { text: { $eq: 'doc1' } },\n  includeVector: false,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareStore with Workers Bindings\nDESCRIPTION: This snippet demonstrates initializing the `CloudflareStore` class using Workers KV bindings. It imports the `CloudflareStore` class and creates an instance, configuring it with bindings to specific KV Namespaces for different tables. The `keyPrefix` is used for environment isolation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { CloudflareStore } from \\\"@mastra/cloudflare\\\";\n\n// --- Example 1: Using Workers Binding ---\nconst storageWorkers = new CloudflareStore({\n  bindings: {\n    threads: THREADS_KV, // KVNamespace binding for threads table\n    messages: MESSAGES_KV, // KVNamespace binding for messages table\n    // Add other tables as needed\n  },\n  keyPrefix: 'dev_', // Optional: isolate keys per environment\n});\"\n```\n\n----------------------------------------\n\nTITLE: Define RAG Workflow Typescript\nDESCRIPTION: Defines a workflow named `ragWorkflow` using the `Workflow` class from `@mastra/core/workflows`. It sets up a trigger schema using Zod to define the expected input, which includes a `query` parameter of type string. This workflow is designed to handle RAG operations based on the provided query.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragWorkflow = new Workflow({\n  name: \"rag-workflow\",\n  triggerSchema: z.object({\n    query: z.string(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with mcp.run Registry\nDESCRIPTION: This TypeScript code demonstrates how to configure MCP using an SSE URL from the mcp.run registry.  The SSE URL (stored in an environment variable) is used to connect to the MCP server.  It's important to handle the SSE URL like a password since it contains a unique signature.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    marketing: {\n      url: new URL(process.env.MCP_RUN_SSE_URL!),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Reinitialize Workflow with commit() - Typescript\nDESCRIPTION: The `.commit()` method reinitializes the workflow's state machine using the current step configuration. It is used after defining the steps in a workflow to apply the configuration. This example shows how to use `.commit()` after defining steps A and B.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/commit.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n  .then(stepB)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Building Vector Database Indexes with TypeScript\nDESCRIPTION: Demonstrates different ways to build vector indexes including HNSW, IVF, and flat index types with configurable parameters. Each example shows how to initialize an index with specific configurations and distance metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Define HNSW index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"hnsw\",\n  hnsw: {\n    m: 8,\n    efConstruction: 32,\n  },\n});\n\n// Define IVF index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"ivfflat\",\n  ivf: {\n    lists: 100,\n  },\n});\n\n// Define flat index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"flat\",\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Thread Details in TypeScript\nDESCRIPTION: This code demonstrates how to retrieve details about a specific thread using the thread instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await thread.get();\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution (Path Comparison) in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates conditional step execution using a simple path comparison for the `when` property. The `processData` step will only execute if the `fetchData` step's status is \"success\".\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      \"fetchData.status\": \"success\",\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings for RAG\nDESCRIPTION: Generates embeddings for the document chunks and stores them in the PgVector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Toxicity Response\nDESCRIPTION: This TypeScript snippet evaluates a response containing a mix of toxic and professional statements. The response is an array of strings, some dismissive and others constructive. The `ToxicityMetric` provides a score reflecting the mixed nature of the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'How was the meeting discussion?';\nconst response2 = [\n  'Half the meeting was just listening to the marketing team ramble on with their usual clueless suggestions.',\n  \"At least the engineering team's presentation was focused and had some solid technical solutions we can actually use.\"\n];\n\nconsole.log('Example 2 - Mixed Toxicity:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'The response shows a mix of dismissive language towards the marketing team while maintaining professional discourse about the engineering team.' }\n```\n\n----------------------------------------\n\nTITLE: Conceptual React Component for Thread List Management\nDESCRIPTION: This code demonstrates a React component (`ThreadList`) that manages a list of chat threads for a given user.  It uses `useState` and `useEffect` hooks to fetch and update the list of threads.  It includes a button to create new threads.  The component receives `userId`, `currentThreadId`, and `onSelectThread` as props.  It is a conceptual component and assumes the existence of asynchronous functions `fetchThreads` and `createNewThread` for interacting with a backend API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/use-chat.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// スレッドリストの概念的なReactコンポーネント\nimport React, { useState, useEffect } from 'react';\n\n// API関数が存在すると仮定: fetchThreads, createNewThread\nasync function fetchThreads(userId: string): Promise<{ id: string; title: string }[]> { /* ... */ }\nasync function createNewThread(userId: string): Promise<{ id: string; title: string }> { /* ... */ }\n\nfunction ThreadList({ userId, currentThreadId, onSelectThread }) {\n  const [threads, setThreads] = useState([]);\n  // ... ローディングとエラーステート ...\n\n  useEffect(() => {\n    // userIdのスレッドを取得\n  }, [userId]);\n\n  const handleCreateThread = async () => {\n    // createNewThread APIを呼び出し、状態を更新し、新しいスレッドを選択\n  };\n\n  // ... スレッドのリストと新しい会話ボタンでUIをレンダリング ...\n  return (\n     <div>\n       <h2>会話</h2>\n       <button onClick={handleCreateThread}>新しい会話</button>\n       <ul>\n         {threads.map(thread => (\n           <li key={thread.id}>\n             <button onClick={() => onSelectThread(thread.id)} disabled={thread.id === currentThreadId}>\n               {thread.title || `チャット ${thread.id.substring(0, 8)}...`}\n             </button>\n           </li>\n         ))}\n       </ul>\n     </div>\n  );\n}\n\n// 親チャットコンポーネントでの使用例\nfunction ChatApp() {\n  const userId = \"user_123\";\n  const [currentThreadId, setCurrentThreadId] = useState<string | null>(null);\n\n  return (\n    <div style={{ display: 'flex' }}>\n      <ThreadList\n        userId={userId}\n        currentThreadId={currentThreadId}\n        onSelectThread={setCurrentThreadId}\n      />\n      <div style={{ flexGrow: 1 }}>\n        {currentThreadId ? (\n          <Chat threadId={currentThreadId} resourceId={userId} /> // あなたのuseChatコンポーネント\n        ) : (\n          <div>会話を選択または開始してください。</div>\n        )}\n      </div>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Security Review Prompt with TypeScript\nDESCRIPTION: This snippet defines a security review prompt to help review code for security vulnerabilities, specifying the involved variables, constraints, and thinking steps the model should undertake. It relies on the `createPrompt` function to set the persona, style, and other options for generating the prompt.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ntype CodeReviewVars = {\n  code: string;\n  focus: 'security' | 'performance' | 'architecture';\n};\n\nconst securityReviewPrompt = createPrompt<CodeReviewVars>('Review code security', {\n  persona: 'Senior Security Engineer',\n  style: 'thorough',\n  tone: 'professional',\n  outputFormat: 'markdown',\n})\n  .text('Review this code for {{focus}} concerns:\\n\\n{{code}}')\n  .constraints([\n    'Focus on security best practices',\n    'Identify potential vulnerabilities',\n    'Suggest secure alternatives',\n    'Reference relevant security standards',\n  ])\n  .thinking({\n    steps: [\n      'Identify sensitive operations',\n      'Check for common vulnerabilities',\n      'Evaluate security controls',\n      'Assess compliance requirements',\n      'Propose security improvements',\n    ],\n  });\n\n// Usage example\nconst review = securityReviewPrompt.toString({\n  code: `\n    function authenticateUser(username, password) {\n      if (username === 'admin' && password === 'password123') {\n        return true;\n      }\n      return false;\n    }\n  `,\n  focus: 'security',\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Workflow\nDESCRIPTION: Initializes a workflow to orchestrate complex AI tasks with sequential steps\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from '@mastra/core';\n\nconst workflow = new Workflow({\n  name: 'my-workflow',\n  steps: [\n    // Workflow steps\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the specific example directory for the re-ranking RAG project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/rerank\n```\n\n----------------------------------------\n\nTITLE: Deleting Index Vector by ID\nDESCRIPTION: This code demonstrates deleting a single vector from the index using its unique ID. The `deleteIndexById` method is called with the index name and the ID of the vector to be removed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nawait pgVector.deleteIndexById(\"my_vectors\", \"vector123\");\n```\n\n----------------------------------------\n\nTITLE: Saving Messages to Memory in TypeScript\nDESCRIPTION: This snippet demonstrates how to save messages to memory, including message content, role, ID, thread ID, creation time, and type.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst savedMessages = await client.saveMessageToMemory({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Hello!\",\n      id: \"1\",\n      threadId: \"thread-1\",\n      createdAt: new Date(),\n      type: \"text\",\n    },\n  ],\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Thread Properties in TypeScript\nDESCRIPTION: This snippet shows how to update thread properties such as title, metadata, and resource ID using the thread instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst updated = await thread.update({\n  title: \"Updated Title\",\n  metadata: { status: \"resolved\" },\n  resourceid: \"resource-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Examples of Measuring Keyword Coverage in TypeScript\nDESCRIPTION: This snippet showcases multiple examples of using the KeywordCoverageMetric with different input and output pairs to illustrate various coverage scenarios. It highlights a perfect coverage case, a partial coverage case, and a case involving technical terms.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/keyword-coverage.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new KeywordCoverageMetric();\n\n// Perfect coverage example\nconst result1 = await metric.measure(\n  \"The quick brown fox jumps over the lazy dog\",\n  \"A quick brown fox jumped over a lazy dog\"\n);\n// {\n//   score: 1.0,\n//   info: {\n//     matchedKeywords: 6,\n//     totalKeywords: 6\n//   }\n// }\n\n// Partial coverage example\nconst result2 = await metric.measure(\n  \"Python features include easy syntax, dynamic typing, and extensive libraries\",\n  \"Python has simple syntax and many libraries\"\n);\n// {\n//   score: 0.67,\n//   info: {\n//     matchedKeywords: 4,\n//     totalKeywords: 6\n//   }\n// }\n\n// Technical terms example\nconst result3 = await metric.measure(\n  \"Discuss React.js component lifecycle and state management\",\n  \"React components have lifecycle methods and manage state\"\n);\n// {\n//   score: 1.0,\n//   info: {\n//     matchedKeywords: 4,\n//     totalKeywords: 4\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Defining Constructor Options for AstraVector\nDESCRIPTION: Defines the constructor options for the AstraVector class, including the Astra DB API token, endpoint, and an optional keyspace name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"token\",\n      type: \"string\",\n      description: \"Astra DB API token\",\n    },\n    {\n      name: \"endpoint\",\n      type: \"string\",\n      description: \"Astra DB API endpoint\",\n    },\n    {\n      name: \"keyspace\",\n      type: \"string\",\n      isOptional: true,\n      description: \"Optional keyspace name\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Install GitHub Integration\nDESCRIPTION: Installs the GitHub integration package using npm. This command adds the @mastra/github package to the project's dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/github\n```\n\n----------------------------------------\n\nTITLE: Define Candidate Workflow - TypeScript\nDESCRIPTION: Defines the overall candidate workflow by chaining the defined steps and implementing branching logic based on the candidate's technical status. It first gathers candidate information, then asks about the specialty if the candidate is technical, or asks about the role if the candidate is not technical.  Uses the `when` condition to define the branching logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst candidateWorkflow = new Workflow({\n  name: \"candidate-workflow\",\n  triggerSchema: z.object({\n    resumeText: z.string(),\n  }),\n});\n\ncandidateWorkflow\n  .step(gatherCandidateInfo)\n  .then(askAboutSpecialty, {\n    when: { \"gatherCandidateInfo.isTechnical\": true },\n  })\n  .after(gatherCandidateInfo)\n  .step(askAboutRole, {\n    when: { \"gatherCandidateInfo.isTechnical\": false },\n  });\n\ncandidateWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Chaining and Parallelizing Steps in Mastra Workflow - TypeScript\nDESCRIPTION: Demonstrates how to chain steps together using `.then()` to create dependent sequences, and then add these chains to the workflow using `.step()` to execute them in parallel. The `commit()` method finalizes the workflow structure. Then creates a run using the `createRun` method and executes the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/parallel-steps.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(stepOne)\n    .then(stepTwo) // chain one\n  .step(stepThree)\n    .then(stepFour) // chain two\n  .commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst result = await start({ triggerData: { inputValue: 3 } });\n```\n\n----------------------------------------\n\nTITLE: Deleting an Index in AstraVector\nDESCRIPTION: Deletes a specified index from the AstraVector class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to delete\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Get Workflow Details using TypeScript\nDESCRIPTION: This snippet retrieves detailed information about a workflow using the `details` method. The `details` method is called on a workflow object. It returns a promise that resolves with the workflow details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await workflow.details();\n```\n\n----------------------------------------\n\nTITLE: Get Tool Details - TypeScript\nDESCRIPTION: Retrieves detailed information about a specific tool. This method is called on the tool instance obtained previously and requires no parameters to return detailed information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/tools.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await tool.details();\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with PgVector in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize PgVector with a PostgreSQL connection string, create an index, and then upsert embeddings along with their metadata into the vector store. It assumes that you have embeddings and chunks data available.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\nconst store = new PgVector(process.env.POSTGRES_CONNECTION_STRING)\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: GoogleVoice Usage Example\nDESCRIPTION: Demonstrates how to use the GoogleVoice class to initialize the service, generate speech from text, and transcribe audio back to text. It outlines the basic steps for leveraging Google's TTS and Speech-to-Text capabilities within Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/google/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GoogleVoice } from '@mastra/voice-google';\n\n// Initialize with configuration\nconst voice = new GoogleVoice({\n  speechModel: {\n    apiKey: 'your-api-key', // Optional, can use GOOGLE_API_KEY env var\n  },\n  listeningModel: {\n    apiKey: 'your-api-key', // Optional, can use GOOGLE_API_KEY env var\n  },\n  speaker: 'en-US-Standard-F', // Default voice\n});\n\n// List available voices\nconst voices = await voice.getSpeakers();\n\n// Generate speech\nconst audioStream = await voice.speak('Hello from Mastra!', {\n  speaker: 'en-US-Standard-F',\n  languageCode: 'en-US',\n});\n\n// Transcribe speech\nconst text = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Accessing Data Through Context Object: TypeScript\nDESCRIPTION: This snippet shows how to utilize the context object for direct access to step results. The processOrderStep retrieves output from fetchUser based on its execution status, demonstrating handling step data in workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new Step({\n  id: 'processOrder',\n  execute: async ({ context }) => {\n    // Access data from a previous step\n    let userData: { name: string, userId: string };\n    if (context.steps['fetchUser']?.status === 'success') {\n      userData = context.steps.fetchUser.output;\n    } else {\n      throw new Error('User data not found');\n    }\n\n    return {\n      orderId: 'order123',\n      userId: userData.userId,\n      status: 'processing',\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Defining and Resuming a Step with Suspend in Mastra\nDESCRIPTION: This snippet demonstrates defining a workflow step that uses the `suspend` function to pause execution and then resuming it using `run.resume()`. The `reviewStep` is defined with an `execute` function that calls `suspend` when a review is needed. After the workflow is resumed, the code after the `suspend` call is executed, utilizing the updated context data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resume.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// 中断ポイントを持つステップ定義\nconst reviewStep = new Step({\n  id: \"review\",\n  execute: async ({ context, suspend }) => {\n    // 実行の最初の部分\n    const initialAnalysis = analyzeData(context.inputData.data);\n\n    if (initialAnalysis.needsReview) {\n      // ここで実行を中断\n      await suspend({ analysis: initialAnalysis });\n\n      // これは resume() が呼び出された後に実行されるコードです\n      // context.inputData は再開中に提供されたデータを含むようになります\n      return {\n        reviewedData: enhanceWithFeedback(initialAnalysis, context.inputData.feedback)\n      };\n    }\n\n    return { reviewedData: initialAnalysis };\n  }\n});\n\nconst { runId, resume, start } = workflow.createRun();\n\nawait start({\n  inputData: {\n    data: \"some data\"\n  }\n});\n\n// 後で、ワークフローを再開\nconst result = await resume({\n  runId: \"workflow-123\",\n  stepId: \"review\",\n  context: {\n    // このデータは `context.inputData` で利用可能になります\n    feedback: \"良さそうですが、セクション3を改善してください\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Interact with Chef Agent via curl\nDESCRIPTION: This command demonstrates how to interact with the chef agent's API endpoint using `curl`. It sends a POST request with a JSON payload containing a user query. The response includes the agent's generated text based on the query.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/chefAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"I have eggs, flour, and milk. What can I make?\"\n      }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Pinecone Query Result Interface (TypeScript)\nDESCRIPTION: Defines the structure of the query result returned from the `query()` method.  It includes the ID of the matched vector, the similarity score, associated metadata, and optionally the vector itself if `includeVector` is set to true.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pinecone.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key\nDESCRIPTION: Example of environment variable configuration where you need to add your OpenAI API key for the application to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Start Development Server (Mastra CLI)\nDESCRIPTION: Starts the Mastra development server using the Mastra CLI. This will create REST API endpoints for the registered agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Installing Memory Package\nDESCRIPTION: This command installs the @mastra/memory package, which is required to use the memory functionality in Mastra agents. It provides the necessary classes and functions for managing conversation history and context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/agent-memory.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Initialize ContentSimilarityMetric\nDESCRIPTION: This snippet initializes a new instance of the `ContentSimilarityMetric` class. This instance will be used to measure the content similarity between different text inputs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/content-similarity.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ContentSimilarityMetric();\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with LibSQL Storage in TypeScript\nDESCRIPTION: This code snippet demonstrates how to configure a Mastra instance to use LibSQL as the storage provider for workflow snapshots. It initializes a `DefaultStorage` instance with a configuration object that specifies the database URL. The `Mastra` class is then instantiated with the storage configuration and workflow definitions.  Environment variables can be used to define database connection details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { DefaultStorage } from \"@mastra/core/storage/libsql\";\n\nconst mastra = new Mastra({\n  storage: new DefaultStorage({\n    config: {\n      url: \"file:storage.db\", // Local file-based database\n      // For production:\n      // url: process.env.DATABASE_URL,\n      // authToken: process.env.DATABASE_AUTH_TOKEN,\n    },\n  }),\n  workflows: {\n    weatherWorkflow,\n    travelWorkflow,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Custom Metric in Mastra\nDESCRIPTION: Instructions for creating a simple custom metric by extending the Metric class and implementing the measure method. This example checks for word inclusion in the output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/custom-eval.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## Basic example\n\nFor a simple example of creating a custom metric that checks if the output contains certain words, see our [Word Inclusion example](/examples/evals/word-inclusion).\n```\n\n----------------------------------------\n\nTITLE: Upserting Embeddings with Metadata in TypeScript\nDESCRIPTION: Demonstrates how to store embedding vectors with their corresponding metadata in a vector database. The upsert operation updates existing vectors if they share the same ID or creates new ones, automatically handling batching for large datasets.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Store embeddings with their corresponding metadata\nawait store.upsert({\n  indexName: 'myCollection',  // index name\n  vectors: embeddings,       // array of embedding vectors\n  metadata: chunks.map(chunk => ({\n    text: chunk.text,  // The original text content\n    id: chunk.id       // Optional unique identifier\n  }))\n});\n```\n\n----------------------------------------\n\nTITLE: MastraVoice speak() Abstract Method\nDESCRIPTION: The definition of the required speak() abstract method that converts text to speech using the configured speech model. It supports both string and stream inputs and allows overriding the default speaker through options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nabstract speak(\n  input: string | NodeJS.ReadableStream,\n  options?: {\n    speaker?: string;\n    [key: string]: unknown;\n  }\n): Promise<NodeJS.ReadableStream | void>\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors in ChromaVector\nDESCRIPTION: Performs a query against an index to retrieve similar vectors based on a query vector, with options to filter results and include vector representations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to query\",\n    },\n    {\n      name: \"queryVector\",\n      type: \"number[]\",\n      description: \"Query vector to find similar vectors\",\n    },\n    {\n      name: \"topK\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"10\",\n      description: \"Number of results to return\",\n    },\n    {\n      name: \"filter\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"Metadata filters for the query\",\n    },\n    {\n      name: \"includeVector\",\n      type: \"boolean\",\n      isOptional: true,\n      defaultValue: \"false\",\n      description: \"Whether to include vectors in the results\",\n    },\n    {\n      name: \"documentFilter\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"Chroma-specific: Filter to apply on the document content\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Initial RAG Query Implementation\nDESCRIPTION: Implementation of the initial query to establish baseline response quality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst query = 'What are all the technologies mentioned for space exploration?';\nconst originalResponse = await agent.generate(query);\nconsole.log('\\nQuery:', query);\nconsole.log('Response:', originalResponse.text);\n```\n\n----------------------------------------\n\nTITLE: Configuring useChat Hook to Prevent Message Duplication in React\nDESCRIPTION: This code shows how to configure the useChat hook to send only the latest message along with threadId and resourceId to prevent message duplication when using Mastra memory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/use-chat.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// components/Chat.tsx (React Example)\nimport { useChat } from \"ai/react\";\n\nexport function Chat({ threadId, resourceId }) {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: \"/api/chat\", // Your backend endpoint\n    // Pass only the latest message and custom IDs\n    experimental_prepareRequestBody: (request) => {\n      // Ensure messages array is not empty and get the last message\n      const lastMessage = request.messages.length > 0 ? request.messages[request.messages.length - 1] : null;\n\n      // Return the structured body for your API route\n      return {\n        message: lastMessage, // Send only the most recent message content/role\n        threadId,\n        resourceId,\n      };\n    },\n    // Optional: Initial messages if loading history from backend\n    // initialMessages: loadedMessages,\n  });\n\n  // ... rest of your chat UI component\n  return (\n    <div>\n      {/* Render messages */}\n      <form onSubmit={handleSubmit}>\n        <input value={input} onChange={handleInputChange} placeholder=\"Send a message...\" />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing UpstashVector Store in TypeScript\nDESCRIPTION: Demonstrates how to initialize an Upstash vector store with URL and token, create an index with specific dimensions, and upsert vectors with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashVector } from '@mastra/upstash'\n\nconst store = new UpstashVector({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Bias Example\nDESCRIPTION: This snippet shows how to evaluate an objective response with low bias using the BiasMetric. It includes the query, unbiased response, and the measurement using the metric. The score and the reason for the score are logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'What is the best hiring practice?';\nconst response3 =\n  'Effective hiring practices focus on objective criteria such as skills, experience, and demonstrated abilities. Using structured interviews and standardized assessments helps ensure fair evaluation of all candidates based on merit.';\n\nconsole.log('Example 3 - Low Bias:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response does not contain any gender or age-related stereotypes or assumptions.' }\n```\n\n----------------------------------------\n\nTITLE: Resuming a Workflow Execution in Mastra\nDESCRIPTION: This code snippet shows how to resume a paused workflow step using the `run.resume()` method. It takes a `runId`, `stepId`, and a `context` object as parameters, allowing the workflow to continue execution from the point where it was suspended and injecting new data into the step's `inputData` property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resume.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nawait run.resume({\n  runId: \"abc-123\",\n  stepId: \"stepTwo\",\n  context: {\n    secondValue: 100\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Using voice.listen() with OpenAIRealtimeVoice for Real-time transcription\nDESCRIPTION: This code snippet showcases how to use `voice.listen()` with `OpenAIRealtimeVoice` to handle real-time audio transcription. It involves connecting to the real-time voice provider, registering an event listener for 'writing' events, and then passing a microphone stream to `voice.listen()`.  Instead of returning text, the transcribed text is emitted via the 'writing' event.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.listen.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst voice = new OpenAIRealtimeVoice();\nawait voice.connect();\n\n// Register event listener for transcription\nvoice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role}: ${text}`);\n});\n\n// This will emit 'writing' events instead of returning text\nconst microphoneStream = getMicrophoneStream();\nawait voice.listen(microphoneStream);\n```\n\n----------------------------------------\n\nTITLE: Chunking a Document with Recursive Strategy\nDESCRIPTION: Shows how to split a document into smaller, manageable chunks using the `recursive` chunking strategy. The example configures the chunk size, overlap, separator, and metadata extraction options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n  extract: {\n    metadata: true, // オプションでメタデータを抽出\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating response with mixed hallucination (TypeScript)\nDESCRIPTION: This snippet evaluates a response that contains some factual inconsistencies with the provided context. It initializes the HallucinationMetric with a context array and measures the hallucination score of a query and a response that partially contradicts the context. The expected output is a score of 0.5, indicating mixed hallucination.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/hallucination.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  '最初のスター・ウォーズ映画は1977年に公開されました。',\n  'ジョージ・ルーカスが監督しました。',\n  '映画は世界中で7億7500万ドルを稼ぎました。',\n  '映画はチュニジアとイギリスで撮影されました。',\n];\n\nconst metric2 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = '最初のスター・ウォーズ映画について教えてください。';\nconst response2 = '最初のスター・ウォーズ映画は1977年に公開され、ジョージ・ルーカスが監督しました。興行収入は10億ドルを超え、全てカリフォルニアで撮影されました。';\n\nconsole.log('例2 - 混合ハルシネーション:');\nconsole.log('コンテキスト:', context2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 0.5, reason: '応答はいくつかの事実に矛盾しています。' }\n```\n\n----------------------------------------\n\nTITLE: Workflow.until() with Function Condition (TypeScript)\nDESCRIPTION: Shows how to use a function as a condition within the `.until()` method. The function checks the result of a previous step ('increment') and returns true when the value reaches or exceeds 10, stopping the loop. Requires the `context` object to access step results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/until.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .until(async ({ context }) => {\n    const result = context.getStepResult<{ value: number }>('increment');\n    return (result?.value ?? 0) >= 10; // Stop when value reaches or exceeds 10\n  }, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Suspending a Workflow with Custom Metadata (TypeScript)\nDESCRIPTION: This code shows how to suspend a workflow and include custom metadata in the snapshot. The `suspend()` function is called with an object containing a `reason` string, lists of `requiredApprovers`, the `requestedBy` user, an `urgency` string, and an `expires` date. This metadata is stored with the snapshot and is available when resuming the workflow.  This allows capturing additional context with a suspended workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nawait suspend({\n  reason: \"Waiting for customer approval\",\n  requiredApprovers: [\"manager\", \"finance\"],\n  requestedBy: currentUser,\n  urgency: \"high\",\n  expires: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Parallel Step Execution in Mastra Workflow\nDESCRIPTION: Demonstrates how to chain and parallelize workflow steps using Mastra's workflow methods. The code shows two parallel chains being created using .step() and .then() methods, followed by workflow execution with sample input data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(stepOne)\n    .then(stepTwo) // chain one\n  .step(stepThree)\n    .then(stepFour) // chain two\n  .commit();\n\nconst { start } = myWorkflow.createRun();\n\nconst result = await start({ triggerData: { inputValue: 3 } });\n```\n\n----------------------------------------\n\nTITLE: Creating an Index in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the createIndex() method for the TurbopufferVector class, highlighting parameters such as indexName and dimension, and specifying the optional distance metric for similarity search.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to create\",\n    },\n    {\n      name: \"dimension\",\n      type: \"number\",\n      description: \"Vector dimension (must match your embedding model)\",\n    },\n    {\n      name: \"metric\",\n      type: \"'cosine' | 'euclidean' | 'dotproduct'\",\n      isOptional: true,\n      defaultValue: \"cosine\",\n      description: \"Distance metric for similarity search\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Text Stream Mode (Default)\nDESCRIPTION: This code initializes a Memory instance with working memory enabled, using the default text-stream mode.  The `enabled` flag enables the working memory feature, and `use: \"text-stream\"` specifies the mode of operation. This mode injects working memory updates directly into the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      use: \"text-stream\", // this is the default mode\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Telemetry Configuration Example\nDESCRIPTION: Demonstrates how to configure telemetry and logging capabilities using the attachListeners function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { attachListeners } from '@mastra/evals';\n\n// Enable basic evaluation tracking\nawait attachListeners();\n\n// Store evals in Mastra Storage (if storage is enabled)\nawait attachListeners(mastra);\n// Note: When using in-memory storage, evaluations are isolated to the test process.\n// When using file storage, evaluations are persisted and can be queried later.\n```\n\n----------------------------------------\n\nTITLE: Generating Text Response from Agent in TypeScript\nDESCRIPTION: This code demonstrates how to generate a text response from an agent using the `.generate()` method. It sends a user message to the agent and logs the agent's response. The input is an array of messages, and the output is an object containing the generated text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myAgent.generate([\n  { role: \"user\", content: \"Hello, how can you assist me today?\" },\n]);\n\nconsole.log(\"Agent:\", response.text);\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork getAgents() Method in TypeScript\nDESCRIPTION: This code snippet illustrates the `getAgents()` method signature for the AgentNetwork class. It returns an array of specialized agents within the network. The return type is Agent[].\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgents(): Agent[]\n```\n\n----------------------------------------\n\nTITLE: Reference Condition in Workflow.if()\nDESCRIPTION: This snippet demonstrates how to use a reference condition with comparison operators in the `.if()` method. It defines a reference to the `value` property of the `startStep`'s result and checks if it's less than 10 using the `$lt` (less than) operator.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/if.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if({\n    ref: { step: startStep, path: 'value' },\n    query: { $lt: 10 }, // 値が10未満の場合に \"if\" ブランチを実行\n  })\n  .then(ifBranchStep)\n  .else()\n  .then(elseBranchStep);\n```\n\n----------------------------------------\n\nTITLE: Creating GlutenCheckerMetric Class (TypeScript)\nDESCRIPTION: Defines the `GlutenCheckerMetric` class, which extends `Metric`. This class serves as the main interface for evaluating gluten content. It uses the `RecipeCompletenessJudge` to perform the evaluation and provides a score (1 for gluten-free, 0 for containing gluten) and detailed information (gluten sources and reason).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nexport interface MetricResultWithInfo extends MetricResult {\n  info: {\n    reason: string;\n    glutenSources: string[];\n  };\n}\n\nexport class GlutenCheckerMetric extends Metric {\n  private judge: GlutenCheckerJudge;\n  constructor(model: LanguageModel) {\n    super();\n\n    this.judge = new GlutenCheckerJudge(model);\n  }\n\n  async measure(output: string): Promise<MetricResultWithInfo> {\n    const { isGlutenFree, glutenSources } = await this.judge.evaluate(output);\n    const score = await this.calculateScore(isGlutenFree);\n    const reason = await this.judge.getReason({\n      isGlutenFree,\n      glutenSources,\n    });\n\n    return {\n      score,\n      info: {\n        glutenSources,\n        reason,\n      },\n    };\n  }\n\n  async calculateScore(isGlutenFree: boolean): Promise<number> {\n    return isGlutenFree ? 1 : 0;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Faithfulness Metric in TypeScript\nDESCRIPTION: Imports the required dependencies from the OpenAI SDK and Mastra Evals library to use the Faithfulness metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { FaithfulnessMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Evaluate Full Keyword Coverage in TypeScript\nDESCRIPTION: Demonstrates how to use the `KeywordCoverageMetric` to evaluate a response with full keyword coverage. It defines an input and output string, measures the keyword coverage using the `metric.measure` method, and logs the result. The expected output is a score of 1, indicating full coverage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/keyword-coverage.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'JavaScript frameworks like React and Vue';\nconst output1 = 'Popular JavaScript frameworks include React and Vue for web development';\n\nconsole.log('Example 1 - Full Coverage:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    totalKeywords: result1.info.totalKeywords,\n    matchedKeywords: result1.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 1, info: { totalKeywords: 4, matchedKeywords: 4 } }\n```\n\n----------------------------------------\n\nTITLE: Chunking Markdown Documents with Mastra for RAG\nDESCRIPTION: This code demonstrates how to use the MDocument class from the @mastra/rag package to process and chunk a markdown document. The fromMarkdown method creates a document instance from raw markdown text, and the chunk method splits it into smaller, semantically meaningful chunks while preserving header hierarchies and formatting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-markdown.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromMarkdown(\"# Your markdown content...\");\n\nconst chunks = await doc.chunk();\n```\n\n----------------------------------------\n\nTITLE: Combine Mastra and Vercel AI SDK Tools in an Agent\nDESCRIPTION: This code snippet demonstrates how to use both Mastra-style tools and Vercel AI SDK tools within the same agent. It imports the `weatherInfo` tool created using the Vercel AI SDK and Mastra tools, then combines them in the `tools` configuration of the `Agent` constructor. It uses gpt-4 as the model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { weatherInfo } from \"../tools/vercelTool\";\nimport * as mastraTools from \"../tools/mastraTools\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions:\n    \"You are a helpful assistant that provides weather information.\",\n  model: openai(\"gpt-4\"),\n  tools: {\n    weatherInfo, // Vercel tool\n    ...mastraTools, // Mastra tools\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Keyword Coverage Metric\nDESCRIPTION: Creates a new instance of the KeywordCoverageMetric class for evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/keyword-coverage.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new KeywordCoverageMetric();\n```\n\n----------------------------------------\n\nTITLE: Monitoring Workflow State Changes with run.watch() in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the `run.watch()` method to subscribe to state changes during a Mastra workflow execution. The callback function logs the results and active paths, providing insights into the workflow's progress.  The `unsubscribe` function is used to stop the monitoring process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/watch.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst workflow = new Workflow({\n  name: \"document-processor\"\n});\n\nconst run = workflow.createRun();\n\n// 状態の変化を購読する\nconst unsubscribe = run.watch(({results, activePaths}) => {\n  console.log('結果:', results);\n  console.log('アクティブパス:', activePaths);\n});\n\n// ワークフローを実行する\nawait run.start({\n  input: { text: \"このドキュメントを処理する\" }\n});\n\n// 監視を停止する\nunsubscribe();\n```\n\n----------------------------------------\n\nTITLE: Using onFinish Callback in TypeScript\nDESCRIPTION: This code demonstrates how to use the `onFinish` callback while streaming a response from the agent. The `onFinish` callback provides detailed information about the completed interaction, including steps, final text, finish reason, token usage, and reasoning details. This is useful for monitoring and logging purposes. The callback is triggered after the LLM finishes generating the response and all tool executions are complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onFinish: ({\n      steps,\n      text,\n      finishReason, // 'complete', 'length', 'tool'など\n      usage, // トークン使用統計\n      reasoningDetails, // エージェントの決定に関する追加コンテキスト\n    }) => {\n      console.log(\"Stream complete:\", {\n        totalSteps: steps.length,\n        finishReason,\n        usage,\n      });\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Realtime Voice Event Handling in Mastra\nDESCRIPTION: This snippet demonstrates how to listen for events emitted by a real-time voice provider in a Mastra agent. It shows how to handle `speaking`, `writing`, and `error` events, including accessing audio data, transcribed text, and error messages. Dependencies include the agent instance (`agent`) with a connected real-time voice provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Listen for speech audio data sent from voice provider\nagent.voice.on(\"speaking\", ({ audio }) => {\n  // audio contains ReadableStream or Int16Array audio data\n});\n\n// Listen for transcribed text sent from both voice provider and user\nagent.voice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role} said: ${text}`);\n});\n\n// Listen for errors\nagent.voice.on(\"error\", (error) => {\n  console.error(\"Voice error:\", error);\n});\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution of Nested Workflows in TypeScript\nDESCRIPTION: Demonstrates two methods for executing multiple nested workflows in parallel using either the after() method or step() with an array.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow\n  .step(nestedWorkflowA)\n  .step(nestedWorkflowB)\n  .after([nestedWorkflowA, nestedWorkflowB])\n  .step(finalStep);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow.step([nestedWorkflowA, nestedWorkflowB]).then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Updating Code Syntax for ElevenLabs Voice\nDESCRIPTION: This snippet illustrates the necessary changes in object instantiation and method calls when migrating from the deprecated package to the new voice package. Adjustments include changes in the API structure and methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/elevenlabs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n- const tts = new ElevenLabsTTS({\n-   model: {\n-     name: 'Adam',\n-     apiKey: 'your-api-key'\n-   }\n- });\n+ const voice = new ElevenLabsVoice({\n+   speechModel: {\n+     name: 'eleven_multilingual_v2',\n+     apiKey: 'your-api-key'\n+   },\n+   speaker: 'Adam'\n+ });\n\n- const voices = await tts.voices();\n+ const speakers = await voice.getSpeakers();\n\n- const result = await tts.generate({ voice: 'Adam', text: 'Hello' });\n+ const stream = await voice.speak('Hello', { speaker: 'Adam' });\n```\n\n----------------------------------------\n\nTITLE: Workflow with Trigger Schema in Typescript\nDESCRIPTION: This code snippet shows how to define a trigger schema for a workflow using Zod in Typescript. The trigger schema is used to validate the initial data passed to the workflow and provides TypeScript types for workflow inputs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: \"order-process\",\n  triggerSchema: z.object({\n    orderId: z.string(),\n    customer: z.object({\n      id: z.string(),\n      email: z.string().email(),\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring ElevenLabs Voice with environment variables\nDESCRIPTION: This snippet shows how to configure the ElevenLabs voice module by setting an environment variable for the API key necessary for authentication. It requires the user to have an API key provided by ElevenLabs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nELEVENLABS_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Mapping from Trigger Data in Mastra Workflow\nDESCRIPTION: Provides an example of how to map data from the workflow trigger to a step in a Mastra workflow, demonstrating the use of variable mapping from trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Define a step that needs user input\nconst processUserInput = new Step({\n  id: \"processUserInput\",\n  execute: async ({ context }) => {\n    // The inputData will be available in context because of the variable mapping\n    const { inputData } = context.inputData;\n\n    return {\n      processedData: `Processed: ${inputData}`\n    };\n  },\n});\n\n// Create the workflow\nconst workflow = new Workflow({\n  name: \"trigger-mapping\",\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\n// Map the trigger data to the step\nworkflow\n  .step(processUserInput, {\n    variables: {\n      inputData: { step: 'trigger', path: 'inputData' },\n    }\n  })\n  .commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Querying PgVector with Metadata Filters\nDESCRIPTION: This snippet demonstrates querying a PgVector store using metadata filters. It showcases simple equality, numerical comparison, and array membership using MongoDB/Sift-like query syntax. The query is executed against the `my_index` index with a specified `queryVector` and returns the top 10 results (`topK: 10`).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/metadata-filters.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\nconst store = new PgVector(connectionString);\n\nconst results = await store.query({\n  indexName: \"my_index\",\n  queryVector: queryVector,\n  topK: 10,\n  filter: {\n    category: \"electronics\",  // 単純な等価\n    price: { $gt: 100 },     // 数値比較\n    tags: { $in: [\"sale\", \"new\"] }  // 配列メンバーシップ\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Using Deployer in a TypeScript Project\nDESCRIPTION: This snippet shows how to import and create an instance of the Deployer from @mastra/deployer, configuring it with a project path and deployment type to manage dependencies and write configuration files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/server/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Deployer } from '@mastra/deployer';\n\n// Create a deployer instance\nconst deployer = new Deployer({\n  dir: '/path/to/project',\n  type: 'Deploy', // or 'Dev' for development mode\n});\n\n// Install dependencies\nawait deployer.install();\n\n// Write package.json\nawait deployer.writePackageJson();\n\n// Get Mastra instance\nconst { mastra } = await deployer.getMastra();\n```\n\n----------------------------------------\n\nTITLE: Sequential Execution with Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to chain steps in a Mastra workflow so that they execute in a specific order. Each step's output becomes the input of the next step, ensuring dependencies are met.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(fetchOrderData).then(validateData).then(processOrder);\n```\n\n----------------------------------------\n\nTITLE: Defining the IndexStats interface\nDESCRIPTION: This code defines the `IndexStats` interface, which represents the structure of the information returned when describing an index. It includes properties for dimension, count, and metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/libsql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Document from Text Content in TypeScript\nDESCRIPTION: This code demonstrates how to create an MDocument instance from a text string containing information about the benefits of regular exercise.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/metadata-extraction.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`Title: The Benefits of Regular Exercise\n\nRegular exercise has numerous health benefits. It improves cardiovascular health, \nstrengthens muscles, and boosts mental wellbeing.\n\nKey Benefits:\n• Reduces stress and anxiety\n• Improves sleep quality\n• Helps maintain healthy weight\n• Increases energy levels\n\nFor optimal results, experts recommend at least 150 minutes of moderate exercise \nper week.`);\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra for RAG\nDESCRIPTION: Creates instances of PgVector and Mastra with the configured components for the RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n  workflows: { ragWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with Traceloop using TypeScript\nDESCRIPTION: This code snippet shows how to configure Mastra to use Traceloop for telemetry data export. It initializes a `Mastra` instance with telemetry settings, specifying the service name, enabling telemetry, and setting the export type to OTLP (OpenTelemetry Protocol).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/traceloop.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Query Object Condition in Mastra Workflow (Typescript)\nDESCRIPTION: This snippet illustrates how to define a step condition using a query object. It references the 'status' property of the 'auth' step's output and uses the `$eq` operator to check if it's equal to 'authenticated'. The 'processOrder' step executes only when this condition is met.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-condition.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: {\n    ref: { step: 'auth', path: 'status' },\n    query: { $eq: 'authenticated' }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: TTS with Sarvam Voice Agent\nDESCRIPTION: This code shows how to use an Agent with Sarvam voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Sarvam's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { SarvamVoice } from \"@mastra/voice-sarvam\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new SarvamVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Analysis of LLM-Generated Summary in TypeScript\nDESCRIPTION: This snippet provides an analysis of a Tesla-related summary using the `SummarizationMetric`. The code evaluates the LLM's generated summary against the source text, illustrating the generation of a score reflecting factual accuracy and coverage. It highlights where the summary succeeds and fails in accuracy and completeness.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/summarization.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new SummarizationMetric(model);\n\nconst result = await metric.measure(\n  \"The electric car company Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning. Elon Musk joined in 2004 as the largest investor and became CEO in 2008. The company's first car, the Roadster, was launched in 2008.\",\n  \"Tesla, founded by Elon Musk in 2003, revolutionized the electric car industry starting with the Roadster in 2008.\"\n);\n\n// Example output:\n// {\n//   score: 0.5,\n//   info: {\n//     reason: \"The score is 0.5 because while the coverage is good (0.75) - mentioning the founding year, first car model, and launch date - the alignment score is lower (0.5) due to incorrectly attributing the company's founding to Elon Musk instead of Martin Eberhard and Marc Tarpenning. The final score takes the minimum of these two scores to ensure both factual accuracy and coverage are necessary for a good summary.\"\n//     alignmentScore: 0.5,\n//     coverageScore: 0.75,\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Qdrant with Mastra (TSX)\nDESCRIPTION: This code snippet explains how to create a collection (index) and upsert embeddings into a Qdrant vector database using the `QdrantVector` class from the `@mastra/qdrant` package. It relies on the `openai` package to create embeddings and `MDocument` from `@mastra/rag` to handle text chunks.  The `QDRANT_URL` and `QDRANT_API_KEY` environment variables are required for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { QdrantVector } from '@mastra/qdrant';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n  maxRetries: 3,\n});\n\nconst qdrant = new QdrantVector(\n  process.env.QDRANT_URL,\n  process.env.QDRANT_API_KEY,\n);\n\nawait qdrant.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait qdrant.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: CompletenessMetric Example with Analysis in TypeScript\nDESCRIPTION: Provides an example usage of the CompletenessMetric class, demonstrating how to measure the completeness of a simple sentence. The example includes the expected output, showing the score and detailed information about the input elements, output elements, missing elements, and element counts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/completeness.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new CompletenessMetric();\n\nconst result = await metric.measure(\n  \"The quick brown fox jumps over the lazy dog\",\n  \"A brown fox jumped over a dog\"\n);\n\n// 例の出力:\n// {\n//   score: 0.75,\n//   info: {\n//     inputElements: [\"quick\", \"brown\", \"fox\", \"jump\", \"lazy\", \"dog\"],\n//     outputElements: [\"brown\", \"fox\", \"jump\", \"dog\"],\n//     missingElements: [\"quick\", \"lazy\"],\n//     elementCounts: { input: 6, output: 4 }\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Main Application Logic\nDESCRIPTION: Orchestrates the voice conversation, recording, Cloudinary upload, and Roark Analytics integration.  It initializes the conversation, handles recording, uploads the recording to Cloudinary, sends data to Roark Analytics, and logs the analysis results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Roark } from '@roarkanalytics/sdk';\nimport chalk from 'chalk';\n\nimport { mastra } from './mastra';\nimport { createConversation, formatToolInvocations } from './utils';\nimport { uploadToCloudinary } from './upload';\nimport fs from 'fs';\n\nconst client = new Roark({\n    bearerToken: process.env.ROARK_API_KEY\n});\n\nasync function speechToSpeechServerExample() {\n    const { start, stop } = createConversation({\n        mastra,\n        recordingPath: './speech-to-speech-server.mp3',\n        providerOptions: {},\n        initialMessage: 'Howdy partner',\n        onConversationEnd: async (props) => {\n            // File upload\n            fs.writeFileSync(props.recordingPath, props.audioBuffer)\n            const url = await uploadToCloudinary(props.recordingPath)\n\n            // Send to Roark\n            console.log('Send to Roark', url)\n            const response = await client.callAnalysis.create({\n                recordingUrl: url,\n                startedAt: props.startedAt,\n                callDirection: 'INBOUND',\n                interfaceType: 'PHONE',\n                participants: [\n                    { role: 'AGENT', spokeFirst: props.agent.spokeFirst, name: props.agent.name, phoneNumber: props.agent.phoneNumber },\n                    { role: 'CUSTOMER', name: 'Yujohn Nattrass', phoneNumber: '987654321' },\n                ],\n                properties: props.metadata,\n                toolInvocations: formatToolInvocations(props.toolInvocations),\n            });\n\n            console.log('Call Recording Posted:', response.data);\n        },\n        onWriting: (ev) => {\n            if (ev.role === 'assistant') {\n                process.stdout.write(chalk.blue(ev.text));\n            }\n        },\n    });\n\n    await start();\n\n    process.on('SIGINT', async (e) => {\n        await stop();\n    })\n}\n\nspeechToSpeechServerExample().catch(console.error)\n```\n\n----------------------------------------\n\nTITLE: Configuring Routes for Cloudflare Worker\nDESCRIPTION: This TypeScript snippet shows how to configure routes for directing traffic to your Cloudflare Worker based on URL patterns and domains, enhancing the application's routing capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/cloudflare.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst routes = [\n  {\n    pattern: 'api.example.com/*',\n    zone_name: 'example.com',\n    custom_domain: true,\n  },\n  {\n    pattern: 'example.com/api/*',\n    zone_name: 'example.com',\n  },\n];\n```\n\n----------------------------------------\n\nTITLE: Processing Audio and Transcribing with STT - TypeScript\nDESCRIPTION: This snippet explains how to process audio from a web request and transcribe it using the agent's STT capabilities. It extracts the audio file from the request's form data, converts it to a readable stream, retrieves the note taker agent, and transcribes the audio using the agent's `voice?.listen()` method. Dependencies include `node:stream` and the Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/speech-to-text.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from '@/src/mastra'; // Import the Mastra instance\nimport { Readable } from 'node:stream';\n\nexport async function POST(req: Request) {\n  // Get the audio file from the request\n  const formData = await req.formData();\n  const audioFile = formData.get('audio') as File;\n  const arrayBuffer = await audioFile.arrayBuffer();\n  const buffer = Buffer.from(arrayBuffer);\n  const readable = Readable.from(buffer);\n\n  // Get the note taker agent from the Mastra instance\n  const noteTakerAgent = mastra.getAgent('noteTakerAgent');\n \n  // Transcribe the audio file\n  const text = await noteTakerAgent.voice?.listen(readable);\n\n  return new Response(JSON.stringify({ text }), {\n    headers: { 'Content-Type': 'application/json' },\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio Input in Mastra\nDESCRIPTION: This snippet demonstrates how to transcribe an audio file using the `listen` method of a Mastra agent's voice interface. It reads the audio file as a stream using `createReadStream` and passes it to the `listen` method for transcription. It includes error handling for transcription failures. Dependencies include `fs` and `path`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\n\n// Read audio file and transcribe\nconst audioFilePath = path.join(process.cwd(), \"/agent.m4a\");\nconst audioStream = createReadStream(audioFilePath);\n\ntry {\n  console.log(\"Transcribing audio file...\");\n  const transcription = await agent.voice.listen(audioStream, {\n    filetype: \"m4a\",\n  });\n  console.log(\"Transcription:\", transcription);\n} catch (error) {\n  console.error(\"Error transcribing audio:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: SummarizationMetric Usage with Analysis\nDESCRIPTION: Illustrates the usage of the SummarizationMetric with an example, showing the detailed output including score, reason, alignment score, and coverage score. It showcases how the metric evaluates both the factual accuracy (alignment) and the information coverage of a summary.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/summarization.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\n\n// モデルを評価用に設定\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new SummarizationMetric(model);\n\nconst result = await metric.measure(\n  \"電気自動車会社Teslaは2003年にMartin EberhardとMarc Tarpenningによって設立されました。Elon Muskは2004年に最大の投資家として参加し、2008年にCEOになりました。会社の最初の車であるRoadsterは2008年に発売されました。\",\n  \"Teslaは2003年にElon Muskによって設立され、2008年にRoadsterで電気自動車業界を革新しました。\",\n);\n\n// 出力例:\n// {\n//   score: 0.5,\n//   info: {\n//     reason: \"スコアが0.5である理由は、カバレッジが良好（0.75）である一方で、\n//           設立年、最初の車種、発売日を言及しているが、\n//           会社の設立をElon Muskに誤って帰属しているため、\n//           アライメントスコアが低い（0.5）からです。\n//           最終スコアはこれら二つのスコアの最小値を取り、\n//           事実の正確性とカバレッジの両方が良い要約に必要であることを保証します。\"\n//     alignmentScore: 0.5,\n//     coverageScore: 0.75,\n//   }\n// }\n\n```\n\n----------------------------------------\n\nTITLE: Evaluate Partial Coverage with CompletenessMetric\nDESCRIPTION: Demonstrates evaluating a text that partially covers the reference.  It defines a reference and text, then measures the completeness score using the CompletenessMetric. This shows how the score decreases when elements are missing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/completeness.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst text2 = 'The primary colors are red and blue.';\nconst reference2 = 'The primary colors are red, blue, and yellow.';\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Text:', text2);\nconsole.log('Reference:', reference2);\n\nconst result2 = await metric.measure(reference2, text2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    missingElements: result2.info.missingElements,\n    elementCounts: result2.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.875, info: { missingElements: ['yellow'], elementCounts: { input: 8, output: 7 } } }\n```\n\n----------------------------------------\n\nTITLE: Get Memory Status (TypeScript)\nDESCRIPTION: Retrieves the status of the memory system for a given agent. Requires agentId. Returns an object indicating the memory system's status.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst status = await client.getMemoryStatus(\"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Initializing SarvamVoice with Configuration TypeScript\nDESCRIPTION: This snippet shows how to initialize the SarvamVoice class with both default settings using environment variables and specific configurations for speech and listening models. It demonstrates setting API keys, models, languages, and voice properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/sarvam.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SarvamVoice } from \"@mastra/voice-sarvam\";\n\n// 環境変数を使用してデフォルト設定で初期化\nconst voice = new SarvamVoice();\n\n// または特定の設定で初期化\nconst voiceWithConfig = new SarvamVoice({\n   speechModel: {\n    model: \"bulbul:v1\",\n    apiKey: process.env.SARVAM_API_KEY!,\n    language: \"en-IN\",\n    properties: {\n      pitch: 0,\n      pace: 1.65,\n      loudness: 1.5,\n      speech_sample_rate: 8000,\n      enable_preprocessing: false,\n      eng_interpolation_wt: 123,\n    },\n  },\n  listeningModel: {\n    model: \"saarika:v2\",\n    apiKey: process.env.SARVAM_API_KEY!,\n    languageCode: \"en-IN\",\n     filetype?: 'wav';\n  },\n  speaker: \"meera\", // デフォルトの声\n});\n```\n\n----------------------------------------\n\nTITLE: Comparing Initial and Re-ranked Results\nDESCRIPTION: Prints both initial and re-ranked results to demonstrate the improvement in retrieval quality, showing scores for semantic relevance, vector similarity, and position for each result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconsole.log('Initial Results:');\ninitialResults.forEach((result, index) => {\n  console.log(`Result ${index + 1}:`, {\n    text: result.metadata.text,\n    score: result.score,\n  });\n});\n\nconsole.log('Re-ranked Results:');\nrerankedResults.forEach(({ result, score, details }, index) => {\n  console.log(`Result ${index + 1}:`, {\n    text: result.metadata.text,\n    score: score,\n    semantic: details.semantic,\n    vector: details.vector,\n    position: details.position,\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Getting All Workflows using TypeScript\nDESCRIPTION: This snippet retrieves a list of all available workflows using the `getWorkflows` method. It requires an initialized `client` object that provides access to the Workflows API.  The function returns a list of workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflows = await client.getWorkflows();\n```\n\n----------------------------------------\n\nTITLE: Initialize Project and Install Dependencies (Bash)\nDESCRIPTION: Initializes a new Node.js project and installs the necessary dependencies for the research assistant, including @mastra/core, @mastra/rag, @mastra/pg, @ai-sdk/openai, ai, and zod.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir research-assistant\ncd research-assistant\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y\nnpm install @mastra/core @mastra/rag @mastra/pg @ai-sdk/openai ai zod\n```\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/agents\ntouch src/mastra/agents/researchAgent.ts\ntouch src/mastra/index.ts src/store.ts src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Set Environment Variables (Bash)\nDESCRIPTION: Sets the environment variables required for API access and database connection. Requires an OpenAI API key and a PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nPOSTGRES_CONNECTION_STRING=your_connection_string\n```\n\n----------------------------------------\n\nTITLE: Evaluate Partial Keyword Coverage in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a response with partial keyword coverage. An input and output are defined, and the `metric.measure` method calculates the keyword coverage score. The expected output demonstrates that only some keywords are covered, resulting in a score between 0 and 1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/keyword-coverage.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'TypeScript offers interfaces, generics, and type inference';\nconst output2 = 'TypeScript provides type inference and some advanced features';\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    totalKeywords: result2.info.totalKeywords,\n    matchedKeywords: result2.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.5, info: { totalKeywords: 6, matchedKeywords: 3 } }\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAI Voice Integration with Custom Configurations\nDESCRIPTION: This TypeScript snippet demonstrates the initialization of the PlayAIVoice class with a custom speech model configuration. Here, you can specify the API key, user ID, and speaker options, falling back to environment variables as needed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new PlayAIVoice({\n  speechModel: {\n    name: 'PlayDialog', // Optional, defaults to 'PlayDialog'\n    apiKey: 'your-api-key', // Optional, can use PLAYAI_API_KEY env var\n    userId: 'your-user-id', // Optional, can use PLAYAI_USER_ID env var\n  },\n  speaker: 's3://voice-cloning-zero-shot/baf1ef41-36b6-428c-9bdf-50ba54682bd8/original/manifest.json', // Optional, defaults to first available voice\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing MastraClient in NextJS\nDESCRIPTION: Creating a client instance to connect to the Mastra backend service from a NextJS application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from '@mastra/client-js';\n\n// Initialize the client\nexport const mastraClient = new MastraClient({\n  baseUrl: process.env.NEXT_PUBLIC_MASTRA_API_URL || 'http://localhost:4111',\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAG Tool with Custom Description (TypeScript)\nDESCRIPTION: This snippet illustrates how to initialize `createGraphRAGTool` with a custom description.  By providing a tailored description, the tool's purpose is customized to align with specific application context, such as focusing on analyzing historical data for pattern identification within a company's documents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/graph-rag-tool.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  description: \"Analyze document relationships to find complex patterns and connections in our company's historical data\"\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow.while() with Function Condition\nDESCRIPTION: Illustrates using a function as a condition within the `.while()` method.  The function accesses the workflow context to evaluate a result from a previous step, determining whether to continue the loop. Requires a workflow, `incrementStep`, `finalStep`, and a step that produces a result with a 'value' property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/while.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(async ({ context }) => {\n    const result = context.getStepResult<{ value: number }>('increment');\n    return (result?.value ?? 0) < 10; // Continue as long as value is less than 10\n  }, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for RAG Workflow\nDESCRIPTION: Imports necessary dependencies for the RAG system, including Mastra core components, OpenAI, PgVector, and other utilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { PgVector } from \"@mastra/pg\";\nimport { createVectorQueryTool, MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Suspending Workflow Execution in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to use the `suspend()` function within a Mastra workflow step to pause execution when a certain condition is met. The workflow will wait for explicit resumption.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/suspend.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst approvalStep = new Step({\n  id: \"needsApproval\",\n  execute: async ({ context, suspend }) => {\n    if (context.steps.amount > 1000) {\n      await suspend();\n    }\n    return { approved: true };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Properties in Mastra Workflow Variables\nDESCRIPTION: Shows how to access nested properties using dot notation in the 'path' field when mapping variables in a Mastra workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(step1)\n  .then(step2, {\n    variables: {\n      // Access a nested property from step1's output\n      nestedValue: { step: step1, path: 'nested.deeply.value' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Chaining Multiple Processors in Mastra\nDESCRIPTION: This snippet shows how to chain multiple processors together by specifying them in the `processors` array of the `Memory` constructor. The processors are executed in the order they appear in the array. The `TokenLimiter` should be placed last for accurate token limiting after other filters are applied.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/memory-processors.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { ToolCallFilter, TokenLimiter } from \"@mastra/memory/processors\";\n// Assume a hypothetical 'PIIFilter' custom processor exists\n// import { PIIFilter } from './custom-processors';\n\nconst memoryWithMultipleProcessors = new Memory({\n  processors: [\n    // 1. Filter specific tool calls first\n    new ToolCallFilter({ exclude: [\"verboseDebugTool\"] }),\n    // 2. Apply custom filtering (e.g., remove hypothetical PII - use with caution)\n    // new PIIFilter(),\n    // 3. Apply token limiting as the final step\n    new TokenLimiter(127000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Thread by ID with Memory in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to use the getThreadById function from the Mastra's core memory library. It requires the Memory class to be imported from '@mastra/core/memory', and needs a valid configuration passed during instantiation. The key parameter is 'threadId', which is a mandatory string representing the ID of the thread to be retrieved. The function returns a promise resolving to the desired thread object or null if no matching thread is found.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/getThreadById.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/core/memory\";\n\nconst memory = new Memory(config);\n\nconst thread = await memory.getThreadById({ threadId: \"thread-123\" });\n```\n\n----------------------------------------\n\nTITLE: Generating Story Content and TTS (Mastra)\nDESCRIPTION: This code snippet demonstrates generating story content and converting it to speech using the Mastra client. It takes form data as input, retrieves a Mastra agent, constructs a message with story details, generates a story response using the agent, converts the story text to speech using the agent's voice, and updates the story state with the generated content and audio. It also handles potential errors and loading states.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst handleInitialSubmit = async (formData: FormData) => {\n  setIsLoading(true);\n  try {\n    const agent = mastraClient.getAgent('storyTellerAgent');\n    const message = `Current phase: BEGINNING. Story genre: ${formData.genre}, Protagonist name: ${formData.protagonistDetails.name}, Protagonist age: ${formData.protagonistDetails.age}, Protagonist gender: ${formData.protagonistDetails.gender}, Protagonist occupation: ${formData.protagonistDetails.occupation}, Story Setting: ${formData.setting}`;\n    const storyResponse = await agent.generate({\n      messages: [{ role: 'user', content: message }],\n      threadId: storyState.threadId,\n      resourceId: storyState.resourceId,\n    });\n\n    const storyText = storyResponse.text;\n\n    const audioResponse = await agent.voice.speak(storyText);\n\n    if (!audioResponse.body) {\n      throw new Error('No audio stream received');\n    }\n\n    const audio = await readStream(audioResponse.body);\n\n    setStoryState(prev => ({\n      phase: 'beginning',\n      threadId: prev.threadId,\n      resourceId: prev.resourceId,\n      content: {\n        ...prev.content,\n        beginning: storyText,\n      },\n    }));\n\n    setAudioBlob(audio);\n    return audio;\n  } catch (error) {\n    console.error('Error generating story beginning:', error);\n  } finally {\n    setIsLoading(false);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Workflow Run State Monitoring with run.watch() in Typescript\nDESCRIPTION: This code demonstrates how to use the `run.watch()` function to subscribe to state changes in a Mastra workflow run. It imports the `Workflow` class, creates a new workflow and run, and then uses `run.watch()` to log results and active paths to the console. The `unsubscribe` function is used to stop monitoring state changes after the workflow is started.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/watch.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst workflow = new Workflow({\n  name: \"document-processor\"\n});\n\nconst run = workflow.createRun();\n\n// Subscribe to state changes\nconst unsubscribe = run.watch(({results, activePaths}) => {\n  console.log('Results:', results);\n  console.log('Active paths:', activePaths);\n});\n\n// Run the workflow\nawait run.start({\n  input: { text: \"Process this document\" }\n});\n\n// Stop watching\nunsubscribe();\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Agent with PgVector Prompt in TypeScript\nDESCRIPTION: This snippet demonstrates how to set up a RAG (Retrieval-Augmented Generation) agent using the PgVector prompt. It includes the agent configuration with instructions and the vector query tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PGVECTOR_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${PGVECTOR_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Updating imports for migration (typescript)\nDESCRIPTION: This code snippet shows the changes required for imports when migrating from @mastra/speech-deepgram to @mastra/voice-deepgram. It highlights the change from DeepgramTTS to DeepgramVoice.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/deepgram/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Old\nimport { DeepgramTTS } from '@mastra/speech-deepgram';\n// New\nimport { DeepgramVoice } from '@mastra/voice-deepgram';\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in Environment File\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file, which is required for the context precision evaluation to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Precision Context Usage\nDESCRIPTION: This example demonstrates evaluating a response where all context information is relevant. It creates a ContextPrecisionMetric instance with photosynthesis-related context and measures how precisely the response uses that context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-precision.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'Photosynthesis converts sunlight into energy.',\n  'Plants use chlorophyll for photosynthesis.',\n  'Photosynthesis produces oxygen as a byproduct.',\n  'The process requires sunlight and chlorophyll.',\n];\n\nconst metric1 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'What is photosynthesis and how does it work?';\nconst response1 = 'Photosynthesis is a process where plants convert sunlight into energy using chlorophyll, producing oxygen as a byproduct.';\n\nconsole.log('Example 1 - High Precision:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The context uses all relevant information and does not include any irrelevant information.' }\n```\n\n----------------------------------------\n\nTITLE: Perfect Alignment Evaluation Example\nDESCRIPTION: Implementation of prompt alignment evaluation for a response that perfectly follows all instructions. Demonstrates setup of instructions, metric configuration, and evaluation of weather-related response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions1 = [\n  'Use complete sentences',\n  'Include temperature in Celsius',\n  'Mention wind conditions',\n  'State precipitation chance',\n];\n\nconst metric1 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions1,\n});\n\nconst query1 = 'What is the weather like?';\nconst response1 =\n  'The temperature is 22 degrees Celsius with moderate winds from the northwest. There is a 30% chance of rain.';\n\nconsole.log('Example 1 - Perfect Alignment:');\nconsole.log('Instructions:', instructions1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n  details: result1.info.scoreDetails,\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow.while() Usage Example (Basic)\nDESCRIPTION: Demonstrates the basic usage of the `.while()` method in a Mastra workflow to create a loop. It repeats a step as long as a condition is true, then continues to the next step in the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/while.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(condition, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: resumeWithEvent() Syntax - TypeScript\nDESCRIPTION: Shows the syntax for the `resumeWithEvent()` method, which resumes a suspended workflow execution by providing data for a specific event.  The workflow must have been suspended at an event step. It returns a Promise resolving to a WorkflowRunResult object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resumeWithEvent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst run = workflow.createRun();\n\n// ワークフローが開始され、イベントステップで一時停止した後\nawait run.resumeWithEvent(eventName: string, data: any): Promise<WorkflowRunResult>\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector with Configuration Object\nDESCRIPTION: This code shows how to initialize the `PgVector` class using a configuration object. The object includes the connection string and an optional schema name.  This provides flexibility for specifying the schema used by the vector store. It is the second way to instantiate `PgVector`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\n// 設定オブジェクトを使用する方法（オプションのschemaNameを含む）\nconst vectorStore2 = new PgVector({\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\n  schemaName: 'custom_schema', // オプション\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Query Result Interface\nDESCRIPTION: This code defines the `QueryResult` interface, which represents the structure of the objects returned by query operations. It includes the ID, score, metadata, and optionally the vector itself, if `includeVector` is true. The metadata is a key-value pair object containing the data attached to a given vector during upsert.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Extending Deployer for Custom Deployment in TypeScript\nDESCRIPTION: This code snippet demonstrates how to extend the Deployer abstract class to create a custom deployer. This involves implementing the required deploy method, which packages an application for deployment. The snippet requires @mastra/deployer and is implemented in TypeScript.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/deployer.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Deployer } from \"@mastra/deployer\";\n\n// Create a custom deployer by extending the abstract Deployer class\nclass CustomDeployer extends Deployer {\n  constructor() {\n    super({ name: 'custom-deployer' });\n  }\n\n  // Implement the abstract deploy method\n  async deploy(outputDirectory: string): Promise<void> {\n    // Prepare the output directory\n    await this.prepare(outputDirectory);\n    \n    // Bundle the application\n    await this._bundle('server.ts', 'mastra.ts', outputDirectory);\n    \n    // Custom deployment logic\n    // ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Workflow Errors in Typescript\nDESCRIPTION: This code snippet illustrates how to handle workflow errors, specifically validation errors, using a try-catch block in Typescript.  It shows how to identify the type of validation error and access details about the error.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const { runId, start, watch, resume } = workflow.createRun();\n  await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    // バリデーションエラーを処理する\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details); // { stepId?: string, path?: string[] }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ElevenLabsVoice with default settings\nDESCRIPTION: This snippet shows how to initialize the ElevenLabsVoice class with default settings, relying on the ELEVENLABS_API_KEY environment variable for authentication. It imports the necessary class from the @mastra/voice-elevenlabs package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/elevenlabs.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\n\n// デフォルトの設定で初期化（ELEVENLABS_API_KEY環境変数を使用）\nconst voice = new ElevenLabsVoice();\n```\n\n----------------------------------------\n\nTITLE: Configuring Working Memory in TypeScript\nDESCRIPTION: This code demonstrates configuring the working memory feature of the `Memory` class.  It shows how to enable working memory, define a template for storing persistent information, and choose between 'text-stream' or 'tool-call' modes for updating the memory.  The `template` property defines the structure of the information to be stored.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/Memory.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      template: \"# User\\n- **First Name**:\\n- **Last Name**:\",\n      use: \"tool-call\", // または 'text-stream'\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mastra Instance with Vector Store\nDESCRIPTION: Initializes the Mastra instance and configures PgVector for vector storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { PgVector } from '@mastra/pg';\n\nimport { researchAgent } from './agents/researchAgent';\n\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\nexport const mastra = new Mastra({\n  agents: { researchAgent },\n  vectors: { pgVector },\n});\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Processors\nDESCRIPTION: This code combines `ToolCallFilter` and `TokenLimiter` processors. It first filters out tool calls (excluding `imageGenTool`) and then limits the number of tokens to 16000. The `TokenLimiter` is placed last for accurate measurement after other filters/transformations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Memory } from \\\"@mastra/memory\\\";\nimport { TokenLimiter, ToolCallFilter } from \\\"@mastra/memory/processors\\\";\n\nconst memory = new Memory({\n  processors: [\n    // 最初にツール呼び出しをフィルタリング\n    new ToolCallFilter({ exclude: [\\\"imageGenTool\\\"] }),\n    // 次にトークンを制限（他のフィルタ/変換後の正確な測定のためにトークンリミッターは常に最後に配置）\n    new TokenLimiter(16000),\n  ],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings\nDESCRIPTION: This code generates embeddings for the text chunks using the OpenAI embedding model and stores them in the vector database. It first creates an index in the vector store, then upserts the embeddings along with the associated metadata, enabling efficient similarity searches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Custom Configuration Example - Typescript\nDESCRIPTION: This code shows how to use the `AnswerRelevancyMetric` with custom configuration options, including `uncertaintyWeight` and `scale`. It imports the required modules, sets up the model, creates a metric instance with specified options, calls the measure method with a question and corresponding answer, and then prints example output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/answer-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { AnswerRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new AnswerRelevancyMetric(\n  model,\n  {\n    uncertaintyWeight: 0.5, // Higher weight for uncertain verdicts\n    scale: 5, // Use 0-5 scale instead of 0-1\n  },\n);\n\nconst result = await metric.measure(\n  \"What are the benefits of exercise?\",\n  \"Regular exercise improves cardiovascular health, builds strength, and boosts mental wellbeing.\",\n);\n\n// Example output:\n// {\n//   score: 4.5,\n//   info: {\n//     reason: \"The score is 4.5 out of 5 because the response directly addresses the query\n//           with specific, accurate benefits of exercise. It covers multiple aspects\n//           (cardiovascular, muscular, and mental health) in a clear and concise manner.\n//           The answer is highly relevant and provides appropriate detail without\n//           including unnecessary information.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Initializing ElevenLabs Voice in TypeScript\nDESCRIPTION: This TypeScript snippet initializes the ElevenLabsVoice class with configuration parameters such as the speech model and default speaker. It assumes that the '@mastra/voice-elevenlabs' module is imported correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ElevenLabsVoice } from '@mastra/voice-elevenlabs';\n\n// Initialize with configuration\nconst voice = new ElevenLabsVoice({\n  speechModel: {\n    name: 'eleven_multilingual_v2',\n    apiKey: 'your-api-key', // Optional, can use ELEVENLABS_API_KEY env var\n  },\n  speaker: 'Adam', // Default speaker\n});\n```\n\n----------------------------------------\n\nTITLE: Defining QueryResult Interface\nDESCRIPTION: This code defines the `QueryResult` interface, which represents the structure of the data returned when querying the LibSQLVector store.  It includes properties such as the id, score, metadata, and optionally, the vector itself.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/libsql.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Instantiate Mastra with Components Typescript\nDESCRIPTION: Instantiates PgVector and Mastra with the defined agents, vectors, and workflows. It initializes `PgVector` with the PostgreSQL connection string from environment variables. Then it initializes `Mastra` with the RAG agent, PgVector, and the RAG workflow, making them available for use in the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n  workflows: { ragWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Passing Context Between Steps in Typescript\nDESCRIPTION: This code snippet shows how to pass data between workflow steps using the context object in Typescript.  It demonstrates how to access the output of previous steps through `context.steps` and use that data in subsequent steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step({\n    id: 'getData',\n    execute: async ({ context }) => {\n      return {\n        data: { id: '123', value: 'example' }\n      };\n    }\n  })\n  .step({\n    id: 'processData',\n    execute: async ({ context }) => {\n      // コンテキスト.stepsを通じて前のステップからのデータにアクセス\n      const previousData = context.steps.getData.output.data;\n      // previousData.id と previousData.value を処理\n    }\n  });\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for Hallucination metric\nDESCRIPTION: This snippet shows how to import the necessary modules from the '@ai-sdk/openai' and '@mastra/evals/llm' packages. These dependencies are essential for setting up and using the HallucinationMetric class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/hallucination.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { HallucinationMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Partial Word Inclusion Example Usage\nDESCRIPTION: Shows metric evaluation when only some target words are found in the output text, resulting in a partial score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/word-inclusion.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst words2 = ['python', 'javascript', 'typescript', 'rust'];\nconst metric2 = new WordInclusionMetric(words2);\n\nconst input2 = 'What programming languages do you know?';\nconst output2 = 'I know python and javascript very well.';\n\nconst result2 = await metric2.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: result2.info,\n});\n// Example Output:\n// Metric Result: { score: 0.5, info: { totalWords: 4, matchedWords: 2 } }\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with High Contextual Recall\nDESCRIPTION: This TypeScript snippet demonstrates evaluating a response with high contextual recall using the `ContextualRecallMetric`. It defines a context, a query, and a response that incorporates all information from the context.  The metric is initialized with the `gpt-4o-mini` model, and the `measure` method is used to evaluate the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/contextual-recall.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  '製品の特徴にはクラウド同期が含まれます。',\n  'オフラインモードが利用可能です。',\n  '複数のデバイスをサポートします。',\n];\n\nconst metric1 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = '製品の主な特徴は何ですか？';\nconst response1 = '製品の特徴にはクラウド同期、オフラインモードのサポート、複数のデバイスでの作業が可能です。';\n\nconsole.log('例 1 - 高リコール:');\nconsole.log('コンテキスト:', context1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 1, reason: '出力のすべての要素がコンテキストによってサポートされています。' }\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution with Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to add two steps to a Mastra workflow that will execute in parallel. The steps are independent and can run concurrently, improving workflow speed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(fetchUserData).step(fetchOrderData);\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with Mixed Context Relevancy\nDESCRIPTION: This snippet shows how to evaluate a response where some context is irrelevant. It defines a context array, initializes a `ContextRelevancyMetric` instance, defines a query and a corresponding response, measures the context relevancy, and prints the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-relevancy.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  '日食は月が太陽を遮るときに起こります。',\n  '月は日食の間に地球と太陽の間を移動します。',\n  '月は夜に見えます。',\n  '月には大気がありません。',\n];\n\nconst metric2 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = '日食の原因は何ですか？';\nconst response2 = '日食は月が地球と太陽の間を移動し、日光を遮るときに起こります。';\n\nconsole.log('例 2 - 混合関連性:');\nconsole.log('コンテキスト:', context2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.5, reason: 'コンテキストは一部の関連情報を使用し、一部の無関係な情報を含んでいます。' }\n```\n\n----------------------------------------\n\nTITLE: Setting up LangWatch Exporter in Mastra\nDESCRIPTION: This TypeScript snippet demonstrates how to configure Mastra to use LangWatch for telemetry export. It requires the '@mastra/core' and 'langwatch' packages. Key parameters include the API key and project ID, which are fetched from environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langwatch.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { LangWatchExporter } from \"langwatch\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new LangWatchExporter({\n        apiKey: process.env.LANGWATCH_API_KEY,\n        projectId: process.env.LANGWATCH_PROJECT_ID,\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Agent Tool in Mastra AI (TypeScript)\nDESCRIPTION: This code demonstrates how to retrieve information about a specific tool available to the agent using its ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst tool = await agent.getTool(\"tool-id\");\n```\n\n----------------------------------------\n\nTITLE: Mapping Trigger Data to Step Input (TypeScript)\nDESCRIPTION: Illustrates how to map data from a workflow trigger to a step's input using the `variables` property.  The `processUserInput` step receives data directly from the `inputData` field of the trigger. Requires `@mastra/core` and `zod`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// ユーザー入力が必要なステップを定義\nconst processUserInput = new Step({\n  id: \"processUserInput\",\n  execute: async ({ context }) => {\n    // inputDataは変数マッピングのためにcontextで利用可能になります\n    const { inputData } = context.inputData;\n\n    return {\n      processedData: `Processed: ${inputData}`\n    };\n  },\n});\n\n// ワークフローを作成\nconst workflow = new Workflow({\n  name: \"trigger-mapping\",\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\n// トリガーデータをステップにマッピング\nworkflow\n  .step(processUserInput, {\n    variables: {\n      inputData: { step: 'trigger', path: 'inputData' },\n    }\n  })\n  .commit();\n\n  // Mastraにワークフローを登録\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Testing API Endpoint with cURL\nDESCRIPTION: Shows how to test the research assistant API endpoint using cURL command.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/researchAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"What were the main findings about model parallelization?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Tool Call Mode\nDESCRIPTION: This code initializes a Memory instance with working memory enabled, using the tool-call mode. This mode requires explicit tool calls to update the working memory, which is necessary when using `toDataStream()`. The `use: \"tool-call\"` setting specifies this mode.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolCallMemory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      use: \"tool-call\", // Required for toDataStream() compatibility\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareStore with REST API (TypeScript)\nDESCRIPTION: Initializes the CloudflareStore using the REST API, suitable for server-side Node.js environments. It requires the Cloudflare account ID and API token to be set as environment variables and allows for an optional namespace prefix.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n// Or using REST API\nconst store = new CloudflareStore({\n  accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,\n  apiToken: process.env.CLOUDFLARE_API_TOKEN!,\n  namespacePrefix: 'myapp_', // Optional\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Environment Setup\nDESCRIPTION: Defines the environment variables required for the RAG system.  `OPENAI_API_KEY` stores the OpenAI API key and `POSTGRES_CONNECTION_STRING` holds the connection string for the PostgreSQL database where PGVector stores vector embeddings and metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Workflow with Reference-Based Conditions in TypeScript\nDESCRIPTION: This snippet demonstrates how to use reference-based conditions with comparison operators in a Mastra workflow. It provides an alternative to function-based conditions for implementing conditional branching.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Using reference-based conditions instead of functions\nconditionalWorkflow\n  .step(startStep)\n  .if({\n    ref: { step: startStep, path: 'value' },\n    query: { $gte: 10 }, // Condition: value is 10 or greater\n  })\n  .then(highValueStep)\n  .then(finalStep)\n  .else()\n  .then(lowValueStep)\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the required dependencies using PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Query Tool\nDESCRIPTION: Creates a vector query tool using `createVectorQueryTool` from `@mastra/rag`.  This tool is configured with an ID, vector store name, index name, embedding model, and enables filtering.  The embedding model is a small text embedding model provided by OpenAI. The `enableFilter: true` option is crucial for allowing metadata filtering during vector queries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst vectorQueryTool = createVectorQueryTool({\n  id: 'vectorQueryTool',\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding('text-embedding-3-small'),\n  enableFilter: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Upstash Storage Configuration - TypeScript\nDESCRIPTION: This code shows how to configure Mastra to use Upstash (Redis compatible) as the storage engine. It requires the `@mastra/upstash` package to be installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst mastra = new Mastra({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Console Logger Creation (TypeScript)\nDESCRIPTION: Demonstrates how to create a console logger using the createLogger function. The logger is configured with the name \"Mastra\" and level \"debug\". It logs an informational message when the application starts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/create-logger.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst consoleLogger = createLogger({ name: \"Mastra\", level: \"debug\" });\nconsoleLogger.info(\"App started\");\n```\n\n----------------------------------------\n\nTITLE: Transforming Chunks to Metadata\nDESCRIPTION: Transforms the document chunks into a structured metadata format suitable for filtering.  The code iterates through the chunks and extracts relevant information, including text, excerpt keywords, and assigns a nested ID. This metadata is then associated with the vector embeddings to enable filtering during the retrieval process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunkMetadata = chunks?.map((chunk: any, index: number) => ({\n  text: chunk.text,\n  ...chunk.metadata,\n  nested: {\n    keywords: chunk.metadata.excerptKeywords\n      .replace('KEYWORDS:', '')\n      .split(',')\n      .map(k => k.trim()),\n    id: index,\n  },\n}));\n```\n\n----------------------------------------\n\nTITLE: Querying a Thread by ID\nDESCRIPTION: This code snippet shows how to retrieve a thread by its ID using the getThreadById method. It expects the threadId as a parameter and returns the corresponding thread object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst savedThread = await store.getThreadById({ threadId: 'thread-123' });\n```\n\n----------------------------------------\n\nTITLE: Running Mastra Development Server\nDESCRIPTION: Command to start the Mastra development server and open the Mastra playground. This needs to be run after project creation to begin development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: KeywordCoverageMetric Examples with Analysis in TypeScript\nDESCRIPTION: This snippet demonstrates multiple examples using `KeywordCoverageMetric` to evaluate keyword coverage, including cases with perfect, partial, and technical keyword matches. Each example calls the `measure` method with different input and output texts, showcasing how the metric handles various scenarios, calculating and returning a score and detailed info.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/keyword-coverage.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new KeywordCoverageMetric();\n\n// Perfect coverage example\nconst result1 = await metric.measure(\n  \"The quick brown fox jumps over the lazy dog\",\n  \"A quick brown fox jumped over a lazy dog\"\n);\n// {\n//   score: 1.0,\n//   info: {\n//     matchedKeywords: 6,\n//     totalKeywords: 6\n//   }\n// }\n\n// Partial coverage example\nconst result2 = await metric.measure(\n  \"Python features include easy syntax, dynamic typing, and extensive libraries\",\n  \"Python has simple syntax and many libraries\"\n);\n// {\n//   score: 0.67,\n//   info: {\n//     matchedKeywords: 4,\n//     totalKeywords: 6\n//   }\n// }\n\n// Technical terms example\nconst result3 = await metric.measure(\n  \"Discuss React.js component lifecycle and state management\",\n  \"React components have lifecycle methods and manage state\"\n);\n// {\n//   score: 1.0,\n//   info: {\n//     matchedKeywords: 4,\n//     totalKeywords: 4\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Branch with .after() in Mastra Workflow\nDESCRIPTION: This snippet shows how to use `.after()` to create a new branch in a Mastra workflow after a specific step (stepA) has completed.  It defines that `stepC` should only execute after `stepA` is finished, creating a parallel execution path with `stepB`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/after.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n    .then(stepB)\n  .after(stepA)  // stepAが完了した後に新しいブランチを作成\n    .step(stepC);\n```\n\n----------------------------------------\n\nTITLE: Generating Agent Response in Mastra AI (TypeScript)\nDESCRIPTION: This code demonstrates how to generate a response from an agent, including optional parameters for thread and resource IDs, and output configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await agent.generate({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Hello, how are you?\",\n    },\n  ],\n  threadId: \"thread-1\", // Optional: Thread ID for conversation context\n  resourceid: \"resource-1\", // Optional: Resource ID\n  output: {}, // Optional: Output configuration\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing a Specific Agent in Mastra AI (TypeScript)\nDESCRIPTION: This code shows how to get an instance of a specific agent using its ID with the Mastra AI client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = client.getAgent(\"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in Environment File\nDESCRIPTION: Example of how to edit the .env file to include your OpenAI API key, which is required for the example to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Processing Documents into Chunks\nDESCRIPTION: This snippet demonstrates how to process a document into smaller chunks. It uses the `MDocument.fromText` method to create a document from the given text and then chunks it using the `chunk` method. The chunking strategy is set to \"recursive\" with a size of 512 and an overlap of 50. The separator is set to newline character.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(\n  `The Impact of Climate Change on Global Agriculture...`,\n);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming speech with PlayAITTS\nDESCRIPTION: This code snippet demonstrates how to stream speech from text using the `stream()` method of the PlayAITTS class. The stream allows for real-time audio playback without waiting for the entire audio to be generated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n\"// Stream speech\\nconst stream = await tts.stream({\\n  voice: 'en-US-1',\\n  text: 'Hello from Mastra!',\\n});\"\n```\n\n----------------------------------------\n\nTITLE: Conditional Step Execution (Function) in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates conditional step execution in Mastra workflows using a function for the `when` property. The `processData` step will only execute if the `fetchData` step's status is \"success\".\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: async ({ context }) => {\n      const fetchData = context?.getStepResult<{ status: string }>(\"fetchData\");\n      return fetchData?.status === \"success\";\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Integrating Function Calling with OpenAI Real-time Voice in TypeScript\nDESCRIPTION: This example demonstrates how to define a custom weather tool, initialize the OpenAIRealtimeVoice provider, add the tool to the voice provider, and connect to the real-time service. The weather tool is created using createTool() with input/output schemas and an execute function that fetches weather data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.addTools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\n// Define tools\nconst weatherTool = createTool({\n  id: \"getWeather\",\n  description: \"Get the current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"The city and state, e.g. San Francisco, CA\"),\n  }),\n  outputSchema: z.object({\n    message: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // Fetch weather data from an API\n    const response = await fetch(`https://api.weather.com?location=${encodeURIComponent(context.location)}`);\n    const data = await response.json();\n    return { message: `The current temperature in ${context.location} is ${data.temperature}°F with ${data.conditions}.` };\n  },\n});\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Add tools to the voice provider\nvoice.addTools({\n  getWeather: weatherTool,\n});\n\n// Connect to the real-time service\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: Create Agent with GitHub Tool\nDESCRIPTION: Defines an agent named `Code Review Agent` and includes the `getMainBranchRef` tool in its configuration. This allows the agent to interact with GitHub repositories during conversations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { getMainBranchRef } from \"../tools\";\n\nexport const codeReviewAgent = new Agent({\n  name: \"Code Review Agent\",\n  instructions:\n    \"An agent that reviews code repositories and provides feedback.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    getMainBranchRef,\n    // other tools...\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Wrangler CLI Deployment (Bash)\nDESCRIPTION: Commands to deploy the Mastra application to Cloudflare Workers using the Wrangler CLI. Includes installation, login, and deployment steps for both preview and production environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/cloudflare.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g wrangler\ncd .mastra/output\nwrangler login\nwrangler deploy\nwrangler deploy --env production\n```\n\n----------------------------------------\n\nTITLE: Storing Evaluations in Mastra Storage with Vitest\nDESCRIPTION: This TypeScript snippet demonstrates how to store evaluation results in Mastra Storage within Vitest tests. It imports `beforeAll` from `vitest`, `attachListeners` from `@mastra/evals`, and `mastra` from a local setup file. The `beforeAll` hook ensures that listeners are attached before any test cases are executed, allowing the framework to capture and send evaluation results to the Mastra Storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/running-in-ci.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { beforeAll } from 'vitest';\nimport { attachListeners } from '@mastra/evals';\nimport { mastra } from './your-mastra-setup';\n\nbeforeAll(async () => {\n  // Store evals in Mastra Storage (requires storage to be enabled)\n  await attachListeners(mastra);\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra Hallucination Evaluation\nDESCRIPTION: This code imports the necessary dependencies for using Mastra's Hallucination metric. It includes the OpenAI client from ai-sdk and the HallucinationMetric from Mastra's evals library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/hallucination.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { HallucinationMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech-to-Speech Voice Interactions\nDESCRIPTION: Shows how to create real-time speech-to-speech interactions using the OpenAIRealtimeVoice provider. This example includes setting up the agent with the realtime voice provider, establishing connections, and handling microphone input for dynamic conversations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { search, calculate } from \"../tools\";\n\n// Initialize the realtime voice provider\nconst voice = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: process.env.OPENAI_API_KEY,\n    model: \"gpt-4o-mini-realtime\",\n  },\n  speaker: \"alloy\",\n});\n\n// Create an agent with speech-to-speech voice capabilities\nexport const agent = new Agent({\n  name: \"Agent\",\n  instructions: `You are a helpful assistant with speech-to-speech capabilities.`,\n  model: openai(\"gpt-4o\"),\n  tools: {\n    // Tools configured on Agent are passed to voice provider\n    search,\n    calculate,\n  },\n  voice,\n});\n\n// Establish a WebSocket connection\nawait agent.voice.connect();\n\n// Start a conversation\nagent.voice.speak(\"Hello, I'm your AI assistant!\");\n\n// Stream audio from a microphone\nconst microphoneStream = getMicrophoneStream();\nagent.voice.send(microphoneStream);\n\n// When done with the conversation\nagent.voice.close();\n```\n\n----------------------------------------\n\nTITLE: Vercel Deployment Configuration in JSON\nDESCRIPTION: Shows the configuration settings within the automatically generated vercel.json file. It sets the version, install command, build paths, and routing for deploying a Mastra application to Vercel.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/vercel.mdx#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \"version\": 2,\\n  \"installCommand\": \"npm install --omit=dev\",\\n  \"builds\": [\\n    {\\n      \"src\": \"index.mjs\",\\n      \"use\": \"@vercel/node\",\\n      \"config\": {\\n        \"includeFiles\": [\"**\"]\\n      }\\n    }\\n  ],\\n  \"routes\": [\\n    {\\n      \"src\": \"/(.*)\",\\n      \"dest\": \"index.mjs\"\\n    }\\n  ]\\n}\n```\n\n----------------------------------------\n\nTITLE: Message Interface Definition Typescript\nDESCRIPTION: Defines the structure of a message object used in the `messages` parameter of the `generate()` method. It includes the `role` (system, user, or assistant) and the `content` of the message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/generate.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Add Support for CommonJS\nDESCRIPTION: This patch adds support for CommonJS (CJS) modules. This enables Mastra to be used in environments that require CJS modules, expanding its compatibility.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nbb4f447: Add support for commonjs\n```\n\n----------------------------------------\n\nTITLE: Environment Setup\nDESCRIPTION: This snippet shows how to set up the environment variables required for the RAG system. It defines the OpenAI API key and the PostgreSQL connection string. These variables are crucial for authenticating with OpenAI and connecting to the PGVector database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Chunking Documents - TypeScript\nDESCRIPTION: The `chunk()` method splits an MDocument into smaller chunks, optionally extracting metadata. This async method, implemented in TypeScript, returns a promise resolving to an array of chunks. It can accept `ChunkParams` to tailor the chunking process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync chunk(params?: ChunkParams): Promise<Chunk[]>\n```\n\n----------------------------------------\n\nTITLE: Evaluate Minimal Keyword Coverage in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a response with minimal keyword coverage. The code defines input and output texts, measures keyword coverage using `metric.measure`, and logs the results, illustrating a scenario where very few keywords are matched, leading to a low coverage score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/keyword-coverage.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'Machine learning models require data preprocessing, feature engineering, and hyperparameter tuning';\nconst output3 = 'Data preparation is important for models';\n\nconsole.log('Example 3 - Minimal Coverage:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    totalKeywords: result3.info.totalKeywords,\n    matchedKeywords: result3.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.2, info: { totalKeywords: 10, matchedKeywords: 2 } }\n```\n\n----------------------------------------\n\nTITLE: Displaying Search Results in Typescript\nDESCRIPTION: This snippet shows the expected output format of a basic semantic search. The result is an array of objects containing the text, similarity score, and metadata of each matched chunk. The metadata includes the source of the document.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n[\n  {\n    text: \"気候変動は重大な課題をもたらします...\",\n    score: 0.89,\n    metadata: { source: \"article1.txt\" }\n  },\n  {\n    text: \"気温の上昇は作物の収穫量に影響を与えます...\",\n    score: 0.82,\n    metadata: { source: \"article1.txt\" }\n  }\n  // ... さらに多くの結果\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Condition-Based Loops with while() Method and Function Condition\nDESCRIPTION: Demonstrates how to repeat a step as long as a specified function-based condition remains true using the while() method, useful for iterative processing with dynamic termination conditions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Step that increments a counter while below target\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // Current counter value\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      // Continue while counter is less than 10\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) < 10;\n    },\n    incrementStep,\n    {\n      // Pass current counter to next iteration\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Console Logger in Mastra\nDESCRIPTION: Sets up a minimal console logger at the INFO level that will print informational messages and above (DEBUG, INFO, WARN, ERROR) to the console. The configuration specifies a name for grouping logs and the minimum severity level to record.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/logging.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\nexport const mastra = new Mastra({\n  // Other Mastra configuration...\n  logger: createLogger({\n    name: \"Mastra\",\n    level: \"info\",\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Using speak() Method with CompositeVoice Provider in TypeScript\nDESCRIPTION: This example demonstrates how to use the speak() method with a CompositeVoice provider, which delegates to the configured speaking provider. This is useful when using different providers for speaking and listening.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.speak.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nconst voice = new CompositeVoice({\n  speakProvider: new PlayAIVoice(),\n  listenProvider: new OpenAIVoice(),\n});\n// This will use the PlayAIVoice provider\nconst audioStream = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Implementing a Cyclical Workflow with Mastra in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a workflow with cyclical dependencies using Mastra. It defines steps for doubling a value and incrementing by one, then configures a workflow that loops through these steps. The workflow is executed with a trigger value, showcasing how to handle repeated execution and conditional logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/cyclical-dependencies.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\nasync function main() {\n  const doubleValue = new Step({\n    id: 'doubleValue',\n    description: 'Doubles the input value',\n    inputSchema: z.object({\n      inputValue: z.number(),\n    }),\n    outputSchema: z.object({\n      doubledValue: z.number(),\n    }),\n    execute: async ({ context }) => {\n      const doubledValue = context.inputValue * 2;\n      return { doubledValue };\n    },\n  });\n\n  const incrementByOne = new Step({\n    id: 'incrementByOne',\n    description: 'Adds 1 to the input value',\n    outputSchema: z.object({\n      incrementedValue: z.number(),\n    }),\n    execute: async ({ context }) => {\n      const valueToIncrement = context?.getStepResult<{ firstValue: number }>('trigger')?.firstValue;\n      if (!valueToIncrement) throw new Error('No value to increment provided');\n      const incrementedValue = valueToIncrement + 1;\n      return { incrementedValue };\n    },\n  });\n\n  const cyclicalWorkflow = new Workflow({\n    name: 'cyclical-workflow',\n    triggerSchema: z.object({\n      firstValue: z.number(),\n    }),\n  });\n\n  cyclicalWorkflow\n    .step(doubleValue, {\n      variables: {\n        inputValue: {\n          step: 'trigger',\n          path: 'firstValue',\n        },\n      },\n    })\n    .then(incrementByOne)\n    .after(doubleValue)\n    .step(doubleValue, {\n      variables: {\n        inputValue: {\n          step: doubleValue,\n          path: 'doubledValue',\n        },\n      },\n    })\n    .commit();\n\n  const { runId, start } = cyclicalWorkflow.createRun();\n\n  console.log('Run', runId);\n\n  const res = await start({ triggerData: { firstValue: 6 } });\n\n  console.log(res.results);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Initialize TextualDifferenceMetric\nDESCRIPTION: Initializes a new instance of the TextualDifferenceMetric class. This instance will be used to measure the difference between text strings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/textual-difference.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new TextualDifferenceMetric();\n```\n\n----------------------------------------\n\nTITLE: No Word Inclusion Example Usage\nDESCRIPTION: Demonstrates metric evaluation when no target words are found in the output text, resulting in a zero score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/word-inclusion.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst words3 = ['cloud', 'server', 'database'];\nconst metric3 = new WordInclusionMetric(words3);\n\nconst input3 = 'Tell me about your infrastructure';\nconst output3 = 'We use modern technology for our systems.';\n\nconst result3 = await metric3.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: result3.info,\n});\n// Example Output:\n// Metric Result: { score: 0, info: { totalWords: 3, matchedWords: 0 } }\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Qdrant in TypeScript\nDESCRIPTION: This code snippet initializes QdrantVector with URL and API key, creates an index, and upserts embeddings with metadata. It requires the @mastra/qdrant package and appropriate environment variables for Qdrant.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { QdrantVector } from '@mastra/qdrant'\n\nconst store = new QdrantVector({\n  url: process.env.QDRANT_URL,\n  apiKey: process.env.QDRANT_API_KEY\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Execute Tool with Arguments - TypeScript\nDESCRIPTION: Executes a specific tool with provided arguments such as parameters and optional context identifiers. This snippet demonstrates how to pass arguments for execution and includes optional properties like threadId and resourceid.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/tools.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await tool.execute({\n  args: {\n    param1: \"value1\",\n    param2: \"value2\",\n  },\n  threadId: \"thread-1\", // Optional: Thread context\n  resourceid: \"resource-1\", // Optional: Resource identifier\n});\n```\n\n----------------------------------------\n\nTITLE: Netlify Configuration in TOML\nDESCRIPTION: This TOML snippet defines the configuration for Netlify deployment, which includes settings for functions and redirects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/netlify.mdx#2025-04-22_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[functions]\nnode_bundler = \"esbuild\"            \ndirectory = \"netlify/functions\"\n\n[[redirects]]\nforce = true\nfrom = \"/*\"\nstatus = 200\nto = \"/.netlify/functions/api/:splat\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example of how to set up the environment variables file with OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/hybrid-vector-search/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Measure Moderate Text Similarity\nDESCRIPTION: This snippet demonstrates how to measure the similarity between two text strings that have similar meaning but different wording using the `ContentSimilarityMetric`. It logs the input texts and the resulting similarity score and info.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/content-similarity.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst text2 = 'A brown fox quickly leaps across a sleeping dog.';\nconst reference2 = 'The quick brown fox jumps over the lazy dog.';\n\nconsole.log('Example 2 - Moderate Similarity:');\nconsole.log('Text:', text2);\nconsole.log('Reference:', reference2);\n\nconst result2 = await metric.measure(reference2, text2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    similarity: result2.info.similarity,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Protected Properties Configuration Table in React/TSX\nDESCRIPTION: React component defining protected properties for MastraVoice class including model configurations, speaker settings, and realtime configuration options. Uses a PropertiesTable component to display the configuration structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#2025-04-22_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"listeningModel\",\n      type: \"BuiltInModelConfig | undefined\",\n      description: \"Configuration for the speech-to-text model\",\n      isOptional: true,\n    },\n    {\n      name: \"speechModel\",\n      type: \"BuiltInModelConfig | undefined\",\n      description: \"Configuration for the text-to-speech model\",\n      isOptional: true,\n    },\n    {\n      name: \"speaker\",\n      type: \"string | undefined\",\n      description: \"Default speaker/voice ID\",\n      isOptional: true,\n    },\n    {\n      name: \"realtimeConfig\",\n      type: \"{ model?: string; apiKey?: string; options?: unknown } | undefined\",\n      description: \"Configuration for real-time speech-to-speech capabilities\",\n      isOptional: true,\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Using Storage Functionality in TypeScript\nDESCRIPTION: This snippet demonstrates the use of the PostgresStore class to create, save, and retrieve threads and messages in a PostgreSQL database. It requires a PostgreSQL server and connection configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PostgresStore } from '@mastra/pg';\n\nconst store = new PostgresStore({\n  host: 'localhost',\n  port: 5432,\n  database: 'mastra',\n  user: 'postgres',\n  password: 'postgres',\n});\n\n// Create a thread\nawait store.saveThread({\n  id: 'thread-123',\n  resourceId: 'resource-456',\n  title: 'My Thread',\n  metadata: { key: 'value' },\n});\n\n// Add messages to thread\nawait store.saveMessages([\n  {\n    id: 'msg-789',\n    threadId: 'thread-123',\n    role: 'user',\n    type: 'text',\n    content: [{ type: 'text', text: 'Hello' }],\n  },\n]);\n\n// Query threads and messages\nconst savedThread = await store.getThread('thread-123');\nconst messages = await store.getMessages('thread-123');\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra\nDESCRIPTION: Instantiates `PgVector` and `Mastra` with necessary configurations. `PgVector` is initialized with a database connection string. `Mastra` is initialized with the configured agent and vector store. The `ragAgent` is retrieved from the `Mastra` instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Fixing Cloudflare Wrangler Entry Point\nDESCRIPTION: This code snippet describes a fix related to the Cloudflare Wrangler. Specifically, it ensures that the Cloudflare Wrangler points to the correct entry point file. This correction prevents deployment issues and ensures that the application starts correctly on the Cloudflare platform.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_2\n\nLANGUAGE: TEXT\nCODE:\n```\nfe11c20: have cloudflare wrangler point to correct entry point file\n```\n\n----------------------------------------\n\nTITLE: Handling Validation Errors in Workflow Execution - Typescript\nDESCRIPTION: This snippet demonstrates how to handle validation errors that may occur during workflow execution. It uses a `try...catch` block to catch `ValidationError` instances and log their type and details. A `ValidationError` is thrown if the workflow configuration is invalid.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/createRun.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const { runId, start, watch, resume, resumeWithEvent } = workflow.createRun();\n  await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    // バリデーションエラーを処理する\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Manual Installation - Initialize TypeScript Project (yarn)\nDESCRIPTION: These commands initialize a TypeScript project using yarn, install necessary dependencies including `@mastra/core`, zod, and @ai-sdk/openai, and initialize the TypeScript compiler.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nyarn init -y\nyarn add typescript tsx @types/node mastra --dev\nyarn add @mastra/core zod @ai-sdk/openai\nyarn dlx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Evaluating Partial Coverage Summary\nDESCRIPTION: Evaluates a summary that is factually accurate but omits important information using the `SummarizationMetric`. The example shows how the `measure` method assesses a summary with an alignment score of 1 (factually accurate) but a lower coverage score due to missing key details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = `The Python programming language was created by Guido van Rossum and was first released \nin 1991. It emphasizes code readability with its notable use of significant whitespace. Python is \ndynamically typed and garbage-collected. It supports multiple programming paradigms, including \nstructured, object-oriented, and functional programming.`;\n\nconst output2 = `Python, created by Guido van Rossum, is a programming language known for its readable \ncode and use of whitespace. It was released in 1991.`;\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    reason: result2.info.reason,\n    alignmentScore: result2.info.alignmentScore,\n    coverageScore: result2.info.coverageScore,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.4,\n//   info: {\n//     reason: \"The score is 0.4 because while the summary is factually accurate (alignment score: 1), it only covers a portion of the key information from the source text (coverage score: 0.4), omitting several important technical details.\",\n//     alignmentScore: 1,\n//     coverageScore: 0.4\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Building Mastra project\nDESCRIPTION: This command builds the Mastra project in the current directory for production.  It uses Rollup to bundle the code and outputs to the `.mastra` directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/cli/build.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"mastra build\"\n```\n\n----------------------------------------\n\nTITLE: Configuring a Basic Console Logger in Mastra\nDESCRIPTION: This code snippet demonstrates how to configure a basic console logger within a Mastra application using the createLogger function from the @mastra/core/logger module. It sets the logger name to \"Mastra\" and the log level to \"info\", ensuring that information messages and above are output to the console. Requires @mastra/core as a dependency.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/logging.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\nexport const mastra = new Mastra({\n  // Other Mastra configuration...\n  logger: createLogger({\n    name: \"Mastra\",\n    level: \"info\",\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Workflow Run with start() Method in TypeScript\nDESCRIPTION: Demonstrates how to create and start a workflow run with trigger data. The example shows basic usage of the createRun() and start() methods with an input value.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/start.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start } = workflow.createRun();\nconst result = await start({ \n  triggerData: { inputValue: 42 } \n});\n```\n\n----------------------------------------\n\nTITLE: Automatic Installation - Create Mastra Project (pnpm)\nDESCRIPTION: This command initiates the automatic installation of a new Mastra project using the `create-mastra` package with pnpm. It scaffolds the project with necessary configurations and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Processing Workflow Execution Results (TypeScript)\nDESCRIPTION: This example demonstrates how to process the results of a workflow execution. It extracts the `runId`, `results`, and `status` from the returned object and checks if the workflow completed successfully before logging the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/execute.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, results, status } = await workflow.execute({\n  triggerData: { inputValue: 42 }\n});\n\nif (status === \"COMPLETED\") {\n  console.log(\"ステップの結果:\", results);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector with Connection String\nDESCRIPTION: This code snippet demonstrates how to instantiate the `PgVector` class using a connection string. The connection string specifies the PostgreSQL database connection details, including user, password, host, port, and database name. This is one of the two ways to instantiate the `PgVector` class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\n// 接続文字列を使用する方法（文字列形式）\nconst vectorStore1 = new PgVector('postgresql://user:password@localhost:5432/mydb');\n```\n\n----------------------------------------\n\nTITLE: Token Limiter Usage in Mastra\nDESCRIPTION: This snippet shows how to use the `TokenLimiter` processor to prevent errors caused by exceeding the LLM's context window limit.  It counts the tokens in retrieved memory messages and removes the oldest messages until the total count is below the specified `limit`. It uses `o200k_base` encoding by default for GPT-4o.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/memory-processors.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter } from \"@mastra/memory/processors\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  model: openai(\"gpt-4o\"),\n  memory: new Memory({\n    processors: [\n      // Ensure the total tokens from memory don't exceed ~127k\n      new TokenLimiter(127000),\n    ],\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Complete Coverage with Completeness Metric\nDESCRIPTION: This example demonstrates how to evaluate a response that covers all elements of the input text using the Completeness metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/completeness.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst text1 = 'The primary colors are red, blue, and yellow.';\nconst reference1 = 'The primary colors are red, blue, and yellow.';\n\nconsole.log('Example 1 - Complete Coverage:');\nconsole.log('Text:', text1);\nconsole.log('Reference:', reference1);\n\nconst result1 = await metric.measure(reference1, text1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    missingElements: result1.info.missingElements,\n    elementCounts: result1.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: { score: 1, info: { missingElements: [], elementCounts: { input: 8, output: 8 } } }\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration\nDESCRIPTION: Environment variable configuration for OpenAI API key and Postgres connection string\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in .env File\nDESCRIPTION: Example of how to set the OpenAI API key in the environment variables file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SarvamVoice in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the SarvamVoice class with default or custom configurations, and how to use the speak and listen methods for text-to-speech and speech-to-text functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/sarvam.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SarvamVoice } from \"@mastra/voice-sarvam\";\n\n// Initialize with default configuration using environment variables\nconst voice = new SarvamVoice();\n\n// Or initialize with specific configuration\nconst voiceWithConfig = new SarvamVoice({\n   speechModel: {\n    model: \"bulbul:v1\",\n    apiKey: process.env.SARVAM_API_KEY!,\n    language: \"en-IN\",\n    properties: {\n      pitch: 0,\n      pace: 1.65,\n      loudness: 1.5,\n      speech_sample_rate: 8000,\n      enable_preprocessing: false,\n      eng_interpolation_wt: 123,\n    },\n  },\n  listeningModel: {\n    model: \"saarika:v2\",\n    apiKey: process.env.SARVAM_API_KEY!,\n    languageCode: \"en-IN\",\n     filetype?: 'wav';\n  },\n  speaker: \"meera\", // Default voice\n});\n\n\n// Convert text to speech\nconst audioStream = await voice.speak(\"Hello, how can I help you?\");\n\n\n// Convert speech to text\nconst text = await voice.listen(audioStream, {\n  filetype: \"wav\",\n});\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the upsert() method for adding or updating embedding vectors in the Turbopuffer vector store. It specifies parameters for vectors, metadata, and optional IDs for the vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"vectors\",\n      type: \"number[][]\",\n      description: \"Array of embedding vectors\",\n    },\n    {\n      name: \"metadata\",\n      type: \"Record<string, any>[]\",\n      isOptional: true,\n      description: \"Metadata for each vector\",\n    },\n    {\n      name: \"ids\",\n      type: \"string[]\",\n      isOptional: true,\n      description: \"Optional vector IDs (auto-generated if not provided)\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Memory Setup with Token Limit and Encoding (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates configuring a Memory instance with a TokenLimiter and specifying a custom encoding.  The TokenLimiter is set to 16000 tokens, and the encoding is set to 'cl100k_base', which is suitable for certain models like GPT-3.5.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter } from \"@mastra/memory/processors\";\nimport cl100k_base from \"js-tiktoken/ranks/cl100k_base\";\n\nconst memory = new Memory({\n  processors: [\n    new TokenLimiter({\n      limit: 16000,\n      encoding: cl100k_base, // Specific encoding for certain models eg GPT-3.5\n    }),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Memory Threads in TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve all memory threads for a specific resource and agent using the Mastra client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst threads = await client.getMemoryThreads({\n  resourceId: \"resource-1\",\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Todo List Agent with Working Memory in TypeScript\nDESCRIPTION: Demonstrates how to use the todo list agent to add a new task. It uses maskStreamTags to hide working memory updates from users and processes the response stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\nimport { maskStreamTags } from \"@mastra/core/utils\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Add a new todo item\nconst response = await todoAgent.stream(\n  \"Add a task: Build a new feature for our app. It should take about 2 hours and needs to be done by next Friday.\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// Process the stream, hiding working memory updates\nfor await (const chunk of maskStreamTags(\n  response.textStream,\n  \"working_memory\",\n)) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for Mastra Context Relevancy Example\nDESCRIPTION: Configuration of the OpenAI API key in the environment file required for using the Context Relevancy metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Documenting Nested Parameters with PropertiesTable\nDESCRIPTION: Demonstrates how to create a separate PropertiesTable to describe properties of a nested options object in function parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_3\n\nLANGUAGE: mdx\nCODE:\n```\n### options\n\n<PropertiesTable\n  content={[\n    {\n      name: \"verbose\",\n      type: \"boolean\",\n      description: \"Enables detailed logging when 'true'.\",\n      isOptional: true,\n      defaultValue: \"false\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Workflow Error Monitoring in Typescript\nDESCRIPTION: This code snippet shows how to monitor a Mastra workflow for errors using the `watch` method. It checks the results of each step to identify failures and logs an error message if any step has failed.  It requires the `workflow` object with `createRun` method from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst { start, watch } = workflow.createRun();\n\nwatch(async ({ results }) => {\n  // 失敗したステップがあるか確認\n  const failedSteps = Object.entries(results)\n    .filter(([_, step]) => step.status === \"failed\")\n    .map(([stepId]) => stepId);\n\n  if (failedSteps.length > 0) {\n    console.error(`ワークフローに失敗したステップがあります: ${failedSteps.join(', ')}`);\n    // アラートやログ記録などの是正措置を取る\n  }\n});\n\nawait start();\n```\n\n----------------------------------------\n\nTITLE: Example Usage of Embed Functions in AI SDK with TypeScript\nDESCRIPTION: Provides example usage of both `embed` and `embedMany` functions to demonstrate embedding operations. Uses `openai.embedding('text-embedding-3-small')` as the model and processes single and multiple text inputs to generate embeddings for various queries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/embeddings.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed, embedMany } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\n// Single embedding\nconst singleResult = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: \"What is the meaning of life?\",\n});\n\n// Multiple embeddings\nconst multipleResult = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: [\n    \"First question about life\",\n    \"Second question about universe\",\n    \"Third question about everything\"\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/speech-azure with npm\nDESCRIPTION: This command installs the @mastra/speech-azure package as a project dependency using npm. This allows the project to utilize Azure's Text-to-Speech capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/azure/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/speech-azure\"\n```\n\n----------------------------------------\n\nTITLE: Using on() with CompositeVoice\nDESCRIPTION: This code illustrates how the `on()` method works in conjunction with `CompositeVoice`. It initializes a `CompositeVoice` with a real-time provider (`OpenAIRealtimeVoice`) and then registers an event listener on the `CompositeVoice` instance. This effectively delegates the event listening to the underlying real-time provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.on.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // MacBook Proでの高品質オーディオの標準であるHz単位のオーディオサンプルレート\n  channels: 1,        // モノラルオーディオ出力（ステレオの場合は2）\n  bitDepth: 16,       // オーディオ品質のビット深度 - CD品質の標準（16ビット解像度）\n});\n\nconst realtimeVoice = new OpenAIRealtimeVoice();\nconst voice = new CompositeVoice({\n  realtimeProvider: realtimeVoice,\n});\n\n// リアルタイムサービスに接続\nawait voice.connect();\n\n// これにより、OpenAIRealtimeVoiceプロバイダーにイベントリスナーが登録されます\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker)\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Conditional Branching using Function Condition (Status Check) in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a conditional branch based on the status from a previous step. The `if` branch executes only when the status is 'success'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/if.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const result = context.getStepResult<{ status: string }>('start');\n    return result?.status === 'success'; // Execute \"if\" branch when status is \"success\"\n  })\n  .then(successStep)\n  .else()\n  .then(failureStep);\n```\n\n----------------------------------------\n\nTITLE: Monitoring a Workflow with TypeScript\nDESCRIPTION: This snippet shows how to monitor the transitions of a workflow run using the `watch` method. It creates a workflow run and then calls the `watch` method, providing a callback function that logs information about the latest transition state. `workflow.start` then initiates the workflow run.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ntry{\n  // Get workflow instance\n  const workflow = client.getWorkflow(\"workflow-id\");\n\n  // Create a workflow run\n  const {runId} = workflow.createRun()\n\n  // Watch workflow run \n     workflow.watch({runId},(record)=>{\n       // Every new record is the latest transition state of the workflow run\n\n        console.log({\n          activePaths: record.activePaths,\n          results: record.results,\n          timestamp: record.timestamp,\n          runId: record.runId\n        });\n     });\n\n  // Start workflow run\n     workflow.start({\n      runId,\n      triggerData: {\n        city: 'New York',\n      },\n    });\n}catch(e){\n  console.error(e);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with Cloudflare Deployer\nDESCRIPTION: Example of setting up a Mastra instance with Cloudflare deployer configuration, including logger setup and agent configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra, createLogger } from '@mastra/core';\nimport { CloudflareDeployer } from '@mastra/deployer-cloudflare';\n\nexport const mastra = new Mastra({\n  agents: { /* your agents here */ },\n  logger: createLogger({ name: 'MyApp', level: 'debug' }),\n  deployer: new CloudflareDeployer({\n    scope: 'your-cloudflare-scope',\n    projectName: 'your-project-name',\n    // See complete configuration options in the reference docs\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Create and Store Embeddings Typescript\nDESCRIPTION: Generates embeddings for the document chunks and stores them in the vector store. It uses the `embedMany` function from the `ai` library to generate embeddings using the `text-embedding-3-small` model from OpenAI. It then creates an index in the vector store and upserts the embeddings and metadata into the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedding Dimensions with Google in TypeScript\nDESCRIPTION: Shows how to configure the dimensionality of embeddings when using Google's text-embedding-004 model. This method truncates excessive values from the end of the embedding vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: google.textEmbeddingModel('text-embedding-004', {\n    outputDimensionality: 256  // Truncates excessive values from the end\n  }),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra for SigNoz with OTLP in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to configure the Mastra observability settings to export telemetry data to SigNoz using the OpenTelemetry (OTLP) exporter. The `serviceName` parameter specifies the name of your service within SigNoz, and `enabled` activates the telemetry export.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/signoz.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Performing Text-to-Speech with DeepgramVoice\nDESCRIPTION: This code snippet illustrates how to use the `speak` method of the DeepgramVoice class to convert text to speech. It takes a string as input and returns a promise that resolves to a Node.js ReadableStream containing the audio data.  The `audioStream` can then be piped to an audio player or saved to a file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/deepgram.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Text-to-Speech\nconst audioStream = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Context Relevancy Evaluation\nDESCRIPTION: Imports the OpenAI client and ContextRelevancyMetric from Mastra's evals library, which are required to use the context relevancy evaluation functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextRelevancyMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Evaluate Tone Stability in TypeScript\nDESCRIPTION: This code snippet demonstrates how to evaluate the tone stability within a single text using the ToneConsistencyMetric. It analyzes the sentiment consistency within 'input2' by comparing it to an empty string 'output2', representing a stability analysis.  The metric result, including score and information, is then logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/tone-consistency.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'Great service! Friendly staff. Perfect atmosphere.';\nconst output2 = ''; // 安定性分析のための空の文字列\n\nconsole.log('Example 2 - Tone Stability:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: result2.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Embed Chunk Array with OpenAI in Typescript\nDESCRIPTION: This code snippet shows how to generate embeddings for an array of text chunks using the `embedMany` function. It imports necessary modules from `@ai-sdk/openai`, `@mastra/rag`, and `ai`. It initializes a document, chunks it, and then uses `embedMany` to convert the text chunks into numerical vectors using the OpenAI embedding model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/embed-chunk-array.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { MDocument } from '@mastra/rag';\nimport { embed } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Sending Recommendations to Customer in Mastra Step\nDESCRIPTION: This snippet defines a Mastra Step for sending the final recommendations to the customer. It generates an email content based on the approved recommendations and additional input from the human reviewer.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Send the recommendations to the customer\nconst sendRecommendations = new Step({\n  id: 'sendRecommendations',\n  outputSchema: z.object({\n    emailSent: z.boolean(),\n    emailContent: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const { customerName } = context.getStepResult(generateRecommendations) || { customerName: '' };\n    const { finalRecommendations, customerNote, offerDiscount } = context.getStepResult(reviewRecommendations) || {\n      finalRecommendations: [],\n      customerNote: '',\n      offerDiscount: false,\n    };\n\n    // Generate email content based on the recommendations\n    let emailContent = `Dear ${customerName},\\n\\nBased on your preferences, we recommend:\\n\\n`;\n\n    finalRecommendations.forEach(product => {\n      emailContent += `- ${product.productName}: $${product.price.toFixed(2)}\\n`;\n    });\n\n    if (offerDiscount) {\n      emailContent += '\\nAs a valued customer, use code SAVE10 for 10% off your next purchase!\\n';\n    }\n\n    if (customerNote) {\n      emailContent += `\\nPersonal note: ${customerNote}\\n`;\n    }\n\n    emailContent += '\\nThank you for your business,\\nThe Sales Team';\n\n    // In a real application, you would send this email\n    console.log('Email content generated:', emailContent);\n\n    return {\n      emailSent: true,\n      emailContent,\n    };\n  },\n});\n\n// Build the workflow\nconst recommendationWorkflow = new Workflow({\n  name: 'product-recommendation-workflow',\n  triggerSchema: z.object({\n    customerName: z.string(),\n  }),\n});\n\nrecommendationWorkflow\n.step(generateRecommendations)\n.then(reviewRecommendations)\n.then(sendRecommendations)\n.commit();\n\n// Register the workflow\nconst mastra = new Mastra({\n  workflows: { recommendationWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Variable Mapping in Mastra Workflow (TypeScript)\nDESCRIPTION: Demonstrates mapping trigger data to a step's input and mapping the output of one step to the input of another step using the `variables` property within a Mastra workflow.  It defines a workflow with two steps and configures data mapping between them. Requires `zod` for schema definition and `@mastra/core` for workflow and step classes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'data-mapping-workflow',\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\nworkflow\n  .step(step1, {\n    variables: {\n      // トリガーデータをステップ入力にマッピング\n      inputData: { step: 'trigger', path: 'inputData' }\n    }\n  })\n  .then(step2, {\n    variables: {\n      // step1の出力をstep2の入力にマッピング\n      previousValue: { step: step1, path: 'outputField' }\n    }\n  })\n  .commit();\n\n// Mastraにワークフローを登録\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Suspend Workflow Execution (Basic)\nDESCRIPTION: This code snippet demonstrates the basic usage of the `suspend()` function within a Mastra workflow step. It pauses the workflow execution if a condition is met (amount > 1000) and returns a resolved Promise when suspension is successful.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/suspend.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst approvalStep = new Step({\n  id: \"needsApproval\",\n  execute: async ({ context, suspend }) => {\n    if (context.steps.amount > 1000) {\n      await suspend();\n    }\n    return { approved: true };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for LangWatch\nDESCRIPTION: This snippet outlines the required environment variables for integrating LangWatch with Mastra. Set these variables with your LangWatch API key and project ID to enable telemetry export from Mastra to LangWatch.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langwatch.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nLANGWATCH_API_KEY=your_api_key\nLANGWATCH_PROJECT_ID=your_project_id\n```\n\n----------------------------------------\n\nTITLE: Retrieving Tool Details via API\nDESCRIPTION: This snippet shows how to retrieve detailed information about a specific tool using the `tool.details()` method. It assumes that `tool` is an instance of a specific tool obtained via `client.getTool()`. The method returns a promise that resolves to an object containing the tool details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/tools.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await tool.details();\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for LibSQL in Typescript\nDESCRIPTION: This snippet shows how to integrate a `LIBSQL_PROMPT` into an agent's instructions for querying LibSQL.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { LIBSQL_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${LIBSQL_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Chat Logic in Next.js API Route with Mastra Agent and Memory\nDESCRIPTION: This code snippet showcases a Next.js API route (`app/api/chat/route.ts`) that processes chat messages using a Mastra Agent and Memory. The route expects a JSON payload containing a single `message` (of type `CoreMessage`), a `threadId`, and a `resourceId`.  It retrieves the message content, interacts with the Mastra Agent to generate a response, and streams the response back to the client. It also includes error handling for cases where the message content is missing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/use-chat.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// app/api/chat/route.ts (Next.js Example)\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { CoreMessage } from \"@mastra/core\"; // Import CoreMessage\n\nconst agent = new Agent({\n  name: \"ChatAgent\",\n  instructions: \"You are a helpful assistant.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory(), // Assumes default memory setup\n});\n\nexport async function POST(request: Request) {\n  // Get data structured by experimental_prepareRequestBody\n  const { message, threadId, resourceId }: { message: CoreMessage | null; threadId: string; resourceId: string } = await request.json();\n\n  // Handle cases where message might be null (e.g., initial load or error)\n  if (!message || !message.content) {\n    // Return an appropriate response or error\n    return new Response(\"Missing message content\", { status: 400 });\n  }\n\n  // Process with memory using the single message content\n  const stream = await agent.stream(message.content, {\n    threadId,\n    resourceId,\n    // Pass other message properties if needed, e.g., role\n    // messageOptions: { role: message.role }\n  });\n\n  // Return the streaming response\n  return stream.toDataStreamResponse();\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Voice Package using npm\nDESCRIPTION: This snippet provides the necessary command to install the @mastra/voice-azure package, which is required for integrating Azure Voice capabilities into the project. Ensure you have npm installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-azure\n```\n\n----------------------------------------\n\nTITLE: Cloudflare Native Bindings Configuration\nDESCRIPTION: Configures Cloudflare Native Bindings for the AI model in the wrangler.jsonc file.  The 'binding' parameter specifies the identifier for the AI binding.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"ai\": {\n    \"binding\": \"AI\"\n  }\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings with Metadata in TypeScript\nDESCRIPTION: This code snippet showcases how to upsert embeddings along with their associated metadata into a vector store. It updates existing vectors if their IDs match, or creates new vectors if they don't exist. The upsert method automatically handles batching for large datasets.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Store embeddings with their corresponding metadata\nawait store.upsert({\n  indexName: 'myCollection',  // index name\n  vectors: embeddings,       // array of embedding vectors\n  metadata: chunks.map(chunk => ({\n    text: chunk.text,  // The original text content\n    id: chunk.id       // Optional unique identifier\n  }))\n});\n```\n\n----------------------------------------\n\nTITLE: Defining the QueryResult interface\nDESCRIPTION: This code defines the `QueryResult` interface, which represents the structure of the data returned by a query. It includes properties for id, score, metadata, and optionally the vector itself.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/libsql.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // includeVector が true の場合のみ含まれます\n}\n```\n\n----------------------------------------\n\nTITLE: Toxicity Metric Basic Usage\nDESCRIPTION: Demonstrates the basic usage of the ToxicityMetric class to evaluate the toxicity of an LLM's output. It initializes the ToxicityMetric with an OpenAI model, measures the toxicity of a given input and output pair, and logs the resulting score and reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/toxicity.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ToxicityMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ToxicityMetric(model, {\n  scale: 1, // Default scale is 0-1\n});\n\nconst result = await metric.measure(\n  \"How is Sarah as a person?\",\n  \"Sarah is a dedicated team member who always delivers quality work.\",\n);\n\nconsole.log(result.score); // Score from 0-1 (0 = not toxic, 1 = toxic)\nconsole.log(result.info.reason); // Explanation of the toxicity assessment\n```\n\n----------------------------------------\n\nTITLE: Extracting Metadata with Parameters - TypeScript\nDESCRIPTION: The method `extractMetadata()` asynchronously extracts metadata using specified parameters. In TypeScript, this returns a promise resolving to an updated MDocument, with extraction driven by `ExtractParams`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nasync extractMetadata(params: ExtractParams): Promise<MDocument>\n```\n\n----------------------------------------\n\nTITLE: Context Precision Metric with Analysis (TypeScript)\nDESCRIPTION: This code snippet provides an example of using the `ContextPrecisionMetric` class with an analysis of the result. It configures the metric with a specific context related to exercise benefits and then evaluates the precision of that context when answering a question about the benefits of exercise. The output includes a score and a reason for the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-precision.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPrecisionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPrecisionMetric(model, {\n  context: [\n    \"運動は心臓を強化し、血液循環を改善します。\",\n    \"バランスの取れた食事は健康に重要です。\",\n    \"定期的な身体活動はストレスと不安を軽減します。\",\n    \"運動器具は高価な場合があります。\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"運動の利点は何ですか？\",\n  \"定期的な運動は心血管の健康と精神的な健康を改善します。\",\n);\n\n// Example output:\n// {\n//   score: 0.75,\n//   info: {\n//     reason: \"スコアが0.75である理由は、最初と3番目のコンテキストが出力で言及された利点に非常に関連しているためです。\n//           一方、2番目と4番目のコンテキストは運動の利点に直接関連していません。関連するコンテキストは\n//           シーケンスの最初と中間にうまく配置されています。\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Describing Index in Upstash Vector Store in TypeScript\nDESCRIPTION: The `describeIndex()` method provides details about a particular index based on its name. This method facilitates retrieving information about the dimension, count, and metric of the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to describe\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Installing the Cloudflare Deployer for Mastra\nDESCRIPTION: Command to install the @mastra/deployer-cloudflare package using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/deployer-cloudflare\n```\n\n----------------------------------------\n\nTITLE: Ask About Role Step - TypeScript\nDESCRIPTION: Defines a step to ask a non-technical candidate about what interests them most about the role. It retrieves the candidate's information, crafts a question using the resume text as context, and generates a question string focused on their interest in the role. It relies on the `gatherCandidateInfo` step and returns an object containing the generated question.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst askAboutRole = new Step({\n  id: \"askAboutRole\",\n  outputSchema: z.object({\n    question: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const candidateInfo = context?.getStepResult<CandidateInfo>(\n      \"gatherCandidateInfo\",\n    );\n\n    const prompt = `\n          You are a recruiter. Given the resume below, craft a short question\n          for ${candidateInfo?.candidateName} asking what interests them most about this role.\n          Resume: ${candidateInfo?.resumeText}\n        `;\n    const res = await recruiter.generate(prompt);\n    return { question: res?.text?.trim() || \"\" };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing D1Store with Workers Binding - Typescript\nDESCRIPTION: This code snippet demonstrates how to initialize the `D1Store` class using the Workers binding method in TypeScript. The `D1Database` binding is expected to be provided by the Workers runtime, and an optional `tablePrefix` can be used to isolate tables per environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare-d1.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { D1Store } from \\\"@mastra/cloudflare-d1\\\";\n\n// --- Example 1: Using Workers Binding ---\nconst storageWorkers = new D1Store({\n  binding: D1Database, // D1Database binding provided by the Workers runtime\n  tablePrefix: 'dev_', // Optional: isolate tables per environment\n});\"\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using DeepgramVoice in TypeScript\nDESCRIPTION: Example showing how to initialize the DeepgramVoice provider with both default and custom configurations, and how to use its speak() and listen() methods for text-to-speech and speech-to-text functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/deepgram.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DeepgramVoice } from \"@mastra/voice-deepgram\";\n\n// Initialize with default configuration (uses DEEPGRAM_API_KEY environment variable)\nconst voice = new DeepgramVoice();\n\n// Initialize with custom configuration\nconst voice = new DeepgramVoice({\n  speechModel: {\n    name: 'aura',\n    apiKey: 'your-api-key',\n  },\n  listeningModel: {\n    name: 'nova-2',\n    apiKey: 'your-api-key',\n  },\n  speaker: 'asteria-en',\n});\n\n// Text-to-Speech\nconst audioStream = await voice.speak(\"Hello, world!\");\n\n// Speech-to-Text\nconst transcript = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Configuration File\nDESCRIPTION: Command to create an environment configuration file by copying the example template.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration File\nDESCRIPTION: Command to create a copy of the example environment file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Initializing UpstashStore Instance in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to import and initialize the UpstashStore class. It sets up the storage with necessary parameters such as URL and authentication token, pulling these from environment variables. This configuration is crucial for interacting with the Upstash storage service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/upstash.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst storage = new UpstashStore({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN,\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking Text with Mastra RAG in TSX\nDESCRIPTION: This code snippet demonstrates how to use the `MDocument.fromText` method to create a document from plain text and then chunk it into smaller segments using the `chunk` method. This is useful for processing large text documents for search, analysis, or retrieval in RAG applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/chunk-text.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk();\n```\n\n----------------------------------------\n\nTITLE: Running Debate from the Command Line (TypeScript)\nDESCRIPTION: This script takes a topic and number of turns from the user via command line prompts using `@clack/prompts`, then initiates the debate by calling the `runDebate` function. It handles user cancellation and error conditions, and exits appropriately. It depends on the `runDebate` function defined in the 'turn-taking.ts' file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { runDebate } from './debate/turn-taking';\nimport * as p from '@clack/prompts';\n\nasync function main() {\n    // Get the topic from the user\n    const topic = await p.text({\n        message: 'Enter a topic for the agents to discuss:',\n        placeholder: 'Climate change',\n        validate(value) {\n            if (!value) return 'Please enter a topic';\n            return;\n        },\n    });\n\n    // Exit if cancelled\n    if (p.isCancel(topic)) {\n        p.cancel('Operation cancelled.');\n        process.exit(0);\n    }\n\n    // Get the number of turns\n    const turnsInput = await p.text({\n        message: 'How many turns should each agent have?',\n        placeholder: '3',\n        initialValue: '3',\n        validate(value) {\n            const num = parseInt(value);\n            if (isNaN(num) || num < 1) return 'Please enter a positive number';\n            return;\n        },\n    });\n\n    // Exit if cancelled\n    if (p.isCancel(turnsInput)) {\n        p.cancel('Operation cancelled.');\n        process.exit(0);\n    }\n\n    const turns = parseInt(turnsInput as string);\n\n    // Run the debate\n    await runDebate(topic as string, turns);\n}\n\nmain().catch((error) => {\n    p.log.error('An error occurred:');\n    console.error(error);\n    process.exit(1);\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Reasoning Prompt for Gluten Evaluation Explanation\nDESCRIPTION: Generates a detailed explanation prompt about why a recipe is considered gluten-free or not. This prompt takes the gluten evaluation results and structures them into a human-readable format with reasoning.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const generateReasonPrompt = ({\\n  isGlutenFree,\\n  glutenSources,\\n}: {\\n  isGlutenFree: boolean;\\n  glutenSources: string[];\\n}) => `Explain why this recipe is${isGlutenFree ? '' : ' not'} gluten-free.\\n\\n${glutenSources.length > 0 ? `Sources of gluten: ${glutenSources.join(', ')}` : 'No gluten-containing ingredients found'}\\n\\nReturn your response in this format:\\n{\\n  \"reason\": \"This recipe is [gluten-free/contains gluten] because [explanation]\"\\n}`;\n```\n\n----------------------------------------\n\nTITLE: Setting Configuration Environment Variables for Traceloop\nDESCRIPTION: This snippet details the necessary environment variables to configure Traceloop with Mastra, which includes specifying the OTLP endpoint and authorization headers. Ensure to replace the placeholder values with your actual API key and destination ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/traceloop.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.traceloop.com\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer your_api_key, x-traceloop-destination-id=your_destination_id\"\n```\n\n----------------------------------------\n\nTITLE: AzureVoice Usage Example in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the AzureVoice class for text-to-speech and speech-to-text conversion. It initializes the AzureVoice class with configuration, converts text to speech, and converts speech to text using Azure Cognitive Services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/azure.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AzureVoice } from '@mastra/voice-azure';\n\n// Initialize with configuration\nconst voice = new AzureVoice({\n  speechModel: {\n    name: 'neural',\n    apiKey: 'your-azure-speech-api-key',\n    region: 'eastus'\n  },\n  listeningModel: {\n    name: 'whisper',\n    apiKey: 'your-azure-speech-api-key',\n    region: 'eastus'\n  },\n  speaker: 'en-US-JennyNeural'  // Default voice\n});\n\n// Convert text to speech\nconst audioStream = await voice.speak('Hello, how can I help you?', {\n  speaker: 'en-US-GuyNeural',  // Override default voice\n  style: 'cheerful'  // Voice style\n});\n\n// Convert speech to text\nconst text = await voice.listen(audioStream, {\n  filetype: 'wav',\n  language: 'en-US'\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Toxicity Metric and OpenAI\nDESCRIPTION: This TypeScript snippet imports the necessary modules from the `@ai-sdk/openai` and `@mastra/evals/llm` libraries. The `openai` function is used to initialize the OpenAI client, and `ToxicityMetric` is used to evaluate text for toxicity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ToxicityMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Mastra Client Configuration Options\nDESCRIPTION: Configuration options for initializing the Mastra client, including base URL, retry settings, backoff timing, and custom headers. This demonstrates all available options for customizing the client behavior.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/client-sdks/client-js/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new MastraClient({\n    baseUrl: string;           // Base URL for the Mastra API\n    retries?: number;          // Number of retry attempts (default: 3)\n    backoffMs?: number;        // Initial backoff time in ms (default: 300)\n    maxBackoffMs?: number;     // Maximum backoff time in ms (default: 5000)\n    headers?: Record<string, string>; // Custom headers\n});\n```\n\n----------------------------------------\n\nTITLE: Context Position Metric Example with Analysis in Mastra Evals\nDESCRIPTION: Provides an example of using the ContextPositionMetric class with an analysis of the resulting score and reasoning. It demonstrates how the metric evaluates the context based on relevance and position, and explains the score's interpretation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-position.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPositionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPositionMetric(model, {\n  context: [\n    \"バランスの取れた食事は健康に重要です。\",\n    \"運動は心臓を強化し、血液循環を改善します。\",\n    \"定期的な身体活動はストレスと不安を軽減します。\",\n    \"運動器具は高価な場合があります。\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"運動の利点は何ですか？\",\n  \"定期的な運動は心血管の健康と精神的な健康を改善します。\",\n);\n\n// Example output:\n// {\n//   score: 0.5,\n//   info: {\n//     reason: \"スコアが0.5である理由は、2番目と3番目のコンテキストが運動の利点に非常に関連しているが、\n//           シーケンスの最初に最適に配置されていないためです。最初と最後のコンテキストはクエリに関連しておらず、\n//           位置重み付きスコアリングに影響を与えます。\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Suspend Workflow with Metadata\nDESCRIPTION: This code snippet demonstrates how to use the `suspend()` function with metadata.  Metadata can be used to store additional information about the suspended state, such as the reason for suspension and the user who requested it. Returns a resolved Promise when suspension is successful.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/suspend.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst reviewStep = new Step({\n  id: \"review\",\n  execute: async ({ context, suspend }) => {\n    await suspend({\n      reason: \"Needs manager approval\",\n      requestedBy: context.user\n    });\n    return { reviewed: true };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Using Toolsets with Agent's stream()\nDESCRIPTION: This example demonstrates how to use the toolsets with the `stream()` method of an Agent.  An agent is initialized without tools, and then later configured with a MCPConfiguration object. The toolsets are passed into the agent stream method, allowing it to dynamically access the defined tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// まず、ツールなしでエージェントを作成\nconst agent = new Agent({\n  name: \"Multi-tool Agent\",\n  instructions: \"あなたはユーザーが株価と天気を確認するのを手伝います。\",\n  model: openai(\"gpt-4\"),\n});\n\n// 後で、ユーザー固有の設定でMCPを構成\nconst mcp = new MCPConfiguration({\n  servers: {\n    stockPrice: {\n      command: \"npx\",\n      args: [\"tsx\", \"stock-price.ts\"],\n      env: {\n        API_KEY: \"user-123-api-key\",\n      },\n      timeout: 20000, // サーバー固有のタイムアウト\n    },\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),\n      requestInit: {\n        headers: {\n          Authorization: `Bearer user-123-token`,\n        },\n      },\n    },\n  },\n});\n\n// すべてのツールセットをstream()またはgenerate()に渡す\nconst response = await agent.stream(\n  \"AAPLの調子はどうですか？また、天気はどうですか？\",\n  {\n    toolsets: await mcp.getToolsets(),\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Mastra Build Command Usage\nDESCRIPTION: Examples of using the build command with default and custom directory options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Build using default directory\nmastra build\n\n# Build from custom directory\nmastra build --dir path/to/mastra\n```\n\n----------------------------------------\n\nTITLE: Creating RecipeCompletenessJudge Class (TypeScript)\nDESCRIPTION: Defines the `RecipeCompletenessJudge` class, which extends `MastraAgentJudge`. This class encapsulates the logic for evaluating the gluten content of a recipe using the defined prompts and an LLM. It includes methods to analyze the recipe (`evaluate`) and provide a human-readable explanation (`getReason`).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { type LanguageModel } from '@mastra/core/llm';\nimport { MastraAgentJudge } from '@mastra/evals/judge';\nimport { z } from 'zod';\nimport { GLUTEN_INSTRUCTIONS, generateGlutenPrompt, generateReasonPrompt } from './prompts';\n\nexport class RecipeCompletenessJudge extends MastraAgentJudge {\n  constructor(model: LanguageModel) {\n    super('Gluten Checker', GLUTEN_INSTRUCTIONS, model);\n  }\n\n  async evaluate(output: string): Promise<{ \n    isGlutenFree: boolean; \n    glutenSources: string[];\n  }> {\n    const glutenPrompt = generateGlutenPrompt({ output });\n    const result = await this.agent.generate(glutenPrompt, {\n      output: z.object({\n        isGlutenFree: z.boolean(),\n        glutenSources: z.array(z.string()),\n      }),\n    });\n\n    return result.object;\n  }\n\n  async getReason(args: { isGlutenFree: boolean; glutenSources: string[] }): Promise<string> {\n    const prompt = generateReasonPrompt(args);\n    const result = await this.agent.generate(prompt, {\n      output: z.object({\n        reason: z.string(),\n      }),\n    });\n\n    return result.object.reason;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Environment Variables in Mastra Telemetry Config (TypeScript)\nDESCRIPTION: This code snippet shows how to use environment variables defined in the `.env` file within the Mastra telemetry configuration. By omitting the `endpoint` and `headers` properties within the `export` section, Mastra will automatically retrieve these settings from the environment variables `OTEL_EXPORTER_OTLP_ENDPOINT` and `OTEL_EXPORTER_OTLP_HEADERS`. This approach simplifies configuration management, especially in different deployment environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/tracing.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const mastra = new Mastra({\n  // ... 他の設定\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n      // エンドポイントとヘッダーは環境変数から取得されます\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra in TypeScript\nDESCRIPTION: This snippet instantiates `PgVector` and `Mastra` using the connection string from the environment variables and the configured agent.  It creates a `PgVector` instance for managing the vector database and a `Mastra` instance with the 'ragAgent' and 'pgVector'.  Finally, it retrieves the agent for usage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\n\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Set OpenAI API Key in .env file\nDESCRIPTION: This code snippet shows how to configure the OpenAI API key within a `.env` file. The key is necessary for authenticating requests made by the chef agent to the OpenAI API.  Ensure you replace `your_openai_api_key` with your actual OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Process Document into Chunks Typescript\nDESCRIPTION: Processes a text document into smaller chunks using the `MDocument` class. It initializes `MDocument` with the sample text. The `chunk` method is used to split the document into chunks with a recursive strategy, a specified size of 512 characters, an overlap of 50 characters, and a newline separator.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`The Impact of Climate Change on Global Agriculture...`);\n\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing MastraClient in TypeScript\nDESCRIPTION: This code initializes the MastraClient with a base URL, which can be configured through an environment variable.  It imports MastraClient from '@mastra/client-js' and creates a singleton instance, allowing it to be used in other parts of the application.  The baseUrl is defaulted to 'http://localhost:4111' if the environment variable is not set.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from '@mastra/client-js';\n\n// Initialize the client\nexport const mastraClient = new MastraClient({\n  baseUrl: process.env.NEXT_PUBLIC_MASTRA_API_URL || 'http://localhost:4111',\n});\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mastra Setup Command Arguments\nDESCRIPTION: This snippet outlines the command-line arguments for initializing Mastra in non-interactive mode. It includes options for specifying components, LLM provider, API key, example code inclusion, and the directory for Mastra files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/add-to-existing-project.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nArguments:\n  --components     Specify components: agents, tools, workflows\n  --llm            LLM provider: openai, anthropic, groq, google or cerebras\n  --llm-api-key    Provider API key\n  --example        Include example implementation\n  --dir            Directory for Mastra files (defaults to src/)\n```\n\n----------------------------------------\n\nTITLE: Initializing Vector Query Tool with Custom Description\nDESCRIPTION: This snippet demonstrates how to initialize the `createVectorQueryTool` with a custom description. This allows for tailoring the tool's description to specific use cases while maintaining the fundamental purpose of information retrieval. The example focuses on customizing the tool description for searching a document archive to answer questions about company policies and procedures.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/vector-query-tool.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  description: \"会社の方針や手順に関する質問に答えるために関連情報を見つけるために、文書アーカイブを検索します\"\n});\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Cloudflare Vectorize in TypeScript\nDESCRIPTION: This code initializes CloudflareVector with account ID and API token, creates an index, and upserts embeddings with metadata. It requires @mastra/vectorize and appropriate Cloudflare environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CloudflareVector } from '@mastra/vectorize'\n\nconst store = new CloudflareVector({\n  accountId: process.env.CF_ACCOUNT_ID,\n  apiToken: process.env.CF_API_TOKEN\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Importing MDocument from @mastra/rag Typescript\nDESCRIPTION: Imports the MDocument class from the @mastra/rag library, which is essential for creating and manipulating document objects within the Mastra framework. This import statement is a prerequisite for working with document processing features in Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/metadata-extraction.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n```\n\n----------------------------------------\n\nTITLE: Creating a PlayAIVoice Object with Parameters\nDESCRIPTION: This TypeScript snippet shows how to instantiate a PlayAIVoice object with detailed speech model parameters. It allows customization of the speech generation settings including voice options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nnew PlayAIVoice({\n  speechModel?: {\n    name?: 'PlayDialog' | 'Play3.0-mini', // Default: 'PlayDialog'\n    apiKey?: string,                      // Optional, can use PLAYAI_API_KEY env var\n    userId?: string,                      // Optional, can use PLAYAI_USER_ID env var\n  },\n  speaker?: string                        // Optional, defaults to first available voice ID\n})\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into LibSQL with Mastra (TSX)\nDESCRIPTION: This code demonstrates how to create a collection and upsert embeddings into a LibSQL database (a SQLite fork with vector extensions) using the `LibSQLVector` class from the `@mastra/core/vector/libsql` package.  It uses the `openai` package for embedding generation and `MDocument` from `@mastra/rag` for text processing.  The `DATABASE_URL` and optionally `DATABASE_AUTH_TOKEN` environment variables are required.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_5\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map((chunk) => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst libsql = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  authToken: process.env.DATABASE_AUTH_TOKEN, // Optional: for Turso cloud databases\n});\n\nawait libsql.createIndex({\n  indexName: \"test_collection\",\n  dimension: 1536,\n});\n\nawait libsql.upsert({\n  indexName: \"test_collection\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Upstash Storage (TypeScript)\nDESCRIPTION: This code snippet shows how to initialize a Mastra workflow using Upstash as the storage engine.  It requires the `UPSTASH_URL` and `UPSTASH_TOKEN` environment variables to be set. The `UpstashStore` class is used to configure the connection to the Upstash Redis instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst mastra = new Mastra({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining AI Content Generation Step with Suspension in TypeScript\nDESCRIPTION: This code defines a step that simulates AI content generation and handles potential suspension for human guidance. It takes user input and an optional `guidance` as input.  The `execute` function generates an initial draft, checks its confidence score, and suspends the workflow if the score is low and no `guidance` is provided. Upon resumption with human guidance, the function enhances the generated content using the provided guidance and returns the improved output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Generate content with AI (may suspend for human guidance)\nconst promptAgent = new Step({\n  id: 'promptAgent',\n  inputSchema: z.object({\n    guidance: z.string(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const userInput = context.getStepResult(getUserInput)?.userInput;\n    console.log(`Generating content based on: ${userInput}`);\n\n    const guidance = context.inputData?.guidance;\n\n    // Simulate AI generating content\n    const initialDraft = generateInitialDraft(userInput);\n\n    // If confidence is high, return the generated content directly\n    if (initialDraft.confidenceScore > 0.7) {\n      return { modelOutput: initialDraft.content };\n    }\n\n    console.log('Low confidence in generated content, suspending for human guidance', {guidance});\n\n    // If confidence is low, suspend for human guidance\n    if (!guidance) {\n      // only suspend if no guidance is provided\n      await suspend();\n      return undefined;\n    }\n\n    // This code runs after resume with human guidance\n    console.log('Resumed with human guidance');\n\n    // Use the human guidance to improve the output\n    return {\n      modelOutput: enhanceWithGuidance(initialDraft.content, guidance),\n    };\n  },\n  outputSchema: z.object({ modelOutput: z.string() }).optional(),\n});\n```\n\n----------------------------------------\n\nTITLE: Query Result Interface for Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the structure of the QueryResult interface, which represents the expected format of query results, including fields like id, score, metadata, and an optional vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Executing TypeScript Agent Script\nDESCRIPTION: This snippet shows how to execute the TypeScript agent script using `npx tsx`. It assumes the script is located at `src/index.ts` and that the necessary dependencies are installed.  The `tsx` command is used for direct execution of TypeScript files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nnpx tsx src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Retrieving System Logs with Filtering - TypeScript\nDESCRIPTION: This code snippet demonstrates how to retrieve system logs using the `getLogs` method of the Mastra client. It allows optional filtering based on parameters such as `transportId`.  It assumes that `client` is an instance of the Mastra API client. The expected output is a list of logs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/logs.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst logs = await client.getLogs({\n  transportId: \"transport-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Managing Turn-Taking in the Debate (TypeScript)\nDESCRIPTION: This snippet manages the turn-taking flow between the two agents in the debate. It defines the `processTurn` function which generates the agent's response based on a prompt that includes the current topic and the previous agent's response. It also includes code for converting the text response to speech, playing the audio, and recording the debate.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"../../mastra\";\nimport { playAudio, Recorder } from \"@mastra/node-audio\";\nimport * as p from \"@clack/prompts\";\n\n// Helper function to format text with line wrapping\nfunction formatText(text: string, maxWidth: number): string {\n  const words = text.split(\" \");\n  let result = \"\";\n  let currentLine = \"\";\n\n  for (const word of words) {\n    if (currentLine.length + word.length + 1 <= maxWidth) {\n      currentLine += (currentLine ? \" \" : \"\") + word;\n    } else {\n      result += (result ? \"\\n\" : \"\") + currentLine;\n      currentLine = word;\n    }\n  }\n\n  if (currentLine) {\n    result += (result ? \"\\n\" : \"\") + currentLine;\n  }\n\n  return result;\n}\n\n// Initialize audio recorder\nconst recorder = new Recorder({\n  outputPath: \"./debate.mp3\",\n});\n\n// Process one turn of the conversation\nasync function processTurn(\n  agentName: \"optimistAgent\" | \"skepticAgent\",\n  otherAgentName: string,\n  topic: string,\n  previousResponse: string = \"\"\n) {\n  const agent = mastra.getAgent(agentName);\n  const spinner = p.spinner();\n  spinner.start(`${agent.name} is thinking...`);\n\n  let prompt;\n  if (!previousResponse) {\n    // First turn\n    prompt = `Discuss this topic: ${topic}. Introduce your perspective on it.`;\n  } else {\n    // Responding to the other agent\n    prompt = `The topic is: ${topic}. ${otherAgentName} just said: \"${previousResponse}\". Respond to their points.`;\n  }\n\n  // Generate text response\n  const { text } = await agent.generate(prompt, {\n    temperature: 0.9,\n  });\n\n  spinner.message(`${agent.name} is speaking...`);\n\n  // Convert to speech and play\n  const audioStream = await agent.voice.speak(text, {\n    speed: 1.2,\n    responseFormat: \"wav\", // Optional: specify a response format\n  });\n\n  if (audioStream) {\n    audioStream.on(\"data\", (chunk) => {\n      recorder.write(chunk);\n    });\n  }\n\n  spinner.stop(`${agent.name} said:`);\n\n  // Format the text to wrap at 80 characters for better display\n  const formattedText = formatText(text, 80);\n  p.note(formattedText, agent.name);\n\n  if (audioStream) {\n    const speaker = playAudio(audioStream);\n\n    await new Promise<void>((resolve) => {\n      speaker.once(\"close\", () => {\n        resolve();\n      });\n    });\n  }\n\n  return text;\n}\n\n// Main function to run the debate\nexport async function runDebate(topic: string, turns: number = 3) {\n  recorder.start();\n\n  p.intro(\"AI Debate - Two Agents Discussing a Topic\");\n  p.log.info(`Starting a debate on: ${topic}`);\n  p.log.info(\n    `The debate will continue for ${turns} turns each. Press Ctrl+C to exit at any time.`\n  );\n\n  let optimistResponse = \"\";\n  let skepticResponse = \"\";\n  const responses = [];\n\n  for (let turn = 1; turn <= turns; turn++) {\n    p.log.step(`Turn ${turn}`);\n\n    // Optimist's turn\n    optimistResponse = await processTurn(\n      \"optimistAgent\",\n      \"Skeptic\",\n      topic,\n      skepticResponse\n    );\n\n    responses.push({\n      agent: \"Optimist\",\n      text: optimistResponse,\n    });\n\n    // Skeptic's turn\n    skepticResponse = await processTurn(\n      \"skepticAgent\",\n      \"Optimist\",\n      topic,\n      optimistResponse\n    );\n\n    responses.push({\n      agent: \"Skeptic\",\n      text: skepticResponse,\n    });\n  }\n\n  recorder.end();\n  p.outro(\"Debate concluded! The full audio has been saved to debate.mp3\");\n\n  return responses;\n}\n```\n\n----------------------------------------\n\nTITLE: Installing and Initializing Mastra CLI\nDESCRIPTION: This snippet demonstrates how to install the Mastra CLI globally using npm and then initialize Mastra within an existing project. It installs the latest version of Mastra and then runs the `mastra init` command to set up Mastra in the current project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/add-to-existing-project.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g mastra@latest \nmastra init\n```\n\n----------------------------------------\n\nTITLE: Disconnecting from MCP Servers\nDESCRIPTION: Defines the `disconnect()` method for the MCPConfiguration class, which disconnects from all MCP servers and releases associated resources. It returns a promise that resolves when the disconnection is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync disconnect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Search and Re-ranking with Mastra\nDESCRIPTION: Executes a vector search on the stored embeddings and re-ranks the results using Mastra's rerank function, combining vector similarity, semantic relevance, and position scores.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query = 'explain technical trading analysis';\n\n// Get query embedding\nconst { embedding: queryEmbedding } = await embed({\n  value: query,\n  model: openai.embedding('text-embedding-3-small'),\n});\n\n// Get initial results\nconst initialResults = await pgVector.query({\n  indexName: 'embeddings',\n  queryVector: queryEmbedding,\n  topK: 3,\n});\n\n// Re-rank results\nconst rerankedResults = await rerank(initialResults, query, openai('gpt-4o-mini'), {\n  weights: {\n    semantic: 0.5,  // How well the content matches the query semantically\n    vector: 0.3,    // Original vector similarity score\n    position: 0.2   // Preserves original result ordering\n  },\n  topK: 3,\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Errors with LibSQLVector\nDESCRIPTION: This code demonstrates how to handle potential errors when using the `LibSQLVector` class, particularly during a query operation. It uses a try-catch block to catch errors and provide specific error messages based on the error encountered.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/libsql.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"my-collection\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  // 特定のエラーケースを処理\n  if (error.message.includes(\"Invalid index name format\")) {\n    console.error(\n      \"インデックス名は文字/アンダースコアで始まり、英数字のみを含む必要があります\",\n    );\n  } else if (error.message.includes(\"Table not found\")) {\n    console.error(\"指定されたインデックスは存在しません\");\n  } else {\n    console.error(\"ベクトルストアエラー:\", error.message);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Context Position Metric Basic Usage in Mastra Evals\nDESCRIPTION: Demonstrates the basic usage of the ContextPositionMetric class to evaluate the position of context nodes based on their relevance to a query and output. It configures the model, sets up the metric with a context array, measures the relevance, and logs the score and reasoning.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-position.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPositionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPositionMetric(model, {\n  context: [\n    \"光合成は、植物が太陽光からエネルギーを作り出すために使用する生物学的プロセスです。\",\n    \"光合成の過程で酸素が副産物として生成されます。\",\n    \"植物は成長するために土壌から水と栄養素を必要とします。\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"光合成とは何ですか？\",\n  \"光合成は、植物が太陽光をエネルギーに変換するプロセスです。\",\n);\n\nconsole.log(result.score); // 0-1の位置スコア\nconsole.log(result.info.reason); // スコアの説明\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector and Mastra Instance\nDESCRIPTION: Creates instances of PgVector for vector storage and Mastra with configured agents and vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Creating Debate Interface with Mastra Client in Next.js\nDESCRIPTION: This code snippet creates a Next.js component called `DebateInterface` that allows users to start a debate between two AI agents using the Mastra client. It initializes the Mastra client, handles user input for the debate topic and number of turns, and updates the UI with the agents' responses as the debate progresses. The component also includes functionality to play the audio of each response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n'use client';\n\nimport { useState, useRef } from 'react';\nimport { MastraClient } from '@mastra/client-js';\n\nconst mastraClient = new MastraClient({\n  baseUrl: process.env.NEXT_PUBLIC_MASTRA_URL || 'http://localhost:4111',\n});\n\nexport default function DebateInterface() {\n  const [topic, setTopic] = useState('');\n  const [turns, setTurns] = useState(3);\n  const [isDebating, setIsDebating] = useState(false);\n  const [responses, setResponses] = useState<any[]>([]);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const audioRef = useRef<HTMLAudioElement>(null);\n\n  // Function to start the debate\n  const startDebate = async () => {\n    if (!topic) return;\n    \n    setIsDebating(true);\n    setResponses([]);\n    \n    try {\n      const optimist = mastraClient.getAgent('optimistAgent');\n      const skeptic = mastraClient.getAgent('skepticAgent');\n      \n      const newResponses = [];\n      let optimistResponse = \"\";\n      let skepticResponse = \"\";\n      \n      for (let turn = 1; turn <= turns; turn++) {\n        // Optimist's turn\n        let prompt;\n        if (turn === 1) {\n          prompt = `Discuss this topic: ${topic}. Introduce your perspective on it.`;\n        } else {\n          prompt = `The topic is: ${topic}. Skeptic just said: \\\"${skepticResponse}\\\". Respond to their points.`;\n        }\n        \n        const optimistResult = await optimist.generate({\n          messages: [{ role: 'user', content: prompt }],\n        });\n        \n        optimistResponse = optimistResult.text;\n        newResponses.push({\n          agent: 'Optimist',\n          text: optimistResponse\n        });\n        \n        // Update UI after each response\n        setResponses([...newResponses]);\n        \n        // Skeptic's turn\n        prompt = `The topic is: ${topic}. Optimist just said: \\\"${optimistResponse}\\\". Respond to their points.`;\n        \n        const skepticResult = await skeptic.generate({\n          messages: [{ role: 'user', content: prompt }],\n        });\n        \n        skepticResponse = skepticResult.text;\n        newResponses.push({\n          agent: 'Skeptic',\n          text: skepticResponse\n        });\n        \n        // Update UI after each response\n        setResponses([...newResponses]);\n      }\n    } catch (error) {\n      console.error('Error starting debate:', error);\n    } finally {\n      setIsDebating(false);\n    }\n  };\n\n  // Function to play audio for a specific response\n  const playAudio = async (text: string, agent: string) => {\n    if (isPlaying) return;\n    \n    try {\n      setIsPlaying(true);\n      const agentClient = mastraClient.getAgent(agent === 'Optimist' ? 'optimistAgent' : 'skepticAgent');\n      \n      const audioResponse = await agentClient.voice.speak(text);\n      \n      if (!audioResponse.body) {\n        throw new Error('No audio stream received');\n      }\n      \n      // Convert stream to blob\n      const reader = audioResponse.body.getReader();\n      const chunks = [];\n      \n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n        chunks.push(value);\n      }\n      \n      const blob = new Blob(chunks, { type: 'audio/mpeg' });\n      const url = URL.createObjectURL(blob);\n      \n      if (audioRef.current) {\n        audioRef.current.src = url;\n        audioRef.current.onended = () => {\n          setIsPlaying(false);\n          URL.revokeObjectURL(url);\n        };\n        audioRef.current.play();\n      }\n    } catch (error) {\n      console.error('Error playing audio:', error);\n      setIsPlaying(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-4xl mx-auto p-4\">\n      <h1 className=\"text-2xl font-bold mb-4\">AI Debate with Turn Taking</h1>\n      \n      <div className=\"mb-6\">\n        <label className=\"block mb-2\">Debate Topic:</label>\n        <input\n          type=\"text\"\n          value={topic}\n          onChange={(e) => setTopic(e.target.value)}\n          className=\"w-full p-2 border rounded\"\n          placeholder=\"e.g., Climate change, AI ethics, Space exploration\"\n        />\n      </div>\n      \n      <div className=\"mb-6\">\n        <label className=\"block mb-2\">Number of Turns (per agent):</label>\n        <input\n          type=\"number\"\n          value={turns}\n          onChange={(e) => setTurns(parseInt(e.target.value))}\n          min={1}\n          max={10}\n          className=\"w-full p-2 border rounded\"\n        />\n      </div>\n      \n      <button\n        onClick={startDebate}\n        disabled={isDebating || !topic}\n        className=\"px-4 py-2 bg-blue-500 text-white rounded disabled:bg-gray-300\"\n      >\n        {isDebating ? 'Debate in Progress...' : 'Start Debate'}\n      </button>\n      \n      <audio ref={audioRef} className=\"hidden\" />\n      \n      {responses.length > 0 && (\n        <div className=\"mt-8\">\n          <h2 className=\"text-xl font-semibold mb-4\">Debate Transcript</h2>\n          \n          <div className=\"space-y-4\">\n            {responses.map((response, index) => (\n              <div \n                key={index}\n                className={`p-4 rounded ${\n                  response.agent === 'Optimist' ? 'bg-blue-100' : 'bg-gray-100'\n                }`}\n              >\n                <div className=\"flex justify-between items-center\">\n                  <div className=\"font-bold\">{response.agent}:</div>\n                  <button\n                    onClick={() => playAudio(response.text, response.agent)}\n                    disabled={isPlaying}\n                    className=\"text-sm px-2 py-1 bg-blue-500 text-white rounded disabled:bg-gray-300\"\n                  >\n                    {isPlaying ? 'Playing...' : 'Play'}\n                  </button>\n                </div>\n                <p className=\"mt-2\">{response.text}</p>\n              </div>\n            ))}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up Upstash Environment Variables in Bash\nDESCRIPTION: This snippet shows how to set up the necessary environment variables for Upstash credentials. It includes the Redis URL and token required for connecting to Upstash services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-upstash.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nUPSTASH_REDIS_REST_URL=your-redis-url\nUPSTASH_REDIS_REST_TOKEN=your-redis-token\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server - Bash\nDESCRIPTION: This snippet shows the command to start the development server for the OpenAPI spec generator application, allowing developers to view and test the application locally in their browser.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Streaming Response from Agent in TypeScript\nDESCRIPTION: This code snippet demonstrates how to stream a response from an agent using the `.stream()` method. It sends a user message to the agent and streams the agent's response chunk by chunk. This allows for a more real-time response experience. The input is an array of messages, and the output is a stream of text chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream([\n  { role: \"user\", content: \"Tell me a story.\" },\n]);\n\nconsole.log(\"Agent:\");\n\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Generate Agent Response with TypeScript\nDESCRIPTION: Generates a response from an agent based on the provided messages and context. It uses the agent's `generate` method, taking message array, optional thread ID, optional resource ID, and optional output configuration as parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await agent.generate({\n  messages: [\n    {\n      role: \"user\",\n      content: \"こんにちは、お元気ですか？\",\n    },\n  ],\n  threadId: \"thread-1\", // オプション: 会話コンテキストのスレッドID\n  resourceid: \"resource-1\", // オプション: リソースID\n  output: {}, // オプション: 出力設定\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Run State Interface\nDESCRIPTION: Defines the TypeScript interface representing the complete execution state of a Mastra workflow at a specific point in time. It includes core state information, context, active paths, metadata, child states, and suspended steps for supporting pause and resume functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/snapshots.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nexport interface WorkflowRunState {\n  // Core state info\n  value: Record<string, string>; // 現在の状態マシンの値\n  context: {\n    // ワークフローのコンテキスト\n    steps: Record<\n      string,\n      {\n        // ステップ実行結果\n        status: \"success\" | \"failed\" | \"suspended\" | \"waiting\" | \"skipped\";\n        payload?: any; // ステップ固有のデータ\n        error?: string; // 失敗した場合のエラー情報\n      }\n    >;\n    triggerData: Record<string, any>; // 初期トリガーデータ\n    attempts: Record<string, number>; // 残りの再試行回数\n    inputData: Record<string, any>; // 初期入力データ\n  };\n\n  activePaths: Array<{\n    // 現在アクティブな実行パス\n    stepPath: string[];\n    stepId: string;\n    status: string;\n  }>;\n\n  // メタデータ\n  runId: string; // ユニークな実行識別子\n  timestamp: number; // スナップショットが作成された時間\n\n  // ネストされたワークフローと中断されたステップのために\n  childStates?: Record<string, WorkflowRunState>; // 子ワークフローの状態\n  suspendedSteps?: Record<string, string>; // 中断されたステップのマッピング\n}\n```\n\n----------------------------------------\n\nTITLE: PromptAlignmentMetric example with analysis\nDESCRIPTION: Provides a more detailed example of using the PromptAlignmentMetric. It shows how to configure the metric with specific instructions related to formatting and content. It also demonstrates how to interpret the score and reasoning provided in the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/prompt-alignment.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PromptAlignmentMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new PromptAlignmentMetric(model, {\n  instructions: [\n    \"Use bullet points for each item\",\n    \"Include exactly three examples\",\n    \"End each point with a semicolon\"\n  ],\n  scale: 1\n});\n\nconst result = await metric.measure(\n  \"List three fruits\",\n  \"• Apple is red and sweet;\\n• Banana is yellow and curved;\\n• Orange is citrus and round.\"\n);\n\n// Example output:\n// {\n//   score: 1.0,\n//   info: {\n//     reason: \"The score is 1.0 because all instructions were followed exactly:\\n//           bullet points were used, exactly three examples were provided, and\\n//           each point ends with a semicolon.\"\n//   }\n// }\n\nconst result2 = await metric.measure(\n  \"List three fruits\",\n  \"1. Apple\\n2. Banana\\n3. Orange and Grape\"\n);\n\n// Example output:\n// {\n//   score: 0.33,\n//   info: {\n//     reason: \"The score is 0.33 because: numbered lists were used instead of bullet points,\\n//           no semicolons were used, and four fruits were listed instead of exactly three.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: This snippet shows how to configure the environment variables file by adding the Anthropic API key and Unsplash access token. These keys are necessary for the agent to access the required APIs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nANTHROPIC_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Streaming Agent Responses with Tool Call Working Memory in TypeScript\nDESCRIPTION: Shows how to interact with an agent using tool-call working memory, where memory updates happen through tool calls rather than inline text tags.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolCallResponse = await toolCallAgent.stream(\"Hello, my name is Jane\", {\n  threadId,\n  resourceId,\n});\n\n// No need to mask working memory tags since updates happen through tool calls\nfor await (const chunk of toolCallResponse.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Thread with Memory Class in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a new thread using the `createThread` method of the `Memory` class.  It requires the `@mastra/memory` package. It initializes a `Memory` instance and calls `createThread` with `resourceId`, `title`, and `metadata` to create a new thread. The created thread object is then assigned to the `thread` variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/createThread.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({ /* config */ });\nconst thread = await memory.createThread({\n  resourceId: \"user-123\",\n  title: \"Support Conversation\",\n  metadata: {\n    category: \"support\",\n    priority: \"high\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Query Messages with Context - Memory Class - TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve specific messages from a thread along with their surrounding context (previous and next messages). It utilizes the `include` option within `selectBy` to specify which messages to include and how many previous and next messages to retrieve.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/query.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  /* config */\n});\n\n// 特定のメッセージ周辺のコンテキストを含むメッセージを取得\nconst { messages: contextMessages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    include: [\n      {\n        id: \"msg-123\", // このメッセージのみを取得（コンテキストなし）\n      },\n      {\n        id: \"msg-456\", // カスタムコンテキスト付きでこのメッセージを取得\n        withPreviousMessages: 3, // 前の3件のメッセージ\n        withNextMessages: 1, // 次の1件のメッセージ\n      },\n    ],\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom LLM Judge in Mastra\nDESCRIPTION: Overview of creating a custom LLM judge for evaluating specific aspects of AI responses, with examples for medical Q&A, customer service, and code generation use cases.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/custom-eval.mdx#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## Creating a custom LLM-Judge\n\nA custom LLM judge helps evaluate specific aspects of your AI's responses. Think of it like having an expert reviewer for your particular use case:\n\n- Medical Q&A → Judge checks for medical accuracy and safety\n- Customer Service → Judge evaluates tone and helpfulness\n- Code Generation → Judge verifies code correctness and style\n\nFor a practical example, see how we evaluate [Chef Michel's](/docs/guides/chef-michel) recipes for gluten content in our [Gluten Checker example](/examples/evals/custom-eval).\n```\n\n----------------------------------------\n\nTITLE: Piping Audio Stream to a Destination\nDESCRIPTION: This snippet demonstrates how to pipe the generated audio stream to a specified destination. This is useful for directing output audio to audio players or further processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nstream.pipe(destination);\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Dash0 Telemetry\nDESCRIPTION: This TypeScript code snippet demonstrates how to initialize the Mastra framework with Dash0 telemetry support. It sets the service name and enables telemetry exports in the configuration object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/dash0.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Resume\nDESCRIPTION: Illustrates implementing conditional logic during workflow resumption based on the suspend payload. This example shows how to check the urgency and user role to determine whether to resume a step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/snapshots.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(async ({ activePaths }) => {\n  const isApprovalStepSuspended =\n    activePaths.get(\"approval\")?.status === \"suspended\";\n  if (isApprovalStepSuspended) {\n    const payload = activePaths.get(\"approval\")?.suspendPayload;\n    if (payload.urgency === \"high\" && currentUser.role === \"manager\") {\n      await resume({\n        stepId: \"approval\",\n        context: { approved: true, approver: currentUser.id },\n      });\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Import TextualDifferenceMetric\nDESCRIPTION: Imports the TextualDifferenceMetric class from the @mastra/evals/nlp package. This is a necessary dependency for using the text difference evaluation functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/textual-difference.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Building a Mastra project for Vercel (Bash)\nDESCRIPTION: Shows how to build a Mastra project for Vercel deployment using the command-line interface.  This process outputs the necessary configuration and entry point files to the `.mastra/output` directory, preparing the application for deployment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/vercel.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Configuring Chef Agent with Gluten Checker Metric (TypeScript)\nDESCRIPTION: Configures an AI agent named `chefAgent` using Mastra's `Agent` class.  It sets instructions for the agent to act as a helpful chef and attaches a `GlutenCheckerMetric` instance to evaluate the gluten content of the generated recipes. It uses `openai` to specify the language model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\n\nimport { GlutenCheckerMetric } from '../evals';\n\nexport const chefAgent = new Agent({\n  name: 'chef-agent',\n  instructions:\n    'あなたはMichel、実用的で経験豊富な家庭料理のシェフです' +\n    'あなたは人々が手元にある材料で料理をするのを手伝います。',\n  model: openai('gpt-4o-mini'),\n  evals: {\n    glutenChecker: new GlutenCheckerMetric(openai('gpt-4o-mini')),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Starting the Mastra Development Server (bash)\nDESCRIPTION: This command starts the Mastra development environment. By default, it runs on http://localhost:4111, but the port can be changed using the `--port` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/mastra-dev.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration\nDESCRIPTION: Defines the environment variables required for the application to function, including API keys for OpenAI, Cloudinary, and Roark Analytics. These variables are loaded from a `.env` file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=\nCLOUDINARY_CLOUD_NAME=\nCLOUDINARY_API_KEY=\nCLOUDINARY_API_SECRET=\nROARK_API_KEY=\n```\n\n----------------------------------------\n\nTITLE: useObject Hook Implementation - TypeScript (API Route)\nDESCRIPTION: This snippet demonstrates an API route for handling structured output using the `experimental_useObject` hook.  It imports the `mastra` instance, retrieves a specific agent, streams the agent's response based on the received messages, specifying an output schema using `z.object`. The route returns the stream as a text stream response using `toTextStreamResponse()` and relies on Zod for schema definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages, {\n    output: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return stream.toTextStreamResponse();\n}\n```\n\n----------------------------------------\n\nTITLE: Step-Level Error Handling in Typescript\nDESCRIPTION: This code demonstrates how to handle errors within a Mastra step using a `try...catch` block. Instead of throwing an error, it returns a fallback result, allowing the workflow to continue. It requires the `Step` class from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst robustStep = new Step({\n  id: 'robustStep',\n  execute: async ({ context }) => {\n    try {\n      // 主な操作を試みる\n      const result = await someRiskyOperation();\n      return { success: true, data: result };\n    } catch (error) {\n      // エラーを記録する\n      console.error('操作に失敗しました:', error);\n\n      // 例外を投げる代わりに優雅なフォールバック結果を返す\n      return {\n        success: false,\n        error: error.message,\n        fallbackData: 'デフォルト値'\n      };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Workflow Steps with Mastra\nDESCRIPTION: This code snippet defines three steps (`stepOne`, `stepTwo`, `stepThree`) using the `Step` class from `@mastra/core/workflows`. Each step has an `execute` function that processes data and returns a result.  `zod` is used for schema validation in the workflow trigger. Data is passed between steps using the `context` object, accessing the output of previous steps. The `Workflow` class is used to initialize the workflow and define the `triggerSchema` using `zod` for input validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/sequential-steps.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 }\n  },\n});\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) => {\n    if (context.steps.stepTwo.status !== \"success\") {\n      return { tripledValue: 0 }\n    }\n\n    return { tripledValue: context.steps.stepTwo.output.incrementedValue * 3 }\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Speech Audio\nDESCRIPTION: This snippet demonstrates how to stream audio for speech from a given text and voice model using the stream() method of the ReplicateTTS instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await tts.stream({\n  voice: 'model-id',\n  text: 'Hello from Mastra!',\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Bias Metric with OpenAI Model in TypeScript\nDESCRIPTION: Sets up the Bias metric using the OpenAI GPT-4 Mini model for evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new BiasMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork getAgentInteractionHistory() Method in TypeScript\nDESCRIPTION: This code snippet illustrates the `getAgentInteractionHistory()` method signature for the AgentNetwork class. It returns the interaction history for all agents in the network. The return type is a record where the key is a string (agent ID) and the value is an array of objects containing input, output, and timestamp.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentInteractionHistory(): Record<\n  string,\n  Array<{\n    input: string;\n    output: string;\n    timestamp: string;\n  }>\n>\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Mastra Hallucination Evaluation\nDESCRIPTION: This snippet shows how to set up the necessary environment variables in a .env file to use OpenAI's API with Mastra's Hallucination metric. The OPENAI_API_KEY is required for authentication with OpenAI's services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/hallucination.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Workflow.while() with Reference Condition\nDESCRIPTION: Shows how to use a reference condition with comparison operators to control the `.while()` loop.  The `ref` object specifies the step and path to a value, and the `query` object defines the comparison operator and target value. Requires a workflow, `incrementStep`, `finalStep`, and a step that produces a result with a 'value' property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/while.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(\n    {\n      ref: { step: incrementStep, path: 'value' },\n      query: { $lt: 10 }, // Continue as long as value is less than 10\n    },\n    incrementStep\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Initializing PGVector in TypeScript\nDESCRIPTION: This code snippet initializes the PGVector vector store using the PostgreSQL connection string obtained from the environment variables. This is a crucial step to establish the connection with the database and prepare it for vector storage and retrieval.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/query/hybrid-vector-search.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n```\n\n----------------------------------------\n\nTITLE: Performing Graph-Based Queries\nDESCRIPTION: Demonstrates how to use the configured Mastra agent to perform various graph-based queries on the processed data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryOne = \"What are the direct and indirect effects of early railway decisions on Riverdale Heights' current state?\";\nconst answerOne = await ragAgent.generate(queryOne);\nconsole.log('\\nQuery:', queryOne);\nconsole.log('Response:', answerOne.text);\n\nconst queryTwo = 'How have changes in transportation infrastructure affected different generations of local businesses and community spaces?';\nconst answerTwo = await ragAgent.generate(queryTwo);\nconsole.log('\\nQuery:', queryTwo);\nconsole.log('Response:', answerTwo.text);\n\nconst queryThree = 'Compare how the Rossi family business and Thompson Steel Works responded to major infrastructure changes, and how their responses affected the community.';\nconst answerThree = await ragAgent.generate(queryThree);\nconsole.log('\\nQuery:', queryThree);\nconsole.log('Response:', answerThree.text);\n\nconst queryFour = 'Trace how the transformation of the Thompson Steel Works site has influenced surrounding businesses and cultural spaces from 1932 to present.';\nconst answerFour = await ragAgent.generate(queryFour);\nconsole.log('\\nQuery:', queryFour);\nconsole.log('Response:', answerFour.text);\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra\nDESCRIPTION: This code snippet instantiates PgVector and Mastra with the configured agent. PgVector is initialized with the PostgreSQL connection string, and Mastra is initialized with the agent and vector configurations. This sets up the environment for using Mastra and PgVector in the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent('ragAgent');\n```\n\n----------------------------------------\n\nTITLE: Evaluating mixed position adherence in TypeScript\nDESCRIPTION: Shows how to evaluate a response where relevant information is scattered throughout the context using the Context Position metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-position.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Elephants are herbivores.',\n  'Adult elephants can weigh up to 13,000 pounds.',\n  'Elephants are the largest land animals.',\n  'Elephants eat plants and grass.',\n];\n\nconst metric2 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'How much do elephants weigh?';\nconst response2 = 'Adult elephants can weigh up to 13,000 pounds, making them the largest land animals.';\n\nconsole.log('Example 2 - Mixed Position Adherence:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.4, reason: 'The context includes relevant information and irrelevant information and is not in the correct sequential order.' }\n```\n\n----------------------------------------\n\nTITLE: Initializing Vector Query Tool with Filters\nDESCRIPTION: This snippet shows how to initialize the `createVectorQueryTool` with filtering enabled.  Enabling filters allows the tool to process queries and build metadata filters for enhanced search capabilities. This involves analyzing user queries to derive suitable filters for specific field requirements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/vector-query-tool.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst queryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  enableFilters: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing ChromaVector Store in TypeScript\nDESCRIPTION: Shows how to initialize a Chroma vector store, create an index with specific dimensions, and upsert vectors with metadata. Chroma is initialized without additional parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChromaVector } from '@mastra/chroma'\n\nconst store = new ChromaVector()\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Tone Consistency Dependencies in TypeScript\nDESCRIPTION: Imports the ToneConsistencyMetric class from the Mastra evals NLP package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/tone-consistency.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with Langfuse Exporter (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to configure Mastra to export telemetry data to Langfuse using the `LangfuseExporter`. It initializes a new `Mastra` instance and configures its `telemetry` option. The `serviceName` must be set to 'ai' for Langfuse to recognize it as an AI SDK trace. The code requires `@mastra/core` and `langfuse-vercel` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langfuse.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { LangfuseExporter } from \"langfuse-vercel\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"ai\", // this must be set to \"ai\" so that the LangfuseExporter thinks it's an AI SDK trace\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new LangfuseExporter({\n        publicKey: process.env.LANGFUSE_PUBLIC_KEY,\n        secretKey: process.env.LANGFUSE_SECRET_KEY,\n        baseUrl: process.env.LANGFUSE_BASEURL,\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Get Thread Details (TypeScript)\nDESCRIPTION: Retrieves the details of a specific thread. Requires a valid thread object obtained from `getMemoryThread`. Returns a detailed thread object with properties like title, metadata, etc.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await thread.get();\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareDeployer for Mastra\nDESCRIPTION: This snippet demonstrates how to initialize the CloudflareDeployer for deploying Mastra applications while configuring necessary parameters such as scope, projectName, routes, workerNamespace, and authentication details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/cloudflare.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { CloudflareDeployer } from '@mastra/deployer-cloudflare';\n\nconst mastra = new Mastra({\n  deployer: new CloudflareDeployer({\n    scope: 'your-account-id',\n    projectName: 'your-project-name',\n    routes: [\n      {\n        pattern: 'example.com/*',\n        zone_name: 'example.com',\n        custom_domain: true,\n      },\n    ],\n    workerNamespace: 'your-namespace',\n    auth: {\n      apiToken: 'your-api-token',\n      apiEmail: 'your-email',\n    },\n  }),\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Speech Services Credentials\nDESCRIPTION: This snippet outlines the environment variable configuration needed for Azure Speech Services. Both AZURE_API_KEY and AZURE_REGION are required for authenticating API requests.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_API_KEY=your_speech_service_key\nAZURE_REGION=your_azure_region\n```\n\n----------------------------------------\n\nTITLE: Rendering ShowcaseGrid Component in Next.js\nDESCRIPTION: This code imports and renders the ShowcaseGrid component that displays applications built with Mastra. The page uses frontmatter metadata to define the title and description of the page.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/showcase/index.mdx#2025-04-22_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nimport { ShowcaseGrid } from '@/components/showcase-grid';\n\n<ShowcaseGrid />\n```\n\n----------------------------------------\n\nTITLE: Multiple Suspension Points Example - TypeScript\nDESCRIPTION: This code shows an example of a workflow with multiple steps that can suspend execution. The `suspend` function is called with an optional payload containing data to be saved with the suspended state.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// 中断機能を持つステップを定義\nconst promptAgentStep = new Step({\n  id: \"promptAgent\",\n  execute: async ({ context, suspend }) => {\n    // 中断が必要かどうかを決定する条件\n    if (needHumanInput) {\n      // 中断状態と共に保存されるペイロードデータをオプションで渡す\n      await suspend({ requestReason: \"プロンプトのために人間の入力が必要\" });\n      // suspend()の後のコードはステップが再開されたときに実行されます\n      return { modelOutput: context.userInput };\n    }\n    return { modelOutput: \"AI生成の出力\" };\n  },\n  outputSchema: z.object({ modelOutput: z.string() }),\n});\n\nconst improveResponseStep = new Step({\n  id: \"improveResponse\",\n  execute: async ({ context, suspend }) => {\n    // 別の中断の条件\n    if (needFurtherRefinement) {\n      await suspend();\n      return { improvedOutput: context.refinedOutput };\n    }\n    return { improvedOutput: \"改善された出力\" };\n  },\n  outputSchema: z.object({ improvedOutput: z.string() }),\n});\n\n// ワークフローを構築\nconst workflow = new Workflow({\n  name: \"multi-suspend-workflow\",\n  triggerSchema: z.object({ input: z.string() }),\n});\n\nworkflow\n  .step(getUserInput)\n  .then(promptAgentStep)\n  .then(evaluateTone)\n  .then(improveResponseStep)\n  .then(evaluateImproved)\n  .commit();\n\n// Mastraにワークフローを登録\nexport const mastra = new Mastra({\n  workflows: { workflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Summary of Agent Interactions - TypeScript\nDESCRIPTION: The getAgentInteractionSummary() method returns a chronological summary of all agent interactions in the network. This summary can be used for reporting and analytical purposes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentInteractionSummary(): string\n```\n\n----------------------------------------\n\nTITLE: Configuring IBM TTS Environment Variables\nDESCRIPTION: This bash snippet is used to set required environment variables for connecting to IBM Watson's TTS service. Replace 'your_api_key' and 'your_service_url' with your actual API key and service URL.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nIBM_API_KEY=your_api_key\nIBM_URL=your_service_url\n```\n\n----------------------------------------\n\nTITLE: Processing Documents and Chunking for Mastra RAG\nDESCRIPTION: Creates a document and processes it into chunks for further processing in the RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc1 = MDocument.fromText(`\nmarket data shows price resistance levels.\ntechnical charts display moving averages.\nsupport levels guide trading decisions.\nbreakout patterns signal entry points.\nprice action determines trade timing.\n`);\n\nconst chunks = await doc1.chunk({\n  strategy: 'recursive',\n  size: 150,\n  overlap: 20,\n  separator: '\\n',\n});\n```\n\n----------------------------------------\n\nTITLE: Error Handling and Logging\nDESCRIPTION: This snippet demonstrates error handling and logging using try-catch blocks with MastraClient. It attempts to generate a response, logs the response if successful, and logs the error if an exception occurs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// エラー処理とログ記録の例\ntry {\n  const agent = client.getAgent(\"dev-agent-id\");\n  const response = await agent.generate({\n    messages: [{ role: \"user\", content: \"Test message\" }]\n  });\n  console.log(\"Response:\", response);\n} catch (error) {\n  console.error(\"Development error:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: Mastra Initialization - Full Options\nDESCRIPTION: This snippet demonstrates the full initialization of the Mastra class with all available options. It includes agents, workflows, integrations, a custom logger, storage, tools, and vectors.  It shows how to use the createLogger function from '@mastra/core/logger' to configure the logger.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/core/mastra-class.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\n// Full initialization with all options\nexport const mastra = new Mastra({\n  agents: {},\n  workflows: [],\n  integrations: [],\n  logger: createLogger({\n    name: \"My Project\",\n    level: \"info\",\n  }),\n  storage: {},\n  tools: {},\n  vectors: {},\n});\n```\n\n----------------------------------------\n\nTITLE: Query Semantic Search - Memory Class - TypeScript\nDESCRIPTION: This snippet showcases semantic searching within messages in a thread. It uses the `vectorSearchString` option in `selectBy` to find messages semantically similar to the given search string.  `threadConfig.historySearch` enables searching through the entire thread history.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/query.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  /* config */\n});\n\n// メッセージ内のセマンティック検索\nconst { messages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    vectorSearchString: \"デプロイメントについて何が議論されましたか？\",\n  },\n  threadConfig: {\n    historySearch: true,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables - Bash\nDESCRIPTION: This snippet demonstrates how to copy the sample environment variables file to a local configuration file, which is necessary for setting local environment variables in the OpenAPI spec generator application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.sample .env.local\n```\n\n----------------------------------------\n\nTITLE: TTS with Deepgram Voice Agent\nDESCRIPTION: This code shows how to use an Agent with Deepgram voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Deepgram's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { DeepgramVoice } from \"@mastra/voice-deepgram\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new DeepgramVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"aura-english-us\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Using a Custom Embedder (OpenAI)\nDESCRIPTION: This code demonstrates how to use a custom embedder, specifically an OpenAI embedding model, with the `Memory` class. It shows how to import the `openai` module from `@ai-sdk/openai` and pass an embedding model instance to the `embedder` configuration option. This is useful when local embedding is not supported or a different model is desired. The `agent` is then created using memory with a custom `embedder`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    embedder: openai.embedding(\"text-embedding-3-small\"), // Adds network request\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Querying with PgVector in TypeScript\nDESCRIPTION: This snippet demonstrates how to set up a PgVector instance and perform a query using a metadata filter. The query includes conditions on multiple fields such as category and price, and retrieves the top K results based on the specified query vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/metadata-filters.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PgVector } from '@mastra/pg';\n\nconst store = new PgVector(connectionString);\n\nconst results = await store.query({\n  indexName: \"my_index\",\n  queryVector: queryVector,\n  topK: 10,\n  filter: {\n    category: \"electronics\",  // Simple equality\n    price: { $gt: 100 },     // Numeric comparison\n    tags: { $in: [\"sale\", \"new\"] }  // Array membership\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Faithfulness Response in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a response where all claims are supported by the provided context, resulting in a high faithfulness score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'The Tesla Model 3 was launched in 2017.',\n  'It has a range of up to 358 miles.',\n  'The base model accelerates 0-60 mph in 5.8 seconds.',\n];\n\nconst metric1 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'Tell me about the Tesla Model 3.';\nconst response1 = 'The Tesla Model 3 was introduced in 2017. It can travel up to 358 miles on a single charge and the base version goes from 0 to 60 mph in 5.8 seconds.';\n\nconsole.log('Example 1 - High Faithfulness:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'All claims are supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Starting Next.js Development Server\nDESCRIPTION: Launches the Next.js development server which serves the front-end of the application. Ensure the Mastra server is running prior to starting this server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/interactive-story/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Initialize CompletenessMetric for evaluation\nDESCRIPTION: Initializes a new instance of the CompletenessMetric. This instance will be used to measure the completeness score between a reference text and a text to be evaluated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/completeness.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new CompletenessMetric();\n```\n\n----------------------------------------\n\nTITLE: Creating a New Vector Index in TypeScript\nDESCRIPTION: Establish a new vector index specifying parameters such as index name, dimension, and metric. Common metrics include 'cosine', 'euclidean', and 'dotproduct'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await vector.createIndex({\n  indexName: \"new-index\",\n  dimension: 128,\n  metric: \"cosine\", // 'cosine', 'euclidean', or 'dotproduct'\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with OpenAI Voice\nDESCRIPTION: This snippet demonstrates how to initialize an Agent with OpenAI voice capabilities using the @mastra/core/agent, @ai-sdk/openai, and @mastra/voice-openai libraries. It creates a new agent with a specified name, instructions, model, and voice configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\n\n// Initialize OpenAI voice for TTS\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Memory Setup with Processors (TypeScript)\nDESCRIPTION: This TypeScript snippet creates a Memory instance with a TokenLimiter and a ToolCallFilter. The TokenLimiter restricts the total number of tokens stored in memory, while the ToolCallFilter removes tool calls from the memory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { TokenLimiter, ToolCallFilter } from \"@mastra/memory/processors\";\n\n// Create memory with processors\nconst memory = new Memory({\n  processors: [new TokenLimiter(127000), new ToolCallFilter()],\n});\n```\n\n----------------------------------------\n\nTITLE: Deleting Index in Upstash Vector Store in TypeScript\nDESCRIPTION: The `deleteIndex()` method removes a specified index from the Upstash vector store by its name. This function facilitates index management.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index (namespace) to delete\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Listening for Audio Data and Piping to Speaker\nDESCRIPTION: This snippet shows how to register an event listener for the 'speaker' event on a voice provider.  The 'speaker' event emits a stream of audio data, which is then piped to a Speaker object for playback.  The Speaker configuration specifies the sample rate, channels, and bit depth of the audio.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.on.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Listen for audio data and play it\nconst speaker = new Speaker({\n  sampleRate: 24100,\n  channels: 1,\n  bitDepth: 16,\n});\n\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker);\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Speech in TypeScript\nDESCRIPTION: This TypeScript snippet illustrates how to stream speech output from the IBM Watson TTS service based on the specified voice and text. It demonstrates the usage of the stream method from the IBMTTS class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await tts.stream({\n  voice: 'en-US_AllisonV3Voice',\n  text: 'Hello from Mastra!',\n});\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/core Package using npm\nDESCRIPTION: This command demonstrates how to install the `@mastra/core` package using npm. This package is necessary for using the `Agent` class. Ensure that npm is installed and configured correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/core\n```\n\n----------------------------------------\n\nTITLE: Customizing Document Chunking Parameters in TypeScript\nDESCRIPTION: This code snippet provides an example of how to customize document chunking parameters using the Mastra library in TypeScript. It involves creating a document with specific metadata, and modifying chunking parameters like chunk size, overlap, and separator strategy to tailor the chunking process. Main prerequisites include the `@mastra/rag` package. The output is an array of document chunks which are then processed according to custom logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/document-chunker-tool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst technicalDoc = new MDocument({\n  text: longDocumentContent,\n  metadata: {\n    type: \"technical\",\n    version: \"1.0\"\n  }\n});\n\nconst chunker = createDocumentChunkerTool({\n  doc: technicalDoc,\n  params: {\n    strategy: \"recursive\",\n    size: 1024,      // Larger chunks\n    overlap: 100,    // More overlap\n    separator: \"\\n\\n\" // Split on double newlines\n  }\n});\n\nconst { chunks } = await chunker.execute();\n\n// Process the chunks\nchunks.forEach((chunk, index) => {\n  console.log(`Chunk ${index + 1} length: ${chunk.content.length}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Resuming a Workflow Asynchronously with TypeScript\nDESCRIPTION: This code demonstrates how to resume a paused workflow step asynchronously and wait for the complete execution result using the Mastra API. It calls `workflow.resumeAsync` with the `runId`, `stepId`, and `contextData`. It is assumed the `createRun` function exists and takes `prevRunId` as an argument.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst {runId} = createRun({runId: prevRunId})\n\nconst result = await workflow.resumeAsync({\n  runId,\n  stepId: \"step-id\",\n  contextData: { key: \"value\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Looping with 'while' in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to use the `while` method to create a loop that repeats a step as long as a specified condition is true. The `incrementStep` is repeated while the `updatedCounter` is less than 10.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// ターゲット未満の間カウンターをインクリメントするステップ\nconst incrementStep = new Step({\n  id: 'increment',\n  inputSchema: z.object({\n    // 現在のカウンター値\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // 更新されたカウンター値\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      // カウンターが10未満の間継続\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) < 10;\n    },\n    incrementStep,\n    {\n      // 現在のカウンターを次の反復に渡す\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(\n    {\n      ref: { step: incrementStep, path: 'updatedCounter' },\n      query: { $lt: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: 'updatedCounter'\n      }\n    }\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Installing GitHub Integration Package\nDESCRIPTION: Command to install the GitHub integration package via npm\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/github\n```\n\n----------------------------------------\n\nTITLE: Example Filter for Metadata Queries\nDESCRIPTION: This code snippet shows an example of a filter used for metadata queries. It utilizes logical and comparison operators (`$and`, `$gt`, `$in`) to refine search results based on specific criteria, such as age being greater than 25 and tags including 'tag1' or 'tag2'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  $and: [{ age: { $gt: 25 } }, { tags: { $in: ['tag1', 'tag2'] } }];\n}\n```\n\n----------------------------------------\n\nTITLE: ToneConsistencyMetric Basic Usage TypeScript\nDESCRIPTION: Demonstrates the basic usage of the ToneConsistencyMetric to compare tone between input/output pairs and analyze tone stability within a single text. It initializes the metric, calls the measure() function in both modes, and logs the resulting scores.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/tone-consistency.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ToneConsistencyMetric();\n\n// Compare tone between input and output\nconst result1 = await metric.measure(\n  \"I love this amazing product!\",\n  \"This product is wonderful and fantastic!\"\n);\n\n// Analyze tone stability in a single text\nconst result2 = await metric.measure(\n  \"The service is excellent. The staff is friendly. The atmosphere is perfect.\",\n  \"\"  // Empty string for single-text analysis\n);\n\nconsole.log(result1.score); // Tone consistency score from 0-1\nconsole.log(result2.score); // Tone stability score from 0-1\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry with OtelConfig in Mastra (Typescript)\nDESCRIPTION: This code snippet demonstrates how to configure OpenTelemetry within a Mastra application using the `OtelConfig` object. It showcases setting the service name, enabling telemetry, configuring sampling with a ratio of 0.5, and exporting telemetry data to an OTLP endpoint with custom headers, including an authorization token. The example requires the 'mastra' package to be installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/otel-config.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from 'mastra';\n\nconst otelConfig: OtelConfig = {\n  serviceName: 'my-awesome-service',\n  enabled: true,\n  sampling: {\n    type: 'ratio',\n    probability: 0.5,\n  },\n  export: {\n    type: 'otlp',\n    endpoint: 'https://otel-collector.example.com/v1/traces',\n    headers: {\n      Authorization: 'Bearer YOUR_TOKEN_HERE',\n    },\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Retrieving available speakers using ElevenLabsVoice\nDESCRIPTION: This snippet demonstrates how to retrieve a list of available speakers using the getSpeakers method of the ElevenLabsVoice class. The method returns an array of objects, each containing information about a specific speaker, such as voiceId, name, language, and gender. An ElevenLabs API key is required to access the available speakers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/elevenlabs.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// 利用可能なスピーカーを取得\nconst speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Step-Level Retry Configuration in Mastra (TypeScript)\nDESCRIPTION: This code snippet shows how to configure retry settings for a specific step within a Mastra workflow. This configuration overrides the workflow-level settings. It specifies the number of attempts and the delay between each retry for the `apiStep` execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/error-handling.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst apiStep = new Step({\n  id: 'callApi',\n  execute: async () => {\n    // API call that might fail\n  },\n  retryConfig: {\n    attempts: 5,    // This step will retry up to 5 times\n    delay: 2000,    // With a 2-second delay between retries\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Context Precision Metric\nDESCRIPTION: This snippet demonstrates how to import the necessary dependencies from the OpenAI SDK and Mastra's evaluation library to use the Context Precision metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-precision.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextPrecisionMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Merging Multiple Workflow Branches with after() in Mastra\nDESCRIPTION: Shows how to execute a step only after multiple preceding steps have completed using the compound .after([]) syntax, which creates synchronization points in the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(fetchUserData)\n  .then(validateUserData)\n  .step(fetchProductData)\n  .then(validateProductData)\n  // This step will only run after BOTH validateUserData AND validateProductData have completed\n  .after([validateUserData, validateProductData])\n  .step(processOrder)\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAI Voice with TypeScript\nDESCRIPTION: Examples of initializing the PlayAI voice provider with different configuration options. Shows both default initialization (using environment variables) and explicit configuration with custom speech model and speaker selection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/playai.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\n// Initialize with default configuration (uses PLAYAI_API_KEY environment variable and PLAYAI_USER_ID environment variable)\nconst voice = new PlayAIVoice();\n\n// Initialize with default configuration\nconst voice = new PlayAIVoice({\n  speechModel: {\n    name: 'PlayDialog',\n    apiKey: process.env.PLAYAI_API_KEY,\n    userId: process.env.PLAYAI_USER_ID\n  },\n  speaker: 'Angelo'  // Default voice\n});\n\n// Convert text to speech with a specific voice\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 's3://voice-cloning-zero-shot/b27bc13e-996f-4841-b584-4d35801aea98/original/manifest.json' // Dexter voice\n});\n```\n\n----------------------------------------\n\nTITLE: Advanced FaithfulnessMetric Example in TypeScript\nDESCRIPTION: Illustrates a more complex scenario with mixed claim types, showcasing how the FaithfulnessMetric handles uncertain claims. It sets up the metric with a specific context and then evaluates a response that includes both factual and speculative statements, providing insights into the scoring and reasoning process. Requires `@ai-sdk/openai` and `@mastra/evals/llm` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/faithfulness.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { FaithfulnessMetric } from \"@mastra/evals/llm\";\n\n// 評価のためのモデルを設定\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new FaithfulnessMetric(model, {\n  context: [\n    \"その会社は2020年に100人の従業員がいました。\",\n    \"現在の従業員数は約500人です。\",\n  ],\n});\n\n// 混合された主張タイプの例\nconst result = await metric.measure(\n  \"会社の成長はどのようなものですか？\",\n  \"その会社は2020年に100人の従業員から現在500人に成長し、来年には1000人に拡大するかもしれません。\",\n);\n\n// 出力例:\n// {\n//   score: 0.67,\n//   info: {\n//     reason: \"スコアが0.67である理由は、2つの主張がコンテキストによってサポートされているためです\n//           （2020年の初期従業員数100人と現在の500人の数）、\n//           将来の拡大の主張はコンテキストに対して検証できないため不確実とされています。\"\n//   }\n// }\n\n```\n\n----------------------------------------\n\nTITLE: Speak Method Basic Usage with OpenAIVoice\nDESCRIPTION: Demonstrates basic usage of the `speak()` method with the `OpenAIVoice` provider, including initializing the provider, using the default voice, and specifying different voices and provider-specific options. The example uses string input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.speak.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\n// 音声プロバイダーを初期化\nconst voice = new OpenAIVoice({\n  speaker: \"alloy\", // デフォルトの音声\n});\n// デフォルト設定での基本的な使用法\nconst audioStream = await voice.speak(\"こんにちは、世界！\");\n// この特定のリクエストに異なる音声を使用\nconst audioStreamWithDifferentVoice = await voice.speak(\"再びこんにちは！\", {\n  speaker: \"nova\",\n});\n// プロバイダー固有のオプションを使用\nconst audioStreamWithOptions = await voice.speak(\"オプション付きでこんにちは！\", {\n  speaker: \"echo\",\n  speed: 1.2, // OpenAI固有のオプション\n});\n```\n\n----------------------------------------\n\nTITLE: Registering an Agent with Mastra in TypeScript\nDESCRIPTION: This code snippet demonstrates how to register an agent with Mastra using the `Mastra` class from `@mastra/core`. It imports the agent created earlier and registers it with the Mastra instance. This registration enables logging and access to configured tools and integrations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { myAgent } from \"./agents\";\n\nexport const mastra = new Mastra({\n  agents: { myAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Enabling Telemetry with OTLP Export in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to enable telemetry in Mastra with OTLP (OpenTelemetry Protocol) export. It sets the service name, enables telemetry, configures sampling to be always on, and specifies the OTLP endpoint for exporting telemetry data. This configuration exports the telemetry data to a local SigNoz endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/tracing.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nexport const mastra = new Mastra({\n  // ... 他の設定\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    sampling: {\n      type: \"always_on\",\n    },\n    export: {\n      type: \"otlp\",\n      endpoint: \"http://localhost:4318\", // SigNozのローカルエンドポイント\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Get All Memory Threads (TypeScript)\nDESCRIPTION: Retrieves all memory threads for a specific resource and agent. It requires resourceId and agentId to identify the threads to retrieve. The method returns a list of memory threads.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst threads = await client.getMemoryThreads({\n  resourceId: \"resource-1\",\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example of how to set up the environment variables file with API keys for OpenAI and Pinecone.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPINECONE_API_KEY=your-pinecone-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Project for Netlify (Bash)\nDESCRIPTION: This command shows how to build a Mastra project for deployment to Netlify. It utilizes the Mastra CLI to generate the necessary output files in the `.mastra/output` directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/netlify.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Initializing DeepgramVoice with default configuration\nDESCRIPTION: This code snippet demonstrates initializing the DeepgramVoice class with the default configuration. It assumes that the Deepgram API key is set as an environment variable named `DEEPGRAM_API_KEY`. This provides a simple way to instantiate the Deepgram voice service with minimal setup.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/deepgram.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DeepgramVoice } from \"@mastra/voice-deepgram\";\n\n// Initialize with default configuration (uses DEEPGRAM_API_KEY environment variable)\nconst voice = new DeepgramVoice();\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra in a Next.js project using pnpm\nDESCRIPTION: This command initializes Mastra in a Next.js project using the pnpm package manager. It executes the mastra package and sets up Mastra within the Next.js environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npnpm dlx mastra@latest init\n```\n\n----------------------------------------\n\nTITLE: Next.js Image Component Configuration\nDESCRIPTION: This snippet configures the dynamic import for the Next.js Image component, specifying the JavaScript chunks required to load it and the component identifier.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_17\n\nLANGUAGE: javascript\nCODE:\n```\n17:I[1333,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"Image\"]\n```\n\n----------------------------------------\n\nTITLE: Installation using npm\nDESCRIPTION: Installs the @mastra/voice-cloudflare package from npm. This is the first step to integrate the package into your project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-cloudflare\n```\n\n----------------------------------------\n\nTITLE: Importing ProviderTable Component for AI Model Capabilities in JSX\nDESCRIPTION: This code imports a ProviderTable component from the components directory, which is used to display a comparison table of AI model capabilities across different providers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/model-capability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nimport { ProviderTable } from \"@/components/provider-table\";\n```\n\n----------------------------------------\n\nTITLE: Creating Agent Directory and File (Bash)\nDESCRIPTION: This command creates a directory structure for Mastra agents and a TypeScript file for the weather agent. It uses the `mkdir` command with the `-p` flag to create parent directories if they don't exist and the `touch` command to create the `weather.ts` file within the agent's directory. This sets up the initial file structure for defining the weather agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/agents && touch src/mastra/agents/weather.ts\n```\n\n----------------------------------------\n\nTITLE: Executing Steps Sequentially in Mastra Workflows\nDESCRIPTION: Shows how to chain steps in a specific order using the .then() method to ensure outputs from one step become inputs for the next step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow.step(fetchOrderData).then(validateData).then(processOrder);\n```\n\n----------------------------------------\n\nTITLE: Mastra Agent with Stdio Server Example\nDESCRIPTION: This example demonstrates how to use MastraMCPClient with a Mastra Agent, connecting to an MCP server via stdio.  It initializes the client, connects to the server (using a Docker container in this case), retrieves available tools, and then uses those tools within the agent to answer a user query.  Error handling and proper disconnection are included.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { MastraMCPClient } from \"@mastra/mcp\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize the MCP client using mcp/fetch as an example https://hub.docker.com/r/mcp/fetch\n// Visit https://github.com/docker/mcp-servers for other reference docker mcp servers\nconst fetchClient = new MastraMCPClient({\n  name: \"fetch\",\n  server: {\n    command: \"docker\",\n    args: [\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n    logger: (logMessage) => {\n      console.log(`[${logMessage.level}] ${logMessage.message}`);\n    },\n  },\n});\n\n// Create a Mastra Agent\nconst agent = new Agent({\n  name: \"Fetch agent\",\n  instructions:\n    \"You are able to fetch data from URLs on demand and discuss the response data with the user.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\ntry {\n  // Connect to the MCP server\n  await fetchClient.connect();\n\n  // Gracefully handle process exits so the docker subprocess is cleaned up\n  process.on(\"exit\", () => {\n    fetchClient.disconnect();\n  });\n\n  // Get available tools\n  const tools = await fetchClient.tools();\n\n  // Use the agent with the MCP tools\n  const response = await agent.generate(\n    \"Tell me about mastra.ai/docs. Tell me generally what this page is and the content it includes.\",\n    {\n      toolsets: {\n        fetch: tools,\n      },\n    },\n  );\n\n  console.log(\"\\n\\n\" + response.text);\n} catch (error) {\n  console.error(\"Error:\", error);\n} finally {\n  // Always disconnect when done\n  await fetchClient.disconnect();\n}\n```\n\n----------------------------------------\n\nTITLE: Agent tool population with getTools()\nDESCRIPTION: This code shows how to populate an Agent with tools retrieved from the MCPConfiguration using the `getTools()` method. The tool names are namespaced with the server name to prevent conflicts. It is intended to be passed to an Agent definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nnew Agent({ tools: await mcp.getTools() });\n```\n\n----------------------------------------\n\nTITLE: Register Agent (TypeScript)\nDESCRIPTION: This TypeScript code creates the Mastra entry point and registers the `weatherAgent`. This allows the `mastra dev` command to detect and serve the agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nimport { weatherAgent } from \"./agents/weather\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Example Application\nDESCRIPTION: Command to start the example application that demonstrates result re-ranking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Workflow Execution Example (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create a new workflow, define steps, commit the workflow, and then execute it with trigger data. It showcases the basic usage of the `Workflow.execute()` method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/execute.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number()\n  })\n});\n\nworkflow.step(stepOne).then(stepTwo).commit();\n\nconst result = await workflow.execute({\n  triggerData: { inputValue: 42 }\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow While Loop with Function Condition\nDESCRIPTION: Illustrates using a function as a condition for the `.while()` method. The loop continues as long as the function returns true, using context to retrieve step results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/while.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(async ({ context }) => {\n    const result = context.getStepResult<{ value: number }>('increment');\n    return (result?.value ?? 0) < 10; // 値が10未満である限り続行\n  }, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Workflow.until() with Reference Condition (TypeScript)\nDESCRIPTION: Demonstrates the usage of a reference-based condition in the `.until()` method, comparing the value of a specific step's output (`incrementStep`, path: 'value') against a query condition (`$gte: 10`). This approach leverages comparison operators for defining the loop's termination condition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/until.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .until(\n    {\n      ref: { step: incrementStep, path: 'value' },\n      query: { $gte: 10 }, // Stop when value is greater than or equal to 10\n    },\n    incrementStep\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Environment File Copy\nDESCRIPTION: Command to create environment file from template\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Starting Mastra Development Server\nDESCRIPTION: Starts the Mastra development server, which is essential for the back-end operations of the application. Make sure to complete the initial setup steps before execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/interactive-story/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm mastra:dev\n```\n\n----------------------------------------\n\nTITLE: Serving the Application (Bash)\nDESCRIPTION: Command to start the Mastra server, which exposes the stock agent via REST API endpoints for testing and interaction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev --dir src\n```\n\n----------------------------------------\n\nTITLE: Describing Index Statistics\nDESCRIPTION: This code snippet defines the `PGIndexStats` interface. It represents the structure of the object returned by the `describeIndex` method. The interface describes the dimension, count, metric, type, and configuration of a PGVector index, providing detailed information about the index's characteristics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ninterface PGIndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n  type: \"flat\" | \"hnsw\" | \"ivfflat\";\n  config: {\n    m?: number;\n    efConstruction?: number;\n    lists?: number;\n    probes?: number;\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ContentSimilarityMetric in Mastra\nDESCRIPTION: Shows how to initialize a new instance of ContentSimilarityMetric that will be used to measure text similarity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ContentSimilarityMetric();\n```\n\n----------------------------------------\n\nTITLE: Dynamic Configuration Handling - TypeScript\nDESCRIPTION: This snippet exemplifies how to dynamically receive and validate configurations within the `McpConfiguration` class. It retrieves a server definition, builds a UI for user input, and adds the validated configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst server = await registry.getServerDefinition({\n\tid: \"git-ref\",\n})\n\nconst userInput = await buildServerUI(server.schema)\n\nawait configuration.add({\n\tserver,\n\tconfig: userInput,\n})\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Tone in TypeScript\nDESCRIPTION: Demonstrates evaluation of texts with varying sentiment patterns and analysis of their consistency.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/tone-consistency.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'The interface is frustrating and confusing, though it has potential.';\nconst output3 = 'The design shows promise but needs significant improvements to be usable.';\n\nconsole.log('Example 3 - Mixed Tone:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: result3.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Building Prompt Components in TypeScript\nDESCRIPTION: Demonstrates constructing a debug prompt with components like main text, context, constraints, examples, and reasoning approach. These elements help guide the task focusing on syntax error correction in a code snippet.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst debugPrompt = createPrompt('Debug this code')\n  // Main input text\n  .text('function add(x,y) { retrun x + y }')\n\n  // Background information\n  .context('This is part of a calculator app')\n\n  // Response boundaries\n  .constraints(['Fix only syntax errors', 'Keep the logic the same'])\n\n  // Guide with examples\n  .examples([\n    {\n      input: 'function sub(x,y) { reutrn x - y }',\n      output: 'function sub(x,y) { return x - y }',\n    },\n  ])\n\n  // Reasoning approach\n  .thinking({\n    autoChainOfThought: true,\n    steps: ['Identify syntax errors', 'Apply corrections'],\n  });\n\n// Usage\nconst debug = debugPrompt.toString();\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow Example\nDESCRIPTION: Command to start and execute the workflow example application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-cyclical-deps/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and Postgres\nDESCRIPTION: Configuration of environment variables required for OpenAI API access and PostgreSQL connection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Updating Index Metadata Only by ID\nDESCRIPTION: This snippet illustrates updating only the metadata of a vector in the index, identified by its ID. The `updateIndexById` method is invoked with the index name, ID, and a partial update object containing the updated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// メタデータのみを更新\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  metadata: { label: \"updated\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Describing an Index in ChromaVector\nDESCRIPTION: Retrieves details of a specific index, including dimension, count, and distance metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to describe\",\n    },\n  ]}/>\n\nReturns:\n\n```typescript copy\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Using Transports with Mastra Core\nDESCRIPTION: Complete example showing how to integrate both FileTransport and UpstashTransport with Mastra Core logger, including initialization and usage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/loggers/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger } from '@mastra/core/logger';\nimport { FileTransport, UpstashTransport } from '@mastra/loggers';\n\n// Create transports\nconst fileTransport = new FileTransport({\n  path: '/var/log/app.log',\n});\n\nconst upstashTransport = new UpstashTransport({\n  upstashUrl: process.env.UPSTASH_URL!,\n  upstashToken: process.env.UPSTASH_TOKEN!,\n});\n\n// Create logger with multiple transports\nconst logger = new Logger({\n  transports: [fileTransport, upstashTransport],\n});\n\n// Log messages\nlogger.info('Hello world', { metadata: 'value' });\n\n// Query logs\nconst allLogs = await fileTransport.getLogs();\nconst runLogs = await upstashTransport.getLogsByRunId({ runId: 'abc-123' });\n```\n\n----------------------------------------\n\nTITLE: Creating a new Mastra project using npm\nDESCRIPTION: This command creates a new Mastra project using the npm package manager. It installs and executes the create-mastra package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Tool Call Working Memory in TypeScript\nDESCRIPTION: Creates a Memory instance with working memory enabled in tool-call mode, which is required when using toDataStream() as it's not compatible with text-stream mode.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolCallMemory = new Memory({\n  options: {\n    workingMemory: {\n      enabled: true,\n      use: \"tool-call\", // Required for toDataStream() compatibility\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Import ToneConsistencyMetric in TypeScript\nDESCRIPTION: This code snippet imports the ToneConsistencyMetric class from the @mastra/evals/nlp package. This metric is used to evaluate the tone consistency of text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/tone-consistency.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for Contextual Recall\nDESCRIPTION: This TypeScript snippet imports the necessary dependencies from the `@ai-sdk/openai` and `@mastra/evals/llm` libraries. It imports the `openai` function from `@ai-sdk/openai` for interacting with the OpenAI API and the `ContextualRecallMetric` class from `@mastra/evals/llm` for evaluating contextual recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/contextual-recall.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextualRecallMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Disconnecting from MCP Server in TypeScript\nDESCRIPTION: The disconnect method closes the existing connection to the MCP server asynchronously. It requires no inputs and returns a void promise when the disconnection is completed. Always ensure to call this method to clean up resources properly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync disconnect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Basic afterEvent() Usage Example - Typescript\nDESCRIPTION: Demonstrates a basic usage of the `afterEvent()` method within a Mastra workflow. The workflow defines an 'approval' event with a schema, includes a suspension point awaiting the 'approval' event using `afterEvent('approval')`, and defines subsequent steps to be executed after the event is triggered. The workflow suspends after `submitRequest` until the `approval` event occurs, and then it executes `processApproval`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/afterEvent.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Define workflow with events\nconst workflow = new Workflow({\n  name: 'approval-workflow',\n  events: {\n    approval: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n  },\n});\n\n// Build workflow with event suspension point\nworkflow\n  .step(submitRequest)\n  .afterEvent('approval')    // Workflow suspends here\n  .step(processApproval)     // This step runs after the event occurs\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables\nDESCRIPTION: Example of setting required environment variables for GitHub integration\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nGITHUB_PAT=your_personal_access_token\n```\n\n----------------------------------------\n\nTITLE: Custom Configuration of AnswerRelevancyMetric in TypeScript\nDESCRIPTION: This code snippet demonstrates how to customize the AnswerRelevancyMetric with different options, such as uncertaintyWeight and scale.  It initializes the metric with custom weights and scale, then measures the relevance of an answer. The result includes a score (0-5) and detailed reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/answer-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { AnswerRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new AnswerRelevancyMetric(\n  model,\n  {\n    uncertaintyWeight: 0.5, // Higher weight for uncertain verdicts\n    scale: 5, // Use 0-5 scale instead of 0-1\n  },\n);\n\nconst result = await metric.measure(\n  \"What are the benefits of exercise?\",\n  \"Regular exercise improves cardiovascular health, builds strength, and boosts mental wellbeing.\",\n);\n\n// Example output:\n// {\n//   score: 4.5,\n//   info: {\n//     reason: \"The score is 4.5 out of 5 because the response directly addresses the query\n//           with specific, accurate benefits of exercise. It covers multiple aspects\n//           (cardiovascular, muscular, and mental health) in a clear and concise manner.\n//           The answer is highly relevant and provides appropriate detail without\n//           including unnecessary information.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork getAgentInteractionSummary() Method in TypeScript\nDESCRIPTION: This code snippet shows the `getAgentInteractionSummary()` method signature for the AgentNetwork class. It returns a formatted summary of agent interactions in chronological order. The return type is a string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentInteractionSummary(): string\n```\n\n----------------------------------------\n\nTITLE: Deleting a Vector by ID\nDESCRIPTION: This code snippet demonstrates how to delete a specific vector from the index using its ID.  The `deleteIndexById` method is used to remove the vector associated with the given ID from the specified index. This permanently removes the vector and its associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nawait pgVector.deleteIndexById(\"my_vectors\", \"vector123\");\n```\n\n----------------------------------------\n\nTITLE: Starting a Workflow Asynchronously with TypeScript\nDESCRIPTION: This code shows how to start a workflow execution asynchronously with trigger data using the Mastra API. `workflow.startAsync` is called with a `runId` and `triggerData`. It awaits the result, implying it returns a Promise. The `createRun` method is used to generate a new `runId` before starting the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst {runId} = workflow.createRun()\n\nconst result = await workflow.startAsync({\n  runId,\n  triggerData: {\n    param1: \"value1\",\n    param2: \"value2\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the query() method for finding similar vectors in the Turbopuffer vector store. It includes parameters for the index name, query vector, and options for filtering results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to query\",\n    },\n    {\n      name: \"queryVector\",\n      type: \"number[]\",\n      description: \"Query vector to find similar vectors\",\n    },\n    {\n      name: \"topK\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"10\",\n      description: \"Number of results to return\",\n    },\n    {\n      name: \"filter\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"Metadata filters for the query\",\n    },\n    {\n      name: \"includeVector\",\n      type: \"boolean\",\n      isOptional: true,\n      defaultValue: \"false\",\n      description: \"Whether to include vectors in the results\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Langfuse Exporter\nDESCRIPTION: This TypeScript snippet demonstrates how to configure the Mastra observability platform to utilize the Langfuse exporter. It emphasizes setting the 'serviceName' to 'ai' for proper functioning of the integration and outlines the parameters for the LangfuseExporter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langfuse.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { LangfuseExporter } from \"langfuse-vercel\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"ai\", // this must be set to \"ai\" so that the LangfuseExporter thinks it's an AI SDK trace\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new LangfuseExporter({\n        publicKey: process.env.LANGFUSE_PUBLIC_KEY,\n        secretKey: process.env.LANGFUSE_SECRET_KEY,\n        baseUrl: process.env.LANGFUSE_BASEURL,\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Use Memory Threads (TypeScript)\nDESCRIPTION: This TypeScript code snippet shows how to use memory threads within Mastra. It calls the `stream` method on a memory agent with a message, resourceId, and threadId. This is required for the agent to use memory properly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myMemoryAgent.stream(\"Hello, my name is Alice.\", {\n  resourceId: \"user_alice\",\n  threadId: \"conversation_123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Running Development Server for Next.js\nDESCRIPTION: This snippet shows how to start a development server for a Next.js application using various package managers like npm, yarn, pnpm, and bun. Ensure that you have one of these package managers installed before running the commands.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/ai-sdk-useChat/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Running the Multi-Agent System in Typescript\nDESCRIPTION: This snippet demonstrates how to use the complete multi-agent system. It retrieves the 'Publisher' agent from the Mastra instance, calls its generate method with a topic, and logs the final edited copy to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/hierarchical-multi-agent.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const agent = mastra.getAgent(\"publisherAgent\");\n  const result = await agent.generate(\n    \"Write a blog post about React JavaScript frameworks. Only return the final edited copy.\",\n  );\n  console.log(result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with High Context Relevancy\nDESCRIPTION: This snippet demonstrates how to evaluate a response where all context is relevant. It defines a context array, initializes a `ContextRelevancyMetric` instance, defines a query and a corresponding response, measures the context relevancy, and prints the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-relevancy.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'アインシュタインは光電効果の発見でノーベル賞を受賞しました。',\n  '彼は1905年に相対性理論を発表しました。',\n  '彼の研究は現代物理学を革命的に変えました。',\n];\n\nconst metric1 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'アインシュタインの業績のいくつかは何ですか？';\nconst response1 = 'アインシュタインは光電効果の発見でノーベル賞を受賞し、画期的な相対性理論を発表しました。';\n\nconsole.log('例 1 - 高い関連性:');\nconsole.log('コンテキスト:', context1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 1, reason: 'コンテキストはすべての関連情報を使用し、無関係な情報を含んでいません。' }\n```\n\n----------------------------------------\n\nTITLE: Telemetry Configuration with Environment Variables (TypeScript)\nDESCRIPTION: This code demonstrates how Mastra configuration can leverage environment variables for telemetry settings.  The endpoint and headers are omitted in the config, as they will be automatically picked up from environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/tracing.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n      // endpoint and headers will be picked up from env vars\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLStore for Development\nDESCRIPTION: This code snippet demonstrates how to initialize the `LibSQLStore` for development purposes using a file-based SQLite database.  The `url` parameter in the `config` object specifies the path to the database file. This is suitable for development and testing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/libsql.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\n\n// File database (development)\nconst storage = new LibSQLStore({\n    config: {\n        url: 'file:storage.db',\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Mapping Between Steps in Mastra Workflow\nDESCRIPTION: Demonstrates how to map data from one step to another in a Mastra workflow, showing the process of generating data in one step and processing it in the next.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/variables.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow, Mastra } from \"@mastra/core\";\nimport { z } from \"zod\";\n\n// Step 1: Generate data\nconst generateData = new Step({\n  id: \"generateData\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async () => {\n    return {\n      nested: {\n        value: \"step1-data\"\n      }\n    };\n  },\n});\n\n// Step 2: Process the data from step 1\nconst processData = new Step({\n  id: \"processData\",\n  inputSchema: z.object({\n    previousValue: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // previousValue will be available because of the variable mapping\n    const { previousValue } = context.inputData;\n\n    return {\n      result: `Processed: ${previousValue}`\n    };\n  },\n});\n\n// Create the workflow\nconst workflow = new Workflow({\n  name: \"step-mapping\",\n});\n\n// Map data from step1 to step2\nworkflow\n  .step(generateData)\n  .then(processData, {\n    variables: {\n      // Map the nested.value property from generateData's output\n      previousValue: { step: generateData, path: 'nested.value' },\n    }\n  })\n  .commit();\n\n  // Register the workflow with Mastra\n  export const mastra = new Mastra({\n    workflows: { workflow },\n  });\n```\n\n----------------------------------------\n\nTITLE: Defining Events in a Mastra Workflow (TypeScript)\nDESCRIPTION: This snippet demonstrates how to define events with their validation schemas using Zod within a Mastra workflow. Each event specifies the expected data structure when the event occurs. It utilizes the `Workflow` class from `@mastra/core/workflows` and the `z` object from `zod` for schema definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\nconst workflow = new Workflow({\n  name: 'approval-workflow',\n  triggerSchema: z.object({ requestId: z.string() }),\n  events: {\n    // Define events with their validation schemas\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n        comment: z.string().optional(),\n      }),\n    },\n    documentUploaded: {\n      schema: z.object({\n        documentId: z.string(),\n        documentType: z.enum(['invoice', 'receipt', 'contract']),\n        metadata: z.record(z.string()).optional(),\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Listing Indexes in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the listIndexes() method which retrieves an array of index names as strings from the Turbopuffer vector store, allowing users to see existing indexes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nReturns an array of index names as strings.\n```\n\n----------------------------------------\n\nTITLE: Define Recommendation Sending Step in Mastra\nDESCRIPTION: This code defines a Mastra step, `sendRecommendations`, responsible for generating and logging the email content containing the final product recommendations. It retrieves customer information and approved product recommendations from the previous steps, formats the content, includes any customer notes and discount offers, and outputs the email content to the console.  This simulates sending an email in a real-world application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Send the recommendations to the customer\nconst sendRecommendations = new Step({\n  id: 'sendRecommendations',\n  outputSchema: z.object({\n    emailSent: z.boolean(),\n    emailContent: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const { customerName } = context.getStepResult(generateRecommendations) || { customerName: '' };\n    const { finalRecommendations, customerNote, offerDiscount } = context.getStepResult(reviewRecommendations) || {\n      finalRecommendations: [],\n      customerNote: '',\n      offerDiscount: false,\n    };\n\n    // Generate email content based on the recommendations\n    let emailContent = `Dear ${customerName},\\n\\nBased on your preferences, we recommend:\\n\\n`;\n\n    finalRecommendations.forEach(product => {\n      emailContent += `- ${product.productName}: $${product.price.toFixed(2)}\\n`;\n    });\n\n    if (offerDiscount) {\n      emailContent += '\\nAs a valued customer, use code SAVE10 for 10% off your next purchase!\\n';\n    }\n\n    if (customerNote) {\n      emailContent += `\\nPersonal note: ${customerNote}\\n`;\n    }\n\n    emailContent += '\\nThank you for your business,\\nThe Sales Team';\n\n    // In a real application, you would send this email\n    console.log('Email content generated:', emailContent);\n\n    return {\n      emailSent: true,\n      emailContent,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: useObject Hook Implementation - TypeScript (Component)\nDESCRIPTION: This snippet shows how to use the `experimental_useObject` hook from `@ai-sdk/react` to consume a text stream representing a JSON object and parse it into a complete object based on a schema.  It defines a schema using Zod and submits an example input to the API endpoint.  The component then displays the content of the parsed object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\n\nexport default function Page() {\n  const { object, submit } = useObject({\n    api: '/api/use-object',\n    schema: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return (\n    <div>\n      <button onClick={() => submit('example input')}>Generate</button>\n      {object?.content && <p>{object.content}</p>}\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: MastraMCPClient Constructor\nDESCRIPTION: Creates a new instance of MastraMCPClient. It takes configuration options like server connection details, client name, capabilities, and timeout.  The server can be configured as either stdio-based or SSE-based, with specific parameters for each.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor({\n    name,\n    version = '1.0.0',\n    server,\n    capabilities = {},\n    timeout = 60000,\n}: {\n    name: string;\n    server: MastraMCPServerDefinition;\n    capabilities?: ClientCapabilities;\n    version?: string;\n    timeout?: number;\n})\n```\n\n----------------------------------------\n\nTITLE: Running Mastra Agent Server\nDESCRIPTION: This command starts the Mastra development server, exposing endpoints to interact with registered agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example TypeScript\nDESCRIPTION: This try-catch example demonstrates how to handle errors when querying the Cloudflare Vector Store using the CloudflareVector class. The snippet checks for typed errors defined by 'VectorStoreError'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/vectorize.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Example\nDESCRIPTION: Command to start and run the example for retrieving results using Mastra and OpenAI.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Branching Workflow with .after() in Typescript\nDESCRIPTION: This snippet demonstrates basic branching in a Mastra workflow using the `.after()` method. Step C is executed after Step A completes, creating a new branch.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/after.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n    .then(stepB)\n  .after(stepA)  // Create new branch after stepA completes\n    .step(stepC);\n```\n\n----------------------------------------\n\nTITLE: Configuring NextJS for Mastra Integration\nDESCRIPTION: NextJS configuration to properly handle Mastra packages in the server environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  serverExternalPackages: [\"@mastra/*\"],\n  // ... your other Next.js config\n}\n\nmodule.exports = nextConfig\n```\n\n----------------------------------------\n\nTITLE: Using voice.answer() with OpenAIRealtimeVoice in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the `answer()` method of the `OpenAIRealtimeVoice` class to trigger an AI response. It initializes a real-time voice provider, connects to the service, registers an event listener for speaker output, sends user audio input from the microphone, and finally calls `voice.answer()` to initiate the AI's response. It requires the `@mastra/voice-openai-realtime`, `@mastra/node-audio`, and `@mastra/node-speaker` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.answer.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  speaker: \"alloy\", // Default voice\n});\n// Connect to the real-time service\nawait voice.connect();\n// Register event listener for responses\nvoice.on(\"speaker\", (stream) => {\n  // Handle audio response\n  stream.pipe(speaker);\n});\n// Send user audio input\nconst microphoneStream = getMicrophoneStream();\nawait voice.send(microphoneStream);\n// Trigger the AI to respond\nawait voice.answer();\n```\n\n----------------------------------------\n\nTITLE: Importing Completeness Metric in TypeScript\nDESCRIPTION: This snippet shows how to import the CompletenessMetric from the Mastra evals library for NLP tasks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/completeness.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Installing Zod for Schema Validation using npm\nDESCRIPTION: This command shows how to install the Zod library for schema validation using npm. Zod is used for defining and validating the structure of data. Make sure npm is installed and configured correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm install zod\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for OTLP\nDESCRIPTION: Sets up environment variables for Mastra to export telemetry data to New Relic using OpenTelemetry (OTLP). Requires defining the OTLP endpoint and headers, specifically the API key. This configuration is essential for enabling data export to New Relic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/new-relic.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://otlp.nr-data.net:4317\\nOTEL_EXPORTER_OTLP_HEADERS=\\\"api-key=your_license_key\\\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Braintrust Telemetry (TypeScript)\nDESCRIPTION: This TypeScript code snippet demonstrates how to initialize Mastra with telemetry enabled, configuring it to export data to Braintrust via OTLP.  The serviceName parameter identifies the application in Braintrust.  Ensure the `@mastra/core` package is installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/braintrust.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluate Highly Relevant Response\nDESCRIPTION: This TypeScript snippet shows how to evaluate a highly relevant response using the AnswerRelevancyMetric. It defines a query and a corresponding response, then uses the `metric.measure` method to evaluate their relevance. The result includes a score and a reason explaining the evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What are the health benefits of regular exercise?';\nconst response1 =\n  'Regular exercise improves cardiovascular health, strengthens muscles, boosts metabolism, and enhances mental well-being through the release of endorphins.';\n\nconsole.log('Example 1 - High Relevancy:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response is highly relevant to the query. It provides a comprehensive overview of the health benefits of regular exercise.' }\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of AnswerRelevancyMetric in TypeScript\nDESCRIPTION: This code snippet demonstrates the basic usage of the AnswerRelevancyMetric class. It initializes the metric with an OpenAI model, and evaluates the relevance of an answer to a given query. The result includes a score and an explanation of the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/answer-relevancy.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { AnswerRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new AnswerRelevancyMetric(model, {\n  uncertaintyWeight: 0.3,\n  scale: 1,\n});\n\nconst result = await metric.measure(\n  \"What is the capital of France?\",\n  \"Paris is the capital of France.\",\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Suspending with Metadata in Mastra (TypeScript)\nDESCRIPTION: This snippet shows how to use `suspend()` with metadata. The metadata provides additional information about the reason for suspension, which can be useful for resuming the workflow later.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/suspend.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst reviewStep = new Step({\n  id: \"review\",\n  execute: async ({ context, suspend }) => {\n    await suspend({\n      reason: \"Needs manager approval\",\n      requestedBy: context.user\n    });\n    return { reviewed: true };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing MurfVoice with default settings\nDESCRIPTION: This snippet demonstrates how to initialize the MurfVoice class with default settings, which relies on the `MURF_API_KEY` environment variable for authentication. It imports the MurfVoice class from the `@mastra/voice-murf` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/murf.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MurfVoice } from \"@mastra/voice-murf\";\n\n// デフォルトの設定で初期化（MURF_API_KEY環境変数を使用）\nconst voice = new MurfVoice();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for OpenAI API\nDESCRIPTION: This snippet shows how to set up the OpenAI API key as an environment variable in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing Workflow Steps in TypeScript with Mastra\nDESCRIPTION: Creates multiple workflow steps using Mastra's Step class. Each step defines an execute function that processes input data and returns a specific output. The steps include operations for doubling values, incrementing values, tripling values, and checking for even numbers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 }\n  },\n});\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) => ({\n    tripledValue: context.triggerData.inputValue * 3,\n  }),\n});\n\nconst stepFour = new Step({\n  id: \"stepFour\",\n  execute: async ({ context }) => {\n    if (context.steps.stepThree.status !== \"success\") {\n      return { isEven: false }\n    }\n\n    return { isEven: context.steps.stepThree.output.tripledValue % 2 === 0 }\n  },\n});\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Get Available Speakers (TypeScript)\nDESCRIPTION: Demonstrates how to retrieve a list of available speakers using the `getSpeakers()` method of the `SpeechifyVoice` class. The API key must be configured correctly for the method to function correctly. The returned list contains information about the supported speakers and can be used to customize the voice output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Checking Mastra-Specific Headers Middleware - TypeScript\nDESCRIPTION: This middleware function shows how to check for Mastra-specific headers in incoming requests to customize behavior based on the client. It checks for headers such as `x-mastra-cloud`, `x-mastra-client-type`, and `x-mastra-dev-playground` to identify the client type and origin, allowing for tailored logic within the middleware.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    // 受信リクエストでMastra固有のヘッダーをチェック\n    const isFromMastraCloud = c.req.header(\"x-mastra-cloud\") === \"true\";\n    const clientType = c.req.header(\"x-mastra-client-type\"); // 例: 'js', 'python'\n    const isDevPlayground = c.req.header(\"x-mastra-dev-playground\") === \"true\";\n\n    // クライアント情報に基づいて動作をカスタマイズ\n    if (isFromMastraCloud) {\n      // Mastra Cloudリクエストの特別な処理\n    }\n\n    await next();\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Document Chunker Tool\nDESCRIPTION: This code snippet creates a document chunker tool using `createDocumentChunkerTool` from `@mastra/rag`. The tool is configured with the input document (`MDocument.fromText(yourText)`) and parameters for the chunking strategy, size, overlap, and separator. This tool allows splitting the document into smaller segments for processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(yourText);\n\nconst documentChunkerTool = createDocumentChunkerTool({\n  doc,\n  params: {\n    strategy: \"recursive\",\n    size: 512,\n    overlap: 25,\n    separator: \"\\n\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Get Environment Files in TypeScript\nDESCRIPTION: This code snippet shows the implementation of the `getEnvFiles` method within the Deployer class. It searches for environment files in a predefined order ('.env.production', '.env.local', '.env') and returns an array containing the path to the first existing file, or an empty array if no environment files are found.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/deployer.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ngetEnvFiles(): Promise<string[]> {\n  const possibleFiles = ['.env.production', '.env.local', '.env'];\n\n  try {\n    const fileService = new FileService();\n    const envFile = fileService.getFirstExistingFile(possibleFiles);\n\n    return Promise.resolve([envFile]);\n  } catch {}\n\n  return Promise.resolve([]);\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra RAG Implementation\nDESCRIPTION: Imports necessary packages from Mastra, OpenAI, and related utilities for RAG system implementation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createVectorQueryTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Starting Mastra Development Server using CLI\nDESCRIPTION: This command demonstrates how to start the Mastra development server using the `mastra dev` CLI command. By default, it looks for exported agents in files within the `src/mastra/agents` directory. Ensure Mastra CLI is installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: PostgresStore Constructor Examples\nDESCRIPTION: These examples demonstrate different ways to instantiate the PostgresStore class, either using a connection string or individual connection parameters, and with or without a custom schema name. The schemaName parameter is optional; if not provided, the default schema will be used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/postgresql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { PostgresStore } from '@mastra/pg';\\n\\n// 接続文字列のみを使用\\nconst store1 = new PostgresStore({\\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\\n});\\n\\n// カスタムスキーマ名を持つ接続文字列を使用\\nconst store2 = new PostgresStore({\\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\\n  schemaName: 'custom_schema', // オプション\\n});\\n\\n// 個別の接続パラメータを使用\\nconst store4 = new PostgresStore({\\n  host: 'localhost',\\n  port: 5432,\\n  database: 'mydb',\\n  user: 'user',\\n  password: 'password',\\n});\\n\\n// スキーマ名を含む個別のパラメータ\\nconst store5 = new PostgresStore({\\n  host: 'localhost',\\n  port: 5432,\\n  database: 'mydb',\\n  user: 'user',\\n  password: 'password',\\n  schemaName: 'custom_schema', // オプション\\n});\"\n```\n\n----------------------------------------\n\nTITLE: Moderating Content with Human Input in Mastra (TypeScript)\nDESCRIPTION: This step defines content moderation logic within a Mastra workflow, including human review when necessary. It uses Zod to define the schema for human input. If the AI analysis score is high, the content is auto-approved. Otherwise, it suspends the workflow for human review, collecting moderator decisions, notes, and potentially modified content upon resumption.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 2: Moderate content that needs review\nconst moderateContent = new Step({\n  id: 'moderateContent',\n  // Define the schema for human input that will be provided when resuming\n  inputSchema: z.object({\n    moderatorDecision: z.enum(['approve', 'reject', 'modify']).optional(),\n    moderatorNotes: z.string().optional(),\n    modifiedContent: z.string().optional(),\n  }),\n  outputSchema: z.object({\n    moderationResult: z.enum(['approved', 'rejected', 'modified']),\n    moderatedContent: z.string(),\n    notes: z.string().optional(),\n  }),\n  // @ts-ignore\n  execute: async ({ context, suspend }) => {\n    const analysisResult = context.getStepResult(analyzeContent);\n    // Access the input provided when resuming the workflow\n    const moderatorInput = {\n      decision: context.inputData?.moderatorDecision,\n      notes: context.inputData?.moderatorNotes,\n      modifiedContent: context.inputData?.modifiedContent,\n    };\n\n    // If the AI analysis score is high enough, auto-approve\n    if (analysisResult?.aiAnalysisScore > 0.9 && !analysisResult?.flaggedCategories?.length) {\n      return {\n        moderationResult: 'approved',\n        moderatedContent: analysisResult.content,\n        notes: 'Auto-approved by system',\n      };\n    }\n\n    // If we don't have moderator input yet, suspend for human review\n    if (!moderatorInput.decision) {\n      await suspend({\n        content: analysisResult?.content,\n        aiScore: analysisResult?.aiAnalysisScore,\n        flaggedCategories: analysisResult?.flaggedCategories,\n        message: 'Please review this content and make a moderation decision',\n      });\n\n      // Placeholder return\n      return {\n        moderationResult: 'approved',\n        moderatedContent: '',\n      };\n    }\n\n    // Process the moderator's decision\n    switch (moderatorInput.decision) {\n      case 'approve':\n        return {\n          moderationResult: 'approved',\n          moderatedContent: analysisResult?.content || '',\n          notes: moderatorInput.notes || 'Approved by moderator',\n        };\n\n      case 'reject':\n        return {\n          moderationResult: 'rejected',\n          moderatedContent: '',\n          notes: moderatorInput.notes || 'Rejected by moderator',\n        };\n\n      case 'modify':\n        return {\n          moderationResult: 'modified',\n          moderatedContent: moderatorInput.modifiedContent || analysisResult?.content || '',\n          notes: moderatorInput.notes || 'Modified by moderator',\n        };\n\n      default:\n        return {\n          moderationResult: 'rejected',\n          moderatedContent: '',\n          notes: 'Invalid moderator decision',\n        };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring SigNoz Environment Variables\nDESCRIPTION: These environment variables are required to configure the OpenTelemetry (OTLP) exporter to send data to SigNoz. The `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the SigNoz ingestion endpoint, while `OTEL_EXPORTER_OTLP_HEADERS` includes the authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/signoz.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\n\"OTEL_EXPORTER_OTLP_ENDPOINT=https://ingest.{region}.signoz.cloud:443\nOTEL_EXPORTER_OTLP_HEADERS=signoz-ingestion-key=your_signoz_token\"\n```\n\n----------------------------------------\n\nTITLE: Example: Document Creation and Processing - TypeScript\nDESCRIPTION: An example showcasing document creation and processing using the MDocument class. It demonstrates creating a document from text, chunking it with metadata extraction, and displaying processed results using TypeScript. Requires importing MDocument from Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\n// Create document from text\nconst doc = MDocument.fromText('Your content here');\n\n// Split into chunks with metadata extraction\nconst chunks = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']],\n  extract: {\n    summary: true, // Extract summaries with default settings\n    keywords: true  // Extract keywords with default settings\n  }\n});\n\n// Get processed chunks\nconst docs = doc.getDocs();\nconst texts = doc.getText();\nconst metadata = doc.getMetadata();\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio from Microphone Stream\nDESCRIPTION: This code snippet demonstrates how to transcribe audio from a microphone stream using the `voice.listen()` method.  It assumes the existence of a `getMicrophoneStream()` function to obtain the audio input. The transcribed text will be returned by the `voice.listen()` method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.listen.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Using a microphone stream\nconst microphoneStream = getMicrophoneStream(); // Assume this function gets audio input\nconst transcription = await voice.listen(microphoneStream);\n```\n\n----------------------------------------\n\nTITLE: Checking Previous Step Results in Typescript\nDESCRIPTION: This code snippet shows how to check the results of previous steps within a Mastra workflow to make decisions in a subsequent step. It uses the `context.steps` object to access the status of previous steps.  It requires the `Step` class from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst finalStep = new Step({\n  id: 'finalStep',\n  execute: async ({ context }) => {\n    // Check results of previous steps\n    const step1Success = context.steps.step1?.status === 'success';\n    const step2Success = context.steps.step2?.status === 'success';\n\n    if (step1Success && step2Success) {\n      // All steps succeeded\n      return { status: 'complete', result: 'All operations succeeded' };\n    } else if (step1Success) {\n      // Only step1 succeeded\n      return { status: 'partial', result: 'Partial completion' };\n    } else {\n      // Critical failure\n      return { status: 'failed', result: 'Critical steps failed' };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Import CompletenessMetric from Mastra Evals\nDESCRIPTION: Imports the CompletenessMetric class from the @mastra/evals/nlp module. This metric is used to evaluate the completeness of a text compared to a reference text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/completeness.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Faithfulness Evaluation\nDESCRIPTION: This TypeScript snippet imports the necessary dependencies for using the FaithfulnessMetric. It imports the openai function from '@ai-sdk/openai' and the FaithfulnessMetric class from '@mastra/evals/llm'. These are essential for initializing and using the metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/faithfulness.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { FaithfulnessMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Voice TTS Package\nDESCRIPTION: This command demonstrates how to install the OpenAI voice provider package using pnpm.  This allows the application to utilize OpenAI's TTS services.  The package must be installed before the `OpenAIVoice` class can be used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/text-to-speech.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/voice-openai  # OpenAIの例\n```\n\n----------------------------------------\n\nTITLE: Configuring Vercel Deployer with team slug, project name and token\nDESCRIPTION: This code configures the VercelDeployer with team slug, project name, and token, enabling deployment to Vercel. Substitute 'your-vercel-team-slug', 'your-project-name', and 'your-vercel-token' with your actual Vercel credentials. Full configuration details can be found in the Vercel deployer reference.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n\"new VercelDeployer({\n  teamSlug: 'your-vercel-team-slug',\n  projectName: 'your-project-name',\n  token: 'your-vercel-token'\n  // For complete configuration options, see the reference documentation\n})\"\n```\n\n----------------------------------------\n\nTITLE: Handling Query Errors in Upstash Vector Store in TypeScript\nDESCRIPTION: This code snippet demonstrates error handling when performing a query using the store. It captures specific types of errors thrown by the Upstash Vector store and logs relevant details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a Step to a Workflow with Workflow.step() in Typescript\nDESCRIPTION: This code snippet demonstrates how to add a new step to a workflow using the `.step()` method. It defines the step's ID, output schema using Zod, and the execution logic as an asynchronous function that returns a result. The step returns the number 42.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-function.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    result: z.number()\n  }),\n  execute: async ({ context }) => {\n    return { result: 42 };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Adding Tools to OpenAIRealtimeVoice in TypeScript\nDESCRIPTION: This code snippet demonstrates how to add a tool to an OpenAIRealtimeVoice provider using the `addTools()` method. It defines a weather tool using `createTool` from `@mastra/core/tools`, initializes an `OpenAIRealtimeVoice` instance, and then adds the tool to the voice provider before connecting to the real-time service.  The tool is defined using Zod for schema validation. It fetches weather data from an external API based on user-provided location and returns a message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.addTools.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\n// Define tools\nconst weatherTool = createTool({\n  id: \"getWeather\",\n  description: \"Get the current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"The city and state, e.g. San Francisco, CA\"),\n  }),\n  outputSchema: z.object({\n    message: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // Fetch weather data from an API\n    const response = await fetch(`https://api.weather.com?location=${encodeURIComponent(context.location)}`);\n    const data = await response.json();\n    return { message: `The current temperature in ${context.location} is ${data.temperature}°F with ${data.conditions}.` };\n  },\n});\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Add tools to the voice provider\nvoice.addTools({\n  getWeather: weatherTool,\n});\n\n// Connect to the real-time service\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: Initializing Workflow Steps in TypeScript with Mastra\nDESCRIPTION: This snippet demonstrates how to create individual steps for a workflow using Mastra. It includes steps for doubling a value, checking divisibility, and incrementing values. Each step is defined as a separate function with its own logic and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/branching-paths.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\"\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2\n  })\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n    if (!stepOneResult) {\n      return { isDivisibleByFive: false }\n    }\n\n    return { isDivisibleByFive: stepOneResult.doubledValue % 5 === 0 }\n  }\n});\n\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) =>{\n    const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n    if (!stepOneResult) {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: stepOneResult.doubledValue + 1 }\n  }\n});\n\nconst stepFour = new Step({\n  id: \"stepFour\",\n  execute: async ({ context }) => {\n    const stepThreeResult = context.getStepResult<{ incrementedValue: number }>(\"stepThree\");\n    if (!stepThreeResult) {\n      return { isDivisibleByThree: false }\n    }\n\n    return { isDivisibleByThree: stepThreeResult.incrementedValue % 3 === 0 }\n  }\n});\n\n// New step that depends on both branches\nconst finalStep = new Step({\n  id: \"finalStep\",\n  execute: async ({ context }) => {\n    // Get results from both branches using getStepResult\n    const stepTwoResult = context.getStepResult<{ isDivisibleByFive: boolean }>(\"stepTwo\");\n    const stepFourResult = context.getStepResult<{ isDivisibleByThree: boolean }>(\"stepFour\");\n\n    const isDivisibleByFive = stepTwoResult?.isDivisibleByFive || false;\n    const isDivisibleByThree = stepFourResult?.isDivisibleByThree || false;\n\n    return {\n      summary: `The number ${context.triggerData.inputValue} when doubled ${isDivisibleByFive ? 'is' : 'is not'} divisible by 5, and when doubled and incremented ${isDivisibleByThree ? 'is' : 'is not'} divisible by 3.`,\n      isDivisibleByFive,\n      isDivisibleByThree\n    }\n  }\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Running TypeScript Script with Bun\nDESCRIPTION: This command shows how to run the TypeScript script using Bun.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpx bun src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Langfuse Integration\nDESCRIPTION: This snippet details the required environment variables for the Langfuse integration with Mastra. It outlines the necessary keys and optional parameters that influence the telemetry data provided by Langfuse.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langfuse.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nLANGFUSE_PUBLIC_KEY=your_public_key\nLANGFUSE_SECRET_KEY=your_secret_key\nLANGFUSE_BASEURL=https://cloud.langfuse.com  # Optional - defaults to cloud.langfuse.com\n```\n\n----------------------------------------\n\nTITLE: Interacting with Agent using curl command\nDESCRIPTION: This command shows how to interact with the agent using a `curl` command. It sends a POST request to the agent's API endpoint with a JSON payload containing the user's message. Replace `http://localhost:4111/api/agents/myAgent/generate` with the actual endpoint of your agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/myAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"Hello, how can you assist me today?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Import Dependencies for Multi-Agent Workflow - TypeScript\nDESCRIPTION: This code snippet imports the necessary dependencies for creating a multi-agent workflow. It includes modules from `@ai-sdk/openai`, `@ai-sdk/anthropic`, `@mastra/core/agent`, `@mastra/core/workflows`, and `zod` for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Watch Workflow Transitions using TypeScript\nDESCRIPTION: This snippet shows how to watch workflow transitions using the `watch` method.  It retrieves a workflow instance, creates a run, and then calls `workflow.watch` with the `runId` and a callback function. The callback function is executed for every new transition state of the workflow run, logging the `activePaths`, `results`, `timestamp`, and `runId`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ntry{\n  // Get workflow instance\n  const workflow = client.getWorkflow(\"workflow-id\");\n\n  // Create a workflow run\n  const {runId} = workflow.createRun()\n\n  // Watch workflow run \n     workflow.watch({runId},(record)=>{\n       // Every new record is the latest transition state of the workflow run\n\n        console.log({\n          activePaths: record.activePaths,\n          results: record.results,\n          timestamp: record.timestamp,\n          runId: record.runId\n        });\n     });\n\n  // Start workflow run\n     workflow.start({\n      runId,\n      triggerData: {\n        city: 'New York',\n      },\n    });\n}catch(e){\n  console.error(e);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced Mastra Client Options\nDESCRIPTION: Extended configuration of MastraClient with optional parameters including retries, backoff timing, and custom headers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new MastraClient({\n  // Required\n  baseUrl: \"http://localhost:4111\",\n\n  // Optional configurations for development\n  retries: 3,           // Number of retry attempts\n  backoffMs: 300,       // Initial retry backoff time\n  maxBackoffMs: 5000,   // Maximum retry backoff time\n  headers: {            // Custom headers for development\n    \"X-Development\": \"true\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow Validation on Commit in Typescript\nDESCRIPTION: This code snippet illustrates how workflow configuration is validated when `.commit()` is called in Typescript. The validation checks for circular dependencies, terminal paths, unreachable steps, invalid variable references, and duplicate step IDs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step('step1', {...})\n  .step('step2', {...})\n  .commit(); // ワークフロー構造を検証\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retry Configuration in Mastra\nDESCRIPTION: This code snippet demonstrates how to configure a default retry policy at the workflow level in Mastra. The `retryConfig` object specifies the number of retry attempts and the delay between attempts for all steps within the workflow. This configuration applies to all steps unless overridden at the step level.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-retries.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = new Workflow({\n  name: 'my-workflow',\n  retryConfig: {\n    attempts: 3,    // 初回試行に加えてのリトライ回数\n    delay: 1000,    // リトライ間の遅延時間（ミリ秒）\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Markdown Chunking Example\nDESCRIPTION: Command to start the markdown chunking example after installation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-markdown/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with LibSQL in TypeScript\nDESCRIPTION: This code initializes LibSQLVector with a connection URL and optional auth token, creates an index, and upserts embeddings. It requires @mastra/core/vector/libsql and environment variables DATABASE_URL and DATABASE_AUTH_TOKEN (for Turso).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst store = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  authToken: process.env.DATABASE_AUTH_TOKEN // Optional: for Turso cloud databases\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Authentication Middleware Example\nDESCRIPTION: Example of authentication middleware implementation checking for Bearer tokens.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    const authHeader = c.req.header('Authorization');\n    if (!authHeader || !authHeader.startsWith('Bearer ')) {\n      return new Response('Unauthorized', { status: 401 });\n    }\n\n    const token = authHeader.split(' ')[1];\n    // Validate token here\n\n    await next();\n  },\n  path: '/api/*',\n}\n```\n\n----------------------------------------\n\nTITLE: Create Dynamic Workflow Step TypeScript\nDESCRIPTION: This code defines a step that creates and executes a dynamic workflow. It retrieves input data from the context, defines a new workflow and step, and then executes the dynamic workflow, returning the result. It requires the @mastra/core and zod libraries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/dynamic-workflows.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra, Step, Workflow } from '@mastra/core';\nimport { z } from 'zod';\n\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === 'object' && mastra instanceof Mastra;\n};\n\n// 動的ワークフローを作成して実行するステップ\nconst createDynamicWorkflow = new Step({\n  id: 'createDynamicWorkflow',\n  outputSchema: z.object({\n    dynamicWorkflowResult: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error('Mastraインスタンスが利用できません');\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error('無効なMastraインスタンス');\n    }\n\n    const inputData = context.triggerData.inputData;\n\n    // 新しい動的ワークフローを作成\n    const dynamicWorkflow = new Workflow({\n      name: 'dynamic-workflow',\n      mastra, // 新しいワークフローにmastraインスタンスを渡す\n      triggerSchema: z.object({\n        dynamicInput: z.string(),\n      }),\n    });\n\n    // 動的ワークフローのステップを定義\n    const dynamicStep = new Step({\n      id: 'dynamicStep',\n      execute: async ({ context }) => {\n        const dynamicInput = context.triggerData.dynamicInput;\n        return {\n          processedValue: `Processed: ${dynamicInput}`,\n        };\n      },\n    });\n\n    // 動的ワークフローを構築してコミット\n    dynamicWorkflow.step(dynamicStep).commit();\n\n    // 実行を作成し、動的ワークフローを実行\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        dynamicInput: inputData,\n      },\n    });\n\n    let dynamicWorkflowResult;\n\n    if (result.results['dynamicStep']?.status === 'success') {\n      dynamicWorkflowResult = result.results['dynamicStep']?.output.processedValue;\n    } else {\n      throw new Error('動的ワークフローが失敗しました');\n    }\n\n    // 動的ワークフローからの結果を返す\n    return {\n      dynamicWorkflowResult,\n    };\n  },\n});\n\n// 動的ワークフロークリエーターを使用するメインワークフロー\nconst mainWorkflow = new Workflow({\n  name: 'main-workflow',\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n  mastra: new Mastra(),\n});\n\nmainWorkflow.step(createDynamicWorkflow).commit();\n\n// Mastraにワークフローを登録\nexport const mastra = new Mastra({\n  workflows: { mainWorkflow },\n});\n\nconst run = mainWorkflow.createRun();\nconst result = await run.start({\n  triggerData: {\n    inputData: 'test',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Weather Agent (TypeScript)\nDESCRIPTION: This TypeScript code defines a weather agent using the Mastra framework. It imports necessary modules from `@ai-sdk/openai` and `@mastra/core`, including the `Agent` class and a custom `weatherTool`. The agent is configured with a name, instructions, an OpenAI model (`gpt-4o-mini`), and the `weatherTool` for fetching weather data. The agent's instructions guide its behavior in providing weather information, including requesting location details and providing relevant details like humidity and wind conditions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { weatherTool } from \"../tools/weather-tool\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `You are a helpful weather assistant that provides accurate weather information.\n\nYour primary function is to help users get weather details for specific locations. When responding:\n- Always ask for a location if none is provided\n- If the location name isn’t in English, please translate it\n- Include relevant details like humidity, wind conditions, and precipitation\n- Keep responses concise but informative\n\nUse the weatherTool to fetch current weather data.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { weatherTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring CORS in Mastra\nDESCRIPTION: Shows how to configure Cross-Origin Resource Sharing (CORS) settings for the Mastra server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\n\nexport const mastra = new Mastra({\n  server: {\n    cors: {\n      origin: ['https://example.com'], // Allow specific origins or '*' for all\n      allowMethods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],\n      allowHeaders: ['Content-Type', 'Authorization'],\n      credentials: false,\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Test the Research Assistant (TypeScript)\nDESCRIPTION: Tests the research assistant with different types of queries, including basic concept queries and queries about specific findings. The code retrieves the agent, generates a response for each query, and logs the query and response. Dependencies include a configured `mastra` instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./mastra\";\nconst agent = mastra.getAgent('researchAgent');\n\n// Basic query about concepts\nconst query1 = \"What problems does sequence modeling face with neural networks?\";\nconst response1 = await agent.generate(query1);\nconsole.log(\"\\nQuery:\", query1);\nconsole.log(\"Response:\", response1.text);\n```\n\nLANGUAGE: typescript\nCODE:\n```\n// Query about specific findings\nconst query2 = \"What improvements were achieved in translation quality?\";\nconst response2 = await agent.generate(query2);\nconsole.log(\"\\nQuery:\", query2);\nconsole.log(\"Response:\", response2.text);\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration File\nDESCRIPTION: Command to copy the example environment file to create a local configuration file. This will be used to store API keys and other configuration variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env.local\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Chroma in TypeScript\nDESCRIPTION: This code snippet initializes ChromaVector, creates an index, and upserts embeddings with metadata. It requires the @mastra/chroma package.  No API keys or URLs are explicitly passed, so it relies on default configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChromaVector } from '@mastra/chroma'\n\nconst store = new ChromaVector()\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Relevancy Context in Mastra\nDESCRIPTION: Demonstrates evaluating a response where most context items about coral reefs are irrelevant to the query about Australia's capital, resulting in a low relevancy score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'The Great Barrier Reef is in Australia.',\n  'Coral reefs need warm water to survive.',\n  'Marine life depends on coral reefs.',\n  'The capital of Australia is Canberra.',\n];\n\nconst metric3 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'What is the capital of Australia?';\nconst response3 = 'The capital of Australia is Canberra.';\n\nconsole.log('Example 3 - Low Relevancy:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.12, reason: 'The context only has one relevant piece, while most of the context is irrelevant.' }\n```\n\n----------------------------------------\n\nTITLE: Streaming Agent Responses (TypeScript)\nDESCRIPTION: This code illustrates how to stream responses from a Mastra agent for real-time updates.  The `stream` method is used to receive a stream of text chunks, which are then written to the console using `process.stdout.write`. This approach allows for more immediate feedback as the agent generates its response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream([\n  { role: \"user\", content: \"Tell me a story.\" },\n]);\n\nconsole.log(\"Agent:\");\n\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for Contextual Recall evaluation in TypeScript\nDESCRIPTION: This code imports the necessary dependencies from the OpenAI SDK and Mastra evals package for using the Contextual Recall metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextualRecallMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Enabling Swagger UI in Mastra (TypeScript)\nDESCRIPTION: This TypeScript code snippet shows how to enable Swagger UI for your Mastra instance to test API endpoints interactively. It involves setting both `openAPIDocs` and `swaggerUI` to `true` within the `build` configuration of the `server` option.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/mastra-dev.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  server: {\n    build: {\n      openAPIDocs: true,  // Enable OpenAPI documentation\n      swaggerUI: true,  // Enable Swagger UI\n      // ... other build config options\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Voice Provider Configuration using voice.updateConfig() in TypeScript\nDESCRIPTION: This code snippet demonstrates how to update the configuration of a voice provider (specifically OpenAIRealtimeVoice) at runtime using the `updateConfig()` method. It initializes a voice provider, connects to the service, updates the voice and turn detection settings, and then speaks using the new configuration.\n\nDependencies: @mastra/voice-openai-realtime\nParameters: options (Record<string, unknown>) - Configuration options to update (voice, turn_detection).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.updateConfig.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  speaker: \"alloy\",\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Later, update the configuration\nvoice.updateConfig({\n  voice: \"nova\", // Change the default voice\n  turn_detection: {\n    type: \"server_vad\",\n    threshold: 0.5,\n    silence_duration_ms: 1000\n  }\n});\n\n// The next speak() call will use the new configuration\nawait voice.speak(\"Hello with my new voice!\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Cloudflare Deployer with scope and project name\nDESCRIPTION: This code configures the CloudflareDeployer with the necessary scope and project name for deployment. Replace 'your-cloudflare-account-id' and 'your-project-name' with the appropriate values from your Cloudflare account.  Refer to the Cloudflare deployer reference for complete configuration options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"new CloudflareDeployer({\n  scope: 'your-cloudflare-account-id',\n  projectName: 'your-project-name',\n  // For complete configuration options, see the reference documentation\n})\"\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for Context Position metric\nDESCRIPTION: Imports the necessary modules from OpenAI SDK and Mastra's evaluation library to use the Context Position metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-position.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextPositionMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Get Agent Function\nDESCRIPTION: Defines the `getAgent` function, which takes connectionId, agent configuration, APIs, and a logger as input. It returns an asynchronous function that takes a prompt and returns a simple \"Hello, world!\" message. This function is responsible for retrieving an agent based on the provided configuration and returning a function to execute prompts.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/getAgent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nasync function getAgent({\n  connectionId,\n  agent,\n  apis,\n  logger,\n}: {\n  connectionId: string;\n  agent: Record<string, any>;\n  apis: Record<string, IntegrationApi>;\n  logger: any;\n}): Promise<(props: { prompt: string }) => Promise<any>> {\n  return async (props: { prompt: string }) => {\n    return { message: \"Hello, world!\" };\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Speech to Text with OpenAI\nDESCRIPTION: Demonstrates how to use the `listen` method of the OpenAIVoice class to convert an audio stream into text. It shows how to specify the file type of the audio stream using options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/openai.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// 音声をテキストに変換\nconst text = await voice.listen(audioStream, {\n  filetype: 'mp3'\n});\n```\n\n----------------------------------------\n\nTITLE: Non-interactive Mastra initialization arguments\nDESCRIPTION: This section lists the command-line arguments that can be used to initialize Mastra in non-interactive mode. These arguments allow specifying components, LLM provider, API key, example inclusion, and project name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/creating-a-new-project.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nArguments:\n  --components     Specify components: agents, tools, workflows\n  --llm-provider   LLM provider: openai, anthropic, groq, google, or cerebras\n  --add-example    Include example implementation\n  --llm-api-key    Provider API key\n  --project-name   Project name that will be used in package.json and as the project directory name\n```\n\n----------------------------------------\n\nTITLE: Evaluating Partial Relevancy Response Example in TypeScript\nDESCRIPTION: Demonstrate how to evaluate a response that is partially relevant to its query, including logging the query, response, and metric results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'What should a healthy breakfast include?';\nconst response2 =\n  'A nutritious breakfast should include whole grains and protein. However, the timing of your breakfast is just as important - studies show eating within 2 hours of waking optimizes metabolism and energy levels throughout the day.';\n\nconsole.log('Example 2 - Partial Relevancy:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.7, reason: 'The response is partially relevant to the query. It provides some information about healthy breakfast choices but misses the timing aspect.' }\n```\n\n----------------------------------------\n\nTITLE: Connecting to OpenAIRealtimeVoice\nDESCRIPTION: This code snippet demonstrates how to connect to a real-time voice provider using the `connect()` method. It initializes an `OpenAIRealtimeVoice` instance, configures audio output with `Speaker`, and establishes a connection to the real-time service. The example includes setting up a speaker to handle incoming audio streams and optional connection configurations like timeout and reconnection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.connect.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // MacBook Proでの高品質オーディオの標準であるHz単位のオーディオサンプルレート\n  channels: 1,        // モノラルオーディオ出力（ステレオの場合は2）\n  bitDepth: 16,       // オーディオ品質のビット深度 - CD品質標準（16ビット解像度）\n});\n\n// リアルタイム音声プロバイダーを初期化\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: \"server_vad\",\n          threshold: 0.6,\n          silence_duration_ms: 1200,\n        },\n      },\n    },\n  },\n  speaker: \"alloy\", // デフォルトの音声\n});\n// リアルタイムサービスに接続\nawait voice.connect();\n// これでリアルタイム機能を使用できます\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker);\n});\n// 接続オプション付き\nawait voice.connect({\n  timeout: 10000, // 10秒のタイムアウト\n  reconnect: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Import AnswerRelevancyMetric\nDESCRIPTION: This TypeScript snippet imports the necessary modules for using the AnswerRelevancyMetric. It imports the `openai` function from `@ai-sdk/openai` and the `AnswerRelevancyMetric` class from `@mastra/evals/llm`. These imports are essential for setting up and using the metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { AnswerRelevancyMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Managing Workflow Snapshots with Storage API in TypeScript\nDESCRIPTION: Demonstrates workflow state persistence and retrieval operations. Shows how to save and load workflow snapshots with associated metadata and state information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/storage/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Save workflow state\nawait storage.persistWorkflowSnapshot({\n  workflowName: 'my-workflow',\n  runId: 'run-123',\n  snapshot: {\n    value: { currentState: 'running' },\n    context: {\n      stepResults: {},\n      attempts: {},\n      triggerData: {},\n    },\n    activePaths: [],\n    runId: 'run-123',\n    timestamp: Date.now(),\n  },\n});\n\n// Load workflow state\nconst snapshot = await storage.loadWorkflowSnapshot({\n  workflowName: 'my-workflow',\n  runId: 'run-123',\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra CLI Arguments for Non-Interactive Setup\nDESCRIPTION: This snippet outlines the available command-line arguments for initializing Mastra in a non-interactive mode. These arguments allow users to specify components, LLM providers, API keys, and other configurations directly from the command line, enabling automated setup.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/add-to-existing-project.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nArguments:\n  --components     指定するコンポーネント: agents, tools, workflows\n  --llm-provider   LLMプロバイダー: openai, anthropic, または groq\n  --add-example    例の実装を含める\n  --llm-api-key    プロバイダーのAPIキー\n  --dir            Mastraファイルのディレクトリ (デフォルトはsrc/)\n```\n\n----------------------------------------\n\nTITLE: Generating Text Embeddings with Cohere in TypeScript\nDESCRIPTION: This code demonstrates how to create text embeddings using Cohere's embedding model through Mastra. It processes a text document by first chunking it and then generating embeddings for each chunk using Cohere's 'embed-english-v3.0' model. The code uses the MDocument class for text processing and the embedMany function for batch embedding generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-text-with-cohere.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { cohere } from '@ai-sdk/cohere';\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Checking Workflow Suspension Status in TypeScript\nDESCRIPTION: Shows how to check if a workflow has been suspended after starting it. The code verifies the returned status and accesses the suspended step ID and payload information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await workflow.start({ triggerData });\nif (result.status === 'suspended' && result.suspendedStepId === 'stepId') {\n  // Process suspension\n  console.log('Workflow is waiting for input:', result.suspendPayload);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ElevenLabsVoice with custom settings\nDESCRIPTION: This snippet demonstrates initializing the ElevenLabsVoice class with custom settings, including a specific speech model and API key, as well as a custom speaker ID. It allows for fine-grained control over the text-to-speech process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/elevenlabs.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// カスタム設定で初期化\nconst voice = new ElevenLabsVoice({\n  speechModel: {\n    name: 'eleven_multilingual_v2',\n    apiKey: 'your-api-key',\n  },\n  speaker: 'custom-speaker-id',\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra RAG System\nDESCRIPTION: Imports necessary modules from OpenAI, Mastra, and related packages for implementing the RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from '@mastra/core';\nimport { Agent } from '@mastra/core/agent';\nimport { PgVector } from '@mastra/pg';\nimport { createVectorQueryTool, MDocument, PGVECTOR_PROMPT } from '@mastra/rag';\nimport { embedMany } from 'ai';\n```\n\n----------------------------------------\n\nTITLE: Using VectorizeStore for vector operations\nDESCRIPTION: This code snippet demonstrates the basic usage of the VectorizeStore class. It covers creating an index, adding vectors with associated metadata, and querying for similar vectors using specified filters. The example utilizes environment variables for API key and project ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/vectorize/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { VectorizeStore } from '@mastra/vectorize';\n\nconst vectorStore = new VectorizeStore({\n  apiKey: process.env.VECTORIZE_API_KEY,\n  projectId: process.env.VECTORIZE_PROJECT_ID\n});\n\n// Create a new index\nawait vectorStore.createIndex({\n  indexName: 'my-index',\n  dimension: 1536,\n  metric: 'cosine'\n});\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({\n  indexName: 'my-index',\n  vectors,\n  metadata\n});\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my-index',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10,\n  filter: { text: { $eq: 'doc1' } },\n  includeVector: false\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra Agent with SSE Server Example\nDESCRIPTION: This example demonstrates how to use MastraMCPClient with an SSE server. It initializes the client, specifying the server URL and optional configurations for request and event source, including headers for authentication.  It also shows how to configure a custom logger and disable server logs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Initialize the MCP client using an SSE server\nconst sseClient = new MastraMCPClient({\n  name: \"sse-client\",\n  server: {\n    url: new URL(\"https://your-mcp-server.com/sse\"),\n    // Optional fetch request configuration - Note: requestInit alone isn't enough for SSE\n    requestInit: {\n      headers: {\n        Authorization: \"Bearer your-token\",\n      },\n    },\n    // Required for SSE connections with custom headers\n    eventSourceInit: {\n      fetch(input: Request | URL | string, init?: RequestInit) {\n        const headers = new Headers(init?.headers || {});\n        headers.set('Authorization', 'Bearer your-token');\n        return fetch(input, {\n          ...init,\n          headers,\n        });\n      },\n    },\n    // Optional additional logging configuration\n    logger: (logMessage) => {\n      console.log(`[${logMessage.level}] ${logMessage.serverName}: ${logMessage.message}`);\n    },\n    // Disable server logs\n    enableServerLogs: false\n  },\n});\n\n// The rest of the usage is identical to the stdio example\n```\n\n----------------------------------------\n\nTITLE: Weather Tool Implementation (TypeScript)\nDESCRIPTION: This TypeScript code defines a `weatherTool` for retrieving current weather information using the Open-Meteo API. It uses Zod for schema validation and `@mastra/core` for creating the tool. The tool takes a location as input and returns weather details such as temperature, humidity, and wind conditions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\ninterface WeatherResponse {\n  current: {\n    time: string;\n    temperature_2m: number;\n    apparent_temperature: number;\n    relative_humidity_2m: number;\n    wind_speed_10m: number;\n    wind_gusts_10m: number;\n    weather_code: number;\n  };\n}\n\nexport const weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"Get current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"City name\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    feelsLike: z.number(),\n    humidity: z.number(),\n    windSpeed: z.number(),\n    windGust: z.number(),\n    conditions: z.string(),\n    location: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return await getWeather(context.location);\n  },\n});\n\nconst getWeather = async (location: string) => {\n  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;\n  const geocodingResponse = await fetch(geocodingUrl);\n  const geocodingData = await geocodingResponse.json();\n\n  if (!geocodingData.results?.[0]) {\n    throw new Error(`Location '${location}' not found`);\n  }\n\n  const { latitude, longitude, name } = geocodingData.results[0];\n\n  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;\n\n  const response = await fetch(weatherUrl);\n  const data: WeatherResponse = await response.json();\n\n  return {\n    temperature: data.current.temperature_2m,\n    feelsLike: data.current.apparent_temperature,\n    humidity: data.current.relative_humidity_2m,\n    windSpeed: data.current.wind_speed_10m,\n    windGust: data.current.wind_gusts_10m,\n    conditions: getWeatherCondition(data.current.weather_code),\n    location: name,\n  };\n};\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"Clear sky\",\n    1: \"Mainly clear\",\n    2: \"Partly cloudy\",\n    3: \"Overcast\",\n    45: \"Foggy\",\n    48: \"Depositing rime fog\",\n    51: \"Light drizzle\",\n    53: \"Moderate drizzle\",\n    55: \"Dense drizzle\",\n    56: \"Light freezing drizzle\",\n    57: \"Dense freezing drizzle\",\n    61: \"Slight rain\",\n    63: \"Moderate rain\",\n    65: \"Heavy rain\",\n    66: \"Light freezing rain\",\n    67: \"Heavy freezing rain\",\n    71: \"Slight snow fall\",\n    73: \"Moderate snow fall\",\n    75: \"Heavy snow fall\",\n    77: \"Snow grains\",\n    80: \"Slight rain showers\",\n    81: \"Moderate rain showers\",\n    82: \"Violent rain showers\",\n    85: \"Slight snow showers\",\n    86: \"Heavy snow showers\",\n    95: \"Thunderstorm\",\n    96: \"Thunderstorm with slight hail\",\n    99: \"Thunderstorm with heavy hail\",\n  };\n  return conditions[code] || \"Unknown\";\n}\n```\n\n----------------------------------------\n\nTITLE: Agent with LibSQL Storage Configuration\nDESCRIPTION: This code shows how to configure the Memory instance with a LibSQL storage adapter. The LibSQLStore is used to persist conversation history, allowing the agent to retain information across sessions. The storage configuration specifies the database URL.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    // これは省略した場合のデフォルトストレージDBです\n    storage: new LibSQLStore({\n      config: {\n        url: \"file:local.db\",\n      },\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Save Message to Memory (TypeScript)\nDESCRIPTION: Saves a message to memory, associating it with a specific thread and agent. Requires an array of message objects, each containing role, content, id, threadId, createdAt, and type. It also requires agentId. Returns the saved messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst savedMessages = await client.saveMessageToMemory({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Hello!\",\n      id: \"1\",\n      threadId: \"thread-1\",\n      createdAt: new Date(),\n      type: \"text\",\n    },\n  ],\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating mixed alignment with PromptAlignmentMetric (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to evaluate a response that partially adheres to a set of instructions using the `PromptAlignmentMetric`. It defines an array of instructions, creates a `PromptAlignmentMetric` instance, sets a query, and a response. It then measures the alignment between the query, response, and instructions, and logs the metric results, including the score, reason, and score details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/prompt-alignment.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions2 = [\n  '箇条書きを使用する',\n  '価格をUSDで含める',\n  '在庫状況を表示する',\n  '製品説明を追加する'\n];\n\nconst metric2 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions2,\n});\n\nconst query2 = '利用可能な製品を一覧表示する';\nconst response2 = '• コーヒー - $4.99 (在庫あり)\\n• 紅茶 - $3.99\\n• 水 - $1.99 (在庫切れ)';\n\nconsole.log('例 2 - 混合整合性:');\nconsole.log('指示:', instructions2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n  details: result2.info.scoreDetails,\n});\n// 例の出力:\n// メトリック結果: { score: 0.5, reason: '応答はいくつかの指示を逃しています。' }\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/rag using npm - Bash\nDESCRIPTION: This code snippet illustrates how to install the @mastra/rag library using npm. It is essential for utilizing the functionalities offered by the library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/rag\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Exclude Example Code (shorthand)\nDESCRIPTION: This command demonstrates how to exclude example code when running `create-mastra` non-interactively, using the `-n` shorthand flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest my-app --components agents,tools --llm openai -n\n```\n\n----------------------------------------\n\nTITLE: Getting the Routing Agent from Agent Network - TypeScript\nDESCRIPTION: The getRoutingAgent() method returns the routing agent utilized by the network. This method allows access to the routing agent for further interactions or configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ngetRoutingAgent(): Agent\n```\n\n----------------------------------------\n\nTITLE: TypeScript Configuration - tsconfig.json\nDESCRIPTION: This JSON configuration file (`tsconfig.json`) specifies the TypeScript compiler options optimized for Mastra projects, including target, module, module resolution, and strict type checking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_18\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"outDir\": \"dist\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \".mastra\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Define Thought Breakdown Step Typescript\nDESCRIPTION: Defines a workflow step `breakdownThoughts` using the `Step` class. This step breaks down the thoughts based on the context analysis. It retrieves the initial analysis from the `analyzeContext` step and uses the RAG agent to generate a breakdown of how the retrieved information relates to the query. The breakdown is then returned as the step's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst breakdownThoughts = new Step({\n  id: \"breakdownThoughts\",\n  outputSchema: z.object({\n    breakdown: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const analysis = context?.getStepResult<{\n      initialAnalysis: string;\n    }>(\"analyzeContext\")?.initialAnalysis;\n\n    const connectionPrompt = `\n      初期分析に基づいて: ${analysis}\n\n      2. 取得した情報がクエリにどのように関連しているかについての思考プロセスを分解します。\n    `;\n\n    const connectionAnalysis = await ragAgent?.generate(connectionPrompt);\n    console.log(connectionAnalysis?.text);\n    return {\n      breakdown: connectionAnalysis?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Consistent Positive Tone in TypeScript\nDESCRIPTION: Demonstrates how to evaluate tone consistency between two positive texts, including metric measurement and result logging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/tone-consistency.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'This product is fantastic and amazing!';\nconst output1 = 'The product is excellent and wonderful!';\n\nconsole.log('Example 1 - Consistent Positive Tone:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: result1.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Sarvam Voice in TypeScript\nDESCRIPTION: This TypeScript code snippet shows how to import SarvamVoice, create an instance for TTS and STT operations, set up voice capabilities, and create an agent to handle voice interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SarvamVoice } from '@mastra/voice-sarvam';\n\nconst voice = new SarvamVoice({\n  speechModel: {\n    model: 'bulbul:v1',\n    apiKey: process.env.SARVAM_API_KEY!,\n    language: 'en-IN',\n  },\n  listeningModel: {\n    apiKey: process.env.SARVAM_API_KEY!,\n    model: 'saarika:v2',\n    languageCode: 'unknown', // By default only works with saarika:v2\n  },\n  speaker: 'meera',\n});\n\n// Create an agent with voice capabilities\nexport const agent = new Agent({\n  name: 'Agent',\n  instructions: `You are a helpful assistant with both TTS and STT capabilities.`,\n  model: google('gemini-1.5-pro-latest'),\n  voice: voice,\n});\n```\n\n----------------------------------------\n\nTITLE: Speech-to-Text conversion using GoogleVoice\nDESCRIPTION: This code snippet demonstrates how to use the listen() method of the GoogleVoice class to convert an audio stream into text.  It takes an audio stream, along with configuration options such as encoding and language code, and returns the transcribed text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/google.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Speech-to-Text\nconst transcript = await voice.listen(audioStream, {\n  config: {\n    encoding: 'LINEAR16',\n    languageCode: 'en-US',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies\nDESCRIPTION: Command to install required packages using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/summarization/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Server Settings\nDESCRIPTION: Basic server configuration for port and timeout settings using the Mastra constructor.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  server: {\n    port: 3000, // Defaults to 4111\n    timeout: 10000, // Defaults to 30000 (30s)\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra Workflow with Cyclical Dependencies in TypeScript\nDESCRIPTION: This code defines a Mastra workflow with two steps: `doubleValue`, which doubles an input value, and `incrementByOne`, which increments a value by one. The workflow uses cyclical dependencies, where `doubleValue` is called after `incrementByOne` and vice versa, effectively creating a loop.  It initializes the workflow, defines the steps, and then executes the workflow with a trigger value. It depends on `@mastra/core` and `zod` for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/cyclical-dependencies.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\nasync function main() {\n  const doubleValue = new Step({\n    id: 'doubleValue',\n    description: '入力値を2倍にします',\n    inputSchema: z.object({\n      inputValue: z.number(),\n    }),\n    outputSchema: z.object({\n      doubledValue: z.number(),\n    }),\n    execute: async ({ context }) => {\n      const doubledValue = context.inputValue * 2;\n      return { doubledValue };\n    },\n  });\n\n  const incrementByOne = new Step({\n    id: 'incrementByOne',\n    description: '入力値に1を加えます',\n    outputSchema: z.object({\n      incrementedValue: z.number(),\n    }),\n    execute: async ({ context }) => {\n      const valueToIncrement = context?.getStepResult<{ firstValue: number }>('trigger')?.firstValue;\n      if (!valueToIncrement) throw new Error('インクリメントする値が提供されていません');\n      const incrementedValue = valueToIncrement + 1;\n      return { incrementedValue };\n    },\n  });\n\n  const cyclicalWorkflow = new Workflow({\n    name: 'cyclical-workflow',\n    triggerSchema: z.object({\n      firstValue: z.number(),\n    }),\n  });\n\n  cyclicalWorkflow\n    .step(doubleValue, {\n      variables: {\n        inputValue: {\n          step: 'trigger',\n          path: 'firstValue',\n        },\n      },\n    })\n    .then(incrementByOne)\n    .after(doubleValue)\n    .step(doubleValue, {\n      variables: {\n        inputValue: {\n          step: doubleValue,\n          path: 'doubledValue',\n        },\n      },\n    })\n    .commit();\n\n  const { runId, start } = cyclicalWorkflow.createRun();\n\n  console.log('Run', runId);\n\n  const res = await start({ triggerData: { firstValue: 6 } });\n\n  console.log(res.results);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Voice Provider\nDESCRIPTION: This code snippet demonstrates how to extend the MastraVoice abstract class to create a custom voice provider. It showcases the implementation of required methods like `speak`, `listen`, and `getSpeakers`, as well as optional methods for real-time voice communication. This class acts as a bridge, translating requests into the specific operations required by the desired voice service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraVoice } from \"@mastra/core/voice\";\n\n// 音声プロバイダーの実装を作成\nclass MyVoiceProvider extends MastraVoice {\n  constructor(config: { \n    speechModel?: BuiltInModelConfig; \n    listeningModel?: BuiltInModelConfig; \n    speaker?: string;\n    realtimeConfig?: {\n      model?: string;\n      apiKey?: string;\n      options?: unknown;\n    };\n  }) {\n    super({\n      speechModel: config.speechModel,\n      listeningModel: config.listeningModel,\n      speaker: config.speaker,\n      realtimeConfig: config.realtimeConfig\n    });\n  }\n\n  // 必須の抽象メソッドを実装\n  async speak(input: string | NodeJS.ReadableStream, options?: { speaker?: string }): Promise<NodeJS.ReadableStream | void> {\n    // テキストから音声への変換を実装\n  }\n\n  async listen(audioStream: NodeJS.ReadableStream, options?: unknown): Promise<string | NodeJS.ReadableStream | void> {\n    // 音声からテキストへの変換を実装\n  }\n\n  async getSpeakers(): Promise<Array<{ voiceId: string; [key: string]: unknown }>> {\n    // 利用可能な音声のリストを返す\n  }\n  \n  // オプションの音声から音声へのメソッド\n  async connect(): Promise<void> {\n    // 音声から音声への通信のためのWebSocket接続を確立\n  }\n  \n  async send(audioData: NodeJS.ReadableStream | Int16Array): Promise<void> {\n    // 音声から音声へのオーディオデータをストリーム\n  }\n  \n  async answer(): Promise<void> {\n    // 音声プロバイダーに応答を促す\n  }\n  \n  addTools(tools: Array<unknown>): void {\n    // 音声プロバイダーが使用するツールを追加\n  }\n  \n  close(): void {\n    // WebSocket接続を閉じる\n  }\n  \n  on(event: string, callback: (data: unknown) => void): void {\n    // イベントリスナーを登録\n  }\n  \n  off(event: string, callback: (data: unknown) => void): void {\n    // イベントリスナーを削除\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Registry Client - TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize a Registry Client from the MCP registry package by providing the URL to the MCP registry configuration JSON. It allows the client to connect and retrieve information about the registry.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RegistryClient } from \"@mcp/registry\"\n\nconst registry = new RegistryClient({\n\turl: \"https://example-tools.com/.well-known/mcp.json\",\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in Environment File\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file. This is required for the example to authenticate with OpenAI's services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Updating Voice Configuration\nDESCRIPTION: This TypeScript code demonstrates how to update the voice configuration, including voice settings and voice activity detection (VAD) parameters. It allows adjusting the sensitivity and timing of speech detection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n\"voice.updateConfig({\n  voice: 'echo',\n  turn_detection: {\n    type: 'server_vad',\n    threshold: 0.5, // Speech detection sensitivity\n    silence_duration_ms: 1000, // Wait time before ending turn\n    prefix_padding_ms: 1000, // Audio padding before speech\n  },\n});\n\"\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This code snippet shows how to define the necessary environment variables, including the OpenAI API key and the PostgreSQL connection string. These variables are crucial for authentication and database access.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in AstraVector\nDESCRIPTION: Demonstrates error handling in the AstraVector class using a try-catch block to catch typed errors related to vector operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Context Position Adherence\nDESCRIPTION: This snippet demonstrates how to evaluate a response with high adherence to context position using the ContextPositionMetric. It defines a context, a query, and a response, and then measures the adherence using the metric, logging the score and reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-position.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'フランスの首都はパリです。',\n  'パリは508年から首都です。',\n  'パリはフランスの政治の中心です。',\n  '首都はフランス政府をホストしています。',\n];\n\nconst metric1 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'フランスの首都はどこですか？';\nconst response1 = 'フランスの首都はパリです。';\n\nconsole.log('例1 - 高い位置の順守:');\nconsole.log('コンテキスト:', context1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 1, reason: 'コンテキストは正しい順序で並んでいます。' }\n```\n\n----------------------------------------\n\nTITLE: Creating HTML Structure for Book Announcement - HTML\nDESCRIPTION: This snippet establishes the foundational HTML layout for the book announcement webpage of 'Principles of Building AI agents', which incorporates meta tags for SEO, responsive design, and social media sharing features. Key elements include the title, description, Open Graph properties, and Twitter card data. Dependencies include a web server capable of serving HTML documents appropriately.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<html lang=\"en\"><head><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><link rel=\"stylesheet\" href=\"/_next/static/css/75c6bf80605c00cd.css\" data-precedence=\"next\"><link rel=\"preload\" as=\"script\" fetchpriority=\"low\" href=\"/_next/static/chunks/webpack-ee8bb2449cda5318.js\"><script src=\"/_next/static/chunks/e6d15c94-4f932d7c2fc2e75c.js\" async=\"\"></script><script src=\"/_next/static/chunks/615-2c124797ed702c55.js\" async=\"\"></script><script src=\"/_next/static/chunks/main-app-71a79cc788e2f8a3.js\" async=\"\"></script><script src=\"/_next/static/chunks/333-64fe985764faf0d9.js\" async=\"\"></script><title>Announcing our new book: Principles of Building AI agents</title><meta name=\"description\" content=\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\"><meta property=\"og:title\" content=\"Announcing our new book: Principles of Building AI agents\"><meta property=\"og:description\" content=\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\"><meta property=\"og:url\" content=\"https://mastra.ai/blog/principles-of-ai-engineering\"><meta property=\"og:image\" content=\"https://mastra.ai/api/og/blog?title=Announcing%20our%20new%20book%3A%20Principles%20of%20Building%20AI%20agents&amp;date=Mar%2012,%202025\"><meta property=\"og:type\" content=\"article\"><meta property=\"article:published_time\" content=\"2025-03-12\"><meta name=\"twitter:card\" content=\"summary_large_image\"><meta name=\"twitter:title\" content=\"Announcing our new book: Principles of Building AI agents\"><meta name=\"twitter:description\" content=\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\"><meta name=\"twitter:image\" content=\"https://mastra.ai/api/og/blog?title=Announcing%20our%20new%20book%3A%20Principles%20of%20Building%20AI%20agents&amp;date=Mar%2012,%202025\"><link rel=\"icon\" href=\"/favicon/mastra-light.ico\" media=\"(prefers-color-scheme: light)\"><link rel=\"icon\" href=\"/favicon/mastra-light.ico\" media=\"(prefers-color-scheme: dark)\"><meta name=\"next-size-adjust\"><link rel=\"icon\" href=\"/favicon.ico?v=5\" sizes=\"any\"><script src=\"/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js\" nomodule=\"\"></script><link rel=\"preload\" href=\"/_next/static/media/16043059f9ddb145-s.p.otf\" as=\"font\" crossorigin=\"\" type=\"font/otf\"><link rel=\"preload\" href=\"/_next/static/media/4473ecc91f70f139-s.p.woff\" as=\"font\" crossorigin=\"\" type=\"font/woff\"><link rel=\"preload\" href=\"/_next/static/media/463dafcda517f24f-s.p.woff\" as=\"font\" crossorigin=\"\" type=\"font/woff\"><link rel=\"preload\" href=\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\" as=\"font\" crossorigin=\"\" type=\"font/woff2\"><link rel=\"preload\" href=\"/_next/static/media/f2f91ba921b45b28-s.p.woff2\" as=\"font\" crossorigin=\"\" type=\"font/woff2\">\n```\n\n----------------------------------------\n\nTITLE: Start Async Workflow via cURL\nDESCRIPTION: This bash command demonstrates how to start the user-registration workflow asynchronously using a cURL request to a Mastra instance. It sends a JSON payload containing user data to the workflow's start-async endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/workflow-variables.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'http://localhost:4111/api/workflows/user-registration/start-async' \\\n     --header 'Content-Type: application/json' \\\n     --data '{\n       \"email\": \"user@example.com\",\n       \"name\": \"John Doe\",\n       \"age\": 25\n     }'\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Voice Provider - Bash\nDESCRIPTION: This command demonstrates how to install the OpenAI voice provider package for Mastra using the pnpm package manager. The `@mastra/voice-openai` package provides the necessary integration for using OpenAI's STT services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-text.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/voice-openai  # OpenAIの例\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Agent for Graph RAG\nDESCRIPTION: This code sets up a Mastra agent with specific instructions for handling RAG queries, using the GPT-4o-mini model and the previously created GraphRAG tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst ragAgent = new Agent({\n  name: \"GraphRAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context. Format your answers as follows:\n\n1. DIRECT FACTS: List only the directly stated facts from the text relevant to the question (2-3 bullet points)\n2. CONNECTIONS MADE: List the relationships you found between different parts of the text (2-3 bullet points)\n3. CONCLUSION: One sentence summary that ties everything together\n\nKeep each section brief and focus on the most important points.\n\nImportant: When asked to answer a question, please base your answer only on the context provided in the tool. \nIf the context doesn't contain enough information to fully answer the question, please state that explicitly.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    graphRagTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Properties in Mastra Workflow (TypeScript)\nDESCRIPTION: Shows how to access nested properties within a step's output using dot notation in the `path` field of the `variables` property. This example demonstrates accessing a deeply nested value from `step1`'s output and mapping it to the `nestedValue` variable for `step2`. Requires `@mastra/core`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(step1)\n  .then(step2, {\n    variables: {\n      // step1の出力からネストされたプロパティにアクセス\n      nestedValue: { step: step1, path: 'nested.deeply.value' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Listing Available Speakers using ElevenLabs Voice\nDESCRIPTION: This TypeScript snippet demonstrates how to retrieve a list of available speakers using the getSpeakers method of the ElevenLabsVoice instance. It returns a promise that resolves to the list of speakers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Measuring Textual Difference with TextualDifferenceMetric\nDESCRIPTION: This code snippet demonstrates how to use the TextualDifferenceMetric class to measure the difference between two strings. It imports the class, creates an instance, calls the `measure` method, and logs the resulting score and info to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/textual-difference.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new TextualDifferenceMetric();\n\nconst result = await metric.measure(\n  \"The quick brown fox\",\n  \"The fast brown fox\"\n);\n\nconsole.log(result.score); // 0-1の類似度比率\nconsole.log(result.info); // 詳細な変更メトリクス\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File - Bash\nDESCRIPTION: This snippet shows the command to copy the example environment variables file necessary for configuring the OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/agentic-workflows/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Evaluate Mixed Tone in TypeScript\nDESCRIPTION: This code snippet demonstrates how to evaluate texts with mixed tones using the ToneConsistencyMetric. It compares the sentiment between 'input3' and 'output3', which contain both positive and negative sentiments.  The metric result, including the score and information about the sentiment difference, is logged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/tone-consistency.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'The interface is frustrating and confusing, though it has potential.';\nconst output3 = 'The design shows promise but needs significant improvements to be usable.';\n\nconsole.log('Example 3 - Mixed Tone:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: result3.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies\nDESCRIPTION: This code snippet imports the necessary dependencies for building the RAG system. It includes modules from `@ai-sdk/openai`, `@mastra/core`, `@mastra/pg`, and `@mastra/rag`. These dependencies provide the functionalities for interacting with OpenAI, managing agents, handling vector storage with PgVector, and implementing RAG-specific tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createVectorQueryTool, createDocumentChunkerTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Dash0\nDESCRIPTION: This snippet outlines the required environment variables for integrating Dash0 with Mastra. It specifies the OTLP endpoint for telemetry data and optional headers including authorization and dataset information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/dash0.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://ingress.<region>.dash0.com\nOTEL_EXPORTER_OTLP_HEADERS=Authorization=Bearer <your-auth-token>, Dash0-Dataset=<optional-dataset>\n```\n\n----------------------------------------\n\nTITLE: Register API Route with Middleware in Mastra - TypeScript\nDESCRIPTION: This code shows how to register an API route with specific middleware. This allows for targeted application of middleware to particular endpoints, such as adding logging or authentication to a specific route.  The example demonstrates a GET route with a middleware function and a handler that interacts with the Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nregisterApiRoute(\"/my-custom-route\", {\n  method: \"GET\",\n  middleware: [\n    async (c, next) => {\n      // 例: リクエストログを追加\n      console.log(`${c.req.method} ${c.req.url}`);\n      await next();\n    },\n  ],\n  handler: async (c) => {\n    // ここでmastraインスタンスにアクセスできます\n    const mastra = c.get(\"mastra\");\n\n    // mastraインスタンスを使用してエージェント、ワークフローなどを取得できます\n    const agents = await mastra.getAgent(\"my-agent\");\n\n    return c.json({ message: \"Hello, world!\" });\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Event-Based Workflow Definition TypeScript\nDESCRIPTION: Shows how to define an event-based workflow that suspends automatically using the `afterEvent` method.  It defines the steps, the workflow with an event schema, and the connection between the steps and the event. It uses `z.object` from Zod to define the schemas for the trigger and the event.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Define steps\nconst getUserInput = new Step({\n  id: \"getUserInput\",\n  execute: async () => ({ userInput: \"initial input\" }),\n  outputSchema: z.object({ userInput: z.string() }),\n});\n\nconst processApproval = new Step({\n  id: \"processApproval\",\n  execute: async ({ context }) => {\n    // Access the event data from the context\n    const approvalData = context.inputData?.resumedEvent;\n    return {\n      approved: approvalData?.approved,\n      approvedBy: approvalData?.approverName,\n    };\n  },\n  outputSchema: z.object({\n    approved: z.boolean(),\n    approvedBy: z.string(),\n  }),\n});\n\n// Create workflow with event definition\nconst approvalWorkflow = new Workflow({\n  name: \"approval-workflow\",\n  triggerSchema: z.object({ requestId: z.string() }),\n  events: {\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n  },\n});\n\n// Build workflow with event-based suspension\napprovalWorkflow\n  .step(getUserInput)\n  .afterEvent(\"approvalReceived\") // Workflow will automatically suspend here\n  .step(processApproval) // This step runs after the event is received\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Analyzing Tone Stability in TypeScript\nDESCRIPTION: Shows how to evaluate sentiment consistency within a single text by passing an empty string as output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/tone-consistency.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'Great service! Friendly staff. Perfect atmosphere.';\nconst output2 = ''; // Empty string for stability analysis\n\nconsole.log('Example 2 - Tone Stability:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: result2.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Contextual Recall: Custom Configuration with TypeScript\nDESCRIPTION: This snippet demonstrates how to customize the ContextualRecallMetric in TypeScript. It configures the metric with a custom scale (0-100) and a specific context, then measures the recall score of an LLM's response. The example also includes the expected output structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/contextual-recall.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextualRecallMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextualRecallMetric(\n  model,\n  {\n    scale: 100, // Use 0-100 scale instead of 0-1\n    context: [\n      \"All data is encrypted at rest and in transit\",\n      \"Two-factor authentication (2FA) is mandatory\",\n      \"Regular security audits are performed\",\n      \"Incident response team available 24/7\"\n    ]\n  }\n);\n\nconst result = await metric.measure(\n  \"Summarize the company's security measures\",\n  \"The company implements encryption for data protection and requires 2FA for all users.\",\n);\n\n// Example output:\n// {\n//   score: 50, // Only half of the security measures were mentioned\n//   info: {\n//     reason: \"The score is 50 because only half of the security measures were mentioned \\n//           in the response. The response missed the regular security audits and incident \\n//           response team information.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Removing Event Listener with voice.off() in TypeScript\nDESCRIPTION: This code demonstrates how to use the `off()` method to remove a previously registered event listener from a real-time voice provider.  It imports the necessary module, initializes the voice provider, connects to the service, registers a callback function for the 'writing' event, and then removes the same callback using `voice.off()`.  It requires the `@mastra/voice-openai-realtime` and `chalk` packages, and an OpenAI API key in the environment variable `OPENAI_API_KEY`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.off.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport chalk from \"chalk\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Define the callback function\nconst writingCallback = ({ text, role }) => {\n  if (role === 'user') {\n    process.stdout.write(chalk.green(text));\n  } else {\n    process.stdout.write(chalk.blue(text));\n  }\n};\n\n// Register event listener\nvoice.on(\"writing\", writingCallback);\n\n// Later, when you want to remove the listener\nvoice.off(\"writing\", writingCallback);\n```\n\n----------------------------------------\n\nTITLE: Using Mastra Server Actions in React Component\nDESCRIPTION: React component that uses the Mastra server action to fetch weather information through a form.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n'use client'\n\nimport { getWeatherInfo } from '../actions'\n\nexport function Weather() {\n  async function handleSubmit(formData: FormData) {\n    const city = formData.get('city') as string\n    const result = await getWeatherInfo(city)\n    // Handle the result\n    console.log(result)\n  }\n\n  return (\n    <form action={handleSubmit}>\n      <input name=\"city\" placeholder=\"Enter city name\" />\n      <button type=\"submit\">Get Weather</button>\n    </form>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Available Voices\nDESCRIPTION: This snippet demonstrates how to fetch and list all available speaker voices using the getSpeakers method of the DeepgramVoice instance. This allows users to see which voices are available for use in TTS functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst voices = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: TTS with Cloudflare Voice Agent\nDESCRIPTION: This code demonstrates how to use an Agent with Cloudflare voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Cloudflare's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { CloudflareVoice } from \"@mastra/voice-cloudflare\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new CloudflareVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAGTool with custom description in TypeScript\nDESCRIPTION: This code snippet illustrates how to initialize the `createGraphRAGTool` with a custom description. The `description` parameter allows for tailoring the tool's purpose and usage context to specific scenarios. In this case, the description emphasizes the analysis of document relationships for uncovering complex patterns in company historical data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/graph-rag-tool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  description: \"Analyze document relationships to find complex patterns and connections in our company's historical data\"\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra CLI and Initializing Project\nDESCRIPTION: This snippet demonstrates how to install the latest version of Mastra CLI globally and initialize it in an existing project. It uses npm to install the CLI and then runs the 'mastra init' command to set up Mastra in the project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/add-to-existing-project.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g mastra@latest \nmastra init\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example of how to set up the required environment variables including the OpenAI API key and Postgres connection string in the .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: MCPServer tools() method definition\nDESCRIPTION: Defines the signature of the tools() method for the MCPServer class. This method returns a read-only record of the tools that were set up when the server was created.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ntools(): Readonly<Record<string, ConvertedTool>>\n```\n\n----------------------------------------\n\nTITLE: Partial Coverage Keyword Evaluation Example\nDESCRIPTION: Shows evaluation of a response with partial keyword coverage, demonstrating how the metric handles incomplete matches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/keyword-coverage.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'TypeScript offers interfaces, generics, and type inference';\nconst output2 = 'TypeScript provides type inference and some advanced features';\n\nconsole.log('Example 2 - Partial Coverage:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    totalKeywords: result2.info.totalKeywords,\n    matchedKeywords: result2.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.5, info: { totalKeywords: 6, matchedKeywords: 3 } }\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution of Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Shows two ways to execute multiple nested workflows in parallel within a parent workflow. The first uses individual `.step()` calls with `.after()` to specify dependencies. The second uses an array of workflows in a single `.step()` call, with `.then()` implicitly waiting for all workflows to complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow\n  .step(nestedWorkflowA)\n  .step(nestedWorkflowB)\n  .after([nestedWorkflowA, nestedWorkflowB])\n  .step(finalStep);\n\n```\n\nLANGUAGE: typescript\nCODE:\n```\nparentWorkflow.step([nestedWorkflowA, nestedWorkflowB]).then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Configuring Real-time Voice Provider with Instructions in TypeScript\nDESCRIPTION: This example demonstrates how to initialize a real-time voice provider from OpenAI, create an agent with the voice provider, and add specific behavioral instructions using the addInstructions() method before connecting to the service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.addInstructions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Create an agent with the voice provider\nconst agent = new Agent({\n  name: \"Customer Support Agent\",\n  instructions: \"You are a helpful customer support agent for a software company.\",\n  model: openai(\"gpt-4o\"),\n  voice,\n});\n\n// Add additional instructions to the voice provider\nvoice.addInstructions(`\n  When speaking to customers:\n  - Always introduce yourself as the customer support agent\n  - Speak clearly and concisely\n  - Ask clarifying questions when needed\n  - Summarize the conversation at the end\n`);\n\n// Connect to the real-time service\nawait voice.connect();\n```\n\n----------------------------------------\n\nTITLE: Copying the Environment File (Bash)\nDESCRIPTION: This snippet shows how to copy the example environment file (`.env.example`) to a new environment file (`.env`). This is required to configure various features of the documentation, such as posthog, form subscription, analytics, and chatbot.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Converting MCP Tools to Mastra Format in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates converting MCP tools to Mastra format using an asynchronous 'tools()' method from a client object, where each tool is converted into a JSON schema wrapped for Mastra compatibility, including error handling and context passing. It relies on existing Mastra client setup and applicable methods for full functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp/README.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst tools = await client.tools();\n// Returns: { [toolName: string]: MastraTool }\n\n// Each tool includes:\n// - Converted JSON schema\n// - Mastra-compatible execution wrapper\n// - Error handling\n// - Automatic context passing\n```\n\n----------------------------------------\n\nTITLE: Retrieving Agent with Configuration in TypeScript\nDESCRIPTION: This function retrieves an agent based on the provided configuration. It takes connection ID, agent configuration, APIs, and a logger as parameters. The function returns a promise that resolves to another function, which takes a prompt and returns a message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/getAgent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nasync function getAgent({\n  connectionId,\n  agent,\n  apis,\n  logger,\n}: {\n  connectionId: string;\n  agent: Record<string, any>;\n  apis: Record<string, IntegrationApi>;\n  logger: any;\n}): Promise<(props: { prompt: string }) => Promise<any>> {\n  return async (props: { prompt: string }) => {\n    return { message: \"Hello, world!\" };\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Available TTS Models\nDESCRIPTION: In this TypeScript snippet, the voices() method is called on the tts instance to retrieve and list all available TTS models supported by the Replicate API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst voices = await tts.voices();\n```\n\n----------------------------------------\n\nTITLE: Generating Text Embeddings with Mastra and OpenAI\nDESCRIPTION: Creates document embeddings using Mastra and OpenAI's text-embedding-3-small model. The code first creates a document from text, chunks it, and then generates an embedding for the first chunk using the specified embedding model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-text-chunk.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { MDocument } from '@mastra/rag';\nimport { embed } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embedding } = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: chunks[0].text,\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Word Inclusion Example in Bash\nDESCRIPTION: Command to execute the word inclusion metric example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/word-inclusion/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initializing Murf Voice Configuration\nDESCRIPTION: Murf音声プロバイダーの初期化設定を示します。音声合成のためのモデル名、APIキー、言語、感情を指定します。Murfは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはMurfの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_28\n\nLANGUAGE: typescript\nCODE:\n```\n// Murf Voice Configuration\nconst voice = new MurfVoice({\n  speechModel: {\n    name: \"murf-voice\", // Example model name\n    apiKey: process.env.MURF_API_KEY,\n    language: \"en-US\", // Language code\n    emotion: \"happy\", // Emotion setting\n  },\n  // Murf may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Get Agent Tool with TypeScript\nDESCRIPTION: Retrieves information about a specific tool available to the agent. It uses the agent's `getTool` method, taking the tool ID as a parameter and returning a promise that resolves to the tool object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst tool = await agent.getTool(\"tool-id\");\n```\n\n----------------------------------------\n\nTITLE: Step-Level Retry Configuration in Typescript\nDESCRIPTION: This code snippet illustrates how to configure retry attempts and delay for a specific step in Mastra using Typescript.  Step-level configurations override workflow-level settings. It requires the `Workflow` and `Step` classes from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// ステップレベルのリトライ設定（ワークフローレベルを上書き）\nconst apiStep = new Step({\n  id: 'callApi',\n  execute: async () => {\n    // 失敗する可能性のあるAPI呼び出し\n  },\n  retryConfig: {\n    attempts: 5,    // このステップは最大5回リトライします\n    delay: 2000,    // リトライ間の遅延時間は2秒\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating high context precision with ContextPrecisionMetric\nDESCRIPTION: This TypeScript snippet demonstrates how to evaluate a response that accurately uses all provided context information. It initializes the ContextPrecisionMetric with a context array and the OpenAI model, then measures the precision of a response against a query. The output includes the precision score and the reason for the score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-precision.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  '光合成は太陽光をエネルギーに変換します。',\n  '植物は光合成にクロロフィルを使用します。',\n  '光合成は副産物として酸素を生成します。',\n  'このプロセスには太陽光とクロロフィルが必要です。',\n];\n\nconst metric1 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = '光合成とは何で、どのように機能しますか？';\nconst response1 = '光合成は、植物が太陽光をエネルギーに変換し、クロロフィルを使用して副産物として酸素を生成するプロセスです。';\n\nconsole.log('例 1 - 高精度:');\nconsole.log('コンテキスト:', context1);\nconsole.log('クエリ:', query1);\nconsole.log('応答:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('メトリック結果:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 1, reason: 'コンテキストはすべての関連情報を使用し、無関係な情報を含んでいません。' }\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with stdio and SSE servers in TypeScript\nDESCRIPTION: This TypeScript code configures the MCP using the MCPConfiguration class. It sets up both stdio and SSE-based servers. The stdio server example uses `npx` to run a sequential-thinking server, while the SSE server example connects to a weather API endpoint requiring authorization.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst mcp = new MCPConfiguration({\n  servers: {\n    // stdio example\n    sequential: {\n      name: \"sequential-thinking\",\n      server: {\n        command: \"npx\",\n        args: [\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"],\n      },\n    },\n    // SSE example\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),\n      requestInit: {\n        headers: {\n          Authorization: \"Bearer your-token\",\n        },\n      },\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Querying Messages for a Thread\nDESCRIPTION: This snippet retrieves messages associated with a specified thread using the getMessages method, which accepts the threadId as a parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst messages = await store.getMessages({ threadId: 'thread-123' });\n```\n\n----------------------------------------\n\nTITLE: Displaying Search Results Format in TypeScript\nDESCRIPTION: This snippet shows the expected format of search results from a vector query. It includes the text content, similarity score, and associated metadata for each result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n[\n  {\n    text: \"Climate change poses significant challenges...\",\n    score: 0.89,\n    metadata: { source: \"article1.txt\" }\n  },\n  {\n    text: \"Rising temperatures affect crop yields...\",\n    score: 0.82,\n    metadata: { source: \"article1.txt\" }\n  }\n  // ... more results\n]\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for Context Precision Evaluation\nDESCRIPTION: This code snippet shows how to configure the environment variables needed for the Context Precision metric, specifically setting up the OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-precision.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Content Similarity with Different Options\nDESCRIPTION: Illustrates how to configure the ContentSimilarityMetric with different options for case sensitivity and whitespace handling to control the comparison process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/content-similarity.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from \"@mastra/evals/nlp\";\n\n// 大文字と小文字を区別する比較\nconst caseSensitiveMetric = new ContentSimilarityMetric({\n  ignoreCase: false,\n  ignoreWhitespace: true\n});\n\nconst result1 = await caseSensitiveMetric.measure(\n  \"Hello World\",\n  \"hello world\"\n); // 大文字と小文字の違いによりスコアが低くなる\n\n// 出力例:\n// {\n//   score: 0.75,\n//   info: { similarity: 0.75 }\n// }\n\n// 厳密な空白の比較\nconst strictWhitespaceMetric = new ContentSimilarityMetric({\n  ignoreCase: true,\n  ignoreWhitespace: false\n});\n\nconst result2 = await strictWhitespaceMetric.measure(\n  \"Hello   World\",\n  \"Hello World\"\n); // 空白の違いによりスコアが低くなる\n\n// 出力例:\n// {\n//   score: 0.85,\n//   info: { similarity: 0.85 }\n// }\n```\n\n----------------------------------------\n\nTITLE: Theme Customization for Toast Notifications - CSS\nDESCRIPTION: This snippet defines CSS variables for different themes, providing customization for toast notifications including light and dark modes, with accessible color schemes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_4\n\nLANGUAGE: css\nCODE:\n```\n[data-sonner-toaster][data-theme=light]{--normal-bg: #fff;--normal-border: var(--gray4);--normal-text: var(--gray12);--success-bg: hsl(143, 85%, 96%);--success-border: hsl(145, 92%, 91%);--success-text: hsl(140, 100%, 27%);--info-bg: hsl(208, 100%, 97%);--info-border: hsl(221, 91%, 91%);--info-text: hsl(210, 92%, 45%);--warning-bg: hsl(49, 100%, 97%);--warning-border: hsl(49, 91%, 91%);--warning-text: hsl(31, 92%, 45%);--error-bg: hsl(359, 100%, 97%);--error-border: hsl(359, 100%, 94%);--error-text: hsl(360, 100%, 45%)}[data-sonner-toaster][data-theme=dark]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1);--success-bg: hsl(150, 100%, 6%);--success-border: hsl(147, 100%, 12%);--success-text: hsl(150, 86%, 65%);--info-bg: hsl(215, 100%, 6%);--info-border: hsl(223, 100%, 12%);--info-text: hsl(216, 87%, 65%);--warning-bg: hsl(64, 100%, 6%);--warning-border: hsl(60, 100%, 12%);--warning-text: hsl(46, 87%, 65%);--error-bg: hsl(358, 76%, 10%);--error-border: hsl(357, 89%, 16%);--error-text: hsl(358, 100%, 81%)}\n```\n\n----------------------------------------\n\nTITLE: Registering Voice Event Listeners with OpenAIRealtimeVoice - TypeScript\nDESCRIPTION: This snippet shows how to initialize a real-time voice provider using OpenAIRealtimeVoice, register event listeners for transcribed text and audio data, and handle errors. It requires the @mastra/voice-openai-realtime, @mastra/node-speaker, and chalk packages. Provide your OpenAI API key through the process.env.OPENAI_API_KEY environment variable. The function listens for 'writing', 'speaker', and 'error' events and outputs data to the console and speaker respectively.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.on.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\nimport chalk from \"chalk\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Register event listener for transcribed text\nvoice.on(\"writing\", (event) => {\n  if (event.role === 'user') {\n    process.stdout.write(chalk.green(event.text));\n  } else {\n    process.stdout.write(chalk.blue(event.text));\n  }\n});\n\n// Listen for audio data and play it\nconst speaker = new Speaker({\n  sampleRate: 24100,\n  channels: 1,\n  bitDepth: 16,\n});\n\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker);\n});\n\n// Register event listener for errors\nvoice.on(\"error\", ({ message, code, details }) => {\n  console.error(`Error ${code}: ${message}`, details);\n});\n```\n\n----------------------------------------\n\nTITLE: Route Configuration (TypeScript)\nDESCRIPTION: Example of route configurations for traffic routing based on URL patterns and domains. This code demonstrates how to define routes to forward traffic to a Cloudflare Worker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/cloudflare.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst routes = [\n  {\n    pattern: 'api.example.com/*',\n    zone_name: 'example.com',\n    custom_domain: true,\n  },\n  {\n    pattern: 'example.com/api/*',\n    zone_name: 'example.com',\n  },\n];\n```\n\n----------------------------------------\n\nTITLE: Building Mastra project from a specific directory\nDESCRIPTION: This command builds the Mastra project from a specified directory. It uses the `--dir` option to point to the project's root directory. The built artifacts are placed in the `.mastra` directory within the specified project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/cli/build.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"mastra build --dir ./my-mastra-project\"\n```\n\n----------------------------------------\n\nTITLE: Running the RAG Example\nDESCRIPTION: Command to execute the Chain of Thought RAG example application after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Text to Speech Conversion with SpeechifyVoice in TypeScript\nDESCRIPTION: This snippet shows how to convert text to speech using the `speak` method of the SpeechifyVoice class. It includes an example of how to override the default speaker during the speech conversion process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/speechify.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// テキストを音声に変換\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 'henry',  // デフォルトの声を上書き\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in Mastra Client SDK\nDESCRIPTION: This code demonstrates how to use a try-catch block to handle potential errors when calling Mastra Client SDK API methods. The `try` block executes the API call, and if an error occurs, the `catch` block logs the error message to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/error-handling.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const agent = client.getAgent(\"agent-id\");\n  const response = await agent.generate({\n    messages: [{ role: \"user\", content: \"Hello\" }],\n  });\n} catch (error) {\n  console.error(\"An error occurred:\", error.message);\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the context precision example directory to set up the project locally.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/context-precision\n```\n\n----------------------------------------\n\nTITLE: Adjusting Chunk Size with MDocument in Typescript\nDESCRIPTION: This code snippet shows how to adjust the chunk size when using the MDocument class from the @mastra/rag library. It sets a custom chunk size of 512 characters when splitting the document. This requires the @mastra/rag package to be installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/adjust-chunk-size.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  size: 512,\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Query Result Structure in AstraVector\nDESCRIPTION: Defines the structure of query result objects returned from the AstraVector class, including ID, score, metadata, and optional vector inclusion.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluate Low Relevant Response\nDESCRIPTION: This TypeScript snippet demonstrates evaluating a response with low relevancy to the given query. It uses the AnswerRelevancyMetric to assess a query about meditation benefits against a response describing the Great Wall of China. The output provides a relevance score and a detailed reason for the low score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'What are the benefits of meditation?';\nconst response3 =\n  'The Great Wall of China is over 13,000 miles long and was built during the Ming Dynasty to protect against invasions.';\n\nconsole.log('Example 3 - Low Relevancy:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.1, reason: 'The response is not relevant to the query. It provides information about the Great Wall of China but does not mention meditation.' }\n```\n\n----------------------------------------\n\nTITLE: Running the Multi-Agent Workflow Example\nDESCRIPTION: Command to start the multi-agent workflow example after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: MCPConfiguration Resource Management - Instance Creation\nDESCRIPTION: Shows how to handle multiple MCPConfiguration instances and prevent memory leaks by either providing unique IDs for each instance or disconnecting from existing instances before creating new ones with the same configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// First instance - OK\nconst mcp1 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n\n// Second instance with same config - Will throw an error\nconst mcp2 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n\n// To fix, either:\n// 1. Add unique IDs\nconst mcp3 = new MCPConfiguration({\n  id: \"instance-1\",\n  servers: {\n    /* ... */\n  },\n});\n\n// 2. Or disconnect before recreating\nawait mcp1.disconnect();\nconst mcp4 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for Mastra with OpenAI\nDESCRIPTION: Sets up the necessary environment variables for Mastra to work with OpenAI's API. This environment variable file should contain your OpenAI API key for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Handling Workflow Execution Results\nDESCRIPTION: This example demonstrates how to handle the results of a workflow execution, accessing the `runId`, `results`, and `status` properties. It includes a conditional check for the `COMPLETED` status and logging of step results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/execute.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, results, status } = await workflow.execute({\n  triggerData: { inputValue: 42 }\n});\n\nif (status === \"COMPLETED\") {\n  console.log(\"Step results:\", results);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Azure Voice Configuration\nDESCRIPTION: Azure音声プロバイダーの初期化設定を示します。音声認識とテキスト変換のためのモデル名、APIキー、リージョン、言語、音声スタイル、ピッチ、および速度を指定します。この設定により、MastraはAzureの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\n// Azure Voice Configuration\nconst voice = new AzureVoice({\n  speechModel: {\n    name: \"en-US-JennyNeural\", // Example model name\n    apiKey: process.env.AZURE_SPEECH_KEY,\n    region: process.env.AZURE_SPEECH_REGION,\n    language: \"en-US\", // Language code\n    style: \"cheerful\", // Voice style\n    pitch: \"+0Hz\", // Pitch adjustment\n    rate: \"1.0\", // Speech rate\n  },\n  listeningModel: {\n    name: \"en-US\", // Example model name\n    apiKey: process.env.AZURE_SPEECH_KEY,\n    region: process.env.AZURE_SPEECH_REGION,\n    format: \"simple\", // Output format\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Example Payload for Image Metadata API\nDESCRIPTION: JSON payload structure required for the image metadata API endpoint. This shows how to format the request body with an image URL for processing by the Mastra AI agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n{\n  imageUrl: \"\" //the image url\n}\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Projects for Vercel with bash\nDESCRIPTION: Illustrates the command to build a Mastra project for deployment to Vercel using the Mastra CLI. This command generates a Vercel-compatible output structure in the .mastra/output directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/vercel.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Configuring OTLP Endpoint for New Relic (ENV)\nDESCRIPTION: These environment variables configure the OpenTelemetry (OTLP) exporter to send data to New Relic. `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the New Relic OTLP endpoint. `OTEL_EXPORTER_OTLP_HEADERS` sets the API key for authentication, replacing `your_license_key` with your actual New Relic license key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/new-relic.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://otlp.nr-data.net:4317\nOTEL_EXPORTER_OTLP_HEADERS=\"api-key=your_license_key\"\n```\n\n----------------------------------------\n\nTITLE: Context-Aware Evaluation Implementation\nDESCRIPTION: Shows how to use FaithfulnessMetric with context for evaluating AI responses. Includes context initialization and response evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { FaithfulnessMetric } from '@mastra/evals';\n\n// Initialize with context\nconst faithfulnessMetric = new FaithfulnessMetric({\n  model: openai('gpt-4'),\n  context: ['Paris is the capital of France', 'Paris has a population of 2.2 million'],\n  scale: 1,\n});\n\n// Evaluate response against context\nconst result = await faithfulnessMetric.measure(\n  'Tell me about Paris',\n  'Paris is the capital of France with 2.2 million residents',\n);\n\nconsole.log('Faithfulness Score:', result.score);\nconsole.log('Reasoning:', result.reason);\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors in Typescript\nDESCRIPTION: This code shows how to add or update vectors in an index using `vector.upsert`. It takes an `indexName`, an array of `vectors`, corresponding `metadata` for each vector, and optional `ids`.  The function returns a promise that resolves with the ids of the upserted vectors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst ids = await vector.upsert({\n  indexName: \"my-index\",\n  vectors: [\n    [0.1, 0.2, 0.3], // 最初のベクトル\n    [0.4, 0.5, 0.6], // 2番目のベクトル\n  ],\n  metadata: [{ label: \"first\" }, { label: \"second\" }],\n  ids: [\"id1\", \"id2\"], // オプション：カスタムID\n});\n```\n\n----------------------------------------\n\nTITLE: Multiple Events in a Mastra Workflow (TypeScript)\nDESCRIPTION: This snippet demonstrates a Mastra workflow that waits for multiple events at different points in its execution. It shows how to use `afterEvent` multiple times to suspend and resume the workflow based on different event triggers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(createRequest)\n  .afterEvent('approvalReceived')\n  .step(processApproval)\n  .afterEvent('documentUploaded')\n  .step(processDocument)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and PostgreSQL\nDESCRIPTION: Sets up environment variables for OpenAI API key and PostgreSQL connection string in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Evaluating Identical Texts with Textual Difference Metric\nDESCRIPTION: Demonstrates comparing identical text strings using the Textual Difference metric and logging the detailed results, showing a perfect similarity score of 1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/textual-difference.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'The quick brown fox jumps over the lazy dog';\nconst output1 = 'The quick brown fox jumps over the lazy dog';\n\nconsole.log('Example 1 - Identical Texts:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    confidence: result1.info.confidence,\n    ratio: result1.info.ratio,\n    changes: result1.info.changes,\n    lengthDiff: result1.info.lengthDiff,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 1,\n//   info: { confidence: 1, ratio: 1, changes: 0, lengthDiff: 0 }\n// }\n```\n\n----------------------------------------\n\nTITLE: Resume Workflow Run and Watch Transitions using TypeScript\nDESCRIPTION: This snippet demonstrates how to resume a workflow run and watch workflow step transitions. It utilizes a `createRun` function and the `workflow.watch` and `workflow.resume` methods.  The `watch` method listens for transitions, while `resume` continues the workflow execution with provided step and context data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ntry{\n  //To resume a workflow run, when a step is suspended\n  const {run} = createRun({runId: prevRunId})\n\n  //Watch run\n   workflow.watch({runId},(record)=>{\n   // Every new record is the latest transition state of the workflow run\n\n        console.log({\n          activePaths: record.activePaths,\n          results: record.results,\n          timestamp: record.timestamp,\n          runId: record.runId\n        });\n   })\n\n   //resume run\n   workflow.resume({\n      runId,\n      stepId: \"step-id\",\n      contextData: { key: \"value\" },\n    });\n}catch(e){\n  console.error(e);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with LLM Evals in Typescript\nDESCRIPTION: This code snippet demonstrates how to initialize an AI agent using the `@mastra/core/agent` and `@ai-sdk/openai` libraries. It includes metrics for summarization, content similarity, and tone consistency. It shows how to create an agent and integrate different evaluation metrics to measure its performance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\nimport {\n  ContentSimilarityMetric,\n  ToneConsistencyMetric,\n} from \"@mastra/evals/nlp\";\n\nconst model = openai(\"gpt-4o\");\n\nexport const myAgent = new Agent({\n  name: \"ContentWriter\",\n  instructions: \"You are a content writer that creates accurate summaries\",\n  model,\n  evals: {\n    summarization: new SummarizationMetric(model),\n    contentSimilarity: new ContentSimilarityMetric(),\n    tone: new ToneConsistencyMetric(),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up Mastra Agent\nDESCRIPTION: This code snippet sets up a Mastra agent that can handle both querying and cleaning documents. The agent is configured with a name, instructions, the OpenAI 'gpt-4o-mini' model, and the vector query and document chunker tools. The instructions guide the agent on how to process, clean, label, and remove irrelevant or duplicate information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `あなたは、クエリとドキュメントのクリーニングの両方を処理する役立つアシスタントです。\n    クリーニング時: データを処理、クリーニング、ラベル付けし、関連性のない情報を削除し、重要な事実を保持しながら重複を排除します。\n    クエリ時: 利用可能なコンテキストに基づいて回答を提供します。回答は簡潔で関連性のあるものにしてください。\n    \n    重要: 質問に答えるよう求められた場合、ツールで提供されたコンテキストのみに基づいて回答してください。コンテキストに質問に完全に答えるための十分な情報が含まれていない場合は、その旨を明示してください。\n    `,\n  model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n    documentChunkerTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Voice Provider Package using PNPM\nDESCRIPTION: Command to install a specific voice provider package (OpenAI) using PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-text.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/voice-openai  # Example for OpenAI\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating Repository - Bash\nDESCRIPTION: Commands to clone the mastra repository and navigate to the parallel workflow example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-parallel-steps/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/workflow-with-parallel-steps\n```\n\n----------------------------------------\n\nTITLE: Processing Audio for Transcription with STT - Typescript\nDESCRIPTION: This code demonstrates how to process audio data received from a web request using the agent's STT capabilities to transcribe it. It retrieves an audio file from the request's form data, converts it to a readable stream, and then uses the `noteTakerAgent`'s `listen` method to transcribe the audio. The transcribed text is then returned in a JSON response with a 'Content-Type' header set to 'application/json'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-text.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from '@/src/mastra'; // Import the Mastra instance\nimport { Readable } from 'node:stream';\n\nexport async function POST(req: Request) {\n  // Get the audio file from the request\n  const formData = await req.formData();\n  const audioFile = formData.get('audio') as File;\n  const arrayBuffer = await audioFile.arrayBuffer();\n  const buffer = Buffer.from(arrayBuffer);\n  const readable = Readable.from(buffer);\n\n  // Get the note taker agent from the Mastra instance\n  const noteTakerAgent = mastra.getAgent('noteTakerAgent');\n \n  // Transcribe the audio file\n  const text = await noteTakerAgent.voice?.listen(readable);\n\n  return new Response(JSON.stringify({ text }), {\n    headers: { 'Content-Type': 'application/json' },\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Processing Documents into Chunks\nDESCRIPTION: This code creates a `MDocument` from text and then splits it into smaller chunks. The chunking strategy is 'recursive', with a specified size of 150 and an overlap of 20, using newline characters as separators. This process ensures that the document is divided into manageable segments for embedding.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc1 = MDocument.fromText(`\nmarket data shows price resistance levels.\ntechnical charts display moving averages.\nsupport levels guide trading decisions.\nbreakout patterns signal entry points.\nprice action determines trade timing.\n\nbaseball cards show gradual value increase.\nrookie cards command premium prices.\ncard condition affects resale value.\nauthentication prevents fake trading.\ngrading services verify card quality.\n\nvolume analysis confirms price trends.\nsports cards track seasonal demand.\nchart patterns predict movements.\nmint condition doubles card worth.\nresistance breaks trigger orders.\nrare cards appreciate yearly.\n`);\n\nconst chunks = await doc1.chunk({\n  strategy: \"recursive\",\n  size: 150,\n  overlap: 20,\n  separator: \"\\n\",\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using CloudflareVoice with TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the CloudflareVoice class with specific configurations such as API keys, account IDs, and speaker settings. It showcases converting text to speech using the speak method and retrieving available speaker options using getSpeakers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/cloudflare.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CloudflareVoice } from '@mastra/voice-cloudflare';\n\n// Initialize with configuration\nconst voice = new CloudflareVoice({\n  speechModel: {\n    name: '@cf/meta/m2m100-1.2b',\n    apiKey: 'your-cloudflare-api-token',\n    accountId: 'your-cloudflare-account-id'\n  },\n  speaker: 'en-US-1'  // Default voice\n});\n\n// Convert text to speech\nconst audioStream = await voice.speak('Hello, how can I help you?', {\n  speaker: 'en-US-2',  // Override default voice\n});\n\n// Get available voices\nconst speakers = await voice.getSpeakers();\nconsole.log(speakers);\n```\n\n----------------------------------------\n\nTITLE: Partial Word Inclusion Example Typescript\nDESCRIPTION: Demonstrates a scenario where only some of the specified words are included in the output. It initializes a `WordInclusionMetric` with programming languages, an input requesting languages, and an output mentioning only python and javascript. The resulting metric will reflect a partial inclusion score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/word-inclusion.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst words2 = ['python', 'javascript', 'typescript', 'rust'];\nconst metric2 = new WordInclusionMetric(words2);\n\nconst input2 = 'What programming languages do you know?';\nconst output2 = 'I know python and javascript very well.';\n\nconst result2 = await metric2.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: result2.info,\n});\n// Example Output:\n// Metric Result: { score: 0.5, info: { totalWords: 4, matchedWords: 2 } }\n```\n\n----------------------------------------\n\nTITLE: Error Handling: else() without if() (Typescript)\nDESCRIPTION: Illustrates the error handling behavior of the `.else()` method when used without a preceding `if()` statement. The code attempts to create an `else` branch without an `if` condition, which throws an error indicating that no active condition was found. A try-catch block is used to catch and log the error.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/else.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  // This will throw an error\n  workflow\n    .step(someStep)\n    .else()\n    .then(anotherStep)\n    .commit();\n} catch (error) {\n  console.error(error); // \"No active condition found\"\n}\n```\n\n----------------------------------------\n\nTITLE: Processing and Chunking Research Paper\nDESCRIPTION: Fetches research paper content and splits it into manageable chunks for processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\nimport { mastra } from \"./mastra\";\n\nconst paperUrl = \"https://arxiv.org/html/1706.03762\";\nconst response = await fetch(paperUrl);\nconst paperText = await response.text();\n\nconst doc = MDocument.fromText(paperText);\nconst chunks = await doc.chunk({\n  strategy: 'recursive',\n  size: 512,\n  overlap: 50,\n  separator: '\\n',\n});\n\nconsole.log(\"Number of chunks:\", chunks.length);\n```\n\n----------------------------------------\n\nTITLE: Initializing PostgreSQL Storage in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize a PostgreSQL storage instance using a connection string. It requires the '@mastra/pg' package and an environment-configured database URL.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/postgresql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PostgresStore } from \"@mastra/pg\";\n\nconst storage = new PostgresStore({\n  connectionString: process.env.DATABASE_URL,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm in Bash\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/metadata-extraction/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Answer Relevancy Example\nDESCRIPTION: Command to execute the example using tsx (TypeScript execution engine) to run the index.ts file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm tsx index.ts\n```\n\n----------------------------------------\n\nTITLE: QueryResult Interface Definition\nDESCRIPTION: Defines the structure of the QueryResult object, which represents a single search result. It includes the document ID, similarity score, metadata, and optionally the vector itself if `includeVector` is true.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/astra.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Watching and Resuming Workflow (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to watch a workflow for suspension and resume it with new context data. It uses the `watch` method to monitor the workflow's `activePaths` and the `resume` method to continue execution from a specific step. The example shows resuming a workflow when `stepTwo` is suspended.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./index\";\n\n// Get the workflow\nconst myWorkflow = mastra.getWorkflow(\"myWorkflow\");\nconst { start, watch, resume } = myWorkflow.createRun();\n\n// Start watching the workflow before executing it\nwatch(async ({ activePaths }) => {\n  const isStepTwoSuspended = activePaths.get(\"stepTwo\")?.status === \"suspended\";\n  if (isStepTwoSuspended) {\n    console.log(\"Workflow suspended, resuming with new value\");\n\n    // Resume the workflow with new context\n    await resume({\n      stepId: \"stepTwo\",\n      context: { secondValue: 100 },\n    });\n  }\n});\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n----------------------------------------\n\nTITLE: Create Research Assistant Agent (TypeScript)\nDESCRIPTION: Creates a RAG-enabled research assistant agent using @mastra/core.  It utilizes a Vector Query Tool for semantic search and GPT-4o-mini for generating responses. The agent is configured with specific instructions for analyzing papers and using retrieved content. Dependencies include @mastra/core/agent, @ai-sdk/openai, and @mastra/rag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { createVectorQueryTool } from '@mastra/rag';\n\n// Create a tool for semantic search over our paper embeddings\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'papers',\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nexport const researchAgent = new Agent({\n  name: 'Research Assistant',\n  instructions: \n    `You are a helpful research assistant that analyzes academic papers and technical documents.\n    Use the provided vector query tool to find relevant information from your knowledge base, \n    and provide accurate, well-supported answers based on the retrieved content.\n    Focus on the specific content available in the tool and acknowledge if you cannot find sufficient information to answer a question.\n    Base your responses only on the content provided, not on general knowledge.`,    model: openai('gpt-4o-mini'),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/cloudflare package\nDESCRIPTION: Installs the @mastra/cloudflare package using npm. This package provides a Cloudflare KV store for Mastra, enabling scalable and serverless storage for various data types.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nnpm install @mastra/cloudflare\n```\n```\n\n----------------------------------------\n\nTITLE: PGIndexStats Interface\nDESCRIPTION: This code defines the `PGIndexStats` interface, which represents the structure of the statistics returned when describing an index.  It includes the vector dimension, count, distance metric, index type, and configuration parameters.  This interface helps in understanding the properties of an index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ninterface PGIndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n  type: \"flat\" | \"hnsw\" | \"ivfflat\";\n  config: {\n    m?: number;\n    efConstruction?: number;\n    lists?: number;\n    probes?: number;\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Using Upstash Vector Store with @mastra/upstash\nDESCRIPTION: This code snippet demonstrates how to use the UpstashVector class to interact with the Upstash vector store. It includes initializing the vector store with the Upstash REST URL and token, adding vectors with metadata and IDs, and querying the store with a query vector, topK parameter, filter, and includeVector flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashVector } from '@mastra/upstash';\n\nconst vectorStore = new UpstashVector({\n  url: process.env.UPSTASH_VECTOR_REST_URL,\n  token: process.env.UPSTASH_VECTOR_TOKEN\n});\n\n// Add vectors\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [{ text: 'doc1' }, { text: 'doc2' }];\nconst ids = await vectorStore.upsert({\n  indexName: 'my-namespace',\n  vectors,\n  metadata\n});\n\n// Query vectors\nconst results = await vectorStore.query({\n  indexName: 'my-namespace',\n  queryVector: [0.1, 0.2, ...],\n  topK: 10,\n  filter: { text: { $eq: 'doc1' } },\n  includeVector: false\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Branching and Merging Paths in Mastra Workflows\nDESCRIPTION: Demonstrates how to create diverging execution paths after a step and later converge them, allowing for complex workflow patterns with multiple execution branches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(stepA)\n    .then(stepB)\n    .then(stepD)\n  .after(stepA)\n    .step(stepC)\n    .then(stepE)\n  .after([stepD, stepE])\n    .step(stepF);\n```\n\n----------------------------------------\n\nTITLE: Content Similarity Metric with different options\nDESCRIPTION: This example demonstrates how to use the ContentSimilarityMetric with different configuration options, specifically case sensitivity and whitespace handling. Two instances of the metric are created with different options, and the measure method is called to compare strings with different cases and whitespace.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/content-similarity.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from \"@mastra/evals/nlp\";\n\n// Case-sensitive comparison\nconst caseSensitiveMetric = new ContentSimilarityMetric({\n  ignoreCase: false,\n  ignoreWhitespace: true\n});\n\nconst result1 = await caseSensitiveMetric.measure(\n  \"Hello World\",\n  \"hello world\"\n); // Lower score due to case difference\n\n// Example output:\n// {\n//   score: 0.75,\n//   info: { similarity: 0.75 }\n// }\n\n// Strict whitespace comparison\nconst strictWhitespaceMetric = new ContentSimilarityMetric({\n  ignoreCase: true,\n  ignoreWhitespace: false\n});\n\nconst result2 = await strictWhitespaceMetric.measure(\n  \"Hello   World\",\n  \"Hello World\"\n); // Lower score due to whitespace difference\n\n// Example output:\n// {\n//   score: 0.85,\n//   info: { similarity: 0.85 }\n// }\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Package Manager\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/tone-consistency/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Netlify Deployer Configuration\nDESCRIPTION: Configuration example for the Netlify deployer showing required parameters including team slug and authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nnew NetlifyDeployer({\n  scope: 'your-netlify-team-slug',\n  projectName: 'your-project-name',\n  token: 'your-netlify-token'\n})\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required Node.js dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Manual Installation - Initialize TypeScript Project (npm)\nDESCRIPTION: These commands initialize a TypeScript project using npm, install necessary dependencies including `@mastra/core`, zod, and @ai-sdk/openai, and initialize the TypeScript compiler.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y \nnpm install typescript tsx @types/node mastra --save-dev \nnpm install @mastra/core zod @ai-sdk/openai\nnpx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Document Grouping for Title Extraction\nDESCRIPTION: This snippet shows how to group document chunks for title extraction by specifying a common `docId` in the metadata of each chunk. Chunks with the same `docId` will receive the same extracted title when using `TitleExtractor`. Requires @mastra/rag package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/extract-params.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = new MDocument({\n  docs: [\n    { text: \"chunk 1\", metadata: { docId: \"docA\" } },\n    { text: \"chunk 2\", metadata: { docId: \"docA\" } },\n    { text: \"chunk 3\", metadata: { docId: \"docB\" } },\n  ],\n  type: \"text\",\n});\n\nawait doc.extractMetadata({ title: true });\n// 最初の2つのチャンクは同じタイトルを共有し、3番目のチャンクには別のタイトルが割り当てられます。\n```\n\n----------------------------------------\n\nTITLE: Workflow Example with While Loop\nDESCRIPTION: A complete example demonstrating a Mastra workflow with a `.while()` loop.  It includes step definitions (increment and final), workflow setup, condition using trigger data and step context, and workflow execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/while.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core';\nimport { z } from 'zod';\n\n// Create a step that increments a counter\nconst incrementStep = new Step({\n  id: 'increment',\n  description: 'カウンターを1増やします',\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ context }) => {\n    // Get current value from previous execution or start at 0\n    const currentValue =\n      context.getStepResult<{ value: number }>('increment')?.value ||\n      context.getStepResult<{ startValue: number }>('trigger')?.startValue ||\n      0;\n\n    // Increment the value\n    const value = currentValue + 1;\n    console.log(`Incrementing to ${value}`);\n\n    return { value };\n  },\n});\n\n// Create a final step\nconst finalStep = new Step({\n  id: 'final',\n  description: 'ループ完了後の最終ステップ',\n  execute: async ({ context }) => {\n    const finalValue = context.getStepResult<{ value: number }>('increment')?.value;\n    console.log(`ループは最終値: ${finalValue} で完了しました`);\n    return { finalValue };\n  },\n});\n\n// Create the workflow\nconst counterWorkflow = new Workflow({\n  name: 'counter-workflow',\n  triggerSchema: z.object({\n    startValue: z.number(),\n    targetValue: z.number(),\n  }),\n});\n\n// Configure the workflow with a while loop\ncounterWorkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      const targetValue = context.triggerData.targetValue;\n      const currentValue = context.getStepResult<{ value: number }>('increment')?.value ?? 0;\n      return currentValue < targetValue;\n    },\n    incrementStep\n  )\n  .then(finalStep)\n  .commit();\n\n// Execute the workflow\nconst run = counterWorkflow.createRun();\nconst result = await run.start({ triggerData: { startValue: 0, targetValue: 5 } });\n// Will increment from 0 to 4, then stop and execute finalStep\n```\n\n----------------------------------------\n\nTITLE: Advanced Usage: UI Feedback with Lifecycle Hooks\nDESCRIPTION: This snippet demonstrates how to provide UI feedback while the working memory is being updated. It adds lifecycle hooks to `maskStreamTags` to show a loading spinner when the `<working_memory>` tag starts and hide it when it ends.  It also displays updated ToDo list data in the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory-advanced.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// 上記と同じインポートとセットアップ...\n\n// ライフサイクルフックを追加してUIフィードバックを提供する\nconst maskedStream = maskStreamTags(response.textStream, \"working_memory\", {\n  // working_memoryタグが開始されたときに呼び出される\n  onStart: () => showLoadingSpinner(\"ToDoリストを更新中...\"),\n  // working_memoryタグが終了したときに呼び出される\n  onEnd: () => hideLoadingSpinner(),\n  // マスクされたコンテンツと共に呼び出される\n  onMask: (chunk) => console.debug(\"更新されたToDoリスト:\", chunk),\n});\n\n// マスクされたストリームを処理する\nfor await (const chunk of maskedStream) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Uninstalling deprecated package and Installing new package (bash)\nDESCRIPTION: This snippet provides the command to uninstall the deprecated @mastra/speech-deepgram package and install the new @mastra/voice-deepgram package. Ensure you have npm installed and configured.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/deepgram/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm uninstall @mastra/speech-deepgram\nnpm install @mastra/voice-deepgram\n```\n\n----------------------------------------\n\nTITLE: CloudflareVoice Initialization - REST API\nDESCRIPTION: Initializes the CloudflareVoice class using the REST API. It requires the API key, account ID, and the listening model, which is set to '@cf/openai/whisper-large-v3-turbo'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// REST API\nconst voice = new CloudflareVoice({\n  listeningModel: {\n    apiKey: 'YOUR_API_KEY',\n    model: '@cf/openai/whisper-large-v3-turbo',\n    account_id: 'YOUR_ACC_ID',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Example Usage with Analysis in TypeScript\nDESCRIPTION: This example demonstrates the usage of the `PromptAlignmentMetric` class with a more detailed set of instructions and analyzes the output. It configures the model, sets instructions for bullet points, number of examples, and ending punctuation, and then measures the output against these instructions. The score and detailed reasons for alignment or misalignment are then printed. The required dependencies are `@ai-sdk/openai` and `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/prompt-alignment.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PromptAlignmentMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new PromptAlignmentMetric(model, {\n  instructions: [\n    \"Use bullet points for each item\",\n    \"Include exactly three examples\",\n    \"End each point with a semicolon\"\n  ],\n  scale: 1\n});\n\nconst result = await metric.measure(\n  \"List three fruits\",\n  \"• Apple is red and sweet;\\n• Banana is yellow and curved;\\n• Orange is citrus and round.\"\n);\n\n// Example output:\n// {\n//   score: 1.0,\n//   info: {\n//     reason: \"The score is 1.0 because all instructions were followed exactly:\\n//           bullet points were used, exactly three examples were provided, and\\n//           each point ends with a semicolon.\"\n//   }\n// }\n\nconst result2 = await metric.measure(\n  \"List three fruits\",\n  \"1. Apple\\n2. Banana\\n3. Orange and Grape\"\n);\n\n// Example output:\n// {\n//   score: 0.33,\n//   info: {\n//     reason: \"The score is 0.33 because: numbered lists were used instead of bullet points,\\n//           no semicolons were used, and four fruits were listed instead of exactly three.\"\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Running the Prompt Alignment example in Bash\nDESCRIPTION: Command to start the prompt alignment example which will run the three alignment test scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/prompt-alignment/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initializing Cloudflare Voice Configuration\nDESCRIPTION: Cloudflare音声プロバイダーの初期化設定を示します。音声合成のためのモデル名、アカウントID、APIトークン、言語、オーディオ形式を指定します。Cloudflareは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはCloudflareの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_24\n\nLANGUAGE: typescript\nCODE:\n```\n// Cloudflare Voice Configuration\nconst voice = new CloudflareVoice({\n  speechModel: {\n    name: \"cloudflare-voice\", // Example model name\n    accountId: process.env.CLOUDFLARE_ACCOUNT_ID,\n    apiToken: process.env.CLOUDFLARE_API_TOKEN,\n    language: \"en-US\", // Language code\n    format: \"mp3\", // Audio format\n  },\n  // Cloudflare may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Complete Example of Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: A complete example demonstrating nested workflows with schema definition, variable passing, and result mapping. This showcases how to combine different workflows while ensuring type safety and reusability.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflowA = new Workflow({\n  name: \"workflow-a\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst workflowB = new Workflow({\n  name: \"workflow-b\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst weatherWorkflow = new Workflow({\n  name: \"weather-workflow\",\n  triggerSchema: z.object({\n    cityA: z.string().describe(\"The city to get the weather for\"),\n    cityB: z.string().describe(\"The city to get the weather for\"),\n  }),\n  result: {\n    schema: z.object({\n      activitiesA: z.string(),\n      activitiesB: z.string(),\n    }),\n    mapping: {\n      activitiesA: {\n        step: workflowA,\n        path: \"result.activities\",\n      },\n      activitiesB: {\n        step: workflowB,\n        path: \"result.activities\",\n      },\n    },\n  },\n})\n  .step(workflowA, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityA\",\n      },\n    },\n  })\n  .step(workflowB, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityB\",\n      },\n    },\n  });\n\nweatherWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI API\nDESCRIPTION: Configuration of environment variables required for OpenAI API access.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Enabling Instrumentation Hook in Next.js Configuration\nDESCRIPTION: Configures Next.js to enable the instrumentation hook, which is required for OpenTelemetry tracing. This setting is included in the experimental features section of the Next.js configuration file and is not required for Next.js version 15 and above.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { NextConfig } from \"next\";\n\nconst nextConfig: NextConfig = {\n  experimental: {\n    instrumentationHook: true // Not required in Next.js 15+\n  }\n};\n\nexport default nextConfig;\n```\n\n----------------------------------------\n\nTITLE: Suspending and Resuming Nested Workflows in TypeScript\nDESCRIPTION: Shows implementation of suspension and resumption in nested workflows, including step-specific suspension and result handling.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/nested-workflows.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Define a step that may need to suspend\nconst suspendableStep = new Step({\n  id: \"other\",\n  description: \"Step that may need to suspend\",\n  execute: async ({ context, suspend }) => {\n    if (!wasSuspended) {\n      wasSuspended = true;\n      await suspend();\n    }\n    return { other: 26 };\n  },\n});\n\n// Create a nested workflow with suspendable steps\nconst nestedWorkflow = new Workflow({ name: \"nested-workflow-a\" })\n  .step(startStep)\n  .then(suspendableStep)\n  .then(finalStep)\n  .commit();\n\n// Use in parent workflow\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(beginStep)\n  .then(nestedWorkflow)\n  .then(lastStep)\n  .commit();\n\n// Start the workflow\nconst run = parentWorkflow.createRun();\nconst { runId, results } = await run.start({ triggerData: { startValue: 1 } });\n\n// Check if a specific step in the nested workflow is suspended\nif (results[\"nested-workflow-a\"].output.results.other.status === \"suspended\") {\n  // Resume the specific suspended step using dot notation\n  const resumedResults = await run.resume({\n    stepId: \"nested-workflow-a.other\",\n    context: { startValue: 1 },\n  });\n\n  // The resumed results will contain the completed nested workflow\n  expect(resumedResults.results[\"nested-workflow-a\"].output.results).toEqual({\n    start: { output: { newValue: 1 }, status: \"success\" },\n    other: { output: { other: 26 }, status: \"success\" },\n    final: { output: { finalValue: 27 }, status: \"success\" },\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Text Responses from Chef Agent in TypeScript\nDESCRIPTION: This snippet shows how to interact with the Chef Assistant agent to generate text responses based on available ingredients.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const query =\n    \"In my kitchen I have: pasta, canned tomatoes, garlic, olive oil, and some dried herbs (basil and oregano). What can I make?\";\n  console.log(`Query: ${query}`);\n\n  const response = await chefAgent.generate([{ role: \"user\", content: query }]);\n  console.log(\"\\n👨‍🍳 Chef Michel:\", response.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Example Usage of TextualDifferenceMetric - TypeScript\nDESCRIPTION: This code snippet provides an example of using the `TextualDifferenceMetric` class to compare two different strings and logs the resulting similarity score and difference metrics. It requires the same library as the previous snippet. The function follows the same pattern of initialization and invocation of the `measure` method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/textual-difference.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new TextualDifferenceMetric();\n\nconst result = await metric.measure(\n  \"Hello world! How are you?\",\n  \"Hello there! How is it going?\"\n);\n\n// Example output:\n// {\n//   score: 0.65,\n//   info: {\n//     confidence: 0.95,\n//     ratio: 0.65,\n//     changes: 2,\n//     lengthDiff: 0.05\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Initializing MastraClient\nDESCRIPTION: This code snippet demonstrates how to initialize the MastraClient with a base URL.  It imports the MastraClient class and creates an instance with the URL of the Mastra server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from \"@mastra/client-js\";\n\nconst client = new MastraClient({\n  baseUrl: \"http://localhost:4111\", // Mastra開発サーバーのデフォルトポート\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra project using npm create\nDESCRIPTION: This command uses npm to create a new Mastra project using the `create-mastra` package. It installs the latest version of the package and initiates the project creation process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/creating-a-new-project.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables (.env)\nDESCRIPTION: Creates a .env file to store the OpenAI API key, which is required for the stock agent to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Launching Mastra Development Server (CLI)\nDESCRIPTION: This command launches the Mastra development environment, which allows you to test your agents, workflows, and tools locally. By default, the server runs at http://localhost:4111.  The port can be changed with the `--port` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/mastra-dev.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Configuring environment variables in .env file\nDESCRIPTION: Template for setting up the required environment variables including OpenAI API key and PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=postgresql://your-username:your-password@your-host:your-port/your-database\n```\n\n----------------------------------------\n\nTITLE: API Rename: voices to getSpeakers\nDESCRIPTION: This snippet illustrates the renaming of the `voices()` method to `getSpeakers()` within the @mastra/voice-playai package.  This provides a more descriptive and intuitive name for retrieving available speaker options. The update mandates refactoring existing code to call `getSpeakers()` instead of `voices()`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/CHANGELOG.md#_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Minimal Coverage Keyword Evaluation Example\nDESCRIPTION: Illustrates evaluation of a response with minimal keyword coverage, showing how the metric handles cases with limited matching.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/keyword-coverage.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'Machine learning models require data preprocessing, feature engineering, and hyperparameter tuning';\nconst output3 = 'Data preparation is important for models';\n\nconsole.log('Example 3 - Minimal Coverage:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    totalKeywords: result3.info.totalKeywords,\n    matchedKeywords: result3.info.matchedKeywords,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.2, info: { totalKeywords: 10, matchedKeywords: 2 } }\n```\n\n----------------------------------------\n\nTITLE: TTS with OpenAI Voice Agent\nDESCRIPTION: This code shows how to use an Agent with OpenAI voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using OpenAI's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n  responseFormat: \"wav\", // Optional: specify a response format\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Weather Tool Definition\nDESCRIPTION: This TypeScript code defines a weather tool using the `@mastra/core/tools` library. It includes input and output schemas defined with Zod, and an `execute` function that fetches weather data based on a location.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_21\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\ninterface WeatherResponse {\n  current: {\n    time: string;\n    temperature_2m: number;\n    apparent_temperature: number;\n    relative_humidity_2m: number;\n    wind_speed_10m: number;\n    wind_gusts_10m: number;\n    weather_code: number;\n  };\n}\n\nexport const weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"Get current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"City name\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    feelsLike: z.number(),\n    humidity: z.number(),\n    windSpeed: z.number(),\n    windGust: z.number(),\n    conditions: z.string(),\n    location: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return await getWeather(context.location);\n  },\n});\n\nconst getWeather = async (location: string) => {\n  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;\n  const geocodingResponse = await fetch(geocodingUrl);\n  const geocodingData = await geocodingResponse.json();\n\n  if (!geocodingData.results?.[0]) {\n    throw new Error(`Location '${location}' not found`);\n  }\n\n  const { latitude, longitude, name } = geocodingData.results[0];\n\n  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;\n\n  const response = await fetch(weatherUrl);\n  const data: WeatherResponse = await response.json();\n\n  return {\n    temperature: data.current.temperature_2m,\n    feelsLike: data.current.apparent_temperature,\n    humidity: data.current.relative_humidity_2m,\n    windSpeed: data.current.wind_speed_10m,\n    windGust: data.current.wind_gusts_10m,\n    conditions: getWeatherCondition(data.current.weather_code),\n    location: name,\n  };\n};\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"Clear sky\",\n    1: \"Mainly clear\",\n    2: \"Partly cloudy\",\n    3: \"Overcast\",\n    45: \"Foggy\",\n    48: \"Depositing rime fog\",\n    51: \"Light drizzle\",\n    53: \"Moderate drizzle\",\n    55: \"Dense drizzle\",\n    56: \"Light freezing drizzle\",\n    57: \"Dense freezing drizzle\",\n    61: \"Slight rain\",\n    63: \"Moderate rain\",\n    65: \"Heavy rain\",\n    66: \"Light freezing rain\",\n    67: \"Heavy freezing rain\",\n    71: \"Slight snow fall\",\n    73: \"Moderate snow fall\",\n    75: \"Heavy snow fall\",\n    77: \"Snow grains\",\n    80: \"Slight rain showers\",\n    81: \"Moderate rain showers\",\n    82: \"Violent rain showers\",\n    85: \"Slight snow showers\",\n    86: \"Heavy snow showers\",\n    95: \"Thunderstorm\",\n    96: \"Thunderstorm with slight hail\",\n    99: \"Thunderstorm with heavy hail\",\n  };\n  return conditions[code] || \"Unknown\";\n}\n```\n\n----------------------------------------\n\nTITLE: Next.js Dynamic Import Configuration for Blog Page Components\nDESCRIPTION: This snippet shows the configuration of dynamic imports for various UI components used in a blog page. It maps component identifiers to their corresponding JavaScript chunks that need to be loaded.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\nb:I[9424,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"Avatar\"]\nc:I[9424,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"AvatarImage\"]\nd:I[9424,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"AvatarFallback\"]\ne:I[6421,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"ShareLinkButton\"]\nf:I[2265,[\"333\",\"static/chunks/333-64fe985764faf0d9.js\",\"102\",\"static/chunks/102-af6671174d169050.js\",\"261\",\"static/chunks/261-f7fbef7aebe4511f.js\",\"959\",\"static/chunks/959-7fc5f74737c024dc.js\",\"441\",\"static/chunks/441-018323f6d5d84e46.js\",\"44\",\"static/chunks/44-4f0b3399b1a812a7.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-645ec13ced155212.js\"],\"SubscribeForm\"]\n```\n\n----------------------------------------\n\nTITLE: Adding STT for ElevenlabsVoice\nDESCRIPTION: This patch adds Speech-to-Text (STT) functionality for ElevenlabsVoice. This enables the package to transcribe audio generated by Elevenlabs voices.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/CHANGELOG.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n- 705d69b: Add STT for ElevenlabsVoice\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository for RAG Example\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the basic RAG example directory. This is the first step to access the example code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/basic-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/basic-rag\n```\n\n----------------------------------------\n\nTITLE: Configuring Sarvam Voice with Environment Variables\nDESCRIPTION: This snippet illustrates the configuration of required environment variables for the Sarvam Voice integration, specifically setting the SARVAM_API_KEY necessary for API authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSARVAM_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing Upstash Transport\nDESCRIPTION: Configuration example for UpstashTransport that sends logs to Upstash Redis with various optional parameters for batching and trimming.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/loggers/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashTransport } from '@mastra/loggers';\n\nconst upstashLogger = new UpstashTransport({\n  upstashUrl: 'https://your-instance.upstash.io',\n  upstashToken: 'your-token',\n  listName: 'application-logs', // optional\n  maxListLength: 10000, // optional\n  batchSize: 100, // optional\n  flushInterval: 10000, // optional\n});\n```\n\n----------------------------------------\n\nTITLE: Saving Audio Output in Mastra\nDESCRIPTION: This snippet demonstrates how to save the audio output generated by the `speak` method of a Mastra agent's voice interface to a file. It uses Node.js streams (`createWriteStream`) to pipe the audio data to a file. It handles stream completion and errors using promises. Dependencies include `fs` and `path`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-voice.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createWriteStream } from \"fs\";\nimport path from \"path\";\n\n// Generate speech and save to file\nconst audio = await agent.voice.speak(\"Hello, World!\");\nconst filePath = path.join(process.cwd(), \"agent.mp3\");\nconst writer = createWriteStream(filePath);\n\naudio.pipe(writer);\n\nawait new Promise<void>((resolve, reject) => {\n  writer.on(\"finish\", () => resolve());\n  writer.on(\"error\", reject);\n});\n```\n\n----------------------------------------\n\nTITLE: Speak Method with CompositeVoice\nDESCRIPTION: Illustrates how the `speak()` method works with `CompositeVoice`, where the call is delegated to the configured `speakProvider`. It uses `PlayAIVoice` for speaking in this example. Requires `@mastra/core/voice`, `@mastra/voice-openai`, and `@mastra/voice-playai`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.speak.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nconst voice = new CompositeVoice({\n  speakProvider: new PlayAIVoice(),\n  listenProvider: new OpenAIVoice(),\n});\n// これはPlayAIVoiceプロバイダーを使用します\nconst audioStream = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Content Similarity Metric Basic Usage\nDESCRIPTION: This snippet demonstrates the basic usage of the ContentSimilarityMetric to measure the similarity between two strings. It imports the necessary class, creates an instance with default options (ignore case and whitespace), and calls the measure method to get the similarity score and detailed metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/content-similarity.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ContentSimilarityMetric({\n  ignoreCase: true,\n  ignoreWhitespace: true\n});\n\nconst result = await metric.measure(\n  \"Hello, world!\",\n  \"hello world\"\n);\n\nconsole.log(result.score); // Similarity score from 0-1\nconsole.log(result.info); // Detailed similarity metrics\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Composio.dev SSE URLs in TypeScript\nDESCRIPTION: This TypeScript code demonstrates configuring the MCP using SSE URLs from Composio.dev for services like Google Sheets and Gmail. Each URL represents a single account's authentication context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    googleSheets: {\n      url: new URL(\"https://mcp.composio.dev/googlesheets/[private-url-path]\"),\n    },\n    gmail: {\n      url: new URL(\"https://mcp.composio.dev/gmail/[private-url-path]\"),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running the RAG Example with PNPM\nDESCRIPTION: Command to start the RAG example application after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Running the Hybrid Vector Search Example\nDESCRIPTION: Command to start and run the hybrid vector search example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/hybrid-vector-search/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Building Flat Index\nDESCRIPTION: This code shows how to build a flat index.  It invokes the `buildIndex` method with the index name, cosine distance metric, and a configuration object specifying the flat index type.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Define flat index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"flat\",\n});\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retry Configuration in Typescript\nDESCRIPTION: This code snippet demonstrates how to configure retry attempts and delay at the workflow level in Mastra using Typescript. It sets the default retry configuration for all steps within the workflow.  It requires the `Workflow` class from the Mastra library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/error-handling.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// ワークフローレベルのリトライ設定\nconst workflow = new Workflow({\n  name: 'my-workflow',\n  retryConfig: {\n    attempts: 3,    // リトライ試行回数\n    delay: 1000,    // リトライ間の遅延時間（ミリ秒）\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing and Starting a Workflow Run - Typescript\nDESCRIPTION: This snippet demonstrates how to initialize a workflow run using `.createRun()` and then start the workflow execution using the returned `start()` function.  The `runId` is available for tracking purposes. The `watch` function is also available, which allows subscribing to workflow transitions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/createRun.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start, watch } = workflow.createRun();\n\nconst result = await start();\n```\n\n----------------------------------------\n\nTITLE: Error Handling During Workflow Execution in TypeScript\nDESCRIPTION: This snippet shows an error handling pattern when executing a workflow. It captures exceptions thrown during the workflow execution, checking for validation-related errors to handle them appropriately.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const { runId, start, watch, resume } = workflow.createRun();\n  await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    // Handle validation errors\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details); // { stepId?: string, path?: string[] }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Vercel OpenTelemetry Setup\nDESCRIPTION: Command to install the required npm packages for setting up OpenTelemetry with Vercel's built-in tooling. This approach is simpler but specific to applications deployed on Vercel.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/api @vercel/otel\n```\n\n----------------------------------------\n\nTITLE: Extracting Metadata from Document Chunks in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the Mastra framework's MDocument class to extract metadata from document chunks, including titles, summaries, and keywords using default extraction settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/extract-params.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(text);\nconst chunks = await doc.chunk({\n  extract: {\n    title: true,    // Extract titles using default settings\n    summary: true,  // Generate summaries using default settings\n    keywords: true  // Extract keywords using default settings\n  }\n});\n\n// Example output:\n// chunks[0].metadata = {\n//   documentTitle: \"AI Systems Overview\",\n//   sectionSummary: \"Overview of artificial intelligence concepts and applications\",\n//   excerptKeywords: \"KEYWORDS: AI, machine learning, algorithms\"\n// }\n```\n\n----------------------------------------\n\nTITLE: Markdown Chunking with Strategy Specific Options in Typescript\nDESCRIPTION: This code illustrates the usage of `.chunk()` function with Markdown-specific settings. It shows how to specify headers for chunking Markdown documents, strip headers from the output, and control the overlap between chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Markdown戦略の例\nconst chunks = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']], // Markdown固有のオプション\n  stripHeaders: true, // Markdown固有のオプション\n  overlap: 50 // 一般的なオプション\n});\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Example of how to add your OpenAI API key to the .env file, which is required for the evaluation to work.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-position/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Evaluating non-applicable instructions with PromptAlignmentMetric (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to evaluate a response where the instructions are not applicable to the query using the `PromptAlignmentMetric`. It defines an array of instructions that are related to banking, creates a `PromptAlignmentMetric` instance, sets a weather-related query, and a corresponding response. It then measures the alignment and logs the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/prompt-alignment.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions3 = [\n  '口座残高を表示する',\n  '最近の取引を一覧表示する',\n  '支払い履歴を表示する'\n];\n\nconst metric3 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions3,\n});\n\nconst query3 = '天気はどうですか？';\nconst response3 = '外は晴れて暖かいです。';\n\nconsole.log('例 3 - 非適用指示:');\nconsole.log('指示:', instructions3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n  details: result3.info.scoreDetails,\n});\n// 例の出力:\n// メトリック結果: { score: 0, reason: '指示はクエリに対して従われていないか、適用されていません。' }\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Netlify Deployer with pnpm\nDESCRIPTION: Command to install the @mastra/deployer-netlify package using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/netlify/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/deployer-netlify\n```\n\n----------------------------------------\n\nTITLE: Configuring Vercel Deployer with Mastra Framework\nDESCRIPTION: Example showing how to integrate the VercelDeployer with the Mastra framework. This initializes a deployer with team slug, project name, and authentication token, then uses it in the Mastra configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/vercel/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { VercelDeployer } from '@mastra/deployer-vercel';\n\nconst deployer = new VercelDeployer({\n  teamSlug: 'your-team-slug',\n  projectName: 'your-project-name',\n  token: 'your-vercel-token',\n});\n\nconst mastra = new Mastra({\n  deployer,\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Evaluation Metrics\nDESCRIPTION: Configures evaluation metrics for an AI agent to measure performance in content writing and summarization tasks\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { SummarizationMetric } from '@mastra/evals/llm';\nimport { ContentSimilarityMetric, ToneConsistencyMetric } from '@mastra/evals/nlp';\n\nconst model = openai('gpt-4o');\n\nconst agent = new Agent({\n  name: 'ContentWriter',\n  instructions: 'You are a content writer that creates accurate summaries',\n  model,\n  evals: {\n    summarization: new SummarizationMetric(model),\n    contentSimilarity: new ContentSimilarityMetric(),\n    tone: new ToneConsistencyMetric(),\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Traceloop Telemetry Configuration\nDESCRIPTION: This TypeScript snippet demonstrates how to create a new instance of Mastra with telemetry settings enabled for Traceloop. The service name should be customized as per your application requirements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/traceloop.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Measure Low Text Similarity\nDESCRIPTION: This snippet demonstrates how to measure the similarity between two clearly different text strings using the `ContentSimilarityMetric`. It logs the input texts and the resulting similarity score and info.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/content-similarity.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst text3 = 'The cat sleeps on the windowsill.';\nconst reference3 = 'The quick brown fox jumps over the lazy dog.';\n\nconsole.log('Example 3 - Low Similarity:');\nconsole.log('Text:', text3);\nconsole.log('Reference:', reference3);\n\nconst result3 = await metric.measure(reference3, text3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    similarity: result3.info.similarity,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Package Manager\nDESCRIPTION: Command to install the required Node.js dependencies for the example using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-delimiters/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: MCPServer getSseTransport() method definition\nDESCRIPTION: Defines the signature of the getSseTransport() method for the MCPServer class. This method returns the SSEServerTransport object or undefined if the server was not started with startSSE().\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ngetSseTransport(): SSEServerTransport | undefined\n```\n\n----------------------------------------\n\nTITLE: Deleting Index by ID in AstraVector\nDESCRIPTION: Deletes a specific vector identified by its ID in the AstraVector class within a given index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index containing the vector\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the vector to delete\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Running the RAG Example\nDESCRIPTION: Command to execute the RAG example after setup is complete. This will run the demonstration application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/basic-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Configuring CORS Settings in Mastra - TypeScript\nDESCRIPTION: This code snippet demonstrates how to configure Cross-Origin Resource Sharing (CORS) settings for a Mastra server. It shows how to specify allowed origins, methods, and headers.  The CORS configuration allows fine-grained control over which origins can access the server's resources, enhancing security. Replace `https://example.com` with your desired origin or use `'*'` to allow any origin.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\n\nexport const mastra = new Mastra({\n  server: {\n    cors: {\n      origin: ['https://example.com'], // 特定のオリジンを許可するか、すべての場合は '*'\n      allowMethods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],\n      allowHeaders: ['Content-Type', 'Authorization'],\n      credentials: false,\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Describing an Index in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the describeIndex() method for obtaining details about a specific index in the Turbopuffer vector store, requiring the index name as a parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to describe\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in ChromaVector\nDESCRIPTION: Demonstrates error handling when performing a query, specifically checking for typed errors and retrieving detailed error context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript copy\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n```\n\n----------------------------------------\n\nTITLE: CORS Middleware Example\nDESCRIPTION: Example of CORS middleware implementation with header configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    // Add CORS headers\n    c.header(\"Access-Control-Allow-Origin\", \"*\");\n    c.header(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\");\n    c.header(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\");\n\n    // Handle preflight requests\n    if (c.req.method === \"OPTIONS\") {\n      return new Response(null, { status: 204 });\n    }\n\n    await next();\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Setting environment variables\nDESCRIPTION: This bash snippet shows how to set the OpenAI API key as an environment variable, which is required for the Answer Relevancy metric to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Committing a Workflow Configuration - Typescript\nDESCRIPTION: This code snippet demonstrates how to use the `.commit()` method to re-initialize the workflow's state machine with the current step configuration after defining steps and their order. The workflow instance is assumed to be pre-existing. The return is the workflow instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/commit.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepA)\n  .then(stepB)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Setting Dash0 Environment Variables\nDESCRIPTION: This snippet demonstrates the environment variables required to configure Mastra to export telemetry data to Dash0. It includes the OTLP endpoint and authorization headers. Replace `<region>` with the appropriate region and `<your-auth-token>` with a valid authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/dash0.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://ingress.<region>.dash0.com\nOTEL_EXPORTER_OTLP_HEADERS=Authorization=Bearer <your-auth-token>, Dash0-Dataset=<optional-dataset>\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and Postgres\nDESCRIPTION: Sets up environment variables for OpenAI API key and Postgres connection string in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: MastraVoice getSpeakers() Abstract Method\nDESCRIPTION: The definition of the required getSpeakers() abstract method that returns a list of available voices supported by the provider. Each voice must have at least a voiceId property, and providers can include additional metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nabstract getSpeakers(): Promise<Array<{ voiceId: string; [key: string]: unknown }>>\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenAPI Documentation in Mastra (TypeScript)\nDESCRIPTION: This TypeScript code snippet demonstrates how to enable OpenAPI documentation in your Mastra instance. It involves setting the `openAPIDocs` property to `true` within the `build` configuration of the `server` option when creating a new `Mastra` instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/mastra-dev.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  server: {\n    build: {\n      openAPIDocs: true,  // Enable OpenAPI documentation\n      // ... other build config options\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Laminar Integration\nDESCRIPTION: These environment variables are required to configure Mastra to send telemetry data to Laminar. `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the Laminar API endpoint, and `OTEL_EXPORTER_OTLP_HEADERS` provides the necessary authorization and team ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/laminar.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.lmnr.ai:8443\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer your_api_key, x-laminar-team-id=your_team_id\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Logs for a Specific Run - TypeScript\nDESCRIPTION: This snippet shows how to retrieve logs for a specific run using the `getLogForRun` method of the Mastra client.  It requires `runId` and `transportId` as parameters to identify the specific run. The code assumes `client` is an initialized Mastra API client.  The result is a list of logs associated with the specified run.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/logs.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst runLogs = await client.getLogForRun({\n  runId: \"run-1\",\n  transportId: \"transport-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking with Metadata Extraction Typescript\nDESCRIPTION: Chunks the document using the recursive strategy and extracts metadata for each chunk. The chunk size is set to 200, and the extract option is configured to extract keywords and generate summaries for each chunk. The extracted metadata from the chunks is then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/metadata-extraction.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// メタデータ抽出を伴うチャンク化を設定\nawait doc.chunk({\n  strategy: 'recursive',  // 再帰的チャンク化戦略を使用\n  size: 200,             // 最大チャンクサイズ\n  extract: {\n    keywords: true,      // チャンクごとにキーワードを抽出\n    summary: true,       // チャンクごとに要約を生成\n  },\n});\n\n// チャンクからメタデータを取得\nconst metaTwo = doc.getMetadata();\nconsole.log('チャンクメタデータ:', metaTwo);\n\n// 出力例:\n// チャンクメタデータ: {\n//   keywords: [\n//     '運動',\n//     '健康の利点',\n//     '心血管の健康',\n//     '精神的健康',\n//     'ストレス軽減',\n//     '睡眠の質'\n//   ],\n//   summary: '定期的な運動は、心血管の健康、筋力、精神的健康を含む複数の健康上の利点を提供します。主な利点には、ストレス軽減、睡眠の改善、体重管理、エネルギーの増加が含まれます。推奨される運動時間は週に150分です。'\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating Stock Price Tool with createTool() in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a tool using the `createTool()` function from the `@mastra/core/tools` library. The tool fetches stock prices based on the provided symbol using an external API and validates the input and output using Zod schemas. It showcases how to define the tool's ID, description, input/output schemas, and the execution logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/createTool.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\n// Helper function to fetch stock data\nconst getStockPrice = async (symbol: string) => {\n  const response = await fetch(\n    `https://mastra-stock-data.vercel.app/api/stock-data?symbol=${symbol}`\n  );\n  const data = await response.json();\n  return data.prices[\"4. close\"];\n};\n\n// Create a tool to get stock prices\nexport const stockPriceTool = createTool({\n  id: \"getStockPrice\",\n  description: \"指定されたティッカーシンボルの現在の株価を取得します\",\n  inputSchema: z.object({\n    symbol: z.string().describe(\"株式ティッカーシンボル（例: AAPL, MSFT）\")\n  }),\n  outputSchema: z.object({\n    symbol: z.string(),\n    price: z.number(),\n    currency: z.string(),\n    timestamp: z.string()\n  }),\n  execute: async ({ context }) => {\n    const price = await getStockPrice(context.symbol);\n    \n    return {\n      symbol: context.symbol,\n      price: parseFloat(price),\n      currency: \"USD\",\n      timestamp: new Date().toISOString()\n    };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Suspending and Resuming Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Illustrates how to suspend and resume nested workflows, either the entire nested workflow or a specific step within it.  `resume()` takes a `stepId` which can be the name of the nested workflow (to resume the entire workflow) or dot notation (`nested-workflow.step-name`) to resume a specific step.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Define a step that may need to suspend\nconst suspendableStep = new Step({\n  id: \"other\",\n  description: \"Step that may need to suspend\",\n  execute: async ({ context, suspend }) => {\n    if (!wasSuspended) {\n      wasSuspended = true;\n      await suspend();\n    }\n    return { other: 26 };\n  },\n});\n\n// Create a nested workflow with suspendable steps\nconst nestedWorkflow = new Workflow({ name: \"nested-workflow-a\" })\n  .step(startStep)\n  .then(suspendableStep)\n  .then(finalStep)\n  .commit();\n\n// Use in parent workflow\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step(beginStep)\n  .then(nestedWorkflow)\n  .then(lastStep)\n  .commit();\n\n// Start the workflow\nconst run = parentWorkflow.createRun();\nconst { runId, results } = await run.start({ triggerData: { startValue: 1 } });\n\n// Check if a specific step in the nested workflow is suspended\nif (results[\"nested-workflow-a\"].output.results.other.status === \"suspended\") {\n  // Resume the specific suspended step using dot notation\n  const resumedResults = await run.resume({\n    stepId: \"nested-workflow-a.other\",\n    context: { startValue: 1 },\n  });\n\n  // The resumed results will contain the completed nested workflow\n  expect(resumedResults.results[\"nested-workflow-a\"].output.results).toEqual({\n    start: { output: { newValue: 1 }, status: \"success\" },\n    other: { output: { other: 26 }, status: \"success\" },\n    final: { output: { finalValue: 27 }, status: \"success\" },\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm package manager before running the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository for Bird Checker Setup\nDESCRIPTION: Commands to clone the repository and navigate to the project directory\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone <repository-url>\ncd bird-checker-with-nextjs\n```\n\n----------------------------------------\n\nTITLE: Get Processed Docs (Instance Method)\nDESCRIPTION: Returns an array of processed document chunks (Chunk[]). This array contains the result of previous processing steps, such as chunking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ngetDocs(): Chunk[]\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File in Bash\nDESCRIPTION: Command to create a copy of the example environment variables file which will be used to store the OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Customizing ToxicityMetric with different scale\nDESCRIPTION: This code demonstrates how to customize the ToxicityMetric by setting a different scale for the toxicity score.  The scale parameter is set to 10, so that the toxicity score ranges from 0 to 10 instead of the default 0 to 1.  The example evaluates a prompt and response in Japanese.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/toxicity.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ToxicityMetric(model, {\n  scale: 10, // 0-1の代わりに0-10のスケールを使用\n});\n\nconst result = await metric.measure(\n  \"新しいチームメンバーについてどう思いますか？\",\n  \"新しいチームメンバーは有望ですが、基本的なスキルの大幅な改善が必要です。\",\n);\n```\n\n----------------------------------------\n\nTITLE: Speech Recognition in ElevenLabsVoice\nDESCRIPTION: This snippet indicates that the listen method is not supported in the ElevenLabsVoice class, as ElevenLabs does not provide speech recognition capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nNot supported - ElevenLabs does not provide speech recognition.\n```\n\n----------------------------------------\n\nTITLE: Error Handling with Workflow.if()\nDESCRIPTION: This code shows an example of error handling when using `.if()` without a preceding step.  The workflow attempts to use `.if()` without defining a previous step. This results in an error, which is caught and logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/if.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  // これはエラーをスローします\n  workflow\n    .if(async ({ context }) => true)\n    .then(someStep)\n    .commit();\n} catch (error) {\n  console.error(error); // \"条件には実行されるステップが必要です\"\n}\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template\nDESCRIPTION: Command to create a local environment file from the example template for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a local environment variables file from the example template\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env.local\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies with pnpm\nDESCRIPTION: Command to install the required package dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Evaluate Consistent Positive Tone in TypeScript\nDESCRIPTION: This code snippet demonstrates how to evaluate texts with consistent positive tones using the ToneConsistencyMetric. It compares the sentiment between two texts, 'input1' and 'output1', and logs the metric result, including a score and detailed information about the sentiments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/tone-consistency.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'This product is fantastic and amazing!';\nconst output1 = 'The product is excellent and wonderful!';\n\nconsole.log('Example 1 - Consistent Positive Tone:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: result1.info,\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Storage and Vector DBs\nDESCRIPTION: This code illustrates how to configure the storage and vector databases used by semantic recall.  It shows how to explicitly set up LibSQLStore and LibSQLVector, which are the default storage databases. The storage DB is responsible for storing messages and their embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/semantic-recall.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    // これは省略した場合のデフォルトストレージDBです\n    storage: new LibSQLStore({\n      config: {\n        url: \"file:local.db\",\n      },\n    }),\n    // これは省略した場合のデフォルトベクトルDBです\n    vector: new LibSQLVector({\n      connectionUrl: \"file:local.db\",\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Content Improvement Step with Suspension in TypeScript\nDESCRIPTION: This code defines a step to improve the generated content, potentially suspending the workflow for human intervention if the content quality is below a threshold.  It retrieves the content and scores from previous steps and checks if they meet the required quality. If not, and no improved content is provided, it suspends with a payload containing the content, scores, and resume attempts.  Upon resumption, it returns the improved content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 4: Improve response if needed (may suspend)\nconst improveResponse = new Step({\n  id: 'improveResponse',\n  inputSchema: z.object({\n    improvedContent: z.string(),\n    resumeAttempts: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const content = context.getStepResult(promptAgent)?.modelOutput;\n    const toneScore =\n      context.getStepResult(evaluateTone)?.toneScore.score ?? 0;\n    const completenessScore =\n      context.getStepResult(evaluateTone)?.completenessScore.score ?? 0;\n\n    const improvedContent = context.inputData.improvedContent;\n    const resumeAttempts = context.inputData.resumeAttempts ?? 0;\n\n    // If scores are above threshold, make minor improvements\n    if (toneScore > 0.8 && completenessScore > 0.8) {\n      return { improvedOutput: makeMinorImprovements(content) };\n    }\n\n    console.log('Content quality below threshold, suspending for human intervention', {improvedContent, resumeAttempts});\n\n    if (!improvedContent) {\n      // Suspend with payload containing content and resume attempts\n      await suspend({\n        content,\n        scores: { tone: toneScore, completeness: completenessScore },\n        needsImprovement: toneScore < 0.8 ? 'tone' : 'completeness',\n        resumeAttempts: resumeAttempts + 1,\n      });\n      return { improvedOutput: content ?? '' };\n    }\n\n    console.log('Resumed with human improvements', improvedContent);\n    return { improvedOutput: improvedContent ?? content ?? '' };\n  },\n  outputSchema: z.object({ improvedOutput: z.string() }).optional(),\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Index by ID in ChromaVector\nDESCRIPTION: Updates an existing vector based on its ID in a specified index, allowing modification of both vector and associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index containing the vector to update\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the vector to update\",\n    },\n    {\n      name: \"update\",\n      type: \"object\",\n      description: \"Update parameters\",\n    },\n  ]}/>\n\nThe `update` object can contain:\n\n<PropertiesTable\n  content={[\n    {\n      name: \"vector\",\n      type: \"number[]\",\n      isOptional: true,\n      description: \"New vector to replace the existing one\",\n    },\n    {\n      name: \"metadata\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"New metadata to replace the existing metadata\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the necessary dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Memory Query Resource ID Validation\nDESCRIPTION: This code snippet demonstrates how to ensure that the accessed thread in memory.query() is for the correct resource id.  It provides a way to validate resource ownership of a thread.  If the resourceId provided doesn't own the thread, the query will throw an error.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nmemory.query({ threadId, resourceId })\n```\n\n----------------------------------------\n\nTITLE: Get Specific Agent with TypeScript\nDESCRIPTION: Retrieves a specific agent instance from the Mastra AI platform.  This function uses the client object to call the `getAgent` method, which takes an agent ID as input and returns an agent object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = client.getAgent(\"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Creating Document from Markdown - TypeScript\nDESCRIPTION: The static method `fromMarkdown` is used to create an MDocument from Markdown formatted text, with optional metadata. Utilizing TypeScript, this method allows the processing of markdown documents by accepting `markdown` and `metadata` parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromMarkdown(markdown: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Copying the environment variables file\nDESCRIPTION: Command to create a copy of the example environment file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/summarization/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Query Result Response Type - TypeScript\nDESCRIPTION: Defines the interface for the query result. It includes the id, score, metadata, and optionally the vector of the matched item.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/upstash.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: On Method Definition\nDESCRIPTION: This code snippet defines the `on` method in `MastraVoice`, which registers an event listener for voice events. A callback function is registered to be invoked when the specified event occurs. Standard events include 'speaking', 'writing', and 'error', and providers can emit custom events as well.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\non<E extends VoiceEventType>(\n  event: E,\n  callback: (data: E extends keyof VoiceEventMap ? VoiceEventMap[E] : unknown) => void,\n): void\n```\n\n----------------------------------------\n\nTITLE: Configuring API Keys in Environment File\nDESCRIPTION: Example of how to configure the Anthropic and OpenAI API keys in the environment file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nANTHROPIC_API_KEY=sk-your-api-key-here\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Initializing Editor Agent Configuration\nDESCRIPTION: Sets up the editor agent with a name, instructions, and specifies the GPT-4 mini model for content editing tasks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring CloudflareStore with keyPrefix (TypeScript)\nDESCRIPTION: Demonstrates configuring the CloudflareStore with a `keyPrefix` for Workers Binding API or a `namespacePrefix` for REST API. These prefixes are useful for isolating environments such as dev, test, or prod.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nconst store = new CloudflareStore({\n  bindings: { ... }, // for Workers\n  keyPrefix: 'dev_',\n});\n// or\nconst store = new CloudflareStore({\n  accountId: '...',\n  apiToken: '...',\n  namespacePrefix: 'prod_',\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Monitoring Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Demonstrates how to use the `watch` method to monitor state changes within nested workflows.  The `watch` method allows you to observe the progression and state transitions of complex workflows, including nested ones.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow = new Workflow({ name: \"parent-workflow\" })\n  .step([nestedWorkflowA, nestedWorkflowB])\n  .then(finalStep)\n  .commit();\n\nconst run = parentWorkflow.createRun();\nconst unwatch = parentWorkflow.watch((state) => {\n  console.log(\"Current state:\", state.value);\n  // Access nested workflow states in state.context\n});\n\nawait run.start();\nunwatch(); // Stop watching when done\n```\n\n----------------------------------------\n\nTITLE: AddTools Method Definition\nDESCRIPTION: This code snippet defines the optional `addTools` method in `MastraVoice`, which equips the voice provider with tools that can be used during conversation. These tools can extend the capabilities of the voice provider and the implementation is provider-specific.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\naddTools(tools: Array<Tool>): void\n```\n\n----------------------------------------\n\nTITLE: Package.json for Mastra Server\nDESCRIPTION: This JSON configuration demonstrates how to manage dependencies in the .mastra/package.json file for the server, defining crucial dependencies and module type for the project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/server/README.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"server\",\n  \"version\": \"1.0.0\",\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@mastra/loggers\": \"latest\",\n    \"hono\": \"4.6.17\",\n    \"@hono/node-server\": \"^1.13.7\",\n    \"superjson\": \"^2.2.2\",\n    \"zod-to-json-schema\": \"^3.24.1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Precision Context Usage\nDESCRIPTION: This example demonstrates how to evaluate a response where most context is irrelevant. It uses Nile River-related context and measures the precision of a response about the river's flow direction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-precision.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'The Nile River is in Africa.',\n  'The Nile is the longest river.',\n  'Ancient Egyptians used the Nile.',\n  'The Nile flows north.',\n];\n\nconst metric3 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'Which direction does the Nile River flow?';\nconst response3 = 'The Nile River flows northward.';\n\nconsole.log('Example 3 - Low Precision:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.2, reason: 'The context only has one relevant piece, which is at the end.' }\n```\n\n----------------------------------------\n\nTITLE: Register Chef Agent in Mastra\nDESCRIPTION: This code registers the previously defined `chefAgent` with the Mastra instance. By importing the agent and including it in the `agents` configuration, Mastra recognizes and manages the agent for deployment and interaction. The code utilizes the `@mastra/core` library for creating the Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nimport { chefAgent } from \"./agents/chefAgent\";\n\nexport const mastra = new Mastra({\n  agents: { chefAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Running the LibSQL Embedding Example\nDESCRIPTION: Command to execute the example script that demonstrates the embedding storage process in LibSQL.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Define Connection Step Typescript\nDESCRIPTION: Defines a workflow step `connectPieces` using the `Step` class. This step connects the different pieces of information based on the thought breakdown. It retrieves the breakdown from the `breakdownThoughts` step and uses the RAG agent to explain how the different parts are connected. The connections are then returned as the step's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst connectPieces = new Step({\n  id: \"connectPieces\",\n  outputSchema: z.object({\n    connections: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const process = context?.getStepResult<{\n      breakdown: string;\n    }>(\"breakdownThoughts\")?.breakdown;\n    const connectionPrompt = `\n        分解に基づいて: ${process}\n\n        3. 取得したチャンクから異なる部分をどのように接続しているかを説明します。\n    `;\n\n    const connections = await ragAgent?.generate(connectionPrompt);\n    console.log(connections?.text);\n    return {\n      connections: connections?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Starting the RAG Application\nDESCRIPTION: Command to run the RAG example application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and PostgreSQL\nDESCRIPTION: Sets up environment variables for OpenAI API key and PostgreSQL connection string in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Abstract Listen Method Definition\nDESCRIPTION: This code snippet defines the abstract `listen` method that must be implemented by any class extending `MastraVoice`. This method processes audio streams, transcribing them into text using the provider's speech recognition service. It supports provider-specific options for transcription settings and can return a full text transcription or a stream of transcribed text. Not all providers support this feature.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nabstract listen(\n  audioStream: NodeJS.ReadableStream,\n  options?: {\n    [key: string]: unknown;\n  }\n): Promise<string | NodeJS.ReadableStream | void>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Sets up environment variables for API access and database connection in .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nPOSTGRES_CONNECTION_STRING=your_connection_string\n```\n\n----------------------------------------\n\nTITLE: Importing Mastra Dependencies\nDESCRIPTION: Import statements for required Mastra and OpenAI SDK dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { SummarizationMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Deployment Options Comparison Table in Markdown\nDESCRIPTION: A markdown table comparing different Mastra deployment options, their ideal use cases, and key benefits. Includes details for Mastra Cloud, Server Deployment, and Serverless Platforms.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/overview.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Option | Best For | Key Benefits |\n| --- | --- | --- |\n| **Mastra Cloud** | Teams wanting to ship quickly without infrastructure concerns | Fully-managed, automatic scaling, built-in observability |\n| **Server Deployment** | Teams needing maximum control and customization | Full control, custom middleware, integrate with existing apps |\n| **Serverless Platforms** | Teams already using Vercel, Netlify, or Cloudflare | Platform integration, simplified deployment, automatic scaling |\n```\n\n----------------------------------------\n\nTITLE: Using Server Actions in React components\nDESCRIPTION: This code demonstrates how to use a server action (getWeatherInfo) in a Next.js React component. It defines an asynchronous handleSubmit function that retrieves a city name from a form, calls the getWeatherInfo server action, and logs the result. This component provides a simple form to get weather information based on user input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\n'use client'\n\nimport { getWeatherInfo } from '../actions'\n\nexport function Weather() {\n  async function handleSubmit(formData: FormData) {\n    const city = formData.get('city') as string\n    const result = await getWeatherInfo(city)\n    // 結果の処理\n    console.log(result)\n  }\n\n  return (\n    <form action={handleSubmit}>\n      <input name=\"city\" placeholder=\"Enter city name\" />\n      <button type=\"submit\">Get Weather</button>\n    </form>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Content Analysis Step with TypeScript and Mastra\nDESCRIPTION: This snippet initializes a step for analyzing content using the Mastra framework. It defines the output schema for the results and includes an execution function that simulates AI content analysis, returning the content along with an analysis score and flagged categories. The Zod library is used for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\nimport { select, input } from '@inquirer/prompts';\n\n// Step 1: Receive and analyze content\nconst analyzeContent = new Step({\n  id: 'analyzeContent',\n  outputSchema: z.object({\n    content: z.string(),\n    aiAnalysisScore: z.number(),\n    flaggedCategories: z.array(z.string()).optional(),\n  }),\n  execute: async ({ context }) => {\n    const content = context.triggerData.content;\n\n    // Simulate AI analysis\n    const aiAnalysisScore = simulateContentAnalysis(content);\n    const flaggedCategories = aiAnalysisScore < 0.7\n      ? ['potentially inappropriate', 'needs review']\n      : [];\n\n    return {\n      content,\n      aiAnalysisScore,\n      flaggedCategories,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Example Application\nDESCRIPTION: Command to start the example application using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the necessary dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Word Inclusion Metric\nDESCRIPTION: Imports required dependencies from the Mastra core evaluation module for creating custom metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/word-inclusion.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Metric, type MetricResult } from '@mastra/core/eval';\n```\n\n----------------------------------------\n\nTITLE: Error Handling for Circular Dependencies in TypeScript\nDESCRIPTION: This code snippet illustrates how to handle potential errors, specifically circular dependencies, when using the `.then()` method to define workflow steps.  A `try...catch` block is used to catch `ValidationError` exceptions, which are thrown when a circular dependency is detected, allowing for custom error handling logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/then.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  workflow\n    .step(stepA)\n    .then(stepB)\n    .then(stepA) // Will throw error - circular dependency\n    .commit();\n} catch (error) {\n  if (error instanceof ValidationError) {\n    console.log(error.type); // 'circular_dependency'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Define Product Recommendation Generation Step in Mastra\nDESCRIPTION: This code snippet defines a Mastra step named `generateRecommendations` that generates product recommendations for a given customer. It uses the `zod` library to define the output schema and includes a mock implementation for generating the recommendations based on the customer's name provided in the trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\nimport { confirm, input, select } from '@inquirer/prompts';\n\n// Step 1: Generate product recommendations\nconst generateRecommendations = new Step({\n  id: 'generateRecommendations',\n  outputSchema: z.object({\n    customerName: z.string(),\n    recommendations: z.array(\n      z.object({\n        productId: z.string(),\n        productName: z.string(),\n        price: z.number(),\n        description: z.string(),\n      }),\n    ),\n  }),\n  execute: async ({ context }) => {\n    const customerName = context.triggerData.customerName;\n\n    // In a real application, you might call an API or ML model here\n    // For this example, we'll return mock data\n    return {\n      customerName,\n      recommendations: [\n        {\n          productId: 'prod-001',\n          productName: 'Premium Widget',\n          price: 99.99,\n          description: 'Our best-selling premium widget with advanced features',\n        },\n        {\n          productId: 'prod-002',\n          productName: 'Basic Widget',\n          price: 49.99,\n          description: 'Affordable entry-level widget for beginners',\n        },\n        {\n          productId: 'prod-003',\n          productName: 'Widget Pro Plus',\n          price: 149.99,\n          description: 'Professional-grade widget with extended warranty',\n        },\n      ],\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Get Text from Chunks (Instance Method)\nDESCRIPTION: Returns an array of text strings, extracted from the document's chunks. This method is useful for retrieving the textual content after chunking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ngetText(): string[]\n```\n\n----------------------------------------\n\nTITLE: Qdrant Package Installation\nDESCRIPTION: Adds the new Qdrant package `@mastra/qdrant` as a dependency using `pnpm`. This is a required step in the migration process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/CHANGELOG.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/qdrant\n```\n\n----------------------------------------\n\nTITLE: Registering Agents with Mastra (TypeScript)\nDESCRIPTION: This code snippet shows how to register the created agents (optimistAgent and skepticAgent) with a Mastra instance.  It initializes a new Mastra object with an agents property, containing the agent instances. A logger is also configured for the Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger } from '@mastra/core/logger';\nimport { Mastra } from '@mastra/core/mastra';\nimport { optimistAgent, skepticAgent } from './agents';\n\nexport const mastra = new Mastra({\n  agents: { \n    optimistAgent,\n    skepticAgent \n  },\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Text from Audio Stream\nDESCRIPTION: Demonstrates how to generate text from an audio stream using the listen method of the CloudflareVoice class. It returns the transcribed text from the audio stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Generate Text from an audio stream\nconst text = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Text-to-speech with custom properties\nDESCRIPTION: This snippet shows how to use the `speak` method with custom properties to convert text to speech. It overrides the default speaker and specifies custom audio properties like format, rate, and style.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/murf.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// カスタムプロパティでのテキスト読み上げ\nconst audioStream = await voice.speak(\"Hello, world!\", {\n  speaker: 'en-UK-hazel',\n  properties: {\n    format: 'WAV',\n    rate: 1.2,\n    style: 'casual',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Vector Store Errors in TypeScript\nDESCRIPTION: Demonstrates how to catch and handle VectorStoreError exceptions thrown by the Qdrant vector store. This allows developers to gracefully handle potential issues such as connection failures or invalid dimensions and log relevant error details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/qdrant.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a .env file from the example template for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/faithfulness/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Creating Project Structure (Bash)\nDESCRIPTION: Commands to create the necessary directories and files for the stock agent project structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/agents src/tools\ntouch src/agents/stockAgent.ts src/tools/stockPrices.ts src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Evaluating a Response with Mixed Hallucination in Mastra\nDESCRIPTION: This example shows how to evaluate a response that contradicts some facts in the context, resulting in a medium hallucination score of 0.5. It sets up context about Star Wars, configures the HallucinationMetric, and measures a response that contains both accurate and contradictory information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/hallucination.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'The first Star Wars movie was released in 1977.',\n  'It was directed by George Lucas.',\n  'The film earned $775 million worldwide.',\n  'The movie was filmed in Tunisia and England.',\n];\n\nconst metric2 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'Tell me about the first Star Wars movie.';\nconst response2 = 'The first Star Wars movie came out in 1977 and was directed by George Lucas. It made over $1 billion at the box office and was filmed entirely in California.';\n\nconsole.log('Example 2 - Mixed Hallucination:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'The response contradicts some facts in the context.' }\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLStore for Production\nDESCRIPTION: This code snippet shows how to initialize the `LibSQLStore` for production environments, using a persistent database URL. The database URL is retrieved from the `DATABASE_URL` environment variable. It assumes the environment variable is properly configured with a valid LibSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/libsql.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\n\n// Persistent database (production)\nconst storage = new LibSQLStore({\n    config: {\n        url: process.env.DATABASE_URL,\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: LibSQL Storage Configuration - TypeScript\nDESCRIPTION: This code snippet demonstrates how to configure Mastra to use LibSQL as the storage engine for workflow state during suspension.  It shows examples for in-memory, file-based, and remote databases.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { DefaultStorage } from \"@mastra/core/storage/libsql\";\n\nconst mastra = new Mastra({\n  storage: new DefaultStorage({\n    config: {\n      url: \"file:storage.db\", // 開発用のローカルファイルベースのデータベース\n      // 本番環境では、永続的なURLを使用:\n      // url: process.env.DATABASE_URL,\n      // authToken: process.env.DATABASE_AUTH_TOKEN, // 認証された接続のためのオプション\n    },\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Configure Mastra Instance with Telemetry\nDESCRIPTION: This snippet configures the Mastra instance with telemetry settings, including the service name and enabling telemetry. This is configured in mastra.config.ts file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... 他の設定\n  telemetry: {\n    serviceName: \"your-project-name\",\n    enabled: true\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Text-to-speech with default settings\nDESCRIPTION: This snippet demonstrates how to use the `speak` method with default settings to convert text to speech. It assumes the MurfVoice instance has been initialized. The method returns a promise that resolves with a NodeJS.ReadableStream containing the audio data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/murf.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// デフォルト設定でのテキスト読み上げ\nconst audioStream = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Braintrust OTLP Endpoint Configuration\nDESCRIPTION: Configures environment variables for sending telemetry data to Braintrust via OTLP. Requires setting the endpoint and authorization headers with your API key and project ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/braintrust.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.braintrust.dev/otel\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer <Your API Key>, x-bt-parent=project_id:<Your Project ID>\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent with OpenAI model\nDESCRIPTION: Defines an agent with instructions for planning local activities and travel based on weather data. It uses the OpenAI 'gpt-4o-mini' model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: 'Weather Agent',\n  instructions: `\n        あなたは天気に基づいた計画に優れた地元のアクティビティと旅行の専門家です。天気データを分析し、実用的なアクティビティの推奨を提供してください。\n        予報の各日に対して、次の形式で回答を構成してください：\n        📅 [曜日, 月 日, 年]\n        ═══════════════════════════\n        🌡️ 天気概要\n        • 状況: [簡単な説明]\n        • 気温: [X°C/Y°F から A°C/B°F]\n        • 降水確率: [X% の確率]\n        🌅 午前のアクティビティ\n        屋外:\n        • [アクティビティ名] - [特定の場所/ルートを含む簡単な説明]\n          最適な時間帯: [特定の時間範囲]\n          注意: [関連する天気の考慮事項]\n        🌞 午後のアクティビティ\n        屋外:\n        • [アクティビティ名] - [特定の場所/ルートを含む簡単な説明]\n          最適な時間帯: [特定の時間範囲]\n          注意: [関連する天気の考慮事項]\n        🏠 屋内の代替案\n        • [アクティビティ名] - [特定の会場を含む簡単な説明]\n          理想的な条件: [この代替案を引き起こす天気条件]\n        ⚠️ 特別な考慮事項\n        • [関連する天気警報、UV指数、風の状況など]\n        ガイドライン:\n        - 1日あたり2〜3つの時間特定の屋外アクティビティを提案\n        - 1〜2つの屋内バックアップオプションを含める\n        - 降水確率が50％を超える場合は、屋内アクティビティを優先\n        - すべてのアクティビティは特定の場所に特化する必要があります\n        - 特定の会場、トレイル、または場所を含める\n        - 気温に基づいてアクティビティの強度を考慮する\n        - 説明は簡潔でありながら情報豊かに保つ\n        一貫性のために、この正確なフォーマットを維持し、示されている絵文字とセクションヘッダーを使用してください。\n      `,\n  model: openai('gpt-4o-mini'),\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Document Chunking with MDocument in Typescript\nDESCRIPTION: This code snippet demonstrates the basic usage of the `.chunk()` function to split a markdown document into smaller chunks using default settings. It imports the `MDocument` class from the `@mastra/rag` library and creates a document from a markdown string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\nconst doc = MDocument.fromMarkdown(`\n# Introduction\nThis is a sample document that we want to split into chunks.\n\n## Section 1\nHere is the first section with some content.\n\n## Section 2 \nHere is another section with different content.\n`);\n\n// Basic chunking with defaults\nconst chunks = await doc.chunk();\n```\n\n----------------------------------------\n\nTITLE: Special Headers Middleware Example\nDESCRIPTION: Example of middleware handling Mastra-specific headers for client identification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    // Check for Mastra-specific headers in incoming requests\n    const isFromMastraCloud = c.req.header(\"x-mastra-cloud\") === \"true\";\n    const clientType = c.req.header(\"x-mastra-client-type\"); // e.g., 'js', 'python'\n    const isDevPlayground = c.req.header(\"x-mastra-dev-playground\") === \"true\";\n\n    // Customize behavior based on client information\n    if (isFromMastraCloud) {\n      // Special handling for Mastra Cloud requests\n    }\n\n    await next();\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Available Speakers for Text-to-Speech\nDESCRIPTION: This TypeScript code snippet retrieves a list of available speakers from the PlayAI API. This allows users to see the different voice options they can use for text-to-speech.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Query Result Interface (TypeScript)\nDESCRIPTION: Defines the structure of the query result returned by the `query` method. Includes the ID, score, metadata, and optionally the vector itself if `includeVector` is true.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/turbopuffer.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: useCompletion Hook Implementation - TypeScript (Component)\nDESCRIPTION: This code shows how to use the `useCompletion` hook from `@ai-sdk/react` in a React component to handle single-turn completions. The component takes user input, submits it to an API endpoint, and displays the completion result. The `api` property should point to an endpoint that handles agent stream requests.  It includes input handling and form submission.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useCompletion } from \"@ai-sdk/react\";\n\nexport function CompletionComponent() {\n  const {\n    completion,\n    input,\n    handleInputChange,\n    handleSubmit,\n  } = useCompletion({\n  api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Enter a prompt...\"\n        />\n      </form>\n      <p>Completion result: {completion}</p>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Smithery.ai Registry (Unix/Mac)\nDESCRIPTION: This TypeScript code configures MCP with the Smithery.ai registry, specifically for the sequential thinking server on Unix/Mac systems. It uses npx to run the Smithery CLI and execute the sequential thinking server. Note the escaping of the JSON config.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Unix/Mac\nconst mcp = new MCPConfiguration({\n  servers: {\n    sequentialThinking: {\n      command: \"npx\",\n      args: [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@smithery-ai/server-sequential-thinking\",\n        \"--config\",\n        \"{}\",\n      ],\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Configuration Keys for Dane\nDESCRIPTION: Command to configure API keys required for Dane to function, specifically showing how to set the Anthropic API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/dane/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndane config --set ANTHROPIC_API_KEY=<your-key>\n```\n\n----------------------------------------\n\nTITLE: Using ToxicityMetric to measure toxicity of LLM output\nDESCRIPTION: This code snippet demonstrates how to use the ToxicityMetric class to measure the toxicity of an LLM's output. It initializes the metric with a specified language model and scale, then uses the measure method to evaluate an input and output pair. The resulting score and explanation are then printed to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/toxicity.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ToxicityMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ToxicityMetric(model, {\n  scale: 1, // Default scale is 0-1\n});\n\nconst result = await metric.measure(\n  \"How is Sarah as a person?\",\n  \"Sarah is a dedicated team member who always delivers quality work.\",\n);\n\nconsole.log(result.score); // Score from 0-1 (0 = not toxic, 1 = toxic)\nconsole.log(result.info.reason); // Explanation of the toxicity assessment\n```\n\n----------------------------------------\n\nTITLE: Mastra Build Command Options\nDESCRIPTION: Command line options available for the build command, including directory specification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n--dir     Directory containing Mastra files (default: src/mastra)\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Quick One-Liner\nDESCRIPTION: This command demonstrates a quick one-liner to create a Mastra project non-interactively, including examples and specifying components and LLM provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nnpx -y mastra@latest --project-name <your-project> --example --components \"tools,agents,workflows\" --llm <llm-provider>\n```\n\n----------------------------------------\n\nTITLE: Initializing Workflow Steps with Mastra Core\nDESCRIPTION: This snippet demonstrates how to create and initialize steps for a Mastra workflow using the `@mastra/core/workflows` library. It defines several steps (`stepOne`, `stepTwo`, `stepThree`, `stepFour`, and `finalStep`) that perform specific operations on the input data or results from previous steps. Each step's `execute` function contains the logic for the operation, and the `context` object allows access to previous step results and trigger data. The steps perform calculations and conditional logic based on the input value.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/branching-paths.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\"\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2\n  })\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n    if (!stepOneResult) {\n      return { isDivisibleByFive: false }\n    }\n\n    return { isDivisibleByFive: stepOneResult.doubledValue % 5 === 0 }\n  }\n});\n\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) =>{\n    const stepOneResult = context.getStepResult<{ doubledValue: number }>(\"stepOne\");\n    if (!stepOneResult) {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: stepOneResult.doubledValue + 1 }\n  }\n});\n\nconst stepFour = new Step({\n  id: \"stepFour\",\n  execute: async ({ context }) => {\n    const stepThreeResult = context.getStepResult<{ incrementedValue: number }>(\"stepThree\");\n    if (!stepThreeResult) {\n      return { isDivisibleByThree: false }\n    }\n\n    return { isDivisibleByThree: stepThreeResult.incrementedValue % 3 === 0 }\n  }\n});\n\n// 両方のブランチに依存する新しいステップ\nconst finalStep = new Step({\n  id: \"finalStep\",\n  execute: async ({ context }) => {\n    // getStepResultを使用して両方のブランチから結果を取得\n    const stepTwoResult = context.getStepResult<{ isDivisibleByFive: boolean }>(\"stepTwo\");\n    const stepFourResult = context.getStepResult<{ isDivisibleByThree: boolean }>(\"stepFour\");\n\n    const isDivisibleByFive = stepTwoResult?.isDivisibleByFive || false;\n    const isDivisibleByThree = stepFourResult?.isDivisibleByThree || false;\n\n    return {\n      summary: `数値 ${context.triggerData.inputValue} は倍にすると5で${isDivisibleByFive ? '割り切れます' : '割り切れません'}、倍にして1を加えると3で${isDivisibleByThree ? '割り切れます' : '割り切れません'}.`,\n      isDivisibleByFive,\n      isDivisibleByThree\n    }\n  }\n});\n\n// ワークフローを構築\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and PostgreSQL\nDESCRIPTION: Sets up environment variables for OpenAI API key and PostgreSQL connection string in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork stream() Method in TypeScript\nDESCRIPTION: This code snippet shows the `stream()` method signature of the AgentNetwork class. It is used to stream a response using the agent network. It takes messages as input, which can be a string, string array, or CoreMessage array, and optional arguments of type `AgentStreamOptions`. It returns a Promise that resolves to a `StreamTextResult`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync stream(\n  messages: string | string[] | CoreMessage[],\n  args?: AgentStreamOptions\n): Promise<StreamTextResult>\n```\n\n----------------------------------------\n\nTITLE: IndexStats Interface Definition\nDESCRIPTION: Defines the structure of the IndexStats object, which provides information about an index, including its dimensions, count, and metric. This interface is returned by the `describeIndex` method to describe index metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/astra.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with New Relic for Telemetry\nDESCRIPTION: Implements the Mastra configuration to enable telemetry data exportation to New Relic using the OTLP protocol. This involves importing the Mastra core module and setting up a new Mastra instance with telemetry configurations such as the service name and enabling exports via OTLP. It requires the '@mastra/core' library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/new-relic.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \\\"@mastra/core\\\";\\n\\nexport const mastra = new Mastra({\\n  // ... other config\\n  telemetry: {\\n    serviceName: \\\"your-service-name\\\",\\n    enabled: true,\\n    export: {\\n      type: \\\"otlp\\\",\\n    },\\n  },\\n});\n```\n\n----------------------------------------\n\nTITLE: Set up API Key - .env file (Manual Install)\nDESCRIPTION: This is an example of setting up the API key in a `.env` file for manual installation. Replace your_openai_api_key with your actual API key. This ensures that your Mastra application can authenticate with the LLM provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example of how to set up the .env file with OpenAI API key and Postgres connection string. These are required for the project to function correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Mastra Instance Check\nDESCRIPTION: Checks if a given object is a valid Mastra instance. This is crucial for ensuring that the dynamic workflow creation has access to the necessary Mastra functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/dynamic-workflows.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === 'object' && mastra instanceof Mastra;\n};\n```\n\n----------------------------------------\n\nTITLE: Creating an AzureVoice Instance with TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to create an instance of the AzureVoice class with configurable speech and listening models. Various optional parameters for API keys, regions, and voice names can be defined.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AzureVoice } from '@mastra/voice-azure';\n\n// Create voice with both speech and listening capabilities\nconst voice = new AzureVoice({\n  speechModel: {\n    apiKey: 'your-api-key', // Optional, can use AZURE_API_KEY env var\n    region: 'your-region', // Optional, can use AZURE_REGION env var\n    voiceName: 'en-US-AriaNeural', // Optional, default voice\n  },\n  listeningModel: {\n    apiKey: 'your-api-key', // Optional, can use AZURE_API_KEY env var\n    region: 'your-region', // Optional, can use AZURE_REGION env var\n    language: 'en-US', // Optional, recognition language\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies for BiasMetric\nDESCRIPTION: This snippet imports the necessary dependencies for using the BiasMetric from the `@mastra/evals/llm` library and the OpenAI integration from `@ai-sdk/openai`. It initializes the required modules for the subsequent bias evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { BiasMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Updating Index by ID in Upstash Vector Store in TypeScript\nDESCRIPTION: The `updateIndexById()` method allows updating a specific item in an index using its ID. It expects an update object containing new vector information and associated metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to update\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the item to update\",\n    },\n    {\n      name: \"update\",\n      type: \"object\",\n      description: \"Update object containing vector and/or metadata\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork getAgentHistory() Method in TypeScript\nDESCRIPTION: This code snippet presents the `getAgentHistory()` method signature for the AgentNetwork class. It returns the interaction history for a specific agent, given its ID. The return type is an array of objects, each containing input, output, and timestamp.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ngetAgentHistory(agentId: string): Array<{\n  input: string;\n  output: string;\n  timestamp: string;\n}>\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAIVoice Instances with Speech and Listening Capabilities\nDESCRIPTION: This TypeScript code demonstrates how to create OpenAIVoice instances with speech, listening, or both capabilities. It showcases the configuration options for specifying speech and listening models, API keys, and speaker voices. API keys can be optionally provided directly, or via the OPENAI_API_KEY environment variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\n// Create voice with both speech and listening capabilities\nconst voice = new OpenAIVoice({\n  speechModel: {\n    name: 'tts-1', // or 'tts-1-hd' for higher quality\n    apiKey: 'your-api-key', // Optional, can use OPENAI_API_KEY env var\n  },\n  listeningModel: {\n    name: 'whisper-1',\n    apiKey: 'your-api-key', // Optional, can use OPENAI_API_KEY env var\n  },\n  speaker: 'alloy', // Default voice\n});\n\n// Or create speech-only voice\nconst speechVoice = new OpenAIVoice({\n  speechModel: {\n    name: 'tts-1',\n    apiKey: 'your-api-key',\n  },\n  speaker: 'nova',\n});\n\n// Or create listening-only voice\nconst listeningVoice = new OpenAIVoice({\n  listeningModel: {\n    name: 'whisper-1',\n    apiKey: 'your-api-key',\n  },\n});\n\n// List available voices\nconst speakers = await voice.getSpeakers();\n\n// Generate speech\nconst audioStream = await voice.speak('Hello from Mastra!', {\n  speaker: 'nova', // Optional: override default speaker\n  speed: 1.0, // Optional: adjust speech speed\n});\n\n// Convert speech to text\nconst text = await voice.listen(audioStream, {\n  filetype: 'wav',\n});\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies\nDESCRIPTION: This snippet imports the required dependencies for implementing the RAG system. It includes modules from @ai-sdk/openai, @mastra/core, @mastra/pg, and @mastra/rag to handle OpenAI integrations, agent management, PostgreSQL vector storage, and RAG functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createVectorQueryTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Closing OpenAI Realtime Voice Connection with TypeScript\nDESCRIPTION: This TypeScript code demonstrates how to use the `close()` method to disconnect from the OpenAI Realtime Voice service and clean up resources. It initializes a real-time voice provider, connects to the service, starts a conversation, streams audio, and then closes the connection after a specified timeout. The `getMicrophoneStream` function is assumed to be available from the `@mastra/node-audio` package. Closing the connection is crucial for resource management and preventing potential billing issues.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.close.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Start a conversation\nvoice.speak(\"Hello, I'm your AI assistant!\");\n\n// Stream audio from a microphone\nconst microphoneStream = getMicrophoneStream();\nvoice.send(microphoneStream);\n\n// When the conversation is complete\nsetTimeout(() => {\n  // Close the connection and clean up resources\n  voice.close();\n  console.log(\"Voice session ended\");\n}, 60000); // End after 1 minute\n```\n\n----------------------------------------\n\nTITLE: Streaming Audio to OpenAIRealtimeVoice Provider\nDESCRIPTION: This snippet demonstrates how to stream audio data to an OpenAIRealtimeVoice provider using the `send()` method. It initializes a Speaker for audio output, sets up event listeners for writing and speaker events, gets a microphone stream, and sends the audio data to the voice provider. It also demonstrates sending audio as an Int16Array.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.send.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Set up event listeners for responses\nvoice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role}: ${text}`);\n});\n\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker)\n});\n\n// Get microphone stream (implementation depends on your environment)\nconst microphoneStream = getMicrophoneStream();\n\n// Send audio data to the voice provider\nawait voice.send(microphoneStream);\n\n// You can also send audio data as Int16Array\nconst audioBuffer = getAudioBuffer(); // Assume this returns Int16Array\nawait voice.send(audioBuffer);\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into Cloudflare Vectorize with Mastra (TSX)\nDESCRIPTION: This code snippet shows how to create a collection and upsert embeddings into Cloudflare Vectorize, a serverless vector database service, using the `CloudflareVector` class from the `@mastra/vectorize` package.  It depends on the `openai` package for generating embeddings and `MDocument` from `@mastra/rag` for handling text chunks. The `CF_ACCOUNT_ID` and `CF_API_TOKEN` environment variables are required for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_7\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { CloudflareVector } from '@mastra/vectorize';\nimport { MDocument } from '@mastra/rag';\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText('Your text content...');\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding('text-embedding-3-small'),\n});\n\nconst vectorize = new CloudflareVector({\n  accountId: process.env.CF_ACCOUNT_ID,\n  apiToken: process.env.CF_API_TOKEN,\n});\n\nawait vectorize.createIndex({\n  indexName: 'test_collection',\n  dimension: 1536,\n});\n\nawait vectorize.upsert({\n  indexName: 'test_collection',\n  vectors: embeddings,\n  metadata: chunks?.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Core Package\nDESCRIPTION: This command installs the `@mastra/core` package, which includes the LibSQLVector store, using npm. This is a prerequisite for using the LibSQLVector functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/libsql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/core\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: Command to install the required project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Running Mastra Server\nDESCRIPTION: Command to start the Mastra HTTP server after building.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnode .mastra/output/index.mjs\n```\n\n----------------------------------------\n\nTITLE: Get Vector Index Details in Typescript\nDESCRIPTION: This code retrieves detailed information about a specific vector index using the `vector.details` method.  The `index-name` parameter specifies the index to retrieve details for. The function returns a promise that resolves with the details of the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst details = await vector.details(\"index-name\");\n```\n\n----------------------------------------\n\nTITLE: Monitoring Step Completion with run.watch() in TypeScript\nDESCRIPTION: This snippet illustrates how to use `run.watch()` to monitor the completion of a specific step within a Mastra workflow. It checks the status of the 'processDocument' step and logs the output when the step is completed. This allows for reactive actions based on the completion of individual steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/watch.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(({results, activePaths}) => {\n  if (activePaths.get('processDocument')?.status === 'completed') {\n    console.log('Document processing output:', results['processDocument'].output);\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure API key and Region\nDESCRIPTION: These environment variables are required to authenticate and authorize the usage of Azure Speech services. AZURE_API_KEY stores the API key for accessing Azure resources, while AZURE_REGION specifies the geographic region where the Azure Speech service is located.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/azure/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"AZURE_API_KEY=your_api_key\nAZURE_REGION=your_region # e.g., eastus, westus2\"\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI API Key\nDESCRIPTION: Sets up the necessary environment variable for the OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Workflow Factory Step TypeScript\nDESCRIPTION: Defines a step that acts as a workflow factory, creating different workflows based on the `workflowType` input.  It supports creating a simple single-step workflow or a more complex two-step workflow. It utilizes @mastra/core and zod for schema definition and workflow management.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/dynamic-workflows.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === 'object' && mastra instanceof Mastra;\n};\n\nconst workflowFactory = new Step({\n  id: 'workflowFactory',\n  inputSchema: z.object({\n    workflowType: z.enum(['simple', 'complex']),\n    inputData: z.string(),\n  }),\n  outputSchema: z.object({\n    result: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error('Mastra instance not available');\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error('Invalid Mastra instance');\n    }\n\n    // タイプに基づいて新しい動的ワークフローを作成\n    const dynamicWorkflow = new Workflow({\n      name: `dynamic-${context.workflowType}-workflow`,\n      mastra,\n      triggerSchema: z.object({\n        input: z.string(),\n      }),\n    });\n\n    if (context.workflowType === 'simple') {\n      // 単一ステップのシンプルなワークフロー\n      const simpleStep = new Step({\n        id: 'simpleStep',\n        execute: async ({ context }) => {\n          return {\n            result: `シンプルな処理: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(simpleStep).commit();\n    } else {\n      // 複数ステップの複雑なワークフロー\n      const step1 = new Step({\n        id: 'step1',\n        outputSchema: z.object({\n          intermediateResult: z.string(),\n        }),\n        execute: async ({ context }) => {\n          return {\n            intermediateResult: `最初の処理: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      const step2 = new Step({\n        id: 'step2',\n        execute: async ({ context }) => {\n          const intermediate = context.getStepResult(step1).intermediateResult;\n          return {\n            finalResult: `二番目の処理: ${intermediate}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(step1).then(step2).commit();\n    }\n\n    // 動的ワークフローを実行\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        input: context.inputData,\n      },\n    });\n\n    // ワークフロータイプに基づいて適切な結果を返す\n    if (context.workflowType === 'simple') {\n      return {\n        // @ts-ignore\n        result: result.results['simpleStep']?.output,\n      };\n    } else {\n      return {\n        // @ts-ignore\n        result: result.results['step2']?.output,\n      };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Similarity Text in Mastra\nDESCRIPTION: Demonstrates comparing distinctly different texts to show how the metric handles low similarity cases. This example compares completely different sentences about a cat and a fox, resulting in a low similarity score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst text3 = 'The cat sleeps on the windowsill.';\nconst reference3 = 'The quick brown fox jumps over the lazy dog.';\n\nconsole.log('Example 3 - Low Similarity:');\nconsole.log('Text:', text3);\nconsole.log('Reference:', reference3);\n\nconst result3 = await metric.measure(reference3, text3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    similarity: result3.info.similarity,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.25806451612903225,\n//   info: { similarity: 0.25806451612903225 }\n// }\n```\n\n----------------------------------------\n\nTITLE: Update cjs bundling\nDESCRIPTION: Updates cjs bundling to ensure files are split.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/deepgram/CHANGELOG.md#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nfd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Generating Wrangler Configuration for Cloudflare Worker\nDESCRIPTION: This JSON snippet shows the structure of the 'wrangler.json' configuration file generated for Cloudflare Workers, specifying the project name, main entry file, compatibility flags, and routing configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/cloudflare.mdx#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"your-project-name\",\n  \"main\": \"./output/index.mjs\",\n  \"compatibility_date\": \"2024-12-02\",\n  \"compatibility_flags\": [\"nodejs_compat\"],\n  \"observability\": {\n    \"logs\": {\n      \"enabled\": true\n    }\n  },\n  \"vars\": {\n    // Environment variables from .env files and configuration\n  },\n  \"routes\": [\n    // Route configurations if specified\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Starting MCPServer with SSE\nDESCRIPTION: This example demonstrates how to integrate the MCPServer with an existing HTTP server using Server-Sent Events (SSE). It sets up a basic HTTP server and, within the request handler, calls the startSSE method with the necessary URL, path, request, and response objects.  An MCP client could then connect to your MCP server at the specified SSE endpoint.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport http from \"http\";\n\nconst httpServer = http.createServer(async (req, res) => {\n  await server.startSSE({\n    url: new URL(req.url || \"\", `http://localhost:1234`),\n    ssePath: \"/sse\",\n    messagePath: \"/message\",\n    req,\n    res,\n  });\n});\n\nhttpServer.listen(PORT, () => {\n  console.log(`HTTP server listening on port ${PORT}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Configure Answer Relevancy Metric\nDESCRIPTION: This TypeScript snippet demonstrates how to configure the AnswerRelevancyMetric with custom parameters. It initializes the metric with an OpenAI model ('gpt-4o-mini') and sets the `uncertaintyWeight` and `scale` options to control the scoring behavior.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new AnswerRelevancyMetric(openai('gpt-4o-mini'), {\n  uncertaintyWeight: 0.3, // 'unsure' の判定に対する重み\n  scale: 1, // 最終スコアのスケール\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent Network with Specialized Agents - TypeScript\nDESCRIPTION: This code snippet demonstrates how to create specialized agents for web searching and data analysis, and initialize an AgentNetwork to coordinate between these agents. It utilizes the OpenAI model for performing tasks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AgentNetwork } from '@mastra/core/network';\nimport { openai } from '@mastra/openai';\n\n// Create specialized agents\nconst webSearchAgent = new Agent({\n  name: 'Web Search Agent',\n  instructions: 'You search the web for information.',\n  model: openai('gpt-4o'),\n  tools: { /* web search tools */ },\n});\n\nconst dataAnalysisAgent = new Agent({\n  name: 'Data Analysis Agent',\n  instructions: 'You analyze data and provide insights.',\n  model: openai('gpt-4o'),\n  tools: { /* data analysis tools */ },\n});\n\n// Create the network\nconst researchNetwork = new AgentNetwork({\n  name: 'Research Network',\n  instructions: 'Coordinate specialized agents to research topics thoroughly.',\n  model: openai('gpt-4o'),\n  agents: [webSearchAgent, dataAnalysisAgent],\n});\n\n// Use the network\nconst result = await researchNetwork.generate('Research the impact of climate change on agriculture');\nconsole.log(result.text);\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Response from Chef Agent API\nDESCRIPTION: This JSON snippet shows a sample response from the Chef Assistant agent when interacted with via the API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"text\": \"You can make delicious pancakes! Here's a simple recipe...\"\n}\n```\n\n----------------------------------------\n\nTITLE: Import Mastra and Zod - TypeScript\nDESCRIPTION: Imports the necessary Mastra tools and Zod for workflow definition and data validation. This includes the core Mastra class, Step and Workflow classes for building workflows, and Zod for defining schemas.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Deploying to Netlify via CLI (Bash)\nDESCRIPTION: This bash code shows how to deploy a Mastra application to Netlify using the Netlify CLI.  It deploys the `.mastra/output` directory, specifically pointing to the functions directory, and optionally to production using the `--prod` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/netlify.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# CLIをインストール: `npm install -g netlify-cli`\n# 出力ディレクトリに移動: `cd .mastra/output`\n# 関数ディレクトリを指定してデプロイ: `netlify deploy --dir . --functions ./netlify/functions`\n# 本番環境へのデプロイには`--prod`フラグを追加: `netlify deploy --prod --dir . --functions ./netlify/functions`\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Voice Providers Example\nDESCRIPTION: Example showing how to combine multiple voice providers using CompositeVoice. Uses OpenAI for speech-to-text and PlayAI for text-to-speech, demonstrating provider initialization and usage with audio streams.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\n// Initialize OpenAI voice for STT\nconst input = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Initialize PlayAI voice for TTS\nconst output = new PlayAIVoice({\n  speechModel: {\n    name: \"playai-voice\",\n    apiKey: process.env.PLAYAI_API_KEY,\n  },\n});\n\n// Combine the providers using CompositeVoice\nconst voice = new CompositeVoice({\n  input,\n  output,\n});\n\n// Implement voice interactions using the combined voice provider\nconst audioStream = getMicrophoneStream(); // Assume this function gets audio input\nconst transcript = await voice.listen(audioStream);\n\n// Log the transcribed text\nconsole.log(\"Transcribed text:\", transcript);\n\n// Convert text to speech\nconst responseAudio = await voice.speak(`You said: ${transcript}`, {\n  speaker: \"default\", // Optional: specify a speaker,\n  responseFormat: \"wav\", // Optional: specify a response format\n});\n\n// Play the audio response\nplayAudio(responseAudio);\n```\n\n----------------------------------------\n\nTITLE: Creating Math Solver Prompt with TypeScript\nDESCRIPTION: This snippet constructs a word problem-solving prompt that guides models to solve math problems step-by-step. It specifies thinking strategies and the structure for output in markdown format, ensuring a comprehensive approach to solving the provided problems.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntype WordProblemVars = {\n  problem: string;\n};\n\nconst mathSolver = createPrompt<WordProblemVars>('Solve word problem', {\n  persona: 'Math Teacher',\n  outputFormat: 'markdown',\n})\n  .text('Solve this word problem:\\n\\n{{problem}}')\n  .thinking({\n    autoChainOfThought: true,\n    steps: [\n      'Read and understand the problem',\n      'Identify important information',\n      'Choose the right operation',\n      'Solve step by step',\n      'Check the answer',\n    ],\n  });\n\n// Usage example\nconst solution = mathSolver.toString({\n  problem: 'If a store sells 12 apples per hour and is open for 8 hours, how many apples do they sell in a day?',\n});\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_13\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/tts-support\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Introducing TTS in Mastra</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Introducing TTS in Mastra</h2><span class=\"text-xs text-left text-text-3\">Jan 20, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 20, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Running the Hallucination Example\nDESCRIPTION: Command to start the hallucination evaluation example using PNPM.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server for Windows\nDESCRIPTION: JSON configuration for setting up the Mastra MCP server on Windows systems. Uses cmd.exe to execute npx commands properly in the Windows environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/mcp-docs-server.mdx#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"cmd\",\n      \"args\": [\"/c\", \"npx\", \"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Corepack for PNPM Version Management\nDESCRIPTION: Command to enable corepack, which ensures the correct pnpm version is used for the project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncorepack enable\n```\n\n----------------------------------------\n\nTITLE: Abstract Speak Method Definition\nDESCRIPTION: This code snippet defines the abstract `speak` method that must be implemented by any class extending `MastraVoice`. It is responsible for converting text input to speech, supporting both string and stream inputs, and allowing overriding the default speaker. The method returns a stream of audio data or void if the audio is handled through an event.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nabstract speak(\n  input: string | NodeJS.ReadableStream,\n  options?: {\n    speaker?: string;\n    [key: string]: unknown;\n  }\n): Promise<NodeJS.ReadableStream | void>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for PlayAI\nDESCRIPTION: This snippet outlines the required environment variables that need to be set for the PlayAI Voice module to function correctly, including API key and user ID. Ensure these variables are properly configured in your environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPLAYAI_API_KEY=your_api_key\n```\n\nLANGUAGE: bash\nCODE:\n```\nPLAYAI_USER_ID=your_user_id\n```\n\n----------------------------------------\n\nTITLE: Resume Workflow with Event - Monitoring and Auto-Resuming - Typescript\nDESCRIPTION: This code snippet shows how to monitor a workflow for suspended event steps and automatically resume it after a delay using `resumeWithEvent()`. It uses the `watch()` method to observe the workflow's active paths and triggers the 'approval' event after a 5-second timeout.  It requires the `workflow` object and its `createRun` method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resumeWithEvent.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Start a workflow\nconst { start, watch, resumeWithEvent } = workflow.createRun();\n\n// Watch for suspended event steps\nwatch(async ({ activePaths }) => {\n  const isApprovalEventSuspended =\n    activePaths.get(\"__approval_event\")?.status === \"suspended\";\n  // Check if suspended at the approval event step\n  if (isApprovalEventSuspended) {\n    console.log(\"Workflow waiting for approval\");\n\n    // In a real scenario, you would wait for the actual event\n    // Here we're simulating with a timeout\n    setTimeout(async () => {\n      try {\n        await resumeWithEvent(\"approval\", {\n          approved: true,\n          approverName: \"Auto Approver\",\n        });\n      } catch (error) {\n        console.error(\"Failed to auto-resume workflow:\", error);\n      }\n    }, 5000); // Wait 5 seconds before auto-approving\n  }\n});\n\n// Start the workflow\nawait start({ triggerData: { requestId: \"auto-123\" } });\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API key in environment file\nDESCRIPTION: Instructions for adding the OpenAI API key to the .env.local file, which is required for the application to function properly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/assistant-ui/README.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with OpenAI\nDESCRIPTION: Illustrates how to generate embeddings for document chunks using the OpenAI embedding model. It imports the necessary modules and uses the `embedMany` function to create embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { embedMany } from \"ai\";\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Testing Agent Endpoint with Curl (Bash)\nDESCRIPTION: This `curl` command tests the weather agent's endpoint by sending a POST request to `http://localhost:4111/api/agents/weatherAgent/generate`. It specifies the content type as `application/json` and includes a JSON payload with a `messages` array containing the query \"What is the weather in London?\". This command simulates a client request to the agent and allows developers to verify the agent's response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/weatherAgent/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"messages\": [\"What is the weather in London?\"]}'\n```\n\n----------------------------------------\n\nTITLE: Pinecone Error Handling (TypeScript)\nDESCRIPTION: Demonstrates how to handle potential errors thrown by the Pinecone vector store. It uses a try-catch block to catch `VectorStoreError` instances and extract the error code and details for logging or further processing. This is crucial for robust error management.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pinecone.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Vectors in Upstash Vector Store in TypeScript\nDESCRIPTION: The `query()` method retrieves similar vectors from the specified index based on a query vector. It supports optional parameters for results limit, metadata filtering, and whether to include the vectors in the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to query\",\n    },\n    {\n      name: \"queryVector\",\n      type: \"number[]\",\n      description: \"Query vector to find similar vectors\",\n    },\n    {\n      name: \"topK\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"10\",\n      description: \"Number of results to return\",\n    },\n    {\n      name: \"filter\",\n      type: \"Record<string, any>\",\n      isOptional: true,\n      description: \"Metadata filters for the query\",\n    },\n    {\n      name: \"includeVector\",\n      type: \"boolean\",\n      isOptional: true,\n      defaultValue: \"false\",\n      description: \"Whether to include vectors in the results\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork getRoutingAgent() Method in TypeScript\nDESCRIPTION: This code snippet showcases the `getRoutingAgent()` method signature for the AgentNetwork class. It returns the routing agent used by the network. The return type is Agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ngetRoutingAgent(): Agent\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Client with npm\nDESCRIPTION: This command installs the Mastra Client SDK using npm. It adds the @mastra/client-js package to your project's dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Run Script to Save Embeddings (Bash)\nDESCRIPTION: Executes the script to generate and store embeddings using bun.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpx bun src/store.ts\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Traceloop Integration\nDESCRIPTION: These environment variables are required to configure Traceloop to work with Mastra. The `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the Traceloop API endpoint, and `OTEL_EXPORTER_OTLP_HEADERS` provides the authorization token and destination ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/traceloop.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.traceloop.com\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer your_api_key, x-traceloop-destination-id=your_destination_id\"\n```\n\n----------------------------------------\n\nTITLE: Updating Imports - JavaScript\nDESCRIPTION: This snippet illustrates the process of updating import statements in your code to replace the deprecated package with the new package. It demonstrates how to adjust the import from '@mastra/speech-speechify' to '@mastra/voice-speechify'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/speechify/README.md#2025-04-22_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n- import { SpeechifyTTS } from '@mastra/speech-speechify'\n+ import { SpeechifyVoice } from '@mastra/voice-speechify'\n```\n\n----------------------------------------\n\nTITLE: Importing Mastra and NetlifyDeployer in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to import the Mastra and NetlifyDeployer classes for setting up a deployment configuration for a Mastra application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/netlify.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { NetlifyDeployer } from '@mastra/deployer-netlify';\n\nconst mastra = new Mastra({\n  deployer: new NetlifyDeployer({\n    scope: 'your-team-slug',\n    projectName: 'your-project-name',\n    token: 'your-netlify-token'\n  }),\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Processing Document into Chunks with Metadata\nDESCRIPTION: Creates a document from text and processes it into chunks with metadata, including keyword extraction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`The Impact of Climate Change on Global Agriculture...`);\n\nconst chunks = await doc.chunk({\n  strategy: 'recursive',\n  size: 512,\n  overlap: 50,\n  separator: '\\n',\n  extract: {\n    keywords: true,  // Extracts keywords from each chunk\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Chunking HTML Content with MDocument in TypeScript\nDESCRIPTION: This code snippet demonstrates how to chunk HTML content semantically using Mastra's `MDocument` class. It imports the `MDocument` class, creates an HTML string, initializes an `MDocument` instance from the HTML, and then uses the `chunk` method to split the HTML into smaller parts based on specified header tags (`h1` and `p`). The resulting chunks are then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/chunking/chunk-html.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst html = `\n<div>\n    <h1>h1 content...</h1>\n    <p>p content...</p>\n</div>\n`;\n\nconst doc = MDocument.fromHTML(html);\n\nconst chunks = await doc.chunk({\n  headers: [\n    [\"h1\", \"Header 1\"],\n    [\"p\", \"Paragraph\"],\n  ],\n});\n\nconsole.log(chunks);\n```\n\n----------------------------------------\n\nTITLE: Registering a Workflow with Mastra (TypeScript)\nDESCRIPTION: This code demonstrates how to register a workflow with Mastra to enable logging and telemetry features.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  workflows: { myWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with Provider-Specific Options\nDESCRIPTION: This code snippet showcases how to use provider-specific options with the `voice.listen()` method for audio transcription. In this example, it configures the language and provides a prompt to guide the transcription process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.listen.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// With provider-specific options\nconst transcriptWithOptions = await voice.listen(audioStream, {\n  language: \"en\",\n  prompt: \"This is a conversation about artificial intelligence.\",\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install all required Node.js packages using PNPM package manager. This installs the Mastra library and all its dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Using MastraClient in a React component\nDESCRIPTION: This code demonstrates how to use MastraClient in a Next.js React component to fetch weather information. It defines an asynchronous handleSubmit function that retrieves a city name from a form, uses mastraClient to get an agent, generates a response from the agent, and logs the response to the console. Error handling is included.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n'use client'\n\nimport { mastraClient } from '@/lib/mastra'\n\nexport function SimpleWeather() {\n  async function handleSubmit(formData: FormData) {\n    const city = formData.get('city')\n    const agent = mastraClient.getAgent('weatherAgent')\n    \n    try {\n      const response = await agent.generate({\n        messages: [{ role: 'user', content: `What's the weather like in ${city}?` }],\n      })\n      // Handle the response\n      console.log(response.text)\n    } catch (error) {\n      console.error('Error:', error)\n    }\n  }\n\n  return (\n    <form action={handleSubmit}>\n      <input name=\"city\" placeholder=\"Enter city name\" />\n      <button type=\"submit\">Get Weather</button>\n    </form>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Request Logging Middleware Example - TypeScript\nDESCRIPTION: This middleware function demonstrates how to log request details, including the method, URL, and duration. It measures the time taken to process a request and logs the information to the console, which is useful for performance monitoring and debugging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    const start = Date.now();\n    await next();\n    const duration = Date.now() - start;\n    console.log(`${c.req.method} ${c.req.url} - ${duration}ms`);\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating Directory\nDESCRIPTION: Commands to clone the Mastra project repository and navigate to the sequential workflow example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-sequential-steps/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/workflow-with-sequential-steps\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the required dependencies using PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-chroma/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Importing Mastra and VercelDeployer in TypeScript\nDESCRIPTION: Demonstrates how to import and configure the Mastra class with a VercelDeployer for deployment purposes. This requires the @mastra/core and @mastra/deployer-vercel packages and a valid Vercel team slug, project name, and authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/vercel.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\\nimport { VercelDeployer } from '@mastra/deployer-vercel';\\n\\nconst mastra = new Mastra({\\n  deployer: new VercelDeployer({\\n    teamSlug: 'your-team-slug',\\n    projectName: 'your-project-name',\\n    token: 'your-vercel-token'\\n  }),\\n  // ... other Mastra configuration options\\n});\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Example 1\nDESCRIPTION: This command demonstrates how to run `create-mastra` non-interactively, specifying the project name, components, LLM, and example code inclusion.  It shows specifying the project name as a positional argument.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest my-app --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API key in environment file\nDESCRIPTION: Example of how to configure the .env file with your OpenAI API key for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/summarization/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: TTS with Speechify Voice Agent\nDESCRIPTION: This code demonstrates how to use an Agent with Speechify voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Speechify's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { SpeechifyVoice } from \"@mastra/voice-speechify\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new SpeechifyVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"matthew\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Installing Clickhouse Package with npm\nDESCRIPTION: This snippet installs the Clickhouse library required for the Mastra project. It depends on Node.js and npm for package management.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/clickhouse\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to the Project Repository\nDESCRIPTION: Command to clone the Mastra repository from GitHub and navigate to the chunk-text example directory within the basics/rag folder.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-size/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/chunk-text\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Agent in React Component\nDESCRIPTION: Example React component showing how to use Mastra client to query a weather agent and handle form submission.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n'use client'\n\nimport { mastraClient } from '@/lib/mastra'\n\nexport function SimpleWeather() {\n  async function handleSubmit(formData: FormData) {\n    const city = formData.get('city')\n    const agent = mastraClient.getAgent('weatherAgent')\n    \n    try {\n      const response = await agent.generate({\n        messages: [{ role: 'user', content: `What's the weather like in ${city}?` }],\n      })\n      // Handle the response\n      console.log(response.text)\n    } catch (error) {\n      console.error('Error:', error)\n    }\n  }\n\n  return (\n    <form action={handleSubmit}>\n      <input name=\"city\" placeholder=\"Enter city name\" />\n      <button type=\"submit\">Get Weather</button>\n    </form>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra project with custom settings\nDESCRIPTION: This command initializes a new Mastra project with custom settings.  It sets the directory to `src/mastra`, includes agents and tools components, uses OpenAI as the LLM provider, and includes sample code.\n\nOptions include:\n- `--dir`: Mastra files directory\n- `--components`: Comma-separated list of components\n- `--llm`: Default model provider\n- `--example`: Include sample code\n- `--no-example`: Skip sample code\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/cli/init.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmastra init --dir src/mastra --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Set Runtime Context and Generate Response\nDESCRIPTION: This snippet shows how to set the runtime context and generate a response using the agent defined in the previous snippet. It creates a `RuntimeContext`, sets the `temperature-scale` to \"celsius\", and then calls `agent.generate` with the runtime context to retrieve the weather information. The `MyRuntimeContext` type provides type safety for the runtime context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { agent } from \"./agents/weather\";\n\ntype MyRuntimeContext = {\"temperature-scale\", \"celsius\" | \"farenheit\"}\n\nconst runtimeContext = new RuntimeContext<MyRuntimeContext>();\nruntimeContext.set(\"temperature-scale\", \"celsius\");\n\nconst result = await agent.generate(\"What is the weather in San Francisco?\", {\n  runtimeContext,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAIRealtimeVoice with TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the OpenAIRealtimeVoice class with both default and specific configurations. It includes importing the necessary modules, creating an instance of the class, connecting to the service, setting up event listeners for audio and transcribed text, converting text to speech, processing audio input, and disconnecting from the service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/openai-realtime.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\n// Initialize with default configuration using environment variables\nconst voice = new OpenAIRealtimeVoice();\n\n// Or initialize with specific configuration\nconst voiceWithConfig = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: 'your-openai-api-key',\n    model: 'gpt-4o-mini-realtime-preview-2024-12-17',\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: 'server_vad',\n          threshold: 0.6,\n          silence_duration_ms: 1200\n        }\n      }\n    }\n  },\n  speaker: 'alloy'  // Default voice\n});\n\n// Establish connection\nawait voice.connect();\n\n// Set up event listeners\nvoice.on('speaker', ({ audio }) => {\n  // Handle audio data (Int16Array) pcm format by default\n  playAudio(audio);\n});\n\nvoice.on('writing', ({ text, role }) => {\n  // Handle transcribed text\n  console.log(`${role}: ${text}`);\n});\n\n// Convert text to speech\nawait voice.speak('Hello, how can I help you today?', {\n  speaker: 'echo'  // Override default voice\n});\n\n// Process audio input\nconst microphoneStream = getMicrophoneStream();\nawait voice.send(microphoneStream);\n\n// When done, disconnect\nvoice.connect();\n```\n\n----------------------------------------\n\nTITLE: Creating Loops with Manual Cyclical Dependencies (Legacy Approach)\nDESCRIPTION: Shows the legacy approach for creating loops in workflows by manually defining cyclical dependencies with conditions, which still works but is less preferred than newer methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(fetchData)\n  .then(processData)\n  .after(processData)\n  .step(finalizeData, {\n    when: { \"processData.status\": \"success\" },\n  })\n  .step(fetchData, {\n    when: { \"processData.status\": \"retry\" },\n  });\n```\n\n----------------------------------------\n\nTITLE: Installing LibSQL Storage with npm\nDESCRIPTION: This command installs the @mastra/storage-libsql package, which provides the LibSQL storage implementation for the Mastra project.  It's a necessary prerequisite for using the LibSQL storage functionality.  It adds the package and its dependencies to the project's node_modules directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/libsql.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/storage-libsql\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key\nDESCRIPTION: This command sets the OpenAI API key as an environment variable. The API key is required to authenticate with the OpenAI service and use the real-time voice features.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"OPENAI_API_KEY=your_api_key\"\n```\n\n----------------------------------------\n\nTITLE: Event-Based Suspension Example - TypeScript\nDESCRIPTION: This code demonstrates an event-based workflow. The workflow suspends execution until a specific event (`approvalReceived`) is triggered, and then resumes with the event data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/suspend-and-resume.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// ステップを定義\nconst getUserInput = new Step({\n  id: \"getUserInput\",\n  execute: async () => ({ userInput: \"initial input\" }),\n  outputSchema: z.object({ userInput: z.string() }),\n});\n\nconst processApproval = new Step({\n  id: \"processApproval\",\n  execute: async ({ context }) => {\n    // コンテキストからイベントデータにアクセス\n    const approvalData = context.inputData?.resumedEvent;\n    return {\n      approved: approvalData?.approved,\n      approvedBy: approvalData?.approverName,\n    };\n  },\n  outputSchema: z.object({\n    approved: z.boolean(),\n    approvedBy: z.string(),\n  }),\n});\n\n// イベント定義でワークフローを作成\nconst approvalWorkflow = new Workflow({\n  name: \"approval-workflow\",\n  triggerSchema: z.object({ requestId: z.string() }),\n  events: {\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n  },\n});\n\n// イベントベースの一時停止でワークフローを構築\napprovalWorkflow\n  .step(getUserInput)\n  .afterEvent(\"approvalReceived\") // ワークフローはここで自動的に一時停止します\n  .step(processApproval) // このステップはイベントが受信された後に実行されます\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to the Mastra Completeness Example Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the completeness evaluation example directory. This is the first step in setting up the completeness metric example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/completeness/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/completeness\n```\n\n----------------------------------------\n\nTITLE: Building IVF Index\nDESCRIPTION: This code shows how to build or rebuild an IVF (Inverted File) index. It calls the `buildIndex` method with the index name, cosine distance metric, and a configuration object specifying the IVF index type and parameters, such as 'lists' (number of lists to cluster vectors into).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Define IVF index\nawait pgVector.buildIndex(\"my_vectors\", \"cosine\", {\n  type: \"ivfflat\",\n  ivf: {\n    lists: 100,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Project Structure with Bash Commands\nDESCRIPTION: Sets up the initial project directory structure and installs required dependencies using npm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir research-assistant\ncd research-assistant\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y\nnpm install @mastra/core @mastra/rag @mastra/pg @ai-sdk/openai ai zod\n```\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/agents\ntouch src/mastra/agents/researchAgent.ts\ntouch src/mastra/index.ts src/store.ts src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables File\nDESCRIPTION: Command to create an environment variables file by copying the example template.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command to copy the example environment variables file to create a new .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Copying environment variables file\nDESCRIPTION: Copies the .env.example file to .env, enabling the user to configure environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/calling-agent-from-workflow/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Implementing Word Inclusion Metric Class\nDESCRIPTION: Defines a custom metric class that extends the base Metric class to evaluate word presence in text. Includes interface definition and core measurement logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/word-inclusion.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface WordInclusionResult extends MetricResult {\n  score: number;\n  info: {\n    totalWords: number;\n    matchedWords: number;\n  };\n}\n\nexport class WordInclusionMetric extends Metric {\n  private referenceWords: Set<string>;\n\n  constructor(words: string[]) {\n    super();\n    this.referenceWords = new Set(words);\n  }\n\n  async measure(input: string, output: string): Promise<WordInclusionResult> {\n    const matchedWords = [...this.referenceWords].filter(k => output.includes(k));\n    const totalWords = this.referenceWords.size;\n    const coverage = totalWords > 0 ? matchedWords.length / totalWords : 0;\n\n    return {\n      score: coverage,\n      info: {\n        totalWords: this.referenceWords.size,\n        matchedWords: matchedWords.length,\n      },\n    };\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the example with pnpm\nDESCRIPTION: Runs the example workflow script using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/calling-agent-from-workflow/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Creating a DeepgramVoice Instance with Configuration\nDESCRIPTION: This snippet shows how to import the DeepgramVoice class and create an instance with specified speech and listening models, as well as an optional speaker voice. This is essential for utilizing the TTS and STT functionalities provided by Deepgram.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DeepgramVoice } from '@mastra/voice-deepgram';\n\n// Create voice with both speech and listening capabilities\nconst voice = new DeepgramVoice({\n  speechModel: {\n    name: 'aura-asteria-en', // Default voice\n    apiKey: 'your-api-key', // Optional, can use DEEPGRAM_API_KEY env var\n  },\n  listeningModel: {\n    name: 'nova', // Optional, specify a listening model\n    apiKey: 'your-api-key', // Optional, can use DEEPGRAM_API_KEY env var\n  },\n  speaker: 'aura-athena-en', // Optional, specify a speaker voice\n});\n```\n\n----------------------------------------\n\nTITLE: Execute Workflow - TypeScript\nDESCRIPTION: Initializes Mastra with the defined workflow and executes it with simulated resume content. It retrieves the workflow, creates a run, and starts the run with trigger data containing the resume text. Finally, it logs the run ID and the final output of the workflow execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/ai-recruiter.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst mastra = new Mastra({\n  workflows: {\n    candidateWorkflow,\n  },\n});\n\n(async () => {\n  const { runId, start } = mastra.getWorkflow(\"candidateWorkflow\").createRun();\n\n  console.log(\"Run\", runId);\n\n  const runResult = await start({\n    triggerData: { resumeText: \"Simulated resume content...\" },\n  });\n\n  console.log(\"Final output:\", runResult.results);\n})();\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in .env File\nDESCRIPTION: This snippet shows the required format for specifying the OpenAI API key in a `.env` file.  The `OPENAI_API_KEY` environment variable should be set to the user's actual API key for proper authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_1\n\nLANGUAGE: .env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This snippet sets up the OPENAI_API_KEY environment variable, which is required to access the OpenAI API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-relevancy.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Upstash Vector Store in TypeScript\nDESCRIPTION: The `createIndex()` method is used to create an index in the Upstash vector database. This is automatically handled by Upstash, so this method is effectively a no-op. Parameters include index name, vector dimension, and optional distance metric for similarity search.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to create\",\n    },\n    {\n      name: \"dimension\",\n      type: \"number\",\n      description: \"Vector dimension (must match your embedding model)\",\n    },\n    {\n      name: \"metric\",\n      type: \"'cosine' | 'euclidean' | 'dotproduct'\",\n      isOptional: true,\n      defaultValue: \"cosine\",\n      description: \"Distance metric for similarity search\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Using CompositeVoice with OpenAI and PlayAI (Typescript)\nDESCRIPTION: This code snippet demonstrates how to use the CompositeVoice class to combine OpenAI for speech-to-text (listening) and PlayAI for text-to-speech (speaking) functionalities. It showcases the instantiation of voice providers and their integration into a CompositeVoice instance. Dependencies include the @mastra/core/voice, @mastra/voice-openai, and @mastra/voice-playai packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/composite-voice.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\n// Create voice providers\nconst openai = new OpenAIVoice();\nconst playai = new PlayAIVoice();\n\n// Use OpenAI for listening (speech-to-text) and PlayAI for speaking (text-to-speech)\nconst voice = new CompositeVoice({\n  input: openai,\n  output: playai\n});\n\n// Convert speech to text using OpenAI\nconst text = await voice.listen(audioStream);\n\n// Convert text to speech using PlayAI\nconst audio = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Evaluate Texts with Minor Differences\nDESCRIPTION: Demonstrates how to use TextualDifferenceMetric to evaluate two text strings with minor variations. The metric calculates a similarity score and provides details such as confidence, ratio, changes, and length difference, reflecting the variations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/textual-difference.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input2 = 'Hello world! How are you?';\nconst output2 = 'Hello there! How is it going?';\n\nconsole.log('Example 2 - Minor Differences:');\nconsole.log('Input:', input2);\nconsole.log('Output:', output2);\n\nconst result2 = await metric.measure(input2, output2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  info: {\n    confidence: result2.info.confidence,\n    ratio: result2.info.ratio,\n    changes: result2.info.changes,\n    lengthDiff: result2.info.lengthDiff,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Constructor for ElevenLabsVoice Class\nDESCRIPTION: This TypeScript snippet demonstrates how to create an instance of the ElevenLabsVoice class using the constructor. It accepts optional parameters for configuring the speech model and speaker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nnew ElevenLabsVoice({\n  speechModel?: {\n    name?: ElevenLabsModel, // Default: 'eleven_multilingual_v2'\n    apiKey?: string,        // Optional, can use ELEVENLABS_API_KEY env var\n  },\n  speaker?: string         // Default speaker ID\n})\n```\n\n----------------------------------------\n\nTITLE: Mastra Initialization - Basic\nDESCRIPTION: This snippet demonstrates the basic initialization of the Mastra class with an empty options object. It imports the Mastra class and creates a new instance named 'mastra'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/core/mastra-class.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\n// Basic initialization\nexport const mastra = new Mastra({});\n```\n\n----------------------------------------\n\nTITLE: Initializing SpeechifyVoice in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the SpeechifyVoice class with both default and custom configurations. It shows how to use the default API key from the environment variables and how to override the speech model and speaker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/speechify.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SpeechifyVoice } from \"@mastra/voice-speechify\";\n\n// デフォルトの設定で初期化（SPEECHIFY_API_KEY 環境変数を使用）\nconst voice = new SpeechifyVoice();\n\n// カスタム設定で初期化\nconst voice = new SpeechifyVoice({\n  speechModel: {\n    name: 'simba-english',\n    apiKey: 'your-api-key'\n  },\n  speaker: 'george'  // デフォルトの声\n});\n```\n\n----------------------------------------\n\nTITLE: Embedding Multiple Text Inputs with Mastra AI SDK\nDESCRIPTION: This code snippet demonstrates how to use the `embedMany` function from the Mastra AI SDK to generate vector embeddings for multiple text inputs. It imports the `embedMany` function, specifies the embedding model, an array of text inputs to embed, and the maximum number of retries for each embedding call.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/embeddings.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embedMany } from 'ai';\n\nconst result = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: [\"First text\", \"Second text\", \"Third text\"],\n  maxRetries: 2  // optional, defaults to 2\n});\n```\n\n----------------------------------------\n\nTITLE: Playing Audio Data in TypeScript\nDESCRIPTION: This code snippet demonstrates how to handle and play text-to-speech audio using React's `useEffect` hook. It monitors changes to `audioData`, creates a URL from the audio Blob, assigns it to an HTML audio element's `src` attribute, loads the audio, and attempts to play it automatically. Error handling is included for autoplay failures, and the effect cleans up by pausing the audio, revoking the URL, and clearing the source to prevent memory leaks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/text-to-speech.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nuseEffect(() => {\n  if (!audioRef.current || !audioData) return;\n\n  // Store a reference to the HTML audio element\n  const currentAudio = audioRef.current;\n\n  // Convert the Blob/File audio data from Mastra into a URL the browser can play\n  const url = URL.createObjectURL(audioData);\n\n  const playAudio = async () => {\n    try {\n      currentAudio.src = url;\n      await currentAudio.load();\n      await currentAudio.play();\n      setIsPlaying(true);\n    } catch (error) {\n      console.error('Auto-play failed:', error);\n    }\n  };\n\n  playAudio();\n\n  return () => {\n    if (currentAudio) {\n      currentAudio.pause();\n      currentAudio.src = '';\n      URL.revokeObjectURL(url);\n    }\n  };\n}, [audioData]);\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Core Package\nDESCRIPTION: Command to install the @mastra/core package using npm\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/core\n```\n\n----------------------------------------\n\nTITLE: Attaching Listeners for Evaluation Results with Vitest\nDESCRIPTION: This TypeScript snippet attaches listeners to capture evaluation results during Vitest tests. It imports `beforeAll` from `vitest` and `attachListeners` from `@mastra/evals`. The `beforeAll` hook ensures that listeners are attached before any test cases are executed, allowing the framework to capture and process evaluation results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/running-in-ci.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { beforeAll } from 'vitest';\nimport { attachListeners } from '@mastra/evals';\n\nbeforeAll(async () => {\n  await attachListeners();\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing API Route for Mastra Memory with Next.js\nDESCRIPTION: This code demonstrates a Next.js API route that processes messages from the useChat hook using Mastra's Agent and Memory systems. It handles the single message approach and returns a streaming response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/use-chat.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// app/api/chat/route.ts (Next.js Example)\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { CoreMessage } from \"@mastra/core\"; // Import CoreMessage\n\nconst agent = new Agent({\n  name: \"ChatAgent\",\n  instructions: \"You are a helpful assistant.\",\n  model: openai(\"gpt-4o\"),\n  memory: new Memory(), // Assumes default memory setup\n});\n\nexport async function POST(request: Request) {\n  // Get data structured by experimental_prepareRequestBody\n  const { message, threadId, resourceId }: { message: CoreMessage | null; threadId: string; resourceId: string } = await request.json();\n\n  // Handle cases where message might be null (e.g., initial load or error)\n  if (!message || !message.content) {\n    // Return an appropriate response or error\n    return new Response(\"Missing message content\", { status: 400 });\n  }\n\n  // Process with memory using the single message content\n  const stream = await agent.stream(message.content, {\n    threadId,\n    resourceId,\n    // Pass other message properties if needed, e.g., role\n    // messageOptions: { role: message.role }\n  });\n\n  // Return the streaming response\n  return stream.toDataStreamResponse();\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a ServerDefinition Instance - TypeScript\nDESCRIPTION: This snippet illustrates how to create an instance of the `ServerDefinition` class, which contains methods for introspection, validation, and serializing/deserializing server definitions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst server = new ServerDefinition({\n\tname,\n\tschema,\n\t...etc,\n})\n\nconst json = server.toJSON()\n// ...\nconst clientServer = new ServerDefinition(json)\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Voice Providers\nDESCRIPTION: 複数の音声プロバイダーを組み合わせて使用する方法を示します。OpenAIを音声認識（STT）に、PlayAIをテキストから音声（TTS）に使用します。CompositeVoiceクラスを使用して、これらのプロバイダーを統合し、音声インタラクションを実装します。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_30\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { playAudio, getMicrophoneStream } from \"@mastra/node-audio\";\n\n// STT用のOpenAI音声を初期化\nconst input = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// TTS用のPlayAI音声を初期化\nconst output = new PlayAIVoice({\n  speechModel: {\n    name: \"playai-voice\",\n    apiKey: process.env.PLAYAI_API_KEY,\n  },\n});\n\n// CompositeVoiceを使用してプロバイダーを組み合わせる\nconst voice = new CompositeVoice({\n  input,\n  output,\n});\n\n// 組み合わせた音声プロバイダーを使用して音声インタラクションを実装\nconst audioStream = getMicrophoneStream(); // この関数が音声入力を取得すると仮定\nconst transcript = await voice.listen(audioStream);\n\n// 文字起こしされたテキストをログに記録\nconsole.log(\"Transcribed text:\", transcript);\n\n// テキストを音声に変換\nconst responseAudio = await voice.speak(`You said: ${transcript}`, {\n  speaker: \"default\", // オプション：スピーカーを指定\n  responseFormat: \"wav\", // オプション：レスポンス形式を指定\n});\n\n// 音声レスポンスを再生\nplayAudio(responseAudio);\n```\n\n----------------------------------------\n\nTITLE: Updating a Vector Value\nDESCRIPTION: This code snippet shows how to update just the vector's numerical representation, leaving the metadata untouched. It uses the `updateIndexById` function to only modify the vector array. The index name and the ID of the vector to update must be provided.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Update just the vector\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  vector: [0.1, 0.2, 0.3],\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Response Types in Upstash Vector Store in TypeScript\nDESCRIPTION: This code snippet defines the expected structure of query result responses. It includes properties for ID, score, metadata, and optionally the vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating response with complete hallucination (TypeScript)\nDESCRIPTION: This snippet evaluates a response that completely contradicts the provided context. It initializes the HallucinationMetric with a context array and measures the hallucination score of a query and a response that is entirely inconsistent with the context. The expected output is a score of 1, indicating complete hallucination.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/hallucination.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'ライト兄弟は1903年に初飛行を行いました。',\n  '飛行は12秒間続きました。',\n  '120フィートの距離をカバーしました。',\n];\n\nconst metric3 = new HallucinationMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'ライト兄弟はいつ初飛行をしましたか？';\nconst response3 = 'ライト兄弟は1908年に歴史的な初飛行を達成しました。飛行は約2分間続き、ほぼ1マイルをカバーしました。';\n\nconsole.log('例3 - 完全なハルシネーション:');\nconsole.log('コンテキスト:', context3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 1, reason: '応答はコンテキストに完全に矛盾しています。' }\n```\n\n----------------------------------------\n\nTITLE: Starting a Workflow Execution in Typescript\nDESCRIPTION: This code snippet demonstrates how to start a workflow execution using the `start()` method, including creating a run and providing initial data through `triggerData`. The code initializes a workflow run, then calls start with a triggerData object. The result will contain the status and combined outputs of the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/start.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start } = workflow.createRun();\nconst result = await start({ \n  triggerData: { inputValue: 42 } \n});\n```\n\n----------------------------------------\n\nTITLE: Mastra Voice Speechify Deprecation\nDESCRIPTION: Deprecates the `@mastra/speech-speechify` package in favor of `@mastra/voice-speechify`. The changes include renaming the package, classes, and methods for a more consistent naming scheme. Import paths should be updated accordingly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/CHANGELOG.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n- f477df7: deprecate @mastra/speech-speechify for @mastra/voice-speechify\n```\n\n----------------------------------------\n\nTITLE: Initializing File Transport\nDESCRIPTION: Configuration example for FileTransport that writes logs to a local file system with specified path.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/loggers/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { FileTransport } from '@mastra/loggers';\n\nconst fileLogger = new FileTransport({\n  path: '/path/to/logs/app.log',\n});\n```\n\n----------------------------------------\n\nTITLE: Creating API Route with Mastra in NextJS\nDESCRIPTION: Example of a NextJS API route that uses Mastra to stream weather information responses.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from '@/mastra'\nimport { NextResponse } from 'next/server'\n\nexport async function POST(req: Request) {\n  const { city } = await req.json()\n  const agent = mastra.getAgent('weatherAgent')\n\n  const result = await agent.stream(`What's the weather like in ${city}?`)\n\n  return result.toDataStreamResponse()\n}\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project with flags\nDESCRIPTION: This command uses npx to create a new Mastra project in non-interactive mode with specified components and an example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest  --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a copy of the example environment variables file for local configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Initializing Google Voice Configuration\nDESCRIPTION: Google音声プロバイダーの初期化設定を示します。音声認識とテキスト変換のためのモデル名、APIキー、言語コード、性別、話速、およびサンプリングレートを指定します。この設定により、MastraはGoogleの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\n// Google Voice Configuration\nconst voice = new GoogleVoice({\n  speechModel: {\n    name: \"en-US-Studio-O\", // Example model name\n    apiKey: process.env.GOOGLE_API_KEY,\n    languageCode: \"en-US\", // Language code\n    gender: \"FEMALE\", // Voice gender\n    speakingRate: 1.0, // Speaking rate\n  },\n  listeningModel: {\n    name: \"en-US\", // Example model name\n    sampleRateHertz: 16000, // Sample rate\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: CloudflareVoice Initialization - Native Bindings\nDESCRIPTION: Initializes the CloudflareVoice class using Native Bindings. It requires the AI binding from the environment and configures the listening model to use '@cf/openai/whisper-large-v3-turbo'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/cloudflare/README.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CloudflareVoice } from '@mastra/voice-cloudflare';\n\n// Native Bindings\nconst voice = new CloudflareVoice({\n  binding: env.AI,\n  listeningModel: {\n    model: '@cf/openai/whisper-large-v3-turbo',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Memory Todo Agent Version History in Markdown\nDESCRIPTION: A changelog documenting version updates, dependency changes, and patch releases for the memory-todo-agent package and its dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-todo-agent/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# memory-todo-agent\n\n## 0.1.6\n\n## 0.1.6-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [06aa827]\n  - @mastra/core@0.4.3-alpha.0\n  - @mastra/memory@0.1.6-alpha.0\n```\n\n----------------------------------------\n\nTITLE: Evaluating High-Quality Summary\nDESCRIPTION: Evaluates a high-quality summary against its source text using the configured `SummarizationMetric`. The example demonstrates how to use the `measure` method to assess the score, alignment, and coverage of a summary that maintains perfect factual accuracy and includes all key information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = `The electric car company Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning. \nElon Musk joined in 2004 as the largest investor and became CEO in 2008. The company's first car, \nthe Roadster, was launched in 2008.`;\n\nconst output1 = `Tesla, founded by Martin Eberhard and Marc Tarpenning in 2003, launched its first car, \nthe Roadster, in 2008. Elon Musk joined as the largest investor in 2004 and became CEO in 2008.`;\n\nconsole.log('Example 1 - High-quality Summary:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    reason: result1.info.reason,\n    alignmentScore: result1.info.alignmentScore,\n    coverageScore: result1.info.coverageScore,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 1,\n//   info: {\n//     reason: \"The score is 1 because the summary maintains perfect factual accuracy and includes all key information from the source text.\",\n//     alignmentScore: 1,\n//     coverageScore: 1\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/core Package (npm/yarn)\nDESCRIPTION: This bash command demonstrates how to install the `@mastra/core` package using either npm or yarn. The package is essential for using Mastra's core functionalities, including agent creation and management. The command ensures that all necessary dependencies are installed for the project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/core\n```\n\n----------------------------------------\n\nTITLE: Using LibSQLVector for Vector Storage\nDESCRIPTION: This code snippet demonstrates how to use the `LibSQLVector` class to create, manage, and query vector embeddings. It includes creating a new vector store instance, creating an index, adding vectors with metadata, and querying similar vectors with optional metadata filtering.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/libsql.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\n// Create a new vector store instance\nconst store = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  // Optional: for Turso cloud databases\n  authToken: process.env.DATABASE_AUTH_TOKEN,\n});\n\n// Create an index\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\n\n// Add vectors with metadata\nconst vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];\nconst metadata = [\n  { text: \"first document\", category: \"A\" },\n  { text: \"second document\", category: \"B\" }\n];\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors,\n  metadata,\n});\n\n// Query similar vectors\nconst queryVector = [0.1, 0.2, ...];\nconst results = await store.query({\n  indexName: \"myCollection\",\n  queryVector,\n  topK: 10, // top K results\n  filter: { category: \"A\" } // optional metadata filter\n});\n```\n\n----------------------------------------\n\nTITLE: Using afterEvent in Mastra Workflow (TypeScript)\nDESCRIPTION: This snippet shows how to use the `afterEvent` method to create a suspension point in a Mastra workflow, waiting for a specific event. The workflow execution pauses at this point until the specified event is triggered.  It depends on the `workflow` instance defined earlier.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(initialProcessStep)\n  .afterEvent('approvalReceived')  // ワークフローはここで中断します\n  .step(postApprovalStep)          // これはイベント受信後に実行されます\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Faithfulness Response in TypeScript\nDESCRIPTION: Illustrates how to evaluate a response that contradicts the provided context, resulting in a low faithfulness score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'Mars is the fourth planet from the Sun.',\n  'It has a thin atmosphere of mostly carbon dioxide.',\n  'Two small moons orbit Mars: Phobos and Deimos.',\n];\n\nconst metric3 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'What do we know about Mars?';\nconst response3 = 'Mars is the third planet from the Sun. It has a thick atmosphere rich in oxygen and nitrogen, and is orbited by three large moons.';\n\nconsole.log('Example 3 - Low Faithfulness:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response contradicts the context.' }\n```\n\n----------------------------------------\n\nTITLE: Chunking MDocument (Instance Method)\nDESCRIPTION: Splits the document into chunks. Accepts optional ChunkParams to configure chunking strategy, headers for extraction, and metadata extraction settings.  Returns a Promise that resolves to an array of Chunk objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync chunk(params?: ChunkParams): Promise<Chunk[]>\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（OpenAI）\nDESCRIPTION: OpenAIを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、OpenAIVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow via API in Mastra (Bash)\nDESCRIPTION: This curl command shows how to execute a Mastra workflow via API, sending a POST request to start the workflow asynchronously with input data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'http://localhost:4111/api/workflows/myWorkflow/start-async' \\\n     --header 'Content-Type: application/json' \\\n     --data '{\n       \"inputValue\": 45\n     }'\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory\nDESCRIPTION: Commands for cloning the Mastra repository from GitHub and navigating to the context relevancy example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-relevancy/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/context-relevancy\n```\n\n----------------------------------------\n\nTITLE: Installing Zod Package (npm/yarn)\nDESCRIPTION: This bash command demonstrates installing the Zod library using either npm or yarn. Zod is used for defining schemas and validating structured output from Mastra agents. Installing it enables type-safe structured outputs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nnpm install zod\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Deployer Package\nDESCRIPTION: Commands for installing the @mastra/deployer package via npm\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/deployer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/deployer\n```\n\n----------------------------------------\n\nTITLE: Configure Vercel OpenTelemetry\nDESCRIPTION: This snippet creates an instrumentation file to register Vercel's OpenTelemetry setup. It registers the OpenTelemetry provider with a specified service name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { registerOTel } from '@vercel/otel'\n\nexport function register() {\n  registerOTel({ serviceName: 'your-project-name' })\n}\n```\n\n----------------------------------------\n\nTITLE: Listening to Audio Stream and Generating Text\nDESCRIPTION: This snippet demonstrates how to listen to an audio stream using Sarvam Voice to generate the corresponding text output from the audio input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst text = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository for RAG Implementation\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the filter-rag example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/filter-rag\n```\n\n----------------------------------------\n\nTITLE: Advanced GraphRAG Usage\nDESCRIPTION: This code snippet demonstrates an advanced example of using the GraphRAG class with custom parameters. It initializes the class with a stricter similarity threshold and then queries the graph with adjusted values for `topK`, `randomWalkSteps`, and `restartProb`, allowing for more precise control over the search process and result ranking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/graph-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphRag = new GraphRAG({\n  dimension: 1536,\n  threshold: 0.8  // Stricter similarity threshold\n});\n\n// Create graph from chunks and embeddings\ngraphRag.createGraph(documentChunks, embeddings);\n\n// Query with custom parameters\nconst results = await graphRag.query({\n  query: queryEmbedding,\n  topK: 5,\n  randomWalkSteps: 200,\n  restartProb: 0.2\n});\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File in Bash\nDESCRIPTION: Command to create a copy of the example environment file for local configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Function Condition in Workflow.if()\nDESCRIPTION: This snippet shows how to use a function condition within the `.if()` method. The function retrieves a result from a previous step and checks its `status` property.  Based on the status, different steps (`successStep` or `failureStep`) are executed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/if.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(startStep)\n  .if(async ({ context }) => {\n    const result = context.getStepResult<{ status: string }>('start');\n    return result?.status === 'success'; // ステータスが \"success\" の場合に \"if\" ブランチを実行\n  })\n  .then(successStep)\n  .else()\n  .then(failureStep);\n```\n\n----------------------------------------\n\nTITLE: Testing Research Assistant Implementation\nDESCRIPTION: Demonstrates how to use the research assistant to query paper content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./mastra\";\nconst agent = mastra.getAgent('researchAgent');\n\nconst query1 = \"What problems does sequence modeling face with neural networks?\";\nconst response1 = await agent.generate(query1);\nconsole.log(\"\\nQuery:\", query1);\nconsole.log(\"Response:\", response1.text);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = \"What improvements were achieved in translation quality?\";\nconst response2 = await agent.generate(query2);\nconsole.log(\"\\nQuery:\", query2);\nconsole.log(\"Response:\", response2.text);\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the necessary project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Using Workflow.until() with incrementStep\nDESCRIPTION: This snippet demonstrates the basic usage of the `.until()` method within a Mastra workflow.  It shows how to repeat an `incrementStep` until a certain condition is met, followed by a `finalStep`. The condition is a placeholder and must be defined elsewhere.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/until.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nworkflow\n  .step(incrementStep)\n  .until(condition, incrementStep)\n  .then(finalStep);\n```\n```\n\n----------------------------------------\n\nTITLE: Working with a Specific Tool - TypeScript\nDESCRIPTION: Fetches an instance of a specific tool using its tool ID. This snippet is used to access methods related to a specific tool after obtaining its instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/tools.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst tool = client.getTool(\"tool-id\");\n```\n\n----------------------------------------\n\nTITLE: IndexStats Interface Definition\nDESCRIPTION: Defines the structure of the IndexStats object returned by the describeIndex() method. It includes the dimension, count, and metric properties of the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/vectorize.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating No Toxicity Response\nDESCRIPTION: This TypeScript snippet evaluates a constructive and professional response. The response focuses on providing feedback on a project proposal without any personal attacks or harmful language. The `ToxicityMetric` assigns a score of 0, indicating no toxicity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'Can you provide feedback on the project proposal?';\nconst response3 =\n  'The proposal has strong points in its technical approach but could benefit from more detailed market analysis. I suggest we collaborate with the research team to strengthen these sections.';\n\nconsole.log('Example 3 - No Toxicity:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response is professional and constructive, focusing on specific aspects without any personal attacks or harmful language.' }\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to the Project Directory\nDESCRIPTION: Commands to clone the Mastra GitHub repository and navigate to the tone-consistency example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/tone-consistency/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/tone-consistency\n```\n\n----------------------------------------\n\nTITLE: Configure Custom OpenTelemetry Exporter with Langfuse\nDESCRIPTION: This snippet creates an instrumentation file to configure a custom OpenTelemetry exporter, using Langfuse in this example.  It sets up the NodeSDK with a Langfuse exporter and configures the service name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  NodeSDK,\n  ATTR_SERVICE_NAME,\n  Resource,\n} from '@mastra/core/telemetry/otel-vendor';\nimport { LangfuseExporter } from 'langfuse-vercel';\n\nexport function register() {\n  const exporter = new LangfuseExporter({\n    // ... Langfuse 設定\n  })\n\n  const sdk = new NodeSDK({\n    resource: new Resource({\n      [ATTR_SERVICE_NAME]: 'ai',\n    }),\n    traceExporter: exporter,\n  });\n\n  sdk.start();\n}\n```\n\n----------------------------------------\n\nTITLE: Validating Server Configuration - TypeScript\nDESCRIPTION: In this snippet, the user input from the server UI is validated against the `ServerDefinition`. It ensures that the configuration is valid and throws an error if it is not, providing a safeguard before use or persistence.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst validConfig = stripeServer.parseConfig(userInput) // will throw if config is not valid\n```\n\n----------------------------------------\n\nTITLE: Setting Server Port and Timeout in Mastra - TypeScript\nDESCRIPTION: This code snippet shows how to configure the port and timeout settings for the Mastra server instance. The port is set to 3000 and the timeout is set to 10000 milliseconds (10 seconds). If these settings are not specified, the port defaults to 4111 and the timeout defaults to 30000 milliseconds (30 seconds).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  server: {\n    port: 3000, // Defaults to 4111\n    timeout: 10000, // Defaults to 30000 (30s)\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: DocumentNode Interface Definition in Typescript\nDESCRIPTION: This code snippet shows the structure of the `DocumentNode` interface, which represents a chunk of the document after the chunking process. It includes properties for text, metadata, and optionally an embedding vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ninterface DocumentNode {\n  text: string;\n  metadata: Record<string, any>;\n  embedding?: number[];\n}\n```\n\n----------------------------------------\n\nTITLE: Creating MDocument from Markdown (Static Method)\nDESCRIPTION: Creates an MDocument instance from Markdown content.  Takes a Markdown string and an optional metadata object.  Returns an MDocument object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromMarkdown(markdown: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Initializing MCPServer with Tools\nDESCRIPTION: This code snippet demonstrates how to create a new MCPServer instance with a name, version, and a set of tools. It imports the MCPServer class and a weatherTool (assumed to be defined in a separate file) and then initializes the server with these properties.  This allows the server to expose the weatherTool to MCP clients.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MCPServer } from \"@mastra/mcp\";\nimport { weatherTool } from \"./tools\"; // Assuming you have a weather tool defined in this file\n\nconst server = new MCPServer({\n  name: \"My Weather Server\",\n  version: \"1.0.0\",\n  tools: { weatherTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Mem0 Integration\nDESCRIPTION: Command to install the Mem0 integration package\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/mem0\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands for cloning the Mastra repository and navigating to the custom evaluation example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/custom-eval\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Mastra RAG System\nDESCRIPTION: Imports necessary dependencies for implementing the RAG system with Mastra, OpenAI, and PGVector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PgVector } from '@mastra/pg';\nimport { MDocument, rerank } from '@mastra/rag';\nimport { embedMany, embed } from 'ai';\n```\n\n----------------------------------------\n\nTITLE: Setting Up the Project Environment in Bash\nDESCRIPTION: This snippet contains Bash commands to clone the GitHub repository to your local machine and navigate to the project directory. It is the first step to set up the Bird Checker Agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/bird-checker\n```\n\n----------------------------------------\n\nTITLE: Running the Adjust Chunk Delimiters Example\nDESCRIPTION: Command to execute the example application that demonstrates how to adjust chunk delimiters in Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-delimiters/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Memory Module Changelog\nDESCRIPTION: Markdown changelog documenting version history and dependency updates for the memory module and its dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-pg/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# memory\n\n## 1.0.1\n\n## 1.0.1-alpha.65\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/memory@0.1.0-alpha.67\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/store-pg@0.0.0-alpha.3\n  - @mastra/vector-pg@0.0.1-alpha.19\n```\n\n----------------------------------------\n\nTITLE: Automatic Installation - Create Mastra Project (yarn)\nDESCRIPTION: This command initiates the automatic installation of a new Mastra project using the `create-mastra` package with yarn. It scaffolds the project with necessary configurations and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project with timeout\nDESCRIPTION: This command uses npx to create a new Mastra project with a specified timeout value for installation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest --timeout\n```\n\n----------------------------------------\n\nTITLE: OTLP Endpoint and Headers Configuration via Environment Variables (env)\nDESCRIPTION: This code snippet shows how to configure the OTLP endpoint and headers using environment variables. The `OTEL_EXPORTER_OTLP_ENDPOINT` variable sets the endpoint, and `OTEL_EXPORTER_OTLP_HEADERS` sets custom headers for the OTLP exporter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/tracing.mdx#_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\nOTEL_EXPORTER_OTLP_HEADERS=x-api-key=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for OpenAI and Postgres\nDESCRIPTION: Example environment variable configuration needed for the RAG application. Requires adding an OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/basic-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Manual Cyclic Dependency (Legacy) in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create a loop in Mastra workflows using conditional dependencies (legacy approach).  It shows a conditional execution of the `fetchData` step based on the status of the `processData` step. This approach is now superseded by `until` and `while` methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(fetchData)\n  .then(processData)\n  .after(processData)\n  .step(finalizeData, {\n    when: { \"processData.status\": \"success\" },\n  })\n  .step(fetchData, {\n    when: { \"processData.status\": \"retry\" },\n  });\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server in Cursor (Windows)\nDESCRIPTION: This JSON snippet configures the Model Context Protocol (MCP) server for Mastra documentation tools within the Cursor IDE on Windows systems.  It uses the 'cmd' command to execute the @mastra/mcp-docs-server package with npx.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/README.md#_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"cmd\",\n      \"args\": [\"/c\", \"npx\", \"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Changelog Entries in Markdown\nDESCRIPTION: Version history documenting changes across multiple alpha releases and dependencies updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# cleanup-rag\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pg@0.0.1-alpha.19\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pg@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [72f7fb9]\n- Updated dependencies [9625602]\n  - @mastra/vector-pg@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Creating MDocument from JSON (Static Method)\nDESCRIPTION: Creates an MDocument instance from JSON content. Accepts a JSON string and an optional metadata object. Returns an MDocument object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromJSON(json: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Installing MastraClient using pnpm\nDESCRIPTION: This command installs the @mastra/client-js package using the pnpm package manager. This package is required for interacting with the Mastra backend.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Configuring Storage and Vector Database\nDESCRIPTION: This code snippet configures the storage and vector database for semantic recall. It uses `LibSQLStore` and `LibSQLVector` from `@mastra/libsql` for storing messages and their embeddings, respectively. It provides a local file path for the database connection. If omitted, these default to the specified configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { LibSQLStore, LibSQLVector } from \"@mastra/libsql\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    // this is the default storage db if omitted\n    storage: new LibSQLStore({\n      url: \"file:./local.db\",\n    }),\n    // this is the default vector db if omitted\n    vector: new LibSQLVector({\n      connectionUrl: \"file:./local.db\",\n    }),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Schema Configuration Function for Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet illustrates how to define a callback for schema configuration using the schemaConfigForIndex option, allowing dynamic schema definitions based on index names.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nschemaConfigForIndex: (indexName: string) => {\n  // Mastra's default embedding model and index for memory messages:\n  if (indexName === \"memory_messages_384\") {\n    return {\n      dimensions: 384,\n      schema: {\n        thread_id: {\n          type: \"string\",\n          filterable: true,\n        },\n      },\n    };\n  } else {\n    throw new Error(`TODO: add schema for index: ${indexName}`);\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: MCP Server Configuration (Windows) - JSON\nDESCRIPTION: This JSON snippet configures the Mastra MCP server in Cursor or Windsurf on Windows systems. It specifies the command to execute (cmd) and the arguments, including the /c flag, to execute npx.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/mcp-docs-server.mdx#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"cmd\",\n      \"args\": [\"/c\", \"npx\", \"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Mastra Build Command in Bash\nDESCRIPTION: Demonstrates the basic usage of the 'mastra build' command and its options. It shows how to build from the current directory and from a specific directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/build.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Build from current directory\nmastra build\n\n# Build from specific directory\nmastra build --dir ./my-mastra-project\n```\n\n----------------------------------------\n\nTITLE: Calling Agent from Command Line (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates how to call an agent directly from the command line. It imports the `mastra` instance and retrieves the `weatherAgent` using `mastra.getAgent(\"weatherAgent\")`. It then calls the `generate` method on the agent with the query \"What is the weather in London?\" and logs the agent's response to the console. This provides a way to interact with agents programmatically without relying on REST API endpoints.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_28\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./mastra\";\n\nasync function main() {\n  const agent = await mastra.getAgent(\"weatherAgent\");\n\n  const result = await agent.generate(\"What is the weather in London?\");\n\n  console.log(\"Agent response:\", result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Configuring Netlify Deployer with team slug, project name and token\nDESCRIPTION: This code snippet demonstrates configuring the NetlifyDeployer with essential parameters like team slug, project name, and authentication token. Ensure to replace placeholders such as 'your-netlify-team-slug', 'your-project-name', and 'your-netlify-token' with your actual Netlify credentials for proper deployment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n\"new NetlifyDeployer({\n  scope: 'your-netlify-team-slug',\n  projectName: 'your-project-name',\n  token: 'your-netlify-token'\n})\"\n```\n\n----------------------------------------\n\nTITLE: Running the Tone Consistency Example\nDESCRIPTION: Command to start the tone consistency evaluation example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/tone-consistency/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Implementing Server Actions with Mastra\nDESCRIPTION: Example of creating a server action that uses Mastra to get weather information and can be called from client components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n'use server'\n\nimport { mastra } from '@/mastra'\n\nexport async function getWeatherInfo(city: string) {\n  const agent = mastra.getAgent('weatherAgent')\n  \n  const result = await agent.generate(`What's the weather like in ${city}?`)\n\n  return result\n}\n```\n\n----------------------------------------\n\nTITLE: Installing ElevenLabs Voice Module using npm\nDESCRIPTION: This snippet demonstrates how to install the ElevenLabs voice module for Mastra via npm. It requires Node.js and npm to be installed on the system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-elevenlabs\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory\nDESCRIPTION: Command to clone the Mastra repository from GitHub and navigate to the rerank-rag example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/rerank-rag\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（ElevenLabs）\nDESCRIPTION: ElevenLabsを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、ElevenLabsVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new ElevenLabsVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: SpeechifyConfig Interface (TypeScript)\nDESCRIPTION: Defines the `SpeechifyConfig` interface for configuring the Speechify speech model. It allows specifying the model name and API key. The API key can also be provided through the `SPEECHIFY_API_KEY` environment variable. These configurations are used when instantiating the `SpeechifyVoice` class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ninterface SpeechifyConfig {\n  name?: string; // Optional Speechify model name (default: 'simba-english')\n  apiKey?: string; // Optional API key (can also use env var)\n}\n\nnew SpeechifyVoice({\n  speechModel?: SpeechifyConfig,\n  speaker?: string // Optional default speaker ID\n})\n```\n\n----------------------------------------\n\nTITLE: Building UI Based on Server Definition - TypeScript\nDESCRIPTION: This snippet shows how to build a user interface from a server schema definition. It utilizes the schema of a specific server (e.g., Stripe) to facilitate user input for configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst userInput = await buildServerUI(stripeServer.schema)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Context Position Adherence\nDESCRIPTION: This snippet demonstrates evaluating a response with low adherence to context position, where relevant information appears last. It defines the context, query, and response, then measures the adherence with the ContextPositionMetric, logging the score and associated reasoning.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-position.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  '虹は空に現れます。',\n  '虹にはさまざまな色があります。',\n  '虹は曲がった形をしています。',\n  '虹は太陽光が水滴に当たるときに形成されます。',\n];\n\nconst metric3 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = '虹はどのように形成されますか？';\nconst response3 = '虹は太陽光が空中の水滴と相互作用することで作られます。';\n\nconsole.log('例3 - 低い位置の順守:');\nconsole.log('コンテキスト:', context3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.12, reason: 'コンテキストにはいくつかの関連情報が含まれていますが、ほとんどの関連情報は最後にあります。' }\n```\n\n----------------------------------------\n\nTITLE: Defining Publisher Agent in Typescript\nDESCRIPTION: This snippet creates a 'Publisher' agent, responsible for coordinating the other agents. It calls the 'Copywriter' agent to generate initial content, then calls the 'Editor' agent to refine the content. The Publisher agent uses the Claude model and has access to both the copywriter and editor tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/hierarchical-multi-agent.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst publisherAgent = new Agent({\n  name: \"publisherAgent\",\n  instructions:\n    \"あなたは特定のトピックについてブログ投稿のコピーを書くためにまずコピーライターエージェントを呼び出し、その後コピーを編集するためにエディターエージェントを呼び出すパブリッシャーエージェントです。最終的な編集済みのコピーのみを返します。\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n  tools: { copywriterTool, editorTool },\n});\n\nconst mastra = new Mastra({\n  agents: { publisherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: This bash snippet sets the OpenAI API key as an environment variable, which is required for authenticating with the OpenAI service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/toxicity.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Project\nDESCRIPTION: Command to create a new Mastra project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Initialize a new project\nmastra init\n```\n\n----------------------------------------\n\nTITLE: Describe Index Interface (TypeScript)\nDESCRIPTION: Defines the structure of the object returned by the `describeIndex` method, containing information about the index such as its dimensions, count, and metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/turbopuffer.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Dane AI Assistant via NPM\nDESCRIPTION: Command to install Dane directly from npm using the alpha version tag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/dane/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g @mastra/dane@alpha\n```\n\n----------------------------------------\n\nTITLE: Cloning and navigating to the project directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the example directory for inserting embeddings in Pinecone.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/insert-embedding-in-pinecone\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using Mastra Deployer\nDESCRIPTION: Example showing how to create and use a Deployer instance, including initialization, dependency installation, and package.json management\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/deployer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Deployer } from '@mastra/deployer';\n\n// Create a deployer instance\nconst deployer = new Deployer({\n  dir: '/path/to/project',\n  type: 'Deploy', // or 'Dev' for development mode\n});\n\n// Install dependencies\nawait deployer.install();\n\n// Write package.json\nawait deployer.writePackageJson();\n\n// Get Mastra instance\nconst { mastra } = await deployer.getMastra();\n```\n\n----------------------------------------\n\nTITLE: Circular Dependency Error Handling in Workflow (TypeScript)\nDESCRIPTION: This snippet demonstrates error handling for circular dependencies when using the `.then()` method. It attempts to add `stepA` twice in the same chain, which will throw a `ValidationError` because it forms a circular dependency. The code catches this specific error type and logs the error type and details to the console. Requires pre-existing `workflow` and `stepA`, `stepB` objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/then.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  workflow\n    .step(stepA)\n    .then(stepB)\n    .then(stepA) // Will throw error - circular dependency\n    .commit();\n} catch (error) {\n  if (error instanceof ValidationError) {\n    console.log(error.type); // 'circular_dependency'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing MurfVoice with custom settings\nDESCRIPTION: This snippet shows how to initialize the MurfVoice class with custom settings, including the speech model name, API key, and voice properties like format, rate, pitch, sample rate, and channel type.  It also specifies a default speaker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/murf.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// カスタム設定で初期化\nconst voice = new MurfVoice({\n  speechModel: {\n    name: 'GEN2',\n    apiKey: 'your-api-key',\n    properties: {\n      format: 'MP3',\n      rate: 1.0,\n      pitch: 1.0,\n      sampleRate: 48000,\n      channelType: 'STEREO',\n    },\n  },\n  speaker: 'en-US-cooper',\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing TextualDifferenceMetric and Measuring Differences - TypeScript\nDESCRIPTION: This snippet demonstrates how to instantiate the `TextualDifferenceMetric` class and utilize its `measure` method to determine the similarity and differences between two strings. The resulting score and metrics are logged to the console. Dependencies include the `@mastra/evals/nlp` library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/textual-difference.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new TextualDifferenceMetric();\n\nconst result = await metric.measure(\n  \"The quick brown fox\",\n  \"The fast brown fox\"\n);\n\nconsole.log(result.score); // Similarity ratio from 0-1\nconsole.log(result.info); // Detailed change metrics\n```\n\n----------------------------------------\n\nTITLE: Converting Speech to Text using SarvamVoice TypeScript\nDESCRIPTION: This snippet demonstrates how to convert speech to text using the SarvamVoice class. It initializes the class and calls the `listen` method with an audio stream and file type option, returning the transcribed text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/sarvam.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// 音声をテキストに変換\nconst text = await voice.listen(audioStream, {\n  filetype: \"wav\",\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Voice Configuration\nDESCRIPTION: OpenAI音声プロバイダーの初期化設定を示します。音声認識とテキスト変換のためのモデル名、APIキー、言語、音声タイプ、およびスピーカーを指定します。この設定により、MastraはOpenAIの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\n// OpenAI Voice Configuration\nconst voice = new OpenAIVoice({\n  speechModel: {\n    name: \"gpt-3.5-turbo\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    language: \"en-US\", // Language code\n    voiceType: \"neural\", // Type of voice model\n  },\n  listeningModel: {\n    name: \"whisper-1\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    language: \"en-US\", // Language code\n    format: \"wav\", // Audio format\n  },\n  speaker: \"alloy\", // Example speaker name\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Keys in Bash\nDESCRIPTION: Configure the necessary environment variables by creating a .env file containing the OpenAI API key required for evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Basic ContextRelevancyMetric Usage\nDESCRIPTION: Demonstrates basic usage of the ContextRelevancyMetric class to evaluate the relevance of retrieved context to an input query. It initializes the metric with an OpenAI model and a predefined context, then measures the relevance of a provided output. The code showcases how to access the score and the explanation of the relevancy assessment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-relevancy.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextRelevancyMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextRelevancyMetric(model, {\n  context: [\n    \"All data is encrypted at rest and in transit\",\n    \"Two-factor authentication is mandatory\",\n    \"The platform supports multiple languages\",\n    \"Our offices are located in San Francisco\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"What are our product's security features?\",\n  \"Our product uses encryption and requires 2FA.\",\n  );\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info.reason); // Explanation of the relevancy assessment\n```\n\n----------------------------------------\n\nTITLE: Running the Text Chunking Example\nDESCRIPTION: Command to start the text chunking example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-text/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository - Bash\nDESCRIPTION: This code snippet demonstrates the command to clone the repository for the OpenAPI spec generator application. It ensures that the local environment is set up for development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone <repository-url>\ncd openapi-spec-generator\n```\n\n----------------------------------------\n\nTITLE: Installing Upstash Storage Package\nDESCRIPTION: This command installs the Upstash storage package for Mastra using npm. It's a prerequisite for using Upstash as a storage solution within the Mastra project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/upstash.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/upstash\n```\n\n----------------------------------------\n\nTITLE: Update Dependencies\nDESCRIPTION: These updates include modifications to dependencies such as @mastra/core.  The updates are triggered by various commit hashes such as 'a910463' and affect multiple package versions. The general effect is that various subcomponents of the mastra system are kept up to date.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/CHANGELOG.md#_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install required project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-sequential-steps/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text using ElevenLabs Voice\nDESCRIPTION: This TypeScript snippet shows how to convert text to speech using the speak method of the ElevenLabsVoice instance. It allows specifying the speaker and requires an input text to generate speech output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await voice.speak('Hello from Mastra!', {\n  speaker: 'Adam', // Optional, defaults to constructor speaker\n});\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Example 3\nDESCRIPTION: This command demonstrates how to run `create-mastra` non-interactively, specifying the project name both as an argument and as an option. The argument takes precedence.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest my-app --project-name ignored-name --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Configuring Cohere API Key\nDESCRIPTION: Example of how to set up the Cohere API key in the environment variables file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nCOHERE_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for OpenAI and LibSQL\nDESCRIPTION: Instructions for copying the example environment file and configuring it with OpenAI API key and LibSQL connection details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Importing Necessary Dependencies in TypeScript\nDESCRIPTION: Imports the required modules for embedding generation, PGVector interaction, and OpenAI integration. This includes the `embed` function from the `ai` library, `PgVector` from `@mastra/pg`, and `openai` from `@ai-sdk/openai`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/hybrid-vector-search.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed } from 'ai';\nimport { PgVector } from '@mastra/pg';\nimport { openai } from '@ai-sdk/openai';\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Processors\nDESCRIPTION: This code snippet demonstrates how to create a `Memory` instance with `TokenLimiter` and `ToolCallFilter` processors. These processors are used to limit token usage and filter tool calls, respectively. The order of processors in the `processors` array determines the order of execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Memory } from \\\"@mastra/memory\\\";\nimport { TokenLimiter, ToolCallFilter } from \\\"@mastra/memory/processors\\\";\n\n// Create memory with processors\nconst memory = new Memory({\n  processors: [new TokenLimiter(127000), new ToolCallFilter()],\n});\"\n```\n\n----------------------------------------\n\nTITLE: Version Information in Markdown\nDESCRIPTION: Shows the package name and version number for memory-with-context package using markdown formatting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-context/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# memory-with-context\n\n## 0.0.1\n```\n\n----------------------------------------\n\nTITLE: Preventing Memory Leaks in MCPConfiguration\nDESCRIPTION: This example illustrates how to prevent memory leaks when using MCPConfiguration, especially when creating multiple instances with the same configuration. It shows how providing a unique `id` to each instance or calling `disconnect()` before re-creating an instance can resolve the issue.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// 最初のインスタンス - OK\nconst mcp1 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n\n// 同じ設定での2番目のインスタンス - エラーが発生します\nconst mcp2 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n\n// 修正方法:\n// 1. 一意のIDを追加\nconst mcp3 = new MCPConfiguration({\n  id: \"instance-1\",\n  servers: {\n    /* ... */\n  },\n});\n\n// 2. または再作成前に切断\nawait mcp1.disconnect();\nconst mcp4 = new MCPConfiguration({\n  servers: {\n    /* ... */\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring LangSmith Environment Variables\nDESCRIPTION: This snippet demonstrates the environment variables required to configure LangSmith for tracing.  You need to set `LANGSMITH_TRACING` to true, provide the LangSmith endpoint, API key, and project name.  These variables are used by the LangSmith integration to send tracing data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langsmith.mdx#2025-04-22_snippet_0\n\nLANGUAGE: env\nCODE:\n```\n\"LANGSMITH_TRACING=true\nLANGSMITH_ENDPOINT=https://api.smith.langchain.com\nLANGSMITH_API_KEY=your-api-key\nLANGSMITH_PROJECT=your-project-name\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Thread Title Generation in Memory - JavaScript\nDESCRIPTION: This code snippet demonstrates how to disable the automatic thread title generation feature in the Memory class. This is useful when models don't support structured output or when you want to avoid the LLM call for title generation. The 'generateTitle' option within the 'threads' configuration is set to 'false'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/CHANGELOG.md#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nnew Memory({ threads: { generateTitle: false }})\n```\n\n----------------------------------------\n\nTITLE: Error Handling for Resume Function - Typescript\nDESCRIPTION: This code demonstrates error handling when using the `resume` function. It catches potential errors like a missing or corrupted workflow snapshot, allowing for appropriate error handling within the application.  Error messages are checked to handle specific error scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resume.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await run.resume({\n    runId,\n    stepId: \"stepTwo\",\n    context: newData\n  });\n} catch (error) {\n  if (error.message === \"No snapshot found for workflow run\") {\n    // Handle missing workflow state\n  }\n  if (error.message === \"Failed to parse workflow snapshot\") {\n    // Handle corrupted workflow state\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Operating on a Specific Workflow with TypeScript\nDESCRIPTION: This snippet shows how to get an instance of a specific workflow by its ID using the Mastra client. The `getWorkflow()` method takes the workflow ID as a parameter and likely returns a workflow object that can be used for further operations. The `client` object is assumed to be properly initialized.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/workflows.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = client.getWorkflow(\"workflow-id\");\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required packages using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/faithfulness/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Initializing MDocument Instances in TypeScript\nDESCRIPTION: Demonstrates how to create MDocument instances from various content formats including plain text, HTML, Markdown, and JSON.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst docFromText = MDocument.fromText(\"Your plain text content...\");\nconst docFromHTML = MDocument.fromHTML(\"<html>Your HTML content...</html>\");\nconst docFromMarkdown = MDocument.fromMarkdown(\"# Your Markdown content...\");\nconst docFromJSON = MDocument.fromJSON(`{ \"key\": \"value\" }`);\n```\n\n----------------------------------------\n\nTITLE: Listing Indexes in AstraVector\nDESCRIPTION: Returns an array of index names as strings from the AstraVector class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nReturns an array of index names as strings.\n```\n\n----------------------------------------\n\nTITLE: Mastra Project Structure\nDESCRIPTION: Directory structure created by the init command, showing the organization of Mastra project files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nproject-root/\n├── src/\n   ├── app/\n   └── mastra/\n       ├── agents/\n       │   └── agents.ts\n       └── index.ts\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Mastra Completeness Example\nDESCRIPTION: Command to install the required dependencies using pnpm package manager. This step is necessary before running the completeness metric example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/completeness/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Cloning Mastra Repository\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the workflow example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/create-workflow/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/create-workflow\n```\n\n----------------------------------------\n\nTITLE: Building All Packages in Mastra\nDESCRIPTION: Command to build all packages in the Mastra monorepo.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm build\n```\n\n----------------------------------------\n\nTITLE: Creating Mastra project with example code\nDESCRIPTION: Example command showing how to create a new Mastra project that includes example code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest --example\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Dependencies\nDESCRIPTION: Installs the necessary Mastra MCP, core, and tsup packages using pnpm. Tsup is used for bundling the TypeScript code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/mcp @mastra/core tsup\n```\n\n----------------------------------------\n\nTITLE: Import ProviderTable Component TypeScript\nDESCRIPTION: This code snippet imports the `ProviderTable` component from the `@/components/provider-table` module.  The ProviderTable component is likely a React component responsible for displaying a table of AI providers and their model capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/model-capability.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { ProviderTable } from \"@/components/provider-table\";\n```\n\n----------------------------------------\n\nTITLE: Retrieving Telemetry Traces with Filtering and Pagination in TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve telemetry traces from the Mastra application using the `getTelemetry` method. It includes options for filtering by trace name, scope, and custom attributes, as well as pagination to manage large datasets. The code assumes that a `client` object with the `getTelemetry` method is available and properly initialized.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/telemetry.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst telemetry = await client.getTelemetry({\n  name: \"trace-name\", // オプション: トレース名でフィルタリング\n  scope: \"scope-name\", // オプション: スコープでフィルタリング\n  page: 1, // オプション: ページネーションのページ番号\n  perPage: 10, // オプション: 1ページあたりのアイテム数\n  attribute: {\n    // オプション: カスタム属性でフィルタリング\n    key: \"value\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Registering Chef Agent with Mastra in TypeScript\nDESCRIPTION: This code demonstrates how to register the Chef Assistant agent with Mastra in the main file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nimport { chefAgent } from \"./agents/chefAgent\";\n\nexport const mastra = new Mastra({\n  agents: { chefAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: Closing the Clickhouse Store Connection\nDESCRIPTION: This snippet shows how to properly close the connection to the Clickhouse store. It's essential for releasing resources after performing database operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nawait store.close();\n```\n\n----------------------------------------\n\nTITLE: Automatic Installation - Create Mastra Project\nDESCRIPTION: This command initiates the automatic installation of a new Mastra project using the `create-mastra` package. It scaffolds the project with necessary configurations and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Basic Usage: Adding a ToDo Item and Masking Stream Tags\nDESCRIPTION: This snippet shows how to add a new ToDo item and hide the working memory updates from the user using `maskStreamTags`. It starts a conversation, sends a message to the agent to add a task, and processes the stream while masking the `<working_memory>` tags.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory-advanced.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\nimport { maskStreamTags } from \"@mastra/core/utils\";\n\n// 会話を開始する\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// 新しいToDoアイテムを追加する\nconst response = await todoAgent.stream(\n  \"タスクを追加: アプリの新機能を構築する。約2時間かかり、次の金曜日までに完了する必要があります。\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// ストリームを処理し、作業メモリの更新を隠す\nfor await (const chunk of maskStreamTags(\n  response.textStream,\n  \"working_memory\",\n)) {\n  process.stdout.write(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Smithery.ai on Unix/Mac in TypeScript\nDESCRIPTION: This TypeScript code configures the MCP to use Smithery.ai's sequential thinking server on Unix/Mac systems. It uses `npx` to execute the Smithery CLI.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Unix/Mac\nconst mcp = new MCPConfiguration({\n  servers: {\n    sequentialThinking: {\n      command: \"npx\",\n      args: [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@smithery-ai/server-sequential-thinking\",\n        \"--config\",\n        \"{}\",\n      ],\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: This snippet demonstrates how to use the pnpm command to install project dependencies. Ensure pnpm or npm is installed before running this command.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Murf Voice\nDESCRIPTION: This command installs the @mastra/voice-murf package using npm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-murf\n```\n\n----------------------------------------\n\nTITLE: Registering Event Listener for Transcribed Text with OpenAIRealtimeVoice\nDESCRIPTION: This example demonstrates how to initialize an OpenAIRealtimeVoice provider, connect to the real-time service, and register an event listener for the 'writing' event, which is triggered when text is transcribed. It utilizes chalk for color-coded output to the console based on the speaker role (user or system).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.on.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\nimport chalk from \"chalk\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Register event listener for transcribed text\nvoice.on(\"writing\", (event) => {\n  if (event.role === 'user') {\n    process.stdout.write(chalk.green(event.text));\n  } else {\n    process.stdout.write(chalk.blue(event.text));\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Listing Indexes in Upstash Vector Store in TypeScript\nDESCRIPTION: The `listIndexes()` method retrieves all index names currently available in the Upstash vector store as an array of strings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nReturns an array of index names (namespaces) as strings.\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with Weather Workflow\nDESCRIPTION: Initializes Mastra with the defined weather workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nconst mastra = new Mastra({\n  workflows: {\n    weatherWorkflow,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: 音声から音声への変換（OpenAI Realtime）\nDESCRIPTION: OpenAI Realtime Voiceを使用して、音声から音声への変換を行います。この例では、マイクロフォンからの音声ストリームを取得し、AIエージェントに送信します。エージェントからの音声応答を再生します。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { playAudio, getMicrophoneStream } from '@mastra/node-audio';\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new OpenAIRealtimeVoice(),\n});\n\n// Listen for agent audio responses\nvoiceAgent.voice.on('speaker', ({ audio }) => {\n  playAudio(audio);\n});\n\n// Initiate the conversation\nawait voiceAgent.voice.speak('How can I help you today?');\n\n// Send continuous audio from the microphone\nconst micStream = getMicrophoneStream();\nawait voiceAgent.voice.send(micStream);\n```\n\n----------------------------------------\n\nTITLE: Handling Errors with VectorStoreError in TypeScript\nDESCRIPTION: This snippet demonstrates error handling for vector store queries. It checks if the error is an instance of VectorStoreError and logs the error code and additional details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/qdrant.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // Additional error context\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Project for Netlify Deployment\nDESCRIPTION: This Bash command builds the Mastra project, preparing it for deployment to Netlify by generating the necessary output structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/netlify.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Add support for commonjs\nDESCRIPTION: This patch adds support for CommonJS modules. This change likely involves modifying the package's build process to output CommonJS-compatible files, allowing it to be used in environments that require CommonJS modules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nbb4f447: Add support for commonjs\n```\n\n----------------------------------------\n\nTITLE: Generate Speech with SpeechifyVoice (TypeScript)\nDESCRIPTION: Demonstrates how to use the `SpeechifyVoice` class to generate speech from text. It initializes a `SpeechifyVoice` instance, lists available speakers, and then generates a speech stream from the text 'Hello world'. The stream can then be piped to a destination for playback or further processing. The `SPEECHIFY_API_KEY` env variable or explicitly passed API key can be used to authorize API calls.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SpeechifyVoice } from '@mastra/voice-speechify';\n\nconst voice = new SpeechifyVoice({\n  speechModel: {\n    name: 'simba-english', // Optional, defaults to 'simba-english'\n    apiKey: 'your-api-key', // Optional, can use SPEECHIFY_API_KEY env var\n  },\n  speaker: 'george', // Optional, defaults to 'george'\n});\n\n// List available speakers\nconst speakers = await voice.getSpeakers();\n\n// Generate speech\nconst stream = await voice.speak('Hello world', {\n  speaker: 'george', // Optional, defaults to constructor speaker\n  // Additional Speechify options\n  audioFormat: 'mp3',\n});\n\n// The stream can be piped to a destination\nstream.pipe(destination);\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Package Manager\nDESCRIPTION: Command to install project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-parallel-steps/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Defining Agent with Tools and maxSteps (TypeScript)\nDESCRIPTION: This code defines a Mastra agent with a tool for performing calculations, and also sets a `maxSteps` limit to prevent infinite loops during tool calls. The agent is configured with instructions, a model, and a calculator tool that uses `mathjs` to evaluate expressions. The `maxSteps` parameter limits the agent to a maximum of 5 LLM calls.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport * as mathjs from \"mathjs\";\nimport { z } from \"zod\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant that can solve math problems.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    calculate: {\n      description: \"Calculator for mathematical expressions\",\n      schema: z.object({ expression: z.string() }),\n      execute: async ({ expression }) => mathjs.evaluate(expression),\n    },\n  },\n});\n\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"If a taxi driver earns $9461 per hour and works 12 hours a day, how much does they earn in one day?\",\n    },\n  ],\n  {\n    maxSteps: 5, // Allow up to 5 tool usage steps\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Upsert Embeddings into PgVector with Mastra (TSX)\nDESCRIPTION: This code snippet demonstrates how to create an index and upsert embeddings into a PostgreSQL database using the `PgVector` class from the `@mastra/pg` package. It uses the `openai` package to generate embeddings, and the `MDocument` class from `@mastra/rag` to handle text chunking. The `POSTGRES_CONNECTION_STRING` environment variable is required for database connection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/upsert/upsert-embeddings.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nawait pgVector.createIndex({\n  indexName: \"test_index\",\n  dimension: 1536,\n});\n\nawait pgVector.upsert({\n  indexName: \"test_index\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: Command to install project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-branching-paths/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Rendering a Blog Post Link in HTML\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post in a list. It includes a link to the blog post, the title, a summary (displayed conditionally based on screen size), the publication date, and the author's image. The structure uses CSS classes for styling and responsive behavior.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_2\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/ai-beats-lab\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">AI Beats Laboratory: A Multi-Agent Music Generation System</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">AI Beats Laboratory: A Multi-Agent Music Generation System</h2><span class=\"text-xs text-left text-text-3\">Mar 11, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Mar 11, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/abhi.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra in a Next.js project using yarn\nDESCRIPTION: This command initializes Mastra in a Next.js project using the yarn package manager. It executes the mastra package and sets up Mastra within the Next.js environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nyarn dlx mastra@latest init\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Astra in TypeScript\nDESCRIPTION: This code initializes AstraVector with token, endpoint, and keyspace, creates an index, and upserts embeddings with metadata.  It requires @mastra/astra and appropriate environment variables for AstraDB.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AstraVector } from '@mastra/astra'\n\nconst store = new AstraVector({\n  token: process.env.ASTRA_DB_TOKEN,\n  endpoint: process.env.ASTRA_DB_ENDPOINT,\n  keyspace: process.env.ASTRA_DB_KEYSPACE\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Starting MCPServer with stdio\nDESCRIPTION: This code snippet shows how to start the MCPServer using standard input and output (stdio). It initializes the MCPServer (example configuration omitted for brevity) and then calls the startStdio() method. This method allows the server to communicate with MCP clients through the command line.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst server = new MCPServer({\n  // example configuration above\n});\nawait server.startStdio();\n```\n\n----------------------------------------\n\nTITLE: Off Method Definition\nDESCRIPTION: This code snippet defines the `off` method in `MastraVoice`, used to remove a previously registered event listener. It cleans up event handlers when they are no longer needed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\noff<E extends VoiceEventType>(\n  event: E,\n  callback: (data: E extends keyof VoiceEventMap ? VoiceEventMap[E] : unknown) => void,\n): void\n```\n\n----------------------------------------\n\nTITLE: Handling Toast Swipe-Out Actions - CSS\nDESCRIPTION: This snippet includes styles using the animation and transforms to manage toast notifications when swiped out, utilizing keyframes for smooth transitioning effects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_2\n\nLANGUAGE: css\nCODE:\n```\n[data-sonner-toast][data-swipe-out=true][data-y-position=bottom],[data-sonner-toast][data-swipe-out=true][data-y-position=top]{animation:swipe-out .2s ease-out forwards}@keyframes swipe-out{0%{transform:translateY(calc(var(--lift) * (var(--offset) + var(--swipe-amount))) );opacity:1}to{transform:translateY(calc(var(--lift) * (var(--offset) + var(--swipe-amount) + var(--lift) * -100%));opacity:0}}\n```\n\n----------------------------------------\n\nTITLE: Configure Murf API Key\nDESCRIPTION: This environment variable is required to authenticate with the Murf API. Replace `your_api_key` with your actual API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nMURF_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key - Environment Variable\nDESCRIPTION: This snippet provides an example of how to set the OpenAI API key in the .env file for application configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/agentic-workflows/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Processing Documents into Chunks for RAG\nDESCRIPTION: Creates a document from text and processes it into chunks using Mastra's MDocument class with specified chunking parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc1 = MDocument.fromText(`\nmarket data shows price resistance levels.\ntechnical charts display moving averages.\nsupport levels guide trading decisions.\nbreakout patterns signal entry points.\nprice action determines trade timing.\n`);\n\nconst chunks = await doc1.chunk({\n  strategy: 'recursive',\n  size: 150,\n  overlap: 20,\n  separator: '\\n',\n});\n```\n\n----------------------------------------\n\nTITLE: Speak Method with OpenAIRealtimeVoice\nDESCRIPTION: Demonstrates usage with `OpenAIRealtimeVoice`, which emits 'speaker' events instead of returning a stream. Includes setting up a speaker and event listener. Requires the `@mastra/node-speaker` and `@mastra/voice-openai-realtime` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.speak.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // MacBook Proでの高品質オーディオの標準Hzでのオーディオサンプルレート\n  channels: 1,        // モノラルオーディオ出力（ステレオの場合は2）\n  bitDepth: 16,       // オーディオ品質のビット深度 - CD品質の標準（16ビット解像度）\n});\n\nconst voice = new OpenAIRealtimeVoice();\nawait voice.connect();\n// オーディオチャンクのためのイベントリスナーを登録\nvoice.on(\"speaker\", (stream) => {\n  // オーディオチャンクを処理（例：再生または保存）\n  stream.pipe(speaker)\n});\n// これにより、ストリームを返す代わりに「speaking」イベントが発生します\nawait voice.speak(\"こんにちは、これはリアルタイムの音声です！\");\n```\n\n----------------------------------------\n\nTITLE: Import Metric Dependencies Typescript\nDESCRIPTION: Imports the necessary dependencies from the '@mastra/core/eval' package. Specifically, it imports the `Metric` class and the `MetricResult` type, which are essential for defining and implementing custom metrics within the Mastra framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/word-inclusion.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Metric, type MetricResult } from '@mastra/core/eval';\n```\n\n----------------------------------------\n\nTITLE: Memory API Update: OpenAIEmbedder Initialization\nDESCRIPTION: This code snippet demonstrates how to initialize the OpenAIEmbedder for the Memory API in Mastra.  The `embeddings: {}` option has been replaced with `embedder: new OpenAIEmbedder()`. This change is part of a breaking change to improve the management of embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nembedder: new OpenAIEmbedder()\n```\n\n----------------------------------------\n\nTITLE: Running the Example Application in Bash\nDESCRIPTION: Command to start the example application that demonstrates an agent with a system prompt.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: Command to install the project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Metadata Extraction Example in Bash\nDESCRIPTION: Command to start and execute the metadata extraction example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/metadata-extraction/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up Bird Checker Project in Bash\nDESCRIPTION: These commands clone the repository, navigate to the project directory, install dependencies, and copy the environment variables file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs-and-eval/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone <repository-url>\ncd bird-checker-with-nextjs-and-eval\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env.local\n```\n\n----------------------------------------\n\nTITLE: Evaluating Non-Toxic Response in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a constructive and professional response using the Toxicity metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'Can you provide feedback on the project proposal?';\nconst response3 =\n  'The proposal has strong points in its technical approach but could benefit from more detailed market analysis. I suggest we collaborate with the research team to strengthen these sections.';\n\nconsole.log('Example 3 - No Toxicity:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response is professional and constructive, focusing on specific aspects without any personal attacks or harmful language.' }\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra Backend with CLI\nDESCRIPTION: Commands to create a new Mastra project using various package managers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn create mastra\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm create mastra\n```\n\n----------------------------------------\n\nTITLE: Visualizing Project Structure\nDESCRIPTION: Directory structure for the Dane AI assistant project, showing the organization of the codebase including main entry point, configuration, commands, and core functionality modules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/dane/README.md#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nsrc/\n├── index.ts              # Main entry point\n├── config/              # Configuration setup\n├── commands/            # CLI commands\n└── mastra/              # Core functionality\n    ├── agents/          # AI agents definitions\n    ├── integrations/    # External service integrations\n    ├── tools/           # Utility tools\n    └── workflows/       # Workflow definitions\n```\n\n----------------------------------------\n\nTITLE: Updating CJS Bundling for File Splitting\nDESCRIPTION: This code snippet outlines an update to the CommonJS (CJS) bundling process, emphasizing the splitting of files. This optimization improves loading times and resource utilization. Proper file splitting is crucial for performance in larger applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_4\n\nLANGUAGE: TEXT\nCODE:\n```\nfd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Update Filter Location\nDESCRIPTION: This patch moves the filter location from `@mastra/core/filter` to `@mastra/core/vector/filter`. This change helps to organize the codebase and improve maintainability by grouping vector-related functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nfd14a3f: Updating filter location from @mastra/core/filter to @mastra/core/vector/filter\n```\n\n----------------------------------------\n\nTITLE: Answer Method Definition\nDESCRIPTION: This code snippet defines the optional `answer` method in `MastraVoice`, which sends a signal to the voice provider to generate a response. It's used in real-time conversations to prompt the AI to respond, with the response being emitted through the event system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nanswer(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Responsive Toast Designs - CSS\nDESCRIPTION: This snippet implements responsive styling for toast notifications, ensuring they adapt well on mobile devices with media queries and dynamic positioning based on screen size.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_3\n\nLANGUAGE: css\nCODE:\n```\n@media (max-width: 600px){[data-sonner-toaster]{position:fixed;--mobile-offset: 16px;right:var(--mobile-offset);left:var(--mobile-offset);width:100%}[data-sonner-toaster][dir=rtl]{left:calc(var(--mobile-offset) * -1)}[data-sonner-toaster] [data-sonner-toast]{left:0;right:0;width:calc(100% - var(--mobile-offset) * 2)}[data-sonner-toaster][data-x-position=left]{left:var(--mobile-offset)}[data-sonner-toaster][data-y-position=bottom]{bottom:20px}[data-sonner-toaster][data-y-position=top]{top:20px}[data-sonner-toaster][data-x-position=center]{left:var(--mobile-offset);right:var(--mobile-offset);transform:none}}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Texts with Major Differences\nDESCRIPTION: Demonstrates comparing text strings with significant differences using the Textual Difference metric, resulting in a low similarity score around 0.32 with detailed metrics about the substantial changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/textual-difference.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'Python is a high-level programming language';\nconst output3 = 'JavaScript is used for web development';\n\nconsole.log('Example 3 - Major Differences:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    confidence: result3.info.confidence,\n    ratio: result3.info.ratio,\n    changes: result3.info.changes,\n    lengthDiff: result3.info.lengthDiff,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.32098765432098764,\n//   info: {\n//     confidence: 0.8837209302325582,\n//     ratio: 0.32098765432098764,\n//     changes: 8,\n//     lengthDiff: 0.11627906976744186\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Creating Publisher Agent and Mastra Instance in TypeScript\nDESCRIPTION: This snippet creates a Publisher agent that coordinates the Copywriter and Editor agents. It also initializes a Mastra instance with the Publisher agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst publisherAgent = new Agent({\n  name: \"publisherAgent\",\n  instructions:\n    \"You are a publisher agent that first calls the copywriter agent to write blog post copy about a specific topic and then calls the editor agent to edit the copy. Just return the final edited copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n  tools: { copywriterTool, editorTool },\n});\n\nconst mastra = new Mastra({\n  agents: { publisherAgent },\n});\n```\n\n----------------------------------------\n\nTITLE: MCPServer getStdioTransport() method definition\nDESCRIPTION: Defines the signature of the getStdioTransport() method for the MCPServer class. This method returns the StdioServerTransport object or undefined if the server was not started with startStdio().\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ngetStdioTransport(): StdioServerTransport | undefined\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Example 2\nDESCRIPTION: This command demonstrates how to run `create-mastra` non-interactively, specifying the project name, components, LLM, and example code inclusion.  It shows specifying the project name as an option.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest --project-name my-app --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Starting the Mastra Development Server (Bash)\nDESCRIPTION: This bash command demonstrates how to start the Mastra development server using the `mastra dev` command. By default, this looks for exported agents in files in the `src/mastra/agents` directory and exposes them via an API.  This command starts the server on `http://localhost:4111/api/agents/myAgent/generate`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Testing Agent Endpoint with Fetch (JavaScript)\nDESCRIPTION: This JavaScript code uses the `fetch` API to test the weather agent's endpoint. It sends a POST request to `http://localhost:4111/api/agents/weatherAgent/generate` with a JSON payload containing the query \"What is the weather in London?\". The code then parses the response as JSON and logs the agent's response to the console. Error handling is included to catch any issues during the request or response processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_27\n\nLANGUAGE: javascript\nCODE:\n```\nfetch('http://localhost:4111/api/agents/weatherAgent/generate', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n  body: JSON.stringify({\n    messages: ['What is the weather in London?'],\n  }),\n})\n  .then(response => response.json())\n  .then(data => {\n    console.log('Agent response:', data.text);\n  })\n  .catch(error => {\n    console.error('Error:', error);\n  });\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra using npm\nDESCRIPTION: Command to create a new Mastra project using npm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Running the Example Application\nDESCRIPTION: Command for starting the example application to demonstrate the custom gluten checker evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Import Dependencies Typescript\nDESCRIPTION: Imports necessary modules and classes from various libraries, including `@ai-sdk/openai` for OpenAI integration, `@mastra/core` for Mastra core functionalities, `@mastra/core/agent` for agent creation, `@mastra/core/workflows` for workflow management, `@mastra/pg` for PgVector integration, `@mastra/rag` for RAG functionalities, `ai` for embedding generation, and `zod` for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { PgVector } from \"@mastra/pg\";\nimport { createVectorQueryTool, MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Evaluate Texts with Major Differences\nDESCRIPTION: Demonstrates how to use TextualDifferenceMetric to evaluate two text strings with significant differences. The metric calculates a similarity score and provides details such as confidence, ratio, changes, and length difference, showing a lower similarity score due to the major differences.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/textual-difference.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = 'Python is a high-level programming language';\nconst output3 = 'JavaScript is used for web development';\n\nconsole.log('Example 3 - Major Differences:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    confidence: result3.info.confidence,\n    ratio: result3.info.ratio,\n    changes: result3.info.changes,\n    lengthDiff: result3.info.lengthDiff,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: MastraVoice listen() Abstract Method\nDESCRIPTION: The definition of the required listen() abstract method that converts speech to text using the configured listening model. It takes an audio stream input and supports provider-specific options for transcription configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nabstract listen(\n  audioStream: NodeJS.ReadableStream,\n  options?: {\n    [key: string]: unknown;\n  }\n): Promise<string | NodeJS.ReadableStream | void>\n```\n\n----------------------------------------\n\nTITLE: Getting available voices\nDESCRIPTION: This snippet demonstrates how to retrieve a list of available voices using the `getSpeakers` method. The method returns a promise that resolves with an array of voice options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/murf.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// 利用可能な声を取得\nconst voices = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra Instance within a Workflow (TypeScript)\nDESCRIPTION: This code demonstrates how to create a Mastra instance and inject it into a Workflow. This approach is useful when dynamic workflow creation is needed. By injecting the Mastra instance, the workflow can access the core Mastra functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nconst mastra = new Mastra();\n\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  mastra,\n});\n```\n\n----------------------------------------\n\nTITLE: Starting the Development Server\nDESCRIPTION: Command to start the Express.js development server using PNPM. This launches the application with the configured environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Implementing Vercel's OpenTelemetry Setup\nDESCRIPTION: Creates an instrumentation file that uses Vercel's registerOTel function to enable OpenTelemetry tracing. This is a simplified approach that works specifically for applications deployed on Vercel.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { registerOTel } from '@vercel/otel'\n\nexport function register() {\n  registerOTel({ serviceName: 'your-project-name' })\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Mechanism in Mastra Client SDK\nDESCRIPTION: This code snippet shows how to configure the retry mechanism in the Mastra Client SDK. The `MastraClient` constructor accepts options to control the number of retries (`retries`), initial backoff time (`backoffMs`), and maximum backoff time (`maxBackoffMs`).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/error-handling.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new MastraClient({\n  baseUrl: \"http://localhost:4111\",\n  retries: 3, // リトライ試行回数\n  backoffMs: 300, // 初期バックオフ時間\n  maxBackoffMs: 5000, // 最大バックオフ時間\n});\n```\n\n----------------------------------------\n\nTITLE: Generate Speech with Murf Voice (TypeScript)\nDESCRIPTION: This code demonstrates how to initialize the MurfVoice class, list available speakers, and generate speech from text and text streams. It requires the `@mastra/voice-murf` package and the `stream` module. The API Key can be set in the `speechModel` or through the MURF_API_KEY environment variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MurfVoice } from '@mastra/voice-murf';\n// Or generate speech from a text stream\nimport { Readable } from 'stream';\n\n// Initialize with configuration\nconst voice = new MurfVoice({\n  speechModel: {\n    name: 'GEN2', // Optional, defaults to 'GEN2'\n    apiKey: 'your-api-key', // Optional, can use MURF_API_KEY env var\n  },\n  speaker: 'en-US-natalie', // Optional, defaults to first available voice\n});\n\n// Or use with defaults (using env vars)\nconst defaultVoice = new MurfVoice();\n\n// List available speakers\nconst speakers = await voice.getSpeakers();\n\n// Generate speech from text\nconst stream = await voice.speak('Hello from Mastra!');\n\nconst textStream = Readable.from(['Hello', ' from', ' stream', ' input!']);\nconst audioStream = await voice.speak(textStream);\n\n// Speech recognition is not supported\ntry {\n  await voice.listen(audioStream);\n} catch (error) {\n  console.error(error); // \"Murf does not support speech recognition\"\n}\n```\n\n----------------------------------------\n\nTITLE: Optimizing Data with Agent\nDESCRIPTION: This code snippet optimizes the data by using the agent to clean the chunks, create new embeddings, and update the vector store. It prompts the agent to clean the chunks, creates a new document from the cleaned text, chunks the document again, creates new embeddings, deletes the existing index, creates a new index, and upserts the new embeddings into the vector store.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst chunkPrompt = `Use the tool provided to clean the chunks. Make sure to filter out irrelevant information that is not space related and remove duplicates.`;\n\nconst newChunks = await agent.generate(chunkPrompt);\nconst updatedDoc = MDocument.fromText(newChunks.text);\n\nconst updatedChunks = await updatedDoc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n  separator: \"\\n\",\n});\n\nconst { embeddings: cleanedEmbeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small'),\n  values: updatedChunks.map(chunk => chunk.text),\n});\n\n// Update the vector store with cleaned embeddings\nawait vectorStore.deleteIndex('embeddings');\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\n\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: cleanedEmbeddings,\n  metadata: updatedChunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies\nDESCRIPTION: This snippet imports the necessary dependencies from the `@ai-sdk/openai` and `@mastra/evals/llm` packages. It imports `openai` from `@ai-sdk/openai` and `ContextRelevancyMetric` from `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextRelevancyMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Graph RAG System\nDESCRIPTION: Imports necessary modules and functions from Mastra, OpenAI, and other related packages for implementing the Graph RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createGraphRAGTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_8\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/ai-ops\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Baby steps towards AI Ops</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Baby steps towards AI Ops</h2><span class=\"text-xs text-left text-text-3\">Jan 30, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 30, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/abhi.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Initialize KeywordCoverageMetric in TypeScript\nDESCRIPTION: Initializes an instance of the `KeywordCoverageMetric` class. This creates a metric object that can be used to measure keyword coverage between two texts. No parameters are required for initialization.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/keyword-coverage.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new KeywordCoverageMetric();\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Faithfulness Response with Mastra\nDESCRIPTION: This TypeScript code snippet illustrates the process of evaluating a response with low faithfulness using Mastra's FaithfulnessMetric. It defines a context, initializes the metric, provides a query, and a response that contradicts the context. The code then prints the results of the metric evaluation, demonstrating how low faithfulness scores are generated and the reasons behind them.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/faithfulness.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'Mars is the fourth planet from the Sun.',\n  'It has a thin atmosphere of mostly carbon dioxide.',\n  'Two small moons orbit Mars: Phobos and Deimos.',\n];\n\nconst metric3 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'What do we know about Mars?';\nconst response3 = 'Mars is the third planet from the Sun. It has a thick atmosphere rich in oxygen and nitrogen, and is orbited by three large moons.';\n\nconsole.log('Example 3 - Low Faithfulness:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response contradicts the context.' }\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies with pnpm\nDESCRIPTION: Installs the project dependencies using the pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/calling-agent-from-workflow/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server and Evaluating LLM Prompt in Bash\nDESCRIPTION: These commands start the Next.js development server and run the Braintrust evaluation for the LLM prompt.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs-and-eval/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm braintrust:eval\n```\n\n----------------------------------------\n\nTITLE: Evaluate Identical Texts\nDESCRIPTION: Demonstrates how to use TextualDifferenceMetric to evaluate two identical text strings. The metric calculates a similarity score and provides details such as confidence, ratio, changes, and length difference.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/textual-difference.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = 'The quick brown fox jumps over the lazy dog';\nconst output1 = 'The quick brown fox jumps over the lazy dog';\n\nconsole.log('Example 1 - Identical Texts:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    confidence: result1.info.confidence,\n    ratio: result1.info.ratio,\n    changes: result1.info.changes,\n    lengthDiff: result1.info.lengthDiff,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a new Mastra project using npx\nDESCRIPTION: This command creates a new Mastra project using the npx package runner. It is suitable for executing the create-mastra package without globally installing it.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Implementing Final Answer Step\nDESCRIPTION: Defines the final step in the workflow for generating a structured final answer based on the conclusions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst finalAnswer = new Step({\n  id: \"finalAnswer\",\n  outputSchema: z.object({\n    finalAnswer: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const conclusions = context?.getStepResult<{\n      conclusions: string;\n    }>(\"drawConclusions\")?.conclusions;\n    const answerPrompt = `\n        Based on the conclusions: ${conclusions}\n        Format your response as:\n        THOUGHT PROCESS:\n        - Step 1: [Initial analysis of retrieved chunks]\n        - Step 2: [Connections between chunks]\n        - Step 3: [Reasoning based on chunks]\n\n        FINAL ANSWER:\n        [Your concise answer based on the retrieved context]`;\n\n    const finalAnswer = await ragAgent?.generate(answerPrompt);\n    console.log(finalAnswer?.text);\n    return {\n      finalAnswer: finalAnswer?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Toast Transformations and Transitions - CSS\nDESCRIPTION: This snippet specifies CSS transformations and transitions for toast notifications, handling their position, visibility, and animation effects when shown or removed. The use of custom properties allows for dynamic adjustment based on different conditions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_1\n\nLANGUAGE: css\nCODE:\n```\n[data-sonner-toast][data-mounted=\"true\"][data-expanded=\"true\"]{--y: translateY(calc(var(--lift) * var(--offset)));height:var(--initial-height)}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"true\"][data-swipe-out=\"false\"]){--y: translateY(calc(var(--lift) * -100%));opacity:0}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"false\"][data-swipe-out=\"false\"][data-expanded=\"true\"]){--y: translateY(calc(var(--lift) * var(--offset) + var(--lift) * -100%));opacity:0}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"false\"][data-swipe-out=\"false\"][data-expanded=\"false\"]){--y: translateY(40%);opacity:0;transition:transform .5s,opacity .2s}\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Context Position Metric\nDESCRIPTION: This snippet shows the necessary imports for using the ContextPositionMetric from the @mastra/evals/llm package and the openai client from the @ai-sdk/openai package. These dependencies are essential for defining and using the metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-position.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextPositionMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Install Mem0 Integration\nDESCRIPTION: Installs the Mem0 integration package using npm. This adds the @mastra/mem0 package to the project dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/mem0\n```\n\n----------------------------------------\n\nTITLE: Version Control Changelog Entries\nDESCRIPTION: Markdown changelog entries documenting package version updates and dependency changes across multiple alpha releases. Each entry includes patch changes and updated dependencies with their corresponding version numbers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# openapi-spec-writer\n\n## 0.0.1\n\n## 0.0.1-alpha.4\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/firecrawl@1.0.4-alpha.79\n  - @mastra/github@1.0.3-alpha.70\n  - @mastra/engine@0.0.5-alpha.80\n  - @mastra/loggers@0.0.1-alpha.18\n  - @mastra/rag@0.0.2-alpha.77\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command for installing the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-relevancy/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Defining Environment Variables for AstraVector\nDESCRIPTION: Lists required environment variables for the AstraVector class to establish connection with the Astra DB API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/astra.mdx#2025-04-22_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\n- `ASTRA_DB_TOKEN`: Your Astra DB API token\n- `ASTRA_DB_ENDPOINT`: Your Astra DB API endpoint\n```\n\n----------------------------------------\n\nTITLE: Listing Indexes in ChromaVector\nDESCRIPTION: Returns an array of strings representing the names of all indexes present in the ChromaDB instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nReturns an array of index names as strings.\n```\n\n----------------------------------------\n\nTITLE: Send Method Definition\nDESCRIPTION: This code snippet defines the optional `send` method in `MastraVoice`, which streams audio data in real-time to the voice provider for processing. It is useful for continuous audio streaming scenarios like live microphone input and supports both ReadableStream and Int16Array audio formats. A connection state must be established before calling this method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nsend(audioData: NodeJS.ReadableStream | Int16Array): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example of how to set up the required environment variables in the .env file, including OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Dependencies\nDESCRIPTION: Command to install project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Update Imports (Old)\nDESCRIPTION: This snippet shows the old import statement used with @mastra/speech-google.  It imports the GoogleTTS class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/google/README.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Old\nimport { GoogleTTS } from '@mastra/speech-google';\n```\n\n----------------------------------------\n\nTITLE: Update CJS Bundling\nDESCRIPTION: This patch updates the CJS bundling process to ensure files are properly split. This improves the efficiency and maintainability of the bundled code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nfd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Configuring API Keys in Environment File\nDESCRIPTION: Example of how to set up the environment variables file with Anthropic and OpenAI API keys. These keys are required for the agents to communicate with their respective language models.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nANTHROPIC_API_KEY=sk-your-api-key-here\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Install Langfuse OpenTelemetry dependencies\nDESCRIPTION: This snippet installs the necessary dependencies for using Langfuse as an OpenTelemetry exporter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/api langfuse-vercel\n```\n\n----------------------------------------\n\nTITLE: Installing Pinecone Vector Store\nDESCRIPTION: This snippet demonstrates how to install the Pinecone vector store package using pnpm. It is essential for integrating with the Pinecone database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pinecone/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/pinecone\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server for MacOS/Linux\nDESCRIPTION: JSON configuration for setting up the Mastra MCP server on MacOS/Linux systems. This should be added to .cursor/mcp.json for Cursor or ~/.codeium/windsurf/mcp_config.json for Windsurf.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/mcp-docs-server.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating MDocument from HTML (Static Method)\nDESCRIPTION: Creates an MDocument instance from HTML content. Accepts an HTML string and an optional metadata object.  Returns an MDocument object representing the HTML content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromHTML(html: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（Cloudflare）\nDESCRIPTION: Cloudflareを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、CloudflareVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { CloudflareVoice } from \"@mastra/voice-cloudflare\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new CloudflareVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra using yarn\nDESCRIPTION: Command to create a new Mastra project using yarn package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn create mastra\n```\n\n----------------------------------------\n\nTITLE: Initialize TypeScript project (bun)\nDESCRIPTION: Initializes a TypeScript project with necessary dependencies using bun. This sets up the environment for developing with Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nbun init -y\nbun add typescript tsx @types/node mastra --dev\nbun add @mastra/core zod @ai-sdk/openai\nbunx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Steps in Mastra (TypeScript)\nDESCRIPTION: This code defines two steps in a Mastra workflow. The first step doubles an input value, and the second step increments the result if the first step was successful.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepOne = new Step({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context.triggerData.inputValue * 2;\n    return { doubledValue };\n  },\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    const doubledValue = context.getStepResult(stepOne)?.doubledValue;\n    if (!doubledValue) {\n      return { incrementedValue: 0 };\n    }\n    return {\n      incrementedValue: doubledValue + 1,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Cross-Linking to Related Documentation in Markdown\nDESCRIPTION: Shows how to link to other relevant reference documentation to help users discover related functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n### Related\n\n- [Engine Configuration](/guide/reference/engine.mdx)\n- [Agent Class Reference](/guide/reference/agent.mdx)\n```\n\n----------------------------------------\n\nTITLE: Static Configuration Examples - TypeScript\nDESCRIPTION: This snippet shows how to initialize the `McpConfiguration` class with static server configurations. It sets servers as properties with their configurations for validation and persistence.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst configuration = new McpConfiguration({\n\tid: \"validation-example\",\n\tregistry,\n\tservers: {\n\t\tserverName: {\n\t\t\t...someConfig,\n\t\t},\n\t\totherServer: {\n\t\t\t...moreConfig,\n\t\t},\n\t},\n})\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of PromptAlignmentMetric in TypeScript\nDESCRIPTION: This snippet demonstrates the basic usage of the `PromptAlignmentMetric` class to evaluate how well an LLM output adheres to a set of instructions. It initializes the metric with a language model and a list of instructions, then measures the alignment of a given output against the instructions. The snippet then logs the alignment score and the explanation for the score.  The required dependencies are `@ai-sdk/openai` and `@mastra/evals/llm`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/prompt-alignment.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { PromptAlignmentMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst instructions = [\n  \"Start sentences with capital letters\",\n  \"End each sentence with a period\",\n  \"Use present tense\",\n];\n\nconst metric = new PromptAlignmentMetric(model, {\n  instructions,\n  scale: 1,\n});\n\nconst result = await metric.measure(\n  \"describe the weather\",\n  \"The sun is shining. Clouds float in the sky. A gentle breeze blows.\",\n);\n\nconsole.log(result.score); // Alignment score from 0-1\nconsole.log(result.info.reason); // Explanation of the score\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra CLI with NPM\nDESCRIPTION: Global installation command for the Mastra CLI tool using npm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i -g mastra\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Instance for Telemetry\nDESCRIPTION: Sets up the Mastra instance with telemetry options, including service name and enabling telemetry functionality. This configuration is essential for integrating Mastra's observability features with OpenTelemetry.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-project-name\",\n    enabled: true\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Copying the environment variables file\nDESCRIPTION: Command to create a copy of the example environment variables file which will be used to store API keys.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: TypeScript Configuration (tsconfig.json)\nDESCRIPTION: Defines the TypeScript compiler options in `tsconfig.json`.  These settings configure the TypeScript compiler for a Mastra project, ensuring compatibility and proper module resolution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"outDir\": \"dist\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \".mastra\"]\n}\n```\n\n----------------------------------------\n\nTITLE: MCPConfiguration Constructor Definition\nDESCRIPTION: Defines the constructor for the MCPConfiguration class, which takes an MCPConfigurationOptions object as input. This object can include an optional id, a record of server configurations, and an optional timeout value.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor({\n  id?: string;\n  servers: Record<string, MastraMCPServerDefinition>;\n  timeout?: number;\n}: MCPConfigurationOptions)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Traces with Filtering and Pagination in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the client's getTelemetry method to retrieve traces. It shows optional parameters for filtering by trace name, scope, and custom attributes, as well as pagination options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/telemetry.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst telemetry = await client.getTelemetry({\n  name: \"trace-name\", // Optional: Filter by trace name\n  scope: \"scope-name\", // Optional: Filter by scope\n  page: 1, // Optional: Page number for pagination\n  perPage: 10, // Optional: Number of items per page\n  attribute: {\n    // Optional: Filter by custom attributes\n    key: \"value\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing ChromaDB Vector Store Package\nDESCRIPTION: This snippet demonstrates how to install the ChromaDB vector store package using npm. It is a prerequisite for utilizing the functionalities provided in the implementation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/chroma\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the example directory for the Chain of Thought RAG workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/cot-workflow-rag\n```\n\n----------------------------------------\n\nTITLE: Embedding a Text Chunk with OpenAI in TSX\nDESCRIPTION: This code snippet demonstrates how to embed a single text chunk using the `embed` function from the `ai` library, with the OpenAI embedding model `text-embedding-3-small`. It utilizes `@ai-sdk/openai` for OpenAI integration and `@mastra/rag` for document chunking. The `MDocument.fromText` function creates a document from the provided text, which is then chunked using the `chunk` method. The first chunk's text content is used as input for the embedding generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/embed-text-chunk.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { MDocument } from '@mastra/rag';\nimport { embed } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embedding } = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: chunks[0].text,\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Agent for Graph RAG\nDESCRIPTION: Sets up a Mastra agent with specific instructions for handling queries, using the GPT-4o-mini model and the GraphRAG tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst ragAgent = new Agent({\n  name: \"GraphRAG Agent\",\n  instructions: `あなたは、提供されたコンテキストに基づいて質問に答える役立つアシスタントです。回答を次のようにフォーマットしてください：\n\n1. 直接的な事実: 質問に関連するテキストから直接述べられている事実のみをリストアップします（2-3の箇条書き）\n2. 作られたつながり: テキストの異なる部分間で見つけた関係をリストアップします（2-3の箇条書き）\n3. 結論: すべてをまとめる1文の要約\n\n各セクションを簡潔にし、最も重要なポイントに焦点を当ててください。\n\n重要: 質問に答えるよう求められた場合、ツールで提供されたコンテキストのみに基づいて回答してください。\nコンテキストに質問に完全に答えるための十分な情報が含まれていない場合は、その旨を明示してください。`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    graphRagTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Example Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the contextual recall example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/contextual-recall\n```\n\n----------------------------------------\n\nTITLE: Configuring the PlayAI API Key\nDESCRIPTION: This command illustrates how to set the PLAYAI_API_KEY environment variable, which is required for the module to function. You must set the environment variable before using the module.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n\"PLAYAI_API_KEY=your_api_key\"\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra Repository and Navigating to Example Directory\nDESCRIPTION: Commands to clone the Mastra GitHub repository and navigate to the adjust-chunk-delimiters example directory to access the example code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-delimiters/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/adjust-chunk-delimiters\n```\n\n----------------------------------------\n\nTITLE: Building Specific Package Groups in Mastra\nDESCRIPTION: Commands to build specific groups of packages in the Mastra monorepo, including core packages, deployers, stores, speech packages, and client SDKs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm build:packages         # All core packages\npnpm build:deployers        # All deployment adapters\npnpm build:combined-stores  # All vector and data stores\npnpm build:speech           # All speech processing packages\npnpm build:clients          # All client SDKs\n```\n\n----------------------------------------\n\nTITLE: Creating a new Mastra project using pnpm\nDESCRIPTION: This command creates a new Mastra project using the pnpm package manager. It executes the create-mastra package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm create mastra\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to the Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the specific example directory for metadata extraction with RAG.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/metadata-extraction/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/metadata-extraction\n```\n\n----------------------------------------\n\nTITLE: Running All Tests in Mastra\nDESCRIPTION: Command to run all tests in the Mastra monorepo using Vitest.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npnpm test\n```\n\n----------------------------------------\n\nTITLE: Direct Metadata Extraction from Document in TypeScript\nDESCRIPTION: This snippet shows how to extract metadata directly from an MDocument instance. It configures extraction options for keywords and summary, then retrieves and logs the extracted metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/metadata-extraction.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Configure metadata extraction options\nawait doc.extractMetadata({\n  keywords: true,  // Extract important keywords\n  summary: true,   // Generate a concise summary\n});\n\n// Retrieve the extracted metadata\nconst meta = doc.getMetadata();\nconsole.log('Extracted Metadata:', meta);\n\n// Example Output:\n// Extracted Metadata: {\n//   keywords: [\n//     'exercise',\n//     'health benefits',\n//     'cardiovascular health',\n//     'mental wellbeing',\n//     'stress reduction',\n//     'sleep quality'\n//   ],\n//   summary: 'Regular exercise provides multiple health benefits including improved cardiovascular health, muscle strength, and mental wellbeing. Key benefits include stress reduction, better sleep, weight management, and increased energy. Recommended exercise duration is 150 minutes per week.'\n// }\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Mastra Client\nDESCRIPTION: Basic initialization of the MastraClient with the default development server configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from \"@mastra/client-js\";\n\nconst client = new MastraClient({\n  baseUrl: \"http://localhost:4111\", // Default Mastra development server port\n});\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1-alpha.44\nDESCRIPTION: Changelog entry documenting dependency updates for alpha version 44\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [14064f2]\n  - @mastra/core@0.1.27-alpha.66\n  - @mastra/memory@0.0.2-alpha.46\n```\n\n----------------------------------------\n\nTITLE: MCPClient resources() Method\nDESCRIPTION: Retrieves a list of available resources from the MCP server.  It returns a Promise that resolves with a `ListResourcesResult` object. The specific structure of `ListResourcesResult` is not detailed but contains the list of available resources.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync resources(): Promise<ListResourcesResult>\n```\n\n----------------------------------------\n\nTITLE: Installing Memory Package\nDESCRIPTION: These commands demonstrate how to install the `@mastra/memory` package using npm, pnpm, or yarn.  The package is a dependency for using the memory processors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/memory\n# または\npnpm add @mastra/memory\n# または\nyarn add @mastra/memory\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Example of how to format the .env file with your OpenAI API key for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/faithfulness/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Install Memory Package with npm\nDESCRIPTION: This command installs the @mastra/memory package using npm.  This package is required to add memory capabilities to Mastra agents. The copy button allows users to copy the command for easy execution in their terminal.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Querying Last Messages from a Thread Using TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve the last 50 messages from a specific thread by using the Memory class's query method. It initializes a Memory instance and calls the query function with the necessary parameters, specifically focusing on fetching recent messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/query.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  /* config */\n});\n\n// Get last 50 messages\nconst { messages, uiMessages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    last: 50,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Fixing Cloudflare Deployer\nDESCRIPTION: This code snippet signifies a general fix for the Cloudflare deployer.  It indicates that there was an issue with the Cloudflare deployer that needed to be addressed, improving its overall functionality or stability. This might involve resolving configuration problems or addressing errors that could occur during the deployment process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_1\n\nLANGUAGE: TEXT\nCODE:\n```\n85a2461: Fix cloudflare deployer\n```\n\n----------------------------------------\n\nTITLE: Adding CommonJS support\nDESCRIPTION: This patch adds support for CommonJS module format. This allows the Mastra package to be used in environments that require CommonJS modules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/CHANGELOG.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n- bb4f447: Add support for commonjs\n```\n\n----------------------------------------\n\nTITLE: Configuring Vitest Test Setup for Mastra\nDESCRIPTION: Test setup configuration that attaches necessary listeners for Mastra eval execution. Required for capturing eval results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { beforeAll } from 'vitest';\nimport { attachListeners } from '@mastra/evals';\n\nbeforeAll(async () => {\n  await attachListeners();\n});\n```\n\n----------------------------------------\n\nTITLE: Dependency Version History in Markdown\nDESCRIPTION: Changelog entries showing version updates and dependency changes for the bird-checker-with-nextjs package, tracking changes from version 0.1.1-alpha.43 through 0.0.1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# bird-checker-with-nextjs\n\n## 0.0.1\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n```\n\n----------------------------------------\n\nTITLE: Defining Forecast Schema\nDESCRIPTION: Defines a Zod schema for validating the weather forecast data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\nconst forecastSchema = z.array(\n  z.object({\n    date: z.string(),\n    maxTemp: z.number(),\n    minTemp: z.number(),\n    precipitationChance: z.number(),\n    condition: z.string(),\n    location: z.string(),\n  }),\n);\n```\n\n----------------------------------------\n\nTITLE: Using ToneConsistencyMetric for Tone Evaluation\nDESCRIPTION: This code snippet demonstrates how to use the `ToneConsistencyMetric` class to compare the emotional tone between two texts (input/output) and to analyze the tone stability within a single text. It imports the metric class, instantiates it, and calls the `measure` method in both modes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/tone-consistency.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ToneConsistencyMetric();\n\n// 入力と出力のトーンを比較\nconst result1 = await metric.measure(\n  \"I love this amazing product!\",\n  \"This product is wonderful and fantastic!\"\n);\n\n// 単一のテキストでのトーンの安定性を分析\nconst result2 = await metric.measure(\n  \"The service is excellent. The staff is friendly. The atmosphere is perfect.\",\n  \"\"  // 単一テキスト分析のための空文字列\n);\n\nconsole.log(result1.score); // 0-1のトーン一貫性スコア\nconsole.log(result2.score); // 0-1のトーン安定性スコア\n```\n\n----------------------------------------\n\nTITLE: Query Last Messages - Memory Class - TypeScript\nDESCRIPTION: This snippet shows how to retrieve the last 50 messages from a specified thread using the `query` method of the `Memory` class. It initializes a `Memory` instance and calls the `query` method with the `threadId` and `selectBy` options to fetch the messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/query.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  /* config */\n});\n\n// 最後の50件のメッセージを取得\nconst { messages, uiMessages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    last: 50,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Rendering Reference Cards - React - JavaScript\nDESCRIPTION: This code snippet illustrates the use of the ReferenceCards component in a React application. It is designed to display various API references neatly and is an integral part of the documentation structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/index.mdx#2025-04-22_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\n<ReferenceCards />\n```\n\n----------------------------------------\n\nTITLE: Generating Speech - JavaScript\nDESCRIPTION: This code snippet shows the transition from generating audio results using the deprecated package to using the new package's method for speaking text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/speechify/README.md#2025-04-22_snippet_4\n\nLANGUAGE: diff\nCODE:\n```\n- const { audioResult } = await tts.generate({ text: 'Hello' });\n+ const stream = await voice.speak('Hello');\n```\n\n----------------------------------------\n\nTITLE: Documenting Function Returns with PropertiesTable\nDESCRIPTION: Shows how to document what a function returns using the PropertiesTable component for structured information about return properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_4\n\nLANGUAGE: mdx\nCODE:\n```\n## Returns\n\n<PropertiesTable\n  content={[\n    {\n      name: \"transformedData\",\n      type: \"string\",\n      description:\n        \"The final transformed data after applying the function logic.\",\n    },\n    {\n      name: \"metadata\",\n      type: \"object\",\n      description: \"Additional information about the transformation.\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: Command to install project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/hybrid-vector-search/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Configuring LibSQL Storage\nDESCRIPTION: Demonstrates how to configure Mastra to use LibSQL as the storage provider for workflow snapshots. It shows how to instantiate the `DefaultStorage` class with a configuration object specifying the database URL and authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/snapshots.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { DefaultStorage } from \"@mastra/core/storage/libsql\";\n\nconst mastra = new Mastra({\n  storage: new DefaultStorage({\n    config: {\n      url: \"file:storage.db\", // ローカルファイルベースのデータベース\n      // 本番環境の場合:\n      // url: process.env.DATABASE_URL,\n      // authToken: process.env.DATABASE_AUTH_TOKEN,\n    },\n  }),\n  workflows: {\n    weatherWorkflow,\n    travelWorkflow,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Custom Configuration of ContextRelevancyMetric in TypeScript\nDESCRIPTION: This code demonstrates how to customize the ContextRelevancyMetric by setting the `scale` option. The scale option allows adjusting the range of the relevance score. Requires `@ai-sdk/openai` and `@mastra/evals/llm` dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-relevancy.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextRelevancyMetric } from \"@mastra/evals/llm\";\n\n// モデルを評価用に設定\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextRelevancyMetric(model, {\n  scale: 100, // 0-1の代わりに0-100のスケールを使用\n  context: [\n    \"ベーシックプランは月額$10です\",\n    \"プロプランには月額$30の高度な機能が含まれています\",\n    \"エンタープライズプランはカスタム価格です\",\n    \"当社は2020年に設立されました\",\n    \"世界中にオフィスがあります\"\n  ]\n});\n\nconst result = await metric.measure(\n  \"私たちの価格プランは何ですか？\",\n  \"ベーシック、プロ、エンタープライズプランを提供しています。\",\n);\n\n// 出力例:\n// {\n//   score: 60,\n//   info: {\n//     reason: \"5つのステートメントのうち3つが価格プランに関連しています。会社の設立やオフィスの場所に関するステートメントは価格の問い合わせには関連していません。\"\n//   }\n// }\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Project with Custom Settings in Bash\nDESCRIPTION: This command creates a new Mastra project with custom settings. It specifies a custom directory, selects specific components, sets the default LLM provider, and includes example code. Options can be adjusted as needed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/init.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmastra init --dir src/mastra --components agents,tools --llm openai --example\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Using NPM Create Command\nDESCRIPTION: Creates a new Mastra project using the create-mastra package via npm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/creating-a-new-project.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Updating Instance Creation - JavaScript\nDESCRIPTION: This code snippet shows the change in how to create an instance of the voice processing class. It demonstrates switching from 'SpeechifyTTS' to 'SpeechifyVoice' and updating the configuration properties accordingly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/speechify/README.md#2025-04-22_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n- const tts = new SpeechifyTTS({\n-   model: {\n-     name: 'simba-multilingual',\n-     voice: 'george',\n-   }\n- });\n+ const voice = new SpeechifyVoice({\n+   speechModel: {\n+     name: 'simba-english',\n+   },\n+   speaker: 'george'\n+ });\n```\n\n----------------------------------------\n\nTITLE: ToneConsistencyMetric Example Usage with Modes TypeScript\nDESCRIPTION: Illustrates a complete example of using ToneConsistencyMetric in both consistency and stability modes. The consistency mode compares the sentiment between two input texts, while the stability mode analyzes sentiment variations within a single input text. The expected output for each mode is also shown.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/tone-consistency.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ToneConsistencyMetric();\n\n// Tone Consistency Mode\nconst consistencyResult = await metric.measure(\n  \"This product is fantastic and amazing!\",\n  \"The product is excellent and wonderful!\"\n);\n// Example output:\n// {\n//   score: 0.95,\n//   info: {\n//     responseSentiment: 0.8,\n//     referenceSentiment: 0.75,\n//     difference: 0.05\n//   }\n// }\n\n// Tone Stability Mode\nconst stabilityResult = await metric.measure(\n  \"Great service! Friendly staff. Perfect atmosphere.\",\n  \"\"\n);\n// Example output:\n// {\n//   score: 0.9,\n//   info: {\n//     avgSentiment: 0.6,\n//     sentimentVariance: 0.1\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Agent Creation with AI SDK Model - TypeScript\nDESCRIPTION: This snippet demonstrates creating a Mastra agent using a model directly from the Vercel AI SDK. It imports the OpenAI module from `@ai-sdk/openai` and uses it to specify the model in the `Agent` constructor. The code shows how to define an agent with instructions and then use it to generate a response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"Instructions for the agent...\",\n  model: openai(\"gpt-4-turbo\"), // Model comes directly from AI SDK\n});\n\nconst result = await agent.generate(\"What is the weather like?\");\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/upstash via npm\nDESCRIPTION: This command installs the @mastra/upstash package as a dependency in your project. It allows you to use Upstash as a provider for Mastra's vector store and database functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/upstash\n```\n\n----------------------------------------\n\nTITLE: Creating a Mastra project using mastra CLI\nDESCRIPTION: These commands install the `mastra` CLI globally and then use it to create a new project. The installation command ensures the latest version of the CLI is used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/creating-a-new-project.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g mastra@latest\nmastra create\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the HTML chunking example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-html/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/chunk-html\n```\n\n----------------------------------------\n\nTITLE: Generating Responses with MastraClient\nDESCRIPTION: This code demonstrates how to generate responses using the MastraClient. It retrieves an agent by ID and then calls the generate method with a list of messages to simulate interaction with the agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Get a reference to your local agent\nconst agent = client.getAgent(\"dev-agent-id\");\n\n// Generate responses\nconst response = await agent.generate({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Hello, I'm testing the local development setup!\"\n    }\n  ]\n});\n```\n\n----------------------------------------\n\nTITLE: Step Definition with Suspend Point - Typescript\nDESCRIPTION: This snippet shows a step definition that includes a `suspend` call, pausing workflow execution.  Upon resuming, the step receives data in `context.inputData`, enabling it to continue processing with the new information. This demonstrates the async/await flow of suspend and resume functionality in Mastra workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/resume.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Step definition with suspend point\nconst reviewStep = new Step({\n  id: \"review\",\n  execute: async ({ context, suspend }) => {\n    // First part of execution\n    const initialAnalysis = analyzeData(context.inputData.data);\n\n    if (initialAnalysis.needsReview) {\n      // Suspend execution here\n      await suspend({ analysis: initialAnalysis });\n\n      // This code runs after resume() is called\n      // context.inputData now contains any data provided during resume\n      return {\n        reviewedData: enhanceWithFeedback(initialAnalysis, context.inputData.feedback)\n      };\n    }\n\n    return { reviewedData: initialAnalysis };\n  }\n});\n\nconst { runId, resume, start } = workflow.createRun();\n\nawait start({\n  inputData: {\n    data: \"some data\"\n  }\n});\n\n// Later, resume the workflow\nconst result = await resume({\n  runId: \"workflow-123\",\n  stepId: \"review\",\n  context: {\n    // This data will be available in `context.inputData`\n    feedback: \"Looks good, but improve section 3\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Running Support Agent Demo\nDESCRIPTION: Command to execute the support agent demo that demonstrates token limiting functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm run support\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Middleware to Mastra Server - TypeScript\nDESCRIPTION: This code snippet demonstrates how to add custom middleware functions to a Mastra server. Middleware can be applied globally or to specific routes, allowing for functionality like authentication, logging, and CORS handling. The example shows both global middleware and route-specific middleware using `registerApiRoute`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\n\nexport const mastra = new Mastra({\n  // 他の設定オプション\n  server: {\n    middleware: [\n    {\n      handler: async (c, next) => {\n        // 例: 認証チェックを追加\n        const authHeader = c.req.header('Authorization');\n        if (!authHeader) {\n          return new Response('Unauthorized', { status: 401 });\n        }\n\n        // 次のミドルウェアまたはルートハンドラに進む\n        await next();\n      },\n      path: '/api/*'\n    },\n    // すべてのルートにミドルウェアを追加\n    async (c, next) => {\n      // 例: リクエストログを追加\n      console.log(`${c.req.method} ${c.req.url}`);\n      await next();\n    },\n  ]\n});\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a copy of the example environment variables file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/hybrid-vector-search/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with Low Contextual Recall\nDESCRIPTION: This TypeScript snippet demonstrates evaluating a response with low contextual recall.  The response provides information that is not supported by the provided context. The `ContextualRecallMetric` assigns a low score to indicate the lack of relevant information in the response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/contextual-recall.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  '太陽系には8つの惑星があります。',\n  '水星は太陽に最も近いです。',\n  '金星は最も暑い惑星です。',\n  '火星は赤い惑星と呼ばれています。',\n];\n\nconst metric3 = new ContextualRecallMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = '太陽系について教えてください。';\nconst response3 = '木星は太陽系で最大の惑星です。';\n\nconsole.log('例 3 - 低リコール:');\nconsole.log('コンテキスト:', context3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// 出力例:\n// メトリック結果: { score: 0, reason: '出力のいずれもコンテキストによってサポートされていません。' }\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors in Upstash Vector Store in TypeScript\nDESCRIPTION: The `upsert()` method allows adding or updating vectors in the specified index within Upstash. It requires the index name and the vectors to be upserted, with optional metadata and IDs parameters for additional context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to upsert into\",\n    },\n    {\n      name: \"vectors\",\n      type: \"number[][]\",\n      description: \"Array of embedding vectors\",\n    },\n    {\n      name: \"metadata\",\n      type: \"Record<string, any>[]\",\n      isOptional: true,\n      description: \"Metadata for each vector\",\n    },\n    {\n      name: \"ids\",\n      type: \"string[]\",\n      isOptional: true,\n      description: \"Optional vector IDs (auto-generated if not provided)\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Execute TypeScript Code with Bun\nDESCRIPTION: This code snippet shows how to execute the TypeScript code using the Bun runtime. The `npx bun` command directly executes the specified TypeScript file, running the defined agent interaction logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpx bun src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Project Structure\nDESCRIPTION: This code snippet outlines the project structure for the stock price agent, showing the directories for agents, tools, and the main index file, along with the package.json and .env files. It provides a clear overview of how the project is organized.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/stock-agent.mdx#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nstock-price-agent/\n├── src/\n│   ├── agents/\n│   │   └── stockAgent.ts\n│   ├── tools/\n│   │   └── stockPrices.ts\n│   └── index.ts\n├── package.json\n└── .env\n```\n\n----------------------------------------\n\nTITLE: Creating Function Title and Description in Markdown\nDESCRIPTION: Shows how to start a reference page with a title and brief description that explains what the function does and its purpose.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# MyFunction Reference\n\nThe MyFunction utility in Mastra allows you to transform data before passing it to the engine.\n```\n\n----------------------------------------\n\nTITLE: Running the Example Application\nDESCRIPTION: Command to start the Chain of Thought RAG workflow example after configuration is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with Cloudflare Deployer\nDESCRIPTION: Example of initializing the CloudflareDeployer and integrating it with a Mastra application. Shows the basic configuration including account scope, project name, routes, worker namespace, and authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { CloudflareDeployer } from '@mastra/deployer-cloudflare';\n\nconst deployer = new CloudflareDeployer({\n  scope: 'your-account-id',\n  projectName: 'your-project-name',\n  routes: [\n    {\n      pattern: 'example.com/*',\n      zone_name: 'example.com',\n      custom_domain: true,\n    },\n  ],\n  workerNamespace: 'your-namespace',\n  auth: {\n    apiToken: 'your-api-token',\n    apiEmail: 'your-email',\n  },\n});\n\nconst mastra = new Mastra({\n  deployer,\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Speak Method with Text Stream Input\nDESCRIPTION: Shows how to use the `speak()` method with a text stream input. It imports the `Readable` stream from Node.js and creates a stream of strings that are then passed to the `speak()` method. The output is an audio stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.speak.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Readable } from \"stream\";\nconst textStream = Readable.from([\"こんにちは\", \" ストリーム\", \" から\", \" です！\"]);\nconst audioStreamFromTextStream = await voice.speak(textStream);\n```\n\n----------------------------------------\n\nTITLE: Set Google API Key\nDESCRIPTION: Sets the Google API key as an environment variable. This API key is required for authenticating with the Google Cloud services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/google/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nGOOGLE_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Configuring the Mastra Agent\nDESCRIPTION: This code sets up a Mastra agent with specific instructions, a model, and the vector query tool. The agent is designed to answer questions based on the provided context and uses the vector query tool to retrieve relevant information. It's configured to explicitly state when the context lacks sufficient information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const ragAgent = new Agent({\n  name: \"RAG Agent\",\n  instructions: `You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.\n    Important: When asked to answer a question, please base your answer only on the context provided in the tool. \n    If the context doesn't contain enough information to fully answer the question, please state that explicitly.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    vectorQueryTool,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/create-workflow/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: JSON-LD Schema for Blog Posting\nDESCRIPTION: This JSON-LD snippet provides structured data about the blog posting for search engines and other applications. It defines the context, type, headline, publication date, modification date, description, image URL, author, and URL of the blog post, enabling richer search results and better SEO. The schema describes a blog post announcing the new book.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"Announcing our new book: Principles of Building AI agents\",\"datePublished\":\"2025-03-12\",\"dateModified\":\"2025-03-12\",\"description\":\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\",\"image\":\"/og/blog?title=Announcing%20our%20new%20book%3A%20Principles%20of%20Building%20AI%20agents&date=Mar 12, 2025\",\"url\":\"https://mastra.ai/blog/principles-of-ai-engineering\",\"author\":{\"@type\":\"Company\",\"name\":\"Mastra\"}}\n```\n\n----------------------------------------\n\nTITLE: HTML for Mastra AI Blog Post Layout\nDESCRIPTION: This HTML snippet defines the layout and structure of a Mastra AI blog post page. It includes the navigation bar, back link to the blog, article heading, metadata, and content. The HTML defines the structure using classes for styling and also includes a reference to a logo image.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_6\n\nLANGUAGE: html\nCODE:\n```\n<style><script src=\"/_vercel/insights/script.js\" defer=\"\" data-sdkn=\"@vercel/analytics/react\" data-sdkv=\"1.4.1\"></script><script async=\"\" src=\"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/E63P0H7150OW/E63P0H7150OW.js.gz\"></script></head><!--$--><!--/$--><body class=\"antialiased dark __variable_1e4310 __variable_ed711f __variable_20916a __variable_d65c78 __variable_3ba0ff\"><div class=\"page flex flex-col w-full mx-auto font-sans overflow-hidden overflow-y-scroll h-full\"><nav class=\"z-50 sticky h-[60px] top-0 border-[0.5px] border-x-0 border-t-0 border-border-1\"><div class=\"flex xl:max-w-[64.25rem] border-t-0 border-border-1 max-h-[49px] md:max-h-none mx-auto justify-between items-center pl-3 pr-4 py-3 bg-[rgba(10,10,10,0.25)]\"><a class=\"rounded-full\" href=\"/\"><img alt=\"mastra\" loading=\"lazy\" width=\"24\" height=\"23\" decoding=\"async\" data-nimg=\"1\" class=\"w-[5.5rem] md:w-[7.5rem] md:h-[2rem]\" style=\"color:transparent\" src=\"/logo.svg\"></a><div class=\"flex items-center justify-between\"><button class=\"grid place-items-center md:hidden\"><span class=\"sr-only\">Open main menu</span><svg width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\"><rect x=\"1\" y=\"7.5\" width=\"14\" height=\"1\" rx=\"0.5\" style=\"transform-origin:center\" class=\"transition-transform duration-150 ease-ease-out-quad translate-y-[-3.5px]\"></rect><rect x=\"1\" y=\"7.5\" width=\"14\" height=\"1\" rx=\"0.5\" style=\"transform-origin:center\" class=\"transition-transform duration-150 ease-ease-out-quad translate-y-[3.5px]\"></rect></svg></button></div><ul class=\" hidden md:flex items-center gap-2\"><li><a class=\"font-medium text-white rounded-md hover:bg-[rgba(41,41,41,0.50)] md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 md:text-text-3\" href=\"/blog\">Blog</a></li><li><a target=\"_blank\" href=\"/examples\" class=\"font-medium rounded-md hover:bg-[rgba(41,41,41,0.50)]  md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 text-white md:text-text-3\">Examples</a></li><li><a target=\"_blank\" href=\"/docs\" class=\"font-medium rounded-md hover:bg-[rgba(41,41,41,0.50)]  md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 text-white md:text-text-3\">Docs</a></li></ul><ul data-open=\"false\" class=\"group blur-bg fixed text-2xl top-12 left-0 w-full h-full bg-[hsla(0,0%,4%,.8)] md:blur-0 md:backdrop-blur-none data-[open=true]:opacity-100 data-[open-true]:translate-y-0 data-[open=false]:-translate-y-5 md:data-[open=false]:translate-y-0 data-[open=false]:hidden md:data-[open=false]:flex md:rounded-none flex flex-col items-start px-1 pt-6 gap-3 border-border-1 border-t-[0.5px] md:px-0 md:py-0 md:bg-transparent md:border-none md:flex-row md:w-auto font-normal md:static md:gap-[1.18rem] md:items-center transition-transform ease-ease-out-quad\"><li><a class=\"font-medium text-white md:hidden rounded-md hover:bg-[rgba(41,41,41,0.50)] md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 md:text-text-3\" href=\"/blog\">Blog</a></li><li><a target=\"_blank\" href=\"/examples\" class=\"font-medium md:hidden rounded-md hover:bg-[rgba(41,41,41,0.50)]  md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 text-white md:text-text-3\">Examples</a></li><li><a target=\"_blank\" href=\"/docs\" class=\"font-medium md:hidden rounded-md hover:bg-[rgba(41,41,41,0.50)]  md:text-[0.9rem] transition-colors hover:text-white py-2 px-3 text-white md:text-text-3\">Docs</a></li><ul class=\"flex w-full flex-col p-2 text-text-5 md:p-0 md:flex-row gap-5 md:items-center \"><li><a target=\"_blank\" href=\"https://github.com/mastra-ai/mastra\" class=\"font-medium w-fit rounded-md opacity-90 transition-colors hover:opacity-100 flex items-center gap-2 justify-start pl-[7px] pr-2.5 py-2 h-[2.125rem] text-white text-sm\"><svg class=\"w-[22px] h-[22px] transition-colors text-[#E6E6E6] hover:text-white\"><use href=\"/icons/sprite.svg#github\"></use></svg><div class=\"flex gap-1 items-center\"><span>10.3k</span><svg class=\"h-3 w-3 text-[#E6E6E6]\"><use href=\"/icons/sprite.svg#star\"></use></svg></div></a></li><li class=\"w-fit md:w-full\"><a class=\"bg-white rounded-md hover:opacity-90 w-full py-[0.56rem] lg:w-auto justify-center group flex h-[2.125rem] items-center gap-1 px-4 lg:py-2 font-semibold text-[0.9rem] text-black\" href=\"/cloud-beta\"><span> <!-- -->Request Access</span></a></li></ul></ul></div></nav><div class=\"flex-1  w-full mx-auto\"><div class=\"px-5\"><section class=\"mx-auto relative pt-[50px] px-4 mb-20 max-w-xl\"><a class=\"flex absolute items-center z-50 -left-[35%]  group gap-1\" href=\"/blog\"><svg class=\" group-hover:text-text-6  text-text-3 size-3 transition-colors\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"currentColor\" role=\"img\" focusable=\"false\" aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M10.7803 4.78033C11.0732 4.48744 11.0732 4.01256 10.7803 3.71967C10.4874 3.42678 10.0126 3.42678 9.71967 3.71967L5.71967 7.71967C5.42933 8.01001 5.42643 8.47986 5.71318 8.77376L9.61581 12.7738C9.90508 13.0702 10.3799 13.0761 10.6764 12.7868C10.9729 12.4976 10.9787 12.0227 10.6895 11.7262L7.30417 8.25649L10.7803 4.78033Z\"></path></svg><span class=\"text-text-3 text-sm group-hover:text-text-6 transition-colors\">Blog</span></a><script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"Announcing our new book: Principles of Building AI agents\",\"datePublished\":\"2025-03-12\",\"dateModified\":\"2025-03-12\",\"description\":\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\",\"image\":\"/og/blog?title=Announcing%20our%20new%20book%3A%20Principles%20of%20Building%20AI%20agents&date=Mar 12, 2025\",\"url\":\"https://mastra.ai/blog/principles-of-ai-engineering\",\"author\":{\"@type\":\"Company\",\"name\":\"Mastra\"}}</script><h1 class=\"title font-semibold text-2xl text-white tracking-tighter\">Announcing our new book: Principles of Building AI agents</h1><div class=\"flex justify-between items-center mt-2 mb-8 text-sm\"><p class=\"text-sm text-neutral-400 dark:text-neutral-400\">Mar 12, 2025</p></div><article class=\"prose prose-pre:text-5xl\"><h2 id=\"principles-of-building-ai-agents\"><a href=\"#principles-of-building-ai-agents\" class=\"anchor\"></a>Principles of Building AI agents</h2>\n<img alt=\"Sam, Shane, and Abhi with the Principles of Building AI agents book\" loading=\"lazy\" width=\"800\" height=\"400\" decoding=\"async\" data-nimg=\"1\" class=\"rounded-lg\" style=\"color:transparent\" srcset=\"/_next/image?url=%2Fimages%2Fbooklaunch.jpg&amp;w=828&amp;q=75 1x, /_next/image?url=%2Fimages%2Fbooklaunch.jpg&amp;w=1920&amp;q=75 2x\" src=\"/_next/image?url=%2Fimages%2Fbooklaunch.jpg&amp;w=1920&amp;q=75\">\n<p>Today is YC demo day and we're excited to announce the release of our new book: Principles of Building AI agents. While we've been giving print copies away to attendees, the <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://mastra.ai/book\">digital version is available to everyone</a>.</p>\n<p>The book covers everything you need to get started building AI agents and applications, such as: the basics of choosing a model, prompt engineering 101, building your first agent, workflows and evals, and even serverless deployment.</p>\n<p>Here's a glimpse at the foreward, told directly in my (Sam's) voice. It gets at why we wrote the book:</p>\n<h2 id=\"foreward\"><a href=\"#foreward\" class=\"anchor\"></a>Foreward</h2>\n<p>For the last three months, I’ve been holed up in an apartment in San Francisco’s Dogpatch district with my cofounders, Shane Thomas and Abhi Aiyer.</p>\n<p>We’re building an open-source JavaScript frame- work called Mastra to help people build their own AI agents and assistants.</p>\n<p>We’ve come to the right spot.</p>\n<p>We’re in the Winter 2025 batch of YCombinator, the most popular startup incubator in the world (colloquially, YC W25).</p>\n<p>Over half of the batch is building some sort of “vertical agent” — AI application generating CAD diagrams for aerospace engineers, Excel financials for private equity, a customer support agent for iOS apps.</p>\n<p>These three months have come at some personal sacrifice.</p>\n<p>Shane has traveled from South Dakota with his girlfriend Elizabeth, their three-year-old daughter and newborn son. I usually have 50-50 custody of my seven-year-old son and five-year-old daughter, but for these three months I’m down to every-other- weekend. Abhi’s up from LA, where he bleeds Lakers purple and gold.</p>\n<p>Our backstory is that Shane, Abhi and I met while building a popular open-source JavaScript website framework called Gatsby. I was the co- founder, and Shane and Abhi were key engineers.</p>\n<p>While OpenAI and Anthropic’s models are widely available, the secrets of building effective AI applications are hidden in niche Twitter/X accounts, in-person SF meetups, and founder groupchats.</p>\n<p>But AI engineering is just a new domain, like data engineering a few years ago, or DevOps before that. It’s not impossibly complex. An engineer with a framework like Mastra should be able get up to speed in a day or two. With the right tools, it’s easy to build an agent as it is to build a website.</p>\n<p>This book is intentionally a short read, even with the code examples and diagrams we’ve included. It should fit in your back pocket, or slide into your purse. You should be able to use the code examples and get something simple working in a day or two.</p>\n<h2 id=\"getting-the-book\"><a href=\"#getting-the-book\" class=\"anchor\"></a>Getting the book</h2>\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/mcp using pnpm\nDESCRIPTION: This command installs the @mastra/mcp package using pnpm. It's necessary for using MCP functionality within Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/mcp@latest\n```\n\n----------------------------------------\n\nTITLE: Configure and Run Workflow - TypeScript\nDESCRIPTION: This code snippet configures the workflow using the `Workflow` class. It defines a trigger schema with a topic field, adds the `copywriterStep` and `editorStep` sequentially, and then creates and starts a run of the workflow with a specific topic ('React JavaScript frameworks').\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    topic: z.string(),\n  }),\n});\n\n// ステップを順番に実行します。\nmyWorkflow.step(copywriterStep).then(editorStep).commit();\n\nconst { runId, start } = myWorkflow.createRun();\n\nconst res = await start({\n  triggerData: { topic: \"React JavaScript frameworks\" },\n});\nconsole.log(\"Results: \", res.results);\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork Constructor in TypeScript\nDESCRIPTION: This code snippet shows the constructor signature for the AgentNetwork class. It takes a configuration object (`AgentNetworkConfig`) as input, which includes the network's name, instructions for the routing agent, the language model to use for routing, and an array of specialized agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor(config: AgentNetworkConfig)\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install required project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Custom Deployer Implementation in TypeScript\nDESCRIPTION: This code demonstrates how to extend the abstract Deployer class to create a custom deployer. It shows the implementation of the deploy method, which handles the deployment process including preparing the output directory and bundling the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/deployer.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Deployer } from \"@mastra/deployer\";\n\n// Create a custom deployer by extending the abstract Deployer class\nclass CustomDeployer extends Deployer {\n  constructor() {\n    super({ name: 'custom-deployer' });\n  }\n\n  // Implement the abstract deploy method\n  async deploy(outputDirectory: string): Promise<void> {\n    // Prepare the output directory\n    await this.prepare(outputDirectory);\n    \n    // Bundle the application\n    await this._bundle('server.ts', 'mastra.ts', outputDirectory);\n    \n    // Custom deployment logic\n    // ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch for Contributing\nDESCRIPTION: Command to create a new git branch for contributing changes to Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b feature/your-feature-name\n```\n\n----------------------------------------\n\nTITLE: Implementing Copywriter Step Execution\nDESCRIPTION: Defines the copywriter step that generates blog post content based on a provided topic. Includes error handling for missing topic data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterStep = new Step({\n  id: \"copywriterStep\",\n  execute: async ({ context }) => {\n    if (!context?.triggerData?.topic) {\n      throw new Error(\"Topic not found in trigger data\");\n    }\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.triggerData.topic}`,\n    );\n    console.log(\"copywriter result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Loading REB2B JavaScript Library Asynchronously\nDESCRIPTION: This snippet defines a function to dynamically load the REB2B JavaScript library from an S3 bucket using a provided key. It creates a script element, sets its attributes for asynchronous loading, and inserts it before the first script in the document. The code also sets a version number and calls the load function with a specific key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nreb2b.load = function (key) {\n  var script = document.createElement(\"script\");\n  script.type = \"text/javascript\";\n  script.async = true;\n  script.src = \"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/\" + key + \"/reb2b.js.gz\";\n  var first = document.getElementsByTagName(\"script\")[0];\n  first.parentNode.insertBefore(script, first);\n};\nreb2b.SNIPPET_VERSION = \"1.0.1\";\nreb2b.load(\"4N210HEJYQ6Z\");\n```\n\n----------------------------------------\n\nTITLE: Project Structure for Vercel Deployment\nDESCRIPTION: Shows the basic file structure created by the deployer for a Vercel deployment, including the vercel.json configuration file and the application entry point.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/vercel/README.md#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nyour-project/\n├── vercel.json     # Deployment configuration\n└── index.mjs       # Application entry point\n```\n\n----------------------------------------\n\nTITLE: Running the Hierarchical Multi-Agent Example\nDESCRIPTION: Command to start the hierarchical multi-agent example application. This will execute the demonstration of the supervisor planning agent orchestrating other agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（Sarvam）\nDESCRIPTION: Sarvamを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、SarvamVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { SarvamVoice } from \"@mastra/voice-sarvam\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new SarvamVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Storage Package with npm\nDESCRIPTION: The snippet provides the command to install the PostgreSQL storage package using npm. This package is necessary for setting up a PostgreSQL connection through Mastra Core's library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/postgresql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/pg\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file, which is required for running the hallucination tests.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Defining IndexStats Interface in TypeScript\nDESCRIPTION: This interface specifies the properties for index statistics, including dimension, count, and metric, which can be cosine, euclidean, or dotproduct.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/qdrant.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Run the MCP build script\nDESCRIPTION: Executes the build script defined in `package.json` using pnpm, which compiles the TypeScript server code and makes the output file executable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm run build:mcp\n```\n\n----------------------------------------\n\nTITLE: Testing Agent with `curl` after `mastra dev`\nDESCRIPTION: This snippet demonstrates how to test an agent after starting the development server with `mastra dev`. It uses `curl` to send a POST request to the `/api/agents/myAgent/generate` endpoint with a JSON payload containing a user message. It requires the development server to be running and the agent 'myAgent' to be defined.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/cli/dev.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/myAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"Hello, how can you assist me today?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Installing MCP Registry Package\nDESCRIPTION: This code snippet illustrates how to install the MCP Registry Registry package using different package managers like npm, pnpm, and yarn. No specific prerequisites other than having one of these package managers installed. This installation step is crucial to enable the use of MCP Registry Registry functionalities. The snippet requires an internet connection to fetch the package from a repository.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-registry-registry/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Using npm\\nnpm install @mastra/mcp-registry-registry\n```\n\nLANGUAGE: bash\nCODE:\n```\n# Using pnpm\\npnpm add @mastra/mcp-registry-registry\n```\n\nLANGUAGE: bash\nCODE:\n```\n# Using yarn\\nyarn add @mastra/mcp-registry-registry\n```\n\n----------------------------------------\n\nTITLE: Set GitHub Personal Access Token\nDESCRIPTION: Example command to set the GitHub personal access token as an environment variable. This is necessary for the GitHub integration to authenticate with the GitHub API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nGITHUB_PAT=your_personal_access_token\n```\n\n----------------------------------------\n\nTITLE: Building and Running for Search (NPM)\nDESCRIPTION: This snippet shows how to build the documentation and then run the development server to enable search functionality using `pageFind`. First, it builds the `html` files, then runs the development server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Creating Mastra project with custom components and LLM provider\nDESCRIPTION: Example command demonstrating how to create a Mastra project with specific components and LLM provider selection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest -c agents,tools -l anthropic\n```\n\n----------------------------------------\n\nTITLE: CORS Support Middleware Example - TypeScript\nDESCRIPTION: This middleware function demonstrates how to add CORS (Cross-Origin Resource Sharing) headers to responses. It sets headers for `Access-Control-Allow-Origin`, `Access-Control-Allow-Methods`, and `Access-Control-Allow-Headers`. It also handles preflight OPTIONS requests by returning a 204 No Content response.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    // CORSヘッダーを追加\n    c.header(\"Access-Control-Allow-Origin\", \"*\");\n    c.header(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\");\n    c.header(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\");\n\n    // プリフライトリクエストを処理\n    if (c.req.method === \"OPTIONS\") {\n      return new Response(null, { status: 204 });\n    }\n\n    await next();\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Initialize TypeScript project (npm)\nDESCRIPTION: Initializes a TypeScript project with necessary dependencies using npm.  This sets up the environment for developing with Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y \nnpm install typescript tsx @types/node mastra --save-dev \nnpm install @mastra/core zod @ai-sdk/openai npx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Initializing Project and Installing Dependencies (Bash)\nDESCRIPTION: Commands to create a new directory, initialize a Node.js project, and install required dependencies for the stock agent project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir stock-price-agent\ncd stock-price-agent\nnpm init -y\nnpm install @mastra/core zod @ai-sdk/openai\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install all required project dependencies using PNPM package manager. This must be executed in the project root directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Using toolsets with generate() or stream()\nDESCRIPTION: This shows how to pass the toolsets obtained from the `getToolsets()` method to the `generate` or `stream` methods of an Agent. The tool names are namespaced in the format `serverName.toolName`. It is useful for dynamically providing tools to agent calls.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst res = await agent.stream(prompt, {\n  toolsets: await mcp.getToolsets(),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing RecipeCompletenessJudge Class for Gluten Evaluation\nDESCRIPTION: Creates a specialized judge class that extends MastraAgentJudge to evaluate recipe gluten content. The class uses the defined prompts to evaluate recipes and provide reasoning about gluten content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { type LanguageModel } from '@mastra/core/llm';\\nimport { MastraAgentJudge } from '@mastra/evals/judge';\\nimport { z } from 'zod';\\nimport { GLUTEN_INSTRUCTIONS, generateGlutenPrompt, generateReasonPrompt } from './prompts';\\n\\nexport class RecipeCompletenessJudge extends MastraAgentJudge {\\n  constructor(model: LanguageModel) {\\n    super('Gluten Checker', GLUTEN_INSTRUCTIONS, model);\\n  }\\n\\n  async evaluate(output: string): Promise<{\\n    isGlutenFree: boolean;\\n    glutenSources: string[];\\n  }> {\\n    const glutenPrompt = generateGlutenPrompt({ output });\\n    const result = await this.agent.generate(glutenPrompt, {\\n      output: z.object({\\n        isGlutenFree: z.boolean(),\\n        glutenSources: z.array(z.string()),\\n      }),\\n    });\\n\\n    return result.object;\\n  }\\n\\n  async getReason(args: { isGlutenFree: boolean; glutenSources: string[] }): Promise<string> {\\n    const prompt = generateReasonPrompt(args);\\n    const result = await this.agent.generate(prompt, {\\n      output: z.object({\\n        reason: z.string(),\\n      }),\\n    });\\n\\n    return result.object.reason;\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Gluten Evaluation Prompt (TypeScript)\nDESCRIPTION: Generates a prompt for evaluating the gluten content of a recipe. The prompt instructs the LLM to check for specific gluten sources like wheat, barley, rye, flour, pasta, and bread, and to provide a structured JSON response indicating whether the recipe is gluten-free and listing any identified gluten sources.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nexport const generateGlutenPrompt = ({ output }: { output: string }) => `Check if this recipe is gluten-free.\\n\nCheck for:\\n- Wheat\\n- Barley\\n- Rye\\n- Common sources like flour, pasta, bread\n\nExample with gluten:\\n\"Mix flour and water to make dough\"\nResponse: {\\n  \"isGlutenFree\": false,\\n  \"glutenSources\": [\"flour\"]\\n}\n\nExample gluten-free:\\n\"Mix rice, beans, and vegetables\"\nResponse: {\\n  \"isGlutenFree\": true,\\n  \"glutenSources\": []\\n}\n\nRecipe to analyze:\\n${output}\n\nReturn your response in this format:\\n{\n  \"isGlutenFree\": boolean,\n  \"glutenSources\": [\"list ingredients containing gluten\"]\n}`;\n```\n\n----------------------------------------\n\nTITLE: Running the HTML Chunking Example\nDESCRIPTION: Command to execute the HTML chunking example application using PNPM.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-html/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: API Rename: PlayAITTS to PlayAIVoice\nDESCRIPTION: This snippet documents the renaming of the `PlayAITTS` class to `PlayAIVoice` within the @mastra/voice-playai package. This change is part of an effort to provide a more consistent naming scheme. It requires updating import statements and class references in existing code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/CHANGELOG.md#_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Fixing process.versions.node.split in Cloudflare deployer\nDESCRIPTION: This code snippet represents a fix applied to the Cloudflare deployer. Specifically, it addresses an issue related to the process.versions.node.split function, likely ensuring compatibility and correct execution within the Cloudflare environment. This fix would prevent errors arising from incorrect node version parsing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_0\n\nLANGUAGE: TEXT\nCODE:\n```\ncdc0498: Fix process.versions.node.split in cloudflare deployer\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install project dependencies using pnpm package manager\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI API Key\nDESCRIPTION: Sets up the necessary environment variable for the OpenAI API key, which is required for using the Faithfulness metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Version History in Markdown\nDESCRIPTION: Markdown formatted changelog showing version increments from 0.0.1-alpha.0 through 0.0.1, documenting dependency updates for @mastra/rag and @mastra/vector-pg packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# insert-embedding-in-pgvector\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pg@0.0.1-alpha.19\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pg@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [72f7fb9]\n- Updated dependencies [9625602]\n  - @mastra/vector-pg@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Getting Available Speakers in ElevenLabsVoice\nDESCRIPTION: This snippet describes the getSpeakers method, which is a function of the ElevenLabsVoice class. It retrieves a list of available speakers, each with their respective details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nReturns a list of available speakers with their details.\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Using CLI\nDESCRIPTION: Alternative approach to create a Mastra project by first installing the CLI globally and then using the create command.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/creating-a-new-project.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g mastra@latest\nmastra create\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_14\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/changelog-2025-01-17\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-17</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-17</h2><span class=\"text-xs text-left text-text-3\">Jan 17, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 17, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_10\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/api-endpoints\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Every API needs a natural language endpoint</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Every API needs a natural language endpoint</h2><span class=\"text-xs text-left text-text-3\">Jan 25, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 25, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/shane.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Next.js Initial Seed Data Configuration for Blog Route\nDESCRIPTION: This snippet configures the initial data structure for a blog post page, including the buildId, asset prefix, URL parts, and the initial component tree structure with routing information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\n0:[\"$\",\"$L7\",null,{\"buildId\":\"QDi6qfXR2RAetcLnInglW\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"blog\",\"principles-of-ai-engineering\"],\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"principles-of-ai-engineering\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"principles-of-ai-engineering\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]}\n```\n\n----------------------------------------\n\nTITLE: Adding React-Specific ESLint Plugins\nDESCRIPTION: Configuration for adding React-specific ESLint plugins (react-x and react-dom) with their recommended TypeScript rules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/client-side-tools/README.md#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// eslint.config.js\nimport reactX from 'eslint-plugin-react-x';\nimport reactDom from 'eslint-plugin-react-dom';\n\nexport default tseslint.config({\n  plugins: {\n    // Add the react-x and react-dom plugins\n    'react-x': reactX,\n    'react-dom': reactDom,\n  },\n  rules: {\n    // other rules...\n    // Enable its recommended typescript rules\n    ...reactX.configs['recommended-typescript'].rules,\n    ...reactDom.configs.recommended.rules,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM in Bash\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/word-inclusion/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: useCompletion Hook Implementation - TypeScript (API Route)\nDESCRIPTION: This code shows the implementation of an API route for handling completion requests. It imports the `mastra` instance, retrieves a specific agent, streams the agent's response based on the received messages, and returns the stream as a data stream response using `toDataStreamResponse()`. This serves as the backend for the `useCompletion` hook in a frontend application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages);\n\n  return stream.toDataStreamResponse();\n}\n```\n\n----------------------------------------\n\nTITLE: Running Mastra Server - Bash\nDESCRIPTION: This command starts the HTTP server built by the Mastra build process. It executes the `index.mjs` file located in the `.mastra/output` directory using Node.js, which starts the server and exposes the API endpoints.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnode .mastra/output/index.mjs\n```\n\n----------------------------------------\n\nTITLE: Update CJS bundling\nDESCRIPTION: Update cjs bundling to make sure files are split. This aims to improve modularity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/CHANGELOG.md#_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: HTML Document Head Elements\nDESCRIPTION: This snippet shows the contents of the HTML document's `<head>` section. It includes links to stylesheets, preload directives for scripts and fonts, and a favicon link.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<head><link rel=\"stylesheet\" href=\"/_next/static/css/75c6bf80605c00cd.css\" data-precedence=\"next\"><link rel=\"preload\" as=\"script\" fetchpriority=\"low\" href=\"/_next/static/chunks/webpack-ee8bb2449cda5318.js\"><script src=\"/_next/static/chunks/e6d15c94-4f932d7c2fc2e75c.js\" async=\"\"></script><script src=\"/_next/static/chunks/615-2c124797ed702c55.js\" async=\"\"></script><script src=\"/_next/static/chunks/main-app-71a79cc788e2f8a3.js\" async=\"\"></script><script src=\"/_next/static/chunks/333-64fe985764faf0d9.js\" async=\"\"></script><link rel=\"icon\" href=\"/favicon.ico?v=5\" sizes=\"any\"><script src=\"/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js\" nomodule=\"\"></script><link rel=\"preload\" href=\"/_next/static/media/16043059f9ddb145-s.p.otf\" as=\"font\" crossorigin=\"\" type=\"font/otf\"><link rel=\"preload\" href=\"/_next/static/media/4473ecc91f70f139-s.p.woff\" as=\"font\" crossorigin=\"\" type=\"font/woff\"><link rel=\"preload\" href=\"/_next/static/media/463dafcda517f24f-s.p.woff\" as=\"font\" crossorigin=\"\" type=\"font/woff\"><link rel=\"preload\" href=\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\" as=\"font\" crossorigin=\"\" type=\"font/woff2\"><link rel=\"preload\" href=\"/_next/static/media/f2f91ba921b45b28-s.p.woff2\" as=\"font\" crossorigin=\"\" type=\"font/woff2\">\n```\n\n----------------------------------------\n\nTITLE: Cloudflare Deployer Configuration\nDESCRIPTION: Basic configuration example for the Cloudflare deployer showing required parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nnew CloudflareDeployer({\n  scope: 'your-cloudflare-account-id',\n  projectName: 'your-project-name',\n  // For complete configuration options, see the reference documentation\n})\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Age-Related Bias Example in TypeScript\nDESCRIPTION: Shows evaluation of a response with subtle age-related bias using the Bias metric. It includes query, response, and result logging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'How do different age groups perform at work?';\nconst response2 =\n  'Younger workers tend to be more innovative and quick to adapt, though they can be somewhat unreliable and job-hop frequently. Older employees are generally more stable and experienced, but sometimes struggle to keep up with rapid changes in technology. Middle-aged workers often provide the best balance of skills and reliability.';\n\nconsole.log('Example 2 - Mixed Bias:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.7, reason: 'The response contains subtle age-related stereotypes and assumptions about work performance.' }\n```\n\n----------------------------------------\n\nTITLE: Basic Context Precision Metric Usage (TypeScript)\nDESCRIPTION: This code snippet demonstrates the basic usage of the `ContextPrecisionMetric` class to evaluate the relevance of context nodes in generating a response. It initializes the metric with a language model and a context array, then measures the precision of the context given an input and output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-precision.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { ContextPrecisionMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ContextPrecisionMetric(model, {\n  context: [\n    \"光合成は、植物が太陽光からエネルギーを作り出すために使用する生物学的プロセスです。\",\n    \"植物は成長するために土壌から水と栄養素を必要とします。\",\n    \"光合成の過程で副産物として酸素が生成されます。\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"光合成とは何ですか？\",\n  \"光合成は、植物が太陽光をエネルギーに変換するプロセスです。\",\n);\n\nconsole.log(result.score); // 0-1の精度スコア\nconsole.log(result.info.reason); // スコアの説明\n```\n\n----------------------------------------\n\nTITLE: Initializing Agents with Voice Capabilities (TypeScript)\nDESCRIPTION: This code snippet initializes two agents, `agent1` and `agent2`, with different voice configurations. `agent1` uses a `CompositeVoice` that combines OpenAI for speech-to-text and PlayAI for text-to-speech. `agent2` uses OpenAI's voice functionality for both speech-to-text and text-to-speech. It imports necessary dependencies such as `@ai-sdk/openai`, `@mastra/core/agent`, `@mastra/core/voice`, `@mastra/voice-openai`, `@mastra/voice-playai` and standard modules like `fs` and `path`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/adding-voice-capabilities.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n// 必要な依存関係をインポート\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { CompositeVoice } from '@mastra/core/voice';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { createReadStream, createWriteStream } from 'fs';\nimport { PlayAIVoice } from '@mastra/voice-playai';\nimport path from 'path';\n\n// 聞くことと話すことの両方の機能を持つエージェント1を初期化\nconst agent1 = new Agent({\n  name: 'Agent1',\n  instructions: `あなたはSTTとTTSの両方の機能を持つエージェントです。`,\n  model: openai('gpt-4o'),\n  voice: new CompositeVoice({\n    input: new OpenAIVoice(), // 音声をテキストに変換\n    output: new PlayAIVoice(), // テキストを音声に変換\n  }),\n});\n\n// 聞くことと話すことの両方の機能にOpenAIのみを使用するエージェント2を初期化\nconst agent2 = new Agent({\n  name: 'Agent2',\n  instructions: `あなたはSTTとTTSの両方の機能を持つエージェントです。`,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Langfuse Environment Variables\nDESCRIPTION: This snippet shows the environment variables required to configure Langfuse integration with Mastra. `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` are mandatory for authentication, while `LANGFUSE_BASEURL` is optional and defaults to cloud.langfuse.com if not provided. These variables need to be set in the environment where Mastra is running.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langfuse.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nLANGFUSE_PUBLIC_KEY=your_public_key\nLANGFUSE_SECRET_KEY=your_secret_key\nLANGFUSE_BASEURL=https://cloud.langfuse.com\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Project\nDESCRIPTION: Command to build a Mastra project for deployment to the target platform.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the example directory for inserting embeddings in Chroma.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-chroma/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/insert-embedding-in-chroma\n```\n\n----------------------------------------\n\nTITLE: Testing an Agent with cURL in Bash\nDESCRIPTION: This snippet demonstrates how to test an agent after running 'mastra dev' using a cURL command. It sends a POST request to the local development server, specifying the agent ID and providing a user message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/dev.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/myAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"Hello, how can you assist me today?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in .env\nDESCRIPTION: Sets the OpenAI API key in the .env file. Replace 'sk-your-api-key-here' with your actual API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/calling-agent-from-workflow/README.md#_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the project dependencies using PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Generated Mastra project structure\nDESCRIPTION: This code block shows the generated project structure after initializing a Mastra project. It includes the `src/mastra/index.ts` entry point, `package.json`, and `tsconfig.json` files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/local-dev/creating-a-new-project.mdx#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nmy-project/\n├── src/\n│   └── mastra/\n│       └── index.ts    # Mastra entry point\n├── package.json\n└── tsconfig.json\n```\n\n----------------------------------------\n\nTITLE: Testing Agent Endpoint with Curl\nDESCRIPTION: This snippet demonstrates how to test an agent endpoint using the `curl` command. It sends a POST request to the specified URL with a JSON payload containing a message. The endpoint is assumed to be running locally on port 4111.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/weatherAgent/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"messages\": [\"What is the weather in London?\"]}'\n```\n\n----------------------------------------\n\nTITLE: Defining Editor Step in Mastra Workflow\nDESCRIPTION: This snippet defines the editor step in the workflow. It retrieves the copy from the previous copywriter step, passes it to the editor agent for refinement, and returns the edited copy.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorStep = new Step({\n  id: \"editorStep\",\n  execute: async ({ context }) => {\n    const copy = context?.getStepResult<{ copy: number }>(\"copywriterStep\")?.copy;\n\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${copy}`,\n    );\n    console.log(\"editor result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra Project Structure\nDESCRIPTION: Standard directory structure generated for a new Mastra project, showing the main source directory and configuration files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/creating-a-new-project.mdx#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nmy-project/\n├── src/\n│   └── mastra/\n│       └── index.ts    # Mastra entry point\n├── package.json\n└── tsconfig.json\n```\n\n----------------------------------------\n\nTITLE: Installing project dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Define Context Analysis Step Typescript\nDESCRIPTION: Defines a workflow step `analyzeContext` using the `Step` class from `@mastra/core/workflows`. This step analyzes the context based on the initial query. It retrieves the query from the trigger, generates an analysis prompt, and uses the RAG agent to generate an initial analysis. The analysis is then returned as the step's output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-workflow-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst analyzeContext = new Step({\n  id: \"analyzeContext\",\n  outputSchema: z.object({\n    initialAnalysis: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const query = context?.getStepResult<{ query: string }>(      \"trigger\",\n    )?.query;\n\n    const analysisPrompt = `${query} 1. まず、取得したコンテキストチャンクを注意深く分析し、重要な情報を特定します。`;\n\n    const analysis = await ragAgent?.generate(analysisPrompt);\n    console.log(analysis?.text);\n    return {\n      initialAnalysis: analysis?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning repository and navigating to project directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the pgvector embedding example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/insert-embedding-in-pgvector\n```\n\n----------------------------------------\n\nTITLE: useChat Hook Implementation - TypeScript (Component)\nDESCRIPTION: This snippet shows the usage of the `useChat` hook from `@ai-sdk/react` in a React component. The component handles chat interactions by managing messages, input, and form submission. The `api` property in `useChat` should point to an API endpoint that handles agent stream requests. This allows for real-time chat interactions in a frontend application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/ai-sdk.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useChat } from '@ai-sdk/react';\n\nexport function ChatComponent() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}: {m.content}\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Say something...\"\n        />\n      </form>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Monitoring and Auto-Resume with resumeWithEvent() - TypeScript\nDESCRIPTION: Demonstrates monitoring a workflow for suspended event steps and automatically resuming it using `resumeWithEvent()`. It uses the `watch()` method to check for suspended 'approval' events and simulates an automatic approval after a timeout.  Error handling is included for the auto-resume attempt.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resumeWithEvent.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Start a workflow\nconst { start, watch, resumeWithEvent } = workflow.createRun();\n\n// Watch for suspended event steps\nwatch(async ({ activePaths }) => {\n  const isApprovalEventSuspended =\n    activePaths.get(\"__approval_event\")?.status === \"suspended\";\n  // Check if suspended at the approval event step\n  if (isApprovalEventSuspended) {\n    console.log(\"Workflow waiting for approval\");\n\n    // In a real scenario, you would wait for the actual event\n    // Here we're simulating with a timeout\n    setTimeout(async () => {\n      try {\n        await resumeWithEvent(\"approval\", {\n          approved: true,\n          approverName: \"Auto Approver\",\n        });\n      } catch (error) {\n        console.error(\"Failed to auto-resume workflow:\", error);\n      }\n    }, 5000); // Wait 5 seconds before auto-approving\n  }\n});\n\n// Start the workflow\nawait start({ triggerData: { requestId: \"auto-123\" } });\n```\n\n----------------------------------------\n\nTITLE: Defining User Input Step in TypeScript\nDESCRIPTION: This code defines a step in the workflow that retrieves user input. It uses the `Step` class from `@mastra/core/workflows` and `zod` for schema validation. The `execute` function retrieves the user input from the context's `triggerData` and returns it.  The `outputSchema` defines the structure of the output, ensuring it includes a string field named `userInput`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n// Step 1: Get user input\nconst getUserInput = new Step({\n  id: 'getUserInput',\n  execute: async ({ context }) => {\n    // In a real application, this might come from a form or API\n    return { userInput: context.triggerData.input };\n  },\n  outputSchema: z.object({ userInput: z.string() }),\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Upstash Package (Bash)\nDESCRIPTION: This command demonstrates how to install the `@mastra/upstash` package using npm. This package is required to use Upstash as a storage option for Mastra workflows.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/upstash\n```\n\n----------------------------------------\n\nTITLE: Running the Keyword Coverage Example\nDESCRIPTION: Command to execute the Keyword Coverage metric example. This will run the configured scenarios and output the coverage statistics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/keyword-coverage/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Example Frontmatter (Bash)\nDESCRIPTION: This snippet illustrates an example of YAML frontmatter used in Mastra documentation pages. It defines the `title` and `description` metadata for the page.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n---\ntitle: \"Introduction | Mastra Docs\"\ndescription: \"Mastra is a TypeScript agent framework. It helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals.\"\n---\n```\n\n----------------------------------------\n\nTITLE: Example Chef Agent JSON Response\nDESCRIPTION: This is an example of the JSON response received when interacting with the chef agent through the API. It contains the `text` field, which provides the generated response from the agent based on the input query.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"text\": \"You can make delicious pancakes! Here's a simple recipe...\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running the JSON Chunking Example\nDESCRIPTION: Command to execute the JSON chunking example script using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-json/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: MCPConfiguration Constructor Definition\nDESCRIPTION: Defines the constructor for the MCPConfiguration class. It accepts an MCPConfigurationOptions object, which includes an optional ID, a record of server definitions, and an optional timeout value.  This allows initializing an MCPConfiguration instance with various server configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconstructor({\n  id?: string;\n  servers: Record<string, MastraMCPServerDefinition>;\n  timeout?: number;\n}: MCPConfigurationOptions)\n```\n\n----------------------------------------\n\nTITLE: Configuring Upstash Storage\nDESCRIPTION: Illustrates how to configure Mastra to use Upstash as the storage provider for workflow snapshots. It showcases the instantiation of the `UpstashStore` class with the necessary URL and token for connecting to the Upstash Redis-compatible database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/snapshots.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst mastra = new Mastra({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN,\n  }),\n  workflows: {\n    weatherWorkflow,\n    travelWorkflow,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing MastraCloudExporter\nDESCRIPTION: Initializes the MastraCloudExporter with an access token and optional logger and endpoint. This exporter sends telemetry data to Mastra Cloud. It requires a Mastra Cloud access token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cloud/README.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraCloudExporter } from '@mastra/cloud';\n\n// Initialize the exporter with your access token\nconst exporter = new MastraCloudExporter({\n  accessToken: process.env.MASTRA_CLOUD_ACCESS_TOKEN, // Your Mastra Cloud access token\n  logger: yourLoggerInstance, // Optional logger\n  endpoint: 'https://mastra-cloud-endpoint.example.com', // Mastra cloud endpoint\n});\n\n// Use with Mastra instance\nexport const mastra = new Mastra({\n  agents: { agent },\n  logger: createLogger({\n    name: 'Mastra',\n    level: 'info',\n  }),\n  telemetry: {\n    serviceName: 'My-Agent',\n    enabled: true,\n    sampling: {\n      type: 'always_on',\n    },\n    export: {\n      type: 'custom',\n      exporter: new MastraCloudExporter({\n        accessToken: process.env.MASTRA_CLOUD_ACCESS_TOKEN,\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Realtime Voice for Speech-to-Speech in Mastra\nDESCRIPTION: This snippet demonstrates how to configure the OpenAIRealtimeVoice component with custom settings for the chat model, including API key, model selection, and turn detection parameters. It also shows a simplified version with default settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-speech.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: 'your-openai-api-key',\n    model: 'gpt-4o-mini-realtime',\n    options: {\n      sessionConfig: {\n        turn_detection: {\n          type: 'server_vad',\n          threshold: 0.6,\n          silence_duration_ms: 1200,\n        },\n      },\n    },\n  },\n  speaker: 'alloy', // Default voice\n});\n\n// If using default settings the configuration can be simplified to:\nconst voice = new OpenAIRealtimeVoice();\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/vectorize with npm\nDESCRIPTION: This command installs the @mastra/vectorize package using npm. This is a prerequisite for using the VectorizeStore class in a TypeScript or JavaScript project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/vectorize/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/vectorize\n```\n\n----------------------------------------\n\nTITLE: Update CJS Bundling for File Splitting (Patch)\nDESCRIPTION: This patch updates the CommonJS (CJS) bundling process to ensure that files are properly split. This improves the performance and load times of the package in CJS environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: TTS with Azure Voice Agent\nDESCRIPTION: This code demonstrates how to use an Agent with Azure voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Azure's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { AzureVoice } from \"@mastra/voice-azure\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new AzureVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"en-US-JennyNeural\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Connecting to MCP Server in TypeScript\nDESCRIPTION: The connect method establishes a connection with the MCP server asynchronously. No parameters are needed, and it returns a void promise once connected. Ensure the server configuration is correct before attempting a connection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nasync connect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Initializing Summarization Metric\nDESCRIPTION: Configuration of the Summarization metric using OpenAI's GPT-4 model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new SummarizationMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Alternative Reb2b Tracking Integration with IIFE Pattern\nDESCRIPTION: This snippet provides an alternative implementation for initializing Reb2b tracking using an Immediately Invoked Function Expression (IIFE). It creates the reb2b object, defines tracking methods, and loads the tracking script from an S3 bucket with a different API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n!function () {\n  var reb2b = window.reb2b = window.reb2b || [];\n  if (reb2b.invoked) return;\n  reb2b.invoked = true;\n  reb2b.methods = [\"identify\", \"collect\"];\n  reb2b.factory = function (method) {\n    return function () {\n      var args = Array.prototype.slice.call(arguments);\n      args.unshift(method); reb2b.push(args);\n      return reb2b;\n    };\n  };\n  for (var i = 0; i < reb2b.methods.length; i++) {\n    var key = reb2b.methods[i];\n    reb2b[key] = reb2b.factory(key);\n  }\n  reb2b.load = function (key) {\n    var script = document.createElement(\"script\");\n    script.type = \"text/javascript\";\n    script.async = true;\n    script.src = \"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/\" + key + \"/reb2b.js.gz\";\n    var first = document.getElementsByTagName(\"script\")[0];\n    first.parentNode.insertBefore(script, first);\n  };\n  reb2b.SNIPPET_VERSION = \"1.0.1\";\n  reb2b.load(\"4N210HEJYQ6Z\");\n}();\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/voice-murf with npm\nDESCRIPTION: This command installs the `@mastra/voice-murf` package using npm, which is necessary for migrating from the deprecated `@mastra/speech-murf` package. The new package offers updated functionality and a revised API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/murf/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-murf\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry - Version 0.0.1\nDESCRIPTION: Changelog entry documenting version 0.0.1 and its alpha releases, tracking dependency updates to @mastra/core package across multiple versions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-parallel-steps/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# workflow-with-parallel-steps\n\n## 0.0.1\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- Updated dependencies [2f17a5f]\n- Updated dependencies [cb290ee]\n- Updated dependencies [b4d7416]\n- Updated dependencies [38b7f66]\n  - @mastra/core@0.2.0-alpha.84\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [30322ce]\n- Updated dependencies [78eec7c]\n- Updated dependencies [9625602]\n- Updated dependencies [8769a62]\n  - @mastra/core@0.2.0-alpha.83\n```\n\n----------------------------------------\n\nTITLE: Route-Specific Middleware in Mastra\nDESCRIPTION: Shows how to add middleware to specific routes using registerApiRoute.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nregisterApiRoute(\"/my-custom-route\", {\n  method: \"GET\",\n  middleware: [\n    async (c, next) => {\n      // Example: Add request logging\n      console.log(`${c.req.method} ${c.req.url}`);\n      await next();\n    },\n  ],\n  handler: async (c) => {\n    // you have access to mastra instance here\n    const mastra = c.get(\"mastra\");\n\n    // you can use the mastra instance to get agents, workflows, etc.\n    const agents = await mastra.getAgent(\"my-agent\");\n\n    return c.json({ message: \"Hello, world!\" });\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with mcp.run SSE URL in TypeScript\nDESCRIPTION: This TypeScript code shows how to configure the MCP using an SSE URL from mcp.run. It's important to load the SSE URL from an environment variable to manage it securely.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst mcp = new MCPConfiguration({\n  servers: {\n    marketing: {\n      url: new URL(process.env.MCP_RUN_SSE_URL!),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Client Package\nDESCRIPTION: Command to install the Mastra client library package using npm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/client-sdks/client-js/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Repository\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the multi-agent workflow example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/multi-agent-workflow\n```\n\n----------------------------------------\n\nTITLE: Deleting an Index in Typescript\nDESCRIPTION: This code deletes a vector index using the `vector.delete` method.  The `index-name` parameter specifies the index to delete. The method returns a promise that resolves with the deletion result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await vector.delete(\"index-name\");\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Voice Provider\nDESCRIPTION: Demonstrates configuration for OpenAI voice provider with speech and listening models. Includes settings for model name, API key, language, voice type and audio format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIVoice({\n  speechModel: {\n    name: \"gpt-3.5-turbo\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    language: \"en-US\", // Language code\n    voiceType: \"neural\", // Type of voice model\n  },\n  listeningModel: {\n    name: \"whisper-1\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    language: \"en-US\", // Language code\n    format: \"wav\", // Audio format\n  },\n  speaker: \"alloy\", // Example speaker name\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Faithfulness Response with Mastra\nDESCRIPTION: This TypeScript snippet demonstrates how to evaluate a highly faithful response using Mastra's FaithfulnessMetric. It defines a context, initializes the metric with an OpenAI model, provides a query and a corresponding highly faithful response. The measure method is used to evaluate the response and the results (score and reason) are printed to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/faithfulness.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst context1 = [\n  'The Tesla Model 3 was launched in 2017.',\n  'It has a range of up to 358 miles.',\n  'The base model accelerates 0-60 mph in 5.8 seconds.',\n];\n\nconst metric1 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context1,\n});\n\nconst query1 = 'Tell me about the Tesla Model 3.';\nconst response1 = 'The Tesla Model 3 was introduced in 2017. It can travel up to 358 miles on a single charge and the base version goes from 0 to 60 mph in 5.8 seconds.';\n\nconsole.log('Example 1 - High Faithfulness:');\nconsole.log('Context:', context1);\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric1.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'All claims are supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Running the Embedding Example\nDESCRIPTION: Command to start and run the embedding example application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Laminar Configuration Environment Variables\nDESCRIPTION: These environment variables are required to configure Laminar to work with Mastra. `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the Laminar API endpoint, and `OTEL_EXPORTER_OTLP_HEADERS` includes the API key and team ID for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/laminar.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.lmnr.ai:8443\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer your_api_key, x-laminar-team-id=your_team_id\"\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_3\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/prompt-engineering-with-llms\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Prompt Engineering with LLMs</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Prompt Engineering with LLMs</h2><span class=\"text-xs text-left text-text-3\">Feb 14, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Feb 14, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Similarity Text in Mastra\nDESCRIPTION: Demonstrates measuring similarity between nearly identical texts, showing how to call the measure method and interpret the results. The example compares similar sentences about a fox and a dog with minor variations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst text1 = 'The quick brown fox jumps over the lazy dog.';\nconst reference1 = 'A quick brown fox jumped over a lazy dog.';\n\nconsole.log('Example 1 - High Similarity:');\nconsole.log('Text:', text1);\nconsole.log('Reference:', reference1);\n\nconst result1 = await metric.measure(reference1, text1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    similarity: result1.info.similarity,\n  },\n});\n// Example Output:\n// Metric Result: { score: 0.7761194029850746, info: { similarity: 0.7761194029850746 } }\n```\n\n----------------------------------------\n\nTITLE: Starting Development Services for Testing\nDESCRIPTION: Command to start the required development services for testing Mastra components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npnpm run dev:services:up\n```\n\n----------------------------------------\n\nTITLE: Initializing Reb2b Tracking Integration in JavaScript\nDESCRIPTION: This snippet initializes the Reb2b tracking library by creating a global reb2b object, defining tracking methods (identify and collect), and loading the tracking script from an S3 bucket. It implements a factory pattern to create method wrappers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nwindow.reb2b = window.reb2b || [];\nif (!window.reb2b.invoked) {\n  window.reb2b.invoked = true;\n  window.reb2b.methods = [\"identify\", \"collect\"];\n  window.reb2b.factory = function(method) {\n    return function() {\n      var args = Array.prototype.slice.call(arguments);\n      args.unshift(method);\n      window.reb2b.push(args);\n      return window.reb2b;\n    };\n  };\n  window.reb2b.methods.forEach(function(key) {\n    window.reb2b[key] = window.reb2b.factory(key);\n  });\n  window.reb2b.SNIPPET_VERSION = \"1.0.1\";\n\n  const script = document.createElement(\"script\");\n  script.async = true;\n  script.src = \"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/E63P0H7150OW/E63P0H7150OW.js.gz\";\n  document.head.appendChild(script);\n}\n```\n\n----------------------------------------\n\nTITLE: Initialize TypeScript project (yarn)\nDESCRIPTION: Initializes a TypeScript project with necessary dependencies using yarn. This sets up the environment for developing with Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nyarn init -y\nyarn add typescript tsx @types/node mastra --dev\nyarn add @mastra/core zod @ai-sdk/openai\nyarn dlx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_12\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/introducing-mastra-evals\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Introducing Evals in Mastra</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Introducing Evals in Mastra</h2><span class=\"text-xs text-left text-text-3\">Jan 20, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 20, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/nik.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Add Support for CommonJS (Patch)\nDESCRIPTION: This patch introduces support for the CommonJS (CJS) module system. This enables the package to be used in a wider range of environments and projects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_6\n\n\n\n----------------------------------------\n\nTITLE: Creating Workflow Steps and Initializing Workflow in TypeScript\nDESCRIPTION: This snippet shows how to create individual steps for a workflow and initialize the workflow using Mastra. It defines three steps that perform calculations based on input and previous step outputs, and sets up a workflow with a trigger schema.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/sequential-steps.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst stepOne = new Step({\n  id: \"stepOne\",\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new Step({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 }\n    }\n\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 }\n  },\n});\n\nconst stepThree = new Step({\n  id: \"stepThree\",\n  execute: async ({ context }) => {\n    if (context.steps.stepTwo.status !== \"success\") {\n      return { tripledValue: 0 }\n    }\n\n    return { tripledValue: context.steps.stepTwo.output.incrementedValue * 3 }\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Using onStepFinish Callback in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the `onStepFinish` callback to monitor the progress of a multi-step operation. This callback is triggered after each step, providing information about the text, tool calls, and tool results. This is useful for debugging and providing progress updates to the user. `onStepFinish` is available when generating text without structured output and when streaming is not used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await myAgent.generate(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onStepFinish: ({ text, toolCalls, toolResults }) => {\n      console.log(\"Step completed:\", { text, toolCalls, toolResults });\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Get Agent Evaluations with TypeScript\nDESCRIPTION: Retrieves evaluation results for the agent, including both CI evaluations and live evaluations. It uses the agent's `evals` method for CI evaluations and `liveEvals` method for live evaluations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// CI評価を取得\nconst evals = await agent.evals();\n\n// ライブ評価を取得\nconst liveEvals = await agent.liveEvals();\n```\n\n----------------------------------------\n\nTITLE: Using onFinish Callback with Streaming (TypeScript)\nDESCRIPTION: This code snippet shows how to use the `onFinish` callback when streaming responses from an agent. The `onFinish` callback provides detailed information about the completed interaction, including steps, text, finish reason, token usage, and reasoning details. It's useful for monitoring and logging agent activity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await myAgent.stream(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onFinish: ({\n      steps,\n      text,\n      finishReason, // 'complete', 'length', 'tool', etc.\n      usage, // token usage statistics\n      reasoningDetails, // additional context about the agent's decisions\n    }) => {\n      console.log(\"Stream complete:\", {\n        totalSteps: steps.length,\n        finishReason,\n        usage,\n      });\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Create a Weather Info Tool using Vercel AI SDK\nDESCRIPTION: This code snippet showcases how to create a weather information tool using the Vercel AI SDK's `tool` function. It defines a tool with a description, parameters (using Zod for validation), and an `execute` function. The `execute` function simulates fetching weather data based on the provided city. The `city` parameter is described to guide the agent's usage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\n\nexport const weatherInfo = tool({\n  description: \"Fetches the current weather information for a given city\",\n  parameters: z.object({\n    city: z.string().describe(\"The city to get weather for\"),\n  }),\n  execute: async ({ city }) => {\n    // Replace with actual API call\n    const data = await fetch(`https://api.example.com/weather?city=${city}`);\n    return data.json();\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: WordInclusionMetric Class Definition Typescript\nDESCRIPTION: Defines the `WordInclusionMetric` class, which extends the `Metric` class from `@mastra/core/eval`.  This class calculates the word inclusion score based on the presence of reference words in the output string.  It initializes with a set of words and implements a `measure` function to determine the coverage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/word-inclusion.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface WordInclusionResult extends MetricResult {\n  score: number;\n  info: {\n    totalWords: number;\n    matchedWords: number;\n  };\n}\n\nexport class WordInclusionMetric extends Metric {\n  private referenceWords: Set<string>;\n\n  constructor(words: string[]) {\n    super();\n    this.referenceWords = new Set(words);\n  }\n\n  async measure(input: string, output: string): Promise<WordInclusionResult> {\n    const matchedWords = [...this.referenceWords].filter(k => output.includes(k));\n    const totalWords = this.referenceWords.size;\n    const coverage = totalWords > 0 ? matchedWords.length / totalWords : 0;\n\n    return {\n      score: coverage,\n      info: {\n        totalWords: this.referenceWords.size,\n        matchedWords: matchedWords.length,\n      },\n    };\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Weather Agent Implementation (TypeScript)\nDESCRIPTION: This TypeScript code defines a `weatherAgent` that utilizes the OpenAI model (`gpt-4o-mini`) and the previously created `weatherTool` to provide weather information.  The agent is designed to be a helpful weather assistant, always asking for a location if none is provided and translating the location name if it's not in English.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { weatherTool } from \"../tools/weather-tool\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `You are a helpful weather assistant that provides accurate weather information.\n\n  Your primary function is to help users get weather details for specific locations. When responding:\n  - Always ask for a location if none is provided\n  - If the location name isn't in English, please translate it\n  - Include relevant details like humidity, wind conditions, and precipitation\n  - Keep responses concise but informative\n\n  Use the weatherTool to fetch current weather data.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { weatherTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies using pnpm\nDESCRIPTION: The snippet is used to install the necessary dependencies for the project using pnpm, a package manager. Ensure 'pnpm' is installed globally before running the command.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/interactive-story/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Deprecating Package Name in Changelog\nDESCRIPTION: Documents the deprecation of the `@mastra/speech-murf` package in favor of `@mastra/voice-murf`. Highlights the rename of the package and associated API changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n5b1af96: deprecate @mastra/speech-murf for @mastra/voice-murf\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the system-prompt example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/system-prompt\n```\n\n----------------------------------------\n\nTITLE: Manual Installation - Initialize TypeScript Project (pnpm)\nDESCRIPTION: These commands initialize a TypeScript project using pnpm, install necessary dependencies including `@mastra/core`, zod, and @ai-sdk/openai, and initialize the TypeScript compiler.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npnpm init\npnpm add typescript tsx @types/node mastra --save-dev\npnpm add @mastra/core zod @ai-sdk/openai\npnpm dlx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Set Speechify API Key (Bash)\nDESCRIPTION: Sets the Speechify API key as an environment variable.  This is required for authenticating with the Speechify API. The API key is then accessible to the SpeechifyVoice class for generating speech. Replace `your_api_key_here` with your actual Speechify API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport SPEECHIFY_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Text-to-Speech using ElevenLabsVoice\nDESCRIPTION: This snippet illustrates how to convert text to speech using the speak method of the ElevenLabsVoice class. It returns a ReadableStream containing the audio data, which can then be used for playback or further processing. The method requires an ElevenLabs API key to function correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/elevenlabs.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// テキストから音声へ\nconst audioStream = await voice.speak(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This code snippet demonstrates how to set up environment variables. Specifically, it shows how to define the OpenAI API key in a `.env` file. This key is required to use the OpenAI models for prompt alignment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/prompt-alignment.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1-alpha.47\nDESCRIPTION: Changelog entry documenting dependency updates for alpha version 47\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/memory@0.1.0-alpha.67\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/store-upstash@0.0.0-alpha.3\n  - @mastra/vector-pg@0.0.1-alpha.19\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example - TypeScript\nDESCRIPTION: Shows how to catch and handle `VectorStoreError` exceptions that may be thrown by the Upstash Vector Store. It demonstrates accessing the error code and details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/upstash.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Embedding Example\nDESCRIPTION: Command to start the example application that demonstrates embedding insertion in Chroma.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-chroma/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the content similarity example directory. This is the first step in setting up the content similarity example project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/content-similarity/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/content-similarity\n```\n\n----------------------------------------\n\nTITLE: Installing the Package\nDESCRIPTION: This command installs the @mastra/voice-openai-realtime package using npm. It adds the package and its dependencies to your project, allowing you to use the real-time voice integration in your Mastra application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/voice-openai-realtime\"\n```\n\n----------------------------------------\n\nTITLE: Updating imports from @mastra/speech-murf to @mastra/voice-murf\nDESCRIPTION: This code shows the required import statement change when migrating from the old `@mastra/speech-murf` package to the new `@mastra/voice-murf` package. `MurfTTS` is replaced by `MurfVoice`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/murf/README.md#2025-04-22_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n- import { MurfTTS } from '@mastra/speech-murf'\n+ import { MurfVoice } from '@mastra/voice-murf'\n```\n\n----------------------------------------\n\nTITLE: Installing LibSQL Storage\nDESCRIPTION: This command installs the `@mastra/storage-libsql` package using npm. This package provides the LibSQL storage implementation for the Mastra core.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/libsql.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/storage-libsql\n```\n\n----------------------------------------\n\nTITLE: Automatic Installation - Create Mastra Project (npm)\nDESCRIPTION: This command initiates the automatic installation of a new Mastra project using the `create-mastra` package with npm. It scaffolds the project with necessary configurations and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Applying Moderation Results and Logging with TypeScript and Mastra\nDESCRIPTION: This snippet defines a step for applying moderation actions and creating an audit log of the moderation process. It checks the moderation outcome and structures the return data accordingly. The audit log captures details such as the original content, moderation result, AI score, and timestamp.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 3: Apply moderation actions\nconst applyModeration = new Step({\n  id: 'applyModeration',\n  outputSchema: z.object({\n    finalStatus: z.string(),\n    content: z.string().optional(),\n    auditLog: z.object({\n      originalContent: z.string(),\n      moderationResult: z.string(),\n      aiScore: z.number(),\n      timestamp: z.string(),\n    }),\n  }),\n  execute: async ({ context }) => {\n    const analysisResult = context.getStepResult(analyzeContent);\n    const moderationResult = context.getStepResult(moderateContent);\n\n    // Create audit log\n    const auditLog = {\n      originalContent: analysisResult?.content || '',\n      moderationResult: moderationResult?.moderationResult || 'unknown',\n      aiScore: analysisResult?.aiAnalysisScore || 0,\n      timestamp: new Date().toISOString(),\n    };\n\n    // Apply moderation action\n    switch (moderationResult?.moderationResult) {\n      case 'approved':\n        return {\n          finalStatus: 'Content published',\n          content: moderationResult.moderatedContent,\n          auditLog,\n        };\n\n      case 'modified':\n        return {\n          finalStatus: 'Content modified and published',\n          content: moderationResult.moderatedContent,\n          auditLog,\n        };\n\n      case 'rejected':\n        return {\n          finalStatus: 'Content rejected',\n          auditLog,\n        };\n\n      default:\n        return {\n          finalStatus: 'Error in moderation process',\n          auditLog,\n        };\n    }\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Measure High Text Similarity\nDESCRIPTION: This snippet demonstrates how to measure the similarity between two almost identical text strings using the `ContentSimilarityMetric`. It logs the input texts and the resulting similarity score and info.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/content-similarity.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst text1 = 'The quick brown fox jumps over the lazy dog.';\nconst reference1 = 'A quick brown fox jumped over a lazy dog.';\n\nconsole.log('Example 1 - High Similarity:');\nconsole.log('Text:', text1);\nconsole.log('Reference:', reference1);\n\nconst result1 = await metric.measure(reference1, text1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    similarity: result1.info.similarity,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Telemetry\nDESCRIPTION: Configures OpenTelemetry integration for monitoring AI systems with sampling and export options\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\n\nconst mastra = new Mastra({\n  telemetry: {\n    serviceName: 'my-service',\n    enabled: true,\n    sampling: {\n      type: 'ratio',\n      probability: 0.5,\n    },\n    export: {\n      type: 'otlp',\n      endpoint: 'https://otel-collector.example.com/v1/traces',\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Deepgram Voice Configuration\nDESCRIPTION: Deepgram音声プロバイダーの初期化設定を示します。音声認識とテキスト変換のためのモデル名、スピーカー、APIキー、言語、トーン、およびオーディオ形式を指定します。この設定により、MastraはDeepgramの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_25\n\nLANGUAGE: typescript\nCODE:\n```\n// Deepgram Voice Configuration\nconst voice = new DeepgramVoice({\n  speechModel: {\n    name: \"nova-2\", // Example model name\n    speaker: \"aura-english-us\", // Example speaker name\n    apiKey: process.env.DEEPGRAM_API_KEY,\n    language: \"en-US\", // Language code\n    tone: \"formal\", // Tone setting\n  },\n  listeningModel: {\n    name: \"nova-2\", // Example model name\n    format: \"flac\", // Audio format\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/deployer-vercel Package with PNPM\nDESCRIPTION: Command to install the Vercel deployer package for Mastra applications using PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/vercel/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/deployer-vercel\n```\n\n----------------------------------------\n\nTITLE: Disconnecting from MCP Servers\nDESCRIPTION: This snippet shows the `disconnect()` method being called, which is an asynchronous operation that disconnects from all MCP servers and cleans up any associated resources. This is important for proper resource management and preventing memory leaks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/mcp-configuration.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync disconnect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog\nDESCRIPTION: Change history showing version updates and dependency changes for the workflow-with-separate-steps package, with numerous patch releases and corresponding @mastra/core dependency updates\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/workflow-with-separate-steps/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# workflow-with-separate-steps\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Prompt Alignment\nDESCRIPTION: Import statements for required OpenAI and Mastra evaluation dependencies\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PromptAlignmentMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Creating Problem Solver Prompt with TypeScript\nDESCRIPTION: This snippet sets up a prompt to help solve complex problems by exploring multiple solution paths. It describes thinking branches to guide the AI in navigating through technical, user experience, and business impact considerations while generating structured output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ntype ProblemSolvingVars = {\n  problem: string;\n};\n\nconst problemSolver = createPrompt<ProblemSolvingVars>('Solve complex problem', {\n  persona: 'Problem Solver',\n  outputFormat: 'markdown',\n})\n  .text('Solve this problem:\\n\\n{{problem}}')\n  .thinking({\n    branches: {\n      'Technical Solution': [\n        'Analyze technical requirements',\n        'Consider implementation options',\n        'Evaluate technical tradeoffs',\n      ],\n      'User Experience': ['Identify user needs', 'Design user interactions', 'Consider accessibility'],\n      'Business Impact': ['Assess costs', 'Evaluate timeline', 'Consider scalability'],\n    },\n  });\n\n// Usage example\nconst solution = problemSolver.toString({\n  problem: 'Design a new feature for uploading and processing large files in a web application',\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Deployers via npm\nDESCRIPTION: These commands install the Mastra deployers for Cloudflare, Vercel, and Netlify using npm.  Each deployer package provides the necessary tools to deploy a Mastra application to its respective platform.  Ensure Node.js and npm are installed before running these commands.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"# For Cloudflare\nnpm install @mastra/deployer-cloudflare\n\n# For Vercel\nnpm install @mastra/deployer-vercel\n\n# For Netlify\nnpm install @mastra/deployer-netlify\"\n```\n\n----------------------------------------\n\nTITLE: Converting Speech to Text\nDESCRIPTION: This TypeScript snippet shows how to convert audio back into text using the listen method of the AzureVoice instance. It expects the audioStream from the speech generation process as input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst text = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAI Voice Configuration\nDESCRIPTION: PlayAI音声プロバイダーの初期化設定を示します。音声合成のためのモデル名、スピーカー、APIキー、言語、速度を指定します。PlayAIは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはPlayAIの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_22\n\nLANGUAGE: typescript\nCODE:\n```\n// PlayAI Voice Configuration\nconst voice = new PlayAIVoice({\n  speechModel: {\n    name: \"playai-voice\", // Example model name\n    speaker: \"emma\", // Example speaker name\n    apiKey: process.env.PLAYAI_API_KEY,\n    language: \"en-US\", // Language code\n    speed: 1.0, // Speech speed\n  },\n  // PlayAI may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_6\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/agent-memory-guide\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Using Mastra's Agent Memory API</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Using Mastra's Agent Memory API</h2><span class=\"text-xs text-left text-text-3\">Feb 4, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Feb 4, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/tyler.png\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Defining Constructor Options for Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the constructor options for the TurbopufferVector class, detailing properties such as apiKey, baseUrl, and timeouts. It serves to configure the connection settings and behavior of the vector store client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"apiKey\",\n      type: \"string\",\n      description: \"The API key to authenticate with Turbopuffer\",\n    },\n    {\n      name: \"baseUrl\",\n      type: \"string\",\n      isOptional: true,\n      defaultValue: \"https://api.turbopuffer.com\",\n      description: \"The base URL for the Turbopuffer API\",\n    },\n    {\n      name: \"connectTimeout\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"10000\",\n      description:\n        \"The timeout to establish a connection, in ms. Only applicable in Node and Deno.\",\n    },\n    {\n      name: \"connectionIdleTimeout\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"60000\",\n      description:\n        \"The socket idle timeout, in ms. Only applicable in Node and Deno.\",\n    },\n    {\n      name: \"warmConnections\",\n      type: \"number\",\n      isOptional: true,\n      defaultValue: \"0\",\n      description:\n        \"The number of connections to open initially when creating a new client.\",\n    },\n    {\n      name: \"compression\",\n      type: \"boolean\",\n      isOptional: true,\n      defaultValue: \"true\",\n      description:\n        \"Whether to compress requests and accept compressed responses.\",\n    },\n    {\n      name: \"schemaConfigForIndex\",\n      type: \"function\",\n      isOptional: true,\n      description:\n        \"A callback function that takes an index name and returns a config object for that index. This allows you to define explicit schemas per index.\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Evaluating Tone Consistency of Agent Response with Vitest\nDESCRIPTION: This TypeScript snippet demonstrates how to evaluate the tone consistency of an agent's response using the `@mastra/evals` library within a Vitest test. It imports necessary modules, defines a test case within a `describe` block, creates a `ToneConsistencyMetric` instance, evaluates the agent's response using the `evaluate` function, and asserts that the resulting score is 1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/running-in-ci.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { describe, it, expect } from 'vitest';\nimport { evaluate } from \"@mastra/evals\";\nimport { ToneConsistencyMetric } from \"@mastra/evals/nlp\";\nimport { myAgent } from './index';\n\ndescribe('My Agent', () => {\n  it('should validate tone consistency', async () => {\n    const metric = new ToneConsistencyMetric();\n    const result = await evaluate(myAgent, 'Hello, world!', metric)\n\n    expect(result.score).toBe(1);\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Environment variable configuration for Unsplash and Anthropic API keys\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\n# Required for getting image\nNEXT_PUBLIC_UNSPLASH_ACCESS_KEY=your_unsplash_access_key\n\n# Required for AI processing\nANTHROPIC_API_KEY=your_anthropic_key\n```\n\n----------------------------------------\n\nTITLE: Stream Agent Response with TypeScript\nDESCRIPTION: Streams a response from an agent for real-time interactions. It uses the agent's `stream` method, taking a message array as a parameter, and provides two ways to process the data stream: using `processDataStream` utility or reading directly from the response body.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/agents.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst response = await agent.stream({\n  messages: [\n    {\n      role: \"user\",\n      content: \"物語を話して\",\n    },\n  ],\n});\n\n// processDataStreamユーティリティでデータストリームを処理\n response.processDataStream({\n      onTextPart: (text) => {\n        process.stdout.write(text);\n      },\n      onFilePart: (file) => {\n        console.log(file);\n      },\n      onDataPart: (data) => {\n        console.log(data);\n      },\n      onErrorPart: (error) => {\n        console.error(error);\n      },\n  });\n\n// 応答ボディから直接読み取ることもできます\nconst reader = response.body.getReader();\nwhile (true) {\n  const { done, value } = await reader.read();\n  if (done) break;\n  console.log(new TextDecoder().decode(value));\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing DeepgramVoice with custom configuration\nDESCRIPTION: This code snippet shows how to initialize the DeepgramVoice class with custom configuration options, including specifying the speech and listening models, API keys, and a default speaker.  It allows for fine-grained control over the Deepgram service's behavior. This uses `DeepgramVoiceConfig` to specify the `name` and `apiKey` for the models. The speaker is configured using `DeepgramVoiceId`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/deepgram.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DeepgramVoice } from \"@mastra/voice-deepgram\";\n\n// Initialize with custom configuration\nconst voice = new DeepgramVoice({\n  speechModel: {\n    name: 'aura',\n    apiKey: 'your-api-key',\n  },\n  listeningModel: {\n    name: 'nova-2',\n    apiKey: 'your-api-key',\n  },\n  speaker: 'asteria-en',\n});\n```\n\n----------------------------------------\n\nTITLE: Import FileTree Component Nextra TypeScript\nDESCRIPTION: Imports the `FileTree` component from the `nextra/components` module. This component is used to display the project's directory structure in a tree-like format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/project-structure.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { FileTree } from 'nextra/components';\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Faithfulness Response in TypeScript\nDESCRIPTION: Shows how to evaluate a response with some unsupported claims, resulting in a mixed faithfulness score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Python was created by Guido van Rossum.',\n  'The first version was released in 1991.',\n  'Python emphasizes code readability.',\n];\n\nconst metric2 = new FaithfulnessMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'What can you tell me about Python?';\nconst response2 = 'Python was created by Guido van Rossum and released in 1991. It is the most popular programming language today and is used by millions of developers worldwide.';\n\nconsole.log('Example 2 - Mixed Faithfulness:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'Only half of the claims are supported by the context.' }\n```\n\n----------------------------------------\n\nTITLE: Evaluating Summarization with openai and Mastra in TypeScript\nDESCRIPTION: This snippet demonstrates how to utilize the `SummarizationMetric` from the Mastra library for evaluating the quality of text summaries produced by an LLM using OpenAI's model. It requires the @ai-sdk/openai and @mastra/evals/llm libraries. The code measures the alignment and coverage of the generated summary compared to the original text, outputting scores (0 to 1) to assess summarization quality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/summarization.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { SummarizationMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new SummarizationMetric(model);\n\nconst result = await metric.measure(\n  \"The company was founded in 1995 by John Smith. It started with 10 employees and grew to 500 by 2020. The company is based in Seattle.\",\n  \"Founded in 1995 by John Smith, the company grew from 10 to 500 employees by 2020.\"\n);\n\nconsole.log(result.score); // Score from 0-1\nconsole.log(result.info); // Object containing detailed metrics about the summary\n```\n\n----------------------------------------\n\nTITLE: Fetching Agent Evaluations in Mastra AI (TypeScript)\nDESCRIPTION: This snippet shows how to get evaluation results for an agent, including both CI evaluations and live evaluations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/agents.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Get CI evaluations\nconst evals = await agent.evals();\n\n// Get live evaluations\nconst liveEvals = await agent.liveEvals();\n```\n\n----------------------------------------\n\nTITLE: Manual Installation - Initialize TypeScript Project (bun)\nDESCRIPTION: These commands initialize a TypeScript project using bun, install necessary dependencies including `@mastra/core`, zod, and @ai-sdk/openai, and initialize the TypeScript compiler.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nbun init -y\nbun add typescript tsx @types/node mastra --dev\nbun add @mastra/core zod @ai-sdk/openai\nbunx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Import ContentSimilarityMetric\nDESCRIPTION: This snippet imports the `ContentSimilarityMetric` class from the `@mastra/evals/nlp` module. This metric is used to calculate the similarity between two text strings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/content-similarity.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies\nDESCRIPTION: Imports the necessary modules from various libraries including `@ai-sdk/openai`, `@mastra/core`, `@mastra/pg`, and `@mastra/rag`. These modules provide functionalities for interacting with OpenAI, creating Mastra agents, managing PGVector, and building RAG pipelines.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/filter-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from '@mastra/core';\nimport { Agent } from '@mastra/core/agent';\nimport { PgVector } from '@mastra/pg';\nimport { createVectorQueryTool, MDocument, PGVECTOR_PROMPT } from '@mastra/rag';\nimport { embedMany } from 'ai';\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Toxicity Response in TypeScript\nDESCRIPTION: Demonstrates how to evaluate a response with explicit personal attacks using the Toxicity metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What do you think about the new team member?';\nconst response1 =\n  'That incompetent fool is a complete waste of space. They clearly bought their degree and have no business being here. Everyone hates working with them.';\n\nconsole.log('Example 1 - High Toxicity:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response contains severe personal attacks, derogatory language, and harmful generalizations.' }\n```\n\n----------------------------------------\n\nTITLE: Cloning Mastra Repository and Navigating to Example Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the specific example directory for LibSQL embedding insertion.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/insert-embedding-in-libsql\n```\n\n----------------------------------------\n\nTITLE: Setting SigNoz Environment Variables\nDESCRIPTION: These environment variables are required to configure OpenTelemetry (OTLP) to export data to SigNoz. `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the SigNoz ingestion endpoint, and `OTEL_EXPORTER_OTLP_HEADERS` provides the authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/signoz.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://ingest.{region}.signoz.cloud:443\nOTEL_EXPORTER_OTLP_HEADERS=signoz-ingestion-key=your_signoz_token\n```\n\n----------------------------------------\n\nTITLE: Setting LangSmith Environment Variables\nDESCRIPTION: This snippet shows the environment variables required to configure LangSmith for use with Mastra. These variables include the tracing flag, endpoint URL, API key, and project name. These need to be set in your environment before running Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langsmith.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nLANGSMITH_TRACING=true\nLANGSMITH_ENDPOINT=https://api.smith.langchain.com\nLANGSMITH_API_KEY=your-api-key\nLANGSMITH_PROJECT=your-project-name\n```\n\n----------------------------------------\n\nTITLE: Accessing Step Results with getStepResult in Mastra (TypeScript)\nDESCRIPTION: This code demonstrates accessing the results of a previous step using `context.getStepResult` in Mastra workflows, providing type safety. The `analyzeDataStep` uses the result of `fetchUserStep` and provides fallback if step result is not available.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new Step({\n  id: 'fetchUser',\n  outputSchema: z.object({\n    name: z.string(),\n    userId: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return { name: 'John Doe', userId: '123' };\n  },\n});\n\nconst analyzeDataStep = new Step({\n  id: \"analyzeData\",\n  execute: async ({ context }) => {\n    // Type-safe access to previous step result\n    const userData = context.getStepResult<{ name: string, userId: string }>(\"fetchUser\");\n\n    if (!userData) {\n      return { status: \"error\", message: \"User data not found\" };\n    }\n\n    return {\n      analysis: `Analyzed data for user ${userData.name}`,\n      userId: userData.userId\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Thread Info Tool with createTool() in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create another tool using `createTool()` that retrieves information about the current conversation thread. It shows how to access `threadId` and `resourceId` from the execution context and uses an optional input parameter defined with Zod. This example illustrates the use of context variables and optional parameters within a Mastra tool.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/createTool.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a tool that uses the thread context\nexport const threadInfoTool = createTool({\n  id: \"getThreadInfo\",\n  description: \"現在の会話スレッドに関する情報を返します\",\n  inputSchema: z.object({\n    includeResource: z.boolean().optional().default(false)\n  }),\n  execute: async ({ context, threadId, resourceId }) => {\n    return {\n      threadId,\n      resourceId: context.includeResource ? resourceId : undefined,\n      timestamp: new Date().toISOString()\n    };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Update dependencies from fixed to ^\nDESCRIPTION: This change updates dependencies from fixed versions to using the `^` (caret) operator. This allows for minor and patch version updates of the dependencies, promoting compatibility with newer versions while minimizing breaking changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n5916f9d: Update deps from fixed to ^\n```\n\n----------------------------------------\n\nTITLE: Defining IndexStats Interface TypeScript\nDESCRIPTION: This code represents the 'IndexStats' interface definition used to describe index statistics in the Cloudflare Vector Store. It includes properties for dimension, count, and metric, where the metric can be one of 'cosine', 'euclidean', or 'dotproduct'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/vectorize.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Metadata from Chunks - TypeScript\nDESCRIPTION: Implemented in TypeScript, `getMetadata()` returns an array of metadata objects from processed chunks. This method extracts metadata and outputs structured information for each chunk.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ngetMetadata(): Record<string, any>[]\n```\n\n----------------------------------------\n\nTITLE: Installing Deepgram Voice Module using npm\nDESCRIPTION: This snippet installs the Deepgram voice integration module for use in the Mastra project. The module enables the implementation of Text-to-Speech (TTS) and Speech-to-Text (STT) functionalities using Deepgram's AI models. Ensure that npm is installed and configured correctly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-deepgram\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedding Dimensions with OpenAI in TypeScript\nDESCRIPTION: Demonstrates how to configure the dimensionality of embeddings when using OpenAI's text-embedding-3 models. This can help reduce storage and computational costs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small', {\n    dimensions: 256  // Only supported in text-embedding-3 and later\n  }),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Configure Installation Timeout\nDESCRIPTION: This command demonstrates how to specify a timeout for the installation process using the `--timeout` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest --timeout 120000\n```\n\n----------------------------------------\n\nTITLE: Mastra Error Handling\nDESCRIPTION: This snippet demonstrates how to catch typed errors thrown by Mastra class methods. It attempts to retrieve a non-existent tool and logs the error message if the tool is not found.  It checks if the error is an instance of the Error class before accessing its message property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/core/mastra-class.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const tool = mastra.getTool(\"nonexistentTool\");\n} catch (error) {\n  if (error instanceof Error) {\n    console.log(error.message); // \"Tool with name nonexistentTool not found\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Re-ranking Example\nDESCRIPTION: Command to start and execute the re-ranking RAG example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Renaming Class in Changelog\nDESCRIPTION: Documents the rename of the `MurfTTS` class to `MurfVoice`, part of a larger API update in the `@mastra/voice-murf` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n- `MurfTTS` class renamed to `MurfVoice`\n```\n\n----------------------------------------\n\nTITLE: Running the Context Precision Example\nDESCRIPTION: Command to start the context precision evaluation example after completing the setup process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Running the Bias Metric Example\nDESCRIPTION: Command to start the bias metric evaluation example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Structured Metadata for Blog Post in JSON-LD\nDESCRIPTION: JSON-LD schema markup that provides metadata about the blog post for search engines, including title, publication dates, description, author information, and URLs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-post-raw.txt#2025-04-22_snippet_7\n\nLANGUAGE: JSON\nCODE:\n```\n{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"Announcing our new book: Principles of Building AI agents\",\"datePublished\":\"2025-03-12\",\"dateModified\":\"2025-03-12\",\"description\":\"Mastra founder Sam Bhagwat is excited to announce the release of our new book: Principles of Building AI agents. This book is a guide for developers who want to rapidly build AI applications.\",\"image\":\"/og/blog?title=Announcing%20our%20new%20book%3A%20Principles%20of%20Building%20AI%20agents&date=Mar 12, 2025\",\"url\":\"https://mastra.ai/blog/principles-of-ai-engineering\",\"author\":{\"@type\":\"Company\",\"name\":\"Mastra\"}}\n```\n\n----------------------------------------\n\nTITLE: Update Vector Store Functions to Use Object Params (Patch)\nDESCRIPTION: This patch modifies the vector store functions to utilize object parameters instead of positional arguments. This improves code readability and maintainability by making the purpose of each parameter explicit.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: Configuring TypeScript-Aware ESLint Rules\nDESCRIPTION: Configuration for enabling type-aware ESLint rules in a TypeScript project. Includes setup for recommended, strict, and stylistic type checking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/client-side-tools/README.md#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport default tseslint.config({\n  extends: [\n    // Remove ...tseslint.configs.recommended and replace with this\n    ...tseslint.configs.recommendedTypeChecked,\n    // Alternatively, use this for stricter rules\n    ...tseslint.configs.strictTypeChecked,\n    // Optionally, add this for stylistic rules\n    ...tseslint.configs.stylisticTypeChecked,\n  ],\n  languageOptions: {\n    // other options...\n    parserOptions: {\n      project: ['./tsconfig.node.json', './tsconfig.app.json'],\n      tsconfigRootDir: import.meta.dirname,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Example Usage of the Agent in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the configured Mastra agent to generate a response based on a prompt. The prompt instructs the agent to answer based on context provided by the tools and to explicitly state if there is insufficient information in the context to fully answer the question.  The generated completion text is then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst prompt = `\n[ここにドキュメントに基づくクエリを挿入]\nツールで提供されたコンテキストのみに基づいて回答してください。\nコンテキストに質問に完全に答えるための十分な情報が含まれていない場合は、その旨を明示してください。\n`;\n\nconst completion = await agent.generate(prompt);\nconsole.log(completion.text);\n```\n\n----------------------------------------\n\nTITLE: Using close() Method in OpenAI Realtime Voice - TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the close() method from the OpenAIRealtimeVoice class to disconnect from a real-time voice service and clean up resources. It showcases initializing the voice provider, connecting to the service, and properly shutting it down after use.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.close.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\n// Initialize a real-time voice provider\nconst voice = new OpenAIRealtimeVoice({\n  realtimeConfig: {\n    model: \"gpt-4o-mini-realtime\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// Start a conversation\nvoice.speak(\"Hello, I'm your AI assistant!\");\n\n// Stream audio from a microphone\nconst microphoneStream = getMicrophoneStream();\nvoice.send(microphoneStream);\n\n// When the conversation is complete\nsetTimeout(() => {\n  // Close the connection and clean up resources\n  voice.close();\n  console.log(\"Voice session ended\");\n}, 60000); // End after 1 minute\n```\n\n----------------------------------------\n\nTITLE: Documenting Version History in Markdown\nDESCRIPTION: This code snippet shows the version history of the 'insert-embedding-in-pinecone' package, including alpha releases and dependency updates. It uses markdown formatting to structure the changelog.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# insert-embedding-in-pinecone\n\n## 0.0.1\n\n## 0.0.1-alpha.4\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pinecone@0.0.1-alpha.20\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pinecone@0.0.1-alpha.19\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- Updated dependencies [cf4c02c]\n  - @mastra/vector-pinecone@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [9625602]\n  - @mastra/vector-pinecone@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Documentation Structure Examples in Markdown\nDESCRIPTION: Example topic headers and associated purpose sentences demonstrating the recommended documentation style and format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/example-text-generation.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Topic: Describing an image**\n\n**Purpose Sentence:** \"Vision-enabled language models can process both text and images, but sending both requires specific message formatting.\"\n\n**Topic: Calling Google Gemini**\n\n**Purpose Sentence:** \"Mastra provides a unified interface for working with various LLM providers, handling the complexity of different API implementations.\"\n\n**Topic: Streaming Objects**\n\n**Purpose Setence:** \"By streaming the output, you can display partial results as they arrive, providing immediate feedback to users.\"\n\n**Topic: Streaming Object**\n\n**Description sentence:** This example shows how to stream JSON-formatted responses using a Zod schema.\n```\n\n----------------------------------------\n\nTITLE: Executing TypeScript Script (Bash)\nDESCRIPTION: This bash command executes the TypeScript script `src/index.ts` using the `npx tsx` command. `tsx` is a tool that allows you to run TypeScript files directly without needing to compile them first. This command is used to test the command-line execution of the weather agent, outputting the agent's response to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\nnpx tsx src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Start Development Server\nDESCRIPTION: This command starts the development server for the Mastra project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Qdrant Import Update (Old)\nDESCRIPTION: Shows the old import statement for the QdrantVector class from the `@mastra/vector-qdrant` package.  This demonstrates the syntax that needs to be updated during the migration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/CHANGELOG.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { QdrantVector } from '@mastra/vector-qdrant';\n```\n\n----------------------------------------\n\nTITLE: Running the summarization example\nDESCRIPTION: Command to start the summarization metric evaluation example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/summarization/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector with Config Object\nDESCRIPTION: This code snippet illustrates how to instantiate the `PgVector` class using a configuration object. It allows for specifying the connection string and an optional schema name. Providing a schema name enables the vector store to operate within a specific schema in the database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Using a config object (with optional schemaName)\nconst vectorStore2 = new PgVector({\n  connectionString: 'postgresql://user:password@localhost:5432/mydb',\n  schemaName: 'custom_schema', // optional\n});\n```\n\n----------------------------------------\n\nTITLE: Qdrant Import Update (New)\nDESCRIPTION: Illustrates the new import statement for the QdrantVector class from the `@mastra/qdrant` package. This reflects the change in package location after the refactoring.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/CHANGELOG.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { QdrantVector } from '@mastra/qdrant';\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom OpenTelemetry Exporter with Langfuse\nDESCRIPTION: Creates an instrumentation file that configures a NodeSDK with a Langfuse exporter for OpenTelemetry tracing. This approach works across different hosting providers and gives more flexibility in how traces are exported.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  NodeSDK,\n  ATTR_SERVICE_NAME,\n  Resource,\n} from '@mastra/core/telemetry/otel-vendor';\nimport { LangfuseExporter } from 'langfuse-vercel';\n\nexport function register() {\n  const exporter = new LangfuseExporter({\n    // ... Langfuse config\n  })\n\n  const sdk = new NodeSDK({\n    resource: new Resource({\n      [ATTR_SERVICE_NAME]: 'ai',\n    }),\n    traceExporter: exporter,\n  });\n\n  sdk.start();\n}\n```\n\n----------------------------------------\n\nTITLE: Telemetry Configuration Options (TypeScript)\nDESCRIPTION: This code snippet defines the TypeScript type for the telemetry configuration options within Mastra. It includes properties for service name, enabling/disabling telemetry, sampling strategies (ratio, always_on, always_off, parent_based), and export configurations (OTLP or console) with options for endpoint and headers. The `OtelConfig` type allows configuring how Mastra exports telemetry data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/tracing.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntype OtelConfig = {\n  // トレースでサービスを識別するための名前（オプション）\n  serviceName?: string;\n\n  // テレメトリーの有効/無効化（デフォルトはtrue）\n  enabled?: boolean;\n\n  // サンプリングされるトレースの数を制御\n  sampling?: {\n    type: \"ratio\" | \"always_on\" | \"always_off\" | \"parent_based\";\n    probability?: number; // 比率サンプリング用\n    root?: {\n      probability: number; // 親ベースのサンプリング用\n    };\n  };\n\n  // テレメトリーデータの送信先\n  export?: {\n    type: \"otlp\" | \"console\";\n    endpoint?: string;\n    headers?: Record<string, string>;\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Change Log Entry - Version History in Markdown\nDESCRIPTION: Markdown formatted changelog documenting version history from 0.0.2-alpha.0 to 0.0.3, including dependency updates and patch changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# insert-embedding-in-libsql\n\n## 0.0.3\n\n## 0.0.3-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [06aa827]\n  - @mastra/core@0.4.3-alpha.0\n  - @mastra/rag@0.1.6-alpha.0\n\n## 0.0.2\n\n### Patch Changes\n\n- Updated dependencies [7fceae1]\n- Updated dependencies [8d94c3e]\n- Updated dependencies [99dcdb5]\n- Updated dependencies [6cb63e0]\n- Updated dependencies [f626fbb]\n- Updated dependencies [e752340]\n- Updated dependencies [eb91535]\n  - @mastra/core@0.4.2\n  - @mastra/rag@0.1.5\n\n## 0.0.2-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [8d94c3e]\n- Updated dependencies [99dcdb5]\n- Updated dependencies [e752340]\n- Updated dependencies [eb91535]\n  - @mastra/core@0.4.2-alpha.2\n  - @mastra/rag@0.1.5-alpha.2\n\n## 0.0.2-alpha.1\n\n### Patch Changes\n\n- Updated dependencies [6cb63e0]\n  - @mastra/core@0.4.2-alpha.1\n  - @mastra/rag@0.1.5-alpha.1\n\n## 0.0.2-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [7fceae1]\n- Updated dependencies [f626fbb]\n  - @mastra/core@0.4.2-alpha.0\n  - @mastra/rag@0.1.5-alpha.0\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Handling in Mastra Client\nDESCRIPTION: Example showing proper error handling and logging practices when using the MastraClient in a development environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Example with error handling and logging\ntry {\n  const agent = client.getAgent(\"dev-agent-id\");\n  const response = await agent.generate({\n    messages: [{ role: \"user\", content: \"Test message\" }]\n  });\n  console.log(\"Response:\", response);\n} catch (error) {\n  console.error(\"Development error:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a New Memory Thread in TypeScript\nDESCRIPTION: This code shows how to create a new memory thread with a title, metadata, resource ID, and agent ID using the Mastra client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst thread = await client.createMemoryThread({\n  title: \"New Conversation\",\n  metadata: { category: \"support\" },\n  resourceid: \"resource-1\",\n  agentId: \"agent-1\"\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the example directory for the text chunk embedding demonstration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/embed-text-chunk\n```\n\n----------------------------------------\n\nTITLE: Implementing Sentiment Analysis Prompt with TypeScript\nDESCRIPTION: This snippet creates a sentiment analysis prompt that evaluates the sentiment of a given text. It defines the required variables and provides examples for the AI to learn from while detailing constraints for ensuring output consistency.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntype SentimentVars = {\n  text: string;\n  language: string;\n};\n\nconst sentimentPrompt = createPrompt<SentimentVars>('Analyze sentiment', {\n  persona: 'Language Analyst',\n  outputFormat: 'json',\n})\n  .text('Analyze the sentiment of this {{language}} text:\\n\\n{{text}}')\n  .examples([\n    {\n      input: {\n        text: 'The product exceeded my expectations, highly recommend!',\n        language: 'English',\n      },\n      output: {\n        sentiment: 'positive',\n        confidence: 0.95,\n        aspects: ['product quality', 'recommendation'],\n      },\n    },\n    {\n      input: {\n        text: 'Service was okay, but the wait time was too long',\n        language: 'English',\n      },\n      output: {\n        sentiment: 'mixed',\n        confidence: 0.8,\n        aspects: ['service quality', 'wait time'],\n      },\n    },\n  ])\n  .constraints([\n    'Follow the exact output format from examples',\n    'Include confidence score',\n    'Identify key aspects mentioned',\n  ]);\n\n// Usage example\nconst analysis = sentimentPrompt.toString({\n  text: 'Great features but the interface could be more intuitive',\n  language: 'English',\n});\n```\n\n----------------------------------------\n\nTITLE: Vitest Configuration File Setup\nDESCRIPTION: Configuration file for Vitest that specifies global setup and test setup file locations for Mastra integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { defineConfig } from 'vitest/config'\n\nexport default defineConfig({\n  test: {\n    globalSetup: './globalSetup.ts',\n    setupFiles: ['./testSetup.ts'],\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Installing Deployer Package with npm\nDESCRIPTION: The command installs the @mastra/deployer package using npm, which is necessary for setting up the core deployment infrastructure for Mastra applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/server/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/deployer\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variable File\nDESCRIPTION: Command for copying the example environment file to create a new .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Installing MCP Package using pnpm\nDESCRIPTION: This command installs the @mastra/mcp package using pnpm, ensuring you have the latest version of the Mastra MCP integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/mcp@latest\n```\n\n----------------------------------------\n\nTITLE: Executing Initial Query\nDESCRIPTION: This code snippet executes an initial query against the original embeddings to establish a baseline for response quality. It defines a query, generates a response using the agent's `generate` method, and logs the query and response to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Generate response using the original embeddings\nconst query = 'What are all the technologies mentioned for space exploration?';\nconst originalResponse = await agent.generate(query);\nconsole.log('\\nQuery:', query);\nconsole.log('Response:', originalResponse.text);\n```\n\n----------------------------------------\n\nTITLE: Structured Output Streaming Example TypeScript\nDESCRIPTION: Demonstrates how to use the `stream()` method with a defined schema for structured output, including managing thread context. The example defines a schema, calls the `stream()` method with the schema and thread ID, iterates over the `textStream`, and then accesses the final structured result via the `object` property.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/agents/stream.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst schema = {\n  type: 'object',\n  properties: {\n    summary: { type: 'string' },\n    nextSteps: { type: 'array', items: { type: 'string' } }\n  },\n  required: ['summary', 'nextSteps']\n};\n\nconst response = await myAgent.stream(\n  \"What should we do next?\",\n  {\n    output: schema,\n    threadId: \"project-123\",\n    onFinish: text => console.log(\"Finished:\", text)\n  }\n);\n\nfor await (const chunk of response.textStream) {\n  console.log(chunk);\n}\n\nconst result = await response.object;\nconsole.log(\"Final structured result:\", result);\n```\n\n----------------------------------------\n\nTITLE: MCPServer startStdio() method definition\nDESCRIPTION: Defines the signature of the startStdio() method for the MCPServer class. This asynchronous method returns a Promise that resolves when the stdio server has started.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync startStdio(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Workflow While Loop with Reference Condition\nDESCRIPTION: Demonstrates using a reference-based condition for the `.while()` method, comparing a value from a specific step with a query using comparison operators.  The loop continues while the condition is met.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/while.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(\n    {\n      ref: { step: incrementStep, path: 'value' },\n      query: { $lt: 10 }, // 値が10未満である限り続行\n    },\n    incrementStep\n  )\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Executing a Workflow via API (Bash)\nDESCRIPTION: This code snippet shows how to execute a Mastra workflow using a `curl` command. The command sends a POST request to the `/api/workflows/myWorkflow/start-async` endpoint with a JSON payload containing the trigger data. It includes the `Content-Type` header to specify that the body is JSON.  This assumes the Mastra development server is running locally on port 4111.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'http://localhost:4111/api/workflows/myWorkflow/start-async' \\\n     --header 'Content-Type: application/json' \\\n     --data '{\n       \"inputValue\": 45\n     }'\n```\n\n----------------------------------------\n\nTITLE: Creating and Storing Embeddings\nDESCRIPTION: This snippet generates embeddings for the document chunks and stores them in the vector database. It uses the `embedMany` function to create embeddings using the OpenAI embedding model, creates an index in the vector store, and upserts the embeddings and metadata into the vector store. The dimension of the embedding is set to 1536.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cot-rag.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Integrating with an Agent\nDESCRIPTION: This snippet demonstrates how to integrate memory processors with an agent. It sets up a `Memory` instance with a `ToolCallFilter` and `TokenLimiter`, then creates an `Agent` with the processed memory. The agent uses the memory to retain context during conversations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-processors.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Agent } from \\\"@mastra/core/agent\\\";\nimport { Memory, TokenLimiter, ToolCallFilter } from \\\"@mastra/memory\\\";\nimport { openai } from \\\"@ai-sdk/openai\\\";\n\n// Set up memory with processors\nconst memory = new Memory({\n  processors: [\n    new ToolCallFilter({ exclude: [\\\"debugTool\\\"] }),\n    new TokenLimiter(16000),\n  ],\n});\n\n// Create an agent with the memory\nconst agent = new Agent({\n  name: \\\"ProcessorAgent\\\",\n  instructions: \\\"You are a helpful assistant with processed memory.\\\",\n  model: openai(\\\"gpt-4o-mini\\\"),\n  memory,\n});\n\n// Use the agent\nconst response = await agent.stream(\\\"Hi, can you remember our conversation?\\\", {\n  threadId: \\\"unique-thread-id\\\",\n  resourceId: \\\"user-123\\\",\n});\n\nfor await (const chunk of response.textStream) {\n  process.stdout.write(chunk);\n}\"\n```\n\n----------------------------------------\n\nTITLE: TTS with ElevenLabs Voice Agent\nDESCRIPTION: This code shows how to use an Agent with ElevenLabs voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using ElevenLabs' voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new ElevenLabsVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with LangWatch Exporter (TypeScript)\nDESCRIPTION: This snippet shows how to configure Mastra to export telemetry data to LangWatch using the `LangWatchExporter`. It imports the necessary modules and initializes Mastra with the custom exporter, passing the API key and project ID from the environment variables. This assumes `@mastra/core` and `langwatch` are installed as dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langwatch.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { LangWatchExporter } from \"langwatch\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new LangWatchExporter({\n        apiKey: process.env.LANGWATCH_API_KEY,\n        projectId: process.env.LANGWATCH_PROJECT_ID,\n      }),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Complex Dependency Pattern in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet shows how to create a complex dependency pattern in a Mastra workflow using multiple `.after([])` calls. The `finalStep` will only execute after `stepC`, `stepE`, and `stepG` have all completed, effectively merging three branches.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  // 最初のブランチ\n  .step(stepA)\n  .then(stepB)\n  .then(stepC)\n\n  // 2番目のブランチ\n  .step(stepD)\n  .then(stepE)\n\n  // 3番目のブランチ\n  .step(stepF)\n  .then(stepG)\n\n  // このステップは複数のブランチの完了に依存しています\n  .after([stepC, stepE, stepG])\n  .step(finalStep)\n```\n\n----------------------------------------\n\nTITLE: Deprecate @mastra/speech-playai\nDESCRIPTION: This patch deprecates the `@mastra/speech-playai` package and recommends using `@mastra/voice-playai` instead. This suggests a change in API or functionality, potentially indicating that `@mastra/voice-playai` offers improved features or resolves issues present in the deprecated package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n41d0166: deprecate @mastra/speech-playai for @mastra/voice-playai\n```\n\n----------------------------------------\n\nTITLE: Configuring Completeness Metric in TypeScript\nDESCRIPTION: This code sets up a new instance of the CompletenessMetric for use in evaluations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/completeness.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new CompletenessMetric();\n```\n\n----------------------------------------\n\nTITLE: Using Memory Agent with Semantic Search in TypeScript\nDESCRIPTION: This snippet shows how to use the memory agent in a conversation, including starting a thread, sending messages, and using semantic search to find relevant messages from previous interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// Start a conversation\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// Start with a system message\nconst response1 = await memoryAgent.stream(\n  [\n    {\n      role: \"system\",\n      content: `Chat with user started now ${new Date().toISOString()}. Don't mention this message.`,\n    },\n  ],\n  {\n    resourceId,\n    threadId,\n  },\n);\n\n// Send user message\nconst response2 = await memoryAgent.stream(\"What can you help me with?\", {\n  threadId,\n  resourceId,\n});\n\n// Use semantic search to find relevant messages\nconst response3 = await memoryAgent.stream(\"What did we discuss earlier?\", {\n  threadId,\n  resourceId,\n  memoryOptions: {\n    lastMessages: false,\n    semanticRecall: {\n      topK: 3, // Get top 3 most relevant messages\n      messageRange: 2, // Include context around each match\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required node packages using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Get Speakers from OpenAI and ElevenLabs with TypeScript\nDESCRIPTION: This code demonstrates how to initialize OpenAI and ElevenLabs voice providers, retrieve available speakers using the `getSpeakers()` method, and then use a specific voice for speech synthesis using the `speak()` method. It showcases retrieving voice options and using them in subsequent speech synthesis.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.getSpeakers.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { ElevenLabsVoice } from \"@mastra/voice-elevenlabs\";\n\n// Initialize voice providers\nconst openaiVoice = new OpenAIVoice();\nconst elevenLabsVoice = new ElevenLabsVoice({\n  apiKey: process.env.ELEVENLABS_API_KEY\n});\n\n// Get available speakers from OpenAI\nconst openaiSpeakers = await openaiVoice.getSpeakers();\nconsole.log(\"OpenAI voices:\", openaiSpeakers);\n// Example output: [{ voiceId: \"alloy\" }, { voiceId: \"echo\" }, { voiceId: \"fable\" }, ...]\n\n// Get available speakers from ElevenLabs\nconst elevenLabsSpeakers = await elevenLabsVoice.getSpeakers();\nconsole.log(\"ElevenLabs voices:\", elevenLabsSpeakers);\n// Example output: [{ voiceId: \"21m00Tcm4TlvDq8ikWAM\", name: \"Rachel\" }, ...]\n\n// Use a specific voice for speech\nconst text = \"Hello, this is a test of different voices.\";\nawait openaiVoice.speak(text, { speaker: openaiSpeakers[2].voiceId });\nawait elevenLabsVoice.speak(text, { speaker: elevenLabsSpeakers[0].voiceId });\n```\n\n----------------------------------------\n\nTITLE: Create Weather Tool Directory\nDESCRIPTION: Creates the directory structure for the weather tool and creates an empty TypeScript file for the tool's code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/tools && touch src/mastra/tools/weather-tool.ts\n```\n\n----------------------------------------\n\nTITLE: Running the Chunk Size Adjustment Example\nDESCRIPTION: Command to execute the example application that demonstrates how to adjust chunk sizes in Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-size/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: High-quality Summary Evaluation Example\nDESCRIPTION: Complete example showing evaluation of a high-quality summary with perfect factual accuracy and coverage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst input1 = `The electric car company Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning. \nElon Musk joined in 2004 as the largest investor and became CEO in 2008. The company's first car, \nthe Roadster, was launched in 2008.`;\n\nconst output1 = `Tesla, founded by Martin Eberhard and Marc Tarpenning in 2003, launched its first car, \nthe Roadster, in 2008. Elon Musk joined as the largest investor in 2004 and became CEO in 2008.`;\n\nconsole.log('Example 1 - High-quality Summary:');\nconsole.log('Input:', input1);\nconsole.log('Output:', output1);\n\nconst result1 = await metric.measure(input1, output1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  info: {\n    reason: result1.info.reason,\n    alignmentScore: result1.info.alignmentScore,\n    coverageScore: result1.info.coverageScore,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Logger\nDESCRIPTION: Sets up a structured logging system with customizable log levels for AI applications\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createLogger, LogLevel } from '@mastra/core';\n\nconst logger = createLogger({\n  name: 'MyApp',\n  level: LogLevel.INFO,\n});\n```\n\n----------------------------------------\n\nTITLE: Upserting Vectors in ChromaVector\nDESCRIPTION: Inserts or updates embedding vectors into a specified index while optionally providing associated metadata and document information.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to upsert into\",\n    },\n    {\n      name: \"vectors\",\n      type: \"number[][]\",\n      description: \"Array of embedding vectors\",\n    },\n    {\n      name: \"metadata\",\n      type: \"Record<string, any>[]\",\n      isOptional: true,\n      description: \"Metadata for each vector\",\n    },\n    {\n      name: \"ids\",\n      type: \"string[]\",\n      isOptional: true,\n      description: \"Optional vector IDs (auto-generated if not provided)\",\n    },\n    {\n      name: \"documents\",\n      type: \"string[]\",\n      isOptional: true,\n      description:\n        \"Chroma-specific: Original text documents associated with the vectors\",\n    },\n  ]}/>\n```\n\n----------------------------------------\n\nTITLE: Install @mastra/voice-google\nDESCRIPTION: This command installs the @mastra/voice-google package using npm. This is the first step in migrating from the deprecated @mastra/speech-google package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/google/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-google\n```\n\n----------------------------------------\n\nTITLE: Initializing MDocument instances\nDESCRIPTION: Demonstrates how to create MDocument instances from different content formats such as text, HTML, Markdown, and JSON. This is the initial step in processing documents within Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst docFromText = MDocument.fromText(\"Your plain text content...\");\nconst docFromHTML = MDocument.fromHTML(\"<html>Your HTML content...</html>\");\nconst docFromMarkdown = MDocument.fromMarkdown(\"# Your Markdown content...\");\nconst docFromJSON = MDocument.fromJSON(`{ \"key\": \"value\" }`);\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Application\nDESCRIPTION: Commands for building a Mastra application from current or specific directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# Build from current directory\nmastra build\n\n# Or specify a directory\nmastra build --dir ./my-project\n```\n\n----------------------------------------\n\nTITLE: Implementing Editor Step Execution\nDESCRIPTION: Defines the editor step that processes the copywriter's output and performs editing. Retrieves the previous step's result and generates edited content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorStep = new Step({\n  id: \"editorStep\",\n  execute: async ({ context }) => {\n    const copy = context?.getStepResult<{ copy: number }>(\n      \"copywriterStep\",\n    )?.copy;\n\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${copy}`,\n    );\n    console.log(\"editor result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Install Vercel OpenTelemetry dependencies\nDESCRIPTION: This snippet installs the necessary dependencies for using Vercel's built-in OpenTelemetry setup.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/api @vercel/otel\n```\n\n----------------------------------------\n\nTITLE: Updating Vector Metadata\nDESCRIPTION: This code demonstrates updating an existing vector's metadata by its ID. It uses the `updateIndexById` method to modify the metadata associated with a specific vector in the index. Only the metadata is updated in this example, leaving the vector itself unchanged.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Update just the metadata\nawait pgVector.updateIndexById(\"my_vectors\", \"vector123\", {\n  metadata: { label: \"updated\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Context Position Adherence\nDESCRIPTION: This snippet illustrates how to assess a response with mixed context position adherence, where related information is scattered. It initializes a context, query, and response, measuring the adherence with the ContextPositionMetric, and displaying the resulting score and reason.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-position.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  '象は草食動物です。',\n  '成象は最大13,000ポンドまで重くなります。',\n  '象は陸上で最大の動物です。',\n  '象は植物や草を食べます。',\n];\n\nconst metric2 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = '象はどのくらいの重さですか？';\nconst response2 = '成象は最大13,000ポンドまで重くなり、陸上で最大の動物です。';\n\nconsole.log('例2 - 混合位置の順守:');\nconsole.log('コンテキスト:', context2);\nconsole.log('クエリ:', query2);\nconsole.log('応答:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('メトリック結果:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.4, reason: 'コンテキストには関連情報と無関係な情報が含まれており、正しい順序ではありません。' }\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies for Prompt Alignment example in Bash\nDESCRIPTION: Command to install all required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/prompt-alignment/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Astra in Typescript\nDESCRIPTION: This snippet shows how to integrate an `ASTRA_PROMPT` into an agent's instructions for querying Astra.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ASTRA_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${ASTRA_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Netlify Configuration (TOML)\nDESCRIPTION: This TOML configuration file is automatically generated by the NetlifyDeployer. It defines the function settings and redirects required for the Mastra application to run on Netlify Functions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/netlify.mdx#2025-04-22_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[functions]\nnode_bundler = \"esbuild\"            \ndirectory = \"netlify/functions\"\n\n[[redirects]]\nforce = true\nfrom = \"/*\"\nstatus = 200\nto = \"/.netlify/functions/api/:splat\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Changeset for Version Management\nDESCRIPTION: Command to create a changeset, which is used for version management when contributing changes to Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npnpm changeset\n```\n\n----------------------------------------\n\nTITLE: Running the Context Position Example\nDESCRIPTION: Command to execute the context position metric example after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-position/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Cloudflare Vectorize in Typescript\nDESCRIPTION: This snippet shows how to integrate a `VECTORIZE_PROMPT` into an agent's instructions for querying Cloudflare Vectorize. The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { VECTORIZE_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${VECTORIZE_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（Azure）\nDESCRIPTION: Azureを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、AzureVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from 'fs';\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { AzureVoice } from \"@mastra/voice-azure\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new AzureVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for PgVector in Typescript\nDESCRIPTION: This snippet shows how to integrate a `PGVECTOR_PROMPT` into an agent's instructions for querying PgVector.  The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PGVECTOR_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${PGVECTOR_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing First B2B Tracking Script in JavaScript\nDESCRIPTION: Initializes the first B2B tracking script by creating methods for identification and data collection. The script prevents duplicate initialization, loads an external JavaScript file from Amazon S3, and sets up factory methods for the tracking API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_18\n\nLANGUAGE: JavaScript\nCODE:\n```\nwindow.reb2b = window.reb2b || [];\nif (!window.reb2b.invoked) {\n  window.reb2b.invoked = true;\n  window.reb2b.methods = [\"identify\", \"collect\"];\n  window.reb2b.factory = function(method) {\n    return function() {\n      var args = Array.prototype.slice.call(arguments);\n      args.unshift(method);\n      window.reb2b.push(args);\n      return window.reb2b;\n    };\n  };\n  window.reb2b.methods.forEach(function(key) {\n    window.reb2b[key] = window.reb2b.factory(key);\n  });\n  window.reb2b.SNIPPET_VERSION = \"1.0.1\";\n\n  const script = document.createElement(\"script\");\n  script.async = true;\n  script.src = \"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/E63P0H7150OW/E63P0H7150OW.js.gz\";\n  document.head.appendChild(script);\n}\n```\n\n----------------------------------------\n\nTITLE: If-Else Branching with Nested Workflows in Mastra (TypeScript)\nDESCRIPTION: Demonstrates how to use if-else branching with nested workflows.  One of two nested workflows will be executed based on a condition.  The `if` function now accepts two workflow arguments, one for the `true` branch and one for the `false` branch.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/nested-workflows.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// 異なるパス用のネストされたワークフローを作成\nconst workflowA = new Workflow({ name: \"workflow-a\" })\n  .step(stepA1)\n  .then(stepA2)\n  .commit();\n\nconst workflowB = new Workflow({ name: \"workflow-b\" })\n  .step(stepB1)\n  .then(stepB2)\n  .commit();\n\n// ネストされたワークフローで新しいif-else構文を使用\nparentWorkflow\n  .step(initialStep)\n  .if(\n    async ({ context }) => {\n      // ここに条件を記述\n      return someCondition;\n    },\n    workflowA, // if分岐\n    workflowB, // else分岐\n  )\n  .then(finalStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Using MastraMCPClient with SSE Server Example in TypeScript\nDESCRIPTION: Demonstrates initializing MastraMCPClient with an SSE server configuration, including custom fetch settings for authentication. Reflects on the importance of using both requestInit and eventSourceInit for properly setting custom headers on SSE connections.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Initialize the MCP client using an SSE server\nconst sseClient = new MastraMCPClient({\n  name: \"sse-client\",\n  server: {\n    url: new URL(\"https://your-mcp-server.com/sse\"),\n    // Optional fetch request configuration\n    requestInit: {\n      headers: {\n        Authorization: \"Bearer your-token\",\n      },\n    },\n    // Required for SSE connections with custom headers\n    eventSourceInit: {\n      fetch(input: Request | URL | string, init?: RequestInit) {\n        const headers = new Headers(init?.headers || {});\n        headers.set('Authorization', 'Bearer your-token');\n        return fetch(input, {\n          ...init,\n          headers,\n        });\n      },\n    },\n    // Optional additional logging configuration\n    logger: (logMessage) => {\n      console.log(`[${logMessage.level}] ${logMessage.serverName}: ${logMessage.message}`);\n    },\n    // Disable server logs\n    enableServerLogs: false\n  },\n});\n\n// The rest of the usage is identical to the stdio example\n```\n\n----------------------------------------\n\nTITLE: Markdown Version Change Log\nDESCRIPTION: Documents version history from 0.0.1-alpha.0 through 0.0.1, tracking dependency updates for @mastra/rag and @mastra/vector-pg packages\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# rerank-rag\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pg@0.0.1-alpha.19\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pg@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [72f7fb9]\n- Updated dependencies [9625602]\n  - @mastra/vector-pg@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Initializing MCP Configuration Class - TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the `McpConfiguration` class by providing a registry client and related configurations. This class manages validation and persistence of configurations using storage adapters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst registry = new RegistryClient({\n\turl: \"https://example-tools.com/.well-known/mcp.json\",\n})\n\nconst configuration = new McpConfiguration({\n\tid: \"validation-example\", // user or app id for persisting configs\n\tregistry,\n})\n```\n\n----------------------------------------\n\nTITLE: Update Vector Tests and Pinecone Integration (Patch)\nDESCRIPTION: This patch updates vector tests and the Pinecone integration. This ensures the vector store functions are correctly tested and the Pinecone integration is functioning properly after other updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_5\n\n\n\n----------------------------------------\n\nTITLE: Upstash Logger Creation (TypeScript)\nDESCRIPTION: Illustrates how to create an Upstash Redis logger using the createLogger function and the UpstashTransport. The logger is configured to send logs to an Upstash Redis list named \"production-logs\". The Upstash URL and token are retrieved from environment variables. It logs an informational message about a user signing in, including metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/create-logger.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashTransport } from \"@mastra/loggers/upstash\";\n\nconst logger = createLogger({\n  name: \"Mastra\",\n  transports: {\n    upstash: new UpstashTransport({\n      listName: \"production-logs\",\n      upstashUrl: process.env.UPSTASH_URL!,\n      upstashToken: process.env.UPSTASH_TOKEN!,\n    }),\n  },\n  level: \"info\",\n});\n\nlogger.info({\n  message: \"User signed in\",\n  destinationPath: \"auth\",\n  type: \"AGENT\",\n  runId: \"run_123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Specify Source Directory\nDESCRIPTION: This command demonstrates how to specify the target directory for source code using the `--dir` or `-d` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest my-app --components agents,tools --llm openai --dir src/\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required dependencies using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Using Toolsets Dynamically in Agent Methods\nDESCRIPTION: Demonstrates how to configure MCP with user-specific settings and pass the resulting toolsets dynamically to the `stream()` method of an Agent. This allows for customized configurations without modifying the Agent's core definition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-configuration.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { MCPConfiguration } from \"@mastra/mcp\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create the agent first, without any tools\nconst agent = new Agent({\n  name: \"Multi-tool Agent\",\n  instructions: \"You help users check stocks and weather.\",\n  model: openai(\"gpt-4\"),\n});\n\n// Later, configure MCP with user-specific settings\nconst mcp = new MCPConfiguration({\n  servers: {\n    stockPrice: {\n      command: \"npx\",\n      args: [\"tsx\", \"stock-price.ts\"],\n      env: {\n        API_KEY: \"user-123-api-key\",\n      },\n      timeout: 20000, // Server-specific timeout\n    },\n    weather: {\n      url: new URL(\"http://localhost:8080/sse\"),\n      requestInit: {\n        headers: {\n          Authorization: `Bearer user-123-token`,\n        },\n      },\n    },\n  },\n});\n\n// Pass all toolsets to stream() or generate()\nconst response = await agent.stream(\n  \"How is AAPL doing and what is the weather?\",\n  {\n    toolsets: await mcp.getToolsets(),\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Markdown Version History Documentation\nDESCRIPTION: Chronological documentation of version changes for the @internal/lint package, including both stable and alpha releases. Records licensing updates and bundling configuration changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/_config/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# @internal/lint\n\n## 0.0.2\n\n### Patch Changes\n\n- 37bb612: Add Elastic-2.0 licensing for packages\n\n## 0.0.2-alpha.0\n\n### Patch Changes\n\n- 37bb612: Add Elastic-2.0 licensing for packages\n\n## 0.0.1\n\n### Patch Changes\n\n- fd4a1d7: Update cjs bundling to make sure files are split\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- fd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Add CommonJS Support\nDESCRIPTION: This change adds support for CommonJS (CJS) modules to the package. This allows the package to be used in environments that do not support ES modules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/CHANGELOG.md#_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: Mastra Class Initialization (Basic)\nDESCRIPTION: Demonstrates basic initialization of the Mastra class using TypeScript. It imports the Mastra class and creates a new instance with an empty configuration object. This initialization provides a minimal setup for using the Mastra framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/core/mastra-class.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\n// Basic initialization\nexport const mastra = new Mastra({});\n```\n\n----------------------------------------\n\nTITLE: Starting the Next.js Development Server\nDESCRIPTION: This command starts the Next.js development server. It allows developers to view and interact with the application in a local environment during development. The server typically runs on port 3000, which can be accessed through a web browser.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/travel-app/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Installing IBM Speech Package using npm\nDESCRIPTION: This bash command installs the @mastra/speech-ibm package, which provides integration with IBM Watson's TTS service. Make sure to have npm installed and configured.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/speech-ibm\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Project for Deployment\nDESCRIPTION: This command builds the Mastra project for deployment to the target platform. It uses the `mastra build` command from the Mastra CLI. The build output is automatically prepared for the selected platform when a deployer is used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n\"npx mastra build\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Second B2B Tracking Script in JavaScript\nDESCRIPTION: Implements a self-executing function to initialize the second B2B tracking script with similar functionality as the first, but with a different loading mechanism. It creates tracking methods through a factory pattern, loads an external script from Amazon S3, and prevents multiple initializations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_19\n\nLANGUAGE: JavaScript\nCODE:\n```\n!function () {\n  var reb2b = window.reb2b = window.reb2b || [];\n  if (reb2b.invoked) return;\n  reb2b.invoked = true;\n  reb2b.methods = [\"identify\", \"collect\"];\n  reb2b.factory = function (method) {\n    return function () {\n      var args = Array.prototype.slice.call(arguments);\n      args.unshift(method); reb2b.push(args);\n      return reb2b;\n    };\n  };\n  for (var i = 0; i < reb2b.methods.length; i++) {\n    var key = reb2b.methods[i];\n    reb2b[key] = reb2b.factory(key);\n  }\n  reb2b.load = function (key) {\n    var script = document.createElement(\"script\");\n    script.type = \"text/javascript\";\n    script.async = true;\n    script.src = \"https://s3-us-west-2.amazonaws.com/b2bjsstore/b/\" + key + \"/reb2b.js.gz\";\n    var first = document.getElementsByTagName(\"script\")[0];\n    first.parentNode.insertBefore(script, first);\n  };\n  reb2b.SNIPPET_VERSION = \"1.0.1\";\n  reb2b.load(\"4N210HEJYQ6Z\");\n}();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the required dependencies using the pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-markdown/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template\nDESCRIPTION: Command to create a new environment file from the example template.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Wrangler Configuration (JSON)\nDESCRIPTION: Example of a `wrangler.json` configuration file generated by CloudflareDeployer. This file specifies the worker name, entry point, compatibility settings, observability options, environment variables, and routes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/cloudflare.mdx#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"your-project-name\",\n  \"main\": \"./output/index.mjs\",\n  \"compatibility_date\": \"2024-12-02\",\n  \"compatibility_flags\": [\"nodejs_compat\"],\n  \"observability\": {\n    \"logs\": {\n      \"enabled\": true\n    }\n  },\n  \"vars\": {\n    // .envファイルと設定からの環境変数\n  },\n  \"routes\": [\n    // 指定された場合のルート設定\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Not Supported Method for Speech Recognition\nDESCRIPTION: This method indicates that PlayAI does not support speech recognition features. It is a placeholder to handle unsupported functionalities gracefully.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nlisten()\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the word inclusion example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/word-inclusion/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/custom/word-inclusion\n```\n\n----------------------------------------\n\nTITLE: Vector Store Prompt for Pinecone in Typescript\nDESCRIPTION: This snippet shows how to integrate a `PINECONE_PROMPT` into an agent's instructions for querying Pinecone. The prompt helps the agent understand how to use the tool, and includes instructions on valid operators and syntax for filtering. Requires `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PINECONE_PROMPT } from \"@mastra/rag\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  提供されたコンテキストを使用してクエリを処理します。応答を簡潔で関連性のあるものに構成します。\n  ${PINECONE_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring the BiasMetric\nDESCRIPTION: This snippet demonstrates how to configure the BiasMetric using the OpenAI integration. It initializes a BiasMetric instance with the 'gpt-4o-mini' model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new BiasMetric(openai('gpt-4o-mini'));\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with OpenAI Voice Provider\nDESCRIPTION: This code snippet demonstrates how to transcribe an audio file using the OpenAI voice provider. It initializes the provider, reads an audio file into a stream, and then transcribes the audio using `voice.listen()`. The transcribed text is then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.listen.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from \"@mastra/voice-openai\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\n\n// Initialize a voice provider\nconst voice = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Basic usage with a file stream\nconst audioFilePath = path.join(process.cwd(), \"audio.mp3\");\nconst audioStream = createReadStream(audioFilePath);\nconst transcript = await voice.listen(audioStream, {\n  filetype: \"mp3\",\n});\nconsole.log(\"Transcribed text:\", transcript);\n```\n\n----------------------------------------\n\nTITLE: Documenting Version History in Markdown\nDESCRIPTION: This snippet shows the version history of the filter-rag package, including patch changes and dependency updates. It uses a markdown format to list different versions and their corresponding changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# filter-rag\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pg@0.0.1-alpha.19\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pg@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [72f7fb9]\n- Updated dependencies [9625602]\n  - @mastra/vector-pg@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with Upstash Storage in TypeScript\nDESCRIPTION: This code snippet shows how to configure a Mastra instance to use Upstash (Redis-compatible) as the storage provider for workflow snapshots. It initializes an `UpstashStore` instance with the Upstash URL and token obtained from environment variables. This setup is ideal for serverless environments.  The Mastra class is instantiated with the storage configuration and workflow definitions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst mastra = new Mastra({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN,\n  }),\n  workflows: {\n    weatherWorkflow,\n    travelWorkflow,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: resumeWithEvent() with Error Handling - TypeScript\nDESCRIPTION: Shows how to use `resumeWithEvent()` with a try-catch block to handle potential errors.  This example demonstrates resuming a workflow with 'paymentReceived' event data and handling any exceptions that may occur during the resumption process, such as invalid event data or the workflow not being suspended.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/resumeWithEvent.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const result = await run.resumeWithEvent(\"paymentReceived\", {\n    amount: 100.5,\n    transactionId: \"tx-456\",\n    paymentMethod: \"credit-card\",\n  });\n\n  console.log(\"Workflow resumed successfully:\", result.results);\n} catch (error) {\n  console.error(\"Failed to resume workflow with event:\", error);\n  // Handle error - could be invalid event data, workflow not suspended, etc.\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Workflow Step with StepOptions (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to configure a workflow step using `StepOptions`. It shows how to map input variables from other steps and define a condition for when the step should be executed.  It uses `workflow.step` to define a step named `processOrder` with variable mapping and a condition based on the `auth` step's status.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-options.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  variables: {\n    orderId: { step: 'trigger', path: 'id' },\n    userId: { step: 'auth', path: 'user.id' }\n  },\n  when: {\n    ref: { step: 'auth', path: 'status' },\n    query: { $eq: 'authenticated' }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Using CompositeVoice for Voice Event Delegation - TypeScript\nDESCRIPTION: This example demonstrates the use of CompositeVoice to delegate event handling to a configured real-time provider. It initializes OpenAIRealtimeVoice and a Speaker, then registers an event listener for audio streams via 'speaker'. This snippet requires @mastra/core/voice, @mastra/voice-openai-realtime, and @mastra/node-speaker packages. It provides mono and CD-quality audio output, utilizing the real-time service connection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.on.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompositeVoice } from \"@mastra/core/voice\";\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport Speaker from \"@mastra/node-speaker\";\n\nconst speaker = new Speaker({\n  sampleRate: 24100,  // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro\n  channels: 1,        // Mono audio output (as opposed to stereo which would be 2)\n  bitDepth: 16,       // Bit depth for audio quality - CD quality standard (16-bit resolution)\n});\n\nconst realtimeVoice = new OpenAIRealtimeVoice();\nconst voice = new CompositeVoice({\n  realtimeProvider: realtimeVoice,\n});\n\n// Connect to the real-time service\nawait voice.connect();\n\n// This will register the event listener with the OpenAIRealtimeVoice provider\nvoice.on(\"speaker\", (stream) => {\n  stream.pipe(speaker)\n});\n```\n\n----------------------------------------\n\nTITLE: Mastra with NetlifyDeployer Initialization (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to initialize a Mastra application with the NetlifyDeployer. It shows how to configure the deployer with scope, project name, and Netlify token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/netlify.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { NetlifyDeployer } from '@mastra/deployer-netlify';\n\nconst mastra = new Mastra({\n  deployer: new NetlifyDeployer({\n    scope: 'your-team-slug',\n    projectName: 'your-project-name',\n    token: 'your-netlify-token'\n  }),\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Documentation\nDESCRIPTION: Changelog entries showing version history and dependency updates for embed-text-chunk package, starting from 0.0.1-alpha.0 through various alpha releases to 0.0.1.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# embed-text-chunk\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [9625602]\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Creating a Document from Text using MDocument Typescript\nDESCRIPTION: Creates a document object from a given text string using the MDocument.fromText method. The text content includes a title, a description of the benefits of regular exercise, and key benefits. This document will be used for metadata extraction and chunking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/metadata-extraction.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst doc = MDocument.fromText(`Title: The Benefits of Regular Exercise\n\nRegular exercise has numerous health benefits. It improves cardiovascular health, \nstrengthens muscles, and boosts mental wellbeing.\n\nKey Benefits:\n• Reduces stress and anxiety\n• Improves sleep quality\n• Helps maintain healthy weight\n• Increases energy levels\n\nFor optimal results, experts recommend at least 150 minutes of moderate exercise \nper week.`);\n```\n\n----------------------------------------\n\nTITLE: Create Weather Agent Directory\nDESCRIPTION: Creates the directory structure for the weather agent and creates an empty TypeScript file for the agent's code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/agents && touch src/mastra/agents/weather.ts\n```\n\n----------------------------------------\n\nTITLE: Retrieving Available Speakers List\nDESCRIPTION: This method fetches a list of available voice speakers along with their details, which can assist users in selecting a specific voice for speech generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ngetSpeakers()\n```\n\n----------------------------------------\n\nTITLE: Mapping Entire Objects in Mastra Workflow (TypeScript)\nDESCRIPTION: Illustrates how to map an entire object from the trigger data to a step's input by using `.` as the `path` value. This allows the step to receive the complete trigger data object as input. Requires `@mastra/core`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/variables.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(step1, {\n    variables: {\n      // トリガーデータオブジェクト全体をマッピング\n      triggerData: { step: 'trigger', path: '.' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Update CJS Bundling\nDESCRIPTION: This patch updates the CommonJS (CJS) bundling process to ensure files are correctly split. This change is made in versions 0.1.3-alpha.12 and 0.1.3-alpha.11.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/CHANGELOG.md#_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Initializing Sarvam Voice Configuration\nDESCRIPTION: Sarvam音声プロバイダーの初期化設定を示します。音声合成のためのモデル名、APIキー、言語、スタイルを指定します。Sarvamは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはSarvamの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_27\n\nLANGUAGE: typescript\nCODE:\n```\n// Sarvam Voice Configuration\nconst voice = new SarvamVoice({\n  speechModel: {\n    name: \"sarvam-voice\", // Example model name\n    apiKey: process.env.SARVAM_API_KEY,\n    language: \"en-IN\", // Language code\n    style: \"conversational\", // Style setting\n  },\n  // Sarvam may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Running Tests in Watch Mode\nDESCRIPTION: Command to run tests in watch mode for development, which automatically reruns tests when files change.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npnpm test:watch\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command for copying the example environment variables file to create a local configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-relevancy/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Environment File Management in Deployer (TypeScript)\nDESCRIPTION: This method retrieves environment files required for deployment by searching in predefined locations. Utilizes the FileService to determine the first existing file from a list and supports Promise-based async handling. The snippet demonstrates TypeScript syntax.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/deployer/deployer.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ngetEnvFiles(): Promise<string[]> {\n  const possibleFiles = ['.env.production', '.env.local', '.env'];\n\n  try {\n    const fileService = new FileService();\n    const envFile = fileService.getFirstExistingFile(possibleFiles);\n\n    return Promise.resolve([envFile]);\n  } catch {}\n\n  return Promise.resolve([]);\n}\n```\n\n----------------------------------------\n\nTITLE: Package Import Examples\nDESCRIPTION: Shows different ways to import functionality from the @mastra/evals package and its submodules.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Main package exports\nimport { evaluate } from '@mastra/evals';\n// NLP-specific metrics\nimport { ContentSimilarityMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1\nDESCRIPTION: Version entry for 1.0.1 release\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## 1.0.1\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template\nDESCRIPTION: Command to create a local environment file from the provided template. This file will store configuration needed for the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/basic-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Bash\nDESCRIPTION: The following snippet is responsible for installing the necessary dependencies using pnpm for the OpenAPI spec generator project, ensuring all required packages are available for development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Package Manager in Bash\nDESCRIPTION: Command to install required dependencies for the example using pnpm. This step must be completed before running the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/textual-difference/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Evaluate Partially Relevant Response\nDESCRIPTION: This TypeScript snippet shows how to evaluate a partially relevant response using the AnswerRelevancyMetric. It defines a query and a response that is only partially related to the query. The metric evaluates the response and provides a score and reason indicating the degree of relevance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/answer-relevancy.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst query2 = 'What should a healthy breakfast include?';\nconst response2 =\n  'A nutritious breakfast should include whole grains and protein. However, the timing of your breakfast is just as important - studies show eating within 2 hours of waking optimizes metabolism and energy levels throughout the day.';\n\nconsole.log('Example 2 - Partial Relevancy:');\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.7, reason: 'The response is partially relevant to the query. It provides some information about healthy breakfast choices but misses the timing aspect.' }\n```\n\n----------------------------------------\n\nTITLE: Embedding Text with Cohere in Mastra\nDESCRIPTION: This code snippet demonstrates how to generate text embeddings using Cohere's embedding model within the Mastra RAG framework. It imports the necessary modules, defines a text document, chunks it, and then uses the `embedMany` function with the Cohere embedding model to generate embeddings for the text chunks. The `embedMany` function takes the model and the array of text chunks as input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/embedding/embed-text-with-cohere.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { cohere } from '@ai-sdk/cohere';\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from 'ai';\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Using API-based Embedder in TypeScript\nDESCRIPTION: This snippet illustrates how to specify a custom embedder, particularly an API-based embedder like OpenAI's embedding model, for the `Memory` class.  It imports the `openai` object and uses it to create an embedding model instance (`text-embedding-3-small`).  This allows the `Memory` class to use the specified embedder for generating vector embeddings of messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/Memory.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  memory: new Memory({\n    embedder: openai.embedding(\"text-embedding-3-small\"), // ネットワークリクエストを追加\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Sequential Step Definition with .then() in Workflow (TypeScript)\nDESCRIPTION: This snippet shows how to use the `.then()` method to define a sequence of steps in a Mastra workflow.  `stepTwo` executes after `stepOne`, and `stepThree` executes after `stepTwo`. The method ensures a specific execution order is maintained. No external dependencies are explicitly shown, but relies on a pre-existing `workflow` object and `step` definitions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/then.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepOne)\n  .then(stepTwo)\n  .then(stepThree);\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the chain of thought RAG example directory to set up the project locally.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/cot-rag\n```\n\n----------------------------------------\n\nTITLE: Installing the deprecated package\nDESCRIPTION: This command installs the deprecated @mastra/speech-playai package using npm. This package is no longer recommended for new projects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/speech-playai\"\n```\n\n----------------------------------------\n\nTITLE: Running the Development Server (NPM)\nDESCRIPTION: This snippet demonstrates how to run the documentation's development server using npm. The documentation will be served on `localhost:3000/docs`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Import and Configure Mem0 Integration\nDESCRIPTION: Imports the Mem0Integration class from the @mastra/mem0 package and configures it with an API key and user ID. This allows the application to interact with the Mem0 platform for long-term memory storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mem0Integration } from \"@mastra/mem0\";\n\nexport const mem0 = new Mem0Integration({\n  config: {\n    apiKey: process.env.MEM0_API_KEY!,\n    userId: \"alice\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Tools via API\nDESCRIPTION: This snippet shows how to retrieve a list of all available tools using the `client.getTools()` method. It assumes that `client` is an instance of the Mastra API client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/tools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst tools = await client.getTools();\n```\n\n----------------------------------------\n\nTITLE: Cloudinary Integration\nDESCRIPTION: Configures and uses Cloudinary for storing audio files.  It sets up the Cloudinary configuration using environment variables and provides a function `uploadToCloudinary` to upload a file to Cloudinary.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { v2 as cloudinary } from 'cloudinary';\n\ncloudinary.config({\n    cloud_name: process.env.CLOUDINARY_CLOUD_NAME,\n    api_key: process.env.CLOUDINARY_API_KEY,\n    api_secret: process.env.CLOUDINARY_API_SECRET\n});\n\nexport async function uploadToCloudinary(path: string) {\n    const response = await cloudinary.uploader.upload(path, { resource_type: 'raw' })\n    console.log(response)\n    return response.url\n}\n```\n\n----------------------------------------\n\nTITLE: Generating speech with PlayAITTS\nDESCRIPTION: This code snippet shows how to generate speech from text using the `generate()` method of the PlayAITTS class. It specifies the voice and text to be synthesized and awaits the result.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n\"// Generate speech\\nconst result = await tts.generate({\\n  voice: 'en-US-1',\\n  text: 'Hello from Mastra!',\\n});\"\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（Deepgram）\nDESCRIPTION: Deepgramを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、DeepgramVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { DeepgramVoice } from \"@mastra/voice-deepgram\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new DeepgramVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Vercel Configuration (JSON)\nDESCRIPTION: The vercel.json configuration file generated by VercelDeployer, essential for deploying the Mastra application.  It specifies the Vercel version, install command, builds configuration, and routes configuration for handling requests.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/vercel.mdx#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"version\": 2,\n  \"installCommand\": \"npm install --omit=dev\",\n  \"builds\": [\n    {\n      \"src\": \"index.mjs\",\n      \"use\": \"@vercel/node\",\n      \"config\": {\n        \"includeFiles\": [\"**\"]\n      }\n    }\n  ],\n  \"routes\": [\n    {\n      \"src\": \"/(.*)\",\n      \"dest\": \"index.mjs\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Running the embedding insertion example\nDESCRIPTION: Command to start the example application that will insert embeddings into Pinecone.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pinecone/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Getting Speakers - JavaScript\nDESCRIPTION: This snippet demonstrates the change in how to obtain the available speakers from the new package, replacing the old method of getting voices from the deprecated package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/speechify/README.md#2025-04-22_snippet_3\n\nLANGUAGE: diff\nCODE:\n```\n- const voices = await tts.voices();\n+ const speakers = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the required dependencies using the pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-text/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Install Memory Package (yarn)\nDESCRIPTION: This command installs the @mastra/memory package using yarn. This package provides the necessary functionality for implementing memory processors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with PNPM\nDESCRIPTION: Command to install the required package dependencies using the PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Executing User Registration Workflow via cURL Command\nDESCRIPTION: This bash command demonstrates how to execute the user registration workflow using cURL. It sends a POST request to the Mastra API endpoint with sample user data in JSON format.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/workflow-variables.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'http://localhost:4111/api/workflows/user-registration/start-async' \\\n     --header 'Content-Type: application/json' \\\n     --data '{\n       \"email\": \"user@example.com\",\n       \"name\": \"John Doe\",\n       \"age\": 25\n     }'\n```\n\n----------------------------------------\n\nTITLE: No Word Inclusion Example Typescript\nDESCRIPTION: Shows a case where none of the target words are present in the output. A `WordInclusionMetric` is initialized with cloud-related terms, and the output talks about modern technology, resulting in a zero inclusion score.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/word-inclusion.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst words3 = ['cloud', 'server', 'database'];\nconst metric3 = new WordInclusionMetric(words3);\n\nconst input3 = 'Tell me about your infrastructure';\nconst output3 = 'We use modern technology for our systems.';\n\nconst result3 = await metric3.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: result3.info,\n});\n// Example Output:\n// Metric Result: { score: 0, info: { totalWords: 3, matchedWords: 0 } }\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using FaithfulnessMetric with OpenAI in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the FaithfulnessMetric with the OpenAI language model and use it to measure the faithfulness of an LLM's output against a provided context. The metric evaluates how factually accurate the response is based on the context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/faithfulness.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { FaithfulnessMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new FaithfulnessMetric(model, {\n  context: [\n    \"The company was established in 1995.\",\n    \"Currently employs around 450-550 people.\",\n  ],\n});\n\nconst result = await metric.measure(\n  \"Tell me about the company.\",\n  \"The company was founded in 1995 and has 500 employees.\",\n);\n\nconsole.log(result.score); // 1.0\nconsole.log(result.info.reason); // \"All claims are supported by the context.\"\n```\n\n----------------------------------------\n\nTITLE: Configuring MastraClient with Options\nDESCRIPTION: This code configures the MastraClient with various options, including baseUrl, retries, backoffMs, maxBackoffMs, and custom headers.  These options allow for customizing the client's behavior, especially during development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new MastraClient({\n  // 必須\n  baseUrl: \"http://localhost:4111\",\n\n  // 開発用のオプション設定\n  retries: 3,           // リトライ試行回数\n  backoffMs: 300,       // 初期リトライバックオフ時間\n  maxBackoffMs: 5000,   // 最大リトライバックオフ時間\n  headers: {            // 開発用カスタムヘッダー\n    \"X-Development\": \"true\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Testing Agent Endpoint with Fetch\nDESCRIPTION: This snippet demonstrates how to test an agent endpoint using the `fetch` API in JavaScript. It sends a POST request with a JSON payload and then processes the response to log the agent's reply to the console. It includes error handling for failed requests.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_22\n\nLANGUAGE: javascript\nCODE:\n```\nfetch('http://localhost:4111/api/agents/weatherAgent/generate', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n  body: JSON.stringify({\n    messages: ['What is the weather in London?'],\n  }),\n})\n  .then(response => response.json())\n  .then(data => {\n    console.log('Agent response:', data.text);\n  })\n  .catch(error => {\n    console.error('Error:', error);\n  });\n```\n\n----------------------------------------\n\nTITLE: Generating Commit Messages with Dane\nDESCRIPTION: Command to use Dane's commit message generation functionality, which helps create semantically correct commit messages for your changes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/dane/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Run the commit message generator\ndane commit\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Documentation\nDESCRIPTION: Complete version history log showing incremental changes and dependency updates across multiple alpha releases of the memory module.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-libsql/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# memory\n\n## 0.0.1\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/memory@0.1.0-alpha.67\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/vector-libsql@0.0.1-alpha.20\n```\n\n----------------------------------------\n\nTITLE: Using a Console Logger in Typescript\nDESCRIPTION: This code snippet demonstrates how to use a console logger created with `createLogger()`. It showcases logging messages at different severity levels, including debug, info, and error. Note that debug messages are not logged because the logger level is set to 'info'.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/logger.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Using a console logger\nconst logger = createLogger({ name: 'Mastra', level: 'info' });\n\nlogger.debug('Debug message'); // Won't be logged because level is INFO\nlogger.info({ message: 'User action occurred', destinationPath: 'user-actions', type: 'AGENT' }); // Logged\nlogger.error('An error occurred'); // Logged as ERROR\n```\n\n----------------------------------------\n\nTITLE: BiasMetric Different Bias Types in TypeScript\nDESCRIPTION: This code snippet showcases how to test for different types of bias using the BiasMetric. It configures the metric with an OpenAI model and then measures the bias in two different scenarios, one exhibiting political bias and the other being unbiased, demonstrating the metric's ability to detect these differences.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/bias.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { BiasMetric } from \"@mastra/evals/llm\";\n\n// Configure the model for evaluation\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new BiasMetric(model);\n\n// Testing for different types of bias\nconst results = await Promise.all([\n  metric.measure(\n    \"Describe voting patterns\",\n    \"These radical right-wing voters consistently vote against their interests...\"\n  ),\n  metric.measure(\n    \"Describe workplace dynamics\",\n    \"Modern offices have diverse teams working together based on merit...\"\n  )\n]);\n\n// Example outputs:\n// Political bias example: { score: 1.0 }\n// Unbiased example: { score: 0.0 }\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a copy of the example environment variables file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the cleanup-rag example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/cleanup-rag\n```\n\n----------------------------------------\n\nTITLE: Connecting to Mastra from Frontend in TypeScript\nDESCRIPTION: This code snippet demonstrates how to connect to a Mastra server from a frontend application using the Mastra Client SDK. It imports the `MastraClient` class from `@mastra/client-js` and creates a new instance of the client, configured with the Mastra backend URL. The `baseUrl` should be replaced with the actual URL of the Mastra backend.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/text-to-speech.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MastraClient } from '@mastra/client-js';\n\nexport const mastraClient = new MastraClient({\n  baseUrl: 'http://localhost:4111', // Replace with your Mastra backend URL\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Event Listeners for Voice Interactions\nDESCRIPTION: Demonstrates how to use the event system provided by the realtime voice provider to listen for speaking events, transcribed text, and errors during voice interactions. This allows for more interactive and responsive voice applications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Listen for speech audio data sent from voice provider\nagent.voice.on(\"speaking\", ({ audio }) => {\n  // audio contains ReadableStream or Int16Array audio data\n});\n\n// Listen for transcribed text sent from both voice provider and user\nagent.voice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role} said: ${text}`);\n});\n\n// Listen for errors\nagent.voice.on(\"error\", (error) => {\n  console.error(\"Voice error:\", error);\n});\n```\n\n----------------------------------------\n\nTITLE: Creating an Agent with TTS in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create an agent with Text-to-Speech (TTS) capabilities using the Mastra AI platform and OpenAI. It utilizes the `@ai-sdk/openai`, `@mastra/core/agent`, `@mastra/voice-openai`, and `@mastra/memory` libraries. The agent is configured with instructions, a model (GPT-4o), and a voice (OpenAIVoice).\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/voice/text-to-speech.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { OpenAIVoice } from '@mastra/voice-openai';\nimport { Memory } from '@mastra/memory';\n\nconst instructions = `\n    You are an Interactive Storyteller Agent. Your job is to create engaging\n    short stories with user choices that influence the narrative. // omitted for brevity\n`;\n\nexport const storyTellerAgent = new Agent({\n  name: 'Story Teller Agent',\n  instructions: instructions,\n  model: openai('gpt-4o'),\n  voice: new OpenAIVoice(),\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Vector Store Errors\nDESCRIPTION: This code demonstrates how to handle errors that might be thrown by the Vector Store. It uses a try-catch block to catch potential errors. It specifically checks if the error is an instance of `VectorStoreError` and, if so, logs the error code and details for debugging purposes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pg.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Update Mastra Core Dependency\nDESCRIPTION: Updates the dependency on the `@mastra/core` package to a specific version. The `mastra/core` package likely contains core functionalities or shared components used by the Mastra package. This entry specifies the version of `@mastra/core` being used.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/CHANGELOG.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n- Updated dependencies [a910463]\n  - @mastra/core@0.5.0\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the toxicity example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/toxicity\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Changelog\nDESCRIPTION: Documents the numerous dependency updates in various versions of the packages, primarily affecting `@mastra/core`. These updates ensure compatibility and integration of the latest features and fixes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n- Updated dependencies [a910463]\n- Updated dependencies [59df7b6]\n- Updated dependencies [22643eb]\n- Updated dependencies [6feb23f]\n- Updated dependencies [f2d6727]\n- Updated dependencies [7a7a547]\n- Updated dependencies [29f3a82]\n- Updated dependencies [3d0e290]\n- Updated dependencies [e9fbac5]\n- Updated dependencies [301e4ee]\n- Updated dependencies [ee667a2]\n- Updated dependencies [dfbe4e9]\n- Updated dependencies [dab255b]\n- Updated dependencies [1e8bcbc]\n- Updated dependencies [f6678e4]\n- Updated dependencies [9e81f35]\n- Updated dependencies [c93798b]\n- Updated dependencies [a85ab24]\n- Updated dependencies [dbd9f2d]\n- Updated dependencies [59df7b6]\n- Updated dependencies [caefaa2]\n- Updated dependencies [c151ae6]\n- Updated dependencies [52e0418]\n- Updated dependencies [d79aedf]\n- Updated dependencies [03236ec]\n- Updated dependencies [3764e71]\n- Updated dependencies [df982db]\n- Updated dependencies [a171b37]\n- Updated dependencies [506f1d5]\n- Updated dependencies [02ffb7b]\n- Updated dependencies [0461849]\n- Updated dependencies [2259379]\n- Updated dependencies [aeb5e36]\n- Updated dependencies [f2301de]\n- Updated dependencies [358f069]\n- Updated dependencies [fd4a1d7]\n- Updated dependencies [c139344]\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_7\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/changelog-2025-01-31\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-31</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-31</h2><span class=\"text-xs text-left text-text-3\">Jan 31, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 31, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies in TypeScript\nDESCRIPTION: This snippet imports the necessary modules from the `@ai-sdk/openai`, `@mastra/core`, `@mastra/core/agent`, `@mastra/rag`, and `@mastra/pg` packages. These modules are used to interact with OpenAI, create Mastra agents, implement the vector query tool, and manage the vector store with PgVector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/basic-rag.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from '@mastra/core';\nimport { Agent } from '@mastra/core/agent';\nimport { createVectorQueryTool } from '@mastra/rag';\nimport { PgVector } from '@mastra/pg';\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAIVoice with OpenAI\nDESCRIPTION: Demonstrates how to initialize the OpenAIVoice class with default settings using environment variables and with specific configurations including API keys, speech model, listening model, and a default speaker. It showcases different initialization methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/openai.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\n// 環境変数を使用してデフォルト設定で初期化\nconst voice = new OpenAIVoice();\n\n// または特定の設定で初期化\nconst voiceWithConfig = new OpenAIVoice({\n  speechModel: {\n    name: 'tts-1-hd',\n    apiKey: 'your-openai-api-key'\n  },\n  listeningModel: {\n    name: 'whisper-1',\n    apiKey: 'your-openai-api-key'\n  },\n  speaker: 'alloy'  // デフォルトの声\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Editor Agent and Tool in TypeScript\nDESCRIPTION: This snippet defines an Editor agent using the OpenAI GPT-4 model and creates a tool for editing blog post copy. It uses Zod for input and output schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst editorTool = createTool({\n  id: \"editor-agent\",\n  description: \"Calls the editor agent to edit blog post copy.\",\n  inputSchema: z.object({\n    copy: z.string().describe(\"Blog post copy\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"Edited blog post copy\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${context.copy}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAG and Querying\nDESCRIPTION: This code demonstrates the basic usage of the GraphRAG class. It initializes the class, creates a graph from document chunks and embeddings, and then queries the graph using an embedding vector. The parameters `topK`, `randomWalkSteps`, and `restartProb` control the search process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/graph-rag.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GraphRAG } from \"@mastra/rag\";\n\nconst graphRag = new GraphRAG({\n  dimension: 1536,\n  threshold: 0.7\n});\n\n// Create the graph from chunks and embeddings\ngraphRag.createGraph(documentChunks, embeddings);\n\n// Query the graph with embedding\nconst results = await graphRag.query({\n  query: queryEmbedding,\n  topK: 10,\n  randomWalkSteps: 100,\n  restartProb: 0.15\n});\n```\n\n----------------------------------------\n\nTITLE: Markdown Version History for embed-chunk-array\nDESCRIPTION: Version history showing the progression from alpha releases to stable release, including dependency updates for @mastra/rag package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# embed-chunk-array\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [9625602]\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Environment Setup for OpenAI API Key\nDESCRIPTION: Creates a '.env.development' file to store the OpenAI API key necessary for authentication when interacting with OpenAI services. Edit the 'OPENAI_API_KEY' with your personal API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/interactive-story/README.md#2025-04-22_snippet_1\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the textual-difference example directory. This is the first step in setting up the example locally.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/textual-difference/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/textual-difference\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra\nDESCRIPTION: Initializes the Mastra instance with the defined agent. This step registers the `speechToSpeechServer` agent within the Mastra framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { speechToSpeechServer } from './agents';\n\nexport const mastra = new Mastra({\n    agents: {\n        speechToSpeechServer,\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra for Dash0 with OTLP\nDESCRIPTION: This snippet shows how to configure Mastra to export telemetry data to Dash0 using the OpenTelemetry Protocol (OTLP). The `telemetry` configuration section enables telemetry, sets the service name, and configures the exporter type to `otlp`.  Ensure the `@mastra/core` package is installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/dash0.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Routes for Cloudflare Workers\nDESCRIPTION: Example of configuring routes to direct traffic to a Cloudflare Worker based on URL patterns and domains. Shows both a custom domain configuration and a path-based route configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst routes = [\n  {\n    pattern: 'api.example.com/*',\n    zone_name: 'example.com',\n    custom_domain: true,\n  },\n  {\n    pattern: 'example.com/api/*',\n    zone_name: 'example.com',\n  },\n];\n```\n\n----------------------------------------\n\nTITLE: Example Navigation Meta File (Typescript)\nDESCRIPTION: This snippet shows an example of a `meta.ts` file used to define navigation entries in the Mastra documentation. It exports a `meta` object that maps content filenames to titles that appear in the sidebar.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst meta = {\n  overview: \"Overview\",\n};\n\nexport default meta;\n```\n\n----------------------------------------\n\nTITLE: Deleting a Vector Index in TypeScript\nDESCRIPTION: Remove a specific vector index, identified by its name, from the system. This operation is irreversible and is used to free up resources or manage outdated indexes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await vector.delete(\"index-name\");\n```\n\n----------------------------------------\n\nTITLE: Inaccurate Summary Evaluation Example\nDESCRIPTION: Example showing evaluation of a summary containing factual errors and misrepresentations of the source text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst input3 = `The World Wide Web was invented by Tim Berners-Lee in 1989 while working at CERN. \nHe published the first website in 1991. Berners-Lee made the Web freely available, with no patent \nand no royalties due.`;\n\nconst output3 = `The Internet was created by Tim Berners-Lee at MIT in the early 1990s, and he went \non to commercialize the technology through patents.`;\n\nconsole.log('Example 3 - Inaccurate Summary:');\nconsole.log('Input:', input3);\nconsole.log('Output:', output3);\n\nconst result3 = await metric.measure(input3, output3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    reason: result3.info.reason,\n    alignmentScore: result3.info.alignmentScore,\n    coverageScore: result3.info.coverageScore,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Changelog Entry for Package Updates\nDESCRIPTION: Markdown formatted changelog entries documenting version changes and dependency updates across multiple alpha releases for the Mastra AI project. Includes tracking of breaking changes and patch updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-todo-agent/CHANGELOG.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [70dabd9]\n- Updated dependencies [202d404]\n  - @mastra/core@0.2.0-alpha.98\n  - @mastra/memory@0.1.0-alpha.80\n```\n\n----------------------------------------\n\nTITLE: Running the Content Similarity Example in Bash\nDESCRIPTION: Command to execute the content similarity example after installation. This will run the example that demonstrates the different similarity scenarios and outputs the analysis.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/content-similarity/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM in Bash\nDESCRIPTION: Command to install the necessary Node.js dependencies using the PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: CSS Styles for sonner Toaster\nDESCRIPTION: This CSS code provides styling for the `sonner` toast notification library. It defines variables for colors, spacing, and positioning, and uses them to style various elements of the toaster and toast components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_1\n\nLANGUAGE: css\nCODE:\n```\n<style type=\"text/css\">:where(html[dir=\"ltr\"]),:where([data-sonner-toaster][dir=\"ltr\"]){--toast-icon-margin-start: -3px;--toast-icon-margin-end: 4px;--toast-svg-margin-start: -1px;--toast-svg-margin-end: 0px;--toast-button-margin-start: auto;--toast-button-margin-end: 0;--toast-close-button-start: 0;--toast-close-button-end: unset;--toast-close-button-transform: translate(-35%, -35%)}:where(html[dir=\"rtl\"]),:where([data-sonner-toaster][dir=\"rtl\"]){--toast-icon-margin-start: 4px;--toast-icon-margin-end: -3px;--toast-svg-margin-start: 0px;--toast-svg-margin-end: -1px;--toast-button-margin-start: 0;--toast-button-margin-end: auto;--toast-close-button-start: unset;--toast-close-button-end: 0;--toast-close-button-transform: translate(35%, -35%)}:where([data-sonner-toaster]){position:fixed;width:var(--width);font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;--gray1: hsl(0, 0%, 99%);--gray2: hsl(0, 0%, 97.3%);--gray3: hsl(0, 0%, 95.1%);--gray4: hsl(0, 0%, 93%);--gray5: hsl(0, 0%, 90.9%);--gray6: hsl(0, 0%, 88.7%);--gray7: hsl(0, 0%, 85.8%);--gray8: hsl(0, 0%, 78%);--gray9: hsl(0, 0%, 56.1%);--gray10: hsl(0, 0%, 52.3%);--gray11: hsl(0, 0%, 43.5%);--gray12: hsl(0, 0%, 9%);--border-radius: 8px;box-sizing:border-box;padding:0;margin:0;list-style:none;outline:none;z-index:999999999;transition:transform .4s ease}:where([data-sonner-toaster][data-lifted=\"true\"]){transform:translateY(-10px)}@media (hover: none) and (pointer: coarse){:where([data-sonner-toaster][data-lifted=\"true\"]){transform:none}}:where([data-sonner-toaster][data-x-position=\"right\"]){right:max(var(--offset),env(safe-area-inset-right))}:where([data-sonner-toaster][data-x-position=\"left\"]){left:max(var(--offset),env(safe-area-inset-left))}:where([data-sonner-toaster][data-x-position=\"center\"]){left:50%;transform:translate(-50%)}:where([data-sonner-toaster][data-y-position=\"top\"]){top:max(var(--offset),env(safe-area-inset-top))}:where([data-sonner-toaster][data-y-position=\"bottom\"]){bottom:max(var(--offset),env(safe-area-inset-bottom))}:where([data-sonner-toast]){--y: translateY(100%);--lift-amount: calc(var(--lift) * var(--gap));z-index:var(--z-index);position:absolute;opacity:0;transform:var(--y);filter:blur(0);touch-action:none;transition:transform .4s,opacity .4s,height .4s,box-shadow .2s;box-sizing:border-box;outline:none;overflow-wrap:anywhere}:where([data-sonner-toast][data-styled=\"true\"]){padding:16px;background:var(--normal-bg);border:1px solid var(--normal-border);color:var(--normal-text);border-radius:var(--border-radius);box-shadow:0 4px 12px #0000001a;width:var(--width);font-size:13px;display:flex;align-items:center;gap:6px}:where([data-sonner-toast]:focus-visible){box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}:where([data-sonner-toast][data-y-position=\"top\"]){top:0;--y: translateY(-100%);--lift: 1;--lift-amount: calc(1 * var(--gap))}:where([data-sonner-toast][data-y-position=\"bottom\"]){bottom:0;--y: translateY(100%);--lift: -1;--lift-amount: calc(var(--lift) * var(--gap))}:where([data-sonner-toast]) :where([data-description]){font-weight:400;line-height:1.4;color:inherit}:where([data-sonner-toast]) :where([data-title]){font-weight:500;line-height:1.5;color:inherit}:where([data-sonner-toast]) :where([data-icon]){display:flex;height:16px;width:16px;position:relative;justify-content:flex-start;align-items:center;flex-shrink:0;margin-left:var(--toast-icon-margin-start);margin-right:var(--toast-icon-margin-end)}:where([data-sonner-toast][data-promise=\"true\"]) :where([data-icon])>svg{opacity:0;transform:scale(.8);transform-origin:center;animation:sonner-fade-in .3s ease forwards}:where([data-sonner-toast]) :where([data-icon])>*{flex-shrink:0}:where([data-sonner-toast]) :where([data-icon]) svg{margin-left:var(--toast-svg-margin-start);margin-right:var(--toast-svg-margin-end)}:where([data-sonner-toast]) :where([data-content]){display:flex;flex-direction:column;gap:2px}[data-sonner-toast][data-styled=true] [data-button]{border-radius:4px;padding-left:8px;padding-right:8px;height:24px;font-size:12px;color:var(--normal-bg);background:var(--normal-text);margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end);border:none;cursor:pointer;outline:none;display:flex;align-items:center;flex-shrink:0;transition:opacity .4s,box-shadow .2s}:where([data-sonner-toast]) :where([data-button]):focus-visible{box-shadow:0 0 0 2px #0006}:where([data-sonner-toast]) :where([data-button]):first-of-type{margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end)}:where([data-sonner-toast]) :where([data-cancel]){color:var(--normal-text);background:rgba(0,0,0,.08)}:where([data-sonner-toast][data-theme=\"dark\"]) :where([data-cancel]){background:rgba(255,255,255,.3)}:where([data-sonner-toast]) :where([data-close-button]){position:absolute;left:var(--toast-close-button-start);right:var(--toast-close-button-end);top:0;height:20px;width:20px;display:flex;justify-content:center;align-items:center;padding:0;color:var(--gray12);border:1px solid var(--gray4);transform:var(--toast-close-button-transform);border-radius:50%;cursor:pointer;z-index:1;transition:opacity .1s,background .2s,border-color .2s}[data-sonner-toast] [data-close-button]{background:var(--gray1)}:where([data-sonner-toast]) :where([data-close-button]):focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}:where([data-sonner-toast]) :where([data-disabled=\"true\"]){cursor:not-allowed}:where([data-sonner-toast]):hover :where([data-close-button]):hover{background:var(--gray2);border-color:var(--gray5)}:where([data-sonner-toast][data-swiping=\"true\"]):before{content:\"\";position:absolute;left:0;right:0;height:100%;z-index:-1}:where([data-sonner-toast][data-y-position=\"top\"][data-swiping=\"true\"]):before{bottom:50%;transform:scaleY(3) translateY(50%)}:where([data-sonner-toast][data-y-position=\"bottom\"][data-swiping=\"true\"]):before{top:50%;transform:scaleY(3) translateY(-50%)}:where([data-sonner-toast][data-swiping=\"false\"][data-removed=\"true\"]):before{content:\"\";position:absolute;inset:0;transform:scaleY(2)}:where([data-sonner-toast]):after{content:\"\";position:absolute;left:0;height:calc(var(--gap) + 1px);bottom:100%;width:100%}:where([data-sonner-toast][data-mounted=\"true\"]){--y: translateY(0);opacity:1}:where([data-sonner-toast][data-expanded=\"false\"][data-front=\"false\"]){--scale: var(--toasts-before) * .05 + 1;--y: translateY(calc(var(--lift-amount) * var(--toasts-before))) scale(calc(-1 * var(--scale)));height:var(--front-toast-height)}:where([data-sonner-toast])>*{transition:opacity .4s}:where([data-sonner-toast][data-expanded=\"false\"][data-front=\"false\"][data-styled=\"true\"])>*{opacity:0}:where([data-sonner-toast][data-visible=\"false\"]){opacity:0;pointer-events:none}:where([data-sonner-toast][data-mounted=\"true\"][data-expanded=\"true\"]){--y: translateY(calc(var(--lift) * var(--offset)));height:var(--initial-height)}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"true\"][data-swipe-out=\"false\"]){--y: translateY(calc(var(--lift) * -100%));opacity:0}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"false\"][data-swipe-out=\"false\"][data-expanded=\"true\"]){--y: translateY(calc(var(--lift) * var(--offset) + var(--lift) * -100%));opacity:0}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"false\"][data-swipe-out=\"false\"][data-expanded=\"false\"]){--y: translateY(40%);opacity:0;transition:transform .5s,opacity .2s}:where([data-sonner-toast][data-removed=\"true\"][data-front=\"false\"]):before{height:calc(var(--initial-height) + 20%)}[data-sonner-toast][data-swiping=true]{transform:var(--y) translateY(var(--swipe-amount, 0px));transition:none}[data-sonner-toast][data-swiped=true]{user-select:none}[data-sonner-toast][data-swipe-out=true][data-y-position=bottom],[data-sonner-toast][data-swipe-out=true][data-y-position=top]{animation:swipe-out .2s ease-out forwards}@keyframes swipe-out{0%{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount)));opacity:1}to{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount) + var(--lift) * -100%));opacity:0}}@media (max-width: 600px){[data-sonner-toaster]{position:fixed;--mobile-offset: 16px;right:var(--mobile-offset);left:var(--mobile-offset);width:100%}[data-sonner-toaster][dir=rtl]{left:calc(var(--mobile-offset) * -1)}[data-sonner-toaster] [data-sonner-toast]{left:0;right:0;width:calc(100% - var(--mobile-offset) * 2)}[data-sonner-toaster][data-x-position=left]{left:var(--mobile-offset)}[data-sonner-toaster][data-y-position=bottom]{bottom:20px}[data-sonner-toaster][data-y-position=top]{top\n```\n\n----------------------------------------\n\nTITLE: Defining QueryResult Interface TypeScript\nDESCRIPTION: This code snippet defines the 'QueryResult' interface, representing the structure of results from a vector search query. It includes an ID, a score indicating similarity, and optional metadata and vector data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/vectorize.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[];\n}\n```\n\n----------------------------------------\n\nTITLE: Using Mastra Memory System with Agent Interactions in TypeScript\nDESCRIPTION: Mastraのメモリシステムを使用してエージェントとの会話を管理する例を示します。会話の開始、複数の質問の処理、および以前の会話の記憶を利用する方法が含まれています。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-pg.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { randomUUID } from \"crypto\";\n\n// 会話を開始する\nconst threadId = randomUUID();\nconst resourceId = \"SOME_USER_ID\";\n\n// 材料について尋ねる\nconst response1 = await chefAgent.stream(\n  \"私のキッチンには、パスタ、缶詰のトマト、ニンニク、オリーブオイル、そしていくつかの乾燥ハーブ（バジルとオレガノ）があります。何が作れますか？\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// 別の材料について尋ねる\nconst response2 = await chefAgent.stream(\n  \"今、友達の家にいて、彼らは鶏もも肉、ココナッツミルク、サツマイモ、カレーパウダーを持っています。\",\n  {\n    threadId,\n    resourceId,\n  },\n);\n\n// メモリを使用して以前の会話を思い出す\nconst response3 = await chefAgent.stream(\n  \"友達の家に行く前に何を料理しましたか？\",\n  {\n    threadId,\n    resourceId,\n    memoryOptions: {\n      lastMessages: 3, // コンテキストのために最後の3つのメッセージを取得\n    },\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Branching and Merging Paths in Mastra Workflows (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create branching and merging paths in a Mastra workflow.  stepA branches into stepB and stepC. stepB leads to stepD, and stepC leads to stepE. stepF is only triggered after both stepD and stepE are complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nmyWorkflow\n  .step(stepA)\n    .then(stepB)\n    .then(stepD)\n  .after(stepA)\n    .step(stepC)\n    .then(stepE)\n  .after([stepD, stepE])\n    .step(stepF);\n```\n\n----------------------------------------\n\nTITLE: Configuring Cloudflare Deployer in Mastra\nDESCRIPTION: This snippet shows how to configure the CloudflareDeployer within a Mastra application. It imports the necessary modules and instantiates the Mastra class with the deployer configured. Replace 'your-cloudflare-scope' and 'your-project-name' with your actual Cloudflare scope and project name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/deployment.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Mastra, createLogger } from '@mastra/core';\nimport { CloudflareDeployer } from '@mastra/deployer-cloudflare';\n\nexport const mastra = new Mastra({\n  agents: { /* your agents here */ },\n  logger: createLogger({ name: 'MyApp', level: 'debug' }),\n  deployer: new CloudflareDeployer({\n    scope: 'your-cloudflare-scope',\n    projectName: 'your-project-name',\n    // See complete configuration options in the reference docs\n  }),\n});\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Suspendable Second Step and Workflow Definition\nDESCRIPTION: Creates a second workflow step with suspend capability and defines the complete workflow structure. The step can be suspended if the incremented value is less than 100.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepTwo = new Step({\n  id: 'stepTwo',\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n\n    const secondValue = context.inputData?.secondValue ?? 0;\n    const doubledValue = context.getStepResult(stepOne)?.doubledValue ?? 0;\n\n    const incrementedValue = doubledValue + secondValue;\n\n    if (incrementedValue < 100) {\n      await suspend();\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue };\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new Workflow({\n  name: 'my-workflow',\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\n// run workflows in parallel\nmyWorkflow\n  .step(stepOne)\n  .then(stepTwo)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Retrieving Threads by Resource ID in Memory - Typescript\nDESCRIPTION: This code snippet demonstrates how to retrieve threads associated with a specific resource ID using the `getThreadsByResourceId` function from the `@mastra/core/memory` module. It initializes a `Memory` instance and calls `getThreadsByResourceId` with a resource ID to fetch the associated threads. The `config` variable represents the configuration object required for the Memory instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/getThreadsByResourceId.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/core/memory\";\n\nconst memory = new Memory(config);\n\nconst threads = await memory.getThreadsByResourceId({\n  resourceId: \"resource-123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Step Class Usage with TypeScript\nDESCRIPTION: Demonstrates how to instantiate and use the Step class in TypeScript to define a processing order step within a workflow.  It includes defining input and output schemas using Zod and an asynchronous execute function.  Dependencies include the Step class and Zod library for schema validation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-class.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst processOrder = new Step({\n  id: \"processOrder\",\n  inputSchema: z.object({\n    orderId: z.string(),\n    userId: z.string()\n  }),\n  outputSchema: z.object({\n    status: z.string(),\n    orderId: z.string()\n  }),\n  execute: async ({ context, runId }) => {\n    return {\n      status: \"processed\",\n      orderId: context.orderId\n    };\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables for Prompt Alignment example in Bash\nDESCRIPTION: Command to copy the environment example file to create a new .env file where the OpenAI API key will be stored.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/prompt-alignment/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Workflow using run.watch() in Typescript\nDESCRIPTION: This code snippet shows how to implement error handling within a Mastra workflow using the `run.watch()` function. It checks if the 'processDocument' step has failed and logs the error message if it has. This allows for implementing custom error recovery logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/watch.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nrun.watch(({results, activePaths}) => {\n  if (activePaths.get('processDocument')?.status === 'failed') {\n    console.error('Document processing failed:', results['processDocument'].error);\n    // Implement error recovery logic\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing a Workflow in Typescript\nDESCRIPTION: This code snippet demonstrates how to initialize a new Workflow instance in Typescript using the `@mastra/core/workflows` library. It imports the Workflow class and creates a new instance with a specified name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow } from \"@mastra/core/workflows\";\n\nconst workflow = new Workflow({ name: \"my-workflow\" });\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_4\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/using-ai-sdk-with-mastra\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Using AI SDK with Mastra</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Using AI SDK with Mastra</h2><span class=\"text-xs text-left text-text-3\">Feb 13, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Feb 13, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/shane.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Creating Custom API Routes in Mastra\nDESCRIPTION: Demonstrates how to register custom API routes with handlers using the Mastra server configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { registerApiRoute } from \"@mastra/core/server\";\n\nexport const mastra = new Mastra({\n  server: {\n    apiRoutes: [\n      registerApiRoute(\"/my-custom-route\", {\n        method: \"GET\",\n        handler: async (c) => {\n          // you have access to mastra instance here\n          const mastra = c.get(\"mastra\");\n\n          // you can use the mastra instance to get agents, workflows, etc.\n          const agents = await mastra.getAgent(\"my-agent\");\n\n          return c.json({ message: \"Hello, world!\" });\n        },\n      }),\n    ],\n  },\n  // Other configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Semantic Search with PgVector in Typescript\nDESCRIPTION: This snippet demonstrates a basic semantic search using PgVector. It embeds a query using OpenAI's embedding model, queries the vector store, and displays the results, which include text content and similarity scores. Requires the `@ai-sdk/openai`, `ai`, and `@mastra/pg` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { embed } from \"ai\";\nimport { PgVector } from \"@mastra/pg\";\n\n// クエリを埋め込みに変換\nconst { embedding } = await embed({\n  value: \"記事の主なポイントは何ですか？\",\n  model: openai.embedding('text-embedding-3-small'),\n});\n\n// ベクトルストアをクエリ\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING);\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n});\n\n// 結果を表示\nconsole.log(results);\n```\n\n----------------------------------------\n\nTITLE: Cloning the repository and navigating to the project directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the summarization example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/summarization/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/summarization\n```\n\n----------------------------------------\n\nTITLE: Version History Documentation in Markdown\nDESCRIPTION: Detailed changelog tracking patch versions and dependency updates for yc-directory package. Documents changes across multiple alpha versions and their corresponding dependency version requirements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/yc-directory/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# yc-directory\n\n## 1.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/evals@0.1.0-alpha.27\n```\n\n----------------------------------------\n\nTITLE: Mastra Class Initialization (Full)\nDESCRIPTION: Illustrates a full initialization of the Mastra class in TypeScript with all available options.  It includes agents, workflows, integrations, a custom logger, storage, tools, and vectors.  This example shows how to configure the Mastra instance with various components for comprehensive functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/core/mastra-class.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { createLogger } from \"@mastra/core/logger\";\n\n// Full initialization with all options\nexport const mastra = new Mastra({\n  agents: {},\n  workflows: [],\n  integrations: [],\n  logger: createLogger({\n    name: \"My Project\",\n    level: \"info\",\n  }),\n  storage: {},\n  tools: {},\n  vectors: {},\n});\n```\n\n----------------------------------------\n\nTITLE: File Logger Creation (TypeScript)\nDESCRIPTION: Shows how to create a file logger using the createLogger function and the FileTransport. The logger is configured to write logs to a file named \"test.log\" in the \"test-dir\" directory, with a log level of \"warn\". It logs a warning message about low disk space, including metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/create-logger.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { FileTransport } from \"@mastra/loggers/file\";\n\nconst fileLogger = createLogger({\n  name: \"Mastra\",\n  transports: { file: new FileTransport({ path: \"test-dir/test.log\" }) },\n  level: \"warn\",\n});\nfileLogger.warn(\"Low disk space\", {\n  destinationPath: \"system\",\n  type: \"WORKFLOW\",\n});\n```\n\n----------------------------------------\n\nTITLE: Define Copywriter Agent - TypeScript\nDESCRIPTION: This code snippet defines a copywriter agent using the `Agent` class from `@mastra/core/agent`. It sets the agent's name to 'Copywriter' and provides instructions for generating blog post copy. The model used is 'claude-3-5-sonnet-20241022' from the Anthropic AI SDK.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/multi-agent-workflow.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"あなたはブログ投稿のコピーを書くコピーライターエージェントです。\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Update package.json for MCP Server\nDESCRIPTION: Updates the `package.json` file to include a `bin` entry pointing to the compiled server file and a script to build the server using `tsup`. The build script compiles the TypeScript file, formats it as an ESM module, disables splitting, generates declaration files, and makes the compiled JavaScript file executable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bin\": \"dist/stdio.js\",\n  \"scripts\": {\n    \"build:mcp\": \"tsup src/mastra/stdio.ts --format esm --no-splitting --dts && chmod +x dist/stdio.js\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Getting User Input in Mastra Workflow - TypeScript\nDESCRIPTION: This snippet defines a step that retrieves user input from the context. It simulates user input acquisition, which might come from forms or APIs in practical applications. The output is validated with a Zod schema.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/suspend-and-resume.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\n\n// Step 1: Get user input\nconst getUserInput = new Step({\n  id: 'getUserInput',\n  execute: async ({ context }) => {\n    // In a real application, this might come from a form or API\n    return { userInput: context.triggerData.input };\n  },\n  outputSchema: z.object({ userInput: z.string() }),\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating low position adherence in TypeScript\nDESCRIPTION: Illustrates how to evaluate a response where relevant information appears last in the context using the Context Position metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-position.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'Rainbows appear in the sky.',\n  'Rainbows have different colors.',\n  'Rainbows are curved in shape.',\n  'Rainbows form when sunlight hits water droplets.',\n];\n\nconst metric3 = new ContextPositionMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'How do rainbows form?';\nconst response3 = 'Rainbows are created when sunlight interacts with water droplets in the air.';\n\nconsole.log('Example 3 - Low Position Adherence:');\nconsole.log('Context:', context3);\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.12, reason: 'The context includes some relevant information, but most of the relevant information is at the end.' }\n```\n\n----------------------------------------\n\nTITLE: Initializing KeywordCoverageMetric in TypeScript\nDESCRIPTION: This snippet demonstrates how to import and initialize the KeywordCoverageMetric class for measuring keyword coverage in text. The 'measure' method is called with input and output text, and the result is logged to the console indicating the score and detailed metrics.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/keyword-coverage.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new KeywordCoverageMetric();\n\nconst result = await metric.measure(\n  \"What are the key features of Python programming language?\",\n  \"Python is a high-level programming language known for its simple syntax and extensive libraries.\"\n);\n\nconsole.log(result.score); // Coverage score from 0-1\nconsole.log(result.info); // Object containing detailed metrics about keyword coverage\n```\n\n----------------------------------------\n\nTITLE: Mastra Error Handling\nDESCRIPTION: Shows error handling in Mastra when attempting to access a non-existent tool.  The code uses a try-catch block to handle potential errors. If an error of type Error is caught, the error message is logged to the console.  This ensures that the application can gracefully handle cases where a requested tool is not found.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/core/mastra-class.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const tool = mastra.getTool(\"nonexistentTool\");\n} catch (error) {\n  if (error instanceof Error) {\n    console.log(error.message); // \"Tool with name nonexistentTool not found\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Validation Errors in Workflow Execution\nDESCRIPTION: This code snippet demonstrates how to catch and handle validation errors that may occur during the execution of a workflow using the `start()` method.  It catches `ValidationError` exceptions and logs the error type and details, allowing for specific error handling based on the validation issue.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/start.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const result = await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using MCP tools with a fixed toolset in TypeScript\nDESCRIPTION: This TypeScript code demonstrates how to create a new Agent with a fixed toolset retrieved from the MCP configuration. The tools are obtained using `mcp.getTools()` and are fixed at the time of agent creation. This approach is suitable when the tool configuration remains constant.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = new Agent({\n  name: \"CLI Assistant\",\n  instructions: \"You help users with CLI tasks\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: await mcp.getTools(), // ツールはエージェント作成時に固定されます\n});\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template in Bash\nDESCRIPTION: Command to create a local environment file from the example template. This file will store API keys needed for the application to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Evaluating High Relevancy Response Example in TypeScript\nDESCRIPTION: Demonstrate how to evaluate a response that is highly relevant to its query, including logging the query, response, and metric results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst query1 = 'What are the health benefits of regular exercise?';\nconst response1 =\n  'Regular exercise improves cardiovascular health, strengthens muscles, boosts metabolism, and enhances mental well-being through the release of endorphins.';\n\nconsole.log('Example 1 - High Relevancy:');\nconsole.log('Query:', query1);\nconsole.log('Response:', response1);\n\nconst result1 = await metric.measure(query1, response1);\nconsole.log('Metric Result:', {\n  score: result1.score,\n  reason: result1.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 1, reason: 'The response is highly relevant to the query. It provides a comprehensive overview of the health benefits of regular exercise.' }\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/astra\nDESCRIPTION: This command installs the @mastra/astra package from npm, allowing you to use it in your TypeScript or JavaScript projects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/astra/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/astra\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This code snippet demonstrates how to set up the necessary environment variables for the application, including the OpenAI API key and the PostgreSQL connection string. These variables are essential for the application to connect to the OpenAI service and the PostgreSQL database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/query/hybrid-vector-search.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Rerank Function Usage Example TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the `rerank` function. It imports the `openai` and `rerank` functions, initializes an OpenAI model, and calls the `rerank` function with example parameters, including vector search results, a query string, the model, and an options object specifying weights and the number of top results to return. Requires the `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/rerank.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { rerank } from \"@mastra/rag\";\n\nconst model = openai(\"gpt-4o-mini\");\n\nconst rerankedResults = await rerank(\n  vectorSearchResults,\n  \"How do I deploy to production?\",\n  model,\n  {\n    weights: {\n      semantic: 0.5,\n      vector: 0.3,\n      position: 0.2\n    },\n    topK: 3\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Evaluating Response with Low Context Relevancy\nDESCRIPTION: This snippet demonstrates how to evaluate a response where most of the context is irrelevant. It defines a context array, initializes a `ContextRelevancyMetric` instance, defines a query and a corresponding response, measures the context relevancy, and prints the results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-relevancy.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst context3 = [\n  'グレートバリアリーフはオーストラリアにあります。',\n  'サンゴ礁は生存するために暖かい水を必要とします。',\n  '海洋生物はサンゴ礁に依存しています。',\n  'オーストラリアの首都はキャンベラです。',\n];\n\nconst metric3 = new ContextRelevancyMetric(openai('gpt-4o-mini'), {\n  context: context3,\n});\n\nconst query3 = 'オーストラリアの首都はどこですか？';\nconst response3 = 'オーストラリアの首都はキャンベラです。';\n\nconsole.log('例 3 - 低い関連性:');\nconsole.log('コンテキスト:', context3);\nconsole.log('クエリ:', query3);\nconsole.log('応答:', response3);\n\nconst result3 = await metric3.measure(query3, response3);\nconsole.log('メトリック結果:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// 例の出力:\n// メトリック結果: { score: 0.12, reason: 'コンテキストには関連する情報が1つしかなく、ほとんどのコンテキストが無関係です。' }\n```\n\n----------------------------------------\n\nTITLE: Checking Memory Status in TypeScript\nDESCRIPTION: This code shows how to check the status of the memory system for a specific agent using the Mastra client.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst status = await client.getMemoryStatus(\"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Embedding a Single Text Input with Mastra AI SDK\nDESCRIPTION: This code snippet demonstrates how to use the `embed` function from the Mastra AI SDK to generate a vector embedding for a single text input. It imports the `embed` function, specifies the embedding model to use (e.g., an OpenAI embedding model), the text to embed, and the maximum number of retries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/embeddings.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed } from 'ai';\n\nconst result = await embed({\n  model: openai.embedding('text-embedding-3-small'),\n  value: \"Your text to embed\",\n  maxRetries: 2  // optional, defaults to 2\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Smithery.ai Registry (Windows)\nDESCRIPTION: This TypeScript code configures MCP with the Smithery.ai registry for the sequential thinking server on Windows systems.  It uses `cmd /c` to execute the npx command, which runs the Smithery CLI and the sequential thinking server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Windows\nconst mcp = new MCPConfiguration({\n  servers: {\n    sequentialThinking: {\n      command: \"cmd\",\n      args: [\n        \"/c\",\n        \"npx\",\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@smithery-ai/server-sequential-thinking\",\n        \"--config\",\n        \"{}\",\n      ],\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Memory Configuration - Working Memory Tool Call\nDESCRIPTION: This code snippet demonstrates how to configure the memory object to use tool calls for saving working memory. It introduces a new option within the Memory constructor to enable the tool-call mechanism. This is particularly useful for response methods like toDataStream where masking working memory chunks would be resource intensive.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nnew Memory({ workingMemory: { enabled: true, use: \"tool-call\" } })\n```\n\n----------------------------------------\n\nTITLE: Implementing Azure Speech-to-Text\nDESCRIPTION: Shows integration with Azure's voice services for audio transcription and response generation. Utilizes AzureVoice provider for processing audio files.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from 'fs';\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { AzureVoice } from \"@mastra/voice-azure\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new AzureVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: CloudflareDeployer Initialization (TypeScript)\nDESCRIPTION: Demonstrates how to initialize the CloudflareDeployer with scope, project name, routes, worker namespace, and authentication details. This example shows how to integrate the deployer into a Mastra application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/cloudflare.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { CloudflareDeployer } from '@mastra/deployer-cloudflare';\n\nconst mastra = new Mastra({\n  deployer: new CloudflareDeployer({\n    scope: 'your-account-id',\n    projectName: 'your-project-name',\n    routes: [\n      {\n        pattern: 'example.com/*',\n        zone_name: 'example.com',\n        custom_domain: true,\n      },\n    ],\n    workerNamespace: 'your-namespace',\n    auth: {\n      apiToken: 'your-api-token',\n      apiEmail: 'your-email',\n    },\n  }),\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Mixed Alignment Evaluation Example\nDESCRIPTION: Implementation of prompt alignment evaluation for a response that partially follows the given instructions. Shows evaluation of product listing response with some missing instruction elements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst instructions2 = [\n  'Use bullet points',\n  'Include prices in USD',\n  'Show stock status',\n  'Add product descriptions'\n];\n\nconst metric2 = new PromptAlignmentMetric(openai('gpt-4o-mini'), {\n  instructions: instructions2,\n});\n\nconst query2 = 'List the available products';\nconst response2 = '• Coffee - $4.99 (In Stock)\\n• Tea - $3.99\\n• Water - $1.99 (Out of Stock)';\n\nconsole.log('Example 2 - Mixed Alignment:');\nconsole.log('Instructions:', instructions2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n  details: result2.info.scoreDetails,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Graph Query Tool in Typescript\nDESCRIPTION: This snippet demonstrates how to create a graph query tool using the `createGraphQueryTool` function. It is used for documents with complex relationships and allows for traversing connections between chunks. Requires the `@ai-sdk/openai` and `@mastra/rag` packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/retrieval.mdx#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphQueryTool = createGraphQueryTool({\n  vectorStoreName: 'pgVector',\n  indexName: 'embeddings',\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    threshold: 0.7,\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text\nDESCRIPTION: This snippet illustrates how to generate audio from text input using the speak method of the DeepgramVoice instance. Users can override the default speaker and adjust the speech speed, providing flexibility in audio output.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst audioStream = await voice.speak('Hello from Mastra!', {\n  speaker: 'aura-athena-en', // Optional: override default speaker\n  speed: 1.0, // Optional: adjust speech speed\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Available Speakers in TypeScript\nDESCRIPTION: This code snippet demonstrates how to retrieve a list of available voice options (speakers) using the `getSpeakers` method of the CloudflareVoice class. The returned value is an array of speaker objects, where each object contains the `voiceId` and `language` properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/cloudflare.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Get available voices\nconst speakers = await voice.getSpeakers();\nconsole.log(speakers);\n```\n\n----------------------------------------\n\nTITLE: Custom Memory Configuration with LibSQL in TypeScript\nDESCRIPTION: This snippet showcases how to customize the `Memory` class with specific storage and vector database configurations using LibSQL. It initializes `LibSQLStore` and `LibSQLVector` instances, providing them with database URLs.  It also configures options like `lastMessages`, `semanticRecall` with `topK` and `messageRange`, and `workingMemory`. The configured `Memory` instance is then passed to the `Agent` constructor.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/memory/Memory.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { LibSQLStore } from \"@mastra/core/storage/libsql\";\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst memory = new Memory({\n  // オプションのストレージ設定 - デフォルトでlibsqlが使用されます\n  storage: new LibSQLStore({\n    url: \"file:memory.db\",\n  }),\n\n  // セマンティック検索のためのオプションのベクターデータベース - デフォルトでlibsqlが使用されます\n  vector: new LibSQLVector({\n    url: \"file:vector.db\",\n  }),\n\n  // メモリ設定オプション\n  options: {\n    // 含める最近のメッセージの数\n    lastMessages: 20,\n\n    // セマンティック検索設定\n    semanticRecall: {\n      topK: 3, // 取得する類似メッセージの数\n      messageRange: {\n        // 各結果の周囲に含めるメッセージ\n        before: 2,\n        after: 1,\n      },\n    },\n\n    // 作業メモリ設定\n    workingMemory: {\n      enabled: true,\n      template: `\n# User\n- First Name:\n- Last Name:\n`,\n    },\n  },\n});\n\nconst agent = new Agent({\n  memory,\n  ...otherOptions,\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Trigger Data in Workflows: TypeScript\nDESCRIPTION: This snippet illustrates how to access original trigger data in a workflow, specifically demonstrating type-safe handling of the trigger schema for consistent data management throughout the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/control-flow.mdx#2025-04-22_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\n// Define trigger schema\nconst triggerSchema = z.object({\n  customerId: z.string(),\n  orderItems: z.array(z.string()),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\nconst processOrderStep = new Step({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // Access trigger data with type safety\n    const triggerData = context.getStepResult<TriggerType>('trigger');\n\n    return {\n      customerId: triggerData?.customerId,\n      itemCount: triggerData?.orderItems.length || 0,\n      status: \"processing\"\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"order-workflow\",\n  triggerSchema,\n});\n\nworkflow\n  .step(processOrderStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Workflow Steps\nDESCRIPTION: Connects all the defined steps in the RAG workflow and commits the configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nragWorkflow\n  .step(analyzeContext)\n  .then(breakdownThoughts)\n  .then(connectPieces)\n  .then(drawConclusions)\n  .then(finalAnswer);\n\nragWorkflow.commit();\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech using SarvamVoice TypeScript\nDESCRIPTION: This snippet demonstrates how to convert text to speech using the SarvamVoice class. It initializes the class and calls the `speak` method with a text input, which returns an audio stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/sarvam.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// テキストを音声に変換\nconst audioStream = await voice.speak(\"こんにちは、どのようにお手伝いできますか？\");\n```\n\n----------------------------------------\n\nTITLE: Defining a Working Memory Template\nDESCRIPTION: This snippet defines a template that guides the agent on how to structure the ToDo list data. The template uses Markdown to represent the data structure, helping the agent understand what information to track for each ToDo item.  It also specifies active and completed items.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory-advanced.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    lastMessages: 1,\n    workingMemory: {\n      enabled: true,\n      template: `\n# Todo List\n## アイテムのステータス\n- アクティブなアイテム:\n  - 例 (期限: 3028年2月7日, 開始: 2025年2月7日)\n    - 説明: これは例のタスクです\n## 完了\n- まだありません\n`,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork generate() Method in TypeScript\nDESCRIPTION: This code snippet presents the `generate()` method signature of the AgentNetwork class.  It generates a response using the agent network. It takes messages as input, which can be a string, string array, or CoreMessage array, and optional arguments of type `AgentGenerateOptions`. It returns a Promise that resolves to a `GenerateTextResult`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/networks/agent-network.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync generate(\n  messages: string | string[] | CoreMessage[],\n  args?: AgentGenerateOptions\n): Promise<GenerateTextResult>\n```\n\n----------------------------------------\n\nTITLE: HTML Chunking with Strategy Specific Options in Typescript\nDESCRIPTION: This code demonstrates how to use the `.chunk()` function with HTML-specific options. It shows how to define headers and sections for chunking HTML documents, along with a general size parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// HTML戦略の例\nconst chunks = await doc.chunk({\n  strategy: 'html',\n  headers: [['h1', 'title'], ['h2', 'subtitle']], // HTML固有のオプション\n  sections: [['div.content', 'main']], // HTML固有のオプション\n  size: 500 // 一般的なオプション\n});\n```\n\n----------------------------------------\n\nTITLE: Evaluating Low Bias Example in TypeScript\nDESCRIPTION: Illustrates evaluation of an objective response with low bias using the Bias metric. It includes query, response, and result logging.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst query3 = 'What is the best hiring practice?';\nconst response3 =\n  'Effective hiring practices focus on objective criteria such as skills, experience, and demonstrated abilities. Using structured interviews and standardized assessments helps ensure fair evaluation of all candidates based on merit.';\n\nconsole.log('Example 3 - Low Bias:');\nconsole.log('Query:', query3);\nconsole.log('Response:', response3);\n\nconst result3 = await metric.measure(query3, response3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  reason: result3.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0, reason: 'The response does not contain any gender or age-related stereotypes or assumptions.' }\n```\n\n----------------------------------------\n\nTITLE: Install @mastra/voice-google\nDESCRIPTION: Installs the @mastra/voice-google package as a dependency to enable Google Cloud Voice integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/google/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-google\n```\n\n----------------------------------------\n\nTITLE: Generating and Storing Embeddings\nDESCRIPTION: Creates embeddings for document chunks and stores them in the PostgreSQL vector database with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  values: chunks.map(chunk => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\nconst vectorStore = mastra.getVector(\"pgVector\");\nawait vectorStore.createIndex({\n  indexName: \"embeddings\",\n  dimension: 1536,\n});\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Describing Index Statistics in TypeScript\nDESCRIPTION: Defines the structure of the IndexStats object, which describes the statistics of a Qdrant index, including its dimension, count, and metric. This interface is returned by the `describeIndex()` method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/qdrant.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for RAG System\nDESCRIPTION: Imports necessary modules from OpenAI, PgVector, Mastra, and AI SDK for implementing the RAG system with re-ranking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { PgVector } from '@mastra/pg';\nimport { MDocument, rerank } from '@mastra/rag';\nimport { embedMany, embed } from 'ai';\n```\n\n----------------------------------------\n\nTITLE: Getting All Indexes in Typescript\nDESCRIPTION: This code retrieves a list of all available vector indexes using the `vector.getIndexes` method. The method returns a promise resolving with the list of indexes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst indexes = await vector.getIndexes();\n```\n\n----------------------------------------\n\nTITLE: Rerank Function Signature TypeScript\nDESCRIPTION: This code snippet shows the function signature for the `rerank` function. It takes an array of `QueryResult` objects, a query string, a `ModelConfig` object, and an optional `RerankerFunctionOptions` object as input.  It returns a promise that resolves to an array of `RerankResult` objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/rerank.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction rerank(\n  results: QueryResult[],\n  query: string,\n  modelConfig: ModelConfig,\n  options?: RerankerFunctionOptions\n): Promise<RerankResult[]>\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio from a File\nDESCRIPTION: Demonstrates how to transcribe audio from a file using the agent's listen method. The example reads an audio file as a stream and passes it to the agent for transcription, with appropriate error handling.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createReadStream } from \"fs\";\nimport path from \"path\";\n\n// Read audio file and transcribe\nconst audioFilePath = path.join(process.cwd(), \"/agent.m4a\");\nconst audioStream = createReadStream(audioFilePath);\n\ntry {\n  console.log(\"Transcribing audio file...\");\n  const transcription = await agent.voice.listen(audioStream, {\n    filetype: \"m4a\",\n  });\n  console.log(\"Transcription:\", transcription);\n} catch (error) {\n  console.error(\"Error transcribing audio:\", error);\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Workflow Status in Typescript\nDESCRIPTION: This code snippet demonstrates how to monitor and react to different workflow statuses using the `watch` method in Typescript.  It includes examples for handling suspended, completed, and failed states.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/workflow.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst { runId, start, watch } = workflow.createRun();\n\nwatch(async ({ status }) => {\n  switch (status) {\n    case \"SUSPENDED\":\n      // 一時停止状態の処理\n      break;\n    case \"COMPLETED\":\n      // 結果の処理\n      break;\n    case \"FAILED\":\n      // エラー状態の処理\n      break;\n  }\n});\n\nawait start({ triggerData: data });\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables - Environment\nDESCRIPTION: This code snippet outlines required and optional environment variable settings for the application, including keys for API access and database connection. Proper configuration is essential for the functionality of the API crawling and AI processing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/openapi-spec-writer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\n# Required for API crawling\nFIRECRAWL_API_KEY=your_firecrawl_api_key\nGITHUB_API_KEY=your_github_token\n\n# Required for AI processing (at least one)\nANTHROPIC_API_KEY=your_anthropic_key\nOPENAI_API_KEY=your_openai_key\n\n# Optional: Database URL if using one\nDB_URL=your_database_url\n```\n\n----------------------------------------\n\nTITLE: Create a Tool Directory and File\nDESCRIPTION: These commands create a directory structure `src/mastra/tools` and a file `weather-tool.ts` inside it. This prepares the location where tool definitions will be stored in the project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/mastra/tools && touch src/mastra/tools/weather-tool.ts\n```\n\n----------------------------------------\n\nTITLE: Running Local Development Environment with Package Manager\nDESCRIPTION: Commands to install dependencies and start the local development server using pnpm. This is part of the local development setup process after environment variables have been configured.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/crypto-chatbot/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with Working Memory Enabled\nDESCRIPTION: This code snippet initializes a Memory instance with working memory enabled. The `lastMessages` option is set to 1, indicating that the working memory can maintain conversation consistency even with a short context window. The memory system uses LibSQL storage by default.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/streaming-working-memory-advanced.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\n\nconst memory = new Memory({\n  options: {\n    lastMessages: 1, // 作業メモリは短いコンテキストウィンドウでも会話の一貫性を維持できることを意味します\n    workingMemory: {\n      enabled: true,\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Generate Text Response with Chef Agent\nDESCRIPTION: This code snippet demonstrates how to generate a text response from the chef agent based on a user query. It creates a query about available ingredients and uses the `chefAgent.generate` method to get a response.  The response object includes the generated text, which is then printed to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const query =\n    \"In my kitchen I have: pasta, canned tomatoes, garlic, olive oil, and some dried herbs (basil and oregano). What can I make?\";\n  console.log(`Query: ${query}`);\n\n  const response = await chefAgent.generate([{ role: \"user\", content: query }]);\n  console.log(\"\\n👨‍🍳 Chef Michel:\", response.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example\nDESCRIPTION: Demonstrates how to catch and handle errors thrown by the Astra Vector Store. It specifically checks for instances of `VectorStoreError`, which provide details about the error code and additional context.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/astra.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Data in Step Context (TypeScript)\nDESCRIPTION: This snippet shows how to access the event data within a step's `execute` function after the workflow has been resumed with `resumeWithEvent`.  The event data is available under `context.inputData.resumedEvent`. The code demonstrates retrieving the `approverName` and `approved` fields from the event data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/events.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst processApprovalStep = new Step({\n  id: 'processApproval',\n  execute: async ({ context }) => {\n    // Access the event data\n    const eventData = context.inputData.resumedEvent;\n\n    return {\n      processingResult: `Processed approval from ${eventData.approverName}`,\n      wasApproved: eventData.approved,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Metric Evaluation Example\nDESCRIPTION: Demonstrates how to initialize and use ContentSimilarityMetric and ToxicityMetric for evaluating AI outputs. Shows configuration options and basic usage pattern.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric, ToxicityMetric } from '@mastra/evals';\n\n// Initialize metrics\nconst similarityMetric = new ContentSimilarityMetric({\n  ignoreCase: true,\n  ignoreWhitespace: true,\n});\n\nconst toxicityMetric = new ToxicityMetric({\n  model: openai('gpt-4'),\n  scale: 1, // Optional: adjust scoring scale\n});\n\n// Evaluate outputs\nconst input = 'What is the capital of France?';\nconst output = 'Paris is the capital of France.';\n\nconst similarityResult = await similarityMetric.measure(input, output);\nconst toxicityResult = await toxicityMetric.measure(input, output);\n\nconsole.log('Similarity Score:', similarityResult.score);\nconsole.log('Toxicity Score:', toxicityResult.score);\n```\n\n----------------------------------------\n\nTITLE: Comparing Initial and Re-ranked Results in Mastra RAG System\nDESCRIPTION: Prints and compares the initial vector search results with the re-ranked results, showing improvements in search quality by combining vector similarity and semantic understanding.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconsole.log('Initial Results:');\ninitialResults.forEach((result, index) => {\n  console.log(`Result ${index + 1}:`, {\n    text: result.metadata.text,\n    score: result.score,\n  });\n});\n\nconsole.log('Re-ranked Results:');\nrerankedResults.forEach(({ result, score, details }, index) => {\n  console.log(`Result ${index + 1}:`, {\n    text: result.metadata.text,\n    score: score,\n    semantic: details.semantic,\n    vector: details.vector,\n    position: details.position,\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Connection Step\nDESCRIPTION: Defines the third step in the workflow for connecting different pieces of information from the retrieved chunks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst connectPieces = new Step({\n  id: \"connectPieces\",\n  outputSchema: z.object({\n    connections: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const process = context?.getStepResult<{\n      breakdown: string;\n    }>(\"breakdownThoughts\")?.breakdown;\n    const connectionPrompt = `\n        Based on the breakdown: ${process}\n\n        3. Explain how you're connecting different pieces from the retrieved chunks.\n    `;\n\n    const connections = await ragAgent?.generate(connectionPrompt);\n    console.log(connections?.text);\n    return {\n      connections: connections?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Splitting Action Types in Tools and Workflows\nDESCRIPTION: This change involves the segregation of action types between tools and workflows. It allows for a more organized and distinct separation of concerns, potentially improving maintainability and clarity within the codebase. This change may influence how actions are defined and processed in the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_3\n\nLANGUAGE: TEXT\nCODE:\n```\n52e0418: Split up action types between tools and workflows\n```\n\n----------------------------------------\n\nTITLE: Configure Memory with Last Messages Option\nDESCRIPTION: This code snippet shows how to configure the Memory instance with the lastMessages option. This option specifies the number of recent messages to include in each new request, providing the agent with immediate conversational context. It sets the number of last messages to 10.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  options: {\n    lastMessages: 10,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install project dependencies using the PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-html/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Evaluating Mixed Precision Context Usage\nDESCRIPTION: This example shows how to evaluate a response where some context information is irrelevant. It uses volcano-related context and measures the precision of a response about volcano types.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-precision.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst context2 = [\n  'Volcanoes are openings in the Earth\\'s crust.',\n  'Volcanoes can be active, dormant, or extinct.',\n  'Hawaii has many active volcanoes.',\n  'The Pacific Ring of Fire has many volcanoes.',\n];\n\nconst metric2 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {\n  context: context2,\n});\n\nconst query2 = 'What are the different types of volcanoes?';\nconst response2 = 'Volcanoes can be classified as active, dormant, or extinct based on their activity status.';\n\nconsole.log('Example 2 - Mixed Precision:');\nconsole.log('Context:', context2);\nconsole.log('Query:', query2);\nconsole.log('Response:', response2);\n\nconst result2 = await metric2.measure(query2, response2);\nconsole.log('Metric Result:', {\n  score: result2.score,\n  reason: result2.info.reason,\n});\n// Example Output:\n// Metric Result: { score: 0.5, reason: 'The context uses some relevant information and includes some irrelevant information.' }\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Evals Package\nDESCRIPTION: NPM installation command for the @mastra/evals package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/evals\n```\n\n----------------------------------------\n\nTITLE: MCPClient disconnect() Method\nDESCRIPTION: Closes the connection with the MCP server. This method is asynchronous and returns a Promise that resolves when the connection is successfully closed. No specific parameters or return values are defined, implying successful disconnection or an error is thrown.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync disconnect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Defining QueryResult Interface in TypeScript\nDESCRIPTION: This interface outlines the structure for query results, including ID, score, metadata, and an optional vector property. The vector is only included if includeVector is true.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/qdrant.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Setting the OpenAI API Key via Environment Variable\nDESCRIPTION: This command sets the OpenAI API key as an environment variable. Replace 'your_api_key' with your actual OpenAI API key. This is required for authenticating with the OpenAI API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Importing dependencies in TypeScript\nDESCRIPTION: This code snippet imports the necessary dependencies for the application, including modules from the `ai`, `@mastra/pg`, and `@ai-sdk/openai` packages. These dependencies provide functionalities for embedding, vector storage with PGVector, and OpenAI integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/query/hybrid-vector-search.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed } from 'ai';\nimport { PgVector } from '@mastra/pg';\nimport { openai } from '@ai-sdk/openai';\n```\n\n----------------------------------------\n\nTITLE: Deleting Index by ID in Upstash Vector Store in TypeScript\nDESCRIPTION: The `deleteIndexById()` method facilitates the removal of an item from an index using its ID. It handles errors by logging an error message in case of a deletion failure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/upstash.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index from which to delete the item\",\n    },\n    {\n      name: \"id\",\n      type: \"string\",\n      description: \"ID of the item to delete\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Connect Method Definition\nDESCRIPTION: This code snippet defines the optional `connect` method in `MastraVoice`, used for establishing a WebSocket or WebRTC connection for communication. It initializes the connection to the voice service and must be called before using functions like `send` or `answer`. The configuration is provider-specific.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconnect(config?: unknown): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: Creating a New Mastra Project with CLI Tool\nDESCRIPTION: Command to create a new Mastra project using the create-mastra CLI tool, which quickly sets up a new application with all necessary configurations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Mastra Storage Integration Setup\nDESCRIPTION: Configuration for storing eval results in Mastra Storage. Shows how to attach listeners with storage capabilities for persistent result tracking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { beforeAll } from 'vitest';\nimport { attachListeners } from '@mastra/evals';\nimport { mastra } from './your-mastra-setup';\n\nbeforeAll(async () => {\n  // Store evals in Mastra Storage (requires storage to be enabled)\n  await attachListeners(mastra);\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command to copy the example environment file to create a local configuration file for storing API keys.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-precision/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Toxicity Metric Custom Configuration Example\nDESCRIPTION: Shows how to use the ToxicityMetric class with a custom configuration, specifically setting the scale to 10.  It then measures the toxicity of a different input and output pair and implicitly uses the default OpenAI model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/toxicity.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\n\nconst model = openai(\"gpt-4o-mini\");\n\nconst metric = new ToxicityMetric(model, {\n  scale: 10, // Use 0-10 scale instead of 0-1\n});\n\nconst result = await metric.measure(\n  \"What do you think about the new team member?\",\n  \"The new team member shows promise but needs significant improvement in basic skills.\",\n);\n```\n\n----------------------------------------\n\nTITLE: Importing ContentSimilarityMetric from Mastra\nDESCRIPTION: Demonstrates how to import the ContentSimilarityMetric class from the @mastra/evals/nlp package, which is required for text similarity evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with NetlifyDeployer\nDESCRIPTION: Example of how to import and initialize the NetlifyDeployer class with configuration options and integrate it with the Mastra framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/netlify/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { NetlifyDeployer } from '@mastra/deployer-netlify';\n\nconst deployer = new NetlifyDeployer({\n  scope: 'your-team-id',\n  projectName: 'your-project-name',\n  token: 'your-netlify-token',\n});\n\nconst mastra = new Mastra({\n  deployer,\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Document Chunks with createDocumentChunkerTool in TypeScript\nDESCRIPTION: This snippet demonstrates the basic usage of `createDocumentChunkerTool()` to split a document into smaller chunks using the recursive strategy.  It imports the necessary modules from `@mastra/rag`, creates an `MDocument` instance, configures the chunking parameters, executes the chunker, and extracts the resulting chunks.  Dependencies: `@mastra/rag`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/document-chunker-tool.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createDocumentChunkerTool, MDocument } from \"@mastra/rag\";\n\nconst document = new MDocument({\n  text: \"Your document content here...\",\n  metadata: { source: \"user-manual\" }\n});\n\nconst chunker = createDocumentChunkerTool({\n  doc: document,\n  params: {\n    strategy: \"recursive\",\n    size: 512,\n    overlap: 50,\n    separator: \"\\n\"\n  }\n});\n\nconst { chunks } = await chunker.execute();\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP with Smithery.ai on Windows in TypeScript\nDESCRIPTION: This TypeScript code configures the MCP to use Smithery.ai's sequential thinking server on Windows systems. It uses `cmd /c` to execute the Smithery CLI.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// Windows\nconst mcp = new MCPConfiguration({\n  servers: {\n    sequentialThinking: {\n      command: \"cmd\",\n      args: [\n        \"/c\",\n        \"npx\",\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@smithery-ai/server-sequential-thinking\",\n        \"--config\",\n        \"{}\",\n      ],\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Mapping Weather Codes to Conditions\nDESCRIPTION: Defines a function to map weather codes to human-readable conditions in Japanese.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"晴天\",\n    1: \"主に晴れ\",\n    2: \"部分的に曇り\",\n    3: \"曇り\",\n    45: \"霧\",\n    48: \"霧氷の霧\",\n    51: \"小雨\",\n    53: \"適度な霧雨\",\n    55: \"濃い霧雨\",\n    61: \"小雨\",\n    63: \"適度な雨\",\n    65: \"大雨\",\n    71: \"小雪\",\n    73: \"適度な降雪\",\n    75: \"大雪\",\n    95: \"雷雨\",\n  };\n  return conditions[code] || \"不明\";\n}\n```\n\n----------------------------------------\n\nTITLE: Single Dependency with .after() in Mastra Workflow\nDESCRIPTION: This example illustrates a workflow where `logData` is executed after `fetchData` completes. The `.after()` method ensures that `logData` is executed in a separate branch after `fetchData` is finished, possibly allowing other operations to continue concurrently.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/after.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(fetchData)\n  .then(processData)\n  .after(fetchData)  // fetchDataの後に分岐\n  .step(logData);\n```\n\n----------------------------------------\n\nTITLE: Implementing Context Analysis Step\nDESCRIPTION: Defines the first step in the workflow for analyzing the context of the query using the RAG agent.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst analyzeContext = new Step({\n  id: \"analyzeContext\",\n  outputSchema: z.object({\n    initialAnalysis: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const query = context?.getStepResult<{ query: string }>(\n      \"trigger\",\n    )?.query;\n\n    const analysisPrompt = `${query} 1. First, carefully analyze the retrieved context chunks and identify key information.`;\n\n    const analysis = await ragAgent?.generate(analysisPrompt);\n    console.log(analysis?.text);\n    return {\n      initialAnalysis: analysis?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing QdrantVector Store in TypeScript\nDESCRIPTION: Demonstrates how to initialize a Qdrant vector store with URL and API key, create an index with specific dimensions, and upsert vectors with metadata.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { QdrantVector } from '@mastra/qdrant'\n\nconst store = new QdrantVector({\n  url: process.env.QDRANT_URL,\n  apiKey: process.env.QDRANT_API_KEY\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing an Agent with Memory\nDESCRIPTION: Code example showing how to create a Memory instance and integrate it with a Mastra agent. This setup enables the agent to maintain conversation history and context across interactions.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/agent-memory.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from \"@mastra/core/agent\";\nimport { Memory } from \"@mastra/memory\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Basic memory setup\nconst memory = new Memory();\n\nconst agent = new Agent({\n  name: \"MyMemoryAgent\",\n  instructions: \"You are a helpful assistant with memory.\",\n  model: openai(\"gpt-4o\"),\n  memory: memory, // Attach the memory instance\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This code snippet sets up the necessary environment variables for accessing the OpenAI API.  It requires an OpenAI API key to be set in the `.env` file. This key will be used to authenticate requests made to the OpenAI service for evaluating contextual recall.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/contextual-recall.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra Repository and Navigating to Example Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the JSON chunking example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-json/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/chunk-json\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Summarization Metric\nDESCRIPTION: Imports the necessary modules from `@ai-sdk/openai` and `@mastra/evals/llm`.  This includes the `openai` function for creating an OpenAI client and the `SummarizationMetric` class for evaluating summaries.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/summarization.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { SummarizationMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/voice-openai with npm\nDESCRIPTION: This command installs the @mastra/voice-openai package as a dependency for your project. This will allow you to use the OpenAI Voice integration for Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-openai\n```\n\n----------------------------------------\n\nTITLE: Listing Available Voices with AzureVoice\nDESCRIPTION: This snippet shows how to retrieve a list of available voices using the AzureVoice instance. It uses the getSpeakers method, which returns a promise that resolves with the voices.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/azure/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst voices = await voice.getSpeakers();\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Data in a Mastra Step (TypeScript)\nDESCRIPTION: This snippet illustrates how to access event data within a step's execution context in a Mastra workflow. The event data is available as `context.inputData.resumedEvent`. This allows workflow steps to process data provided when the workflow is resumed with an event.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst processApprovalStep = new Step({\n  id: 'processApproval',\n  execute: async ({ context }) => {\n    // イベントデータにアクセス\n    const eventData = context.inputData.resumedEvent;\n\n    return {\n      processingResult: `Processed approval from ${eventData.approverName}`,\n      wasApproved: eventData.approved,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Configuration for Braintrust\nDESCRIPTION: This snippet shows the required environment variables for integrating Braintrust with Mastra using OTLP. It specifies the OTLP endpoint and necessary headers, including the API key and project ID for authentication and association.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/braintrust.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=https://api.braintrust.dev/otel\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer <Your API Key>, x-bt-parent=project_id:<Your Project ID>\"\n```\n\n----------------------------------------\n\nTITLE: Instantiating PgVector and Mastra\nDESCRIPTION: This code instantiates PgVector for PostgreSQL vector storage and Mastra, configuring it with the RAG agent and the PgVector instance. This setup allows Mastra to manage agents and vector stores, enabling the RAG functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/rerank/rerank-rag.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Voice with API Key - TypeScript\nDESCRIPTION: This snippet demonstrates initializing the OpenAIVoice provider in Mastra with a specific model name and API key for authentication. It shows how to provide the necessary parameters within the `listeningModel` configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-text.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst voice = new OpenAIVoice({\n  listeningModel: {\n    name: \"whisper-1\",\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Document from Text - TypeScript\nDESCRIPTION: This static method `fromText` instantiates an MDocument from a given plain text string, with optional metadata. It requires TypeScript and Mastra library dependency. The method accepts `text` and an optional `metadata` parameter to represent the document content.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromText(text: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Update cjs bundling\nDESCRIPTION: This patch updates the cjs bundling to ensure that files are properly split during the bundling process. This improvement likely addresses issues related to code organization, module resolution, or performance optimization within the CommonJS environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nfd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Error Handling: .if() requires a preceding step in TypeScript\nDESCRIPTION: This snippet demonstrates the error handling when the `if` method is used without a preceding step.  It shows how to catch the error and log the error message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/if.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  // This will throw an error\n  workflow\n    .if(async ({ context }) => true)\n    .then(someStep)\n    .commit();\n} catch (error) {\n  console.error(error); // \"Condition requires a step to be executed after\"\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory with LibSQL Defaults in TypeScript\nDESCRIPTION: This snippet shows how to initialize Mastra's memory system using LibSQL as the default storage and vector database backend without any configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/memory/memory-with-libsql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from '@mastra/memory';\nimport { Agent } from '@mastra/core/agent';\n\n// Initialize memory with LibSQL defaults\nconst memory = new Memory();\n\nconst memoryAgent = new Agent({\n  name: \"Memory Agent\",\n  instructions:\n    \"You are an AI agent with the ability to automatically recall memories from previous interactions.\",\n  model: openai('gpt-4o-mini'),\n  memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving available voices using GoogleVoice\nDESCRIPTION: This code snippet shows how to use the getSpeakers() method of the GoogleVoice class to retrieve a list of available voices for a specific language. It takes the language code as an option and returns an array of voice objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/google.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Get available voices for a specific language\nconst voices = await voice.getSpeakers({ languageCode: 'en-US' });\n```\n\n----------------------------------------\n\nTITLE: Customizing Document Chunk Size with Mastra RAG\nDESCRIPTION: Shows how to create document chunks with a custom size using MDocument from Mastra's RAG package. The example demonstrates setting a 512 character chunk size instead of the default 1024 characters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/adjust-chunk-size.mdx#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  size: 512,\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables\nDESCRIPTION: This code snippet sets up the environment variables required for the application. It includes the OpenAI API key and the PostgreSQL connection string. These variables are necessary for authenticating with OpenAI and connecting to the PostgreSQL database.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Pinecone Index Stats Interface (TypeScript)\nDESCRIPTION: Defines the structure of the object returned by `describeIndex()` method. It includes the dimension of the vectors in the index, the number of vectors stored, and the distance metric used for similarity search.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/pinecone.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: MCPClient connect() Method\nDESCRIPTION: Establishes a connection with the configured MCP server.  This method is asynchronous and returns a Promise that resolves when the connection is successfully established. No specific parameters or return values are defined, implying successful connection or an error is thrown.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nasync connect(): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: 音声からテキストへの変換（Google）\nDESCRIPTION: Googleを使用して、音声ファイルからテキストへの変換を行います。Agentオブジェクトを作成し、GoogleVoiceプロバイダーを使用して、音声ファイルを文字起こしします。変換されたテキストはコンソールに出力されます。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { GoogleVoice } from \"@mastra/voice-google\";\nimport { createReadStream } from 'fs';\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new GoogleVoice(),\n});\n\n// Use an audio file from a URL\nconst audioStream = await createReadStream(\"./how_can_i_help_you.mp3\");\n\n// Convert audio to text\nconst transcript = await voiceAgent.voice.listen(audioStream);\nconsole.log(`User said: ${transcript}`);\n\n// Generate a response based on the transcript\nconst { text } = await voiceAgent.generate(transcript);\n```\n\n----------------------------------------\n\nTITLE: Setting OTLP Endpoint and Headers via Environment Variables (.env)\nDESCRIPTION: This code snippet demonstrates how to configure the OTLP endpoint and headers using environment variables.  `OTEL_EXPORTER_OTLP_ENDPOINT` specifies the URL for the OTLP collector, and `OTEL_EXPORTER_OTLP_HEADERS` allows setting custom headers (e.g., API keys) for authentication. This allows for dynamic configuration of telemetry settings without modifying the code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/tracing.mdx#_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\nOTEL_EXPORTER_OTLP_HEADERS=x-api-key=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Installing MCP Package using npm\nDESCRIPTION: This command installs the @mastra/mcp package using npm, ensuring you have the latest version of the Mastra MCP integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/mcp@latest\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the workflow-with-branching-paths example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-branching-paths/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/workflow-with-branching-paths\n```\n\n----------------------------------------\n\nTITLE: Query Result Type (TypeScript)\nDESCRIPTION: Defines the structure of the query result, including the ID, score, metadata, document (if stored), and vector (if requested).  Used when querying the Chroma Vector Store.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chroma.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  document?: string; // Chroma-specific: Original document if it was stored\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Registering Event Listener for Errors\nDESCRIPTION: This example demonstrates how to register an event listener for the 'error' event on a voice provider. The callback function receives an object containing the error message, code, and details, which are then logged to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.on.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Register event listener for errors\nvoice.on(\"error\", ({ message, code, details }) => {\n  console.error(`Error ${code}: ${message}`, details);\n});\n```\n\n----------------------------------------\n\nTITLE: Enable Instrumentation Hook in Next.js\nDESCRIPTION: This snippet configures the Next.js application to enable the instrumentation hook, which is necessary for OpenTelemetry tracing.  This is done in the next.config.ts file. Note that instrumentationHook is not needed in Next.js 15+.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/observability/nextjs-tracing.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { NextConfig } from \"next\";\n\nconst nextConfig: NextConfig = {\n  experimental: {\n    instrumentationHook: true // Next.js 15+ では不要\n  }\n};\n\nexport default nextConfig;\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for RAG System\nDESCRIPTION: Import statements for required libraries including Mastra core, OpenAI, and vector storage components.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createVectorQueryTool, createDocumentChunkerTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Test Assistant with cURL (Bash)\nDESCRIPTION: Tests the research assistant API endpoint using cURL. The code sends a POST request to the specified URL with a JSON payload containing a user message.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:4111/api/agents/researchAgent/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"What were the main findings about model parallelization?\" }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Update CJS Bundling\nDESCRIPTION: Updates the CommonJS (CJS) bundling process to ensure proper file splitting. This optimization likely improves module loading and reduces bundle sizes for projects using the Mastra package in a CJS environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/CHANGELOG.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n- fd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Simple Path Comparison Condition in Mastra Workflow (Typescript)\nDESCRIPTION: This snippet demonstrates how to define a simple path comparison as a step condition. It directly checks if the value at the path 'auth.status' is equal to 'authenticated'. This is a concise way to define conditions based on simple equality checks.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-condition.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.step(processOrder, {\n  when: {\n    \"auth.status\": \"authenticated\"\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Workflow Run Creation\nDESCRIPTION: Shows how to implement error handling when creating and starting a workflow run, including handling of validation errors like circular dependencies, no terminal paths, or unreachable steps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/createRun.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  const { runId, start, watch, resume, resumeWithEvent } = workflow.createRun();\n  await start({ triggerData: data });\n} catch (error) {\n  if (error instanceof ValidationError) {\n    // Handle validation errors\n    console.log(error.type); // 'circular_dependency' | 'no_terminal_path' | 'unreachable_step'\n    console.log(error.details);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Error Handling (TypeScript)\nDESCRIPTION: Demonstrates how to handle errors thrown by the Chroma Vector Store, specifically catching `VectorStoreError` and accessing its code and details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chroma.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Import and Configure GitHub Integration\nDESCRIPTION: Imports the GithubIntegration class from the @mastra/github package and configures it with a personal access token from environment variables. This integration can then be used to interact with the GitHub API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/integrations/index.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubIntegration } from \"@mastra/github\";\n\nexport const github = new GithubIntegration({\n  config: {\n    PERSONAL_ACCESS_TOKEN: process.env.GITHUB_PAT!,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Query Result Type in TypeScript\nDESCRIPTION: Defines the structure of the QueryResult object, which represents the result of a query against a Qdrant index.  It includes the ID of the matched vector, its score, associated metadata, and optionally the vector itself.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/qdrant.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Running Interview Agent Demo\nDESCRIPTION: Command to launch the interactive content filtering demo with forgetful processor.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm run interview\n```\n\n----------------------------------------\n\nTITLE: Evaluate Minimal Coverage with CompletenessMetric\nDESCRIPTION: Demonstrates evaluating a text that covers very few elements of the reference.  It defines a reference and text, then measures the completeness score using the CompletenessMetric.  The resulting score will be low, and missing elements are reported.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/completeness.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst text3 = 'The seasons include summer.';\nconst reference3 = 'The four seasons are spring, summer, fall, and winter.';\n\nconsole.log('Example 3 - Minimal Coverage:');\nconsole.log('Text:', text3);\nconsole.log('Reference:', reference3);\n\nconst result3 = await metric.measure(reference3, text3);\nconsole.log('Metric Result:', {\n  score: result3.score,\n  info: {\n    missingElements: result3.info.missingElements,\n    elementCounts: result3.info.elementCounts,\n  },\n});\n// Example Output:\n// Metric Result: {\n//   score: 0.3333333333333333,\n//   info: {\n//     missingElements: [ 'four', 'spring', 'winter', 'be', 'fall', 'and' ],\n//     elementCounts: { input: 9, output: 4 }\n//   }\n// }\n```\n\n----------------------------------------\n\nTITLE: Installing Platform-Specific Deployers with NPM\nDESCRIPTION: NPM commands to install deployer packages for Cloudflare, Vercel, and Netlify platforms.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# For Cloudflare\nnpm install @mastra/deployer-cloudflare\n\n# For Vercel\nnpm install @mastra/deployer-vercel\n\n# For Netlify\nnpm install @mastra/deployer-netlify\n```\n\n----------------------------------------\n\nTITLE: CommonJS Support Addition\nDESCRIPTION: Adds support for CommonJS (CJS) modules. This enhancement allows the package to be seamlessly integrated into projects that rely on the CJS module system, increasing its compatibility with various JavaScript environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/CHANGELOG.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n- bb4f447: Add support for commonjs\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project (pnpm)\nDESCRIPTION: This command uses pnpm to create a new Mastra project, scaffolding the necessary files and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Request Logging Middleware Example\nDESCRIPTION: Example of request logging middleware with duration tracking.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/server.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  handler: async (c, next) => {\n    const start = Date.now();\n    await next();\n    const duration = Date.now() - start;\n    console.log(`${c.req.method} ${c.req.url} - ${duration}ms`);\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing IBMTTS with Configuration in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize an instance of IBMTTS using configurations, including default voice settings. It shows the structure of the configuration object required for instantiation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { IBMTTS } from '@mastra/speech-ibm';\n\n// Initialize with configuration\nconst tts = new IBMTTS({\n  model: {\n    name: 'en-US_AllisonV3Voice', // Default voice\n    apiKey: 'your-api-key', // Optional, can use IBM_API_KEY env var\n    url: 'your-service-url', // Optional, can use IBM_URL env var\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Prompts with Clear Intentions in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a prompt with a clear and specific intention using the `createPrompt` function. Vague instructions are replaced with precise goals to guide the task execution effectively.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// ❌ Vague intent\ncreatePrompt('fix this');\n\n// ✅ Clear intent\ncreatePrompt('Add type checking to this function');\n```\n\n----------------------------------------\n\nTITLE: Workflow.else() Error Handling in TypeScript\nDESCRIPTION: This code snippet demonstrates the error handling of the `.else()` method.  An error is thrown if `.else()` is used without a preceding `.if()` statement. The expected error message is \"No active condition found\".\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/else.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  // これはエラーをスローします\n  workflow\n    .step(someStep)\n    .else()\n    .then(anotherStep)\n    .commit();\n} catch (error) {\n  console.error(error); // \"No active condition found\"\n}\n```\n\n----------------------------------------\n\nTITLE: Move Chroma Package and Reorganize Source Files (Minor)\nDESCRIPTION: This change moves the Chroma package from `@mastra/vector-chroma` to `@mastra/chroma`, reorganizing source files into `src/vector`. It adds a deprecation notice to the old package and updates documentation and examples, without breaking functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_9\n\n\n\n----------------------------------------\n\nTITLE: Defining Instruction Prompt (TypeScript)\nDESCRIPTION: Defines the instruction prompt for the LLM, setting its role as a Master Chef specializing in identifying gluten in recipes. This prompt provides context and guidance for the LLM's evaluation task.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const GLUTEN_INSTRUCTIONS = `You are a Master Chef that identifies if recipes contain gluten.`;\n```\n\n----------------------------------------\n\nTITLE: Start Development Server with npm\nDESCRIPTION: This command starts the development server for the Mastra project using npm. This is necessary to run the application and test the memory agent in the playground. The copy button allows easy execution in the terminal.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/overview.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables for OpenAI API Key\nDESCRIPTION: This bash snippet demonstrates how to set the OpenAI API key as an environment variable, which is required to authenticate with the OpenAI service. This is a prerequisite for using the ContextPrecisionMetric with the OpenAI language model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-precision.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Importing necessary dependencies\nDESCRIPTION: This TypeScript snippet imports the required dependencies from the `@ai-sdk/openai` and `@mastra/evals/llm` libraries. These dependencies are necessary to initialize the OpenAI language model and the ContextPrecisionMetric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-precision.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { ContextPrecisionMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Fix build errors by changing contracts\nDESCRIPTION: This patch addresses build errors by modifying contracts within the project. This likely involves updating or correcting interface definitions, data structures, or function signatures to resolve compatibility issues during compilation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n5297264: Fix build errors by changing contracts\n```\n\n----------------------------------------\n\nTITLE: Getting a Vector Store Instance in Typescript\nDESCRIPTION: This code snippet demonstrates how to obtain an instance of the vector store using the `client.getVector` method.  The `vector-name` argument is a placeholder for the desired vector store name.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/vectors.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst vector = client.getVector(\"vector-name\");\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra repository\nDESCRIPTION: Clones the Mastra repository from GitHub and navigates to the 'calling-agent-from-workflow' directory in the examples.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/calling-agent-from-workflow/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/calling-agent-from-workflow\n```\n\n----------------------------------------\n\nTITLE: Changelog Entry in Markdown\nDESCRIPTION: A markdown changelog entry showing version history and dependency updates across multiple alpha versions, focused on changes to @mastra/core dependency\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/quick-start/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# quick-start\n\n## 0.0.1\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/core@0.2.0-alpha.85\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- Updated dependencies [2f17a5f]\n- Updated dependencies [cb290ee]\n- Updated dependencies [b4d7416]\n- Updated dependencies [38b7f66]\n  - @mastra/core@0.2.0-alpha.84\n```\n\n----------------------------------------\n\nTITLE: Running the Text Embedding Example\nDESCRIPTION: Command to execute the text chunk embedding example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: MCP Server Configuration (MacOS/Linux) - JSON\nDESCRIPTION: This JSON snippet configures the Mastra MCP server in Cursor or Windsurf on MacOS and Linux systems. It specifies the command to execute and the arguments to pass to the command.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/mcp-docs-server.mdx#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Tool Call Filter Usage in Mastra\nDESCRIPTION: This snippet shows how to use the `ToolCallFilter` processor to remove tool calls from memory messages before sending them to the LLM.  It provides examples of removing all tool calls or excluding specific tool calls/results based on their names. The `TokenLimiter` should be placed last in the processors array for accurate token limiting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/memory/memory-processors.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/memory\";\nimport { ToolCallFilter, TokenLimiter } from \"@mastra/memory/processors\";\n\nconst memoryFilteringTools = new Memory({\n  processors: [\n    // Example 1: Remove all tool calls/results\n    new ToolCallFilter(),\n\n    // Example 2: Remove only noisy image generation tool calls/results\n    new ToolCallFilter({ exclude: [\"generateImageTool\"] }),\n\n    // Always place TokenLimiter last\n    new TokenLimiter(127000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Running Dane's Main Application and Features\nDESCRIPTION: Commands to run Dane's main application and specific features like the issue labeler. These demonstrate the basic usage patterns for interacting with Dane.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/dane/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Run the main application\ndane\n\n# Run the issue labeler\ndane issue-labeler\n```\n\n----------------------------------------\n\nTITLE: Helper Functions for Audio Processing (TypeScript)\nDESCRIPTION: This code snippet includes two helper functions: `saveAudioToFile` and `convertToText`. `saveAudioToFile` saves an audio stream to a file using `createWriteStream` from the `fs` module. `convertToText` converts either a string or a readable stream to text, handling stream data and errors. The functions use Promises for asynchronous operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/adding-voice-capabilities.mdx#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * 音声ストリームをファイルに保存\n */\nasync function saveAudioToFile(audio: NodeJS.ReadableStream, filename: string): Promise<void> {\n  const filePath = path.join(process.cwd(), filename);\n  const writer = createWriteStream(filePath);\n  audio.pipe(writer);\n  return new Promise<void>((resolve, reject) => {\n    writer.on('finish', resolve);\n    writer.on('error', reject);\n  });\n}\n\n/**\n * 文字列またはリーダブルストリームをテキストに変換\n */\nasync function convertToText(input: string | NodeJS.ReadableStream): Promise<string> {\n  if (typeof input === 'string') {\n    return input;\n  }\n\n  const chunks: Buffer[] = [];\n  return new Promise<string>((resolve, reject) => {\n    input.on('data', chunk => chunks.push(Buffer.from(chunk)));\n    input.on('error', err => reject(err));\n    input.on('end', () => resolve(Buffer.concat(chunks).toString('utf-8')));\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Resources from MCP Server in TypeScript\nDESCRIPTION: The resources method fetches a list of available resources from the MCP server asynchronously, returning a promise of ListResourcesResult. It does not require any input parameters. Ensure the server connection is active before calling this method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync resources(): Promise<ListResourcesResult>\n```\n\n----------------------------------------\n\nTITLE: Initializing a Console Logger in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a console logger using `createLogger()` with a specified name and log level.  It logs an informational message to the console. Requires the `createLogger` function to be defined.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/create-logger.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst consoleLogger = createLogger({ name: \"Mastra\", level: \"debug\" });\nconsoleLogger.info(\"App started\");\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text using PlayAI\nDESCRIPTION: This snippet illustrates how to convert a string of text into speech using the PlayAIVoice.speak method. It shows the functionality to both generate speech from text and handle it as a readable stream.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await voice.speak('Hello from Mastra!');\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst textStream = getTextStream(); // Your text stream source\nconst audioStream = await voice.speak(textStream);\n```\n\n----------------------------------------\n\nTITLE: Configuring Embedding Dimensions with OpenAI\nDESCRIPTION: Shows how to configure the embedding dimensions when using the OpenAI embedding model. This example reduces the dimensionality to 256 for storage optimization.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst { embeddings } = await embedMany({\n  model: openai.embedding('text-embedding-3-small', {\n    dimensions: 256  // text-embedding-3以降でのみサポート\n  }),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: MCPClient tools() Method\nDESCRIPTION: Fetches available tools from the server and transforms them into a format compatible with Mastra. Returns a Promise that resolves to a record mapping tool names to Mastra Tool implementations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/client.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync tools(): Promise<Record<string, Tool>>\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in .env File (Bash)\nDESCRIPTION: This snippet shows how to set the OpenAI API key as an environment variable in a `.env` file. This API key is required for accessing the OpenAI language models used in the evaluation process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/custom-eval.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Configuring TokenLimiter with Custom Encoding\nDESCRIPTION: Demonstrates how to configure TokenLimiter with a custom encoding for different models, specifically showing setup for a 16k context model.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Import the encoding you need (e.g., for older OpenAI models)\nimport cl100k_base from \"js-tiktoken/ranks/cl100k_base\";\n\nconst memoryForOlderModel = new Memory({\n  processors: [\n    new TokenLimiter({\n      limit: 16000, // Example limit for a 16k context model\n      encoding: cl100k_base,\n    }),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example environment variable configuration needed for the application. It includes API keys for Unsplash and Anthropic, along with an optional port setting.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\n# Required for getting image\nUNSPLASH_ACCESS_KEY=your_unsplash_access_key\n\n# Required for AI processing\nANTHROPIC_API_KEY=your_anthropic_key\n\n# The port you want your server to run on (optional)\nPORT=your_preferred_port\n```\n\n----------------------------------------\n\nTITLE: Creating GraphRAG Tool with Vector Database Configuration\nDESCRIPTION: Initializes a GraphRAG tool using createGraphRAGTool function, configuring vector storage, embedding model, and graph options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphRagTool = createGraphRAGTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.7,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing ReplicateTTS in TypeScript\nDESCRIPTION: This TypeScript snippet initializes the ReplicateTTS class with model configuration, allowing the user to specify a model name and optional API token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ReplicateTTS } from '@mastra/speech-replicate';\n\n// Initialize with configuration\nconst tts = new ReplicateTTS({\n  model: {\n    name: 'default', // Default model\n    apiToken: 'your-api-token', // Optional, can use REPLICATE_API_TOKEN env var\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Providing Advanced Usage Examples in Markdown and TypeScript\nDESCRIPTION: Demonstrates how to include advanced examples with code snippets that reference relevant files to provide additional clarity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n## Additional Examples\n\nFor a more advanced usage, see \"transformDataSync\" in the following file:\n\n```ts filename=\"src/examples/advancedUsage/transformDataSync.ts\"\nimport { MyFunction } from \"@mastra/core\";\n\nexport async function transformDataSync(data: string) {\n  const result = await MyFunction({\n    data,\n    options: { verbose: false },\n  });\n  return result;\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Bird Checker\nDESCRIPTION: This snippet shows the required environment variables for the application, including API keys for Unsplash, Anthropic, and Braintrust.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs-and-eval/README.md#2025-04-22_snippet_1\n\nLANGUAGE: env\nCODE:\n```\n# Required for getting image\nNEXT_PUBLIC_UNSPLASH_ACCESS_KEY=your_unsplash_access_key\n\n# Required for AI processing\nANTHROPIC_API_KEY=your_anthropic_key\n\n# Required for evalutating the llm prompt\nBRAINTRUST_API_KEY=your_braintrust_key\n```\n\n----------------------------------------\n\nTITLE: Describe Index Response Type (TypeScript)\nDESCRIPTION: Defines the structure of the response returned by the `describeIndex` method, providing information about the index such as dimension, count, and distance metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chroma.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Directory\nDESCRIPTION: Commands to clone the repository and navigate to the specific example directory for the workflow with cyclical dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-cyclical-deps/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/workflow-with-cyclical-deps\n```\n\n----------------------------------------\n\nTITLE: Running Mastra CLI Initialization Command\nDESCRIPTION: The 'mastra init' command is an interactive CLI tool that helps set up a new Mastra project. It allows users to specify directories, select components, choose an LLM provider, and include example code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/project-structure.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmastra init\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra using pnpm\nDESCRIPTION: Command to create a new Mastra project using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm create mastra\n```\n\n----------------------------------------\n\nTITLE: Initializing CloudflareStore with Workers Binding API (TypeScript)\nDESCRIPTION: Initializes the CloudflareStore using the Workers Binding API, suitable for Cloudflare Worker environments. It requires KV namespaces to be bound and allows for an optional key prefix.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\nimport { CloudflareStore } from '@mastra/cloudflare';\n\n// Using Workers Binding API\nconst store = new CloudflareStore({\n  bindings: {\n    threads: THREADS_KV_NAMESPACE,\n    messages: MESSAGES_KV_NAMESPACE,\n    workflow_snapshot: WORKFLOW_KV_NAMESPACE,\n    evals: EVALS_KV_NAMESPACE,\n    traces: TRACES_KV_NAMESPACE,\n  },\n  keyPrefix: 'myapp_', // Optional\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/qdrant Package with pnpm\nDESCRIPTION: The snippet installs the @mastra/qdrant package using the pnpm package manager. The package is necessary for utilizing the Qdrant vector store functionality described in the documentation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/qdrant\n```\n\n----------------------------------------\n\nTITLE: Content Similarity Basic Usage\nDESCRIPTION: Demonstrates the basic usage of the ContentSimilarityMetric to measure the similarity between two strings, ignoring case and whitespace differences.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/content-similarity.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ContentSimilarityMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new ContentSimilarityMetric({\n  ignoreCase: true,\n  ignoreWhitespace: true\n});\n\nconst result = await metric.measure(\n  \"Hello, world!\",\n  \"hello world\"\n);\n\nconsole.log(result.score); // 0から1までの類似度スコア\nconsole.log(result.info); // 詳細な類似度メトリクス\n```\n\n----------------------------------------\n\nTITLE: Implementing Thread Management UI in React\nDESCRIPTION: A conceptual React component for managing conversation threads, allowing users to list, select, and create new threads. This component works alongside the Chat component that uses the useChat hook.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/use-chat.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Conceptual React component for a thread list\nimport React, { useState, useEffect } from 'react';\n\n// Assume API functions exist: fetchThreads, createNewThread\nasync function fetchThreads(userId: string): Promise<{ id: string; title: string }[]> { /* ... */ }\nasync function createNewThread(userId: string): Promise<{ id: string; title: string }> { /* ... */ }\n\nfunction ThreadList({ userId, currentThreadId, onSelectThread }) {\n  const [threads, setThreads] = useState([]);\n  // ... loading and error states ...\n\n  useEffect(() => {\n    // Fetch threads for userId\n  }, [userId]);\n\n  const handleCreateThread = async () => {\n    // Call createNewThread API, update state, select new thread\n  };\n\n  // ... render UI with list of threads and New Conversation button ...\n  return (\n     <div>\n       <h2>Conversations</h2>\n       <button onClick={handleCreateThread}>New Conversation</button>\n       <ul>\n         {threads.map(thread => (\n           <li key={thread.id}>\n             <button onClick={() => onSelectThread(thread.id)} disabled={thread.id === currentThreadId}>\n               {thread.title || `Chat ${thread.id.substring(0, 8)}...`}\n             </button>\n           </li>\n         ))}\n       </ul>\n     </div>\n  );\n}\n\n// Example Usage in a Parent Chat Component\nfunction ChatApp() {\n  const userId = \"user_123\";\n  const [currentThreadId, setCurrentThreadId] = useState<string | null>(null);\n\n  return (\n    <div style={{ display: 'flex' }}>\n      <ThreadList\n        userId={userId}\n        currentThreadId={currentThreadId}\n        onSelectThread={setCurrentThreadId}\n      />\n      <div style={{ flexGrow: 1 }}>\n        {currentThreadId ? (\n          <Chat threadId={currentThreadId} resourceId={userId} /> // Your useChat component\n        ) : (\n          <div>Select or start a conversation.</div>\n        )}\n      </div>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: TTS with Murf Voice Agent\nDESCRIPTION: This code demonstrates how to use an Agent with Murf voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Murf's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { MurfVoice } from \"@mastra/voice-murf\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new MurfVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"default\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: afterEvent() Syntax - Typescript\nDESCRIPTION: Shows the syntax for using the `afterEvent()` method in a Mastra workflow.  The method takes a string `eventName` as input, which corresponds to an event defined in the workflow's `events` configuration. It returns the workflow instance for method chaining.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/afterEvent.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow.afterEvent(eventName: string): Workflow\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text in TypeScript\nDESCRIPTION: In this TypeScript snippet, speech is generated from the provided text 'Hello from Mastra!' using the specified voice. It shows how to call the generate method on the IBMTTS instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await tts.generate({\n  voice: 'en-US_AllisonV3Voice',\n  text: 'Hello from Mastra!',\n});\n```\n\n----------------------------------------\n\nTITLE: Setting LangWatch Environment Variables\nDESCRIPTION: This snippet demonstrates how to set the environment variables required for LangWatch integration with Mastra.  It requires `LANGWATCH_API_KEY` and `LANGWATCH_PROJECT_ID` to be configured with the appropriate values.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langwatch.mdx#_snippet_0\n\nLANGUAGE: env\nCODE:\n```\nLANGWATCH_API_KEY=your_api_key\nLANGWATCH_PROJECT_ID=your_project_id\n```\n\n----------------------------------------\n\nTITLE: Response Types in ChromaVector\nDESCRIPTION: Defines the structure of the query result, including fields for ID, score, metadata, and optionally the original document and vector.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chroma.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript copy\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  document?: string; // Chroma-specific: Original document if it was stored\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Saving a thread using CloudflareStore (TypeScript)\nDESCRIPTION: Saves a thread to the Cloudflare KV store using the saveThread method.  The thread object includes an ID, resource ID, title, metadata, and timestamps.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n// Save a thread\nawait store.saveThread({\n  id: 'thread-123',\n  resourceId: 'resource-456',\n  title: 'My Thread',\n  metadata: { key: 'value' },\n  createdAt: new Date(),\n  updatedAt: new Date(),\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Importing Reference Cards - React - JavaScript\nDESCRIPTION: This code snippet demonstrates how to import the ReferenceCards component from the specified path within a React application. The component is essential for rendering the documentation related to Mastra's API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/index.mdx#2025-04-22_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { ReferenceCards } from \"@/components/reference-cards\";\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables\nDESCRIPTION: This snippet sets up the environment variables needed to run the example code. It defines the OPENAI_API_KEY variable which will be used to authenticate with the OpenAI API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/faithfulness.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Update Chroma Vector to Allow Document Storage (Patch)\nDESCRIPTION: This patch enhances the Chroma vector store integration to allow for document storage. This expands the functionality of the Chroma integration by enabling the storage and retrieval of associated documents along with vector embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_7\n\n\n\n----------------------------------------\n\nTITLE: Workflow Execution with Run ID (TypeScript)\nDESCRIPTION: This snippet shows how to execute a workflow with a custom run ID. This is useful for tracking specific executions and associating them with external systems or processes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/execute.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst result = await workflow.execute({\n  runId: \"custom-run-id\",\n  triggerData: { inputValue: 42 }\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install project dependencies using pnpm package manager\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/tool-as-workflow-step/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Installing Sarvam Voice Module using npm\nDESCRIPTION: This code snippet demonstrates how to install the Sarvam Voice module via npm, which is necessary for using its TTS and STT capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/sarvam/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-sarvam\n```\n\n----------------------------------------\n\nTITLE: Running the Example\nDESCRIPTION: Command to start the workflow example\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/tool-as-workflow-step/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub Tool Implementation\nDESCRIPTION: Implementation of a tool that uses GitHub integration to fetch main branch reference\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from \"@mastra/core\";\nimport { z } from \"zod\";\nimport { github } from \"../integrations\";\n\nexport const getMainBranchRef = createTool({\n  id: \"getMainBranchRef\",\n  description: \"Fetch the main branch reference from a GitHub repository\",\n  inputSchema: z.object({\n    owner: z.string(),\n    repo: z.string(),\n  }),\n  outputSchema: z.object({\n    ref: z.string().optional(),\n  }),\n  execute: async ({ context }) => {\n    const client = await github.getApiClient();\n\n    const mainRef = await client.gitGetRef({\n      path: {\n        owner: context.owner,\n        repo: context.repo,\n        ref: \"heads/main\",\n      },\n    });\n\n    return { ref: mainRef.data?.ref };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up an Upstash Logger with UpstashTransport in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a logger that sends logs to Upstash Redis using `createLogger()` and `UpstashTransport`.  It requires setting environment variables for the Upstash URL and token. It logs an info message with metadata. Requires the `@mastra/loggers/upstash` module and environment variables `UPSTASH_URL` and `UPSTASH_TOKEN`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/create-logger.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashTransport } from \"@mastra/loggers/upstash\";\n\nconst logger = createLogger({\n  name: \"Mastra\",\n  transports: {\n    upstash: new UpstashTransport({\n      listName: \"production-logs\",\n      upstashUrl: process.env.UPSTASH_URL!,\n      upstashToken: process.env.UPSTASH_TOKEN!,\n    }),\n  },\n  level: \"info\",\n});\n\nlogger.info({\n  message: \"User signed in\",\n  destinationPath: \"auth\",\n  type: \"AGENT\",\n  runId: \"run_123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Metadata Extraction in TypeScript\nDESCRIPTION: This snippet shows how to import the necessary MDocument class from the @mastra/rag package for document processing and metadata extraction.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/metadata-extraction.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n```\n\n----------------------------------------\n\nTITLE: Creating a Workflow with Trigger Schema in Mastra (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to create a workflow in Mastra using the `Workflow` class.  It defines the workflow's name and specifies the structure of the trigger data using `z.object` from a validation library, indicating the expected input schema for triggering the workflow. The `name` field determines the API endpoint for the workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = new Workflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Extract Metadata (Instance Method)\nDESCRIPTION: Extracts metadata from the document using the specified extractor. Accepts ExtractParams to configure the extraction process. Returns a Promise resolving to the modified MDocument.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nasync extractMetadata(params: ExtractParams): Promise<MDocument>\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Example of how to format the .env file with the OpenAI API key for authentication. The user needs to replace the placeholder with their actual API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Listing Available Voices in TypeScript\nDESCRIPTION: This TypeScript code snippet asynchronously retrieves and lists all available voices for the IBM Watson TTS service. It demonstrates how to interact with the IBMTTS instance to fetch this data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/ibm/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst voices = await tts.voices();\n```\n\n----------------------------------------\n\nTITLE: Defining Clickhouse Configuration Type\nDESCRIPTION: This TypeScript snippet defines a type for the Clickhouse store configuration. It specifies the required fields including URL, username, and password for connecting to the Clickhouse server.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/clickhouse/README.md#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\ntype ClickhouseConfig = {\n  url: string; // Clickhouse HTTP interface URL\n  username: string; // Database username\n  password: string; // Database password\n};\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow Example\nDESCRIPTION: Command to start and execute the sequential workflow example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-sequential-steps/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Publish the MCP server to NPM\nDESCRIPTION: Publishes the compiled Mastra MCP server package to the NPM registry. This makes the server available for others to use via `npx` or as a dependency. It requires an NPM account and assumes the user is logged in.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/deploying-mcp-server.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm publish --access public\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphRAG Tool with Default Options (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to initialize the `createGraphRAGTool` with basic configurations. It imports necessary modules, configures the tool with a vector store, index, embedding model, and default graph options. The tool facilitates graph-based search over documents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/tools/graph-rag-tool.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { createGraphRAGTool } from \"@mastra/rag\";\n\nconst graphTool = createGraphRAGTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding('text-embedding-3-small'),\n  graphOptions: {\n    dimension: 1536,\n    threshold: 0.7,\n    randomWalkSteps: 100,\n    restartProb: 0.15\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Vector Query Result Interface Definition\nDESCRIPTION: Defines the TypeScript interface for query results, specifying the structure of returned data including ID, similarity score, metadata, and optional vector data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pg.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[]; // Only included if includeVector is true\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Memory Package\nDESCRIPTION: Command to install the Mastra memory package using npm or yarn, which is required before implementing memory capabilities for agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/agent-memory.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration for API and Database Access\nDESCRIPTION: Example configuration for the .env file containing the OpenAI API key and LibSQL database connection parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nDATABASE_URL=libsql://your-database-url\nDATABASE_AUTH_TOKEN=your-database-auth-token (optional)\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra in a Next.js project using npx\nDESCRIPTION: This command initializes Mastra in a Next.js project using the npx package runner. It's suitable for executing the mastra package without globally installing it. It sets up Mastra within the Next.js environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra@latest init\n```\n\n----------------------------------------\n\nTITLE: Setting MCP_RUN_SSE_URL Environment Variable\nDESCRIPTION: This bash code shows how to set the `MCP_RUN_SSE_URL` environment variable.  This is useful for externalizing the SSE URL and treating it like a password.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/mcp-guide.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nMCP_RUN_SSE_URL=https://www.mcp.run/api/mcp/sse?nonce=...\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variable for API Token\nDESCRIPTION: This snippet shows how to set the REPLICATE_API_TOKEN environment variable, which is required for authenticating requests to the Replicate API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nREPLICATE_API_TOKEN=your_api_token\n```\n\n----------------------------------------\n\nTITLE: Defining Message Interface in TypeScript\nDESCRIPTION: This snippet defines the TypeScript interface for a message object used in the `stream()` method. It specifies the structure of messages with role and content properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/stream.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Mastra Tools and Zod for Workflow Definition\nDESCRIPTION: This snippet shows the necessary imports for Mastra tools and Zod to handle workflow definitions and data validation in TypeScript.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: This snippet shows how to set the OpenAI API key as an environment variable. This is a prerequisite for using the OpenAI models within the Mastra Evals framework.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/context-position.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Retrieving System Logs with Filtering in Mastra using TypeScript\nDESCRIPTION: This snippet demonstrates how to use the getLogs method to retrieve system logs with optional filtering. It allows specifying a transportId to filter the logs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/logs.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst logs = await client.getLogs({\n  transportId: \"transport-1\",\n});\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/libsql\nDESCRIPTION: This command installs the @mastra/libsql package from npm, adding it as a project dependency.  It allows the project to utilize the vector store and general storage functionalities provided by the library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/libsql\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory - Bash\nDESCRIPTION: This snippet illustrates how to clone the mastra repository from GitHub and navigate into the agentic-workflows directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/agentic-workflows/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/agentic-workflows\n```\n\n----------------------------------------\n\nTITLE: Get Specific Memory Thread Instance (TypeScript)\nDESCRIPTION: Retrieves a specific memory thread instance using the thread ID and agent ID.  Requires a threadId and agentId.  Returns a thread object that allows further operations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/client-js/memory.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst thread = client.getMemoryThread(\"thread-id\", \"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Installing Cloudflare D1 Package with NPM\nDESCRIPTION: This command installs the `@mastra/cloudflare-d1` package using npm.  This package provides the necessary classes and functions to interact with Cloudflare D1 from a Mastra application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare-d1.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/cloudflare-d1\"\n```\n\n----------------------------------------\n\nTITLE: Introduce breaking changes\nDESCRIPTION: This commit introduces breaking changes to the project. This implies modifications that may require updates in code that depends on this package to ensure compatibility with the new version.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/CHANGELOG.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n8b416d9: Breaking changes\n```\n\n----------------------------------------\n\nTITLE: Initializing Speechify Voice Configuration\nDESCRIPTION: Speechify音声プロバイダーの初期化設定を示します。音声合成のためのモデル名、スピーカー、APIキー、言語、速度を指定します。Speechifyは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはSpeechifyの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_26\n\nLANGUAGE: typescript\nCODE:\n```\n// Speechify Voice Configuration\nconst voice = new SpeechifyVoice({\n  speechModel: {\n    name: \"speechify-voice\", // Example model name\n    speaker: \"matthew\", // Example speaker name\n    apiKey: process.env.SPEECHIFY_API_KEY,\n    language: \"en-US\", // Language code\n    speed: 1.0, // Speech speed\n  },\n  // Speechify may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This snippet demonstrates how to set the OpenAI API key as an environment variable, which is a prerequisite for using the OpenAI model for the Hallucination metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/hallucination.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra Telemetry for SigNoz with OTLP\nDESCRIPTION: This TypeScript code snippet shows how to configure Mastra to use SigNoz for telemetry. It initializes a Mastra instance and configures its `telemetry` option to enable OpenTelemetry (OTLP) export, specifying the service name and enabling telemetry.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/signoz.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Packages (NPM)\nDESCRIPTION: This snippet demonstrates how to install the necessary packages for the documentation project using npm. It uses the `npm i` command to install dependencies defined in the `package.json` file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm i\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project (yarn)\nDESCRIPTION: This command uses yarn to create a new Mastra project, scaffolding the necessary files and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Querying Messages with Context Using TypeScript\nDESCRIPTION: This snippet illustrates how to query messages from a thread with context around specific message IDs. It demonstrates how to include specific messages and fetch a defined number of previous and next messages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/query.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst { messages: contextMessages } = await memory.query({\n  threadId: \"thread-123\",\n  selectBy: {\n    include: [\n      {\n        id: \"msg-123\", // Get just this message (no context)\n      },\n      {\n        id: \"msg-456\", // Get this message with custom context\n        withPreviousMessages: 3, // 3 messages before\n        withNextMessages: 1, // 1 message after\n      },\n    ],\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Textual Difference Metric\nDESCRIPTION: Shows how to initialize and configure a new instance of the TextualDifferenceMetric class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/textual-difference.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new TextualDifferenceMetric();\n```\n\n----------------------------------------\n\nTITLE: Running the Example\nDESCRIPTION: Command to start the example application\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Registering a Workflow with Mastra (TypeScript)\nDESCRIPTION: This snippet shows how to register a defined workflow with a Mastra instance. This allows Mastra to manage the workflow, enabling logging and telemetry features.  The `workflows` property in the `Mastra` constructor accepts an object where keys are workflow names and values are the `Workflow` instances.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/overview.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  workflows: { myWorkflow },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Upstash Storage via NPM\nDESCRIPTION: This snippet provides the command to install the Upstash storage package using NPM. It is essential for integrating Upstash storage into a Mastra project, enabling serverless storage capabilities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/upstash.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/upstash\n```\n\n----------------------------------------\n\nTITLE: Updating Imports for New Package - TypeScript\nDESCRIPTION: This TypeScript snippet illustrates how to update import statements from the deprecated package to the new one. It ensures that the application is utilizing the latest features provided by @mastra/voice-openai.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/openai/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Old\nimport { OpenAITTS } from '@mastra/speech-openai';\n// New\nimport { OpenAIVoice } from '@mastra/voice-openai';\n```\n\n----------------------------------------\n\nTITLE: Import KeywordCoverageMetric in TypeScript\nDESCRIPTION: Imports the `KeywordCoverageMetric` class from the `@mastra/evals/nlp` package. This metric is used to evaluate the keyword coverage of a given text compared to a reference text.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/keyword-coverage.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { KeywordCoverageMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Running the Weather Workflow\nDESCRIPTION: Defines an asynchronous main function to run the weather workflow with a specific city (London) as the trigger data.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const { start } = mastra.getWorkflow(\"weatherWorkflow\").createRun();\n\n  const result = await start({\n    triggerData: {\n      city: \"London\",\n    },\n  });\n\n  console.log(\"\\n \\n\");\n  console.log(result);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Installing the @mastra/core package\nDESCRIPTION: This command installs the `@mastra/core` package, which includes the default vector store implementation. This package contains necessary components for vector storage and retrieval.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/libsql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/core\n```\n\n----------------------------------------\n\nTITLE: Describe Index Response Type - TypeScript\nDESCRIPTION: Defines the interface for the response returned by the `describeIndex()` method. It includes the dimension, count, and metric of the index.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/upstash.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the keyword coverage example directory. This is the first step in setting up the example project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/keyword-coverage/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/keyword-coverage\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/mcp using npm\nDESCRIPTION: This command installs the @mastra/mcp package using npm. It's an alternative to pnpm for installing the necessary MCP functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/mcp-guide.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/mcp@latest\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server\nDESCRIPTION: Command to start the Next.js development server\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-nextjs/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Workflow While Loop Usage\nDESCRIPTION: Demonstrates the basic usage of the `.while()` method within a Mastra workflow to repeat a step based on a condition.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/while.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(incrementStep)\n  .while(condition, incrementStep)\n  .then(finalStep);\n```\n\n----------------------------------------\n\nTITLE: Updating code to use PlayAIVoice\nDESCRIPTION: This diff illustrates the changes needed to update code from using `PlayAITTS` to `PlayAIVoice`. It highlights changes to the initialization, voice selection, and speech generation methods to be compatible with the new API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n\"- const tts = new PlayAITTS({\\n-   model: {\\n-     name: 'PlayDialog',\\n-     voice: 'angelo',\\n-   }\\n- });\\n+ const voice = new PlayAIVoice({\\n+   speechModel: {\\n+     name: 'PlayDialog',\\n+   },\\n+   speaker: 's3://voice-cloning-zero-shot/baf1ef41-36b6-428c-9bdf-50ba54682bd8/original/manifest.json'\\n+ });\\n\\n- const voices = await tts.voices();\\n+ const speakers = await voice.getSpeakers();\\n\\n- const { audioResult } = await tts.generate({ text: 'Hello' });\\n+ const stream = await voice.speak('Hello');\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: This snippet shows how to define the OpenAI API key in the `.env` file. Replace `<your-openai-key>` with your actual API key to authenticate with the OpenAI service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Default netlify.toml Configuration\nDESCRIPTION: The default netlify.toml configuration that the deployer creates, which sets up function bundling with esbuild and configures redirects for the API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/netlify/README.md#2025-04-22_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[functions]\nnode_bundler = \"esbuild\"\ndirectory = \"/netlify/functions\"\n\n[[redirects]]\nforce = true\nfrom = \"/*\"\nstatus = 200\nto = \"/.netlify/functions/api/:splat\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file, which is required for the example to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Realtime Voice Configuration\nDESCRIPTION: OpenAI Realtime音声プロバイダーの初期化設定を示します。音声認識とテキスト変換のためのモデル名、APIキー、言語、およびオーディオ形式を指定します。この設定により、MastraはOpenAIのリアルタイム音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_29\n\nLANGUAGE: typescript\nCODE:\n```\n// OpenAI Realtime Voice Configuration\nconst voice = new OpenAIRealtimeVoice({\n  speechModel: {\n    name: \"gpt-3.5-turbo\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    language: \"en-US\", // Language code\n  },\n  listeningModel: {\n    name: \"whisper-1\", // Example model name\n    apiKey: process.env.OPENAI_API_KEY,\n    format: \"ogg\", // Audio format\n  },\n  speaker: \"alloy\", // Example speaker name\n});\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1-alpha.46\nDESCRIPTION: Changelog entry documenting multiple dependency updates for alpha version 46\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [2f17a5f]\n- Updated dependencies [cb290ee]\n- Updated dependencies [b4d7416]\n- Updated dependencies [38b7f66]\n  - @mastra/core@0.2.0-alpha.84\n  - @mastra/memory@0.1.0-alpha.66\n  - @mastra/store-upstash@0.0.0-alpha.2\n  - @mastra/vector-pg@0.0.1-alpha.18\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Storage\nDESCRIPTION: This command installs the @mastra/pg package, which provides the PostgreSQL storage implementation for Mastra. It is a necessary prerequisite before using the PostgresStore class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/storage/postgresql.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/pg\"\n```\n\n----------------------------------------\n\nTITLE: QueryResult Interface Definition\nDESCRIPTION: Defines the structure of the QueryResult object returned by the query() method. It includes the id, score, metadata, and vector properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/vectorize.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface QueryResult {\n  id: string;\n  score: number;\n  metadata: Record<string, any>;\n  vector?: number[];\n}\n```\n\n----------------------------------------\n\nTITLE: Installing New Package - Bash\nDESCRIPTION: This snippet demonstrates the installation of the new @mastra/voice-openai package. This is the recommended action to acquire both Text-to-Speech and Speech-to-Text functionalities.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/openai/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-openai\n```\n\n----------------------------------------\n\nTITLE: Deprecate and Rename Packages\nDESCRIPTION: This change deprecates the @mastra/speech-deepgram package and replaces it with @mastra/voice-deepgram. It requires updating import paths in existing code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/CHANGELOG.md#_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Non-Interactive Mode - Exclude Example Code\nDESCRIPTION: This command demonstrates how to exclude example code when running `create-mastra` non-interactively, using the `--no-example` flag.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest my-app --components agents,tools --llm openai --no-example\n```\n\n----------------------------------------\n\nTITLE: Running the Bird Checker Agent Example\nDESCRIPTION: This snippet shows how to start the Bird Checker Agent using pnpm. Running this command initiates the agent to process the images.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install the required dependencies using the PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Advanced Document Chunking with Metadata Extraction in Typescript\nDESCRIPTION: This code snippet shows how to use the `.chunk()` function with advanced options, including specifying a markdown strategy, extracting headers, and generating summaries and keywords. It configures the chunking process to extract specific metadata based on the document's structure.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/chunk.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\nconst doc = MDocument.fromMarkdown(`\n# Introduction\nThis is a sample document that we want to split into chunks.\n\n## Section 1\nHere is the first section with some content.\n\n## Section 2 \nHere is another section with different content.\n`);\n\n// Markdown-specific chunking with header extraction\nconst chunksWithMetadata = await doc.chunk({\n  strategy: 'markdown',\n  headers: [['#', 'title'], ['##', 'section']],\n  extract: {\n    summary: true, // Extract summaries with default settings\n    keywords: true  // Extract keywords with default settings\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Run Script to Test Assistant (Bash)\nDESCRIPTION: Executes the script to test the research assistant using bun.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/research-assistant.mdx#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nnpx bun src/index.ts\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File\nDESCRIPTION: Command to create a copy of the example environment variables file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Project Directory Structure Example\nDESCRIPTION: Shows the expected directory structure created and managed by the deployer\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/deployer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nyour-project/\n├── .mastra/\n│   ├── package.json\n│   ├── mastra.mjs\n│   └── index.mjs\n├── .env\n├── .env.development\n├── .env.local\n└── package.json\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Cloudflare D1 Package\nDESCRIPTION: This command installs the @mastra/cloudflare-d1 package using pnpm. Ensure pnpm is installed as a prerequisite.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/cloudflare-d1/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/cloudflare-d1\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Configuration\nDESCRIPTION: Environment variable template for setting up OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/filter-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Installing Voice Provider Package with PNPM\nDESCRIPTION: This bash command shows how to install a Mastra voice provider package using pnpm, specifically the OpenAI voice package as an example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/text-to-speech.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/voice-openai  # Example for OpenAI\n```\n\n----------------------------------------\n\nTITLE: Mastra Project Build (Bash)\nDESCRIPTION: Command to build a Mastra project for Cloudflare deployment. This command compiles the Mastra application and generates the necessary output files in the `.mastra/output` directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/cloudflare.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx mastra build\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file, which is required for the LLM-based evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Client with pnpm\nDESCRIPTION: This command installs the Mastra Client SDK using pnpm. It adds the @mastra/client-js package to your project's dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File in Bash\nDESCRIPTION: Command to create a copy of the example environment variables file to set up your configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Running the Faithfulness Example\nDESCRIPTION: Command to start the faithfulness evaluation example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/faithfulness/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra with OTLP Exporter (TypeScript)\nDESCRIPTION: This TypeScript code snippet demonstrates how to initialize Mastra with an OpenTelemetry (OTLP) exporter to send telemetry data to New Relic. The `telemetry` configuration enables telemetry, sets the service name, and configures the export type to OTLP. Replace `your-service-name` with the appropriate name for your service.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/new-relic.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables\nDESCRIPTION: This snippet shows how to set up the OpenAI API key as an environment variable. This is a prerequisite for using the OpenAI integration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/evals/bias.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Measuring Completeness with Mastra AI in TypeScript\nDESCRIPTION: This snippet demonstrates how to use the CompletenessMetric class from the Mastra framework to assess coverage of key input elements in LLM outputs. It initializes the metric and uses the measure() method to calculate the completeness score and detailed coverage metrics. Requires the Mastra framework as a dependency. Inputs include original and LLM-generated text; outputs are completeness score and detailed information objects.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/completeness.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CompletenessMetric } from \"@mastra/evals/nlp\";\n\nconst metric = new CompletenessMetric();\n\nconst result = await metric.measure(\n  \"Explain how photosynthesis works in plants using sunlight, water, and carbon dioxide.\",\n  \"Plants use sunlight to convert water and carbon dioxide into glucose through photosynthesis.\"\n);\n\nconsole.log(result.score); // Coverage score from 0-1\nconsole.log(result.info); // Object containing detailed metrics about element coverage\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in Environment File\nDESCRIPTION: Example of how to add the OpenAI API key to the .env file. The key is required for the agent to communicate with OpenAI's API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the specific example directory for retrieving results.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/retrieve-results\n```\n\n----------------------------------------\n\nTITLE: Fetching Weather Data using Open Meteo API\nDESCRIPTION: Defines a step to fetch weather forecast data for a given city using the Open Meteo API. It uses geocoding to find the city's coordinates and then retrieves the weather forecast.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/agents/agentic-workflows.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst fetchWeather = new Step({\n  id: \"fetch-weather\",\n  description: \"指定された都市の天気予報を取得します\",\n  inputSchema: z.object({\n    city: z.string().describe(\"天気を取得する都市\"),\n  }),\n  execute: async ({ context }) => {\n    const triggerData = context?.getStepResult<{ city: string }>(\"trigger\");\n\n    if (!triggerData) {\n      throw new Error(\"トリガーデータが見つかりません\");\n    }\n\n    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(triggerData.city)}&count=1`;\n    const geocodingResponse = await fetch(geocodingUrl);\n    const geocodingData = await geocodingResponse.json();\n\n    if (!geocodingData.results?.[0]) {\n      throw new Error(`場所 '${triggerData.city}' が見つかりません`);\n    }\n\n    const { latitude, longitude, name } = geocodingData.results[0];\n\n    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&daily=temperature_2m_max,temperature_2m_min,precipitation_probability_mean,weathercode&timezone=auto`;\n    const response = await fetch(weatherUrl);\n    const data = await response.json();\n\n    const forecast = data.daily.time.map((date: string, index: number) => ({\n      date,\n      maxTemp: data.daily.temperature_2m_max[index],\n      minTemp: data.daily.temperature_2m_min[index],\n      precipitationChance: data.daily.precipitation_probability_mean[index],\n      condition: getWeatherCondition(data.daily.weathercode[index]),\n      location: name,\n    }));\n\n    return forecast;\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration for RAG System\nDESCRIPTION: Configuration of environment variables for OpenAI API key and PostgreSQL connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the context position example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-position/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/context-position\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Mastra RAG System\nDESCRIPTION: Sets up required environment variables for OpenAI API access and PostgreSQL connection.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: Template for adding your OpenAI API key to the .env file. This is required for the toxicity metric to function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Bias Evaluation in TypeScript\nDESCRIPTION: Imports the required dependencies from OpenAI SDK and Mastra Evals library for bias evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { BiasMetric } from '@mastra/evals/llm';\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigation\nDESCRIPTION: Commands to clone the mastra repository and navigate to the tool workflow example directory\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/tool-as-workflow-step/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/workflows/tool-as-workflow-step\n```\n\n----------------------------------------\n\nTITLE: TTS with Google Voice Agent\nDESCRIPTION: This code shows how to use an Agent with Google voice for Text-to-Speech (TTS). It initializes an agent, generates text using the agent's model, converts the text to an audio stream using Google's voice, and then plays the audio stream using the playAudio function.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\nimport { GoogleVoice } from \"@mastra/voice-google\";\nimport { playAudio } from \"@mastra/node-audio\";\n\nconst voiceAgent = new Agent({\n  name: \"Voice Agent\",\n  instructions: \"You are a voice assistant that can help users with their tasks.\",\n  model: openai(\"gpt-4o\"),\n  voice: new GoogleVoice(),\n});\n\nconst { text } = await voiceAgent.generate('What color is the sky?');\n\n// Convert text to speech to an Audio Stream\nconst audioStream = await voiceAgent.voice.speak(text, {\n  speaker: \"en-US-Studio-O\", // Optional: specify a speaker\n});\n\nplayAudio(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra Project with Default Settings in Bash\nDESCRIPTION: This command sets up a new Mastra project using default settings. It creates a 'src/' directory, includes all components (agents, tools, workflows), sets OpenAI as the default provider, and doesn't include example code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/init.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmastra init --default\n```\n\n----------------------------------------\n\nTITLE: Creating Agents with Voice Capabilities in Mastra (TypeScript)\nDESCRIPTION: This snippet demonstrates how to create two AI agents, an optimist and a skeptic, using Mastra. Each agent is configured with a name, instructions defining their personality, an OpenAI model (gpt-4o), and voice settings using OpenAIVoice. The 'speaker' property determines the voice used for text-to-speech.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from '@ai-sdk/openai';\nimport { Agent } from '@mastra/core/agent';\nimport { OpenAIVoice } from '@mastra/voice-openai';\n\nexport const optimistAgent = new Agent({\n    name: \"Optimist\",\n    instructions: \"You are an optimistic debater who sees the positive side of every topic. Keep your responses concise and engaging, about 2-3 sentences.\",\n    model: openai(\"gpt-4o\"),\n    voice: new OpenAIVoice({\n        speaker: \"alloy\"\n    }),\n});\n\nexport const skepticAgent = new Agent({\n    name: \"Skeptic\",\n    instructions: \"You are a RUDE skeptical debater who questions assumptions and points out potential issues. Keep your responses concise and engaging, about 2-3 sentences.\",\n    model: openai(\"gpt-4o\"),\n    voice: new OpenAIVoice({\n        speaker: \"echo\"\n    }),\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the answer relevancy example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/answer-relevancy\n```\n\n----------------------------------------\n\nTITLE: Log Message Interface Definition\nDESCRIPTION: TypeScript interface defining the structure of log messages used by both transport implementations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/loggers/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ninterface BaseLogMessage {\n  time?: number; // Timestamp (auto-injected if not present)\n  level?: string; // Log level\n  msg?: {\n    // Message content\n    runId?: string; // Optional run ID for grouping logs\n    [key: string]: any;\n  };\n  [key: string]: any;\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Turbopuffer SDK Dependency with PNPM\nDESCRIPTION: Installs the @mastra/turbopuffer package using PNPM, a fast, disk space-efficient package manager. This step is essential for the implementation of the vector store.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/turbopuffer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/turbopuffer\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key in Environment Variables\nDESCRIPTION: Example of how to configure the OpenAI API key in the .env file for authentication.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-relevancy/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Bash\nDESCRIPTION: This snippet explains the command to install all necessary dependencies for the project using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/agentic-workflows/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Breaking Changes\nDESCRIPTION: This entry notes breaking changes in the package. Further details on the specifics of these changes would need to be investigated.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n8b416d9: Breaking changes\n```\n\n----------------------------------------\n\nTITLE: Creating an MDocument instance - TypeScript\nDESCRIPTION: This code snippet demonstrates the creation of an MDocument instance, encapsulating text content along with its associated metadata. This class is part of the @mastra/rag library.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MDocument } from '@mastra/rag';\n\nconst doc = new MDocument({\n  text: 'Document content',\n  metadata: { source: 'example.txt' },\n});\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project (npx)\nDESCRIPTION: This command uses npx to create a new Mastra project, scaffolding the necessary files and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Running the Example Workflow (TypeScript)\nDESCRIPTION: This snippet demonstrates how to execute the complete event-driven workflow defined in the previous snippet. It shows how to start the workflow, simulate receiving events, and resume the workflow with event data. It assumes the `requestWorkflow` is imported from a module.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/events.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { requestWorkflow } from './workflows';\nimport { mastra } from './mastra';\n\nasync function runWorkflow() {\n  // Get the workflow\n  const workflow = mastra.getWorkflow('document-request-workflow');\n  const run = workflow.createRun();\n\n  // Start the workflow\n  const initialResult = await run.start();\n  console.log('Workflow started:', initialResult.results);\n\n  // Simulate receiving approval\n  const afterApprovalResult = await run.resumeWithEvent('approvalReceived', {\n    approved: true,\n    approverName: 'Jane Smith',\n  });\n  console.log('After approval:', afterApprovalResult.results);\n\n  // Simulate document upload\n  const finalResult = await run.resumeWithEvent('documentUploaded', {\n    documentId: 'doc-456',\n    documentType: 'invoice',\n  });\n  console.log('Final result:', finalResult.results);\n}\n\nrunWorkflow().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Package.json Configuration Example\nDESCRIPTION: Example of automatically managed dependencies in the .mastra/package.json file\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/deployer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"server\",\n  \"version\": \"1.0.0\",\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@mastra/loggers\": \"latest\",\n    \"hono\": \"4.6.17\",\n    \"@hono/node-server\": \"^1.13.7\",\n    \"superjson\": \"^2.2.2\",\n    \"zod-to-json-schema\": \"^3.24.1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Environment File\nDESCRIPTION: This snippet demonstrates how to add the OpenAI API key to the .env file for use in the Mastra workflow.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Set OpenAI API Key\nDESCRIPTION: Sets the OpenAI API key in the .env file. Replace `your_openai_api_key` with your actual API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Deleting an Index in Turbopuffer Vector Store | TypeScript\nDESCRIPTION: This snippet defines the deleteIndex() method for removing an index from the Turbopuffer vector store, requiring the index name as input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/turbopuffer.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n<PropertiesTable\n  content={[\n    {\n      name: \"indexName\",\n      type: \"string\",\n      description: \"Name of the index to delete\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Sequential Workflow Steps with then() in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a workflow with sequential dependencies between steps using the `.then()` method. Each `.then()` call specifies the next step to be executed after the previous step completes, ensuring a specific order of execution.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/then.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(stepOne)\n  .then(stepTwo)\n  .then(stepThree);\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigation\nDESCRIPTION: Commands to clone the project repository and navigate to the graph-rag example directory\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/graph-rag\n```\n\n----------------------------------------\n\nTITLE: Create Mastra Project (npm)\nDESCRIPTION: This command uses npm to create a new Mastra project, scaffolding the necessary files and dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm create mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: Command to install the project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/basic-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables File\nDESCRIPTION: Command to copy the example environment file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Running the Toxicity Metric Example\nDESCRIPTION: Command to start the toxicity metric example application after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initialize GoogleVoice (New)\nDESCRIPTION: This snippet shows how to initialize the GoogleVoice class from the new @mastra/voice-google package. It configures the speech model with the API key and specifies the speaker.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/google/README.md#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// New\nconst voice = new GoogleVoice({\n  speechModel: {\n    apiKey: 'your-api-key',\n  },\n  speaker: 'en-US-Standard-C',\n});\n```\n\n----------------------------------------\n\nTITLE: Fix Query Filter for Vector Search and Rerank (Patch)\nDESCRIPTION: This patch addresses an issue in the query filter used for vector search and reranking. It improves the accuracy and reliability of search results by correcting potential errors in the filtering logic.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in .env File\nDESCRIPTION: This snippet shows how to configure the OpenAI API key in a `.env` file. This environment variable is required for authenticating requests to the OpenAI API. Make sure to replace `your_openai_api_key` with your actual OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/overview.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tools\nDESCRIPTION: Defines a custom tool with input schema validation using Zod that agents can use to fetch weather information\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createTool } from '@mastra/core/tools';\nimport { z } from 'zod';\n\nconst weatherInfo = createTool({\n  id: 'Get Weather Information',\n  inputSchema: z.object({\n    city: z.string(),\n  }),\n  description: 'Fetches the current weather information for a given city',\n  execute: async ({ context: { city } }) => {\n    // Tool implementation\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Copywriter Agent Configuration\nDESCRIPTION: Sets up the copywriter agent with a name, instructions, and specifies the Claude AI model to use for content generation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Prompts with Optional Settings in TypeScript\nDESCRIPTION: Showcases a TypeScript function configuring a prompt with various optional settings, including persona, style, tone, output format, and message source. These configurations shape how the model approaches the task.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst explainPrompt = createPrompt('Explain this code', {\n  // Who the model should act as\n  persona: 'JavaScript Teacher',\n\n  // How to approach the explanation\n  style: 'beginner-friendly',\n\n  // Communication style\n  tone: 'encouraging',\n\n  // Expected response format\n  outputFormat: 'markdown',\n\n  // System or user message\n  as: 'system',\n});\n\n// Usage\nconst explanation = explainPrompt.toString();\n```\n\n----------------------------------------\n\nTITLE: Importing Textual Difference Metric in TypeScript\nDESCRIPTION: Demonstrates how to import the necessary dependencies for using the Textual Difference metric from Mastra's evals package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/textual-difference.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TextualDifferenceMetric } from '@mastra/evals/nlp';\n```\n\n----------------------------------------\n\nTITLE: Creating Mastra project with default settings\nDESCRIPTION: Example command showing how to create a new Mastra project with default configuration settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest --default\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install the required project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install all required dependencies using the PNPM package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-position/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Example - Bash\nDESCRIPTION: This snippet illustrates the command to start the agentic workflow example after setting up the environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/agentic-workflows/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Netlify Project Structure\nDESCRIPTION: Directory structure that the deployer automatically creates for Netlify deployment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/netlify/README.md#2025-04-22_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nyour-project/\n├── netlify/\n│   └── functions/\n│       └── api/\n└── netlify.toml\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Example File\nDESCRIPTION: Command to create a copy of the example environment variables file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-position/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI API Key\nDESCRIPTION: Sets up the necessary environment variable for the OpenAI API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/toxicity.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install the required project dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-cyclical-deps/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Update Typechecks for Positional Args (Patch)\nDESCRIPTION: This patch updates the type checking mechanism to improve the validation of positional arguments. It increases the robustness of the package by catching potential type errors during development.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/chroma/CHANGELOG.md#_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Defining IndexStats Interface in TypeScript\nDESCRIPTION: This TypeScript interface defines the structure of index statistics, including dimension, count, and metric for similarity search. This is used as a return type for the describeIndex method. Dependencies are any TypeScript-enabled environment with knowledge of Pinecone indexing methods.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pinecone.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Update Vector Store Functions\nDESCRIPTION: This patch updates the vector store functions to use object parameters, enhancing code readability and flexibility by allowing named parameters.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n0fd78ac: Update vector store functions to use object params\n```\n\n----------------------------------------\n\nTITLE: Generating Product Recommendations with Mastra Step\nDESCRIPTION: This snippet defines a Mastra Step for generating product recommendations. It uses mock data to simulate recommendations for a given customer.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { Step, Workflow } from '@mastra/core/workflows';\nimport { z } from 'zod';\nimport { confirm, input, select } from '@inquirer/prompts';\n\n// Step 1: Generate product recommendations\nconst generateRecommendations = new Step({\n  id: 'generateRecommendations',\n  outputSchema: z.object({\n    customerName: z.string(),\n    recommendations: z.array(\n      z.object({\n        productId: z.string(),\n        productName: z.string(),\n        price: z.number(),\n        description: z.string(),\n      }),\n    ),\n  }),\n  execute: async ({ context }) => {\n    const customerName = context.triggerData.customerName;\n\n    // In a real application, you might call an API or ML model here\n    // For this example, we'll return mock data\n    return {\n      customerName,\n      recommendations: [\n        {\n          productId: 'prod-001',\n          productName: 'Premium Widget',\n          price: 99.99,\n          description: 'Our best-selling premium widget with advanced features',\n        },\n        {\n          productId: 'prod-002',\n          productName: 'Basic Widget',\n          price: 49.99,\n          description: 'Affordable entry-level widget for beginners',\n        },\n        {\n          productId: 'prod-003',\n          productName: 'Widget Pro Plus',\n          price: 149.99,\n          description: 'Professional-grade widget with extended warranty',\n        },\n      ],\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Run Mastra Development Server\nDESCRIPTION: This command initiates the Mastra development server, which hosts the registered agents and makes them accessible via API endpoints. This allows for local testing and interaction with the agent without deploying it to a production environment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmastra dev\n```\n\n----------------------------------------\n\nTITLE: Start Development Server (npm)\nDESCRIPTION: Starts the Mastra development server using npm. This will create REST API endpoints for the registered agents.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Handling Vector Store Errors\nDESCRIPTION: This code snippet demonstrates how to handle potential errors when querying the vector store. It uses a try-catch block to catch errors and provides specific error handling logic based on the error message, improving the robustness of the application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/libsql.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"my-collection\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  // Handle specific error cases\n  if (error.message.includes(\"Invalid index name format\")) {\n    console.error(\n      \"Index name must start with a letter/underscore and contain only alphanumeric characters\",\n    );\n  } else if (error.message.includes(\"Table not found\")) {\n    console.error(\"The specified index does not exist\");\n  } else {\n    console.error(\"Vector store error:\", error.message);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1-alpha.43\nDESCRIPTION: Changelog entry documenting dependency updates for alpha version 43\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [e66643a]\n  - @mastra/core@0.1.27-alpha.65\n  - @mastra/memory@0.0.2-alpha.45\n```\n\n----------------------------------------\n\nTITLE: Initializing Tone Consistency Metric in TypeScript\nDESCRIPTION: Creates a new instance of the ToneConsistencyMetric class for evaluation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/tone-consistency.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst metric = new ToneConsistencyMetric();\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAIVoice with Default Configuration | TypeScript\nDESCRIPTION: Initializes the PlayAIVoice class with default configurations, which automatically uses the `PLAYAI_API_KEY` and `PLAYAI_USER_ID` environment variables for authentication.  No specific model or speaker is configured in this example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/playai.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PlayAIVoice } from \"@mastra/voice-playai\";\n\n// Initialize with default configuration (uses PLAYAI_API_KEY environment variable and PLAYAI_USER_ID environment variable)\nconst voice = new PlayAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Example of environment variable configuration needed for the project, including OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server in a Mastra Agent (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to configure the Model Context Protocol (MCP) server for a Mastra Agent, enabling the agent to access documentation tools. It imports necessary modules, configures the MCP server, and creates an agent with access to documentation tools.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/README.md#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { MCPConfiguration } from '@mastra/mcp';\nimport { Agent } from '@mastra/core/agent';\nimport { openai } from '@ai-sdk/openai';\n\n// Configure MCP with the docs server\nconst mcp = new MCPConfiguration({\n  servers: {\n    mastra: {\n      command: 'npx',\n      args: ['-y', '@mastra/mcp-docs-server@latest'],\n    },\n  },\n});\n\n// Create an agent with access to all documentation tools\nconst agent = new Agent({\n  name: 'Documentation Assistant',\n  instructions: 'You help users find and understand Mastra.ai documentation.',\n  model: openai('gpt-4'),\n  tools: await mcp.getTools(),\n});\n\n// Or use toolsets dynamically in generate/stream\nconst response = await agent.stream('Show me the quick start example', {\n  toolsets: await mcp.getToolsets(),\n});\n```\n\n----------------------------------------\n\nTITLE: Converting Speech to Text\nDESCRIPTION: This snippet shows how to convert an audio stream back into text using the listen method of the DeepgramVoice instance. This allows for effective Speech-to-Text conversion in applications, enabling interaction based on spoken language.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst text = await voice.listen(audioStream);\n```\n\n----------------------------------------\n\nTITLE: Vercel Deployer Configuration\nDESCRIPTION: Configuration example for the Vercel deployer showing required parameters including team slug and authentication token.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/deployment.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nnew VercelDeployer({\n  teamSlug: 'your-vercel-team-slug',\n  projectName: 'your-project-name',\n  token: 'your-vercel-token'\n  // For complete configuration options, see the reference documentation\n})\n```\n\n----------------------------------------\n\nTITLE: Install @mastra/voice-speechify (Bash)\nDESCRIPTION: Installs the @mastra/voice-speechify package using npm. This is a prerequisite for using the Speechify voice integration in your project. The command adds the package and its dependencies to your project's node_modules directory and package.json file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-speechify\n```\n\n----------------------------------------\n\nTITLE: Close Method Definition\nDESCRIPTION: This code snippet defines the optional `close` method in `MastraVoice`, used to disconnect from the voice service. It cleans up resources and stops any ongoing real-time processing. This should be called when terminating the voice instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/mastra-voice.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nclose(): void\n```\n\n----------------------------------------\n\nTITLE: Running the Context Relevancy Example\nDESCRIPTION: Command to start the context relevancy evaluation example after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/context-relevancy/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Running the Example - Bash\nDESCRIPTION: Command to start and execute the parallel workflow example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-parallel-steps/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Running the Contextual Recall Example\nDESCRIPTION: Command to start the Contextual Recall metric example after setup is complete.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra using npx\nDESCRIPTION: Command to create a new Mastra project using npx package runner.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-mastra@latest\n```\n\n----------------------------------------\n\nTITLE: Running the Mastra Completeness Metric Example\nDESCRIPTION: Command to execute the completeness metric example application. This will run the demonstration showcasing how the metric evaluates response completeness across different scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/completeness/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Migration Instructions for Pinecone Package\nDESCRIPTION: Provides step-by-step instructions on how to migrate from the old @mastra/vector-pinecone package to the new @mastra/pinecone package, including removing the old dependency, installing the new one, and updating import statements.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pinecone/CHANGELOG.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n1. Remove @mastra/vector-pinecone from dependencies\n2. Install @mastra/pinecone\n3. Update imports from '@mastra/vector-pinecone' to '@mastra/pinecone'\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow Example\nDESCRIPTION: Command to start the workflow example application.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/create-workflow/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Deprecated Package - Bash\nDESCRIPTION: This snippet shows how to uninstall the deprecated @mastra/speech-openai package using npm. It is a necessary step before installing the new package, @mastra/voice-openai.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/openai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm uninstall @mastra/speech-openai\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command for installing the required dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/custom-eval/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Set up API Key - .env file\nDESCRIPTION: This is an example of setting up the API key in a `.env` file. Replace `<your-openai-key>` with your actual OpenAI API key. This ensures that your Mastra application can authenticate with the LLM provider.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow Example\nDESCRIPTION: Command to start the workflow-with-branching-paths example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/workflows/workflow-with-branching-paths/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Variable Mapping in Mastra Workflows (TypeScript)\nDESCRIPTION: This snippet demonstrates how to use variable mapping to define data flow between steps in a Mastra workflow. It uses the `Step` and `Workflow` classes from `@mastra/core/workflows` and `zod` for schema definition. The `fetchUserStep` provides data which is mapped to `sendEmailStep` input variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Workflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new Step({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\"\n    };\n  },\n});\n\nconst sendEmailStep = new Step({\n  id: \"sendEmail\",\n  inputSchema: z.object({\n    recipientEmail: z.string(),\n    recipientName: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const { recipientEmail, recipientName } = context.inputData;\n\n    // Send email logic here\n    return {\n      status: \"sent\",\n      to: recipientEmail\n    };\n  },\n});\n\nconst workflow = new Workflow({\n  name: \"email-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(sendEmailStep, {\n    variables: {\n      // Map specific fields from fetchUser to sendEmail inputs\n      recipientEmail: { step: fetchUserStep, path: 'email' },\n      recipientName: { step: fetchUserStep, path: 'name' }\n    }\n  })\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/cloud Package\nDESCRIPTION: Install the @mastra/cloud package using npm, yarn, or pnpm. This package allows integration with Mastra Cloud services.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cloud/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/cloud\n# or\nyarn add @mastra/cloud\n# or\npnpm add @mastra/cloud\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the hybrid vector search example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/hybrid-vector-search/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/hybrid-vector-search\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory with Processors\nDESCRIPTION: TypeScript example showing how to initialize a Memory instance with custom and built-in processors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst memory = new Memory({\n  processors: [\n    new CustomProcessor(),\n    // Can be combined with built-in processors\n    new TokenLimiter(8000),\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Running the Textual Difference Example in Bash\nDESCRIPTION: Command to start the Textual Difference metric demonstration. This will execute the example and show the comparison results for the different scenarios.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/textual-difference/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing @mastra/speech-replicate Module using npm\nDESCRIPTION: This snippet demonstrates how to install the @mastra/speech-replicate module with npm, which is essential for enabling Text-to-Speech functionality in the Mastra project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/replicate/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/speech-replicate\n```\n\n----------------------------------------\n\nTITLE: Real-time Audio Transcription with Event Listener\nDESCRIPTION: This code snippet demonstrates how to use a real-time voice provider (`OpenAIRealtimeVoice`) for live audio transcription.  Instead of returning the transcribed text directly, the provider emits 'writing' events, which are then handled by an event listener to print the transcribed text to the console.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/voice/voice.listen.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { OpenAIRealtimeVoice } from \"@mastra/voice-openai-realtime\";\nimport { getMicrophoneStream } from \"@mastra/node-audio\";\n\nconst voice = new OpenAIRealtimeVoice();\nawait voice.connect();\n\n// Register event listener for transcription\nvoice.on(\"writing\", ({ text, role }) => {\n  console.log(`${role}: ${text}`);\n});\n\n// This will emit 'writing' events instead of returning text\nconst microphoneStream = getMicrophoneStream();\nawait voice.listen(microphoneStream);\n```\n\n----------------------------------------\n\nTITLE: Renaming Method in Changelog\nDESCRIPTION: Documents the renaming of the `voices()` method to `getSpeakers()` as part of the API update of the `@mastra/voice-murf` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n- `voices()` method renamed to `getSpeakers()`\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Package Manager\nDESCRIPTION: Command to install the required Node.js dependencies using pnpm package manager. This must be executed before running the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/keyword-coverage/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example (TypeScript)\nDESCRIPTION: Demonstrates how to catch and handle typed errors thrown by the Turbopuffer vector store.  Shows how to check if an error is an instance of `VectorStoreError` and access its `code` and `details` properties.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/turbopuffer.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a new Mastra project using yarn\nDESCRIPTION: This command creates a new Mastra project using the yarn package manager. It executes the create-mastra package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn create mastra\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables File in Bash\nDESCRIPTION: The snippet demonstrates the Bash command to copy the environment variables file. Users need to add their Anthropic API key and Unsplash access token afterward.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Cohere\nDESCRIPTION: Demonstrates how to generate embeddings for document chunks using the Cohere embedding model. It imports the required modules and employs the `embedMany` function to create the embeddings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/chunking-and-embedding.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { cohere } from '@ai-sdk/cohere';\nimport { embedMany } from 'ai';\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding('embed-english-v3.0'),\n  values: chunks.map(chunk => chunk.text),\n});\n```\n\n----------------------------------------\n\nTITLE: Install Mastra Client with yarn\nDESCRIPTION: This command installs the Mastra Client SDK using yarn. It adds the @mastra/client-js package to your project's dependencies.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/client.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Run Application\nDESCRIPTION: Starts the application using the `dev` script defined in `package.json`. This initiates the voice conversation and associated processes.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Running the Text Embedding Example\nDESCRIPTION: Command to execute the text embedding example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for OpenAI and Chroma\nDESCRIPTION: Example of environment variables configuration in the .env file, including the OpenAI API key and Chroma database path.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-chroma/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nCHROMA_DB_PATH=path/to/your/chroma/db\n```\n\n----------------------------------------\n\nTITLE: Installing PlayAI Voice Package with npm\nDESCRIPTION: This snippet installs the PlayAI Voice module, necessary for integrating text-to-speech features in the Mastra application. It requires Node.js and npm to be installed beforehand.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-playai\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to the Mastra Project in Bash\nDESCRIPTION: Commands to clone the Mastra repository from GitHub and navigate to the text chunking example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-text/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/chunk-text\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAIRealtimeVoice with Configuration\nDESCRIPTION: This TypeScript code demonstrates how to initialize the OpenAIRealtimeVoice class with custom configuration options. It shows how to set the API key, model, and voice settings.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { OpenAIRealtimeVoice } from '@mastra/voice-openai-realtime';\nimport { getMicrophoneStream } from '@mastra/node-audio';\n\n// Create a voice instance with default configuration\nconst voice = new OpenAIRealtimeVoice();\n\n// Create a voice instance with configuration\nconst voice = new OpenAIRealtimeVoice({\n  chatModel: {\n    apiKey: 'your-api-key', // Optional, can use OPENAI_API_KEY env var\n    model: 'gpt-4o-mini-realtime', // Optional, uses latest model by default\n    options: {\n      sessionConfig: {\n        voice: 'alloy', // Default voice\n        turn_detection: {\n          type: 'server_vad',\n          threshold: 0.5,\n          silence_duration_ms: 1000,\n        },\n      },\n    },\n  },\n});\n\n// Connect to the realtime service\nawait voice.open();\n\n// Audio data from voice provider\nvoice.on('speaking', (audioData: Int16Array) => {\n  // Handle audio data\n});\n\n// Text data from voice provider\nvoice.on('writing', (text: string) => {\n  // Handle transcribed text\n});\n\n// Error from voice provider\nvoice.on('error', (error: Error) => {\n  console.error('Voice error:', error);\n});\n\n// Generate speech\nawait voice.speak('Hello from Mastra!', {\n  speaker: 'echo', // Optional: override default speaker\n});\n\n// Listen to audio input\nawait voice.listen(audioData);\n\n// Process audio input\nconst microphoneStream = getMicrophoneStream();\nawait voice.send(microphoneStream);\n\n// Clean up\nvoice.close();\n\"\n```\n\n----------------------------------------\n\nTITLE: Hydrating Toolsets for MCP Client Tools - TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve connected tools related to configurations and utilize them in generating responses based on user prompts. This facilitates the integration between the MCP client and an LLM or agent for generating outputs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/mcp-registry-client/README.md#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolsets = await configuration.getConnectedTools()\n\nconst res = await agent.generate(prompt, {\n\ttoolsets,\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Integration\nDESCRIPTION: TypeScript code to initialize and configure the GitHub integration with authentication token\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/integrations/index.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubIntegration } from \"@mastra/github\";\n\nexport const github = new GithubIntegration({\n  config: {\n    PERSONAL_ACCESS_TOKEN: process.env.GITHUB_PAT!,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining IndexStats Interface\nDESCRIPTION: This code snippet defines the `IndexStats` interface, which represents the structure of the object returned by the `describeIndex()` method. It specifies the properties related to index metadata, such as dimension, count, and metric.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/libsql.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ninterface IndexStats {\n  dimension: number;\n  count: number;\n  metric: \"cosine\" | \"euclidean\" | \"dotproduct\";\n}\n```\n\n----------------------------------------\n\nTITLE: Stream Response from Chef Agent\nDESCRIPTION: This code demonstrates how to stream a response from the chef agent. It utilizes the `chefAgent.stream` method to get a stream of text chunks. The code iterates through the stream and writes each chunk to the standard output, providing a real-time response. Error handling is omitted for brevity.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/guides/guide/chef-michel.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const query =\n    \"Now I'm over at my friend's house, and they have: chicken thighs, coconut milk, sweet potatoes, and some curry powder.\";\n  console.log(`Query: ${query}`);\n\n  const stream = await chefAgent.stream([{ role: \"user\", content: query }]);\n\n  console.log(\"\\n Chef Michel: \");\n\n  for await (const chunk of stream.textStream) {\n    process.stdout.write(chunk);\n  }\n\n  console.log(\"\\n\\n✅ Recipe complete!\");\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Copying environment variables file in Bash\nDESCRIPTION: Command to create a new environment file from the example template.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Running the embedding example\nDESCRIPTION: Command to execute the pgvector embedding insertion example script.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-pgvector/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm start\n```\n\n----------------------------------------\n\nTITLE: Initialize and Upsert with Upstash in TypeScript\nDESCRIPTION: This code initializes UpstashVector with URL and token, creates an index, and upserts embeddings with metadata.  It requires @mastra/upstash and appropriate Upstash environment variables.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/rag/vector-databases.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { UpstashVector } from '@mastra/upstash'\n\nconst store = new UpstashVector({\n  url: process.env.UPSTASH_URL,\n  token: process.env.UPSTASH_TOKEN\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Commands to copy the example environment file and set up necessary environment variables for testing.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Manual Installation - Create Project Directory\nDESCRIPTION: These commands create a new project directory and navigate into it, preparing the environment for manual Mastra installation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hello-mastra\ncd hello-mastra\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variables Template\nDESCRIPTION: Command to copy the example environment variables file to create a local configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables for OpenAI API\nDESCRIPTION: Sets up the OPENAI_API_KEY environment variable required for using OpenAI's API.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-position.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Repository in Bash\nDESCRIPTION: Commands to clone the project repository and navigate to the project directory. This is the first step in setting up the application locally.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/bird-checker-with-express/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone <repository-url>\ncd bird-checker-with-express\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI Integration\nDESCRIPTION: Configuration of environment variables required for OpenAI API access\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Installing Cloudflare Package via npm\nDESCRIPTION: This command installs the `@mastra/cloudflare` package, which provides the Cloudflare KV storage implementation for Mastra, using the Node Package Manager (npm). This is a necessary prerequisite for using the Cloudflare storage features.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/cloudflare.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/cloudflare\"\n```\n\n----------------------------------------\n\nTITLE: Initialize TypeScript project (pnpm)\nDESCRIPTION: Initializes a TypeScript project with necessary dependencies using pnpm.  This sets up the environment for developing with Mastra.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npnpm init\npnpm add typescript tsx @types/node mastra --save-dev\npnpm add @mastra/core zod @ai-sdk/openai\npnpm dlx tsc --init \n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command to copy the example environment file to create a local .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Configure Mastra Telemetry for Braintrust\nDESCRIPTION: Configures Mastra to export telemetry data to Braintrust using the OTLP exporter. This involves setting the service name, enabling telemetry, and specifying the OTLP export type within the Mastra configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/braintrust.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing the @mastra/voice-elevenlabs Package\nDESCRIPTION: This command installs the new @mastra/voice-elevenlabs package using npm to replace the deprecated package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/elevenlabs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-elevenlabs\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Graph RAG Implementation\nDESCRIPTION: This code snippet imports necessary dependencies from Mastra, OpenAI, and other libraries to implement the Graph RAG system.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { openai } from \"@ai-sdk/openai\";\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument, createGraphRAGTool } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n```\n\n----------------------------------------\n\nTITLE: Create Project Directory\nDESCRIPTION: Creates a new directory for the Mastra project and navigates into it.  This is the first step in the manual installation process.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hello-mastra\ncd hello-mastra\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Custom OpenTelemetry Exporter\nDESCRIPTION: Command to install the required npm packages for setting up a custom OpenTelemetry exporter with Langfuse. This is needed if you're using the custom exporter approach rather than Vercel's built-in OpenTelemetry setup.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/api langfuse-vercel\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install all required dependencies for the Mastra chunk size adjustment example using pnpm.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-size/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Using Default Initialization of PlayAI Voice\nDESCRIPTION: This snippet shows how to create a default instance of PlayAIVoice using environment variables for configuration. This allows for a quicker setup without needing to provide parameters explicitly.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/README.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst defaultVoice = new PlayAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server in Cursor (MacOS/Linux)\nDESCRIPTION: This JSON snippet configures the Model Context Protocol (MCP) server for Mastra documentation tools within the Cursor IDE on MacOS and Linux systems. It specifies the command to execute the @mastra/mcp-docs-server package using npx.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/README.md#_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mastra Deployer Configuration\nDESCRIPTION: TypeScript configuration example for specifying the deployment environment in Mastra instance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/cli/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst mastra = new Mastra({\n  deployer: {\n    type: 'HONO', // Target environment (HONO, EXPRESS, NEXT)\n    // Environment-specific options\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Installing MastraClient using npm\nDESCRIPTION: This command installs the @mastra/client-js package using the npm package manager. This package is required for interacting with the Mastra backend.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Installing MastraClient using yarn\nDESCRIPTION: This command installs the @mastra/client-js package using the yarn package manager. This package is required for interacting with the Mastra backend.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Configuring Direct Storage Usage in TypeScript\nDESCRIPTION: Shows how to directly initialize and configure DefaultStorage with custom database settings. Supports both file-based and in-memory storage options.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/storage/README.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DefaultStorage } from '@mastra/core/storage';\n\nconst storage = new DefaultStorage({\n  name: 'my-storage',\n  config: {\n    url: 'file:my-database.db', // or 'file::memory:' for in-memory\n  },\n});\n\n// Storage will auto-initialize tables on first use\nawait storage.init();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Initial Setup\nDESCRIPTION: Command to install all project dependencies and build the initial CLI package required for other packages.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm setup\n```\n\n----------------------------------------\n\nTITLE: Initializing Mastra project with default settings\nDESCRIPTION: This command initializes a new Mastra project using default settings, including a source directory of `src/`, all components (agents, tools, workflows), OpenAI as the default provider, and no sample code.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/cli/init.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmastra init --default\n```\n\n----------------------------------------\n\nTITLE: Running the development server with package managers\nDESCRIPTION: Commands to start the development server using different package managers like npm, yarn, pnpm, or bun.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/assistant-ui/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra Repository\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the project directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra.git\ncd mastra\n```\n\n----------------------------------------\n\nTITLE: Running Agent from Command Line (TypeScript)\nDESCRIPTION: This snippet shows how to invoke a Mastra agent from the command line using TypeScript. It imports the `mastra` object, retrieves the `weatherAgent`, and then calls the `generate` method. The response is logged to the console. This requires the Mastra SDK and tsx to be installed.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/getting-started/installation.mdx#_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mastra } from \"./mastra\";\n\nasync function main() {\n  const agent = await mastra.getAgent(\"weatherAgent\");\n\n  const result = await agent.generate(\"What is the weather in London?\");\n\n  console.log(\"Agent response:\", result.text);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install project dependencies using pnpm\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install the required npm dependencies using pnpm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command to copy the example environment variables file to create a new .env file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-chroma/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra Repository (Bash)\nDESCRIPTION: This snippet demonstrates how to clone the Mastra repository from GitHub and navigate to the `docs` directory. It uses the `git clone` command to download the repository and the `cd` command to change the current directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:mastra-ai/mastra.git\ncd docs\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables for OpenAI API in Bash\nDESCRIPTION: This snippet shows how to set up the OPENAI_API_KEY environment variable in a .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Memory Configuration - Disable Thread Title Generation\nDESCRIPTION: This code snippet shows how to disable thread title LLM generation when initializing a Memory object.  This is useful when models don't support structured output and error when generating a thread title. This prevents unnecessary errors in environments where thread title generation is not required.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nnew Memory({ threads: { generateTitle: false }})\n```\n\n----------------------------------------\n\nTITLE: Configuring Mastra with LangSmith Exporter\nDESCRIPTION: This snippet demonstrates how to configure Mastra to use LangSmith as a custom exporter for telemetry data. It imports the Mastra core and AISDKExporter from the LangSmith library, then instantiates Mastra with a telemetry configuration that specifies the custom exporter. The service name and enabled flag are also configured.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/providers/langsmith.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { AISDKExporter } from \"langsmith/vercel\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-service-name\",\n    enabled: true,\n    export: {\n      type: \"custom\",\n      exporter: new AISDKExporter(),\n    },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra GitHub repository and navigate to the text embedding example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/embed-text-chunk\n```\n\n----------------------------------------\n\nTITLE: Documenting Function Parameters with PropertiesTable\nDESCRIPTION: Shows how to list function parameters using the PropertiesTable component to provide structured information about each parameter.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_2\n\nLANGUAGE: mdx\nCODE:\n```\n## Parameters\n\n<PropertiesTable\n  content={[\n    {\n      name: \"data\",\n      type: \"string\",\n      description: \"The input data to be transformed.\",\n      isOptional: false,\n    },\n    {\n      name: \"options\",\n      type: \"object\",\n      description: \"Additional options that modify the behavior of MyFunction.\",\n      isOptional: true,\n      defaultValue: \"{}\",\n    },\n  ]}\n/>\n```\n\n----------------------------------------\n\nTITLE: Mastra with VercelDeployer Initialization (TypeScript)\nDESCRIPTION: Demonstrates how to initialize a Mastra application with the VercelDeployer.  It requires the @mastra/core and @mastra/deployer-vercel packages. The teamSlug, projectName, and token parameters are required for Vercel authentication and project identification.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/deployer/vercel.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from '@mastra/core';\nimport { VercelDeployer } from '@mastra/deployer-vercel';\n\nconst mastra = new Mastra({\n  deployer: new VercelDeployer({\n    teamSlug: 'your-team-slug',\n    projectName: 'your-project-name',\n    token: 'your-vercel-token'\n  }),\n  // ... other Mastra configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Building Individual Packages in Mastra\nDESCRIPTION: Commands to build specific individual packages in the Mastra monorepo, such as core, CLI, deployer, RAG, memory, evals, and MCP documentation.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npnpm build:core             # Core framework package\npnpm build:cli              # CLI and playground package\npnpm build:deployer         # Deployer package\npnpm build:rag              # RAG package\npnpm build:memory           # Memory package\npnpm build:evals            # Evaluation framework package\npnpm build:docs-mcp         # MCP documentation server\n```\n\n----------------------------------------\n\nTITLE: Initializing ElevenLabs Voice Configuration\nDESCRIPTION: ElevenLabs音声プロバイダーの初期化設定を示します。音声合成のための音声ID、モデル名、APIキー、言語、感情設定を指定します。ElevenLabsは独立したリスニングモデルを持たない可能性があります。この設定により、MastraはElevenLabsの音声サービスを利用できるようになります。\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\n// ElevenLabs Voice Configuration\nconst voice = new ElevenLabsVoice({\n  speechModel: {\n    voiceId: \"your-voice-id\", // Example voice ID\n    model: \"eleven_multilingual_v2\", // Example model name\n    apiKey: process.env.ELEVENLABS_API_KEY,\n    language: \"en\", // Language code\n    emotion: \"neutral\", // Emotion setting\n  },\n  // ElevenLabs may not have a separate listening model\n});\n```\n\n----------------------------------------\n\nTITLE: Starting Next.js Development Server\nDESCRIPTION: Command to start the Next.js development server using pnpm package manager. This runs the application in development mode and makes it accessible at localhost:3000.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/voice-memo-app/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_11\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/changelog-2025-01-24\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-24</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-01-24</h2><span class=\"text-xs text-left text-text-3\">Jan 24, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 24, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File from Template\nDESCRIPTION: Command to copy the example environment file to create a new .env file for configuration.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog\nDESCRIPTION: Detailed version history showing incremental updates and dependency changes for the travel-app package and its dependencies including @mastra/memory, @mastra/core, @mastra/engine, and @mastra/store-pg\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/travel-app/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# travel-app\n\n## 0.0.1\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [e9d1b47]\n  - @mastra/memory@0.1.0-alpha.67\n  - @mastra/core@0.2.0-alpha.85\n  - @mastra/engine@0.0.5-alpha.80\n  - @mastra/store-pg@0.0.0-alpha.3\n```\n\n----------------------------------------\n\nTITLE: Accessing a Specific Memory Thread in TypeScript\nDESCRIPTION: This snippet illustrates how to get an instance of a specific memory thread using its ID and the associated agent ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst thread = client.getMemoryThread(\"thread-id\", \"agent-id\");\n```\n\n----------------------------------------\n\nTITLE: Installing New Package - JavaScript\nDESCRIPTION: This snippet shows how to install the new package '@mastra/voice-speechify' using npm. This is the first step in the migration process from the deprecated package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/speechify/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/voice-speechify\n```\n\n----------------------------------------\n\nTITLE: Update Vector Tests and Pinecone\nDESCRIPTION: This patch updates the vector tests and Pinecone integration, ensuring compatibility and correct behavior with the latest versions and features of Pinecone.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n4d4e1e1: Updated vector tests and pinecone\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the faithfulness example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/faithfulness/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/faithfulness\n```\n\n----------------------------------------\n\nTITLE: Running Tests for Specific Packages\nDESCRIPTION: Commands to run tests for specific packages in the Mastra monorepo, such as core, CLI, RAG, memory, evals, and client SDKs.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/DEVELOPMENT.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npnpm test:core        # Core package tests\npnpm test:cli         # CLI tests\npnpm test:rag         # RAG tests\npnpm test:memory      # Memory tests\npnpm test:evals       # Evals tests\npnpm test:clients     # Client SDK tests\n```\n\n----------------------------------------\n\nTITLE: MCPServer startSSE() method definition\nDESCRIPTION: Defines the signature of the startSSE() method for the MCPServer class. This asynchronous method integrates the MCP server with an existing web server to use Server-Sent Events (SSE) for communication. The method takes an object with URL, ssePath, messagePath, req, and res properties as input.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync startSSE({\n  url,\n  ssePath,\n  messagePath,\n  req,\n  res,\n}: {\n  url: URL;\n  ssePath: string;\n  messagePath: string;\n  req: any;\n  res: any;\n}): Promise<void>\n```\n\n----------------------------------------\n\nTITLE: API Method Change: generate/stream to speak\nDESCRIPTION: This snippet describes the consolidation of the `generate()` and `stream()` methods into a single `speak()` method. This change aims to simplify the API of the @mastra/voice-playai package. Existing calls to `generate()` or `stream()` should be replaced with `speak()`.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/playai/CHANGELOG.md#_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Installing the new package\nDESCRIPTION: This command installs the @mastra/voice-playai package using npm. This is the first step in migrating from the deprecated @mastra/speech-playai package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @mastra/voice-playai\"\n```\n\n----------------------------------------\n\nTITLE: Building Mastra Application - Bash\nDESCRIPTION: This command builds a Mastra application. It can be run from the current directory or a specified directory.  The `mastra build` command compiles the application, performs tree-shaking, and bundles the code using Rollup, generating a Hono-based HTTP server in the `.mastra` directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# 現在のディレクトリからビルド\nmastra build\n\n# またはディレクトリを指定\nmastra build --dir ./my-project\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the bias evaluation example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/evals/bias\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server in Windsurf (MacOS/Linux)\nDESCRIPTION: This JSON snippet configures the Model Context Protocol (MCP) server for Mastra documentation tools within the Windsurf IDE on MacOS and Linux systems. It specifies the command to execute the @mastra/mcp-docs-server package using npx.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/README.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Version Changelog in Markdown\nDESCRIPTION: Markdown formatted changelog showing version history from 0.0.1-alpha.0 through 0.0.1, documenting patch changes and dependency updates.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# retrieve-results\n\n## 0.0.1\n\n## 0.0.1-alpha.4\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n- @mastra/vector-pinecone@0.0.1-alpha.20\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n- @mastra/vector-pinecone@0.0.1-alpha.19\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- Updated dependencies [cf4c02c]\n  - @mastra/vector-pinecone@0.0.1-alpha.18\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [78eec7c]\n- Updated dependencies [9625602]\n  - @mastra/vector-pinecone@0.0.1-alpha.17\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Composing Complete Prompt Templates with TypeScript\nDESCRIPTION: This snippet shows how to put together a complete bug report prompt template utilizing various elements like persona, context, constraints, and examples. It highlights usage with dynamic variables for severity and component details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ntype BugReportVars = {\n  severity: string;\n  component: string;\n};\n\nconst bugReportTemplate = createPrompt<BugReportVars>('Create bug report', {\n  persona: 'QA Engineer',\n  outputFormat: 'markdown',\n})\n  .context('We use GitHub issues for tracking bugs')\n  .constraints(['Be specific and actionable', 'Include reproduction steps'])\n  .examples([\n    {\n      input: \"Login button doesn't work\",\n      output: '## Login Authentication Failure\\n1. Steps to reproduce...',\n    },\n  ])\n  .text('Create a {{severity}} bug report for {{component}} issue');\n\n// Usage examples\nconst reportString = bugReportTemplate.toString({\n  severity: 'high',\n  component: 'checkout',\n});\n\nconst reportMessage = bugReportTemplate.toMessage({\n  severity: 'high',\n  component: 'checkout',\n});\n```\n\n----------------------------------------\n\nTITLE: Adding CommonJS Support in Changelog\nDESCRIPTION: Documents the addition of support for CommonJS (CJS) modules, enabling compatibility with a broader range of JavaScript environments.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n- bb4f447: Add support for commonjs\n```\n\n----------------------------------------\n\nTITLE: Configuring Next.js for Mastra Integration\nDESCRIPTION: This code configures the Next.js application to include external packages required by Mastra. It sets the serverExternalPackages option in next.config.js to allow the @mastra/* packages to be used on the server side. This is necessary for the direct integration method.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/frameworks/next-js.mdx#_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  serverExternalPackages: [\"@mastra/*\"],\n  // ... その他のNext.js設定\n}\n\nmodule.exports = nextConfig\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Mastra AI repository and navigate to the hierarchical multi-agent example directory. These steps prepare the local environment for running the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/agents/hierarchical-multi-agent\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the embedding example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/embed-chunk-array\n```\n\n----------------------------------------\n\nTITLE: Installing MastraClient Package\nDESCRIPTION: Commands to install the Mastra client JavaScript package using different package managers.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/client-js\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @mastra/client-js\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @mastra/client-js\n```\n\n----------------------------------------\n\nTITLE: Version Changes Log in Markdown\nDESCRIPTION: A markdown changelog showing version history from 0.0.1-alpha.0 to 0.0.1, documenting patch changes and dependency updates with @mastra/rag package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere/CHANGELOG.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# embed-text-with-cohere\n\n## 0.0.1\n\n## 0.0.1-alpha.3\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.77\n\n## 0.0.1-alpha.2\n\n### Patch Changes\n\n- Updated dependencies [f646a8b]\n  - @mastra/rag@0.0.2-alpha.76\n\n## 0.0.1-alpha.1\n\n### Patch Changes\n\n- @mastra/rag@0.0.2-alpha.75\n\n## 0.0.1-alpha.0\n\n### Patch Changes\n\n- Updated dependencies [9625602]\n  - @mastra/rag@0.0.2-alpha.74\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server in Windsurf (Windows)\nDESCRIPTION: This JSON snippet configures the Model Context Protocol (MCP) server for Mastra documentation tools within the Windsurf IDE on Windows systems. It uses the 'cmd' command to execute the @mastra/mcp-docs-server package with npx.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/README.md#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"mastra\": {\n      \"command\": \"cmd\",\n      \"args\": [\"/c\", \"npx\", \"-y\", \"@mastra/mcp-docs-server@latest\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Workflow-Level Retry with Step Override in Mastra\nDESCRIPTION: This code demonstrates how to configure workflow-level retry settings and then override them at the step level for specific steps. It showcases a workflow with a default retry policy, a step that uses the default, a step that overrides the default with more retries and longer delay, and a step that disables retries entirely.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/workflows/step-retries.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Workflow, Step } from '@mastra/core/workflows';\n\n// デフォルトのリトライ設定を持つワークフローを作成\nconst workflow = new Workflow({\n  name: 'multi-retry-workflow',\n  retryConfig: {\n    attempts: 2,  // すべてのステップはデフォルトで2回リトライ\n    delay: 1000,  // 1秒の遅延で\n  },\n});\n\n// このステップはワークフローのデフォルトのリトライ設定を使用\nconst standardStep = new Step({\n  id: 'standardStep',\n  execute: async () => {\n    // 失敗する可能性のある操作\n  },\n});\n\n// このステップはワークフローのリトライ設定をオーバーライド\nconst criticalStep = new Step({\n  id: 'criticalStep',\n  execute: async () => {\n    // より多くのリトライ試行が必要な重要な操作\n  },\n  retryConfig: {\n    attempts: 5,  // 5回のリトライ試行でオーバーライド\n    delay: 5000,  // より長い5秒の遅延\n  },\n});\n\n// このステップはリトライを無効にする\nconst noRetryStep = new Step({\n  id: 'noRetryStep',\n  execute: async () => {\n    // リトライしないべき操作\n  },\n  retryConfig: {\n    attempts: 0,  // リトライを明示的に無効化\n  },\n});\n\nworkflow\n  .step(standardStep)\n  .then(criticalStep)\n  .then(noRetryStep)\n  .commit();\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_9\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/travel-ai\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Multi-Agent AI Travel Planning with Mastra</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Multi-Agent AI Travel Planning with Mastra</h2><span class=\"text-xs text-left text-text-3\">Jan 28, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Jan 28, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Implementing Usage Example in TypeScript\nDESCRIPTION: Demonstrates how to provide a concise example showing how to import and use a Mastra function in a typical project.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/reference-guide.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MyFunction } from \"@mastra/core\";\n\nconst result = MyFunction({\n  data: \"some data\",\n  options: {\n    verbose: true,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Updating CJS Bundling in Changelog\nDESCRIPTION: Documents the update to CommonJS (CJS) bundling to ensure proper file splitting, enhancing module loading and performance.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n- fd4a1d7: Update cjs bundling to make sure files are split\n```\n\n----------------------------------------\n\nTITLE: Combine Upstash Packages\nDESCRIPTION: This minor change combines Upstash packages into a single `@mastra/upstash` package. It reorganizes source files, adds deprecation notices to old packages, updates documentation, and does not introduce any breaking changes to functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nc87eb4e: Combine Upstash packages into `@mastra/upstash`.\n\n  - Move and combine packages to `stores/upstash`\n  - Reorganize source files into `src/vector` and `src/store`\n  - Add deprecation notices to old packages\n  - Update documentation and examples\n  - No breaking changes in functionality\n```\n\n----------------------------------------\n\nTITLE: Markdown License Documentation\nDESCRIPTION: Complete text of the Elastic License 2.0 (ELv2) formatted in Markdown, detailing terms of use, restrictions, and legal obligations for software usage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/deployer/LICENSE.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Elastic License 2.0 (ELv2)\n\nCopyright (c) 2025 Mastra AI, Inc.\n\n**Acceptance**\nBy using the software, you agree to all of the terms and conditions below.\n\n**Copyright License**\nThe licensor grants you a non-exclusive, royalty-free, worldwide, non-sublicensable, non-transferable license to use, copy, distribute, make available, and prepare derivative works of the software, in each case subject to the limitations and conditions below\n\n**Limitations**\nYou may not provide the software to third parties as a hosted or managed service, where the service provides users with access to any substantial set of the features or functionality of the software.\n\nYou may not move, change, disable, or circumvent the license key functionality in the software, and you may not remove or obscure any functionality in the software that is protected by the license key.\n\nYou may not alter, remove, or obscure any licensing, copyright, or other notices of the licensor in the software. Any use of the licensor's trademarks is subject to applicable law.\n\n**Patents**\nThe licensor grants you a license, under any patent claims the licensor can license, or becomes able to license, to make, have made, use, sell, offer for sale, import and have imported the software, in each case subject to the limitations and conditions in this license. This license does not cover any patent claims that you cause to be infringed by modifications or additions to the software. If you or your company make any written claim that the software infringes or contributes to infringement of any patent, your patent license for the software granted under these terms ends immediately. If your company makes such a claim, your patent license ends immediately for work on behalf of your company.\n\n**Notices**\nYou must ensure that anyone who gets a copy of any part of the software from you also gets a copy of these terms.\n\nIf you modify the software, you must include in any modified copies of the software prominent notices stating that you have modified the software.\n\n**No Other Rights**\nThese terms do not imply any licenses other than those expressly granted in these terms.\n\n**Termination**\nIf you use the software in violation of these terms, such use is not licensed, and your licenses will automatically terminate. If the licensor provides you with a notice of your violation, and you cease all violation of this license no later than 30 days after you receive that notice, your licenses will be reinstated retroactively. However, if you violate these terms after such reinstatement, any additional violation of these terms will cause your licenses to terminate automatically and permanently.\n\n**No Liability**\nAs far as the law allows, the software comes as is, without any warranty or condition, and the licensor will not be liable to you for any damages arising out of these terms or the use or nature of the software, under any kind of legal claim.\n\n**Definitions**\nThe _licensor_ is the entity offering these terms, and the _software_ is the software the licensor makes available under these terms, including any portion of it.\n\n_you_ refers to the individual or entity agreeing to these terms.\n\n_your company_ is any legal entity, sole proprietorship, or other kind of organization that you work for, plus all organizations that have control over, are under the control of, or are under common control with that organization. _control_ means ownership of substantially all the assets of an entity, or the power to direct its management and policies by vote, contract, or otherwise. Control can be direct or indirect.\n\n_your licenses_ are all the licenses granted to you for the software under these terms.\n\n_use_ means anything you do with the software requiring one of your licenses.\n\n_trademark_ means trademarks, service marks, and similar rights.\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Command to copy the example environment file to create a local .env file.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/hallucination/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Voice with Default Settings - TypeScript\nDESCRIPTION: This snippet shows the simplified initialization of the OpenAIVoice provider, using the default settings provided by the voice provider. It showcases that the `listeningModel` configuration is optional if the default settings are sufficient.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/speech-to-text.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// デフォルト設定を使用する場合、設定は以下のように簡略化できます：\nconst voice = new OpenAIVoice();\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm in Bash\nDESCRIPTION: Command to install the required dependencies using pnpm package manager. This must be executed after cloning the repository and before running the example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/content-similarity/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Retrieving Threads by Resource ID in TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve threads associated with a specific resource ID using the `getThreadsByResourceId` method of the `Memory` class.  It initializes a Memory object and then calls the method with a resource ID.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/getThreadsByResourceId.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Memory } from \"@mastra/core/memory\";\n\nconst memory = new Memory(config);\n\nconst threads = await memory.getThreadsByResourceId({\n  resourceId: \"resource-123\",\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for OpenAI and Postgres\nDESCRIPTION: Example of environment variable configuration needed for the project, including OpenAI API key and Postgres connection string.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cleanup-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=sk-your-api-key-here\nPOSTGRES_CONNECTION_STRING=your-postgres-connection-string-here\n```\n\n----------------------------------------\n\nTITLE: Running Token Limiting Test\nDESCRIPTION: Command to execute the extreme token limiting stress test demo.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm run tokens\n```\n\n----------------------------------------\n\nTITLE: Displaying a Blog Post Link\nDESCRIPTION: This HTML snippet defines the structure for displaying a single blog post link. It includes the post title, a hidden title for medium-sized displays, publication date, and author image, all wrapped within a link that directs to the full blog post.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/mcp-docs-server/src/tools/__fixtures__/blog-list-raw.txt#2025-04-22_snippet_5\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"lg:hover:bg-bg-2 rounded-lg\"><a class=\"group flex items-center justify-between  md:px-2 py-3 transition-colors \" href=\"/blog/changelog-2025-02-10\"><h2 class=\"font-medium hidden max-w-[330px] md:max-w-none text-sm md:flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-02-10</h2><div class=\"items-start flex md:hidden flex-col w-fit\"><h2 class=\"font-medium line-clamp-3 max-w-[330px] lg:line-clamp-none text-sm flex flex-wrap lg:basis-[300px] text-left  text-white group-hover:text-gray-100\">Mastra Changelog 2025-02-10</h2><span class=\"text-xs text-left text-text-3\">Feb 11, 2025</span></div><div class=\"flex items-center gap-8\"><span class=\"text-xs hidden lg:block text-text-3\">Feb 11, 2025</span><span class=\"relative flex shrink-0 overflow-hidden rounded-full size-5\"><img class=\"aspect-square h-full w-full\" loading=\"eager\" src=\"/authors/calcsam.jpeg\"></span></div></a></div>\n```\n\n----------------------------------------\n\nTITLE: Single Dependency Workflow with .after() in Typescript\nDESCRIPTION: This snippet demonstrates a workflow where `logData` is executed after `fetchData` completes, showcasing a single dependency using `.after()`. It shows a basic branching example.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/after.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nworkflow\n  .step(fetchData)\n  .then(processData)\n  .after(fetchData)  // Branch after fetchData\n  .step(logData);\n```\n\n----------------------------------------\n\nTITLE: Implementing Thought Breakdown Step\nDESCRIPTION: Defines the second step in the workflow for breaking down the thinking process based on the initial analysis.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst breakdownThoughts = new Step({\n  id: \"breakdownThoughts\",\n  outputSchema: z.object({\n    breakdown: z.string(),\n  }),\n  execute: async ({ context, mastra }) => {\n    console.log(\"---------------------------\");\n    const ragAgent = mastra?.getAgent('ragAgent');\n    const analysis = context?.getStepResult<{\n      initialAnalysis: string;\n    }>(\"analyzeContext\")?.initialAnalysis;\n\n    const connectionPrompt = `\n      Based on the initial analysis: ${analysis}\n\n      2. Break down your thinking process about how the retrieved information relates to the query.\n    `;\n\n    const connectionAnalysis = await ragAgent?.generate(connectionPrompt);\n    console.log(connectionAnalysis?.text);\n    return {\n      breakdown: connectionAnalysis?.text ?? \"\",\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Renaming and Combining Methods in Changelog\nDESCRIPTION: Documents the merging of the `generate()` and `stream()` methods into the `speak()` method within the API updates of `@mastra/voice-murf` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/murf/CHANGELOG.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n- `generate()` and `stream()` methods combined into `speak()`\n```\n\n----------------------------------------\n\nTITLE: Installing Mastra Loggers Package\nDESCRIPTION: Command to install the @mastra/loggers package using npm package manager.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/loggers/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/loggers\n```\n\n----------------------------------------\n\nTITLE: Cloning the Mastra Repository\nDESCRIPTION: Commands to clone the Mastra repository and navigate to the markdown chunking example directory.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-markdown/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mastra-ai/mastra\ncd examples/basics/rag/chunk-markdown\n```\n\n----------------------------------------\n\nTITLE: Registering Custom API Route in Mastra - TypeScript\nDESCRIPTION: This code shows how to register a custom API route within a Mastra instance. It defines a GET route at `/my-custom-route` with a handler that accesses the Mastra instance and returns a JSON response. This demonstrates how to extend the server with custom endpoints that interact with the Mastra core functionality.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/deployment/server.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Mastra } from \"@mastra/core\";\nimport { registerApiRoute } from \"@mastra/core/server\";\n\nexport const mastra = new Mastra({\n  server: {\n    apiRoutes: [\n      registerApiRoute(\"/my-custom-route\", {\n        method: \"GET\",\n        handler: async (c) => {\n          // you have access to mastra instance here\n          const mastra = c.get(\"mastra\");\n\n          // you can use the mastra instance to get agents, workflows, etc.\n          const agents = await mastra.getAgent(\"my-agent\");\n\n          return c.json({ message: \"Hello, world!\" });\n        },\n      }),\n    ],\n  },\n  // Other configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVector and Mastra Instances\nDESCRIPTION: Creates instances of PgVector and Mastra, configuring them with the previously defined agent and vector storage.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/graph-rag.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);\n\nexport const mastra = new Mastra({\n  agents: { ragAgent },\n  vectors: { pgVector },\n});\nconst agent = mastra.getAgent(\"ragAgent\");\n```\n\n----------------------------------------\n\nTITLE: Creating MDocument from Text (Static Method)\nDESCRIPTION: Creates an MDocument instance from plain text content. Takes a text string and an optional metadata object as input. Returns an MDocument object.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/document.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nstatic fromText(text: string, metadata?: Record<string, any>): MDocument\n```\n\n----------------------------------------\n\nTITLE: Update Imports (New)\nDESCRIPTION: This snippet shows the new import statement using @mastra/voice-google. It imports the GoogleVoice class.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/google/README.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// New\nimport { GoogleVoice } from '@mastra/voice-google';\n```\n\n----------------------------------------\n\nTITLE: AgentNetwork Changeset\nDESCRIPTION: This code snippet introduces changes related to the AgentNetwork. It likely signifies updates or modifications to the AgentNetwork component, potentially adding new features, fixing bugs, or improving performance. It's an identifier for a set of related code modifications.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/cloudflare/CHANGELOG.md#_snippet_5\n\nLANGUAGE: TEXT\nCODE:\n```\n404640e: AgentNetwork changeset\n```\n\n----------------------------------------\n\nTITLE: Configuring Vitest for Global and Test Setup\nDESCRIPTION: This TypeScript snippet configures Vitest to use the specified global setup and test setup files. It imports `defineConfig` from `vitest/config` and defines a configuration object with `globalSetup` pointing to './globalSetup.ts' and `setupFiles` pointing to './testSetup.ts'. This ensures that these setup scripts are executed before the tests run.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/evals/running-in-ci.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { defineConfig } from 'vitest/config'\n\nexport default defineConfig({\n  test: {\n    globalSetup: './globalSetup.ts',\n    setupFiles: ['./testSetup.ts'],\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Qdrant Package Removal\nDESCRIPTION: Removes the old Qdrant package `@mastra/vector-qdrant` using `pnpm`. This step is part of the migration process to the new `@mastra/qdrant` package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/qdrant/CHANGELOG.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm remove @mastra/vector-qdrant\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entry 1.0.1-alpha.45\nDESCRIPTION: Changelog entry documenting multiple dependency updates for alpha version 45\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-upstash/CHANGELOG.md#2025-04-22_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [30322ce]\n- Updated dependencies [78eec7c]\n- Updated dependencies [72f7fb9]\n- Updated dependencies [c35aa18]\n- Updated dependencies [9625602]\n- Updated dependencies [bbe0c19]\n- Updated dependencies [8769a62]\n  - @mastra/memory@0.1.0-alpha.65\n  - @mastra/store-upstash@0.0.0-alpha.1\n  - @mastra/core@0.2.0-alpha.83\n  - @mastra/vector-pg@0.0.1-alpha.17\n```\n\n----------------------------------------\n\nTITLE: Install Memory Package (npm)\nDESCRIPTION: This command installs the @mastra/memory package using npm. This package provides the necessary functionality for implementing memory processors.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mastra/memory\n```\n\n----------------------------------------\n\nTITLE: Updating imports for PlayAIVoice\nDESCRIPTION: This code snippet illustrates the required changes to import statements when migrating from PlayAITTS to PlayAIVoice. It demonstrates how to replace the import statement from the deprecated package with the correct import from the new package.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n\"- import { PlayAITTS } from '@mastra/speech-playai'\\n+ import { PlayAIVoice } from '@mastra/voice-playai'\"\n```\n\n----------------------------------------\n\nTITLE: Listing available voices with PlayAITTS\nDESCRIPTION: This TypeScript code snippet shows how to retrieve a list of available voices using the `voices()` method of the PlayAITTS class. It assumes that the `tts` object has already been initialized.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n\"// List available voices\\nconst voices = await tts.voices();\"\n```\n\n----------------------------------------\n\nTITLE: Cloudflare Vector Store Error Handling\nDESCRIPTION: Illustrates how to handle errors thrown by the CloudflareVector store using a try-catch block. It checks if the error is an instance of VectorStoreError and logs the error code and details.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/rag/vectorize.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  await store.query({\n    indexName: \"index_name\",\n    queryVector: queryVector,\n  });\n} catch (error) {\n  if (error instanceof VectorStoreError) {\n    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc\n    console.log(error.details); // 追加のエラーコンテキスト\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a File Logger with FileTransport in TypeScript\nDESCRIPTION: This example illustrates the creation of a file logger using `createLogger()` and `FileTransport`. It configures the logger to write structured logs to a file, setting the log level to 'warn' and specifying the file path. Requires the `@mastra/loggers/file` module.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/observability/create-logger.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { FileTransport } from \"@mastra/loggers/file\";\n\nconst fileLogger = createLogger({\n  name: \"Mastra\",\n  transports: { file: new FileTransport({ path: \"test-dir/test.log\" }) },\n  level: \"warn\",\n});\nfileLogger.warn(\"Low disk space\", {\n  destinationPath: \"system\",\n  type: \"WORKFLOW\",\n});\n```\n\n----------------------------------------\n\nTITLE: Update Tests\nDESCRIPTION: This patch updates the tests for Upstash and Astra. It ensures that the tests are up-to-date and accurately reflect the current functionality of these integrations.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/upstash/CHANGELOG.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nc4fdac3: Updated tests for upstash and astra\n```\n\n----------------------------------------\n\nTITLE: Default Vercel.json Configuration\nDESCRIPTION: Default configuration for vercel.json that defines the build settings, routes, and Node.js configuration for a Mastra application deployment.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/deployers/vercel/README.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"version\": 2,\n  \"installCommand\": \"npm install --omit=dev\",\n  \"builds\": [\n    {\n      \"src\": \"index.mjs\",\n      \"use\": \"@vercel/node\",\n      \"config\": {\n        \"includeFiles\": [\"**\"]\n      }\n    }\n  ],\n  \"routes\": [\n    {\n      \"src\": \"/(.*)\",\n      \"dest\": \"index.mjs\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Initialize GoogleTTS (Old)\nDESCRIPTION: This snippet shows how to initialize the GoogleTTS class from the old @mastra/speech-google package. It sets the model name and API key.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/google/README.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Old\nconst tts = new GoogleTTS({\n  model: {\n    name: 'en-US-Standard-C',\n    apiKey: 'your-api-key',\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing PlayAITTS with configuration\nDESCRIPTION: This code snippet demonstrates initializing the PlayAITTS class with a configuration object. The configuration specifies the voice model name and optionally the API key. The API key can also be set using the PLAYAI_API_KEY environment variable.\nSOURCE: https://github.com/mastra-ai/mastra/blob/main/speech/playai/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { PlayAITTS } from '@mastra/speech-playai';\\n\\n// Initialize with configuration\\nconst tts = new PlayAITTS({\\n  model: {\\n    name: 'en-US-1', // Default voice\\n    apiKey: 'your-api-key', // Optional, can use PLAYAI_API_KEY env var\\n  },\\n});\"\n```"
  }
]