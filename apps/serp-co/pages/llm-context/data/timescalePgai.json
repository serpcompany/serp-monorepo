[
  {
    "owner": "timescale",
    "repo": "pgai",
    "content": "TITLE: Using the text_to_sql Function\nDESCRIPTION: Example of using the text_to_sql function to convert a natural language query into SQL, along with how to enable debug messages to see the underlying prompts and LLM responses.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.text_to_sql('show me the average order cost by day in November');\n\n/*\n             query             \n-------------------------------\nselect\n  date_trunc('day', o.dt) as day\n, avg(o.cost) as avg_cost\nfrom orders o\nwhere '2024-11-01'::date <= o.dt\nand o.dt < '2024-12-01'::date\ngroup by 1\norder by 1\n(1 row)\n*/\n\n```\n\n----------------------------------------\n\nTITLE: Filtering Vectorizers with Pending Items in SQL\nDESCRIPTION: Example of querying the ai.vectorizer_status view to identify vectorizers that have items waiting to be processed.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.vectorizer_status WHERE pending_items > 0;\n```\n\n----------------------------------------\n\nTITLE: Generating and Executing SQL using ai.text_to_sql and \\gexec (SQL/psql)\nDESCRIPTION: Uses the `ai.text_to_sql` function to generate an SQL query from a natural language question. Instead of just displaying the query, the `psql` metacommand `\\gexec` is used immediately afterward to execute the generated SQL statement directly, returning the query's result.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nselect ai.text_to_sql('How many flights arrived at the IAH airport in June 2024?')\n\\gexec\n```\n```\n\n----------------------------------------\n\nTITLE: Defining a RAG Function in PostgreSQL using pgai (PL/pgSQL)\nDESCRIPTION: Shows the creation of a PL/pgSQL function `generate_rag_response` that implements Retrieval-Augmented Generation (RAG). The function takes a query text, performs a similarity search using `ai.ollama_embed` on the `blogs_embedding` table to find relevant context chunks, aggregates these chunks, and then calls `ai.ollama_chat_complete` with a system prompt, the user query, and the retrieved context to generate a response using the 'llama3' model.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION generate_rag_response(query_text TEXT)\nRETURNS TEXT AS $$\nDECLARE\n   context_chunks TEXT;\n   response TEXT;\nBEGIN\n   -- Perform similarity search to find relevant blog posts\n   SELECT string_agg(title || ': ' || chunk, E'\\n') INTO context_chunks\n   FROM\n   (\n       SELECT title, chunk\n       FROM blogs_embedding\n       ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n       LIMIT 3\n   ) AS relevant_posts;\n\n   -- Generate a summary using llama3\n   SELECT ai.ollama_chat_complete\n   ( 'llama3'\n   , jsonb_build_array\n     ( jsonb_build_object('role', 'system', 'content', 'you are a helpful assistant')\n     , jsonb_build_object\n       ('role', 'user'\n       , 'content', query_text || E'\\nUse the following context to respond.\\n' || context_chunks\n       )\n     )\n   )->'message'->>'content' INTO response;\n\n   RETURN response;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Creating RAG Response Function in PostgreSQL\nDESCRIPTION: SQL function that performs RAG by combining vector similarity search with LLM-based response generation using Ollama. It retrieves relevant context chunks and generates responses based on the query.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION generate_rag_response(query_text TEXT)\nRETURNS TEXT AS $$\nDECLARE\n    context_chunks TEXT;\n    response JSONB;\nBEGIN\n    -- Perform similarity search to find relevant wiki article\n    SELECT string_agg(title || ': ' || chunk, E'\\n') INTO context_chunks\n    FROM\n    (\n        SELECT title, chunk\n        FROM wiki_embeddings \n        ORDER BY embedding <=> ai.ollama_embed('all-minilm', query_text)\n        LIMIT 3\n    ) AS relevant_posts;\n\n    raise notice 'Context provided to LLM: %', context_chunks;\n\n    -- Generate a summary using tinyllama\n    select ai.ollama_generate('tinyllama', \n    query_text || E'\\nUse the following context to respond.\\n' || context_chunks) INTO response;\n\n    RETURN response->>'response';\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with Ollama Embedding in SQL\nDESCRIPTION: This SQL snippet illustrates the creation of a vectorizer leveraging the Ollama API for embedding. It utilizes the ai.embedding_ollama function to define parameters like the model name and dimensions. The base_url parameter sets the API access endpoint, and additional model-specific options can be specified using a JSON object.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_ollama(\n      'nomic-embed-text',\n      768,\n      base_url => \"http://my.ollama.server:443\"\n      options => '{ \"num_ctx\": 1024 }',\n      keep_alive => \"10m\"\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Catalog with OpenAI\nDESCRIPTION: SQL command to create a semantic catalog using OpenAI's embedding and text-to-SQL models, configuring both the embedding and query generation components.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -f - <<EOF\nselect ai.create_semantic_catalog\n( embedding=>ai.embedding_openai('text-embedding-3-small', 1024)\n, text_to_sql=>ai.text_to_sql_openai(model=>'o3-mini')\n);\nEOF\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search in PostgreSQL using pgai (SQL)\nDESCRIPTION: Illustrates how to perform a semantic search query in PostgreSQL using pgai. The query selects chunks from an embedding table and calculates the vector distance (`<=>`) between each chunk's embedding and the embedding of a query string generated by `ai.ollama_embed` (using a specified embedding model). Results are ordered by distance to find the most semantically similar chunks.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n   chunk,\n   embedding <=> ai.ollama_embed(<embedding_model>, 'some-query') as distance\nFROM <embedding_table>\nORDER BY distance\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating a Vectorizer with Ollama Embedding in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a vectorizer for a blog table using the ai.create_vectorizer function. It configures the embedding model, chunking strategy, formatting template, and access permissions.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'website.blog'::regclass,\n    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n    chunking => ai.chunking_character_text_splitter('body', 128, 10),\n    formatting => ai.formatting_python_template('title: $title published: $published $chunk'),\n    grant_to => ai.grant_to('bob', 'alice')\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Catalog with Different Provider Configurations\nDESCRIPTION: Examples of creating a semantic catalog with various combinations of embedding and text-to-SQL providers. Shows how to configure OpenAI, Anthropic, VoyageAI, and Ollama as providers with different models.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- OpenAI embeddings and OpenAI o1 completions\nselect ai.create_semantic_catalog(\n  embedding=>ai.embedding_openai('text-embedding-3-small', 768)\n, text_to_sql=>ai.text_to_sql_openai(model=>'o1')\n);\n\n-- OpenAI embeddings + Claude 3.5 Sonnet completions\nselect ai.create_semantic_catalog(\n  embedding=>ai.embedding_openai('text-embedding-3-small', 768)\n, text_to_sql=>ai.text_to_sql_anthropic(model=>'claude-3-5-sonnet-latest')\n);\n\n-- Voyage embeddings + Claude 3.5 Sonnet completions\nselect ai.create_semantic_catalog(\n  embedding=>ai.embedding_voyageai('voyage-3-lite', 512)\n, text_to_sql=>ai.text_to_sql_anthropic(model=>'claude-3-5-sonnet-latest')\n);\n\n-- Ollama embeddings + OpenAI o1 completions\nselect ai.create_semantic_catalog\n( embedding=>ai.embedding_ollama\n    ( 'nomic-embed-text'\n    , 768\n    , base_url=>'http://host.docker.internal:11434'\n    )\n, text_to_sql=>ai.text_to_sql_openai(model=>'o1')\n);\n```\n\n----------------------------------------\n\nTITLE: Installing or Updating pgai Extension with Text to SQL Feature\nDESCRIPTION: SQL commands to install the pgai extension for the first time or update an existing installation. Requires enabling the text_to_sql feature flag before creating or updating the extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n/*\n * If it's your first time installing pgai\n */\n\nselect set_config('ai.enable_feature_flag_text_to_sql', 'true', false);\ncreate extension if not exists ai cascade;\n\n/*\n * If you already have pgai, update it\n */ \n\nselect set_config('ai.enable_feature_flag_text_to_sql', 'true', false);\nalter extension ai update;\n```\n\n----------------------------------------\n\nTITLE: Querying Vector Embeddings with Distance Calculation\nDESCRIPTION: SQL query to search for similar content using vector embeddings, ordered by distance metric.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT \n   chunk,\n   embedding <=> ai.ollama_embed('nomic-embed-text', <query>) as distance\nFROM blog_contents_embeddings\nORDER BY distance\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Querying with text-to-SQL for Houston flights\nDESCRIPTION: Example of using pgai's text_to_sql function to convert a natural language question about flights to Houston into a SQL query, demonstrating the core functionality of the extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.text_to_sql('How many flights arrived in Houston, TX in June 2024?');\n```\n\n----------------------------------------\n\nTITLE: Generating Article Summary with SQL\nDESCRIPTION: SQL query that uses Ollama to generate a summary of wiki articles stored in the database.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT answer->>'response' as summary\nFROM ai.ollama_generate('tinyllama', \n'Summarize the following and output the summary in a single sentence: '|| (SELECT text FROM wiki WHERE title like 'pgai%')) as answer;\n```\n\n----------------------------------------\n\nTITLE: Configuring DiskANN Indexing\nDESCRIPTION: Demonstrates configuring AI indexing using the DiskANN algorithm, which is optimized for large datasets stored on disk and enabling high-performance approximate searches.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    indexing => ai.indexing_diskann(min_rows => 500000, storage_layout => 'memory_optimized'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with Context Formatting\nDESCRIPTION: SQL query to create a vectorizer that includes title context in each chunk using Python template formatting.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(   \n    'blog'::regclass,\n    destination => 'blog_contents_embeddings',\n    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n    chunking => ai.chunking_recursive_character_text_splitter('contents'),\n    formatting => ai.formatting_python_template('$title: $chunk')\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Automatic Vectorizer in PostgreSQL using pgai (SQL)\nDESCRIPTION: Demonstrates how to create a pgai vectorizer using the `ai.create_vectorizer` function. This function sets up automatic generation and synchronization of vector embeddings for a specified table column. It requires the source table name, a destination table name for embeddings, an embedding function (e.g., `ai.embedding_ollama` specifying model and dimensions), and a chunking strategy (e.g., `ai.chunking_recursive_character_text_splitter` for a text column).\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    <table_name>::regclass,\n    destination => <embedding_table_name>,\n    embedding => ai.embedding_ollama(<model_name>, <dimensions>),\n    chunking => ai.chunking_recursive_character_text_splitter(<column_name>)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring HNSW Indexing\nDESCRIPTION: Configures AI indexing using the HNSW algorithm for efficient nearest neighbor search, particularly suited for in-memory datasets where speed is crucial.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    indexing => ai.indexing_hnsw(min_rows => 50000, opclass => 'vector_l1_ops'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Executing a RAG Function in PostgreSQL (SQL)\nDESCRIPTION: Demonstrates how to execute the previously defined `generate_rag_response` PL/pgSQL function within a standard SQL query to get an AI-generated response based on retrieved context.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT generate_rag_response('Give me some startup advice');\n```\n\n----------------------------------------\n\nTITLE: Chat completion with custom parameters using Ollama in SQL\nDESCRIPTION: SQL query using ai.ollama_chat_complete to generate a chat completion with custom LLM parameters and displaying the full JSON response.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- the following two metacommands cause the raw query results to be printed\n-- without any decoration\n\\pset tuples_only on\n\\pset format unaligned\n\nselect jsonb_pretty(\n  ai.ollama_chat_complete\n  ( 'llama3'\n  , jsonb_build_array\n    ( jsonb_build_object('role', 'system', 'content', 'you are a helpful assistant')\n    , jsonb_build_object('role', 'user', 'content', 'Give a short description of what a large language model is')\n    )\n  , chat_options=> jsonb_build_object\n    ( 'seed', 42\n    , 'temperature', 0.6\n    )\n  )\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Ollama Chat Completion with Function Tools in SQL\nDESCRIPTION: Executes a SQL query that calls ai.ollama_chat_complete with a tools parameter defining a custom function 'get_current_weather'. This enables the LLM to respond with a tool call, allowing structured function invocation. Requires the pgAI extension and an appropriately configured Ollama endpoint; expects JSONB input for chat history and tools, returning LLM tool_call responses.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nselect ai.ollama_chat_complete\n( 'llama3.2:1b'\n, $json$[{\"role\": \"user\", \"content\": \"What is the weather today in Birmingham, Alabama?\"}]$json$::jsonb\n, tools=> $json$\n      [\n        {\n          \"type\": \"function\",\n          \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather for a location\",\n            \"parameters\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"location\": {\n                  \"type\": \"string\",\n                  \"description\": \"The location to get the weather for, e.g. San Francisco, CA\"\n                },\n                \"format\": {\n                  \"type\": \"string\",\n                  \"description\": \"The format to return the weather in, e.g. 'celsius' or 'fahrenheit'\",\n                  \"enum\": [\"celsius\", \"fahrenheit\"]\n                }\n              },\n              \"required\": [\"location\", \"format\"]\n            }\n          }\n        }\n      ]\n  $json$::jsonb\n)->'message'->'tool_calls'\n```\n\n----------------------------------------\n\nTITLE: Auto-generating Descriptions with LLMs\nDESCRIPTION: SQL commands to automatically generate descriptions for database objects using LLMs. This allows generating and optionally saving descriptions for tables, columns, and functions without writing them manually.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Generate a description for the `orders` table and print it\nselect ai.generate_description('orders');\n\n-- Generate a description for the `orders` table, print it, and save it to the semantic catalog\n-- If a description already exists, it will not overwrite\nselect ai.generate_description('orders', save => true);\n\n-- Will save and overwrite the existing description\nselect ai.generate_description('orders', save => true, overwrite => true);\n\n-- Generate and save descriptions for each column in the `orders` table\nselect ai.generate_column_descriptions('orders', save => true);\n\n-- Generate and save a description for your `myfunc` function\nselect ai.generate_function_description('myfunc'::regproc, save => true);\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search on Embedded Blog Contents\nDESCRIPTION: This SQL query performs a semantic search on the embedded blog contents, comparing them to the embedding of the phrase 'good food' and ordering the results by similarity.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    chunk,\n    embedding <=>  ai.openai_embed('text-embedding-3-small', 'good food', dimensions=>768) as distance\nFROM blog_contents_embeddings\nORDER BY distance;\n```\n\n----------------------------------------\n\nTITLE: Executing Cohere Chat Complete Function in SQL\nDESCRIPTION: Example SQL query that uses the cohere_chat_complete function to generate a response to a natural language question with specific parameters for controlling the output.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.cohere_chat_complete\n( 'command-r-plus'\n, jsonb_build_array\n  ( jsonb_build_object\n    ( 'role', 'user'\n    , 'content', 'How much wood would a woodchuck chuck if a woodchuck could chuck wood?'\n    )\n  )\n, seed=>42\n, temperature=>0.0\n)->>'message'->'content'->0->>'text'\n;\n```\n\n----------------------------------------\n\nTITLE: Querying Vectorizer Status\nDESCRIPTION: Monitors the vectorizer's status by checking pending items and related metadata from the vectorizer_status view.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.vectorizer_status;\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG in Python\nDESCRIPTION: Complete Python script that implements RAG functionality using PostgreSQL and Ollama, including database connection, embedding generation, and response generation.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg\nfrom pgvector.psycopg import register_vector\nfrom typing import Optional, List, NamedTuple\nfrom ollama import Client\nfrom dataclasses import dataclass\n\n@dataclass\nclass ChunkData:\n    \"\"\"Represents a chunk of text with its title and content.\"\"\"\n    title: str\n    chunk: str\n\ndef create_db_connection() -> psycopg.Connection:\n    \"\"\"Create and return a database connection.\"\"\"\n    conn = psycopg.connect(\n        \"postgres://postgres:postgres@localhost:5432/postgres\"\n        # Modify connection string as needed for your setup\n    )\n    register_vector(conn)\n    return conn\n\ndef get_embedding(client: Client, text: str) -> list[float]:\n    \"\"\"Get embeddings using Ollama's all-minilm model.\"\"\"\n    response = client.embeddings(model='all-minilm', prompt=text)\n    return response['embedding']\n\ndef get_relevant_chunks(cur: psycopg.Cursor, embedding: list[float], limit: int = 1) -> List[ChunkData]:\n    \"\"\"\n    Retrieve the most relevant chunks based on vector similarity.\n    \n    Args:\n        cur: Database cursor\n        embedding: Query embedding vector\n        limit: Number of chunks to retrieve\n    \n    Returns:\n        List of ChunkData objects containing relevant chunks\n    \"\"\"\n    query = \"\"\"\n    SELECT title, chunk\n    FROM wiki_embeddings \n    ORDER BY embedding <=> %s::vector\n    LIMIT %s\n    \"\"\"\n    \n    cur.execute(query, (embedding, limit))\n    return [ChunkData(title=row[0], chunk=row[1]) for row in cur.fetchall()]\n\ndef format_context(chunks: List[ChunkData]) -> str:\n    \"\"\"\n    Format the chunks into a single context string.\n    \n    Args:\n        chunks: List of ChunkData objects\n    \n    Returns:\n        Formatted context string\n    \"\"\"\n    return \"\\n\\n\".join(f\"{chunk.title}:\\n{chunk.chunk}\" for chunk in chunks)\n\ndef generate_rag_response(query_text: str) -> Optional[str]:\n    \"\"\"\n    Generate a RAG response using pgai, Ollama embeddings, and database content.\n    \n    Args:\n        query_text: The question or query to answer\n    \n    Returns:\n        str: The generated response from the LLM\n    \"\"\"\n    try:\n        # Initialize Ollama client\n        client = Client(host='http://localhost:11434')\n        \n        with create_db_connection() as conn:\n            with conn.cursor() as cur:\n                # Get embeddings for the query using Ollama SDK\n                query_embedding = get_embedding(client, query_text)\n                \n                # Get relevant chunks\n                relevant_chunks = get_relevant_chunks(cur, query_embedding)\n                \n                # Format context\n                context = format_context(relevant_chunks)\n                \n                # Print context for debugging (optional)\n                print(\"Context provided to LLM:\")\n                print(\"------------------------\")\n                print(context)\n                print(\"------------------------\")\n                \n                # Construct prompt with context\n                prompt = f\"\"\"Question: {query_text}\n\nPlease use the following context to provide an accurate response:\n\n{context}\n\nAnswer:\"\"\"\n                \n                # Generate response using Ollama SDK\n                response = client.generate(\n                    model='tinyllama',\n                    prompt=prompt,\n                    stream=False\n                )\n                \n                return response['response']\n                \n    except Exception as e:\n        print(f\"Error generating RAG response: {e}\")\n        return None\n\ndef main():\n    # Example usage\n    questions = [\n        \"What can I use pgai for?\",\n    ]\n    \n    for question in questions:\n        print(\"\\n\" + \"=\"*50)\n        print(f\"Question: {question}\")\n        print(\"-\"*50)\n        \n        response = generate_rag_response(question)\n        if response:\n            print(\"\\nResponse:\")\n            print(response)\n        else:\n            print(\"Failed to generate response\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Converting Text to SQL using ai.text_to_sql (SQL)\nDESCRIPTION: Calls the `ai.text_to_sql` function within PostgreSQL to translate the natural language question \"How many flights arrived at the IAH airport in June 2024?\" into a corresponding SQL query. This relies on the `pgai` extension and a configured LLM (like OpenAI) accessible via the previously set API key.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nselect ai.text_to_sql('How many flights arrived at the IAH airport in June 2024?');\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Embedding\nDESCRIPTION: Example of setting up Azure OpenAI embedding with custom deployment configuration including base URL and API version.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'azure/<deployment name here>',\n      1024,\n      api_key_name => 'AZURE_API_KEY',\n      extra_options => '{\"api_base\": \"<base URL here>\", \"api_version\": \"<version here>\"}'::jsonb\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Managing Database Object Descriptions for Text to SQL\nDESCRIPTION: SQL commands for setting up and managing descriptions for tables, columns, and functions in the semantic catalog. Shows how to add, update, and delete descriptions that help the LLM create accurate queries.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n/*\n * Tables or views\n */\n\n/* Upsert a description */\nselect ai.set_description('orders', 'The orders table stores details about individual orders....');\n\n/* Delete a description */\nselect ai.delete_description('orders');\n\n/*\n * Columns\n */\n\n/* Upsert a description */\nselect ai.set_column_description('orders', 'dt', 'The timestamp at which the order was submitted. This column cannot be null.');\n\n/* Delete a description */\nselect ai.delete_column_description('orders', 'dt');\n\n/* Delete all column descriptions from a table */\nselect ai.delete_column_descriptions('orders');\n\n/*\n * Functions\n */\n\n/* Upsert a description */\nselect ai.set_function_description('myfunc'::regproc, 'This function returns all the orders with a \"pending\" status');\n\n/* Delete a description */\nselect ai.delete_function_description('myfunc'::regproc);\n\n/*\n * SQL queries\n */ \n\n/* Adding a description */\nselect ai.add_sql_example\n( $$select date_trunc('day', o.dt) as day, avg(o.cost) as avg_cost from orders o where '2024-11-01'::date <= o.dt and o.dt < '2024-12-01'::date group by 1 order by 1$$\n, 'This query calculates the daily average cost of orders in November. The orders table is filtered by the dt column to....'\n);\n\n/* Updating a description */\nupdate ai.semantic_catalog_sql\nset sql = 'new example'\nwhere sql = 'old example';\n\n/* Deleting a description */\ndelete from ai.semantic_catalog_sql\nwhere sql = 'old example';\n```\n\n----------------------------------------\n\nTITLE: Batch Processing Multiple Texts for Embeddings\nDESCRIPTION: This SQL query demonstrates how to pass an array of text inputs to generate multiple embeddings in a single request to the OpenAI API.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.litellm_embed\n( 'openai/text-embedding-3-small'\n, array['Timescale is Postgres made Powerful', 'the purple elephant sits on a red mushroom']\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Mistral Model\nDESCRIPTION: This SQL query demonstrates how to generate embeddings using Mistral's embedding model, which has a token limit of 16384 tokens per batch.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed(\n  'mistral/mistral-embed'\n, 'Timescale is Postgres made Powerful'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with Advanced Context and Chunk Size\nDESCRIPTION: SQL query to create a vectorizer with both author and title context, plus custom chunk size configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog'::regclass,\n    destination => 'blog_contents_embeddings',\n    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n    chunking => ai.chunking_recursive_character_text_splitter('contents', chunk_size => 700),\n    formatting => ai.formatting_python_template('$title - by $author - $chunk')\n);\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search\nDESCRIPTION: SQL query to perform semantic search on the vector embeddings using Ollama\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT title, chunk\nFROM wiki_embeddings \nORDER BY embedding <=> ai.ollama_embed('all-minilm', 'properties of light')\nLIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Enabling and Disabling Vectorizer Schedules in SQL\nDESCRIPTION: Example of temporarily pausing vectorizers during system maintenance by disabling their schedules before maintenance and re-enabling them afterward.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\n-- Before starting system maintenance\nSELECT ai.disable_vectorizer_schedule(1);\nSELECT ai.disable_vectorizer_schedule(2);\n\n-- Perform maintenance tasks...\n\n-- After maintenance is complete\nSELECT ai.enable_vectorizer_schedule(1);\nSELECT ai.enable_vectorizer_schedule(2);\n```\n\n----------------------------------------\n\nTITLE: Entity Extraction Using Anthropic Claude API in PostgreSQL\nDESCRIPTION: SQL query that uses the Anthropic Claude API to extract named entities from text. Configures tool parameters and schema for entity extraction, returning person names, organizations, and locations.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\\getenv anthropic_api_key ANTHROPIC_API_KEY\n\nSELECT jsonb_pretty(ai.anthropic_generate\n( 'claude-3-5-sonnet-20240620'\n, jsonb_build_array(\n    jsonb_build_object(\n      'role', 'user',\n      'content', 'John works at Google in New York. He met with Sarah, the CEO of Acme Inc., last week in San Francisco.'\n    )\n  )\n, _max_tokens => 4096\n, _api_key => $1\n, _tools => jsonb_build_array(\n    jsonb_build_object(\n      'name', 'print_entities',\n      'description', 'Prints extract named entities.',\n      'input_schema', jsonb_build_object(\n        'type', 'object',\n        'properties', jsonb_build_object(\n          'entities', jsonb_build_object(\n            'type', 'array',\n            'items', jsonb_build_object(\n              'type', 'object',\n              'properties', jsonb_build_object(\n                'name', jsonb_build_object('type', 'string', 'description', 'The extracted entity name.'),\n                'type', jsonb_build_object('type', 'string', 'description', 'The entity type (e.g., PERSON, ORGANIZATION, LOCATION).'),\n                'context', jsonb_build_object('type', 'string', 'description', 'The context in which the entity appears in the text.')\n              ),\n              'required', jsonb_build_array('name', 'type', 'context')\n            )\n          )\n        ),\n        'required', jsonb_build_array('entities')\n      )\n    )\n  )\n)::jsonb) AS result\n\\bind :anthropic_api_key\n\\g\n```\n\n----------------------------------------\n\nTITLE: Executing RAG Query in PostgreSQL\nDESCRIPTION: SQL query that demonstrates how to use the RAG response generation function to answer questions about wiki data.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT generate_rag_response('What can I use pgai for?') as response;\n```\n\n----------------------------------------\n\nTITLE: Creating Text Embeddings with Cohere in SQL\nDESCRIPTION: SQL example showing how to generate text embeddings using the cohere_embed function with the 'embed-english-light-v3.0' model and specifying the input type as 'search_document'.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.cohere_embed\n( 'embed-english-light-v3.0'\n, 'if a woodchuck could chuck wood, a woodchuck would chuck as much wood as he could'\n, input_type=>'search_document'\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Embeddings with Semantic Search\nDESCRIPTION: SQL query to perform semantic search on the generated embeddings, comparing them against the embedding of the phrase 'good food' and ordering by similarity distance.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-voyage.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    chunk,\n    embedding <=>  ai.voyageai_embed('voyage-3-lite', 'good food') as distance\nFROM blog_contents_embeddings\nORDER BY distance;\n```\n\n----------------------------------------\n\nTITLE: Creating Trigger Function for Comment Moderation\nDESCRIPTION: Defines a trigger function that calls the OpenAI moderation API on new or updated comments and sets their status accordingly.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION moderate_comment() RETURNS TRIGGER AS $$\ndeclare\n    out jsonb;\nBEGIN\n  select ai.openai_moderate(\n    'text-moderation-stable',\n    NEW.body,\n     api_key=>current_setting('ai.openai_api_key', false) -- fail if setting not available\n  )->'results'->0 into out;\n  NEW.status = get_moderation_status(out);\n\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Creating HNSW Vector Index with Vectorizer Configuration\nDESCRIPTION: Creates a vectorizer with HNSW indexing configuration for blog content embeddings. Specifies embedding generation using Ollama, text chunking, formatting, and indexing parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog'::regclass,\n    destination => 'blog_contents_embeddings',\n    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n    chunking => ai.chunking_recursive_character_text_splitter('contents', chunk_size => 700),\n    formatting => ai.formatting_python_template('$title - by $author - $chunk'),\n    indexing => ai.indexing_hnsw(min_rows => 100000, opclass => 'vector_l2_ops')\n);\n```\n\n----------------------------------------\n\nTITLE: Generating LLM Output Using Images and Parameters with Ollama in SQL\nDESCRIPTION: Shows how to generate responses from LLMs with image input by calling ai.ollama_generate in SQL, setting system prompts and embedding parameters. It uses Postgres meta-commands to show raw output and passes an array of images as binary data. Requires pgAI, correct file paths, and Ollama model setup; outputs LLM-generated text descriptions based on input images.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\n-- the following two metacommands cause the raw query results to be printed\n-- without any decoration\n\\pset tuples_only on\n\\pset format unaligned\n\nselect ai.ollama_generate\n( 'llava:7b'\n, 'Please describe this image.'\n, images=> array[pg_read_binary_file('/pgai/tests/postgresql-vs-pinecone.jpg')]\n, system_prompt=>'you are a helpful assistant'\n, embedding_options=> jsonb_build_object\n  ( 'seed', 42\n  , 'temperature', 0.9\n  )\n)->>'response'\n;\n```\n\n----------------------------------------\n\nTITLE: Document Ranking with Cohere AI\nDESCRIPTION: Demonstrates semantic document ranking using Cohere's rerank model. Ranks documents based on their relevance to a query prompt and returns relevance scores.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nselect\n  x.\"index\"\n, x.relevance_score\nfrom jsonb_to_recordset\n(\n    ai.cohere_rerank\n    ( 'rerank-english-v3.0'\n    , 'How long does it take for two programmers to work on something?'\n    , array\n      [ $$Good programmers don't just write programs. They build a working vocabulary.$$\n      , 'One of the best programming skills you can have is knowing when to walk away for awhile.'\n      , 'What one programmer can do in one month, two programmers can do in two months.'\n      , 'how much wood would a woodchuck chuck if a woodchuck could chuck wood?'\n      ]\n    )->'results'\n) x(\"index\" int, relevance_score float8)\norder by relevance_score desc\n;\n```\n\n----------------------------------------\n\nTITLE: Creating LiteLLM Vectorizer with CodeBERT Model\nDESCRIPTION: Demonstrates how to create a vectorizer using LiteLLM to access the Microsoft CodeBERT base embedding model on Huggingface with custom configuration options.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'huggingface/microsoft/codebert-base',\n      768,\n      api_key_name => 'HUGGINGFACE_API_KEY',\n      extra_options => '{\"wait_for_model\": true}'::jsonb\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Using OpenAI Embedding API with New Client Configuration (0.9.0+)\nDESCRIPTION: Example demonstrating the new approach for configuring the OpenAI API base URL introduced in version 0.9.0, which uses the ai.openai_client_config function to set configuration parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_embed(\n    model => 'text-embedding-ada-002',\n    input_text => 'Hello world',\n    client_config => ai.openai_client_config(\n        base_url => 'https://custom-openai-api.com/v1'\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Background Procedure for Comment Moderation\nDESCRIPTION: Defines a procedure that periodically checks for pending comments and moderates them using the OpenAI API.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE PROCEDURE check_new_comments_to_moderate(job_id int, config jsonb) LANGUAGE PLPGSQL AS\n$$\ndeclare\n  comment record;\n  api_key text;\nBEGIN\n  RAISE NOTICE 'Executing action % with config %', job_id, config;\n  -- iterate over comments and moderate them\n  api_key := config->>'api_key';\n  for comment in select * from comments where status = 'pending' limit 1 for update skip locked loop\n    update comments set status = get_moderation_status(comment.body, api_key)\n    where id = comment.id;\n  end loop;\nEND\n$$;\n```\n\n----------------------------------------\n\nTITLE: Text Classification with Cohere AI using SQL\nDESCRIPTION: Demonstrates how to classify text inputs into predefined categories using Cohere's classification model. Uses example data to train the classifier and assigns labels to new inputs with confidence scores.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nwith examples(example, label) as\n(\n    values\n      ('cat', 'animal')\n    , ('dog', 'animal')\n    , ('car', 'machine')\n    , ('truck', 'machine')\n    , ('apple', 'food')\n    , ('broccoli', 'food')\n)\nselect *\nfrom jsonb_to_recordset\n(\n    ai.cohere_classify\n    ( 'embed-english-light-v3.0'\n    , array['bird', 'airplane', 'corn'] --inputs we want to classify\n    , examples=>(select jsonb_agg(jsonb_build_object('text', examples.example, 'label', examples.label)) from examples)\n    )->'classifications'\n) x(input text, prediction text, confidence float8)\n;\n```\n\n----------------------------------------\n\nTITLE: Creating a Vectorizer for the Blog Table\nDESCRIPTION: This SQL command creates a vectorizer for the 'blog' table using OpenAI's text-embedding-3-small model and recursive character text splitting for chunking.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'blog'::regclass,\n   destination => 'blog_contents_embeddings',\n   embedding => ai.embedding_openai('text-embedding-3-small', 768),\n   chunking => ai.chunking_recursive_character_text_splitter('contents')\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Complex SQL for Passenger Count (SQL)\nDESCRIPTION: Executes `ai.text_to_sql` with a complex question about the number of passengers arriving in Houston, TX in June 2024. This requires the LLM to understand the relationships between passengers, bookings, flights, and airports, generating a SQL query involving multiple table joins and a distinct count.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nselect ai.text_to_sql('How many passengers arrived in Houston, TX in June 2024?');\n```\n```\n\n----------------------------------------\n\nTITLE: Recursive Text Chunking with Multiple Separators in SQL\nDESCRIPTION: Example of using ai.chunk_text_recursively with an array of separators to recursively split text into very small chunks. This demonstrates how to handle hierarchical text splitting.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/chunking.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect *\nfrom ai.chunk_text_recursively\n($$if two witches watch two watches, which witch watches which watch?$$\n, separators=>array[' ', '.', '?']\n, chunk_size=>2\n, chunk_overlap=>0\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Character Text Splitter in PgAI\nDESCRIPTION: Example showing how to split text into chunks using ai.chunking_character_text_splitter with specific chunk size and overlap parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    chunking => ai.chunking_character_text_splitter('body', 128, 10, E'\\n'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with OpenAI Model in SQL\nDESCRIPTION: This SQL query generates embeddings using OpenAI's text-embedding-3-small model for the given text, specifying the API key name parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed\n( 'openai/text-embedding-3-small'\n, 'the purple elephant sits on a red mushroom'\n, api_key_name => 'OPENAI_API_KEY'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with Voyage AI Embedding in SQL\nDESCRIPTION: This snippet demonstrates creating a vectorizer for the Voyage AI embedding model. The function ai.embedding_voyageai configures the model, its dimensions, and API key. Users are expected to have the API key managed through environment variables, ensuring no hardcoded secrets are present.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_voyageai(\n      'voyage-3-lite',\n      512,\n      api_key_name => \"TEST_API_KEY\"\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Enforcing Structured JSON Output from Ollama in SQL\nDESCRIPTION: Demonstrates calling ai.ollama_chat_complete in SQL with a response_format parameter, forcing the LLM to return a JSON structure with specific properties ('age' and 'available'). Requires pgAI extension and properly configured LLM. Input parameters include response shape; outputs a single row containing the structured JSON response.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nselect ai.ollama_chat_complete\n( 'llama3.2:1b'\n, $json$[{\"role\": \"user\", \"content\": \"Ollama is 22 years old and busy saving the world. Return a JSON object with the age and availability.\"}]$json$::jsonb\n, response_format=> $json$\n    {\n        \"type\": \"object\",\n        \"properties\": {\n            \"age\": {\n                \"type\": \"integer\"\n            },\n            \"available\": {\n                \"type\": \"boolean\"\n            }\n        },\n        \"required\": [\n            \"age\",\n            \"available\"\n        ]\n    }\n  $json$::jsonb\n)->'message'->'content'\n;\n```\n\n----------------------------------------\n\nTITLE: Creating BGE Large Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using the BGE Large model with 1024 dimensions, chunking the text into 512 character segments with 50 character overlap.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'pg_essays'::regclass,\n   destination => 'essays_bge_large_embeddings',\n   embedding => ai.embedding_ollama('bge-large', 1024),\n   chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for pgai Local Development Environment\nDESCRIPTION: This YAML configuration sets up a local development environment for pgai, including a Postgres deployment with TimescaleDB and pgai extensions, and a pgai vectorizer worker.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai\nservices:\n  db:\n    image: timescale/timescaledb-ha:pg16\n    environment:\n      POSTGRES_PASSWORD: postgres\n      OPENAI_API_KEY: <your-api-key>\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/home/postgres/pgdata/data\n  vectorizer-worker:\n    image: timescale/pgai-vectorizer-worker:latest\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Structuring Vectorizer Output with Markers\nDESCRIPTION: Formats the AI vectorizer output by adding start and end markers around the chunk. Such structure aids specific embedding or retrieval tasks.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    formatting => ai.formatting_python_template('BEGIN DOCUMENT\\n$chunk\\nEND DOCUMENT'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for Postgres with TimescaleDB and pgai\nDESCRIPTION: Docker Compose configuration that sets up Postgres with TimescaleDB, pgai vectorizer worker, and Ollama for embedding and language models. Includes volume configuration and environment variables setup.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai \nservices:\n  db:\n    image: timescale/timescaledb-ha:pg17\n    environment:\n      POSTGRES_PASSWORD: postgres\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/home/postgres/pgdata/data\n  vectorizer-worker:\n    image: timescale/pgai-vectorizer-worker:latest\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\n      OLLAMA_HOST: http://ollama:11434\n    command: [ \"--poll-interval\", \"5s\" ]\n  ollama:\n    image: ollama/ollama\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Implementing Row Level Security in PostgreSQL\nDESCRIPTION: Reference to implementing Row Level Security (RLS) in PostgreSQL for controlling user data access authorization.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n[Row Level Security (RLS)](https://www.postgresql.org/docs/current/ddl-rowsecurity.html)\n```\n\n----------------------------------------\n\nTITLE: Creating Cohere Embedding Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using Cohere's embed-english-v3.0 model with 1024 dimensions and recursive character text splitting\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'paul_graham_essays'::regclass,\n    destination => 'essays_cohere_embeddings',\n    embedding => ai.embedding_litellm(\n        'cohere/embed-english-v3.0',\n        1024,\n        api_key_name => 'COHERE_API_KEY'\n    ),\n    chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Interval TimescaleDB Scheduling in SQL\nDESCRIPTION: Configures a vectorizer with TimescaleDB scheduling to run every hour instead of the default 5 minutes. This allows for customizing how frequently the vectorizer checks for and processes new or updated data.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_timescaledb(interval '1 hour'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Listing Running Ollama Models from PostgreSQL\nDESCRIPTION: Runs a SQL query to list all currently running Ollama models by calling ai.ollama_ps(). Outputs model metadata such as name, family, quantization level, and expiration date. Requires pgAI and a live Ollama instance; outputs one row per active model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\nselect *\nfrom ai.ollama_ps()\n;\n```\n\n----------------------------------------\n\nTITLE: SQL Example: Embedding Generation\nDESCRIPTION: Example SQL code showing how to generate embeddings for text and SQL descriptions\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_5\n\n\n\n----------------------------------------\n\nTITLE: Article Summarization Query Example\nDESCRIPTION: Shows how to use the summarize_article function to extract structured information including author, topics, summary, and metrics from text content.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect * from summarize_article($$\n  From URL: https://docs.timescale.com/use-timescale/latest/compression\n  #  Compression\n\n  Time-series data can be compressed to reduce the amount of storage required,\n  and increase the speed of some queries. This is a cornerstone feature of Timescale.\n  When new data is added to your database, it is in the form of uncompressed rows.\n  Timescale uses a built-in job scheduler to convert this data to the form of\n  compressed columns. This occurs across chunks of Timescale hypertables.\n\n   Timescale charges are based on how much storage you use. You don't pay for a \n   fixed storage size, and you don't need to worry about scaling disk size as your\n   data grows; We handle it all for you. To reduce your data costs further, use\n   compression, a data retention policy, and tiered storage.\n\n$$);\n```\n\n----------------------------------------\n\nTITLE: Querying Embedded Text Samples from PostgreSQL\nDESCRIPTION: Two SQL queries to retrieve sample text records from both OpenAI and Voyage AI embedding tables, limited to 5 results each.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT text FROM sec_filings_openai_embeddings LIMIT 5;\nSELECT text FROM sec_filings_voyage_embeddings LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Sample Structured Output from LLM Returning JSON in SQL\nDESCRIPTION: Presents a sample plain-text output from an enforced JSON response, showing the structure with 'age' as an integer and 'available' as a boolean. Useful for verifying shape conformity after LLM execution. Input is automatically parsed by PostgreSQL as text, revealing correct JSON construction.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n                  structured\n-----------------------------------------------\n \"{\\n  \\\"age\\\": 22,\\n  \\\"available\\\": true\\n}\"\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Multiple Text Embeddings Array\nDESCRIPTION: Generates embeddings for multiple text inputs passed as an array using the voyage-3-lite model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.voyageai_embed\n( 'voyage-3-lite'\n, array['Timescale is Postgres made Powerful', 'the purple elephant sits on a red mushroom']\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Nomic embed-text Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using the Nomic embed-text model with 768 dimensions, chunking the text into 512 character segments with 50 character overlap.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'pg_essays'::regclass,\n   destination => 'essays_nomic_embeddings',\n   embedding => ai.embedding_ollama('nomic-embed-text', 768),\n   chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Chat Completion with Cohere AI\nDESCRIPTION: Demonstrates chat completion functionality using Cohere's command model. Takes a chat prompt and returns an AI-generated response with controlled randomness through seed and temperature parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.cohere_chat_complete\n( 'command-r-plus'\n, jsonb_build_array\n  ( jsonb_build_object\n    ( 'role', 'user'\n    , 'content', 'How much wood would a woodchuck chuck if a woodchuck could chuck wood?'\n    )\n  )\n, seed=>42\n, temperature=>0.0\n)->'message'->'content'->0->>'text'\n;\n```\n\n----------------------------------------\n\nTITLE: Simplified Document Ranking with Cohere AI\nDESCRIPTION: A simplified interface for document ranking using Cohere's rerank model, providing the same functionality with a more user-friendly output format.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nselect *\nfrom ai.cohere_rerank_simple\n( 'rerank-english-v3.0'\n, 'How long does it take for two programmers to work on something?'\n, array\n  [ $$Good programmers don't just write programs. They build a working vocabulary.$$\n  , 'One of the best programming skills you can have is knowing when to walk away for awhile.'\n  , 'What one programmer can do in one month, two programmers can do in two months.'\n  , 'how much wood would a woodchuck chuck if a woodchuck could chuck wood?'\n  ]\n) x\norder by relevance_score desc\n;\n```\n\n----------------------------------------\n\nTITLE: Generating embeddings with Ollama in SQL\nDESCRIPTION: SQL query to generate vector embeddings for a text input using the specified Ollama model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.ollama_embed\n( 'llama3'\n, 'the purple elephant sits on a red mushroom'\n);\n```\n\n----------------------------------------\n\nTITLE: Monitoring Vectorizer Health in SQL\nDESCRIPTION: Example of using the ai.vectorizer_status view to create alerts for vectorizers with large processing backlogs.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\n-- Alert if any vectorizer has more than 1000 pending items\nSELECT id, source_table, pending_items \nFROM ai.vectorizer_status \nWHERE pending_items > 1000;\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer Function for Embedding Generation\nDESCRIPTION: Defines a function to create a vectorizer in pgai for each embedding model with specified dimensions, chunking strategy, and text formatting.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef create_vectorizer(embedding_model, embeddings_dimensions):\n    embeddings_view_name = f\"{'essays'}{'_'}{embedding_model.replace('-','_')}{'_'}{'embeddings'}\"\n\n    with connect_db() as conn:\n        with conn.cursor() as cur:\n            cur.execute(\"\"\"\n                SELECT ai.create_vectorizer(\n                'essays'::regclass,\n                destination => %s,\n                embedding => ai.embedding_ollama(%s, %s),\n                chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50),\n                formatting => ai.formatting_python_template('title: $title $chunk')\n            );\n            \"\"\", (embeddings_view_name, embedding_model, embeddings_dimensions, )\n            )\n```\n\n----------------------------------------\n\nTITLE: Querying Vectorizer Status in SQL\nDESCRIPTION: Example of retrieving an overview of all vectorizers using the ai.vectorizer_status view to monitor their current state.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_34\n\nLANGUAGE: sql\nCODE:\n```\n-- Get an overview of all vectorizers\nSELECT * FROM ai.vectorizer_status;\n```\n\n----------------------------------------\n\nTITLE: Using Bind Variable for API Key in OpenAI Query\nDESCRIPTION: SQL query demonstrating how to use a bind variable for the API key parameter in a pgai function call to list OpenAI models securely.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM ai.openai_list_models(api_key=>$1)\nORDER BY created DESC\n\\bind :my_api_key\n\\g\n```\n\n----------------------------------------\n\nTITLE: Embedding Model Evaluation Function\nDESCRIPTION: Main evaluation function that processes multiple embedding models, calculates accuracy metrics per model and question type, and stores detailed results in CSV format.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef evaluate_embedding_models():\n    evaluation_results = []\n    detailed_results = []\n\n    for model in EMBEDDING_MODELS:\n        print(f\"Evaluating {model['name']}...\")\n\n        embeddings_view = f\"{'essays'}{'_'}{model['name'].replace('-','_')}{'_'}{'embeddings'}\"\n        scores = []\n\n        for q in evaluation_questions:\n            vector_search_results = vector_similarity_search(embeddings_view, model['name'], q['question'])\n            found = any(\n                row[0] == q['source_chunk_id'] and row[1]== q['source_chunk_seq'] \n                for row in vector_search_results\n            )\n\n            scores.append(1 if found else 0)\n\n            detailed_results.append({\n                'model': model['name'],\n                'question': q['question'],\n                'question_type': q['question_type'],\n                'source_chunk_id': q['source_chunk_id'],\n                'source_chunk_seq': q['source_chunk_seq'],\n                'found_correct_chunk': found,\n                'num_results': len(vector_search_results)\n            })\n\n        evaluation_results.append({\n            'model': model['name'],\n            'overall_accuracy': sum(scores) / len(scores),\n            'by_type': {\n                q_type: sum(scores[i] for i, q in enumerate(evaluation_questions) \n                            if q['question_type'] == q_type) / QUESTION_DISTRIBUTION[q_type] / NUM_CHUNKS\n                for q_type in QUESTION_DISTRIBUTION.keys()\n            }\n        })\n    \n    pd.DataFrame(detailed_results).to_csv('./evaluation_data/detailed_results.csv')\n    return evaluation_results\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search with pgvector-python\nDESCRIPTION: This snippet shows how to perform semantic similarity search using pgvector-python's distance functions with SQLAlchemy.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom sqlalchemy import func, text\n\nsimilar_posts = (\n    session.query(BlogPost.content_embeddings)\n    .order_by(\n        BlogPost.content_embeddings.embedding.cosine_distance(\n            func.ai.openai_embed(\n                \"text-embedding-3-small\",\n                \"search query\",\n                text(\"dimensions => 768\")\n            )\n        )\n    )\n    .limit(5)\n    .all()\n)\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Fields in Vectorizer\nDESCRIPTION: Configures an AI vectorizer to prepend author and category information to each text chunk. This setup uses placeholders to enrich embeddings with additional metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    formatting => ai.formatting_python_template('Author: $author\\nCategory: $category\\n$chunk'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Vectorizer in Python using pgai\nDESCRIPTION: This code demonstrates how to create a vectorizer using the CreateVectorizer class from pgai.vectorizer module. It configures embedding, chunking, and formatting options.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pgai.vectorizer import CreateVectorizer\nfrom pgai.vectorizer.configuration import EmbeddingOpenaiConfig, ChunkingCharacterTextSplitterConfig, FormattingPythonTemplateConfig\n\nvectorizer_statement = CreateVectorizer(\n    source=\"blog\",\n    target_table='blog_embeddings',\n    embedding=EmbeddingOpenaiConfig(\n        model='text-embedding-3-small',\n        dimensions=768\n    ),\n    chunking=ChunkingCharacterTextSplitterConfig(\n        chunk_column='content',\n        chunk_size=800,\n        chunk_overlap=400,\n        separator='.',\n        is_separator_regex=False\n    ),\n    formatting=FormattingPythonTemplateConfig(template='$title - $chunk')\n).to_sql()\n```\n\n----------------------------------------\n\nTITLE: Creating Embedding Population Function\nDESCRIPTION: Defines a PL/pgSQL function that processes null embeddings using OpenAI's API in background jobs.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION populate_embedding(job_id int, config jsonb) returns void as $$\nDECLARE\n  r record;\n  api_key text;\nBEGIN\n  api_key := config->>'api_key';\n  FOR r IN select id, contents from document_embedding where embedding IS NULL LIMIT 1 FOR UPDATE SKIP LOCKED LOOP\n    update document_embedding\n    set embedding = ai.openai_embed('text-embedding-ada-002', r.contents, api_key)\n    where id = r.id;\n  END LOOP;\nEND;\n$$ language plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Specifying Embedding Dimensions with OpenAI in SQL\nDESCRIPTION: This SQL query demonstrates how to specify the number of dimensions for the returned embedding, which works for certain models like OpenAI's text-embedding-3-small.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed\n( 'openai/text-embedding-3-small'\n, 'the purple elephant sits on a red mushroom'\n, dimensions=>768\n, api_key_name => 'OPENAI_API_KEY'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI text-embedding-3-large Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using OpenAI's large embedding model with 1536 dimensions, chunking the text into 512 character segments with 50 character overlap.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'pg_essays'::regclass,\n   destination => 'essays_openai_large_embeddings', \n   embedding => ai.embedding_openai('text-embedding-3-large', 1536),\n   chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Evaluation Questions for All Chunks\nDESCRIPTION: Processes each evaluation chunk to generate questions of different types according to the defined distribution and saves all generated questions to a CSV file.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nevaluation_questions = []\n\nfor i, chunk in enumerate(evaluation_chunks, 1):\n    print(f\"Processing chunk {i}/{len(evaluation_chunks)}\")\n\n    for question_type, count in QUESTION_DISTRIBUTION.items():\n        questions = generate_questions_by_question_type(chunk['chunk'], question_type, count)\n\n        for q in questions:\n            evaluation_questions.append({\n                'question': q,\n                'source_chunk_id': chunk['id'],\n                'source_chunk_seq': chunk['chunk_seq'],\n                'question_type': question_type,\n                'chunk': chunk['chunk']\n            })\n\nprint(\"Generated questions in total:\", len(evaluation_questions))\n\npd.DataFrame(evaluation_questions).to_csv('./generated_questions.csv')\n```\n\n----------------------------------------\n\nTITLE: Simplified Text Classification with Cohere AI\nDESCRIPTION: A simplified interface for text classification using Cohere's model, providing the same functionality with a more straightforward syntax.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nwith examples(example, label) as\n(\n    values\n      ('cat', 'animal')\n    , ('dog', 'animal')\n    , ('car', 'machine')\n    , ('truck', 'machine')\n    , ('apple', 'food')\n    , ('broccoli', 'food')\n)\nselect *\nfrom ai.cohere_classify_simple\n( 'embed-english-light-v3.0'\n, array['bird', 'airplane', 'corn']\n, examples=>(select jsonb_agg(jsonb_build_object('text', examples.example, 'label', examples.label)) from examples)\n) x\n;\n```\n\n----------------------------------------\n\nTITLE: Evaluating and Reporting Embedding Model Performance\nDESCRIPTION: Python code that runs the evaluation process on embedding models, saves results to CSV files, and prints a summary of the performance metrics for comparison.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = evaluator.step3_evaluate_models()  # Reads from questions.csv\npd.DataFrame(results).to_csv('results.csv')\nevaluator.print_results()\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced TimescaleDB Scheduling with Start Time and Timezone in SQL\nDESCRIPTION: Sets up a vectorizer with TimescaleDB scheduling that runs every 30 minutes, starting at a specific time, in a specific timezone. This provides fine-grained control over when the vectorizer begins and how it interprets time-based settings.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_timescaledb(\n      interval '30 minutes',\n      initial_start => '2024-01-01 00:00:00'::timestamptz,\n      timezone => 'America/New_York'\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Inspecting LLM Tool Call Response in JSON\nDESCRIPTION: Shows a sample JSON response where the LLM calls the 'get_current_weather' function with populated parameter values. Useful for validating tool schema and interpreting LLM-initiated function calls. This output assumes a prior successful query using the tools parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_11\n\nLANGUAGE: JSON\nCODE:\n```\n[\n   {\n       \"function\": {\n           \"name\": \"get_current_weather\",\n           \"arguments\": {\n               \"format\": \"celsius\",\n               \"location\": \"Birmingham, Alabama\"\n           }\n       }\n   }\n]\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL with OpenAI Key using psql (Bash)\nDESCRIPTION: Connects to the PostgreSQL database as the `postgres` user using the `psql` command-line tool. The `PGOPTIONS` environment variable is used to set the `ai.openai_api_key` configuration parameter for the session, enabling interactions with the OpenAI API via the `pgai` extension for subsequent commands within that session.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_15\n\nLANGUAGE: Bash\nCODE:\n```\n```bash\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" psql -U postgres\n```\n```\n\n----------------------------------------\n\nTITLE: Including User Identifier in Embedding Request\nDESCRIPTION: This SQL query shows how to pass a user identifier to the AI provider by including it in the extra_options parameter as a JSON object.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed\n( 'openai/text-embedding-3-small'\n, 'the purple elephant sits on a red mushroom'\n, api_key_name => 'OPENAI_API_KEY'\n, extra_options => '{\"openai_user\" : \"bac1aaf7-4460-42d3-bba5-2957b057f4a5\"}'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Basic Text Chunking with Custom Parameters in SQL\nDESCRIPTION: Example of using ai.chunk_text with custom parameters to split text on spaces with specific chunk size and no overlap. This demonstrates the function's ability to customize the chunking behavior.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/chunking.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect *\nfrom ai.chunk_text\n($$if two witches watch two watches, which witch watches which watch?$$\n, separator=>' '\n, chunk_size=>10\n, chunk_overlap=>0\n);\n```\n\n----------------------------------------\n\nTITLE: Step-by-Step Evaluation Process in Python\nDESCRIPTION: Python code snippet showing the evaluation workflow for embedding models, including getting chunks, generating questions, and evaluating model performance.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nevaluator = StepByStepEvaluator()\nchunks = evaluator.step1_get_chunks()\npd.DataFrame(chunks).to_csv('chunks.csv')\n\nchunks = pd.read_csv('chunks.csv', index_col=0).to_dict('records')\nevaluator.chunks = chunks\nquestions = evaluator.step2_generate_questions()\npd.DataFrame(questions).to_csv('questions.csv')\n\nresults = evaluator.step3_evaluate_models()  # Reads from questions.csv\npd.DataFrame(results).to_csv('results.csv')\nevaluator.print_results()\n```\n\n----------------------------------------\n\nTITLE: Creating Moderation Status Classification Function\nDESCRIPTION: Defines a function that interprets the OpenAI moderation API response and returns a moderation status based on flagged categories.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION get_moderation_status(result jsonb)\nRETURNS TEXT AS $$\nBEGIN\n    IF result->>'flagged' IS NOT NULL THEN\n        IF result->'categories'->>'violence' then\n            return 'violence';\n        END IF;\n        IF result->'categories'->>'harassment' then\n            return 'harassment';\n        END IF;\n        IF result->'categories'->>'hate' then\n            return 'hate';\n        END IF;\n        IF result->'categories'->>'sexual' then\n            return 'sexual';\n        end if;\n    end if;\n    return 'approved';\nend;\n$$ language plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Text Embedding with Input Type Specification\nDESCRIPTION: Generates embeddings with a specified input type parameter to enhance retrieval quality.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.voyageai_embed\n( 'voyage-3-lite'\n, 'A query'\n, input_type => 'query'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic TimescaleDB Scheduling for Vectorizer in SQL\nDESCRIPTION: Sets up a vectorizer with the default TimescaleDB scheduling (every 5 minutes). This uses TimescaleDB's job scheduling system to automate the periodic execution of the vectorizer for processing new or updated data.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_timescaledb(),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with OpenAI Embedding in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a vectorizer by employing the OpenAI embedding service. It involves setting up a function call to 'ai.create_vectorizer' with ai.embedding_openai. Parameters include the model name and dimensions. The user must have configured an environment variable for the OpenAI API key.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_openai(\n      'text-embedding-3-small', \n      768, \n      chat_user => 'bob',\n      api_key_name => 'MY_OPENAI_API_KEY_NAME'\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer for Blog Content\nDESCRIPTION: SQL command to create a vectorizer that generates embeddings for blog content using Ollama's nomic-embed-text model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n     'blog'::regclass,\n     destination => 'blog_contents_embeddings',\n     embedding => ai.embedding_ollama('nomic-embed-text', 768),\n     chunking => ai.chunking_recursive_character_text_splitter('contents')\n);\n```\n\n----------------------------------------\n\nTITLE: Sample LLM Image Description Output\nDESCRIPTION: Shows a sample text output from the LLM when presented with an image, describing depicted elements and scene context. This helps in verifying the capability of the LLM to generate multi-modal outputs. Image input and descriptive prompt are required; output is plain text.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_15\n\nLANGUAGE: text\nCODE:\n```\n This is a digital image featuring two anthropomorphic characters that appear to be stylized animals. On the left, there's a character that looks like an elephant with boxing gloves on, ready for a fight. The elephant has large ears and eyes, and it's standing upright.\n\nOn the right, there's a character that resembles a pine cone. This character is also anthropomorphic, wearing shorts, boots, and a bandana. It holds what looks like a pine cone in each hand.\n\nThe background of the image suggests an indoor setting with a wooden floor, a stage with lights, and spectators in the stands. The overall atmosphere of the scene is competitive and energetic. \n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizers for Multiple Embedding Models\nDESCRIPTION: Creates vectorizers for three different embedding models (mxbai-embed-large, nomic-embed-text, and bge-m3) with their respective dimensions.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nEMBEDDING_MODELS = [\n    {'name':'mxbai-embed-large', 'dimensions': 1024},\n    {'name':'nomic-embed-text','dimensions': 768},\n    {'name':'bge-m3','dimensions': 1024},\n] \n\nfor model in EMBEDDING_MODELS:\n    create_vectorizer(model['name'], model['dimensions'])\n```\n\n----------------------------------------\n\nTITLE: Configuring Recursive Character Text Splitter in PgAI\nDESCRIPTION: Example demonstrating recursive text splitting with multiple separators using ai.chunking_recursive_character_text_splitter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n  'my_table'::regclass,\n  chunking => ai.chunking_recursive_character_text_splitter(\n    'content', \n    256, \n    20, \n    separators => array[E'\\n;', ' ']\n  ),\n  -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Chunking Text from a Table Column Using ai.chunk_text in SQL\nDESCRIPTION: Demonstrates how to apply the ai.chunk_text function to chunk text stored in a database column. This query joins each row with its chunked text results using a lateral join.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/chunking.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect\n  b.id\n, b.title\n, c.seq\n, c.chunk\nfrom blog b\ncross join lateral ai.chunk_text(b.body) c\norder by b.id, c.seq\n;\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Testing Unreleased Features\nDESCRIPTION: A Docker Compose configuration for testing unreleased pgai features. It sets up a PostgreSQL database with pgai installed, a vectorizer worker, and an Ollama instance for AI model serving.\nSOURCE: https://github.com/timescale/pgai/blob/released/DEVELOPMENT.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai\nservices:\n  db:\n    build:\n      context: projects/extension\n      dockerfile: Dockerfile\n      target: pgai-test-db\n    environment:\n      POSTGRES_PASSWORD: postgres\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/home/postgres/pgdata/data\n    command: [ \"-c\", \"ai.ollama_host=http://ollama:11434\" ]\n  vectorizer-worker:\n    build:\n      context: projects/pgai\n      dockerfile: Dockerfile\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\n      OLLAMA_HOST: http://ollama:11434\n    command: [ \"--poll-interval\", \"5s\", \"--log-level\", \"DEBUG\" ]\n  ollama:\n    image: ollama/ollama\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Disabling Special Indexing\nDESCRIPTION: Illustrates the use of 'ai.indexing_none' to avoid special indexing for embeddings, useful in cases where fast similarity searches are unnecessary.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    indexing => ai.indexing_none(),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Vector Similarity Search Implementation in Python\nDESCRIPTION: Performs vector similarity search against chunk embeddings using database queries. Takes embedding view name, model, and question as inputs to find top-K similar chunks.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nOLLAMA_HOST = os.environ[\"OLLAMA_HOST\"]\n\ndef vector_similarity_search(embeddings_view, embedding_model, question):\n    with connect_db() as conn:\n        with conn.cursor() as cur:\n            cur.execute(f\"\"\"\n                SELECT id, chunk_seq \n                FROM {embeddings_view} \n                ORDER BY embedding <=> ai.ollama_embed(%s, %s, host => %s)\n                LIMIT %s;\n            \"\"\", (embedding_model, question, OLLAMA_HOST, TOP_K,)\n            )\n\n            return cur.fetchall()\n```\n\n----------------------------------------\n\nTITLE: Running Standalone Vectorizer Worker with Docker\nDESCRIPTION: Docker command to run the pgai vectorizer worker as a standalone container. This command is used to process vectorizers on any self-hosted Postgres database with the pgai extension activated.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker run timescale/pgai-vectorizer-worker:{tag version} --db-url <DB URL>\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with AWS Bedrock\nDESCRIPTION: This SQL query shows how to use AWS Bedrock for embeddings through LiteLLM, which requires AWS authentication credentials typically set through environment variables.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed(\n  'bedrock/amazon.titan-embed-text-v2:0'\n, 'Timescale is Postgres made Powerful'\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Cohere Model\nDESCRIPTION: This SQL query shows how to use LiteLLM with Cohere's embedding model. Note that Cohere requires an input_type parameter, which LiteLLM defaults to 'search_document'.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed(\n  'cohere/embed-english-v3.0'\n, 'Timescale is Postgres made Powerful'\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Questions from Text Chunks for Embedding Evaluation\nDESCRIPTION: Python code that loads previously saved chunks, generates questions for each chunk according to the configured distribution, and saves them to a CSV file.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nchunks = pd.read_csv('chunks.csv', index_col=0).to_dict('records')\nevaluator.chunks = chunks\nquestions = evaluator.step2_generate_questions()\npd.DataFrame(questions).to_csv('questions.csv')\n```\n\n----------------------------------------\n\nTITLE: Running PostgreSQL Container with TimescaleDB\nDESCRIPTION: Docker command to start a PostgreSQL instance with TimescaleDB for development purposes, setting up data volume and password configuration. Creates a connection at postgres://postgres:password@localhost/postgres.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/docker.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name pgai -p 5432:5432 \\\n-v pg-data:/home/postgres/pgdata/data \\\n-e POSTGRES_PASSWORD=password timescale/timescaledb-ha:pg17\n```\n\n----------------------------------------\n\nTITLE: Creating Enhanced Moderation Status Function for Background Processing\nDESCRIPTION: Defines an enhanced function for background processing that calls the OpenAI API and extracts the moderation status from the result.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE FUNCTION get_moderation_status(body TEXT, api_key TEXT)\nRETURNS TEXT AS $$\nDECLARE\n    result JSONB;\n    category TEXT;\n    api_key text;\nBEGIN\n\n    select current_setting('ai.openai_api_key', false) into api_key;\n    -- Call OpenAI moderation endpoint\n    select ai.openai_moderate('text-moderation-stable',\n      body,\n      api_key => api_key)->'results'->0 into result;\n\n    -- Check if any category is flagged\n    IF result->>'flagged' = 'true' THEN\n        FOR category IN SELECT jsonb_object_keys(result->'categories') LOOP\n            IF (result->'categories'->>category)::BOOLEAN THEN\n                RETURN category;\n            END IF;\n        END LOOP;\n    END IF;\n\n    RETURN 'approved';\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n----------------------------------------\n\nTITLE: Temporary Admin Access for Maintenance in PostgreSQL\nDESCRIPTION: Example of creating and granting temporary administrative AI access for maintenance purposes, including cleanup.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE temp_admin;\nSELECT ai.grant_ai_usage('temp_admin', admin => true);\n-- After maintenance\nDROP ROLE temp_admin;\n```\n\n----------------------------------------\n\nTITLE: Configuring Fixed Schedule TimescaleDB Scheduling in SQL\nDESCRIPTION: Configures a vectorizer with a fixed daily schedule using TimescaleDB scheduling. This ensures the vectorizer runs at the same time each day (e.g., midnight UTC) rather than on a sliding interval from the last execution.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_timescaledb(\n      interval '1 day',\n      fixed_schedule => true,\n      timezone => 'UTC'\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Listing All Cohere Models in SQL\nDESCRIPTION: SQL query that retrieves all available Cohere models, displaying their names, supported endpoints, fine-tuning status, context length, and tokenizer URLs.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect *\nfrom ai.cohere_list_models()\n;\n```\n\n----------------------------------------\n\nTITLE: Creating Comment Moderation Trigger\nDESCRIPTION: Creates a trigger that executes the moderation function before inserting or updating comments.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TRIGGER moderate_comment_trigger\nBEFORE INSERT OR UPDATE ON comments\n  FOR EACH ROW EXECUTE FUNCTION moderate_comment();\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Google Vertex AI\nDESCRIPTION: This SQL query demonstrates how to use Google Vertex AI for embeddings through LiteLLM, which requires Google Cloud Platform authentication credentials typically set through environment variables.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed(\n  'vertex_ai/text-embedding-005',\n, 'Timescale is Postgres made Powerful'\n);\n```\n\n----------------------------------------\n\nTITLE: Defining SQLAlchemy Model with Vectorizer Relationship\nDESCRIPTION: This code example demonstrates how to define a SQLAlchemy model (BlogPost) with a vectorizer relationship for content embeddings.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom pgai.sqlalchemy import vectorizer_relationship\n\nclass Base(DeclarativeBase):\n    pass\n\nclass BlogPost(Base):\n    __tablename__ = \"blog_posts\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    title: Mapped[str]\n    content: Mapped[str]\n\n    # Add vector embeddings for the content field\n    content_embeddings = vectorizer_relationship(\n        dimensions=768\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Vectorizer with Ollama Embeddings\nDESCRIPTION: SQL query to create a vectorizer using Ollama embeddings with basic configuration for the blog table contents.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer( \n   'blog'::regclass,\n    destination => 'blog_contents_embeddings',\n    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n    chunking => ai.chunking_recursive_character_text_splitter('contents')\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Huggingface Inference\nDESCRIPTION: This SQL query demonstrates how to use Huggingface inference for embeddings, with an option to wait for the model to load when using serverless inference.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed\n( 'huggingface/BAAI/bge-small-en-v1.5'\n, 'Timescale is Postgres made Powerful'\n, extra_options => '{\"wait_for_model\": true}'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search Query\nDESCRIPTION: SQL query to perform semantic search using embeddings and distance calculation.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    chunk,\n    embedding <=>  ai.ollama_embed('nomic-embed-text', 'good food', host => 'http://ollama:11434') as distance\nFROM blog_contents_embeddings\nORDER BY distance\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Azure OpenAI\nDESCRIPTION: This SQL query shows how to use Azure OpenAI for embeddings, requiring the deployment name, base URL, and version configured through extra_options as well as an API key.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed\n( 'azure/<deployment name here>'\n, 'Timescale is Postgres made Powerful'\n, api_key_name => 'AZURE_API_KEY',\n, extra_options => '{\"api_base\": \"<base URL here>\", \"api_version\": \"<version here\">}'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer for Embeddings\nDESCRIPTION: SQL command to create a vectorizer that generates embeddings from the wiki table text using Ollama\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n     'wiki'::regclass,\n     destination => 'wiki_embeddings',\n     embedding => ai.embedding_ollama('all-minilm', 384),\n     chunking => ai.chunking_recursive_character_text_splitter('text')\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama with the host parameter in SQL\nDESCRIPTION: Example of how to use the host parameter to specify the Ollama network address when calling an Ollama function in pgai.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.ollama_generate\n( 'llama3'\n, 'what is the typical weather like in Alabama in June'\n, host=>'http://host.for.ollama:port' -- tells pgai that Ollama is running on the host when pgai is in a docker container\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting just the content from a chat completion response\nDESCRIPTION: SQL query using JSONB operators to extract only the message content from an Ollama chat completion response.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- the following two metacommands cause the raw query results to be printed\n-- without any decoration\n\\pset tuples_only on\n\\pset format unaligned\n\nselect ai.ollama_chat_complete\n( 'llama3'\n, jsonb_build_array\n  ( jsonb_build_object('role', 'system', 'content', 'you are a helpful assistant')\n  , jsonb_build_object('role', 'user', 'content', 'Give a short description of what a large language model is')\n  )\n, chat_options=> jsonb_build_object\n  ( 'seed', 42\n  , 'temperature', 0.6\n  )\n)->'message'->>'content';\n```\n\n----------------------------------------\n\nTITLE: Creating VoyageAI Vectorizer\nDESCRIPTION: SQL command to create a vectorizer that generates embeddings using VoyageAI's voyage-3-lite model with 512 dimensions and recursive character text splitting.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-voyage.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'blog'::regclass,\n   destination => 'blog_contents_embeddings',\n   embedding => ai.embedding_voyageai(\n           'voyage-3-lite',\n           512\n   ),\n   chunking => ai.chunking_recursive_character_text_splitter('contents')\n);\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI and Voyage AI Vectorizers for SEC Filings\nDESCRIPTION: Sets up two vectorizers using different embedding models: OpenAI's text-embedding-3-small (768 dim) and Voyage's finance-2 (1024 dim). Each uses recursive character text splitting with 512 character chunks.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- OpenAI text-embedding-3-small (768 dim)\nSELECT ai.create_vectorizer(\n    'sec_filings'::regclass,\n    destination => 'sec_filings_openai_embeddings',\n    embedding => ai.embedding_openai('text-embedding-3-small', 768),\n    chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n\n-- Voyage finance-2 (1024 dim)\nSELECT ai.create_vectorizer(\n    'sec_filings'::regclass,\n    destination => 'sec_filings_voyage_embeddings',\n    embedding => ai.embedding_voyageai('voyage-finance-2', 1024),\n    chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search Query\nDESCRIPTION: SQL query to perform semantic search on blog content embeddings using a similarity comparison.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    chunk,\n    embedding <=>  ai.ollama_embed('nomic-embed-text', 'good food', host => 'http://ollama:11434') as distance\nFROM blog_contents_embeddings\nORDER BY distance\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Text Embedding Generation Examples\nDESCRIPTION: Shows various ways to generate embeddings including single text, multiple texts, and tokenized input.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_embed\n( 'text-embedding-ada-002'\n, 'the purple elephant sits on a red mushroom'\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_embed\n( 'text-embedding-ada-002'\n, array['Timescale is Postgres made Powerful', 'the purple elephant sits on a red mushroom']\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.openai_embed\n( 'text-embedding-ada-002'\n, array[1820,25977,46840,23874,389,264,2579,58466]\n);\n```\n\n----------------------------------------\n\nTITLE: Basic Text Embedding Query\nDESCRIPTION: Generates embeddings for a single text input using the voyage-3-lite model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.voyageai_embed('voyage-3-lite', 'sample text to embed');\n```\n\n----------------------------------------\n\nTITLE: Granting Regular Usage Permissions in PostgreSQL\nDESCRIPTION: Example of granting basic AI usage permissions to an analyst role. Provides standard access without administrative privileges.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.grant_ai_usage('analyst_role');\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer with Default Formatting\nDESCRIPTION: Demonstrates how to create an AI vectorizer for 'blog_posts' using the default Python formatter. The template format is defined to output the text chunk exactly as it is using $chunk placeholder.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    formatting => ai.formatting_python_template('$chunk'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Tokenizing Text with Cohere in SQL\nDESCRIPTION: SQL example showing how to tokenize a text string using the cohere_tokenize function with the 'command' model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.cohere_tokenize\n( 'command'\n, 'One of the best programming skills you can have is knowing when to walk away for awhile.'\n);\n```\n\n----------------------------------------\n\nTITLE: Generating SQL from Text with Implicit Location (SQL)\nDESCRIPTION: Calls `ai.text_to_sql` with a question (\"How many flights arrived in Houston, TX in June 2024?\") that requires the LLM to infer the airport code(s) for Houston, TX. This demonstrates generating a potentially more complex query involving joins with an airport table based on city and state/region.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nselect ai.text_to_sql('How many flights arrived in Houston, TX in June 2024?');\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer using SQL Functions\nDESCRIPTION: This SQL snippet demonstrates how to create a vectorizer using pgai's SQL functions, including embedding and chunking configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    embedding => ai.embedding_openai('text-embedding-3-small', 768),\n    chunking => ai.chunking_recursive_character_text_splitter(\n        'content',\n        50,  -- chunk_size\n        10   -- chunk_overlap\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Embedding Storage Table Schema\nDESCRIPTION: Defines the table structure for storing blog content embeddings with UUID primary key, foreign key references, and vector data type for embeddings.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog_contents_embeddings_store(\n    embedding_uuid UUID NOT NULL PRIMARY KEY DEFAULT gen_random_uuid(),     \n    id INT,  -- primary key referencing the blog table\n    chunk_seq INT NOT NULL, \n    chunk TEXT NOT NULL,\n    embedding VECTOR(768) NOT NULL,\n    UNIQUE (id, chunk_seq),\n    FOREIGN KEY (id) REFERENCES public.blog(id) ON DELETE CASCADE\n);\n```\n\n----------------------------------------\n\nTITLE: Example SQL Query Generated by ai.text_to_sql (Text)\nDESCRIPTION: Shows an example SQL query that might be generated by the `ai.text_to_sql` function for the question about flights arriving at IAH in June 2024. The output includes the generated SQL for counting flights within the specified date range and airport, indicating it's a single row result. Note that the actual output might vary.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_17\n\nLANGUAGE: Text\nCODE:\n```\n```text\n               text_to_sql\n-----------------------------------------\n SELECT COUNT(*) AS flight_count        +\n FROM postgres_air.flight               +\n WHERE arrival_airport = 'IAH'          +\n   AND scheduled_arrival >= '2024-06-01'+\n   AND scheduled_arrival < '2024-07-01';\n(1 row)\n```\n```\n\n----------------------------------------\n\nTITLE: Entity Detection Query Example\nDESCRIPTION: Simple example of using the detect_entities function to extract named entities from text, showing person, organization, and location recognition.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM detect_entities('John works at Timescale in New York.');\n```\n\n----------------------------------------\n\nTITLE: Checking Vectorizer Status\nDESCRIPTION: SQL query to check the status of all created vectorizers to ensure they are running properly.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.vectorizer_status;\n```\n\n----------------------------------------\n\nTITLE: Sample embedding output\nDESCRIPTION: Example output from the ai.ollama_embed function showing a vector representation of the input text.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n                      ollama_embed                      \n--------------------------------------------------------\n    [0.65253496,0.63268006,... 1.5451192,-2.6915514]\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating Base Blog Table Schema in SQL\nDESCRIPTION: SQL schema definition for a blog table that will be used for vector embeddings, including columns for id, title, authors, contents and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog(\n    id        SERIAL PRIMARY KEY,\n    title     TEXT,\n    authors   TEXT,\n    contents  TEXT,\n    metadata  JSONB \n);\n```\n\n----------------------------------------\n\nTITLE: Basic Dataset Loading with ai.load_dataset\nDESCRIPTION: Example showing the basic usage of ai.load_dataset to load the 'squad' dataset from Hugging Face into PostgreSQL and query the resulting table.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.load_dataset('squad');\n\nselect * from squad limit 10;\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI Embedding Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using OpenAI's text-embedding-3-small model with 1024 dimensions and recursive character text splitting\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/README.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'paul_graham_essays'::regclass,\n    destination => 'essays_openai_small_embeddings',\n    embedding => ai.embedding_openai(\n        'text-embedding-3-small', \n        1024, \n        api_key_name => 'OPENAI_API_KEY'\n    ),\n    chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for TimescaleDB and Vectorizer Worker\nDESCRIPTION: Docker compose configuration that sets up TimescaleDB with pgai, pgvectorscale, and timescaledb, along with the pgai vectorizer worker. Includes environment variables for Postgres and VoyageAI API authentication.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-voyage.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai\nservices:\n  db:\n    image: timescale/timescaledb-ha:pg17\n    environment:\n      POSTGRES_PASSWORD: postgres\n      VOYAGE_API_KEY: your-api-key\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/home/postgres/pgdata/data\n  vectorizer-worker:\n    image: timescale/pgai-vectorizer-worker:latest\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\n      VOYAGE_API_KEY: your-api-key\n    command: [ \"--poll-interval\", \"5s\" ]\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Generated SQL Query for Houston Flights\nDESCRIPTION: SQL query generated by pgai in response to the natural language question about Houston flights, showing how it correctly identifies the airport code, date range, and required table.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n SELECT COUNT(*) AS num_flights\n FROM postgres_air.flight\n WHERE arrival_airport = 'IAH'\n   AND scheduled_arrival >= '2024-06-01'::timestamptz\n   AND scheduled_arrival < '2024-07-01'::timestamptz;\n```\n\n----------------------------------------\n\nTITLE: Configuring User Permissions for Vectorizer in SQL\nDESCRIPTION: Grants permissions on the vectorizer objects to specific database users (bob and alice). This ensures that only authorized users can access and use the objects created by the vectorizer.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\n  SELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    grant_to => ai.grant_to('bob', 'alice'),\n    -- other parameters...\n  );\n```\n\n----------------------------------------\n\nTITLE: Diagnosing Background Job Errors\nDESCRIPTION: Queries the job history to check for error messages from the background moderation job in the last 10 minutes.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nselect err_message from timescaledb_information.job_history\nwhere proc_name = 'check_new_comments_to_moderate'\nand finish_time is not null\nand finish_time > now() - interval '10 minutes';\n```\n\n----------------------------------------\n\nTITLE: Configuring Processing Parameters for Vectorizer in SQL\nDESCRIPTION: Customizes the processing configuration for a vectorizer, setting the batch size to 200 and concurrency to 5. These parameters control how many items are processed at once and how many concurrent processing tasks are executed.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\n  SELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    processing => ai.processing_default(batch_size => 200, concurrency => 5),\n    -- other parameters...\n  );\n```\n\n----------------------------------------\n\nTITLE: Listing Cohere Models for Specific Endpoint\nDESCRIPTION: SQL query that filters Cohere models to only show those supporting a specific endpoint (embedding in this example).\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect *\nfrom ai.cohere_list_models(endpoint=>'embed')\n;\n```\n\n----------------------------------------\n\nTITLE: Creating PGAI Extension in PostgreSQL\nDESCRIPTION: SQL command to create the PGAI extension with cascade option to automatically install required dependencies\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/source.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Disabling a Vectorizer Schedule in SQL\nDESCRIPTION: Example of using the ai.disable_vectorizer_schedule function to temporarily stop automatic processing for a specific vectorizer.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.disable_vectorizer_schedule(1);\n```\n\n----------------------------------------\n\nTITLE: Chat Completion Examples\nDESCRIPTION: Demonstrates text generation using OpenAI's chat completion API with different output formats.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\\pset tuples_only on\n\\pset format unaligned\n\nSELECT jsonb_pretty\n(\n  ai.openai_chat_complete\n  ( 'gpt-4o'\n  , jsonb_build_array\n    ( jsonb_build_object('role', 'system', 'content', 'you are a helpful assistant')\n    , jsonb_build_object('role', 'user', 'content', 'what is the typical weather like in Alabama in June')\n    )\n  )\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\n\\pset tuples_only on\n\\pset format unaligned\n\nselect ai.openai_chat_complete\n( 'gpt-4o'\n, jsonb_build_array\n  ( jsonb_build_object('role', 'system', 'content', 'you are a helpful assistant')\n  , jsonb_build_object('role', 'user', 'content', 'what is the typical weather like in Alabama in June')\n  )\n)->'choices'->0->'message'->>'content'\n;\n```\n\n----------------------------------------\n\nTITLE: Creating Mistral Embedding Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using Mistral's embedding model with 1024 dimensions and recursive character text splitting\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'paul_graham_essays'::regclass,\n    destination => 'essays_mistral_embeddings',\n    embedding => ai.embedding_litellm(\n        'mistral/mistral-embed',\n        1024,\n        api_key_name => 'MISTRAL_API_KEY'\n    ),\n    chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: Scheduling Background Moderation Job\nDESCRIPTION: Schedules the background moderation job to run every 5 seconds with the OpenAI API key configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT add_job('check_new_comments_to_moderate','5 seconds',\n  config => format('{\"api_key\": \"%s\"}', :'OPENAI_API_KEY')::jsonb);\n```\n\n----------------------------------------\n\nTITLE: Listing Ollama models with SQL\nDESCRIPTION: SQL query to list all available models supported by the Ollama provider in pgai, ordered by size in descending order.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * \nFROM ai.ollama_list_models()\nORDER BY size DESC\n;\n```\n\n----------------------------------------\n\nTITLE: Configuring Cohere Embedding Model\nDESCRIPTION: Shows configuration for Cohere's embed-english-v3.0 model with 1024 dimensions using LiteLLM interface.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'cohere/embed-english-v3.0',\n      1024,\n      api_key_name => 'COHERE_API_KEY',\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Comments Table with Moderation Status\nDESCRIPTION: Creates a table to store comments with fields for body text, creation timestamp, and moderation status.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE comments (\n    id SERIAL PRIMARY KEY,\n    body TEXT NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    status TEXT NOT NULL DEFAULT 'pending'\n);\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Blog Data\nDESCRIPTION: SQL commands to insert sample blog posts with various topics and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO blog (title, authors, contents, metadata)\nVALUES\n('Getting Started with PostgreSQL', 'John Doe', 'PostgreSQL is a powerful, open source object-relational database system...', '{\"tags\": [\"database\", \"postgresql\", \"beginner\"], \"read_time\": 5, \"published_date\": \"2024-03-15\"}'),\n\n('10 Tips for Effective Blogging', 'Jane Smith, Mike Johnson', 'Blogging can be a great way to share your thoughts and expertise...', '{\"tags\": [\"blogging\", \"writing\", \"tips\"], \"read_time\": 8, \"published_date\": \"2024-03-20\"}'),\n\n('The Future of Artificial Intelligence', 'Dr. Alan Turing', 'As we look towards the future, artificial intelligence continues to evolve...', '{\"tags\": [\"AI\", \"technology\", \"future\"], \"read_time\": 12, \"published_date\": \"2024-04-01\"}'),\n\n('Healthy Eating Habits for Busy Professionals', 'Samantha Lee', 'Maintaining a healthy diet can be challenging for busy professionals...', '{\"tags\": [\"health\", \"nutrition\", \"lifestyle\"], \"read_time\": 6, \"published_date\": \"2024-04-05\"}'),\n\n('Introduction to Cloud Computing', 'Chris Anderson', 'Cloud computing has revolutionized the way businesses operate...', '{\"tags\": [\"cloud\", \"technology\", \"business\"], \"read_time\": 10, \"published_date\": \"2024-04-10\"}');\n```\n\n----------------------------------------\n\nTITLE: Vertex AI Embedding Setup\nDESCRIPTION: Configuration for Google Vertex AI embedding model with project and credentials setup.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'vertex_ai/text-embedding-005',\n      768,\n      api_key_name => 'VERTEX_CREDENTIALS', -- optional\n      extra_options => '{\"vertex_project\": \"<project id>\", \"vertex_location\": \"<vertex location>\"}'::jsonb -- optional\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Getting Exact Count of Pending Items for a Vectorizer in SQL\nDESCRIPTION: Uses the ai.vectorizer_queue_pending function with the exact_count parameter set to true to retrieve the precise number of pending items for vectorizer ID 1, regardless of queue size.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.vectorizer_queue_pending(1, exact_count=>true);\n```\n\n----------------------------------------\n\nTITLE: Promoting User to AI Administrator in PostgreSQL\nDESCRIPTION: Example demonstrating how to grant administrative AI privileges to an existing user.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.grant_ai_usage('experienced_user', admin => true);\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset using pgai Extension\nDESCRIPTION: SQL command to load the Paul Graham essays dataset from HuggingFace into the PostgreSQL table.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset('sgoel9/paul_graham_essays', table_name => 'pg_essays', if_table_exists => 'append');\n```\n\n----------------------------------------\n\nTITLE: Defining Evaluation Parameters for Embedding Models\nDESCRIPTION: Sets up parameters for evaluating the embedding models, including the number of chunks, questions per chunk, and distribution of question types.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nNUM_CHUNKS = 20\nNUM_QUESTIONS_PER_CHUNK = 20\nTOP_K = 10\n\nQUESTION_DISTRIBUTION = {\n    'short': 4,\n    'long': 4,\n    'direct': 4,\n    'implied': 4,\n    'unclear': 4\n}\n\nassert sum(QUESTION_DISTRIBUTION.values()) == NUM_QUESTIONS_PER_CHUNK\n```\n\n----------------------------------------\n\nTITLE: Setting up Mistral Embedding Model\nDESCRIPTION: Configuration example for Mistral embedding model with 1024 dimensions and API key authentication.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'mistral/mistral-embed',\n      1024,\n      api_key_name => 'MISTRAL_API_KEY',\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Sample Ollama model listing output\nDESCRIPTION: Example output from the ai.ollama_list_models() function showing model information including name, size, and other metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n     name      |     model     |    size    |                              digest                              | family | format |     families      | parent_model | parameter_size | quantization_level |          modified_at          \n---------------+---------------+------------+------------------------------------------------------------------+--------+--------+-------------------+--------------+----------------+--------------------+-------------------------------\n llava:7b      | llava:7b      | 4733363377 | 8dd30f6b0cb19f555f2c7a7ebda861449ea2cc76bf1f44e262931f45fc81d081 | llama  | gguf   | [\"llama\", \"clip\"] |              | 7B             | Q4_0               | 2024-06-17 21:01:26.225392+00\n llama3:latest | llama3:latest | 4661224676 | 365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1 | llama  | gguf   | [\"llama\"]         |              | 8.0B           | Q4_0               | 2024-06-12 21:28:38.49735+00\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Dropping a Vectorizer in SQL\nDESCRIPTION: Example of removing a vectorizer configuration from the system while preserving its target table and view.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\n-- Assuming we have a vectorizer with ID 1\nSELECT ai.drop_vectorizer(1);\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset using pgai\nDESCRIPTION: SQL command to load Paul Graham's essays dataset from HuggingFace into the database\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset('sgoel9/paul_graham_essays');\n```\n\n----------------------------------------\n\nTITLE: Using API Key with VoyageAI Embedding\nDESCRIPTION: SQL query example showing how to call the VoyageAI embedding function with a named API key.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.voyageai_embed('voyage-3-lite', 'sample text to embed', api_key_name => 'my_api_key');\n```\n\n----------------------------------------\n\nTITLE: Results Table Creation and Formatting\nDESCRIPTION: Creates a formatted pandas DataFrame to display evaluation results with styling for better visualization. Includes overall accuracy and per-question-type metrics.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef create_results_table(evaluation_results):\n    # Create lists to store the data\n    rows = []\n    \n    # Process each model's results\n    for result in evaluation_results:\n        row = {\n            'Model': result['model'],\n            'Overall Accuracy': f\"{result['overall_accuracy']:.2%}\",\n        }\n        # Add accuracies for each question type\n        for q_type, acc in result['by_type'].items():\n            row[q_type.capitalize()] = f\"{acc:.2%}\"\n        \n        rows.append(row)\n    \n    # Create DataFrame\n    df = pd.DataFrame(rows)\n    \n    # Reorder columns to put Overall Accuracy after Model\n    columns = ['Model', 'Overall Accuracy'] + [col for col in df.columns if col not in ['Model', 'Overall Accuracy']]\n    df = df[columns]\n    \n    # Display the table\n    return df.style.set_properties(**{\n        'text-align': 'center',\n        'border': '1px solid black',\n        'padding': '8px'\n    }).set_table_styles([\n        {'selector': 'th', 'props': [\n            ('background-color', 'black'),\n            ('text-align', 'center'),\n            ('padding', '8px'),\n            ('border', '1px solid black')\n        ]},\n        {'selector': 'caption', 'props': [\n            ('text-align', 'center'),\n            ('font-weight', 'bold'),\n            ('font-size', '1.1em'),\n            ('padding', '8px')\n        ]}\n    ]).set_caption('Embedding Models Evaluation Results')\n```\n\n----------------------------------------\n\nTITLE: Scheduling Background Job\nDESCRIPTION: Schedules the embedding population job to run every 10 seconds using TimescaleDB's job scheduler.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT add_job('populate_embedding','10s', fixed_schedule => true,\n  config => format('{\"api_key\": \"%s\"}', :'OPENAI_API_KEY')::jsonb);\n```\n\n----------------------------------------\n\nTITLE: Using Default Scheduling with Vectorizer in SQL\nDESCRIPTION: Configures a vectorizer with the platform-specific default scheduling configuration. On Timescale Cloud, this defaults to timescaledb scheduling, while on self-hosted environments it defaults to no automatic scheduling.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_default(),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Messages for Text to SQL\nDESCRIPTION: SQL command to enable debug messages, which show the prompts sent to the LLM and the responses received when using the text_to_sql function.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nset client_min_messages to 'DEBUG1';\n```\n\n----------------------------------------\n\nTITLE: Setting Ollama host configuration at session level\nDESCRIPTION: Sets the Ollama host configuration parameter at the session level using set_config SQL function.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect set_config('ai.ollama_host', 'http://host.for.ollama:port', false);\n```\n\n----------------------------------------\n\nTITLE: Running pgai Vectorizer Worker Container\nDESCRIPTION: Docker command to start the vectorizer worker container with database connection configuration. This worker syncs data and creates embeddings for the pgai system.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/docker.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name pgai-vectorizer-worker -e PGAI_VECTORIZER_WORKER_DB_URL=postgres://postgres:password@localhost/postgres timescale/pgai-vectorizer-worker:latest\n```\n\n----------------------------------------\n\nTITLE: Loading SEC Filings Dataset from Hugging Face\nDESCRIPTION: Uses pgai's load_dataset function to import SEC filings data from Hugging Face into the PostgreSQL database. Supports batch processing and handles existing tables.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset(\n    name => 'MemGPT/example-sec-filings',\n    table_name => 'sec_filings',\n    batch_size => 1000,\n    max_batches => 10,\n    if_table_exists => 'append'\n);\n```\n\n----------------------------------------\n\nTITLE: Listing OpenAI Models\nDESCRIPTION: Queries available OpenAI models sorted by creation date.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * \nFROM ai.openai_list_models()\nORDER BY created DESC\n;\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI text-embedding-3-small Vectorizer\nDESCRIPTION: SQL command to create a vectorizer using OpenAI's small embedding model with 768 dimensions, chunking the text into 512 character segments with 50 character overlap.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n   'pg_essays'::regclass,\n   destination => 'essays_openai_small_embeddings',\n   embedding => ai.embedding_openai('text-embedding-3-small', 768),\n   chunking => ai.chunking_recursive_character_text_splitter('text', 512, 50)\n);\n```\n\n----------------------------------------\n\nTITLE: SQL Example: Delayed Embedding Implementation\nDESCRIPTION: Example SQL code showing how to implement delayed embedding functionality using pgAI and VectorScale extensions\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Configuring No Automatic Scheduling for Vectorizer in SQL\nDESCRIPTION: Sets up a vectorizer with no automatic scheduling, allowing for manual control over when the vectorizer runs. This is the recommended approach for self-hosted deployments or when using external scheduling systems.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    scheduling => ai.scheduling_none(),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Sample chat completion content output\nDESCRIPTION: Example output showing just the text content extracted from a chat completion response using JSONB operators.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nA large language model (LLM) is a type of artificial intelligence designed to process and generate human-like language. It's trained on massive amounts of text data, such as books, articles, and online conversations, which allows it to learn patterns, relationships, and nuances of language.\n\nAn LLM can perform various tasks, including:\n\n1. Natural Language Processing (NLP): understanding and generating human language.\n2. Text generation: creating original text based on input prompts or topics.\n3. Question answering: providing accurate answers to questions posed in natural language.\n4. Sentiment analysis: determining the emotional tone or sentiment behind a piece of text.\n\nLarge language models are typically trained using deep learning algorithms, such as transformer-based architectures (like BERT, RoBERTa, and XLNet), which enable them to learn from vast amounts of data and generate coherent, context-specific responses.\n\nThese models have numerous applications in areas like:\n\n1. Virtual assistants: providing helpful information and answering user queries.\n2. Language translation: facilitating communication between people speaking different languages.\n3. Content creation: generating text for articles, blog posts, or even entire books.\n4. Chatbots: enabling conversational interfaces that can engage with users.\n\nIn summary, a large language model is a powerful AI tool capable of processing and generating human-like language, with applications in various industries and aspects of our lives!\n```\n\n----------------------------------------\n\nTITLE: Huggingface Inference Model Configuration\nDESCRIPTION: Configuration for Huggingface inference model with wait_for_model parameter to ensure model availability.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'huggingface/BAAI/bge-small-en-v1.5',\n    , 384\n    , extra_options => '{\"wait_for_model\": true}'::jsonb\n    )\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Viewing Moderated Comments Results\nDESCRIPTION: Displays the comments table with moderation statuses after the trigger has processed the inserted comments.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ntable comments;\n```\n\n----------------------------------------\n\nTITLE: Creating SEC Filings Table in PostgreSQL\nDESCRIPTION: Creates a table to store SEC filings text data with a serial primary key, which is required for the pgai Vectorizer.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE sec_filings (\n    id SERIAL PRIMARY KEY,\n    text text\n);\n```\n\n----------------------------------------\n\nTITLE: Single Text Embedding with Model Specification\nDESCRIPTION: Generates embeddings for a specific text string using the voyage-3-lite model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.voyageai_embed\n( 'voyage-3-lite'\n, 'the purple elephant sits on a red mushroom'\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Questions of Different Types for Evaluation\nDESCRIPTION: Creates a function to generate questions of different types (short, long, direct, implied, unclear) for each text chunk using the Ollama LLM.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef generate_questions_by_question_type(chunk, question_type, num_questions):\n    prompts = {\n        'short': \"Generate {count} short, simple questions about this text. Questions should be direct, under 10 words\",\n        'long': \"Generate {count} detailed, comprehensive questions about this text. Include specific details:\",\n        'direct': \"Generate {count} questions that directly ask about explicit information in this text\",\n        'implied': \"Generate {count} questions that require understanding context and implications of the text:\",\n        'unclear': \"Generate {count} vague, ambiguous questions about the general topic of this text:\"\n    }\n\n    prompt = prompts[question_type].format(count=num_questions) + f\"\\n\\nText: {chunk}\"\n\n    system_instructions = \"\"\"\n        Generate different types of questions about the given text following the prompt provided. \n        Each question must be on a new line. Do not include empty lines or blank questions.\n    \"\"\"\n\n    with connect_db() as conn:\n        with conn.cursor() as cur:\n            cur.execute(\"\"\"\n                SELECT ai.ollama_generate(\n                    'llama3.2',\n                    %s,\n                    system_prompt=>%s, \n                    host=>%s\n                )->>'response';\n            \"\"\",(prompt, system_instructions, OLLAMA_HOST))\n\n            generated_questions = [q.strip() for q in cur.fetchone()[0].split(\"\\n\") if q.strip()]\n            print(f\"Number of questions generated for {question_type}: {len(generated_questions)}\")\n            return generated_questions \n```\n\n----------------------------------------\n\nTITLE: Creating Vectorizer for Blog Content\nDESCRIPTION: SQL command to create a vectorizer for the blog table using Ollama embedding model with specified parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n     'blog'::regclass,\n     destination => 'blog_contents_embeddings',\n     embedding => ai.embedding_ollama('nomic-embed-text', 768),\n     chunking => ai.chunking_recursive_character_text_splitter('contents')\n);\n```\n\n----------------------------------------\n\nTITLE: Creating New Analyst with AI Permissions in PostgreSQL\nDESCRIPTION: Example showing how to create a new analyst role and grant them basic AI usage permissions.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE new_analyst;\nSELECT ai.grant_ai_usage('new_analyst');\n```\n\n----------------------------------------\n\nTITLE: Checking Vectorizer Status in PostgreSQL\nDESCRIPTION: SQL query to verify the status of vectorization processes in the database, useful for monitoring progress of embedding generation.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.vectorizer_status;\n```\n\n----------------------------------------\n\nTITLE: Testing Comment Moderation with Sample Data\nDESCRIPTION: Inserts test comments with varying content to demonstrate the moderation functionality.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\ninsert into comments (body) values\n  ('I love the new product'),\n  ('He is an asshole'),\n  ('I want to kill them all');\n```\n\n----------------------------------------\n\nTITLE: Using API Key Name in pgai Functions\nDESCRIPTION: Example showing how to call pgai functions with a named API key reference using the api_key_name parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ai.openai_list_models(api_key_name => 'MY_API_KEY');\n```\n\n----------------------------------------\n\nTITLE: Creating Blog Table Schema in PostgreSQL\nDESCRIPTION: SQL command to create a blog table with columns for ID, title, authors, contents, and metadata in JSONB format.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-voyage.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog (\n    id SERIAL PRIMARY KEY,\n    title TEXT,\n    authors TEXT,\n    contents TEXT,\n    metadata JSONB\n);\n```\n\n----------------------------------------\n\nTITLE: Monitoring Vectorizer Queue Status\nDESCRIPTION: SQL query to check if the semantic catalog descriptions have been embedded. The query shows the number of pending items in the object and SQL vectorizer queues, which should eventually reach zero.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect\n  ai.vectorizer_queue_pending(k.obj_vectorizer_id) as obj_pending,\n  ai.vectorizer_queue_pending(k.sql_vectorizer_id) as sql_pending\nfrom ai.semantic_catalog k\nwhere k.catalog_name = 'default';\n```\n\n----------------------------------------\n\nTITLE: Advanced Anthropic Query with Text Extraction\nDESCRIPTION: SQL query showing how to generate and extract specific content from an Anthropic AI response using JSON path extraction\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\\pset tuples_only on\n\\pset format unaligned\n\nselect jsonb_extract_path_text\n(\n   ai.anthropic_generate\n   ( 'claude-3-5-sonnet-20240620'\n   , jsonb_build_array\n     ( jsonb_build_object\n       ( 'role', 'user'\n       , 'content', 'Name five famous people from Birmingham, Alabama.'\n       )\n     )\n   )\n, 'content', '0', 'text'\n);\n```\n\n----------------------------------------\n\nTITLE: Granting Team-wide AI Access in PostgreSQL\nDESCRIPTION: Example showing how to grant AI permissions to an entire team role.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.grant_ai_usage('data_science_team');\n```\n\n----------------------------------------\n\nTITLE: Detokenizing Token IDs with Cohere in SQL\nDESCRIPTION: SQL example demonstrating how to convert token IDs back to text using the cohere_detokenize function with the 'command' model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.cohere_detokenize\n( 'command'\n, array[14485,38374,2630,2060,2252,5164,4905,21,2744,2628,1675,3094,23407,21]\n);\n```\n\n----------------------------------------\n\nTITLE: Enabling a Vectorizer Schedule in SQL\nDESCRIPTION: Example of using the ai.enable_vectorizer_schedule function to resume automatic scheduling for a specific vectorizer.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.enable_vectorizer_schedule(1);\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL with Cohere API Key as Parameter\nDESCRIPTION: Connects to a PostgreSQL database while passing the Cohere API key as a session parameter using PGOPTIONS.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.cohere_api_key=$COHERE_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Creating Document Embedding Table\nDESCRIPTION: Creates a table structure for storing documents and their vector embeddings with a 1536-dimensional vector field.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS document_embedding  (\n    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n    metadata JSONB,\n    contents TEXT,\n    embedding VECTOR(1536)\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Blog Table in PostgreSQL\nDESCRIPTION: This SQL command creates a 'blog' table with columns for id, title, authors, contents, and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog (\n    id SERIAL PRIMARY KEY,\n    title TEXT,\n    authors TEXT,\n    contents TEXT,\n    metadata JSONB\n);\n```\n\n----------------------------------------\n\nTITLE: Creating and Dropping Vectorizers with Alembic Operations\nDESCRIPTION: This code example shows how to use Alembic operations to create and drop vectorizers in migration scripts.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom alembic import op\nfrom pgai.vectorizer.configuration import (\n    EmbeddingOpenaiConfig,\n    ChunkingCharacterTextSplitterConfig,\n    FormattingPythonTemplateConfig\n)\n\n\ndef upgrade() -> None:\n    op.create_vectorizer(\n        source=\"blog\",\n        target_table='blog_embeddings',\n        embedding=EmbeddingOpenaiConfig(\n            model='text-embedding-3-small',\n            dimensions=768\n        ),\n        chunking=ChunkingCharacterTextSplitterConfig(\n            chunk_column='content',\n            chunk_size=800,\n            chunk_overlap=400,\n            separator='.',\n            is_separator_regex=False\n        ),\n        formatting=FormattingPythonTemplateConfig(template='$title - $chunk')\n    )\n\n\ndef downgrade() -> None:\n    op.drop_vectorizer(target_table=\"blog_embeddings\", drop_all=True)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Pending Items Count for a Vectorizer in SQL\nDESCRIPTION: Uses the ai.vectorizer_queue_pending function to return the number of pending items for a specific vectorizer with ID 1. This is the basic usage of the function.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.vectorizer_queue_pending(1);\n```\n\n----------------------------------------\n\nTITLE: Creating DiskANN Index\nDESCRIPTION: Creates a DiskANN index on the embedding column for faster similarity searches.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX document_embedding_idx ON document_embedding\nUSING diskann (embedding);\n```\n\n----------------------------------------\n\nTITLE: Selecting Random Evaluation Chunks from Embeddings\nDESCRIPTION: Selects a random sample of text chunks from the nomic-embed-text embeddings view for evaluation and saves them to a CSV file.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd \n\nevaluation_chunks = []\n\nwith connect_db() as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n                SELECT id, chunk_seq, chunk, title \n                FROM essays_nomic_embed_text_embeddings \n                ORDER BY RANDOM() \n                LIMIT %s\n            \"\"\", (NUM_CHUNKS,))\n        \n        for row in cur.fetchall():\n            evaluation_chunks.append({\n                'id': row[0],\n                'chunk_seq': row[1],\n                'chunk': row[2],\n                'title': row[3]\n            })\n\npd.DataFrame(evaluation_chunks).to_csv('./chunks.csv')\n```\n\n----------------------------------------\n\nTITLE: Basic Function Signature for AI Usage Permissions in PostgreSQL\nDESCRIPTION: Defines the core function signature for granting AI usage permissions to users or roles. Takes a username parameter and an optional admin boolean flag.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.grant_ai_usage(to_user name, admin bool DEFAULT false)\n```\n\n----------------------------------------\n\nTITLE: Loading with Custom Table Name and Field Types\nDESCRIPTION: Example showing how to load a dataset with a custom table name and specify PostgreSQL data types for specific fields using the field_types parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset(\n    name => 'glue',\n    config_name => 'mrpc',\n    table_name => 'mrpc',\n    field_types => '{\"sentence1\": \"text\", \"sentence2\": \"text\"}'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Blog Table Schema\nDESCRIPTION: SQL command to create a blog table with fields for title, authors, contents, and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog (\n    id SERIAL PRIMARY KEY,\n    title TEXT,\n    authors TEXT,\n    contents TEXT,\n    metadata JSONB\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Blog Table Schema\nDESCRIPTION: SQL command to create a blog table with columns for id, title, authors, contents, and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE blog (\n    id SERIAL PRIMARY KEY,\n    title TEXT,\n    authors TEXT,\n    contents TEXT,\n    metadata JSONB\n);\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Extension in PostgreSQL\nDESCRIPTION: SQL command to create and enable the pgai extension in the PostgreSQL database after connecting to it.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai cascade;\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose Services for pgai\nDESCRIPTION: Shell command to start the Docker Compose services defined in the configuration file. This command initializes the local Postgres instance, Ollama service, and vectorizer worker.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Checking Vectorizer Status\nDESCRIPTION: SQL query to check the progress of embedding creation\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nselect * from ai.vectorizer_status;\n```\n\n----------------------------------------\n\nTITLE: Adding Context in Vectorizer Format\nDESCRIPTION: Shows how to format an AI vectorizer output by adding the title and publication date to the chunk format. It uses placeholders for additional columns to provide context for embeddings.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    formatting => ai.formatting_python_template('Title: $title\\nDate: $published\\nContent: $chunk'),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Setting psql Variable from Environment with \\getenv\nDESCRIPTION: SQL metacommand to set a psql variable from an environment variable after connecting to the database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\\getenv my_api_key MY_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Results Display Execution\nDESCRIPTION: Executes the evaluation process and displays the formatted results table.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Display the results\nevaluation_results = evaluate_embedding_models()\nresults_table = create_results_table(evaluation_results)\ndisplay(results_table)\n```\n\n----------------------------------------\n\nTITLE: Text Anonymization Query Example\nDESCRIPTION: Demonstrates using the anonymize_text function to replace named entities with their type identifiers in text.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM anonymize_text('John works at Timescale in New York.');\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset with Multiple Transactions\nDESCRIPTION: Example showing how to load a large dataset using multiple transactions with the ai.load_dataset_multi_txn procedure, committing after every 10 batches.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCALL ai.load_dataset_multi_txn('squad', commit_every_n_batches => 10);\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Blog Data\nDESCRIPTION: SQL insert statements to populate the blog table with sample data including titles, authors, contents, and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO blog (title, authors, contents, metadata)\nVALUES\n('Getting Started with PostgreSQL', 'John Doe', 'PostgreSQL is a powerful, open source object-relational database system...', '{\"tags\": [\"database\", \"postgresql\", \"beginner\"], \"read_time\": 5, \"published_date\": \"2024-03-15\"}'),\n\n('10 Tips for Effective Blogging', 'Jane Smith, Mike Johnson', 'Blogging can be a great way to share your thoughts and expertise...', '{\"tags\": [\"blogging\", \"writing\", \"tips\"], \"read_time\": 8, \"published_date\": \"2024-03-20\"}'),\n\n('The Future of Artificial Intelligence', 'Dr. Alan Turing', 'As we look towards the future, artificial intelligence continues to evolve...', '{\"tags\": [\"AI\", \"technology\", \"future\"], \"read_time\": 12, \"published_date\": \"2024-04-01\"}'),\n\n('Healthy Eating Habits for Busy Professionals', 'Samantha Lee', 'Maintaining a healthy diet can be challenging for busy professionals...', '{\"tags\": [\"health\", \"nutrition\", \"lifestyle\"], \"read_time\": 6, \"published_date\": \"2024-04-05\"}'),\n\n('Introduction to Cloud Computing', 'Chris Anderson', 'Cloud computing has revolutionized the way businesses operate...', '{\"tags\": [\"cloud\", \"technology\", \"business\"], \"read_time\": 10, \"published_date\": \"2024-04-10\"}');\n```\n\n----------------------------------------\n\nTITLE: Enabling pgai Extension in Postgres\nDESCRIPTION: SQL command to enable the pgai extension and its dependencies in the database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Running Vectorizer Worker Locally\nDESCRIPTION: Shell command to run the vectorizer worker using the locally installed pgai package. This command processes vectorizers defined in the specified database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npgai vectorizer worker -d <db-connection-string>\n```\n\n----------------------------------------\n\nTITLE: Monitoring Vectorizer Progress\nDESCRIPTION: Checks the status of vectorizers to monitor their progress in generating embeddings by querying the ai.vectorizer_status view.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith connect_db() as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT * FROM ai.vectorizer_status;\")\n\n        for row in cur.fetchall():\n            print(f\"Vectorizer ID: {row[0]}, Embedding Table: {row[2]}, Pending Items: {row[4]}\")\n        \n```\n\n----------------------------------------\n\nTITLE: SQL Example: Text Summary Generation\nDESCRIPTION: Example SQL code showing how to generate text summaries using the Anthropic API integration\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: Installing pgai Extension\nDESCRIPTION: SQL commands to install the pgai extension with the text-to-SQL feature flag enabled, removing any existing installation first.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -v ON_ERROR_STOP=1 -f - <<EOF\n\ndrop extension if exists ai cascade;\ndrop schema if exists ai cascade;\nselect set_config('ai.enable_feature_flag_text_to_sql', 'true', false);\ncreate extension ai cascade;\n\nEOF\n```\n\n----------------------------------------\n\nTITLE: Enabling pgai Extension in PostgreSQL\nDESCRIPTION: This SQL command enables the pgai extension and its dependencies in the PostgreSQL database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Listing Available Anthropic Models\nDESCRIPTION: SQL query to list all available Anthropic AI models supported by pgai\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * \nFROM ai.anthropic_list_models()\nORDER BY created DESC\n;\n```\n\n----------------------------------------\n\nTITLE: Creating pgai Extension in PostgreSQL\nDESCRIPTION: SQL command executed through Docker to create the pgai extension in the PostgreSQL database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/docker.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it pgai psql -U postgres -c \"CREATE EXTENSION IF NOT EXISTS ai CASCADE;\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for pgai Vectorizer Worker\nDESCRIPTION: Docker Compose configuration file that sets up a local Postgres instance with pgai, an Ollama embedding API service, and a pgai vectorizer worker. This configuration is used for testing pgai and vectorizers locally.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai\nservices:\n  db:\n    image: timescale/timescaledb-ha:pg17\n    environment:\n      POSTGRES_PASSWORD: postgres\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/var/lib/postgresql/data\n  vectorizer-worker:\n    image: timescale/pgai-vectorizer-worker:latest\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\n      OLLAMA_HOST: http://ollama:11434\n    command: [ \"--poll-interval\", \"5s\" ]\n  ollama:\n    image: ollama/ollama\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Loading Paul Graham's Essays into PostgreSQL\nDESCRIPTION: Uses pgai to load the dataset of Paul Graham's essays from Hugging Face into the essays table and verifies the data by displaying the first row.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith connect_db() as conn:\n    with conn.cursor() as cur:\n        # Load Paul Graham's essays dataset into the 'essays' table\n        cur.execute(\"\"\"\n            SELECT ai.load_dataset(\n                    'sgoel9/paul_graham_essays', \n                    table_name => 'essays', \n                    if_table_exists => 'append');\n        \"\"\")\n    \n    with conn.cursor() as cur:\n        # Fetch and print the first row from the 'essays' table to verify the data\n        cur.execute(\"SELECT * FROM essays LIMIT 1;\")\n        print(cur.fetchone())\n```\n\n----------------------------------------\n\nTITLE: Setting Up PostgreSQL Database with pgai Extension\nDESCRIPTION: Creates the pgai extension and initializes a table to store essays with columns for ID, title, date, and text content.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith connect_db() as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"CREATE EXTENSION IF NOT EXISTS ai CASCADE;\")\n\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS essays (\n                id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n                title TEXT NOT NULL,\n                date TEXT,\n                text TEXT NOT NULL\n            );\n          \"\"\") \n```\n\n----------------------------------------\n\nTITLE: Content Tokenization Examples\nDESCRIPTION: Demonstrates tokenizing text content and counting tokens using OpenAI models.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_tokenize\n( 'text-embedding-ada-002'\n, 'Timescale is Postgres made Powerful'\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array_length\n( ai.openai_tokenize\n  ( 'text-embedding-ada-002'\n  , 'Timescale is Postgres made Powerful'\n  )\n, 1\n);\n```\n\n----------------------------------------\n\nTITLE: Generating and Saving Random Text Chunks for Evaluation\nDESCRIPTION: Python code that initializes the evaluator, generates random text chunks from the database, and saves them to a CSV file for later use in the evaluation process.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nevaluator = StepByStepEvaluator()\nchunks = evaluator.step1_get_chunks()\npd.DataFrame(chunks).to_csv('chunks.csv')\n```\n\n----------------------------------------\n\nTITLE: Pre-creating a Table and Appending Data\nDESCRIPTION: Example showing how to pre-create a table with a specific schema and then load data into it using the 'append' option for if_table_exists parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE squad (\n    id          TEXT,\n    title       TEXT,\n    context     TEXT,\n    question    TEXT,\n    answers     JSONB\n);\n\nSELECT ai.load_dataset(\n    name => 'squad',\n    table_name => 'squad',\n    if_table_exists => 'append'\n);\n```\n\n----------------------------------------\n\nTITLE: AWS Bedrock Embedding Configuration\nDESCRIPTION: Setup for AWS Bedrock embedding with AWS credentials and region configuration options.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'my_table'::regclass,\n    embedding => ai.embedding_litellm(\n      'bedrock/amazon.titan-embed-text-v2:0',\n      1024,\n      api_key_name => 'AWS_SECRET_ACCESS_KEY', -- optional\n      extra_options => '{\"aws_access_key_id\": \"<access key id>\", \"aws_region_name\": \"<region name>\"}'::jsonb -- optional\n    ),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Document Embeddings\nDESCRIPTION: Retrieves all documents and their embeddings from the table.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect * from document_embedding;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable with Docker Compose\nDESCRIPTION: YAML configuration showing how to set an API key environment variable in a Docker Compose file for TimescaleDB.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai\nservices:\n  db:\n    image: timescale/timescaledb-ha:pg17\n    environment:\n      MY_API_KEY: <api key here>\n    ...\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset from HuggingFace\nDESCRIPTION: SQL command to load Wikipedia dataset from HuggingFace into the wiki table\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset('wikimedia/wikipedia', '20231101.en', table_name=>'wiki', batch_size=>5, max_batches=>1, if_table_exists=>'append');\n```\n\n----------------------------------------\n\nTITLE: Creating PostgreSQL Table for Paul Graham Essays\nDESCRIPTION: SQL command to create a table with a primary key to store Paul Graham essays, with columns for id, title, date, and text content.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE pg_essays (\n    id SERIAL PRIMARY KEY,\n    title TEXT,\n    date TEXT,\n    text TEXT\n);\n```\n\n----------------------------------------\n\nTITLE: Detokenization Example\nDESCRIPTION: Converts token arrays back into natural language text.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_detokenize('text-embedding-ada-002', array[1820,25977,46840,23874,389,264,2579,58466]);\n```\n\n----------------------------------------\n\nTITLE: Loading Postgres_Air Dataset\nDESCRIPTION: Command to load the Postgres_Air dataset into the demo database, with error stopping enabled to halt on any errors.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -v ON_ERROR_STOP=1 -f postgres_air_2024.sql\n```\n\n----------------------------------------\n\nTITLE: Dropping a Vectorizer with All Associated Objects in SQL\nDESCRIPTION: Example of removing a vectorizer configuration and also dropping its target table and view using the drop_all parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.drop_vectorizer(1, drop_all=>true);\n```\n\n----------------------------------------\n\nTITLE: Checking Pending Items Count for Specific Vectorizer\nDESCRIPTION: Retrieves the exact count of pending items for a specific vectorizer using the vectorizer_queue_pending function with exact counting enabled.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.vectorizer_queue_pending(1, exact_count=>true);\n```\n\n----------------------------------------\n\nTITLE: Setting Shell Environment Variable for API Key\nDESCRIPTION: Command to set an API key as a shell environment variable before connecting to the database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport MY_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Granting Administrative AI Permissions in PostgreSQL\nDESCRIPTION: Example of granting administrative AI permissions to a role, including the ability to grant permissions to others.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/privileges.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.grant_ai_usage('ai_admin_role', admin => true);\n```\n\n----------------------------------------\n\nTITLE: SQL Example: Moderating Content Using Triggers\nDESCRIPTION: Example SQL code demonstrating content moderation using triggers in PostgreSQL with reference to trigger_moderate.sql\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Enabling pgai Extension in PostgreSQL\nDESCRIPTION: SQL command to enable the pgai extension in the PostgreSQL database\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable with Docker\nDESCRIPTION: Command to set an API key environment variable when running a Docker container with TimescaleDB.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -e MY_API_KEY=<api key here> ... timescale/timescaledb-ha:pg17\n```\n\n----------------------------------------\n\nTITLE: Configuring PostgreSQL Connection with API Key\nDESCRIPTION: Connects to PostgreSQL database with Voyage AI API key configured as a session parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.voyage_api_key=$VOYAGE_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Creating PgAI Extension for OpenAI Integration in PostgreSQL\nDESCRIPTION: Creates the AI extension in PostgreSQL to enable OpenAI API integration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate extension if not exists ai cascade;\n```\n\n----------------------------------------\n\nTITLE: Inserting Test Document\nDESCRIPTION: Inserts a sample document into the embedding table for testing.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\ninsert into document_embedding (contents) values\n  ('Test document embedding');\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable in Systemd Unit\nDESCRIPTION: Configuration example showing how to set an API key as an environment variable in a Systemd service unit file.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nEnvironment=MY_API_KEY=<api key here>\n```\n\n----------------------------------------\n\nTITLE: Verifying Dataset Load\nDESCRIPTION: SQL commands to verify that the Postgres_Air dataset was loaded correctly by listing tables and examining database size.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -f - <<EOF\n\\dt+ postgres_air.*\n\\l+ postgres\nEOF\n```\n\n----------------------------------------\n\nTITLE: Creating Wiki Table Schema\nDESCRIPTION: SQL command to create a table structure for storing Wikipedia data\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wiki (\n    id      TEXT PRIMARY KEY,\n    url     TEXT,\n    title   TEXT,\n    text    TEXT\n);\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Extension\nDESCRIPTION: SQL command to enable the pgai extension in PostgreSQL database\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Loading a Subset of Data\nDESCRIPTION: Example showing how to load only a small subset of a dataset by specifying batch_size and max_batches parameters.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset('squad', batch_size => 100, max_batches => 1);\n```\n\n----------------------------------------\n\nTITLE: Enabling pgai Extension in PostgreSQL\nDESCRIPTION: SQL command to enable the AI extension in PostgreSQL, which is required for using embedding models and vectorization capabilities.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Saving Generated Descriptions to Semantic Catalog\nDESCRIPTION: Command to execute the SQL script containing the generated descriptions, saving them to the pgai semantic catalog.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -f desc.sql\n```\n\n----------------------------------------\n\nTITLE: Sample Output: Running Ollama Model Information\nDESCRIPTION: Displays the resulting row from ai.ollama_ps(), including fields like 'name', 'model', 'size', 'digest', and quantization information. This enables users to check LLM resource availability and metadata from SQL. Output is a single record in text table format per model.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_17\n\nLANGUAGE: text\nCODE:\n```\n   name   |  model   |    size    |                              digest                              | parent_model | format | family |     families      | parameter_size | quantization_level |          expires_at           | size_vram  \n----------+----------+------------+------------------------------------------------------------------+--------------+--------+--------+-------------------+----------------+--------------------+-------------------------------+------------\n llava:7b | llava:7b | 5758857216 | 8dd30f6b0cb19f555f2c7a7ebda861449ea2cc76bf1f44e262931f45fc81d081 |              | gguf   | llama  | [\"llama\", \"clip\"] | 7B             | Q4_0               | 2024-06-18 20:07:30.508198+00 | 5758857216\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Bash\nDESCRIPTION: Bash command to set the OpenAI API key as an environment variable for self-hosted Postgres installations.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/overview.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"Your OpenAI API key\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Description Load\nDESCRIPTION: SQL command to verify that the descriptions were successfully loaded into the semantic catalog by counting the rows in the semantic_catalog_obj table.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -c \"select count(*) from ai.semantic_catalog_obj;\"\n```\n\n----------------------------------------\n\nTITLE: Inserting New Data\nDESCRIPTION: SQL command to insert a new row into the wiki table, demonstrating automatic embedding updates\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO wiki (id, url, title, text) VALUES (11,'https://en.wikipedia.org/wiki/Pgai', 'pgai - Power your AI applications with PostgreSQL', 'pgai is a tool to make developing RAG and other AI applications easier. It makes it simple to give an LLM access to data in your PostgreSQL database by enabling semantic search on your data and using the results as part of the Retrieval Augmented Generation (RAG) pipeline. This allows the LLM to answer questions about your data without needing to being trained on your data.');\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection with OpenAI Key\nDESCRIPTION: Connects to PostgreSQL database with OpenAI API key configured as a session parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Adding Development Dependencies with uv\nDESCRIPTION: Command to add a new development dependency to the pgai project using uv, which will only be used during development and not at runtime.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nuv add --directory projects/pgai --dev <package-name>\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data into the Blog Table\nDESCRIPTION: This SQL command inserts sample blog posts into the 'blog' table, including titles, authors, contents, and metadata.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO blog (title, authors, contents, metadata)\nVALUES\n('Getting Started with PostgreSQL', 'John Doe', 'PostgreSQL is a powerful, open source object-relational database system...', '{\"tags\": [\"database\", \"postgresql\", \"beginner\"], \"read_time\": 5, \"published_date\": \"2024-03-15\"}'),\n\n('10 Tips for Effective Blogging', 'Jane Smith, Mike Johnson', 'Blogging can be a great way to share your thoughts and expertise...', '{\"tags\": [\"blogging\", \"writing\", \"tips\"], \"read_time\": 8, \"published_date\": \"2024-03-20\"}'),\n\n('The Future of Artificial Intelligence', 'Dr. Alan Turing', 'As we look towards the future, artificial intelligence continues to evolve...', '{\"tags\": [\"AI\", \"technology\", \"future\"], \"read_time\": 12, \"published_date\": \"2024-04-01\"}'),\n\n('Healthy Eating Habits for Busy Professionals', 'Samantha Lee', 'Maintaining a healthy diet can be challenging for busy professionals...', '{\"tags\": [\"health\", \"nutrition\", \"lifestyle\"], \"read_time\": 6, \"published_date\": \"2024-04-05\"}'),\n\n('Introduction to Cloud Computing', 'Chris Anderson', 'Cloud computing has revolutionized the way businesses operate...', '{\"tags\": [\"cloud\", \"technology\", \"business\"], \"read_time\": 10, \"published_date\": \"2024-04-10\"}');\n```\n\n----------------------------------------\n\nTITLE: Adding Production Dependencies with uv\nDESCRIPTION: Command to add a new production dependency to the pgai project using uv, which will update the dependency lock file.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nuv add --directory projects/pgai <package-name>\n```\n\n----------------------------------------\n\nTITLE: Using Session-level Parameter with psql\nDESCRIPTION: Command to connect to PostgreSQL with psql while setting a session-level parameter for the API key.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.my_api_key=$MY_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Extension via Command Line\nDESCRIPTION: Shell command to install the pgai extension in the PostgreSQL database without directly connecting to it, using docker compose exec.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_16\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose --file compose-dev.yaml exec -t db psql -U postgres -c \"CREATE EXTENSION IF NOT EXISTS ai cascade;\"\n```\n\n----------------------------------------\n\nTITLE: Basic Anthropic Query Generation\nDESCRIPTION: SQL query demonstrating how to generate text using Anthropic's AI model with a simple prompt\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect ai.anthropic_generate\n( 'claude-3-5-sonnet-20240620'\n, jsonb_build_array\n  ( jsonb_build_object\n    ( 'role', 'user'\n    , 'content', 'Name five famous people from Birmingham, Alabama.'\n    )\n  )\n);\n```\n\n----------------------------------------\n\nTITLE: Sample chat completion JSON response\nDESCRIPTION: Example full JSON output from the ai.ollama_chat_complete function, including the generated text and metadata like processing time.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/ollama.md#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"done\": true,\n  \"model\": \"llama3\",\n  \"message\": {\n    \"role\": \"assistant\",\n    \"content\": \"A large language model (LLM) is a type of artificial intelligence designed to process and generate human-like language. It's trained on massive amounts of text data, such as books, articles, and online conversations, which allows it to learn patterns, relationships, and nuances of language.\\n\\nAn LLM can perform various tasks, including:\\n\\n1. Natural Language Processing (NLP): understanding and generating human language.\\n2. Text generation: creating original text based on input prompts or topics.\\n3. Question answering: providing accurate answers to questions posed in natural language.\\n4. Sentiment analysis: determining the emotional tone or sentiment behind a piece of text.\\n\\nLarge language models are typically trained using deep learning algorithms, such as transformer-based architectures (like BERT, RoBERTa, and XLNet), which enable them to learn from vast amounts of data and generate coherent, context-specific responses.\\n\\nThese models have numerous applications in areas like:\\n\\n1. Virtual assistants: providing helpful information and answering user queries.\\n2. Language translation: facilitating communication between people speaking different languages.\\n3. Content creation: generating text for articles, blog posts, or even entire books.\\n4. Chatbots: enabling conversational interfaces that can engage with users.\\n\\nIn summary, a large language model is a powerful AI tool capable of processing and generating human-like language, with applications in various industries and aspects of our lives!\"\n  },\n  \"created_at\": \"2024-06-18T19:57:09.011458Z\",\n  \"eval_count\": 278,\n  \"done_reason\": \"stop\",\n  \"eval_duration\": 8380764000,\n  \"load_duration\": 4187544583,\n  \"total_duration\": 12715492417,\n  \"prompt_eval_count\": 31,\n  \"prompt_eval_duration\": 142132000\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Docker Compose File\nDESCRIPTION: Command to download the docker compose file needed for setting up pgai with Ollama\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -O https://raw.githubusercontent.com/timescale/pgai/main/examples/docker_compose_pgai_ollama/docker-compose.yml\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key via Command Line\nDESCRIPTION: Sets the OpenAI API key as a PostgreSQL configuration parameter via command line using PGOPTIONS.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Loading a Specific Configuration and Split\nDESCRIPTION: Example showing how to load a specific configuration and split of a dataset, in this case the 'mrpc' configuration of the 'glue' dataset with the 'train' split.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/load_dataset_from_huggingface.md#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.load_dataset(\n    name => 'glue',\n    config_name => 'mrpc',\n    split => 'train'\n);\n```\n\n----------------------------------------\n\nTITLE: Example Complex Generated SQL with Multiple Joins (Text)\nDESCRIPTION: Displays a sample SQL query generated by `ai.text_to_sql` for the complex question about passenger counts in Houston. The example shows a query joining four tables (`boarding_pass`, `booking_leg`, `flight`, `airport`), filtering on arrival time and location, and using `COUNT(DISTINCT bp.passenger_id)` to get the desired result.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_24\n\nLANGUAGE: Text\nCODE:\n```\n```text\n                               text_to_sql\n---------------------------------------------------------------------------\n SELECT COUNT(DISTINCT bp.passenger_id) AS num_passengers                 +\n FROM postgres_air.boarding_pass bp                                       +\n JOIN postgres_air.booking_leg bl ON bp.booking_leg_id = bl.booking_leg_id+\n JOIN postgres_air.flight f ON bl.flight_id = f.flight_id                 +\n JOIN postgres_air.airport a ON f.arrival_airport = a.airport_code        +\n WHERE a.city = 'HOUSTON'                                                 +\n   AND a.iso_region = 'US-TX'                                             +\n   AND f.actual_arrival >= '2024-06-01'::timestamptz                      +\n   AND f.actual_arrival < '2024-07-01'::timestamptz;\n(1 row)\n```\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Lists required Python packages including psycopg2 for PostgreSQL connectivity, OpenAI API integration, pandas for data manipulation, and python-dotenv for environment variable management.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/ollama_vectorizer/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npsycopg2-binary\nopenai\npandas\npython-dotenv\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose Services\nDESCRIPTION: Command to start the Docker Compose services (PostgreSQL database and vectorizer worker) in detached mode using the compose-dev.yaml configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml up -d\n```\n\n----------------------------------------\n\nTITLE: SQL Example: Entity Extraction and Anonymization\nDESCRIPTION: Example SQL code demonstrating named entity extraction and anonymization using the pgai extension\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Setting API Key Environment Variable for LiteLLM in Bash\nDESCRIPTION: This snippet shows how to set your provider's API key as an environment variable in your shell for use with LiteLLM.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Enabling pgai Extension\nDESCRIPTION: SQL command to enable the pgai extension and its dependencies in the Postgres database.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS ai CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Shell Environment\nDESCRIPTION: Sets up the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Registering pgai Operations for Alembic\nDESCRIPTION: This snippet demonstrates how to register pgai operations for use with Alembic in the env.py file.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pgai.alembic import register_operations\n\nregister_operations()\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Services\nDESCRIPTION: Command to start the Docker Compose services in detached mode.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies\nDESCRIPTION: Lists required Python packages: psycopg2 for PostgreSQL database connectivity, openai for OpenAI API integration, and pandas for data manipulation and analysis\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/litellm_vectorizer/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npsycopg2\nopenai\npandas\n```\n\n----------------------------------------\n\nTITLE: Pulling Ollama Models for Development\nDESCRIPTION: Commands to pull required Ollama models (llama3, llava:7b, and smollm:135m) for development.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nollama pull llama3\nollama pull llava:7b\nollama pull smollm:135m\n```\n\n----------------------------------------\n\nTITLE: SQL Example: Table Description Generation\nDESCRIPTION: Example SQL code demonstrating how to generate textual descriptions for database tables\nSOURCE: https://github.com/timescale/pgai/blob/released/llms.txt#2025-04-22_snippet_4\n\n\n\n----------------------------------------\n\nTITLE: Setting Voyage AI API Key Environment Variable\nDESCRIPTION: Sets up the Voyage AI API key as an environment variable for secure access.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/voyageai.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport VOYAGE_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Blog Data\nDESCRIPTION: SQL insert statements to populate the blog table with sample articles covering various topics including PostgreSQL, blogging, AI, health, and cloud computing.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-voyage.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO blog (title, authors, contents, metadata)\nVALUES\n('Getting Started with PostgreSQL', 'John Doe', 'PostgreSQL is a powerful, open source object-relational database system...', '{\"tags\": [\"database\", \"postgresql\", \"beginner\"], \"read_time\": 5, \"published_date\": \"2024-03-15\"}'),\n\n('10 Tips for Effective Blogging', 'Jane Smith, Mike Johnson', 'Blogging can be a great way to share your thoughts and expertise...', '{\"tags\": [\"blogging\", \"writing\", \"tips\"], \"read_time\": 8, \"published_date\": \"2024-03-20\"}'),\n\n('The Future of Artificial Intelligence', 'Dr. Alan Turing', 'As we look towards the future, artificial intelligence continues to evolve...', '{\"tags\": [\"AI\", \"technology\", \"future\"], \"read_time\": 12, \"published_date\": \"2024-04-01\"}'),\n\n('Healthy Eating Habits for Busy Professionals', 'Samantha Lee', 'Maintaining a healthy diet can be challenging for busy professionals...', '{\"tags\": [\"health\", \"nutrition\", \"lifestyle\"], \"read_time\": 6, \"published_date\": \"2024-04-05\"}'),\n\n('Introduction to Cloud Computing', 'Chris Anderson', 'Cloud computing has revolutionized the way businesses operate...', '{\"tags\": [\"cloud\", \"technology\", \"business\"], \"read_time\": 10, \"published_date\": \"2024-04-10\"}');\n```\n\n----------------------------------------\n\nTITLE: Cleaning pgai Build Artifacts\nDESCRIPTION: Command to clean pgai extension build artifacts.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\njust ext clean\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for Postgres with TimescaleDB and pgai\nDESCRIPTION: Docker Compose configuration that sets up Postgres with TimescaleDB, pgai vectorizer worker, and Ollama for hosting embedding models.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: pgai \nservices:\n  db:\n    image: timescale/timescaledb-ha:pg17\n    environment:\n      POSTGRES_PASSWORD: postgres\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - data:/home/postgres/pgdata/data\n  vectorizer-worker:\n    image: timescale/pgai-vectorizer-worker:latest\n    environment:\n      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres\n      OLLAMA_HOST: http://ollama:11434\n    command: [ \"--poll-interval\", \"5s\" ]\n  ollama:\n    image: ollama/ollama\nvolumes:\n  data:\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key via ALTER SYSTEM\nDESCRIPTION: Sets and persists the OpenAI API key using SQL commands within a session.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET ai.openai_api_key TO :'OPENAI_API_KEY' ;\nALTER SYSTEM SET ai.openai_api_key TO :'OPENAI_API_KEY' ;\n```\n\n----------------------------------------\n\nTITLE: Building pgai Docker Image\nDESCRIPTION: Command to build the Docker image for pgai extension development using the just command.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\njust ext docker-build\n```\n\n----------------------------------------\n\nTITLE: Listing Default Cohere Model for Generate Endpoint\nDESCRIPTION: SQL query that retrieves the default Cohere model for a specific endpoint (generate), using the default_only parameter.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nselect * \nfrom ai.cohere_list_models(endpoint=>'generate', default_only=>true);\n```\n\n----------------------------------------\n\nTITLE: Generating Database Object Descriptions\nDESCRIPTION: Command to execute a script that generates descriptions for database objects using pgai's LLM integration, creating a SQL file with description definitions.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" \\\n  psql -U postgres -v ON_ERROR_STOP=1 \\\n  -q -X -t -o desc.sql -f gen_desc.sql\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Environment for pgai\nDESCRIPTION: Commands to navigate to the pgai project directory, create a virtual environment using uv, and activate it for development.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd projects/pgai\nuv venv\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Libraries for Embedding Model Evaluation\nDESCRIPTION: Installs the necessary Python libraries (pandas, psycopg2-binary, and Jinja2) for the notebook using pip.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install pandas psycopg2-binary Jinja2\n```\n\n----------------------------------------\n\nTITLE: Checking Vectorizer Worker Logs\nDESCRIPTION: Shell command to monitor the vectorizer worker logs in real-time.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose logs -f vectorizer-worker\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in PostgreSQL\nDESCRIPTION: Sets the OpenAI API key in PostgreSQL configuration file for system-wide access.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\necho \"ai.openai_api_key=${API_KEY}\" >> /path/to/postgresql.conf\n```\n\n----------------------------------------\n\nTITLE: Using OpenAI Embedding API with Legacy Base URL Configuration (Pre-0.9.0)\nDESCRIPTION: Example showing how to call the OpenAI embedding API with the base URL as a separate parameter, which was the approach used in versions prior to 0.9.0 of the pgai extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/openai.md#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.openai_embed(\n    model => 'text-embedding-ada-002',\n    input_text => 'Hello world',\n    base_url => 'https://api.openai.com/v1'\n);\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for RAG\nDESCRIPTION: Bash command to install required Python packages for implementing RAG functionality.\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npip install psycopg pgvector ollama\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL with External Client\nDESCRIPTION: Example command to connect to the PostgreSQL database running in Docker using psql from the host machine with a connection URI.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\npsql 'postgresql://postgres:postgres@localhost'\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for TimescaleDB pgai Project\nDESCRIPTION: This snippet lists the required Python packages for the pgai project. It includes psycopg2-binary for PostgreSQL database connectivity, openai for integrating with OpenAI's APIs, pandas for data manipulation, and python-dotenv for environment variable management.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npsycopg2-binary\nopenai\npandas\npython-dotenv\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install all project dependencies, including optional extras, using uv's sync command.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuv sync --all-extras\n```\n\n----------------------------------------\n\nTITLE: Configuring PostgreSQL Connection with API Key\nDESCRIPTION: Command to connect to PostgreSQL with the Anthropic API key set as a session parameter\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.anthropic_api_key=$ANTHROPIC_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Alembic to Exclude Managed Tables\nDESCRIPTION: This Python code snippet shows how to configure Alembic to exclude pgai managed tables from the autogenerate process.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef include_object(object, name, type_, reflected, compare_to):\n    if type_ == \"table\" and name in target_metadata.info.get(\"pgai_managed_tables\", set()):\n        return False\n    return True\n\ncontext.configure(\n      connection=connection,\n      target_metadata=target_metadata,\n      include_object=include_object\n  )\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Command to set the OpenAI API key as an environment variable in the Docker container for use by pgai.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nexport OPENAI_API_KEY=\"your-key-goes-here\"\n```\n\n----------------------------------------\n\nTITLE: Creating Database Connection Function\nDESCRIPTION: Defines a function to connect to the PostgreSQL database using the connection string defined earlier.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg2\n\ndef connect_db():\n    return psycopg2.connect(DATABASE_CONNECTION_STRING)\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Library in Python\nDESCRIPTION: This snippet shows how to install the pgai library using pip.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install pgai\n```\n\n----------------------------------------\n\nTITLE: Testing Concurrency with pytest\nDESCRIPTION: Command to run a specific test with concurrency to verify that the vectorizer workers are functioning correctly in parallel.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nuv run pytest -k test_process_vectorizer\\[4 -rP\n```\n\n----------------------------------------\n\nTITLE: SHA256 Hash Verification List\nDESCRIPTION: List of SHA256 hashes formatted with --hash= prefix, commonly used in Python pip requirements files or similar package management systems for integrity verification\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n--hash=sha256:6f77fa49079891a4aab203d0b1744acc85577ed16d767b52fc089d83faf8d8ed \\\n--hash=sha256:72c68dda124a1a138340fb62fa21b9bf4848437d9ca60bd35db36f2d3345f373 \\\n--hash=sha256:752bf8a74412b9892f4e5b58f2f890a039f57037f52c89a740757ebd807f33ea \\\n--hash=sha256:76e79bc28a65f467e0409098fa2c4376931fd3207fbeb6b956c7c476d53746dd \\\n--hash=sha256:774d45b1fac1461f48698a9d4b5fa19a69d47ece02fa469825b442263f04021f \\\n--hash=sha256:77da4c6bfa20dd5ea25cbf12c76f181a8e8cd7ea231c673828d0386b1740b8dc \\\n--hash=sha256:77ea385f7dd5b5676d7fd943292ffa18fbf5c72ba98f7d09fc1fb9e819b34c23 \\\n--hash=sha256:80080816b4f52a9d886e67f1f96912891074903238fe54f2de8b786f86baded2 \\\n--hash=sha256:80a539906390591dd39ebb8d773771dc4db82ace6372c4d41e2d293f8e32b8db \\\n--hash=sha256:84433dddea68571a6d6bd4fbf8ff398236031149116a7fff6f777ff95cad3df9 \\\n--hash=sha256:8ed7d27cb56b3e058d3cf684d7200703bcae623e1dcc06ed1e18ecda39fee003 \\\n--hash=sha256:9206649ec587e6b02bd124fb7799b86cddec350f6f6c14bc82a2b70183e708ba \\\n--hash=sha256:983b6efd649723474f29ed42e1467f90a35a74793437d0bc64a5bf482bedfa0a \\\n--hash=sha256:98da17ce9cbf3bfe4617e836d561e433f871129e3a7ac16d6ef4c680f13a839c \\\n--hash=sha256:9c236e635582742fee16603042553d276cca506e824fa2e6489db04039521e90 \\\n--hash=sha256:9da6bc32faac9a293ddfdcb9108d4b20416219461e4ec64dfea8383cac186690 \\\n--hash=sha256:a0817825b900fcd43ac5d05b8b3079937073d2b1ff9cf89427590718b70dd840 \\\n--hash=sha256:a8fffdbd9d1408006baaf02f1068d7dd1f016c6bcb7538682622c556e7b68e35 \\\n--hash=sha256:a9b07268d0c3ca5c170a385a0ab9fb7fdd9f5fd866be004c4ea39e44edce47dd \\\n--hash=sha256:ab19a2d91963ed9e42b4e8d77cd847ae8381576585bad79dbd0a8837a9f6620a \\\n--hash=sha256:ac184f87ff521f4840e6ea0b10c0ec90c6b1dcd0bad2f1e4a9a1b4fa177982ea \\\n--hash=sha256:b0e166f698c5a3e914947388c162be2583e0c638a4703fc6a543e23a88dea3c1 \\\n--hash=sha256:b2170c7e0367dde86a2647ed5b6f57394ea7f53545746104c6b09fc1f4223573 \\\n--hash=sha256:b2d8c62d08e7255f68f7a740bae85b3c9b8e5466baa9cbf7f57f1cde0ac6bc09 \\\n--hash=sha256:b4567955a6bc1b20e9c31612e615af6b53733491aeaa19a6b3b37f3b65477094 \\\n--hash=sha256:b69bb4f51daf461b15e7b3db033160937d3ff88303a7bc808c67bbc1eaf98c78 \\\n--hash=sha256:be9b5b8659dff1f913039c2feee1aca499cfbc19e98fa12bc85e037c17ec6ca5 \\\n--hash=sha256:bf0a05b6059c0528477fba9054d09179beb63744355cab9f38059548fedd46a9 \\\n--hash=sha256:c16842b846a8d2a145223f520b7e18b57c8f476924bda92aeee3a88d11cfc391 \\\n--hash=sha256:c363b53e257246a954ebc7c488304b5592b9c53fbe74d03bc1c64dda153fb847 \\\n--hash=sha256:d20fd853fbb5807c8e84c136c278827b6167ded66c72ec6f9a14b863d809211c \\\n--hash=sha256:d2240ddc86b74966c34554c49d00eaafa8200a18d3a5b6ffbf7da63b11d74ee2 \\\n--hash=sha256:d477ed829077cd945b01fc3115edd132c47e6540ddcd96ca169facff28173057 \\\n--hash=sha256:d50d31bfedd53a928fed6707b15a8dbeef011bb6366297cc435accc888b27c20 \\\n--hash=sha256:dc1d33abb8a0d754ea4763bad944fd965d3d95b5baef6b121c0c9013eaf1907d \\\n--hash=sha256:dc5d1a49d3f8262be192589a4b72f0d03b72dcf46c51ad5852a4fdc67be7b9e4 \\\n--hash=sha256:e7792606d606c8df5277c32ccb58f29b9b8603bf83b48639b7aedf6df4fe8171 \\\n--hash=sha256:ed1708dbf4d2e3a1c5c69110ba2b4eb6678262028afd6c6fbcc5a8dac9cda68e \\\n--hash=sha256:f2d4380bf5f62daabd7b751ea2339c1a21d1c9463f1feb7fc2bdcea2c29c3160 \\\n--hash=sha256:f3513916e8c645d0610815c257cbfd3242adfd5c4cfa78be514e5a3ebb42a41b \\\n--hash=sha256:fa6ce8b52c5987b3e34d5674b0ab529a4602b632ebab0a93b07bfb4dfc8f8a33 \\\n--hash=sha256:fc9ca1c9718cb3b06634c7c8dec57d24e9438b2aa9a0f02b8bb36bf478538880 \\\n--hash=sha256:fd30d9c67d13d891f2360b2a120186729c111238ac63b43dbd37a5a40670b8ca \\\n--hash=sha256:fd7699e8fd9969f455ef2926221e0233f81a2542921471382e77a9e2f2b57f4b\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key in Shell\nDESCRIPTION: Command to set the Anthropic API key as an environment variable in the shell\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/anthropic.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Database Migration Execution\nDESCRIPTION: Command to run database migrations for creating necessary tables and setting up the vectorizer.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nuv run alembic upgrade head\n```\n\n----------------------------------------\n\nTITLE: Creating Vectorscale Extension\nDESCRIPTION: Installs the vectorscale extension for vector operations in PostgreSQL.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/delayed_embed.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Starting the Database Container with Docker Compose\nDESCRIPTION: This shell command starts the database container defined in the Docker Compose configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d db\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings using psql and OpenAI Key (Bash)\nDESCRIPTION: Executes the `gen_embed.sql` script using `psql` to generate embeddings for descriptions, presumably for a semantic catalog. Requires the `OPENAI_API_KEY` environment variable to be set and passed to the PostgreSQL session via `PGOPTIONS`. This is presented as a potentially long-running, one-time setup task.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_14\n\nLANGUAGE: Bash\nCODE:\n```\n```bash\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" \\\npsql -U postgres -v ON_ERROR_STOP=1 -q -X -f gen_embed.sql\n```\n```\n\n----------------------------------------\n\nTITLE: Installing PGAI Extension\nDESCRIPTION: Commands for installing the PGAI PostgreSQL extension using just or the direct build script\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/source.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo just ext install\n```\n\nLANGUAGE: bash\nCODE:\n```\nsudo projects/extension/build.py install\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration for Discord Bot\nDESCRIPTION: Required environment variables configuration in .env file including database connection, API keys, and Discord settings.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nDATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost/postgres\nOPENAI_API_KEY=xxx\nDISCORD_BOT_TOKEN=xxx\nDISCORD_CHANNEL_ID=123\n```\n\n----------------------------------------\n\nTITLE: Running pgai Development Tasks\nDESCRIPTION: Commands for running tests, linting, formatting, and type-checking the pgai project code, which should be run before submitting a PR.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\njust pgai test\njust pgai lint\njust pgai format\njust pgai type-check\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Python Package\nDESCRIPTION: Pip command to install the pgai package from PyPI. This installation adds the vectorizer worker command to the system PATH for local usage.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install pgai\n```\n\n----------------------------------------\n\nTITLE: Configuring pgai Tests with Environment Variables\nDESCRIPTION: Example .env file configuration for enabling/disabling test suites in pgai.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n# enable/disable tests\nENABLE_VECTORIZER_TESTS=1\nENABLE_DUMP_RESTORE_TESTS=1\nENABLE_PRIVILEGES_TESTS=1\nENABLE_CONTENTS_TESTS=1\nENABLE_SECRETS_TESTS=1\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Services\nDESCRIPTION: Command to start the Docker Compose services in detached mode.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer-quick-start.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL with Python Support using ASDF\nDESCRIPTION: Command to install PostgreSQL 16.3 with Python support using the ASDF version manager\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/source.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nPOSTGRES_EXTRA_CONFIGURE_OPTIONS=--with-python asdf install postgres 16.3\n```\n\n----------------------------------------\n\nTITLE: Reinstalling PG AI Extension SQL Commands\nDESCRIPTION: SQL commands required to update from previous versions (0.1.0, 0.2.0, 0.3.0) to version 0.4.0, showing the required drop and recreate process.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/RELEASE_NOTES.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP EXTENSION ai;\nCREATE EXTENSION ai VERSION '0.4.0' CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key via SQL Configuration\nDESCRIPTION: Sets the OpenAI API key as a PostgreSQL configuration parameter using SQL.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/moderate.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect set_config('ai.openai_api_key', :'OPENAI_API_KEY', false) is not null as set_config;\n```\n\n----------------------------------------\n\nTITLE: Listing Available Just Commands\nDESCRIPTION: Command to list all available commands defined in the justfile for the pgai project, showing the tasks that can be run with the 'just' task runner.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\njust -l pgai\n```\n\n----------------------------------------\n\nTITLE: Using CREATE OR REPLACE in SQL\nDESCRIPTION: Reference to the recommended usage of CREATE OR REPLACE statements in SQL files to ensure idempotency during database installations and upgrades.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/sql/idempotent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE\n```\n\n----------------------------------------\n\nTITLE: Connecting to Database with API Key as Session Parameter\nDESCRIPTION: This command connects to PostgreSQL while passing the OpenAI API key as a session parameter, making it available during the session.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPGOPTIONS=\"-c ai.openai_api_key=$OPENAI_API_KEY\" psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Virtual Environment for Embedding Model Evaluation\nDESCRIPTION: Creates and activates a Python virtual environment for the project and installs required dependencies from the requirements.txt file.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/evaluations/voyage_vectorizer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Creating a Blog Table for Text Chunking Examples in SQL\nDESCRIPTION: Creates a simple blog table with id, title, and body columns to demonstrate text chunking functions.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/utils/chunking.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table blog\n( id int not null primary key\n, title text\n, body text\n);\n```\n\n----------------------------------------\n\nTITLE: Schema-Qualified Function Call Example\nDESCRIPTION: Example showing the new schema-qualified way to call pgai functions after the move to the 'ai' schema.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/RELEASE_NOTES.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nai.openai_list_models()\n```\n\n----------------------------------------\n\nTITLE: Connecting to Self-Hosted Postgres Database\nDESCRIPTION: Shell commands to connect to the self-hosted Postgres database using either Docker Compose exec or psql. These commands allow direct interaction with the database for management and querying.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/worker.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose exec -it db psql\n```\n\nLANGUAGE: shell\nCODE:\n```\npsql postgres://postgres:postgres@localhost:5432/postgres\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for Database Connection\nDESCRIPTION: Instructions for creating a .env file with database connection information needed by the load testing scripts.\nSOURCE: https://github.com/timescale/pgai/blob/released/scripts/vectorizer-load-test/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAdd a `.env` file and put a `DB_URL` in it. The value should be a Postgres DB connection URL. It can be a local DB or a remote DB.\n```\n\n----------------------------------------\n\nTITLE: Starting the Vectorizer Worker with Docker Compose\nDESCRIPTION: This shell command starts the vectorizer worker container defined in the Docker Compose configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d vectorizer-worker\n```\n\n----------------------------------------\n\nTITLE: Removing pgai Docker Container\nDESCRIPTION: Command to delete the stopped pgai Docker container.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# When stopped, delete the container\njust ext docker-rm\n```\n\n----------------------------------------\n\nTITLE: Removing Stopped Docker Compose Services and Volumes\nDESCRIPTION: Command to remove already stopped Docker Compose containers and their volumes, which will delete all persistent data.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_20\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml rm -v\n```\n\n----------------------------------------\n\nTITLE: Checking uv Version\nDESCRIPTION: Command to check the installed version of uv, which should be at least 0.5.x for working with the pgai project.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv --version\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Just\nDESCRIPTION: Command to run the project's test suite using the 'just' task runner to verify the development environment is set up correctly.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\njust test\n```\n\n----------------------------------------\n\nTITLE: Creating Extension with Feature Flag in PostgreSQL\nDESCRIPTION: Example of enabling a feature flag and creating the PGAI extension with prerelease features. Shows the warning message that appears when installing prerelease code.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nselect set_config('ai.enable_feature_flag_my_new_feature', 'true', false);\n\ncreate extension ai cascade;\nNOTICE:  installing required extension \"vector\"\nNOTICE:  installing required extension \"plpython3u\"\nWARNING:  Feature flag \"ai.enable_feature_flag_my_new_feature\" has been enabled. Pre-release software will be installed. This code is not production-grade, is not guaranteed to work, and is not supported in any way. Extension upgrades are not supported once pre-release software has been installed.\nCREATE EXTENSION\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Deployment Command\nDESCRIPTION: Command to start the vectorizer and database using Docker Compose.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Updating uv\nDESCRIPTION: Command to update the uv package manager to the latest version if the current version is outdated.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv self update\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL Database\nDESCRIPTION: Command to connect to a PostgreSQL database using psql client\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/source.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npsql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes Documentation\nDESCRIPTION: Detailed changelog in Markdown format documenting version history, features, improvements, and fixes for the Pgai PostgreSQL extension from version 0.9.0 down to 0.4.0. Includes links to pull requests and commit references.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/RELEASE_NOTES.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Pgai extension release notes\n\n## 0.9.0 (2025-03-06)\n\n### New features and improvements\n- [BREAKING] Add openai client config arguments ([#426](https://github.com/timescale/pgai/pull/426))\n- Add support for openai extra request parameteres ([#420](https://github.com/timescale/pgai/pull/420))\n- Add verbose flag to model calls ([#475](https://github.com/timescale/pgai/pull/475))\n- Add chunking functions to the extension ([#418](https://github.com/timescale/pgai/pull/418))\n- Add raw response variants for openai function ([#422](https://github.com/timescale/pgai/pull/422))\n\n[...remaining content truncated for brevity...]\n```\n\n----------------------------------------\n\nTITLE: Package Requirements with Hash Verification in Python\nDESCRIPTION: A requirements file listing Python package dependencies with their versions and cryptographic hashes for secure installation. The file includes core packages like numpy, ollama, openai, and others with their corresponding SHA-256 hash values for integrity verification.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n--hash=sha256:50b3a2710631848991d0bf7de077502e8994c804bb805aeb2925a981de58ec2e \\\n--hash=sha256:55b6d90641869892caa9ca42ff913f7ff1c5ece06474fbd32fb2cf6834726c95 \\\n--hash=sha256:57feec87371dbb3520da6192213c7d6fc892d5589a93db548331954de8248fd2 \\\n--hash=sha256:58130ecf8f7b8112cdb841486404f1282b9c86ccb30d3519faf301b2e5659133 \\\n--hash=sha256:59bfeae4b25ec05b34f1956eaa1cb38032282cd4dfabc5056d0a1ec4d696d3aa \\\n--hash=sha256:5b48204e8d955c47c55b72779802b219a39acc3ee3d0116d5080c388970b76e3 \\\n--hash=sha256:5c09fcfdccdd0b57867577b719c69e347a436b86cd83747f179dbf0cc0d4c1f3 \\\n--hash=sha256:6180c0ae073bddeb5a97a38c03f30c233e0a4d39cd86166251617d1bbd0af436 \\\n--hash=sha256:6b5d83030255983181005e6cfbac1617ce9746b219bc2aad52201ad121226581 \\\n--hash=sha256:76f364861c3bfc98cbbcbd402d83454ed9e01a5224bb3a28bf70002a230f73e2 \\\n--hash=sha256:820c661588bd01a0aa62a1283f20d2be4281b086f80dad9e955e690c75fb54a2 \\\n--hash=sha256:82176036e65644a6cc5bd619f65f6f19781e8ec2e5330f51aa9ada7504cc1926 \\\n--hash=sha256:90f8717cb649eea3504091e640a1b8568faad18bd4b9fcd692853a04475a4b80 \\\n--hash=sha256:99f826cbf970077383d7de805c0681799491cb939c25450b9b5b3ced03ca99f1 \\\n--hash=sha256:a114d03b938376557927ab23f1e950827c3b893ccb94b62fd95d430fd0e5cf53 \\\n--hash=sha256:a7a9541cd308eed5e30318430a9c74d2132e9a8cb46b901326272d780bf2d423 \\\n--hash=sha256:aaed8b0562be4a0876ee3b6946f6869b7bcdb571a5d1496683505944e268b160 \\\n--hash=sha256:b04772ed465fa3cc947db808fa306d79b43e896beb677a56fb2347ca1a49c1fa \\\n--hash=sha256:b1c416351ee6271b2f49b56ad7f308072f6f44b37118d69c2cad94f3fa8a40d5 \\\n--hash=sha256:b225d95519a5bf73860323e633a664b0d85ad3d5bede6d30d95b35d4dfe8805b \\\n--hash=sha256:b2f59caeaf7632cc633b5cf6fc449372b83bbdf0da4ae04d5be36118e46cc0aa \\\n--hash=sha256:b58c621844d55e71c1b7f7c498ce5aa6985d743a1a59034c57a905b3f153c1ef \\\n--hash=sha256:bf6bea52ec97e95560af5ae576bdac3aa3aae0b6758c6efa115236d9e07dae44 \\\n--hash=sha256:c7053d3b0353a8b9de430a4f4b4268ac9a4fb3481af37dfe49825bf45ca24156 \\\n--hash=sha256:c943a53e9186688b45b323602298ab727d8865d8c9ee0b17f8d62d14b56f0753 \\\n--hash=sha256:d1a9dd711d0877a1ece3d2e4fea11a8e75741ca21954c919406b44e7cf971304 \\\n--hash=sha256:d569388c381b24671589335a3be6e1d45546c2988c2ebe30fdcada8457a31008 \\\n--hash=sha256:d618649d4e70ac6efcbba75be98b26ef5078faad23592f9b51ca492953012429 \\\n--hash=sha256:d83a047959d38a7ff552ff94be767b7fd79b831ad1cd9920662db05fec24fe72 \\\n--hash=sha256:d8fff389528cad1618fb4b26b95550327495462cd745d879a8c7c2115248e399 \\\n--hash=sha256:da1758c76f50c39a2efd5e9859ce7d776317eb1dd34317c8152ac9251fc574a3 \\\n--hash=sha256:e9aa71e15d9d9beaad2c6b9319edcdc0a49a43ef5c0a4c8265ca9ee7d6c67774 \\\n--hash=sha256:ec2abea24d98246b94913b76a125e855eb5c434f7c46546046372fe60f666351 \\\n--hash=sha256:f179dee3b863ab1c59580ff60f9d99f632f34ccb38bf67a33ec6b3ecadd0fd76 \\\n--hash=sha256:f90c822a402cb865e396a504f9fc8173ef34212a342d92e362ca498cad308e28 \\\n--hash=sha256:ff3827aef427c89a25cc96ded1759271a93603aba9fb977a6d264648ebf989db\nmultiprocess==0.70.16 \\\n--hash=sha256:161af703d4652a0e1410be6abccecde4a7ddffd19341be0a7011b94aeb171ac1 \\\n--hash=sha256:476887be10e2f59ff183c006af746cb6f1fd0eadcfd4ef49e605cbe2659920ee \\\n--hash=sha256:a0bafd3ae1b732eac64be2e72038231c1ba97724b60b09400d68f229fcc2fbf3 \\\n--hash=sha256:a71d82033454891091a226dfc319d0cfa8019a4e888ef9ca910372a446de4435 \\\n--hash=sha256:af4cabb0dac72abfb1e794fa7855c325fd2b55a10a44628a3c1ad3311c04127a \\\n--hash=sha256:c4a9944c67bd49f823687463660a2d6daae94c289adff97e0f9d696ba6371d02 \\\n--hash=sha256:d951bed82c8f73929ac82c61f01a7b5ce8f3e5ef40f5b52553b4f547ce2b08ec \\\n--hash=sha256:fc0544c531920dde3b00c29863377f87e1632601092ea2daca74e4beb40faa2e\nnumpy==2.2.1 \\\n--hash=sha256:059e6a747ae84fce488c3ee397cee7e5f905fd1bda5fb18c66bc41807ff119b2 \\\n--hash=sha256:08ef779aed40dbc52729d6ffe7dd51df85796a702afbf68a4f4e41fafdc8bda5 \\\n--hash=sha256:164a829b6aacf79ca47ba4814b130c4020b202522a93d7bff2202bfb33b61c60 \\\n--hash=sha256:26c9c4382b19fcfbbed3238a14abf7ff223890ea1936b8890f058e7ba35e8d71 \\\n--hash=sha256:27f5cdf9f493b35f7e41e8368e7d7b4bbafaf9660cba53fb21d2cd174ec09631 \\\n--hash=sha256:31b89fa67a8042e96715c68e071a1200c4e172f93b0fbe01a14c0ff3ff820fc8 \\\n--hash=sha256:32cb94448be47c500d2c7a95f93e2f21a01f1fd05dd2beea1ccd049bb6001cd2 \\\n--hash=sha256:360137f8fb1b753c5cde3ac388597ad680eccbbbb3865ab65efea062c4a1fd16 \\\n--hash=sha256:3683a8d166f2692664262fd4900f207791d005fb088d7fdb973cc8d663626faa \\\n--hash=sha256:38efc1e56b73cc9b182fe55e56e63b044dd26a72128fd2fbd502f75555d92591 \\\n--hash=sha256:3d03883435a19794e41f147612a77a8f56d4e52822337844fff3d4040a142964 \\\n--hash=sha256:3ecc47cd7f6ea0336042be87d9e7da378e5c7e9b3c8ad0f7c966f714fc10d821 \\\n--hash=sha256:40f9e544c1c56ba8f1cf7686a8c9b5bb249e665d40d626a23899ba6d5d9e1484 \\\n--hash=sha256:4250888bcb96617e00bfa28ac24850a83c9f3a16db471eca2ee1f1714df0f957 \\\n--hash=sha256:4511d9e6071452b944207c8ce46ad2f897307910b402ea5fa975da32e0102800 \\\n--hash=sha256:45681fd7128c8ad1c379f0ca0776a8b0c6583d2f69889ddac01559dfe4390918 \\\n--hash=sha256:48fd472630715e1c1c89bf1feab55c29098cb403cc184b4859f9c86d4fcb6a95 \\\n--hash=sha256:4c86e2a209199ead7ee0af65e1d9992d1dce7e1f63c4b9a616500f93820658d0 \\\n--hash=sha256:4dfda918a13cc4f81e9118dea249e192ab167a0bb1966272d5503e39234d694e \\\n--hash=sha256:5062dc1a4e32a10dc2b8b13cedd58988261416e811c1dc4dbdea4f57eea61b0d \\\n--hash=sha256:51faf345324db860b515d3f364eaa93d0e0551a88d6218a7d61286554d190d73 \\\n--hash=sha256:526fc406ab991a340744aad7e25251dd47a6720a685fa3331e5c59fef5282a59 \\\n--hash=sha256:53c09385ff0b72ba79d8715683c1168c12e0b6e84fb0372e97553d1ea91efe51 \\\n--hash=sha256:55ba24ebe208344aa7a00e4482f65742969a039c2acfcb910bc6fcd776eb4355 \\\n--hash=sha256:5b6c390bfaef8c45a260554888966618328d30e72173697e5cabe6b285fb2348 \\\n--hash=sha256:5c5cc0cbabe9452038ed984d05ac87910f89370b9242371bd9079cb4af61811e \\\n--hash=sha256:5edb4e4caf751c1518e6a26a83501fda79bff41cc59dac48d70e6d65d4ec4440 \\\n--hash=sha256:61048b4a49b1c93fe13426e04e04fdf5a03f456616f6e98c7576144677598675 \\\n--hash=sha256:676f4eebf6b2d430300f1f4f4c2461685f8269f94c89698d832cdf9277f30b84 \\\n--hash=sha256:67d4cda6fa6ffa073b08c8372aa5fa767ceb10c9a0587c707505a6d426f4e046 \\\n--hash=sha256:694f9e921a0c8f252980e85bce61ebbd07ed2b7d4fa72d0e4246f2f8aa6642ab \\\n--hash=sha256:733585f9f4b62e9b3528dd1070ec4f52b8acf64215b60a845fa13ebd73cd0712 \\\n--hash=sha256:7671dc19c7019103ca44e8d94917eba8534c76133523ca8406822efdd19c9308 \\\n--hash=sha256:780077d95eafc2ccc3ced969db22377b3864e5b9a0ea5eb347cc93b3ea900315 \\\n--hash=sha256:7ba9cc93a91d86365a5d270dee221fdc04fb68d7478e6bf6af650de78a8339e3 \\\n--hash=sha256:89b16a18e7bba224ce5114db863e7029803c179979e1af6ad6a6b11f70545008 \\\n--hash=sha256:9036d6365d13b6cbe8f27a0eaf73ddcc070cae584e5ff94bb45e3e9d729feab5 \\\n--hash=sha256:93cf4e045bae74c90ca833cba583c14b62cb4ba2cba0abd2b141ab52548247e2 \\\n--hash=sha256:9ad014faa93dbb52c80d8f4d3dcf855865c876c9660cb9bd7553843dd03a4b1e \\\n--hash=sha256:9b1d07b53b78bf84a96898c1bc139ad7f10fda7423f5fd158fd0f47ec5e01ac7 \\\n--hash=sha256:a7746f235c47abc72b102d3bce9977714c2444bdfaea7888d241b4c4bb6a78bf \\\n--hash=sha256:aa3017c40d513ccac9621a2364f939d39e550c542eb2a894b4c8da92b38896ab \\\n--hash=sha256:b34d87e8a3090ea626003f87f9392b3929a7bbf4104a05b6667348b6bd4bf1cd \\\n--hash=sha256:b541032178a718c165a49638d28272b771053f628382d5e9d1c93df23ff58dbf \\\n--hash=sha256:ba5511d8f31c033a5fcbda22dd5c813630af98c70b2661f2d2c654ae3cdfcfc8 \\\n--hash=sha256:bc8a37ad5b22c08e2dbd27df2b3ef7e5c0864235805b1e718a235bcb200cf1cb \\\n--hash=sha256:bff7d8ec20f5f42607599f9994770fa65d76edca264a87b5e4ea5629bce12268 \\\n--hash=sha256:c1ad395cf254c4fbb5b2132fee391f361a6e8c1adbd28f2cd8e79308a615fe9d \\\n--hash=sha256:f1d09e520217618e76396377c81fba6f290d5f926f50c35f3a5f72b01a0da780 \\\n--hash=sha256:f3eac17d9ec51be534685ba877b6ab5edc3ab7ec95c8f163e5d7b39859524716 \\\n--hash=sha256:f419290bc8968a46c4933158c91a0012b7a99bb2e465d5ef5293879742f8797e \\\n--hash=sha256:f62aa6ee4eb43b024b0e5a01cf65a0bb078ef8c395e8713c6e8a12a697144528 \\\n--hash=sha256:f74e6fdeb9a265624ec3a3918430205dff1df7e95a230779746a6af78bc615af \\\n--hash=sha256:f9b57eaa3b0cd8db52049ed0330747b0364e899e8a606a624813452b8203d5f7 \\\n--hash=sha256:fce4f615f8ca31b2e61aa0eb5865a21e14f5629515c9151850aa936c02a1ee51\nollama==0.4.5 \\\n--hash=sha256:74936de89a41c87c9745f09f2e1db964b4783002188ac21241bfab747f46d925 \\\n--hash=sha256:e7fb71a99147046d028ab8b75e51e09437099aea6f8f9a0d91a71f787e97439e\nopenai==1.56.0 \\\n--hash=sha256:0751a6e139a09fca2e9cbbe8a62bfdab901b5865249d2555d005decf966ef9c3 \\\n--hash=sha256:f7fa159c8e18e7f9a8d71ff4b8052452ae70a4edc6b76a6e97eda00d5364923f\norjson==3.10.15 ; platform_python_implementation != 'PyPy' \\\n--hash=sha256:035fb83585e0f15e076759b6fedaf0abb460d1765b6a36f48018a52858443514 \\\n--hash=sha256:05ca7fe452a2e9d8d9d706a2984c95b9c2ebc5db417ce0b7a49b91d50642a23e \\\n--hash=sha256:0a4f27ea5617828e6b58922fdbec67b0aa4bb844e2d363b9244c47fa2180e665 \\\n--hash=sha256:13242f12d295e83c2955756a574ddd6741c81e5b99f2bef8ed8d53e47a01e4b7 \\\n--hash=sha256:17085a6aa91e1cd70ca8533989a18b5433e15d29c574582f76f821737c8d5806 \\\n--hash=sha256:1e6d33efab6b71d67f22bf2962895d3dc6f82a6273a965fab762e64fa90dc399 \\\n--hash=sha256:208beedfa807c922da4e81061dafa9c8489c6328934ca2a562efa707e049e561 \\\n--hash=sha256:552c883d03ad185f720d0c09583ebde257e41b9521b74ff40e08b7dec4559c04 \\\n--hash=sha256:616e3e8d438d02e4854f70bfdc03a6bcdb697358dbaa6bcd19cbe24d24ece1f8 \\\n--hash=sha256:6fd9bc64421e9fe9bd88039e7ce8e58d4fead67ca88e3a4014b143cec7684fd4 \\\n--hash=sha256:7066b74f9f259849629e0d04db6609db4cf5b973248f455ba5d3bd58a4daaa5b \\\n--hash=sha256:73cb85490aa6bf98abd20607ab5c8324c0acb48d6da7863a51be48505646c814 \\\n--hash=sha256:763dadac05e4e9d2bc14938a45a2d0560549561287d41c465d3c58aec818b164 \\\"\n```\n\n----------------------------------------\n\nTITLE: Installing pgai with SQLAlchemy Integration\nDESCRIPTION: This snippet shows how to install pgai with SQLAlchemy extras using pip.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/python-integration.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install \"pgai[sqlalchemy]\"\n```\n\n----------------------------------------\n\nTITLE: Setting Cohere API Key as Environment Variable in Bash\nDESCRIPTION: Sets the Cohere API key as an environment variable for secure access to Cohere services.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/cohere.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport COHERE_API_KEY=\"this-is-my-super-secret-api-key-dont-tell\"\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Variables File\nDESCRIPTION: Sample content for a .env file that provides API keys and configuration for various LLM providers used by the vectorizer worker and tests.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nOLLAMA_HOST=\"\"\nOPENAI_API_KEY=\"\"\nVOYAGE_API_KEY=\"\"\nMISTRAL_API_KEY=\"\"\nCOHERE_API_KEY=\"\"\nHUGGINGFACE_API_KEY=\"\"\nAZURE_OPENAI_API_KEY=\"\"\nAZURE_OPENAI_API_BASE=\"\"\nAZURE_OPENAI_API_VERSION=\"\"\nENABLE_VECTORIZER_TOOL_TESTS=1\n```\n\n----------------------------------------\n\nTITLE: Visualizing RFC Process Flow with Mermaid Diagram\nDESCRIPTION: This Mermaid diagram illustrates the flow of the Request for Comments (RFC) process used for significant changes or new features in the pgai project. It shows the progression from Strawman to Draft, which can then move to either Accepted or Rejected status, with Accepted proposals moving to the Implemented stage.\nSOURCE: https://github.com/timescale/pgai/blob/released/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph LR\n    A[Strawman] --> B[Draft]\n    B --> C[Accepted]\n    B --> D[Rejected]\n    C --> E[Implemented]\n```\n\n----------------------------------------\n\nTITLE: Cross-Database Querying with Foreign Data Wrappers\nDESCRIPTION: Reference to PostgreSQL Foreign Data Wrappers for handling queries across multiple databases.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n[foreign data wrappers](https://www.postgresql.org/docs/current/postgres-fdw.html)\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Containers\nDESCRIPTION: Command to start the PostgreSQL and Ollama containers using docker compose\nSOURCE: https://github.com/timescale/pgai/blob/released/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for pgai\nDESCRIPTION: Command to build a Docker image for the pgai extension from the root of the repository, targeting the test database configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -f projects/extension/Dockerfile --target pgai-test-db -t pgai projects/extension\n```\n\n----------------------------------------\n\nTITLE: Running pgai Docker Container\nDESCRIPTION: Command to run the Docker container for pgai extension development.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\njust ext docker-run\n```\n\n----------------------------------------\n\nTITLE: Checking Vectorizer Worker Logs with Docker Compose\nDESCRIPTION: This shell command displays the logs of the vectorizer worker container, allowing monitoring of the vectorization process.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/quick-start-openai.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose logs -f vectorizer-worker\n```\n\n----------------------------------------\n\nTITLE: Vectorizer Workers Implementation\nDESCRIPTION: Reference to documentation for running vectorizer workers in self-hosted pgai deployments.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/structured_retrieval/text_to_sql.md#2025-04-22_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n[vectorizer workers](https://github.com/timescale/pgai/blob/main/docs/vectorizer/worker.md)\n```\n\n----------------------------------------\n\nTITLE: Cloning PGAI Repository\nDESCRIPTION: Git commands to clone the PGAI repository at a specific tagged release version\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/install/source.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/timescale/pgai.git --branch extension-0.8.0\ncd pgai\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies with Versions and Hashes\nDESCRIPTION: This snippet shows a comprehensive list of Python package dependencies, including their versions and SHA256 hash values. It's typically used in requirements files or package management configurations to ensure reproducible builds and verify package integrity.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_2\n\nLANGUAGE: Text\nCODE:\n```\ngrpcio-status==1.69.0 \\\n    --hash=sha256:595ef84e5178d6281caa732ccf68ff83259241608d26b0e9c40a5e66eee2a2d2 \\\n    --hash=sha256:d6b2a3c9562c03a817c628d7ba9a925e209c228762d6d7677ae5c9401a542853\nh11==0.14.0 \\\n    --hash=sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d \\\n    --hash=sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761\nhttpcore==1.0.7 \\\n    --hash=sha256:8551cb62a169ec7162ac7be8d4817d561f60e08eaa485234898414bb5a8a0b4c \\\n    --hash=sha256:a3fff8f43dc260d5bd363d9f9cf1830fa3a458b332856f34282de498ed420edd\nhttptools==0.6.4 \\\n    --hash=sha256:0614154d5454c21b6410fdf5262b4a3ddb0f53f1e1721cfd59d55f32138c578a \\\n    --hash=sha256:16e603a3bff50db08cd578d54f07032ca1631450ceb972c2f834c2b860c28ea2 \\\n    --hash=sha256:288cd628406cc53f9a541cfaf06041b4c71d751856bab45e3702191f931ccd17 \\\n    --hash=sha256:28908df1b9bb8187393d5b5db91435ccc9c8e891657f9cbb42a2541b44c82fc8 \\\n    --hash=sha256:322d20ea9cdd1fa98bd6a74b77e2ec5b818abdc3d36695ab402a0de8ef2865a3 \\\n    --hash=sha256:342dd6946aa6bda4b8f18c734576106b8a31f2fe31492881a9a160ec84ff4bd5 \\\n    --hash=sha256:345c288418f0944a6fe67be8e6afa9262b18c7626c3ef3c28adc5eabc06a68da \\\n    --hash=sha256:3c73ce323711a6ffb0d247dcd5a550b8babf0f757e86a52558fe5b86d6fefcc0 \\\n    --hash=sha256:40a5ec98d3f49904b9fe36827dcf1aadfef3b89e2bd05b0e35e94f97c2b14721 \\\n    --hash=sha256:40b0f7fe4fd38e6a507bdb751db0379df1e99120c65fbdc8ee6c1d044897a636 \\\n    --hash=sha256:4b36913ba52008249223042dca46e69967985fb4051951f94357ea681e1f5dc0 \\\n    --hash=sha256:4d87b29bd4486c0093fc64dea80231f7c7f7eb4dc70ae394d70a495ab8436071 \\\n    --hash=sha256:4e93eee4add6493b59a5c514da98c939b244fce4a0d8879cd3f466562f4b7d5c \\\n    --hash=sha256:59e724f8b332319e2875efd360e61ac07f33b492889284a3e05e6d13746876f4 \\\n    --hash=sha256:69422b7f458c5af875922cdb5bd586cc1f1033295aa9ff63ee196a87519ac8e1 \\\n    --hash=sha256:85071a1e8c2d051b507161f6c3e26155b5c790e4e28d7f236422dbacc2a9cc44 \\\n    --hash=sha256:856f4bc0478ae143bad54a4242fccb1f3f86a6e1be5548fecfd4102061b3a083 \\\n    --hash=sha256:90d96a385fa941283ebd231464045187a31ad932ebfa541be8edf5b3c2328959 \\\n    --hash=sha256:ade273d7e767d5fae13fa637f4d53b6e961fb7fd93c7797562663f0171c26660 \\\n    --hash=sha256:c26f313951f6e26147833fc923f78f95604bbec812a43e5ee37f26dc9e5a686c \\\n    --hash=sha256:ca80b7485c76f768a3bc83ea58373f8db7b015551117375e4918e2aa77ea9b50 \\\n    --hash=sha256:dacdd3d10ea1b4ca9df97a0a303cbacafc04b5cd375fa98732678151643d4988 \\\n    --hash=sha256:db78cb9ca56b59b016e64b6031eda5653be0589dba2b1b43453f6e8b405a0970 \\\n    --hash=sha256:deee0e3343f98ee8047e9f4c5bc7cedbf69f5734454a94c38ee829fb2d5fa3c1 \\\n    --hash=sha256:df017d6c780287d5c80601dafa31f17bddb170232d85c066604d8558683711a2 \\\n    --hash=sha256:ec4f178901fa1834d4a060320d2f3abc5c9e39766953d038f1458cb885f47e81 \\\n    --hash=sha256:f47f8ed67cc0ff862b84a1189831d1d33c963fb3ce1ee0c65d3b0cbe7b711069 \\\n    --hash=sha256:f8787367fbdfccae38e35abf7641dafc5310310a5987b689f4c32cc8cc3ee975 \\\n    --hash=sha256:f9eb89ecf8b290f2e293325c646a211ff1c2493222798bb80a530c5e7502494f\nhttpx==0.27.2 \\\n    --hash=sha256:7bb2708e112d8fdd7829cd4243970f0c223274051cb35ee80c03301ee29a3df0 \\\n    --hash=sha256:f7c2be1d2f3c3c3160d441802406b206c2b76f5947b11115e6df10c6c65e66c2\nhttpx-sse==0.4.0 \\\n    --hash=sha256:1e81a3a3070ce322add1d3529ed42eb5f70817f45ed6ec915ab753f961139721 \\\n    --hash=sha256:f329af6eae57eaa2bdfd962b42524764af68075ea87370a2de920af5341e318f\nhuggingface-hub==0.27.1 \\\n    --hash=sha256:1c5155ca7d60b60c2e2fc38cbb3ffb7f7c3adf48f824015b219af9061771daec \\\n    --hash=sha256:c004463ca870283909d715d20f066ebd6968c2207dae9393fdffb3c1d4d8f98b\nidna==3.10 \\\n    --hash=sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9 \\\n    --hash=sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3\nimportlib-metadata==8.6.1 \\\n    --hash=sha256:02a89390c1e15fdfdc0d7c6b25cb3e62650d0494005c97d6f148bf5b9787525e \\\n    --hash=sha256:310b41d755445d74569f993ccfc22838295d9fe005425094fad953d7f15c8580\niniconfig==2.0.0 \\\n    --hash=sha256:2d91e135bf72d31a410b17c16da610a82cb55f6b0477d1a902134b24a455b8b3 \\\n    --hash=sha256:b6a85871a79d2e3b22d2d1b94ac2824226a63c6b741c88f7ae975f18b6778374\njinja2==3.1.5 \\\n    --hash=sha256:8fefff8dc3034e27bb80d67c671eb8a9bc424c0ef4c0826edbff304cceff43bb \\\n    --hash=sha256:aba0f4dc9ed8013c424088f68a5c226f7d6097ed89b246d7749c2ec4175c6adb\njiter==0.8.2 \\\n    --hash=sha256:025337859077b41548bdcbabe38698bcd93cfe10b06ff66617a48ff92c9aec60 \\\n    --hash=sha256:14601dcac4889e0a1c75ccf6a0e4baf70dbc75041e51bcf8d0e9274519df6887 \\\n    --hash=sha256:180a8aea058f7535d1c84183c0362c710f4750bef66630c05f40c93c2b152a0f \\\n    --hash=sha256:2dd61c5afc88a4fda7d8b2cf03ae5947c6ac7516d32b7a15bf4b49569a5c076b \\\n    --hash=sha256:32475a42b2ea7b344069dc1e81445cfc00b9d0e3ca837f0523072432332e9f74 \\\n    --hash=sha256:37b2998606d6dadbb5ccda959a33d6a5e853252d921fec1792fc902351bb4e2c \\\n    --hash=sha256:3ac9f578c46f22405ff7f8b1f5848fb753cc4b8377fbec8470a7dc3997ca7566 \\\n    --hash=sha256:3b94a33a241bee9e34b8481cdcaa3d5c2116f575e0226e421bed3f7a6ea71cff \\\n    --hash=sha256:4a9220497ca0cb1fe94e3f334f65b9b5102a0b8147646118f020d8ce1de70105 \\\n    --hash=sha256:4ab9a87f3784eb0e098f84a32670cfe4a79cb6512fd8f42ae3d0709f06405d18 \\\n    --hash=sha256:5127dc1abd809431172bc3fbe8168d6b90556a30bb10acd5ded41c3cfd6f43b6 \\\n    --hash=sha256:5672a86d55416ccd214c778efccf3266b84f87b89063b582167d803246354be4 \\\n    --hash=sha256:580ccf358539153db147e40751a0b41688a5ceb275e6f3e93d91c9467f42b2e3 \\\n    --hash=sha256:58dc9bc9767a1101f4e5e22db1b652161a225874d66f0e5cb8e2c7d1c438b587 \\\n    --hash=sha256:5a90a923338531b7970abb063cfc087eebae6ef8ec8139762007188f6bc69a9f \\\n    --hash=sha256:653cf462db4e8c41995e33d865965e79641ef45369d8a11f54cd30888b7e6ff1 \\\n    --hash=sha256:66227a2c7b575720c1871c8800d3a0122bb8ee94edb43a5685aa9aceb2782d44 \\\n    --hash=sha256:6e5337bf454abddd91bd048ce0dca5134056fc99ca0205258766db35d0a2ea43 \\\n    --hash=sha256:711e408732d4e9a0208008e5892c2966b485c783cd2d9a681f3eb147cf36c7ef \\\n    --hash=sha256:76e324da7b5da060287c54f2fabd3db5f76468006c811831f051942bf68c9d44 \\\n    --hash=sha256:789361ed945d8d42850f919342a8665d2dc79e7e44ca1c97cc786966a21f627a \\\n    --hash=sha256:79aec8172b9e3c6d05fd4b219d5de1ac616bd8da934107325a6c0d0e866a21b6 \\\n    --hash=sha256:7efe4853ecd3d6110301665a5178b9856be7e2a9485f49d91aa4d737ad2ae49e \\\n    --hash=sha256:83c0efd80b29695058d0fd2fa8a556490dbce9804eac3e281f373bbc99045f6c \\\n    --hash=sha256:8b9931fd36ee513c26b5bf08c940b0ac875de175341cbdd4fa3be109f0492586 \\\n    --hash=sha256:8ffc86ae5e3e6a93765d49d1ab47b6075a9c978a2b3b80f0f32628f39caa0c88 \\\n    --hash=sha256:92249669925bc1c54fcd2ec73f70f2c1d6a817928480ee1c65af5f6b81cdf12d \\\n    --hash=sha256:9c63eaef32b7bebac8ebebf4dabebdbc6769a09c127294db6babee38e9f405b9 \\\n    --hash=sha256:a6c710d657c8d1d2adbbb5c0b0c6bfcec28fd35bd6b5f016395f9ac43e878a15 \\\n    --hash=sha256:a9584de0cd306072635fe4b89742bf26feae858a0683b399ad0c2509011b9dc0 \\\n    --hash=sha256:ab7f43235d71e03b941c1630f4b6e3055d46b6cb8728a17663eaac9d8e83a865 \\\n    --hash=sha256:af102d3372e917cffce49b521e4c32c497515119dc7bd8a75665e90a718bbf08 \\\n    --hash=sha256:b25bd626bde7fb51534190c7e3cb97cee89ee76b76d7585580e22f34f5e3f393 \\\n    --hash=sha256:b2dd880785088ff2ad21ffee205e58a8c1ddabc63612444ae41e5e4b321b39c0 \\\n    --hash=sha256:b426f72cd77da3fec300ed3bc990895e2dd6b49e3bfe6c438592a3ba660e41ca\n```\n\n----------------------------------------\n\nTITLE: Running the Data Load Script\nDESCRIPTION: Command to execute the load.sh script which downloads a dataset from HuggingFace, loads and processes the data into the wiki table, and optionally creates a backup dump.\nSOURCE: https://github.com/timescale/pgai/blob/released/scripts/vectorizer-load-test/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./load.sh\n```\n\n----------------------------------------\n\nTITLE: Installing pgai Dependencies with uv\nDESCRIPTION: Command to install the project's dependencies into the virtual environment using uv.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nuv sync --no-install-project\n```\n\n----------------------------------------\n\nTITLE: Creating Demo Database\nDESCRIPTION: SQL commands to drop an existing demo database (if it exists) with force and create a new empty demo database.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npsql -U postgres -f - <<EOF\n\ndrop database if exists demo with (force);\ncreate database demo;\n\nEOF\n```\n\n----------------------------------------\n\nTITLE: HTML Logo Image Element\nDESCRIPTION: Centers and displays the pgai logo image with specified height\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<p align=\"center\">\n    <img height=\"200\" src=\"https://github.com/timescale/pgai/blob/main/docs/images/pgai_logo.png?raw=true\" alt=\"pgai\"/>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Viewing Docker Compose Logs for Specific Service\nDESCRIPTION: Command to view and follow logs for a specific Docker Compose service, in this case the vectorizer-worker service.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_18\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml logs -f vectorizer-worker\n```\n\n----------------------------------------\n\nTITLE: Accessing PostgreSQL Database with psql\nDESCRIPTION: Command to connect to the PostgreSQL database running in Docker using the psql client directly from the container.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml exec -it db psql -U postgres\n```\n\n----------------------------------------\n\nTITLE: Discord Bot Launch Command\nDESCRIPTION: Command to start the Discord bot application.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nuv run python -m pgai_discord_bot.main\n```\n\n----------------------------------------\n\nTITLE: Documentation Import Script Execution\nDESCRIPTION: Command to run the script that populates the database with documentation content.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nuv run python -m pgai_discord_bot.insert_docs\n```\n\n----------------------------------------\n\nTITLE: Viewing Docker Compose Logs for All Services\nDESCRIPTION: Command to view and follow logs for all Docker Compose services, useful for debugging and monitoring the entire stack.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_17\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml logs -f\n```\n\n----------------------------------------\n\nTITLE: Defining Environment Variables for Database and Ollama\nDESCRIPTION: Sets environment variables for the PostgreSQL database connection string and Ollama host URL.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/finding_best_open_source_embedding_model/best_embedding_model_rag_app.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nDATABASE_CONNECTION_STRING=\"postgres://postgres:postgres@localhost:5432/postgres\"\nOLLAMA_HOST=\"http://ollama:11434\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Conventional Commit Format Examples\nDESCRIPTION: Examples of valid commit messages following the Conventional Commits specification, which helps with automation, changelog generation, and maintaining a clear commit history.\nSOURCE: https://github.com/timescale/pgai/blob/released/DEVELOPMENT.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nfeat: add vector similarity search\nfix: resolve null pointer in embedding generation\ndocs: update installation instructions\ntest: add integration tests for OpenAI embedder\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies with Hashes\nDESCRIPTION: Detailed package dependency list specifying exact versions and SHA256 hashes for package verification. Includes packaging v24.2, pandas v2.2.3, and pglast v7.2.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n--hash=sha256:7723ad949a0ea502df656948ddd8b392780a5beaa4c3b5f97e525191b102fff0 \\\n--hash=sha256:7946922ada8f3e0b7b958cc3eb22cfcf6c0df83d1fe5521b4a100103e3fa84c8 \\\n--hash=sha256:7c203f6f969210128af3acae0ef9ea6aab9782939f45f6fe02d05958fe761ef9 \\\npackaging==24.2 \\\n--hash=sha256:09abb1bccd265c01f4a3aa3f7a7db064b36514d2cba19a2f694fe6150451a759 \\\n--hash=sha256:c228a6dc5e932d346bc5739379109d49e8853dd8223571c7c5b55260edc0b97f\npandas==2.2.3 \\\n--hash=sha256:062309c1b9ea12a50e8ce661145c6aab431b1e99530d3cd60640e255778bd43a \\\n--hash=sha256:15c0e1e02e93116177d29ff83e8b1619c93ddc9c49083f237d4312337a61165d \\\npglast==7.2 \\\n--hash=sha256:0136528288bfa971d1dbd76217ccab72f9a6819a1b191f4d72c81466f5623577\n```\n\n----------------------------------------\n\nTITLE: Docker Container Build Command\nDESCRIPTION: Command to build the Docker container with documentation context and tag it as discord_bot.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker build --build-context docs=../../docs . -t discord_bot\n```\n\n----------------------------------------\n\nTITLE: Managing SQL in pgai Extension Development\nDESCRIPTION: Commands for SQL-specific development tasks in pgai extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\njust ext clean-sql\njust ext build\njust ext install-sql-all\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Hashes\nDESCRIPTION: This snippet lists Python package dependencies with their versions and SHA256 hashes. It includes websockets version 14.1 and xxhash version 3.5.0, along with multiple hash values for each package to ensure integrity and security during installation.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_7\n\nLANGUAGE: plaintext\nCODE:\n```\nwebsockets==14.1 \\\n    --hash=sha256:00fe5da3f037041da1ee0cf8e308374e236883f9842c7c465aa65098b1c9af59 \\\n    --hash=sha256:034feb9f4286476f273b9a245fb15f02c34d9586a5bc936aff108c3ba1b21beb \\\n    --hash=sha256:04a97aca96ca2acedf0d1f332c861c5a4486fdcba7bcef35873820f940c4231e \\\n    --hash=sha256:0d4290d559d68288da9f444089fd82490c8d2744309113fc26e2da6e48b65da6 \\\n    --hash=sha256:1288369a6a84e81b90da5dbed48610cd7e5d60af62df9851ed1d1d23a9069f10 \\\n    --hash=sha256:1d045cbe1358d76b24d5e20e7b1878efe578d9897a25c24e6006eef788c0fdf0 \\\n    --hash=sha256:1f874ba705deea77bcf64a9da42c1f5fc2466d8f14daf410bc7d4ceae0a9fcb0 \\\n    --hash=sha256:2177ee3901075167f01c5e335a6685e71b162a54a89a56001f1c3e9e3d2ad250 \\\n    --hash=sha256:219c8187b3ceeadbf2afcf0f25a4918d02da7b944d703b97d12fb01510869078 \\\n    --hash=sha256:3630b670d5057cd9e08b9c4dab6493670e8e762a24c2c94ef312783870736ab9 \\\n    --hash=sha256:368a05465f49c5949e27afd6fbe0a77ce53082185bbb2ac096a3a8afaf4de52e \\\n    --hash=sha256:36ebd71db3b89e1f7b1a5deaa341a654852c3518ea7a8ddfdf69cc66acc2db1b \\\n    --hash=sha256:398b10c77d471c0aab20a845e7a60076b6390bfdaac7a6d2edb0d2c59d75e8d8 \\\n    --hash=sha256:3c3deac3748ec73ef24fc7be0b68220d14d47d6647d2f85b2771cb35ea847aa1 \\\n    --hash=sha256:3f14a96a0034a27f9d47fd9788913924c89612225878f8078bb9d55f859272b0 \\\n    --hash=sha256:449d77d636f8d9c17952628cc7e3b8faf6e92a17ec581ec0c0256300717e1512 \\\n    --hash=sha256:4b6caec8576e760f2c7dd878ba817653144d5f369200b6ddf9771d64385b84d4 \\\n    --hash=sha256:4d4fc827a20abe6d544a119896f6b78ee13fe81cbfef416f3f2ddf09a03f0e2e \\\n    --hash=sha256:5a42d3ecbb2db5080fc578314439b1d79eef71d323dc661aa616fb492436af5d \\\n    --hash=sha256:5b918d288958dc3fa1c5a0b9aa3256cb2b2b84c54407f4813c45d52267600cd3 \\\n    --hash=sha256:660c308dabd2b380807ab64b62985eaccf923a78ebc572bd485375b9ca2b7dc7 \\\n    --hash=sha256:6a6c9bcf7cdc0fd41cc7b7944447982e8acfd9f0d560ea6d6845428ed0562058 \\\n    --hash=sha256:6d24fc337fc055c9e83414c94e1ee0dee902a486d19d2a7f0929e49d7d604b09 \\\n    --hash=sha256:7048eb4415d46368ef29d32133134c513f507fff7d953c18c91104738a68c3b3 \\\n    --hash=sha256:77569d19a13015e840b81550922056acabc25e3f52782625bc6843cfa034e1da \\\n    --hash=sha256:8149a0f5a72ca36720981418eeffeb5c2729ea55fa179091c81a0910a114a5d2 \\\n    --hash=sha256:836bef7ae338a072e9d1863502026f01b14027250a4545672673057997d5c05a \\\n    --hash=sha256:8621a07991add373c3c5c2cf89e1d277e49dc82ed72c75e3afc74bd0acc446f0 \\\n    --hash=sha256:87e31011b5c14a33b29f17eb48932e63e1dcd3fa31d72209848652310d3d1f0d \\\n    --hash=sha256:88cf9163ef674b5be5736a584c999e98daf3aabac6e536e43286eb74c126b9c7 \\\n    --hash=sha256:90b5d9dfbb6d07a84ed3e696012610b6da074d97453bd01e0e30744b472c8179 \\\n    --hash=sha256:90f4c7a069c733d95c308380aae314f2cb45bd8a904fb03eb36d1a4983a4993f \\\n    --hash=sha256:9481a6de29105d73cf4515f2bef8eb71e17ac184c19d0b9918a3701c6c9c4f23 \\\n    --hash=sha256:9607b9a442392e690a57909c362811184ea429585a71061cd5d3c2b98065c199 \\\n    --hash=sha256:9777564c0a72a1d457f0848977a1cbe15cfa75fa2f67ce267441e465717dcf1a \\\n    --hash=sha256:a0adf84bc2e7c86e8a202537b4fd50e6f7f0e4a6b6bf64d7ccb96c4cd3330b29 \\\n    --hash=sha256:a35f704be14768cea9790d921c2c1cc4fc52700410b1c10948511039be824aac \\\n    --hash=sha256:a3dfff83ca578cada2d19e665e9c8368e1598d4e787422a460ec70e531dbdd58 \\\n    --hash=sha256:a655bde548ca98f55b43711b0ceefd2a88a71af6350b0c168aa77562104f3f45 \\\n    --hash=sha256:ad2ab2547761d79926effe63de21479dfaf29834c50f98c4bf5b5480b5838434 \\\n    --hash=sha256:b1f3628a0510bd58968c0f60447e7a692933589b791a6b572fcef374053ca280 \\\n    --hash=sha256:bc6ccf7d54c02ae47a48ddf9414c54d48af9c01076a2e1023e3b486b6e72c707 \\\n    --hash=sha256:bea45f19b7ca000380fbd4e02552be86343080120d074b87f25593ce1700ad58 \\\n    --hash=sha256:cc1fc87428c1d18b643479caa7b15db7d544652e5bf610513d4a3478dbe823d0 \\\n    --hash=sha256:cf5201a04550136ef870aa60ad3d29d2a59e452a7f96b94193bee6d73b8ad9a9 \\\n    --hash=sha256:df174ece723b228d3e8734a6f2a6febbd413ddec39b3dc592f5a4aa0aff28098 \\\n    --hash=sha256:e0744623852f1497d825a49a99bfbec9bea4f3f946df6eb9d8a2f0c37a2fec2e \\\n    --hash=sha256:e5dc25a9dbd1a7f61eca4b7cb04e74ae4b963d658f9e4f9aad9cd00b688692c8 \\\n    --hash=sha256:eb6d38971c800ff02e4a6afd791bbe3b923a9a57ca9aeab7314c21c84bf9ff05 \\\n    --hash=sha256:ed907449fe5e021933e46a3e65d651f641975a768d0649fee59f10c2985529ed \\\n    --hash=sha256:f6cf0ad281c979306a6a34242b371e90e891bce504509fb6bb5246bbbf31e7b6 \\\n    --hash=sha256:f95ba34d71e2fa0c5d225bde3b3bdb152e957150100e75c86bc7f3964c450d89\nxxhash==3.5.0 \\\n    --hash=sha256:02c2e816896dc6f85922ced60097bcf6f008dedfc5073dcba32f9c8dd786f3c1 \\\n    --hash=sha256:07fda5de378626e502b42b311b049848c2ef38784d0d67b6f30bb5008642f8eb \\\n    --hash=sha256:08424f6648526076e28fae6ea2806c0a7d504b9ef05ae61d196d571e5c879c84 \\\n    --hash=sha256:109b436096d0a2dd039c355fa3414160ec4d843dfecc64a14077332a00aeb7da \\\n    --hash=sha256:1308fa542bbdbf2fa85e9e66b1077eea3a88bef38ee8a06270b4298a7a62a166 \\\n    --hash=sha256:1328f6d8cca2b86acb14104e381225a3d7b42c92c4b86ceae814e5c400dbb415 \\\n    --hash=sha256:14470ace8bd3b5d51318782cd94e6f94431974f16cb3b8dc15d52f3b69df8e00 \\\n    --hash=sha256:149b7914451eb154b3dfaa721315117ea1dac2cc55a01bfbd4df7c68c5dd683d \\\n    --hash=sha256:2014c5b3ff15e64feecb6b713af12093f75b7926049e26a580e94dcad3c73d8c \\\n    --hash=sha256:25b5a51dc3dfb20a10833c8eee25903fd2e14059e9afcd329c9da20609a307b2 \\\n    --hash=sha256:3171f693dbc2cef6477054a665dc255d996646b4023fe56cb4db80e26f4cc520 \\\n    --hash=sha256:37889a0d13b0b7d739cfc128b1c902f04e32de17b33d74b637ad42f1c55101f6 \\\n    --hash=sha256:3dbbd9892c5ebffeca1ed620cf0ade13eb55a0d8c84e0751a6653adc6ac40d0c \\\n    --hash=sha256:3e5b5e16c5a480fe5f59f56c30abdeba09ffd75da8d13f6b9b6fd224d0b4d0a2 \\\n    --hash=sha256:3ff2c0a34eae7df88c868be53a8dd56fbdf592109e21d4bfa092a27b0bf4a7bf \\\n    --hash=sha256:4811336f1ce11cac89dcbd18f3a25c527c16311709a89313c3acaf771def2d4b \\\n    --hash=sha256:4cc2d67fdb4d057730c75a64c5923abfa17775ae234a71b0200346bfb0a7f482 \\\n    --hash=sha256:4e28503dccc7d32e0b9817aa0cbfc1f45f563b2c995b7a66c4c8a0d232e840c7 \\\n    --hash=sha256:4e2febf914ace002132aa09169cc572e0d8959d0f305f93d5828c4836f9bc5a6 \\\n    --hash=sha256:53a068fe70301ec30d868ece566ac90d873e3bb059cf83c32e76012c889b8637 \\\n    --hash=sha256:586886c7e89cb9828bcd8a5686b12e161368e0064d040e225e72607b43858ba2 \\\n    --hash=sha256:59aa1203de1cb96dbeab595ded0ad0c0056bb2245ae11fac11c0ceea861382b9 \\\n    --hash=sha256:5a74f23335b9689b66eb6dbe2a931a88fcd7a4c2cc4b1cb0edba8ce381c7a1da \\\n    --hash=sha256:5d0d307d27099bb0cbeea7260eb39ed4fdb99c5542e21e94bb6fd29e49c57a23 \\\n    --hash=sha256:5d3a10609c51da2a1c0ea0293fc3968ca0a18bd73838455b5bca3069d7f8e32b \\\n    --hash=sha256:6027dcd885e21581e46d3c7f682cfb2b870942feeed58a21c29583512c3f09f8 \\\n    --hash=sha256:61a1ff00674879725b194695e17f23d3248998b843eb5e933007ca743310f793 \\\n    --hash=sha256:61c722ed8d49ac9bc26c7071eeaa1f6ff24053d553146d5df031802deffd03da \\\n    --hash=sha256:685c4f4e8c59837de103344eb1c8a3851f670309eb5c361f746805c5471b8c88 \\\n    --hash=sha256:70dabf941dede727cca579e8c205e61121afc9b28516752fd65724be1355cc90 \\\n    --hash=sha256:7c5d3e570ef46adaf93fc81b44aca6002b5a4d8ca11bd0580c07eac537f36680 \\\n    --hash=sha256:7cb29a034301e2982df8b1fe6328a84f4b676106a13e9135a0d7e0c3e9f806da \\\n    --hash=sha256:7f85e0108d51092bdda90672476c7d909c04ada6923c14ff9d913c4f7dc8a3bc \\\n    --hash=sha256:80babcc30e7a1a484eab952d76a4f4673ff601f54d5142c26826502740e70b43 \\\n    --hash=sha256:82085c2abec437abebf457c1d12fccb30cc8b3774a0814872511f0f0562c768c \\\n    --hash=sha256:84f2caddf951c9cbf8dc2e22a89d4ccf5d86391ac6418fe81e3c67d0cf60b45f \\\n    --hash=sha256:893074d651cf25c1cc14e3bea4fceefd67f2921b1bb8e40fcfeba56820de80c6 \\\n    --hash=sha256:89997aa1c4b6a5b1e5b588979d1da048a3c6f15e55c11d117a56b75c84531f5a\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies Installation\nDESCRIPTION: Command to install required Python packages using uv package manager.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/discord_bot/README.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nuv sync\n```\n\n----------------------------------------\n\nTITLE: Example Generated SQL with Table Joins (Text)\nDESCRIPTION: Presents a sample SQL query generated by `ai.text_to_sql` for the question about flights arriving in Houston, TX. This example demonstrates the LLM's ability to construct a query involving joins between the `flight` and `airport` tables and filtering by city and region ('US-TX').\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_22\n\nLANGUAGE: Text\nCODE:\n```\n```text\n                             text_to_sql\n----------------------------------------------------------------------\n SELECT COUNT(*) AS total_flights                                    +\n FROM postgres_air.flight AS f                                       +\n JOIN postgres_air.airport AS a ON f.arrival_airport = a.airport_code+\n WHERE f.actual_arrival >= '2024-06-01'                              +\n   AND f.actual_arrival < '2024-07-01'                               +\n   AND a.city = 'HOUSTON'                                            +\n   AND a.iso_region = 'US-TX';\n(1 row)\n```\n```\n\n----------------------------------------\n\nTITLE: Importing Python Libraries in PGAI Extension\nDESCRIPTION: A placeholder comment that gets replaced during build to enable Python library imports in plpython3u database functions. Must be indented with four spaces.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n    #ADD-PYTHON-LIB-DIR\n```\n\n----------------------------------------\n\nTITLE: Building and Installing pgai Extension\nDESCRIPTION: Commands to build and install the pgai extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\njust ext build\njust ext install-all\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Directory Structure\nDESCRIPTION: File structure for the Docker development environment setup, showing the main files involved in the Docker Compose configuration.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n compose-dev.yaml              # The actual Docker Compose file\n .env                          # Optional environment variables that applies to all services\n db.env                        # Database-specific environment variables\n worker.env                    # Vectorizer-worker-specific environment variables\n Dockerfile                    # Dockerfile for the vectorizer worker service\n ../extension/Dockerfile       # Dockerfile for the PostgreSQL database with the pgai extension preloaded\n```\n\n----------------------------------------\n\nTITLE: Accessing psql Shell for pgai\nDESCRIPTION: Command to get a psql shell to the database in the Docker container.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\njust ext psql-shell\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Logging for ai.text_to_sql (SQL)\nDESCRIPTION: Sets the client-side message level to 'debug' using `set client_min_messages` within `psql`. This enables detailed logging for subsequent commands. Then, it calls `ai.text_to_sql` to allow observation of the internal steps, prompts sent to the LLM, and responses received during the text-to-SQL conversion process.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nset client_min_messages to 'debug';\nselect ai.text_to_sql('How many flights arrived at the IAH airport in June 2024?');\n```\n```\n\n----------------------------------------\n\nTITLE: Managing pgai Docker Container\nDESCRIPTION: Commands to stop, start, and remove the pgai Docker container.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# Stop the container\njust ext docker-stop\n# Start the container\njust ext docker-start\n```\n\n----------------------------------------\n\nTITLE: Accessing Docker Shell for pgai Development\nDESCRIPTION: Command to get a shell session in the running pgai Docker container.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\njust ext docker-shell\n```\n\n----------------------------------------\n\nTITLE: Running pgai Test Server\nDESCRIPTION: Command to run the test server for pgai unit testing.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\njust ext test-server\n```\n\n----------------------------------------\n\nTITLE: Uninstalling pgai Extension\nDESCRIPTION: Command to uninstall the pgai extension.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\njust ext uninstall\n```\n\n----------------------------------------\n\nTITLE: Running pgai Tests\nDESCRIPTION: Command to run the pgai extension tests.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\njust ext test\n```\n\n----------------------------------------\n\nTITLE: Restoring Data from Dump\nDESCRIPTION: Command to execute the restore.sh script which recreates the wiki table from a previously created dump file, providing a faster setup option.\nSOURCE: https://github.com/timescale/pgai/blob/released/scripts/vectorizer-load-test/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./restore.sh\n```\n\n----------------------------------------\n\nTITLE: Cloning the pgai Repository\nDESCRIPTION: Command to clone the pgai repository from GitHub and navigate to the project directory.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:timescale/pgai.git\ncd pgai\n```\n\n----------------------------------------\n\nTITLE: Installing Commit Hook Command\nDESCRIPTION: Command to install the local commit hook that ensures commits meet project standards before pushing changes.\nSOURCE: https://github.com/timescale/pgai/blob/released/DEVELOPMENT.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\njust install-commit-hook\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container for pgai\nDESCRIPTION: Command to run a Docker container with the pgai image, mounting the text-to-SQL example directory and configuring PostgreSQL with the required extensions.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name pgai --hostname pgai -e POSTGRES_HOST_AUTH_METHOD=trust \\\n  --mount type=bind,src=`pwd`/examples/text_to_sql,dst=/demo \\\n  -p 127.0.0.1:5432:5432 pgai \\\n  -c shared_preload_libraries='timescaledb, pgextwlist' \\\n  -c extwlist.extensions='ai,vector'\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Virtual Environment with uv\nDESCRIPTION: Commands to set up a Python virtual environment for pgai extension development using uv.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ncd projects/extension\nuv venv\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Opening Shell in Docker Container\nDESCRIPTION: Command to execute a bash shell inside the pgai Docker container, setting the working directory to the mounted demo directory.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -w /demo -it pgai /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Example Result of Executing Generated SQL (Text)\nDESCRIPTION: Displays the sample result (a flight count of 1273) obtained after executing the SQL query generated by `ai.text_to_sql` using the `\\gexec` metacommand in `psql`. This shows the final answer derived from the LLM-generated query.\nSOURCE: https://github.com/timescale/pgai/blob/released/examples/text_to_sql/README.md#2025-04-22_snippet_19\n\nLANGUAGE: Text\nCODE:\n```\n```text\n flight_count\n--------------\n         1273\n(1 row)\n```\n```\n\n----------------------------------------\n\nTITLE: Connecting to Database with psql Variable\nDESCRIPTION: Command to connect to PostgreSQL with psql while setting up a variable for the API key from an environment variable.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/security/handling-api-keys.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npsql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\" -v my_api_key=$MY_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Stopping Docker Compose Services\nDESCRIPTION: Command to stop and remove the Docker Compose services while retaining the named volume for persistent data storage.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml down\n```\n\n----------------------------------------\n\nTITLE: HTML Center Alignment Div\nDESCRIPTION: Centers content including a heading and badges for Discord and Timescale trial links\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/README.md#2025-04-22_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div align=center>\n\n<h3>pgai allows you to develop RAG, semantic search, and other AI applications directly in PostgreSQL</h3>\n\n[![Discord](https://img.shields.io/badge/Join_us_on_Discord-black?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/KRdHVXAmkp)\n[![Try Timescale for free](https://img.shields.io/badge/Try_Timescale_for_free-black?style=for-the-badge&logo=timescale&logoColor=white)](https://tsdb.co/gh-pgai-signup)\n\n</div>\n```\n\n----------------------------------------\n\nTITLE: Removing Docker Compose Services and Volumes\nDESCRIPTION: Command to stop and remove all Docker Compose containers, networks, and volumes, which will delete all persistent data.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/DEVELOPMENT.md#2025-04-22_snippet_19\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f compose-dev.yaml down -v\n```\n\n----------------------------------------\n\nTITLE: Basic SQL Query for Generating Embeddings with LiteLLM\nDESCRIPTION: A simple SQL query that uses LiteLLM to generate embeddings for the given text using a specified provider and model, referencing the API key by name.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/model_calling/litellm.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.litellm_embed('<provider>/<model>', 'Hello world', api_key_name => 'OPENAI_API_KEY');\n```\n\n----------------------------------------\n\nTITLE: Using Default Indexing for Vectorizers\nDESCRIPTION: Demonstrates the use of platform-specific default indexing options when creating vectorizers. On Timescale Cloud, 'ai.indexing_diskann' is used automatically.\nSOURCE: https://github.com/timescale/pgai/blob/released/docs/vectorizer/api-reference.md#2025-04-22_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ai.create_vectorizer(\n    'blog_posts'::regclass,\n    indexing => ai.indexing_default(),\n    -- other parameters...\n);\n```\n\n----------------------------------------\n\nTITLE: Git Log Command for Release Notes\nDESCRIPTION: Shell command to generate a formatted git log for creating release notes, showing commit messages and links since the last tagged version.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/DEVELOPMENT.md#2025-04-22_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ngit log $(git describe --tags --abbrev=0 --match \"extension-*\")..origin/main --pretty=format:\"%s ([%h](https://github.com/timescale/pgai/commit/%h))\" projects/extension\n```\n\n----------------------------------------\n\nTITLE: Running Dataclass Generation Script for pgai Extension\nDESCRIPTION: Command to execute the script that generates dataclasses for CreateVectorizer parameters. Requires a PostgreSQL database with pgai installed on port 5432.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/pgai/pgai/vectorizer/generate/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv run generate\n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements with Hash Verification\nDESCRIPTION: Detailed package requirements specification with exact versions and SHA256 hash verification for secure dependency installation. Each package includes one or more hash values to verify package integrity during installation.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n-e .\\naiohappyeyeballs==2.4.4 \\n    --hash=sha256:5fdd7d87889c63183afc18ce9271f9b0a7d32c2303e394468dd45d514a757745 \\n    --hash=sha256:a980909d50efcd44795c4afeca523296716d50cd756ddca6af8c65b996e27de8\\naiohttp==3.11.11 \\n    --hash=sha256:0882c2820fd0132240edbb4a51eb8ceb6eef8181db9ad5291ab3332e0d71df5f \\n    --hash=sha256:0a6d3fbf2232e3a08c41eca81ae4f1dff3d8f1a30bae415ebe0af2d2458b8a33\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies with SHA256 Hashes\nDESCRIPTION: Detailed list of Python package dependencies including charset-normalizer, click, cohere, colorama, datasets, dill, distro, docstring-parser, exceptiongroup, fastapi, fastapi-cli, and fastavro. Each package entry includes version number and SHA256 hash values for verification.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\ncharset-normalizer==3.4.1 \\\n    --hash=sha256:0924e81d3d5e70f8126529951dac65c1010cdf117bb75eb02dd12339b57749dd \\\n    --hash=sha256:09b26ae6b1abf0d27570633b2b078a2a20419c99d66fb2823173d73f188ce601\n\nclick==8.1.8 \\\n    --hash=sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2 \\\n    --hash=sha256:ed53c9d8990d83c2a27deae68e4ee337473f6330c040a31d4225c9574d16096a\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies with SHA256 Hashes\nDESCRIPTION: List of Python package dependencies including version numbers and their corresponding SHA256 hash values used for package verification and security. Contains entries for packages like jsonpatch, jsonschema, langchain-core, and other dependencies.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n--hash=sha256:ba5bdf56969cad2019d4e8ffd3f879b5fdc792624129741d3d83fc832fef8c7d \\\n--hash=sha256:bf55846c7b7a680eebaf9c3c48d630e1bf51bdf76c68a5f654b8524335b0ad29 \\\n--hash=sha256:ca1f08b8e43dc3bd0594c992fb1fd2f7ce87f7bf0d44358198d6da8034afdf84\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies with Hashes\nDESCRIPTION: This snippet lists various Python package dependencies along with their versions and SHA256 hashes. It includes packages such as pygments, pytest, python-dateutil, python-dotenv, pytz, pyyaml, referencing, and regex. Each package is specified with its version and one or more SHA256 hashes for verification.\nSOURCE: https://github.com/timescale/pgai/blob/released/projects/extension/requirements-lock.txt#2025-04-22_snippet_6\n\nLANGUAGE: plaintext\nCODE:\n```\npygments==2.19.1 \\\n    --hash=sha256:61c16d2a8576dc0649d9f39e089b5f02bcd27fba10d8fb4dcc28173f7a45151f \\\n    --hash=sha256:9ea1544ad55cecf4b8242fab6dd35a93bbce657034b0611ee383099054ab6d8c\npytest==8.3.2 \\\n    --hash=sha256:4ba08f9ae7dcf84ded419494d229b48d0903ea6407b030eaec46df5e6a73bba5 \\\n    --hash=sha256:c132345d12ce551242c87269de812483f5bcc87cdbb4722e48487ba194f9fdce\npython-dateutil==2.9.0.post0 \\\n    --hash=sha256:37dd54208da7e1cd875388217d5e00ebd4179249f90fb72437e91a35459a0ad3 \\\n    --hash=sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427\npython-dotenv==1.0.1 \\\n    --hash=sha256:e324ee90a023d808f1959c46bcbc04446a10ced277783dc6ee09987c37ec10ca \\\n    --hash=sha256:f7b63ef50f1b690dddf550d03497b66d609393b40b564ed0d674909a68ebf16a\npytz==2024.2 \\\n    --hash=sha256:2aa355083c50a0f93fa581709deac0c9ad65cca8a9e9beac660adcbd493c798a \\\n    --hash=sha256:31c7c1817eb7fae7ca4b8c7ee50c72f93aa2dd863de768e1ef4245d426aa0725\npyyaml==6.0.2 \\\n    --hash=sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48 \\\n    --hash=sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086\nreferencing==0.36.1 \\\n    --hash=sha256:363d9c65f080d0d70bc41c721dce3c7f3e77fc09f269cd5c8813da18069a6794 \\\n    --hash=sha256:ca2e6492769e3602957e9b831b94211599d2aade9477f5d44110d2530cf9aade\nregex==2024.11.6 \\\n    --hash=sha256:02a02d2bb04fec86ad61f3ea7f49c015a0681bf76abb9857f945d26159d2968c \\\n    --hash=sha256:02e28184be537f0e75c1f9b2f8847dc51e08e6e171c6bde130b2687e0c33cf60\n```"
  }
]