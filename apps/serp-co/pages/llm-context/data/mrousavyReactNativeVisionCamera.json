[
  {
    "owner": "mrousavy",
    "repo": "react-native-vision-camera",
    "content": "TITLE: Exposing Frame Processor Plugin to JavaScript in React Native Vision Camera\nDESCRIPTION: This snippet shows how to create a wrapper function that exposes a native Frame Processor Plugin (scanFaces) to JavaScript. It initializes the plugin through VisionCameraProxy and creates a properly typed function that can be called from worklets.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_FINAL.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { VisionCameraProxy, Frame } from 'react-native-vision-camera'\n\nconst plugin = VisionCameraProxy.initFrameProcessorPlugin('scanFaces')\n\n/**\n * Scans faces.\n */\nexport function scanFaces(frame: Frame): object {\n  'worklet'\n  if (plugin == null) throw new Error('Failed to load Frame Processor Plugin \"scanFaces\"!')\n  return plugin.call(frame)\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Video Recording with React Native Vision Camera\nDESCRIPTION: Initiates video recording using the startRecording function of the Camera component. Includes callbacks for handling recording completion and errors.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\ncamera.current.startRecording({\n  onRecordingFinished: (video) => console.log(video),\n  onRecordingError: (error) => console.error(error)\n})\n```\n\n----------------------------------------\n\nTITLE: Implementing Pinch-to-Zoom with React Native Vision Camera\nDESCRIPTION: This code snippet demonstrates how to implement a pinch-to-zoom gesture for a camera component using React Native Vision Camera, react-native-reanimated, and react-native-gesture-handler. It covers creating an animated camera component, managing zoom state, and applying animated props for smooth zooming.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ZOOMING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { Camera, useCameraDevice, CameraProps } from 'react-native-vision-camera'\nimport Reanimated, { useAnimatedProps, useSharedValue } from 'react-native-reanimated'\nimport { Gesture, GestureDetector } from 'react-native-gesture-handler'\n\nReanimated.addWhitelistedNativeProps({\n  zoom: true,\n})\nconst ReanimatedCamera = Reanimated.createAnimatedComponent(Camera)\n\nexport function App() {\n  const device = useCameraDevice('back')\n  const zoom = useSharedValue(device.neutralZoom)\n\n  const zoomOffset = useSharedValue(0);\n  const gesture = Gesture.Pinch()\n    .onBegin(() => {\n      zoomOffset.value = zoom.value\n    })\n    .onUpdate(event => {\n      const z = zoomOffset.value * event.scale\n      zoom.value = interpolate(\n        z,\n        [1, 10],\n        [device.minZoom, device.maxZoom],\n        Extrapolation.CLAMP,\n      )\n    })\n\n  const animatedProps = useAnimatedProps<CameraProps>(\n    () => ({ zoom: zoom.value }),\n    [zoom]\n  )\n\n  if (device == null) return <NoCameraDeviceError />\n  return (\n    <GestureDetector gesture={gesture}>\n      <ReanimatedCamera\n        style={StyleSheet.absoluteFill}\n        device={device}\n        isActive={true}\n        animatedProps={animatedProps}\n      />\n    </GestureDetector>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Camera Implementation in React Native\nDESCRIPTION: Example React component showing basic camera implementation using VisionCamera. Demonstrates how to select a camera device and render a fullscreen camera view.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/README.md#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const device = useCameraDevice('back')\n\n  if (device == null) return <NoCameraErrorView />\n  return (\n    <Camera\n      style={StyleSheet.absoluteFill}\n      device={device}\n      isActive={true}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Using Frame Processor Plugins in React Native Vision Camera\nDESCRIPTION: Example of using a frame processor plugin called 'detectFaces' to process camera frames in a React Native component. The code demonstrates how to implement a frame processor function and attach it to a Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    // highlight-next-line\n    const faces = detectFaces(frame)\n    console.log(`Faces in Frame: ${faces}`)\n  }, [])\n\n  return (\n    <Camera frameProcessor={frameProcessor} {...cameraProps} />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Camera Reference in React Native\nDESCRIPTION: Sets up a camera reference using useRef hook to access camera functions. This is required to use camera methods like takePhoto and takeSnapshot.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const camera = useRef<Camera>(null)\n  // ...\n\n  return (\n    <Camera\n      ref={camera}\n      {...cameraProps}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Camera Format Resolution\nDESCRIPTION: Sets up custom photo resolution by configuring the camera format using useCameraFormat hook.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nconst format = useCameraFormat(device, [\n  { photoResolution: { width: 1280, height: 720 } }\n])\n\nreturn <Camera {...props} format={format} />\n```\n\n----------------------------------------\n\nTITLE: Using Image Labeling with Frame Processors in JSX\nDESCRIPTION: Example of using a frame processor to detect objects in real-time camera frames at 60+ FPS using the vision-camera-image-labeler plugin.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const objects = detectObjects(frame)\n  const label = objects[0].name\n  console.log(`You're looking at a ${label}.`)\n}, [])\n\nreturn <Camera frameProcessor={frameProcessor} />\n```\n\n----------------------------------------\n\nTITLE: Testing Frame Processor Plugin in React Native Camera Component\nDESCRIPTION: This example demonstrates how to use a custom Frame Processor Plugin within a React component. It uses the useFrameProcessor hook to create a frame processor function that calls the scanFaces plugin and logs the results.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_FINAL.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    // highlight-next-line\n    const faces = scanFaces(frame)\n    console.log(`Faces in Frame: ${faces}`)\n  }, [])\n\n  return (\n    <Camera frameProcessor={frameProcessor} {...cameraProps} />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Default Camera Device using Hooks API in React Native Vision Camera\nDESCRIPTION: This snippet demonstrates how to select the default camera device using the Hooks API in React Native Vision Camera. It uses the 'useCameraDevice' hook to get the best matching camera device for the 'back' position.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = useCameraDevice('back')\n```\n\n----------------------------------------\n\nTITLE: Taking a Photo with Camera\nDESCRIPTION: Basic implementation of taking a photo using the camera reference's takePhoto method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nconst photo = await camera.current.takePhoto()\n```\n\n----------------------------------------\n\nTITLE: Selecting Camera Format Using Hooks API\nDESCRIPTION: Example of using the useCameraFormat hook to select a camera format with specific video aspect ratio, resolution, and frame rate requirements.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = useCameraFormat(device, [\n  { videoAspectRatio: 16 / 9 },\n  { videoResolution: { width: 3048, height: 2160 } },\n  { fps: 60 }\n])\n```\n\n----------------------------------------\n\nTITLE: Initializing Camera Component in React Native\nDESCRIPTION: Sets up a Camera component using a ref in a React Native application. This allows access to camera functions through the ref object.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const camera = useRef<Camera>(null)\n  // ...\n\n  return (\n    <Camera\n      ref={camera}\n      {...cameraProps}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Code Scanner with React Hooks API\nDESCRIPTION: Using the useCodeScanner hook to create a code scanner that detects QR codes and EAN-13 barcodes. The hook returns a memoized scanner object that can be passed to the Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nconst codeScanner = useCodeScanner({\n  codeTypes: ['qr', 'ean-13'],\n  onCodeScanned: (codes) => {\n    console.log(`Scanned ${codes.length} codes!`)\n  }\n})\n\nreturn <Camera {...props} codeScanner={codeScanner} />\n```\n\n----------------------------------------\n\nTITLE: Saving Recorded Video to Camera Roll\nDESCRIPTION: Shows how to save a recorded video to the device's camera roll using react-native-cameraroll after the recording is finished.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_10\n\nLANGUAGE: ts\nCODE:\n```\ncamera.current.startRecording({\n  ...props,\n  onRecordingFinished: (video) => {\n    const path = video.path\n    await CameraRoll.save(`file://${path}`, {\n      type: 'video',\n    })\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Enabling Photo Capture in Camera Component\nDESCRIPTION: Configures the Camera component to enable photo capture functionality by setting the photo prop to true.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera\n  {...props}\n  photo={true}\n/>\n```\n\n----------------------------------------\n\nTITLE: Handling Camera Errors with Switch Statement in TypeScript\nDESCRIPTION: Example of how to handle different camera error codes using a switch statement. This pattern allows for specific responses to different types of camera errors based on their error code.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ERRORS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nswitch (error.code) {\n  case \"device/configuration-error\":\n    // prompt user\n    break\n  case \"device/microphone-unavailable\":\n    // ask for permission\n    break\n  case \"capture/recording-in-progress\":\n    // stop recording\n    break\n  default:\n    console.error(error)\n    break\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Camera Focus Implementation with Gesture Handler\nDESCRIPTION: Full example demonstrating camera focus implementation using react-native-gesture-handler. Shows how to set up a tap gesture detector and integrate it with the camera focus function in a React component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FOCUSING.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nimport { Camera, useCameraDevice } from 'react-native-vision-camera'\nimport { Gesture, GestureDetector } from 'react-native-gesture-handler'\n\nexport function App() {\n  const camera = useRef<Camera>(null)\n  const device = useCameraDevice('back')\n\n  const focus = useCallback((point: Point) => {\n    const c = camera.current\n    if (c == null) return\n    c.focus(point)\n  }, [])\n\n  const gesture = Gesture.Tap()\n    .onEnd(({ x, y }) => {\n      runOnJS(focus)({ x, y })\n    })\n\n  if (device == null) return <NoCameraDeviceError />\n  return (\n    <GestureDetector gesture={gesture}>\n      <Camera\n        ref={camera}\n        style={StyleSheet.absoluteFill}\n        device={device}\n        isActive={true}\n      />\n    </GestureDetector>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Stopping Video Recording in React Native Vision Camera\nDESCRIPTION: Stops the ongoing video recording using the stopRecording function of the Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nawait camera.current.stopRecording()\n```\n\n----------------------------------------\n\nTITLE: Handling Runtime Errors in React Native Camera Component\nDESCRIPTION: Example of implementing the onError callback for handling runtime errors in a Camera component. Uses useCallback to memoize the error handler function.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ERRORS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const onError = useCallback((error: CameraRuntimeError) => {\n    console.error(error)\n  }, [])\n\n  return <Camera onError={onError} {...cameraProps} />\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing HDR Camera Component\nDESCRIPTION: Implements a Camera component with HDR support, using the selected format and enabling HDR for both photos and videos based on format capabilities.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/HDR.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nconst format = ...\n\nreturn (\n  <Camera\n    {...props}\n    format={format}\n    videoHdr={format.supportsVideoHdr}\n    photoHdr={format.supportsPhotoHdr}\n  />\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Camera Activity State Management in React Native\nDESCRIPTION: Example showing how to manage camera active state using useIsFocused and useAppState hooks to properly pause the camera when app is minimized or screen changes.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LIFECYCLE.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction App() {\n  const isFocused = useIsFocused()\n  const appState = useAppState()\n  const isActive = isFocused && appState === \"active\"\n\n  return <Camera {...props} isActive={isActive} />\n}\n```\n\n----------------------------------------\n\nTITLE: Reading Photo Data as Blob\nDESCRIPTION: Demonstrates how to read the captured photo's data as a blob using the fetch API.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_8\n\nLANGUAGE: ts\nCODE:\n```\nconst file = await camera.current.takePhoto()\nconst result = await fetch(`file://${file.path}`)\nconst data = await result.blob();\n```\n\n----------------------------------------\n\nTITLE: Taking Snapshots for Faster Photo Capture in React Native Vision Camera\nDESCRIPTION: Demonstrates how to use the takeSnapshot method for faster photo capture compared to regular photo taking.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PERFORMANCE.mdx#2025-04-20_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst snapshot = await camera.current.takeSnapshot({\n  quality: 85\n})\n```\n\n----------------------------------------\n\nTITLE: Installing React Native Vision Camera\nDESCRIPTION: Commands to install the Vision Camera package via npm and set up iOS dependencies using CocoaPods.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/README.md#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm i react-native-vision-camera\ncd ios && pod install\n```\n\n----------------------------------------\n\nTITLE: Handling Camera Capture Errors with Try-Catch\nDESCRIPTION: Example of using try-catch to handle potential errors during photo capture. Demonstrates checking the instance type and error codes to provide specific error handling for different capture scenarios.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ERRORS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const camera = useRef<Camera>(null)\n\n  // called when the user presses a \"capture\" button\n  const onPress = useCallback(() => {\n    try {\n      const photo = await camera.current.takePhoto()\n    } catch (e) {\n      if (e instanceof CameraCaptureError) {\n        switch (e.code) {\n          case \"capture/file-io-error\":\n            console.error(\"Failed to write photo to disk!\")\n            break\n          default:\n            console.error(e)\n            break\n        }\n      }\n    }\n  }, [camera])\n\n  return <Camera ref={camera} {...cameraProps} />\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Camera with Variable FPS Rate for Low Light Conditions\nDESCRIPTION: Example of configuring a Camera component with a variable FPS rate (using a tuple) that allows the camera to automatically adjust between minimum and maximum values based on lighting conditions.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_9\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  // ...\n  const format = ...\n  const minFps = Math.max(format.minFps, 20)\n  const maxFps = Math.min(format.maxFps, 30)\n\n  return (\n    <Camera\n      {...props}\n      fps={[minFps, maxFps]}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting High FPS Format for Slow-Motion Using Hooks API\nDESCRIPTION: Example of using the useCameraFormat hook to find a camera format that supports high frame rates (240 FPS) for slow-motion video recording.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = useCameraFormat(device, [\n  { fps: 240 }\n])\n```\n\n----------------------------------------\n\nTITLE: Using Dynamic Parameters in Frame Processors\nDESCRIPTION: Example of using a dynamic sensitivity parameter in a frame processor that can be updated without requiring native rebuilds.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nconst sensitivity = 0.8\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const faces = detectFaces(frame, { sensitivity: sensitivity })\n  // ...\n}, [sensitivity])\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Frame Processing\nDESCRIPTION: Shows how to use runAsync for handling long-running processing tasks without blocking the camera pipeline\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_INTERACTING.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  console.log(\"I'm running synchronously at 60 FPS!\")\n\n  runAsync(frame, () => {\n    'worklet'\n    console.log(\"I'm running asynchronously, possibly at a lower FPS rate!\")\n    const faces = detectFaces(frame)\n  })\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Basic Camera Focus Implementation in TypeScript\nDESCRIPTION: Simple example showing how to call the camera focus function with x and y coordinates. The focus function expects a Point parameter representing the location relative to the Camera view.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FOCUSING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nawait camera.current.focus({ x: tapEvent.x, y: tapEvent.y })\n```\n\n----------------------------------------\n\nTITLE: Applying Video Stabilization to Camera Component in React Native\nDESCRIPTION: This code demonstrates how to apply the selected video stabilization format to the Camera component in React Native Vision Camera, checking if stabilization is supported.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/STABILIZATION.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nconst format = ...\nconst supportsVideoStabilization = format.videoStabilizationModes.includes('cinematic-extended')\n\nreturn (\n  <Camera\n    {...props}\n    format={format}\n    videoStabilizationMode={supportsVideoStabilization}\n  />\n)\n```\n\n----------------------------------------\n\nTITLE: Pausing and Resuming Video Recording\nDESCRIPTION: Demonstrates how to pause and resume video recording using the pauseRecording and resumeRecording functions of the Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nawait camera.current.pauseRecording()\n...\nawait camera.current.resumeRecording()\n```\n\n----------------------------------------\n\nTITLE: Setting Static Camera Exposure in React Native\nDESCRIPTION: This snippet demonstrates how to set a static exposure value for the Camera component using the exposure prop. The exposure value ranges from device.minExposure to device.maxExposure.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/EXPOSURE.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} exposure={-1} />\n```\n\n----------------------------------------\n\nTITLE: Enabling Code Scanner in gradle.properties for React Native\nDESCRIPTION: Configuration for enabling the code scanner feature in Android by adding a flag to the gradle.properties file. This is required to use the MLKit Vision Barcode Scanning API on Android.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: groovy\nCODE:\n```\nVisionCamera_enableCodeScanner=true\n```\n\n----------------------------------------\n\nTITLE: Implementing Animated Camera Exposure with Reanimated in React Native\nDESCRIPTION: This snippet shows a complete implementation of animated camera exposure using Reanimated. It creates a shared value for the exposure slider, maps it to the device's exposure range, and passes it as an animated prop to the ReanimatedCamera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/EXPOSURE.mdx#2025-04-20_snippet_2\n\nLANGUAGE: jsx\nCODE:\n```\nfunction App() {\n  // 1. create shared value for exposure slider (from -1..0..1)\n  const exposureSlider = useSharedValue(0)\n\n  // 2. map slider to [minExposure, 0, maxExposure]\n  const exposureValue = useDerivedValue(() => {\n    if (device == null) return 0\n\n    return interpolate(exposureSlider.value,\n                       [-1, 0, 1],\n                       [device.minExposure, 0, device.maxExposure])\n  }, [exposureSlider, device])\n\n  // 3. pass it as an animated prop\n  const animatedProps = useAnimatedProps(() => ({\n    exposure: exposureValue.value\n  }), [exposureValue])\n\n  // 4. render Camera\n  return (\n    <ReanimatedCamera\n      {...props}\n      animatedProps={animatedProps}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Camera with High FPS Format\nDESCRIPTION: Example of configuring a Camera component with a high FPS format for slow-motion recording, using the format's maximum supported FPS.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_8\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const device = ...\n  const format = useCameraFormat(device, [\n    { fps: 240 }\n  ])\n  const fps = format.maxFps // <-- 240 FPS, or lower if 240 FPS is not available\n\n  return (\n    <Camera\n      style={StyleSheet.absoluteFill}\n      device={device}\n      format={format}\n      fps={fps}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Camera Format Using Imperative API\nDESCRIPTION: Example of using the getCameraFormat function to select a camera format with specific video aspect ratio, resolution, and frame rate requirements.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = getCameraFormat(device, [\n  { videoAspectRatio: 16 / 9 },\n  { videoResolution: { width: 3048, height: 2160 } },\n  { fps: 60 }\n])\n```\n\n----------------------------------------\n\nTITLE: Configuring Camera for Video and Audio Capture\nDESCRIPTION: Sets up the Camera component with props to enable video and audio capture.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera\n  {...props}\n  video={true}\n  audio={true} // <-- optional\n/>\n```\n\n----------------------------------------\n\nTITLE: Setting Camera Frame Rate in React Native VisionCamera\nDESCRIPTION: Example demonstrating how to set a custom frame rate (FPS) for both the camera preview and video stream using the fps prop.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PREVIEW.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} fps={60} />\n```\n\n----------------------------------------\n\nTITLE: Accessing Frame Information with TypeScript\nDESCRIPTION: Example of accessing frame properties like width, height, and pixel format in a frame processor function.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  console.log(`Frame: ${frame.width}x${frame.height} (${frame.pixelFormat})`)\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Creating a Native Frame Processor Plugin in Swift\nDESCRIPTION: Example of implementing a native Frame Processor Plugin in Swift that uses ML Kit to detect faces with configurable sensitivity.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_8\n\nLANGUAGE: swift\nCODE:\n```\n@objc(FaceDetector)\npublic class FaceDetectorPlugin: FrameProcessorPlugin {\n  private let sensitivity: Double\n\n  public override init(proxy: VisionCameraProxyHolder, options: [AnyHashable: Any]) {\n    super.init(proxy: proxy, options: options)\n    sensitivity = options[\"sensitivity\"] as Double\n  }\n\n  public override func callback(_ frame: Frame, withArguments args: [AnyHashable: Any]) -> Any {\n    let imageBuffer = CMSampleBufferGetImageBuffer(frame.buffer)\n    let faces = MLKit.detectFaces(imageBuffer, sensitivity)\n    return faces.map { face in face.toJson() }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Camera Mirroring\nDESCRIPTION: Shows how to enable mirroring for camera output using the isMirrored prop.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ORIENTATION.mdx#2025-04-20_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} isMirrored={true} />\n```\n\n----------------------------------------\n\nTITLE: Using Predefined Format Template with Hooks API\nDESCRIPTION: Example of using a predefined format template (Snapchat) with the useCameraFormat hook for common camera configurations.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = useCameraFormat(device, Templates.Snapchat)\n```\n\n----------------------------------------\n\nTITLE: Enabling FPS Graph in React Native Vision Camera\nDESCRIPTION: Code snippet showing how to enable the FPS Graph feature in the Camera component for monitoring Frame Processor performance. This helps in profiling and debugging frame processing performance over time.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_TIPS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} enableFpsGraph={true} />\n```\n\n----------------------------------------\n\nTITLE: Creating a Native Frame Processor Plugin in Java\nDESCRIPTION: Example of implementing a native Frame Processor Plugin in Java for Android that performs face detection with configurable sensitivity.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_9\n\nLANGUAGE: java\nCODE:\n```\npublic class FaceDetectorPlugin extends FrameProcessorPlugin {\n  private final Double sensitivity;\n\n  public FaceDetectorPlugin(VisionCameraProxyHolder proxy, Map<String, Object> options) {\n    super();\n    sensitivity = options.get(\"sensitivity\") as Double;\n  }\n\n  @Override\n  public Object callback(Frame frame, Map<String, Object> params) {\n    Image image = frame.getImage();\n    Array<Face> faces = MLKit.detectFaces(image, sensitivity);\n    return faces.stream().map(f -> f.toJson());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Shared Values with Frame Processors\nDESCRIPTION: Shows how to use Shared Values to communicate between Frame Processors and other contexts like React JS or Skia\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_INTERACTING.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nconst bananas = useSharedValue([])\n\n// Detect Bananas in Frame Processor\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const objects = detectObjects(frame)\n  bananas.value = objects.filter((o) => o.type === 'banana')\n}, [bananas])\n\n// Draw bananas in a Skia Canvas\nconst onDraw = useDrawCallback((canvas) => {\n  for (const banana of bananas.value) {\n    const rect = Skia.XYWHRect(banana.x,\n                               banana.y,\n                               banana.width,\n                               banana.height)\n    const paint = Skia.Paint()\n    paint.setColor(Skia.Color('red'))\n    frame.drawRect(rect, paint)\n  }\n})\n```\n\n----------------------------------------\n\nTITLE: Implementing UI Rotation Handler\nDESCRIPTION: Shows how to handle camera UI rotation changes using useState and applying transforms to UI elements.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ORIENTATION.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nconst [uiRotation, setUiRotation] = useState(0)\nconst uiStyle: ViewStyle = {\n  transform: [{ rotate: `${uiRotation}deg` }]\n}\n\nreturn (\n  <View>\n    <Camera {...props} onUIRotationChanged={setUiRotation} />\n    <FlipCameraButton style={uiStyle} />\n  </View>\n)\n```\n\n----------------------------------------\n\nTITLE: Selecting Camera Format with Video Stabilization in React Native (Hooks API)\nDESCRIPTION: This snippet demonstrates how to select a camera format that supports video stabilization using the Hooks API in React Native Vision Camera.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/STABILIZATION.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = useCameraFormat(device, [\n  { videoStabilizationMode: 'cinematic-extended' }\n])\n```\n\n----------------------------------------\n\nTITLE: Selecting Camera Devices for Performance in React Native Vision Camera\nDESCRIPTION: Demonstrates how to select a simpler camera device for faster initialization using both Hooks and Imperative APIs. The example shows choosing a wide-angle camera over a triple camera setup.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PERFORMANCE.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst fasterDevice = useCameraDevice('back', {\n  physicalDevices: ['wide-angle-camera']\n})\nconst slowerDevice = useCameraDevice('back', {\n  physicalDevices: ['ultra-wide-angle-camera', 'wide-angle-camera', 'telephoto-camera']\n})\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst devices = Camera.getAvailableCameraDevices()\nconst fasterDevice = getCameraDevice(devices, 'back', {\n  physicalDevices: ['wide-angle-camera']\n})\nconst slowerDevice = getCameraDevice(devices, 'back', {\n  physicalDevices: ['ultra-wide-angle-camera', 'wide-angle-camera', 'telephoto-camera']\n})\n```\n\n----------------------------------------\n\nTITLE: Implementing Mock Module for VisionCamera Testing\nDESCRIPTION: Creates a mock implementation of the VisionCamera component for testing purposes. It provides mock implementations for camera permissions, device listing, and photo capture functionality while rendering nothing in the UI.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/MOCKING.mdx#2025-04-20_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n// vision-camera.e2e.js\n\nimport React from 'react'\nimport RNFS, { writeFile } from 'react-native-fs'\n\nconsole.log('[DETOX] Using mocked react-native-vision-camera')\n\nexport class VisionCamera extends React.PureComponent {\n  static getAvailableCameraDevices() {\n    return (\n      [\n        {\n          position: 'back',\n        },\n      ]\n    )\n  }\n\n  static async getCameraPermissionStatus() {\n    return 'granted'\n  }\n\n  static async requestCameraPermission() {\n    return 'granted'\n  }\n\n  async takePhoto() {\n    const writePath = `${RNFS.DocumentDirectoryPath}/simulated_camera_photo.png`\n\n    const imageDataBase64 = 'some_large_base_64_encoded_simulated_camera_photo'\n    await writeFile(writePath, imageDataBase64, 'base64')\n\n    return { path: writePath }\n  }\n\n  render() {\n    return null\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Video Codec for Recording\nDESCRIPTION: Configures the video codec for recording, demonstrating how to use H.265 (HEVC) for more efficient encoding.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\ncamera.current.startRecording({\n  ...props,\n  videoCodec: 'h265'\n})\n```\n\n----------------------------------------\n\nTITLE: Using Maximum Resolution Format with Hooks API\nDESCRIPTION: Example of using the useCameraFormat hook with the 'max' flag to select a format with the highest available video and photo resolution.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = useCameraFormat(device, [\n  { videoResolution: 'max' },\n  { photoResolution: 'max' }\n])\n```\n\n----------------------------------------\n\nTITLE: Basic Skia Frame Processor Usage in TypeScript\nDESCRIPTION: Example showing how to create a basic Skia Frame Processor that detects bananas and draws red rectangles around them on the camera frame.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_SKIA.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst frameProcessor = useSkiaFrameProcessor((frame) => {\n  'worklet'\n  const bananas = detectBananas()\n\n  frame.render()\n  for (const banana of bananas) {\n    const paint = Skia.Paint()\n    paint.setColor(Skia.Color('red'))\n    frame.drawRect(banana.rect, paint)\n  }\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Implementing Face Detector Frame Processor Plugin in Kotlin\nDESCRIPTION: Kotlin implementation of a custom Face Detector Frame Processor Plugin class that extends FrameProcessorPlugin and overrides the callback method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_4\n\nLANGUAGE: kotlin\nCODE:\n```\nimport com.mrousavy.camera.frameprocessors.Frame\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPlugin\nimport com.mrousavy.camera.frameprocessors.VisionCameraProxy\n\nclass FaceDetectorFrameProcessorPlugin(proxy: VisionCameraProxy, options: Map<String, Any>?): FrameProcessorPlugin() {\n\n  override fun callback(frame: Frame, arguments: Map<String, Any>?): Any? {\n// highlight-next-line\n    // code goes here\n    return null\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Asynchronous Frame Processors with Event Emitters\nDESCRIPTION: Example of using asynchronous Frame Processor Plugins that communicate back to JavaScript through event emitters. This pattern is useful for computationally intensive operations that can't run at full frame rate.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_9\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    SomeAI.process(frame) // does not block frame processor, runs async\n  }, [])\n\n  useEffect(() => {\n    SomeAI.addListener((results) => {\n      // gets called asynchronously, goes through the React Event Emitter system\n      console.log(`AI results: ${results}`)\n    })\n  }, [])\n\n  return (\n    <Camera frameProcessor={frameProcessor} {...cameraProps} />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Shader Effects with Skia\nDESCRIPTION: Example showing how to use Skia RuntimeEffect to apply an inverted color shader to the camera frame.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_SKIA.mdx#2025-04-20_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst invertColorsFilter = Skia.RuntimeEffect.Make(`\n  uniform shader image;\n  half4 main(vec2 pos) {\n    vec4 color = image.eval(pos);\n    return vec4((1.0 - color).rgb, 1.0);\n  }\n`)\nconst shaderBuilder = Skia.RuntimeShaderBuilder(invertColorsFilter)\nconst imageFilter = Skia.ImageFilter.MakeRuntimeShader(shaderBuilder, null, null)\nconst paint = Skia.Paint()\npaint.setImageFilter(imageFilter)\n\nconst frameProcessor = useSkiaFrameProcessor((frame) => {\n  'worklet'\n  frame.render(paint)\n}, [paint])\n```\n\n----------------------------------------\n\nTITLE: Enabling Location Tags in Camera Component\nDESCRIPTION: React/TSX code to enable GPS location tagging in the Camera component. When enabled, all captured photos and videos will automatically include location data.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_6\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} enableLocation={true} />\n```\n\n----------------------------------------\n\nTITLE: Configuring Video Bit Rate in React Native Vision Camera\nDESCRIPTION: Shows how to set the video bit rate to high or low quality using the videoBitRate prop of the Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_8\n\nLANGUAGE: jsx\nCODE:\n```\n<Camera {...props} videoBitRate=\"high\" />\n```\n\nLANGUAGE: jsx\nCODE:\n```\n<Camera {...props} videoBitRate=\"low\" />\n```\n\nLANGUAGE: jsx\nCODE:\n```\n<Camera {...props} videoBitRate={bitRate} />\n```\n\n----------------------------------------\n\nTITLE: Implementing Face Detector Frame Processor Plugin in Java\nDESCRIPTION: Java implementation of a custom Face Detector Frame Processor Plugin class that extends FrameProcessorPlugin and overrides the callback method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport androidx.annotation.NonNull;\nimport androidx.annotation.Nullable;\nimport com.mrousavy.camera.frameprocessors.Frame;\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPlugin;\nimport com.mrousavy.camera.frameprocessors.VisionCameraProxy;\n\npublic class FaceDetectorFrameProcessorPlugin extends FrameProcessorPlugin {\n  FaceDetectorFrameProcessorPlugin(@NonNull VisionCameraProxy proxy, @Nullable Map<String, Object> options) {}\n\n  @Nullable\n  @Override\n  public Object callback(@NonNull Frame frame, @Nullable Map<String, Object> arguments) throws Throwable {\n// highlight-next-line\n    // code goes here\n    return null;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HDR Format with Hooks API\nDESCRIPTION: Uses the Hooks API to select a camera format that supports HDR capture for both photos and videos.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/HDR.mdx#2025-04-20_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = useCameraFormat(device, [\n  { photoHdr: true },\n  { videoHdr: true },\n])\n```\n\n----------------------------------------\n\nTITLE: Throttled Frame Processing\nDESCRIPTION: Demonstrates how to throttle frame processing to a specific FPS rate using runAtTargetFps\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_INTERACTING.mdx#2025-04-20_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst TARGET_FPS = 2\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  console.log(\"I'm running synchronously at 60 FPS!\")\n\n  runAtTargetFps(TARGET_FPS, () => {\n    'worklet'\n    console.log(\"I'm running synchronously at 2 FPS!\")\n    const brightness = detectBrightness(frame)\n  })\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Implementing Frame Processor Plugin in Swift\nDESCRIPTION: Swift implementation of a Face Detector Frame Processor Plugin showing the class definition, initialization, and callback method. This provides the foundation for implementing custom frame processing logic in Swift.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_IOS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: swift\nCODE:\n```\nimport VisionCamera\n\n@objc(FaceDetectorFrameProcessorPlugin)\npublic class FaceDetectorFrameProcessorPlugin: FrameProcessorPlugin {\n  public override init(proxy: VisionCameraProxyHolder, options: [AnyHashable : Any]! = [:]) {\n    super.init(proxy: proxy, options: options)\n  }\n\n  public override func callback(_ frame: Frame, withArguments arguments: [AnyHashable : Any]?) -> Any {\n    let buffer = frame.buffer\n    let orientation = frame.orientation\n    // code goes here\n    return nil\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Multi-Camera Device using Hooks API in React Native Vision Camera\nDESCRIPTION: This snippet demonstrates how to select a multi-camera device (Triple-Camera) using the Hooks API. It specifies the desired physical devices to include ultra-wide, wide-angle, and telephoto cameras.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = useCameraDevice('back', {\n  physicalDevices: [\n    'ultra-wide-angle-camera',\n    'wide-angle-camera',\n    'telephoto-camera'\n  ]\n})\n```\n\n----------------------------------------\n\nTITLE: Taking Camera Snapshots\nDESCRIPTION: Implementation of taking quick snapshots from the camera preview view using takeSnapshot method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_6\n\nLANGUAGE: ts\nCODE:\n```\nconst snapshot = await camera.current.takeSnapshot({\n  quality: 90\n})\n```\n\n----------------------------------------\n\nTITLE: Canceling Video Recording in React Native Vision Camera\nDESCRIPTION: Cancels the ongoing video recording, deletes the temporary file, and triggers the onRecordingError callback with a specific error.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nawait camera.current.cancelRecording()\n```\n\n----------------------------------------\n\nTITLE: Implementing Long-Running Asynchronous Frame Processors in Java\nDESCRIPTION: A Java implementation of an asynchronous Frame Processor Plugin that copies the frame and processes it on a separate thread. This is useful for operations like network uploads that don't need to block the frame processing pipeline.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_8\n\nLANGUAGE: java\nCODE:\n```\n@Nullable\n@Override\npublic Object callback(@NonNull Frame frame, @Nullable Map<String, Object> arguments) throws Throwable {\n  if (arguments == null) {\n    return null;\n  }\n\n  String serverURL = (String)arguments.get(\"serverURL\");\n  Frame frameCopy = new Frame(/* ... */);\n\n  uploaderQueue.runAsync(() -> {\n    WebRTC.uploadImage(frameCopy, serverURL);\n    frameCopy.close();\n  });\n\n  return null;\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Default Camera Device using Imperative API in React Native Vision Camera\nDESCRIPTION: This code shows how to select the default camera device using the Imperative API in React Native Vision Camera. It first gets all available camera devices and then selects the best matching device for the 'back' position.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst devices = Camera.getAvailableCameraDevices()\nconst device = getCameraDevice(devices, 'back')\n```\n\n----------------------------------------\n\nTITLE: Resizing Frames in a JavaScript Frame Processor\nDESCRIPTION: Example of using a resize function to downscale a frame before detection for improved performance. This demonstrates how to chain multiple frame processor plugins together.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_4\n\nLANGUAGE: js\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  // creates a new `Frame` that's 720x480\n  const resizedFrame = resize(frame, 720, 480)\n\n  // by downscaling the frame, the `detectObjects` function runs faster.\n  const objects = detectObjects(resizedFrame)\n  console.log(objects)\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Setting Output Orientation in Camera Component\nDESCRIPTION: Demonstrates how to set the output orientation property on the Camera component to control photo and video capture orientation.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ORIENTATION.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} outputOrientation=\"device\" />\n```\n\n----------------------------------------\n\nTITLE: Accessing Pixel Format in VisionCamera Frame Processor\nDESCRIPTION: This code snippet demonstrates how to access and log the pixel format of a frame in a VisionCamera frame processor. It also shows how to set the desired pixel format for the camera.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PIXEL_FORMATS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nfunction App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    console.log(frame.pixelFormat) // <-- \"rgb\"\n  }, [])\n\n  return (\n    <Camera\n      style={StyleSheet.absoluteFill}\n      pixelFormat=\"rgb\"\n      frameProcessor={frameProcessor}\n    />\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting External Camera Device using Hooks API in React Native Vision Camera\nDESCRIPTION: This snippet shows how to select an external camera device using the Hooks API. It uses the 'useCameraDevice' hook to get the best matching external camera device.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst usbCamera = useCameraDevice('external')\n```\n\n----------------------------------------\n\nTITLE: Accessing JS Values in Frame Processor\nDESCRIPTION: Demonstrates how to access React state values within a Frame Processor worklet for object detection filtering\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_INTERACTING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nconst targetObject = 'banana'\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const objects = detectObjects(frame)\n  const bananas = objects.filter((o) => o.type === targetObject)\n  console.log(`Detected ${bananas} bananas!`)\n}, [targetObject])\n```\n\n----------------------------------------\n\nTITLE: Configuring Reanimated for Animating Camera Exposure\nDESCRIPTION: This code sets up Reanimated to animate the exposure property of the Camera component. It creates an animated Camera component and adds the exposure prop to the whitelisted animatable properties.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/EXPOSURE.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nimport Reanimated, { addWhitelistedNativeProps } from \"react-native-reanimated\"\n\nconst ReanimatedCamera = Reanimated.createAnimatedComponent(Camera)\naddWhitelistedNativeProps({\n  exposure: true,\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring Android Preview View Type in React Native VisionCamera\nDESCRIPTION: Code example showing how to specify the Android preview implementation using the androidPreviewViewType prop, which affects rendering performance and visual capabilities.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PREVIEW.mdx#2025-04-20_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} androidPreviewViewType=\"texture-view\" />\n```\n\n----------------------------------------\n\nTITLE: Calling JS Functions from Frame Processors\nDESCRIPTION: Demonstrates how to call JavaScript functions from within Frame Processors using createRunOnJS\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_INTERACTING.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nconst onFaceDetected = Worklets.createRunOnJS((face: Face) => {\n  navigation.push(\"FiltersPage\", { face: face })\n})\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const faces = scanFaces(frame)\n  if (faces.length > 0) {\n    onFaceDetected(faces[0])\n  }\n}, [onFaceDetected])\n```\n\n----------------------------------------\n\nTITLE: Java Implementation of a Simple Frame Processor Plugin\nDESCRIPTION: A Java implementation of a Frame Processor Plugin that simply returns a string value. This demonstrates the basic structure of a plugin and how return values are automatically converted to JavaScript values.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n@Nullable\n@Override\npublic Object callback(@NonNull Frame frame, @Nullable Map<String, Object> arguments) throws Throwable {\n  return \"cat\";\n}\n```\n\n----------------------------------------\n\nTITLE: Listening to Preview Start/Stop Events in React Native VisionCamera\nDESCRIPTION: Example showing how to use onPreviewStarted and onPreviewStopped event handlers to get notified when the camera preview begins or ends rendering frames.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PREVIEW.mdx#2025-04-20_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera\n  {...props}\n  onPreviewStarted={() => console.log('Preview started!')}\n  onPreviewStopped={() => console.log('Preview stopped!')}\n/>\n```\n\n----------------------------------------\n\nTITLE: Selecting High FPS Format for Slow-Motion Using Imperative API\nDESCRIPTION: Example of using the getCameraFormat function to find a camera format that supports high frame rates (240 FPS) for slow-motion video recording.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = getCameraFormat(device, [\n  { fps: 240 }\n])\n```\n\n----------------------------------------\n\nTITLE: Using Maximum Resolution Format with Imperative API\nDESCRIPTION: Example of using the getCameraFormat function with the 'max' flag to select a format with the highest available video and photo resolution.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = getCameraFormat(device, [\n  { videoResolution: 'max' },\n  { photoResolution: 'max' }\n])\n```\n\n----------------------------------------\n\nTITLE: Setting Video Frame Rate in React Native Vision Camera\nDESCRIPTION: Demonstrates how to set the frame rate (FPS) for video recording using the fps prop of the Camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_9\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera {...props} fps={60} />\n```\n\n----------------------------------------\n\nTITLE: Configuring Flash for Photo Capture\nDESCRIPTION: Demonstrates how to configure flash settings when taking a photo using the takePhoto options.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nconst photo = await camera.current.takePhoto({\n  flash: 'on' // 'auto' | 'off'\n})\n```\n\n----------------------------------------\n\nTITLE: Accessing Frame Pixel Data with ArrayBuffer\nDESCRIPTION: Example of converting a frame to an ArrayBuffer and accessing raw RGB pixel data from the first pixel.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  if (frame.pixelFormat === 'rgb') {\n    const buffer = frame.toArrayBuffer()\n    const data = new Uint8Array(buffer)\n    console.log(`Pixel at 0,0: RGB(${data[0]}, ${data[1]}, ${data[2]})`)\n  }\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Implementing Code Scanner with Imperative API\nDESCRIPTION: Creating a code scanner object using the imperative approach that detects QR codes and EAN-13 barcodes. This requires manual memoization to prevent unnecessary Camera session rebuilds.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nconst codeScanner: CodeScanner = {\n  codeTypes: ['qr', 'ean-13'],\n  onCodeScanned: (codes) => {\n    console.log(`Scanned ${codes.length} codes!`)\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Flash for Video Recording\nDESCRIPTION: Sets up flash for video recording by configuring the flash option in the startRecording function.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/RECORDING_VIDEOS.mdx#2025-04-20_snippet_6\n\nLANGUAGE: ts\nCODE:\n```\ncamera.current.startRecording({\n  flash: 'on',\n  ...\n})\n```\n\n----------------------------------------\n\nTITLE: Setting Photo Quality Balance\nDESCRIPTION: Shows how to configure the photo quality balance to prioritize speed over quality in the camera component.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_5\n\nLANGUAGE: jsx\nCODE:\n```\nreturn <Camera {...props} photoQualityBalance=\"speed\" />\n```\n\n----------------------------------------\n\nTITLE: Using a Community Image Labeler Plugin\nDESCRIPTION: Example of using the vision-camera-image-labeler community plugin to analyze camera frames and detect objects.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\nconst { labelImage } = useImageLabeler()\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const labels = labelImage(frame)\n  const label = labels[0].name\n  console.log(`You're looking at a ${label}.`)\n}, [labelImage])\n```\n\n----------------------------------------\n\nTITLE: Selecting Optimal Camera Format for Frame Processors\nDESCRIPTION: Code example showing how to select a camera format with specific resolution to optimize Frame Processor performance.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_10\n\nLANGUAGE: ts\nCODE:\n```\nconst format = useCameraFormat(device, [\n  { videoResolution: { width: 1280, height: 720 } }\n])\n```\n\n----------------------------------------\n\nTITLE: Selecting Appropriate Camera Format Resolution in React Native Vision Camera\nDESCRIPTION: Shows how to select a specific video resolution format using both Hooks and Imperative APIs to optimize performance and avoid unnecessary downsizing.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PERFORMANCE.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = useCameraFormat(device, [\n  { videoResolution: { width: 1920, height: 1080 } }\n])\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = getCameraFormat(device, [\n  { videoResolution: { width: 1920, height: 1080 } }\n])\n```\n\n----------------------------------------\n\nTITLE: Implementing C++ Frame Processor Plugin with JSI\nDESCRIPTION: Shows how to create a C++ Frame Processor Plugin using JSI, including header inclusion, function creation, JSI function wrapping, and global property setting. The example demonstrates a simple plugin that returns a number value.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_PLUGIN_CPP.mdx#2025-04-20_snippet_0\n\nLANGUAGE: cpp\nCODE:\n```\n// 1. Include headers\n#include \"frameprocessors/FrameHostObject.h\"\n\n// 2. Create C++ func\nauto myPlugin = [=](jsi::Runtime& runtime,\n                    const jsi::Value& thisArg,\n                    const jsi::Value* args,\n                    size_t count) -> jsi::Value {\n  auto frame = args[0].asObject(runtime).asHostObject<FrameHostObject>(runtime);\n  // Unwrap the Frame, then do your Frame Processing here, and return any JSI value as a result.\n  // For example, you can run very efficient OpenCV tasks here.\n  return jsi::Value(42);\n};\n// 3. Wrap C++ func in jsi::Function\nauto jsiFunc = jsi::Function::createFromHostFunction(runtime,\n                                                     jsi::PropNameID::forUtf8(runtime,\n                                                                              \"myCppPlugin\"),\n                                                     1,\n                                                     myPlugin);\n// 4. Add it to global so it can be called from JS\nruntime.global().setProperty(runtime, \"myCppPlugin\", jsiFunc);\n```\n\n----------------------------------------\n\nTITLE: Setting Photo Quality Balance for Speed in React Native Vision Camera\nDESCRIPTION: Shows how to set the photoQualityBalance prop to 'speed' to optimize the photo pipeline for faster photo capture.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PERFORMANCE.mdx#2025-04-20_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\nreturn <Camera {...props} photoQualityBalance=\"speed\" />\n```\n\n----------------------------------------\n\nTITLE: Getting Location Permission Status Imperatively\nDESCRIPTION: TypeScript code to check the current location permission status using the Camera API's imperative method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nconst permissionStatus = Camera.getLocationPermissionStatus()\n```\n\n----------------------------------------\n\nTITLE: Rendering Camera Component with Code Scanner in Class Component\nDESCRIPTION: Example of how to render the Camera component with the codeScanner prop in a class component's render method.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\nrender() {\n  return <Camera {...props} codeScanner={this.codeScanner} />\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Multi-Camera Device using Imperative API in React Native Vision Camera\nDESCRIPTION: This code shows how to select a multi-camera device (Triple-Camera) using the Imperative API. It gets all available devices and then selects a device with the specified physical cameras.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst devices = Camera.getAvailableCameraDevices()\nconst device = getCameraDevice(devices, 'back', {\n  physicalDevices: [\n    'ultra-wide-angle-camera',\n    'wide-angle-camera',\n    'telephoto-camera'\n  ]\n})\n```\n\n----------------------------------------\n\nTITLE: Passing Parameters to Frame Processor Plugins\nDESCRIPTION: Example of passing parameters to a Frame Processor Plugin from JavaScript. The example shows how to provide configuration options to native functions.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const faces = scanFaces(frame, { accuracy: 'fast' })\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Frame Manipulation in Java Frame Processor Plugin\nDESCRIPTION: A Java implementation that creates and returns a new Frame object. This demonstrates how to manipulate frame data and return modified frames to JavaScript.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n@Nullable\n@Override\npublic Object callback(@NonNull Frame frame, @Nullable Map<String, Object> arguments) throws Throwable {\n  Frame resizedFrame = new Frame(/* ... */);\n  return resizedFrame;\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Camera Component Implementation\nDESCRIPTION: Minimal Camera component implementation with only required properties for troubleshooting black screen issues.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera device={device} isActive={true} style={{ width: 500, height: 500 }} />\n```\n\n----------------------------------------\n\nTITLE: Configuring HDR Format with Imperative API\nDESCRIPTION: Uses the Imperative API to select a camera format that supports HDR capture for both photos and videos.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/HDR.mdx#2025-04-20_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = getCameraFormat(device, [\n  { photoHdr: true },\n  { videoHdr: true },\n])\n```\n\n----------------------------------------\n\nTITLE: Using a Return Value from a Frame Processor Plugin in JavaScript\nDESCRIPTION: Example of how to use the return value from a native Frame Processor Plugin in JavaScript code. The plugin returns a string that can be directly used in JavaScript.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_2\n\nLANGUAGE: js\nCODE:\n```\nexport function detectObject(frame: Frame): string {\n  'worklet'\n  const result = detectObject(frame)\n  console.log(result) // <-- \"cat\"\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Exceptions in Java Frame Processor Plugin\nDESCRIPTION: A Java implementation that demonstrates error handling in Frame Processor Plugins. The code throws an exception when the parameters don't match the expected format.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_6\n\nLANGUAGE: java\nCODE:\n```\n@Nullable\n@Override\npublic Object callback(@NonNull Frame frame, @Nullable Map<String, Object> arguments) throws Throwable {\n  if (arguments != null && arguments.get(\"codeType\") instanceof String) {\n    // ...\n  } else {\n    throw new RuntimeException(\"codeType property has to be a string!\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Location Permission Hook in React Native\nDESCRIPTION: TypeScript/React code using the useLocationPermission hook to handle location permissions. This hook provides the current permission status and a function to request permission.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nconst { hasPermission, requestPermission } = useLocationPermission()\n```\n\n----------------------------------------\n\nTITLE: Using Predefined Format Template with Imperative API\nDESCRIPTION: Example of using a predefined format template (Snapchat) with the getCameraFormat function for common camera configurations.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FORMATS.mdx#2025-04-20_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst device = ...\nconst format = getCameraFormat(device, Templates.Snapchat)\n```\n\n----------------------------------------\n\nTITLE: Saving Photos to Camera Roll\nDESCRIPTION: Shows how to save a captured photo to the device's camera roll using react-native-cameraroll.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TAKING_PHOTOS.mdx#2025-04-20_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\nconst file = await camera.current.takePhoto()\nawait CameraRoll.save(`file://${file.path}`, {\n  type: 'photo',\n})\n```\n\n----------------------------------------\n\nTITLE: Custom Camera Device Selection using Hooks API in React Native Vision Camera\nDESCRIPTION: This snippet shows how to implement custom camera device selection using the Hooks API. It uses 'useCameraDevices' to get all devices and then applies a custom filter function to find the best device.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst devices = useCameraDevices()\nconst device = useMemo(() => findBestDevice(devices), [devices])\n```\n\n----------------------------------------\n\nTITLE: Setting Appropriate Frame Rate in React Native Vision Camera\nDESCRIPTION: Demonstrates how to set the fps prop to match the required frame rate and avoid unnecessary processing.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PERFORMANCE.mdx#2025-04-20_snippet_4\n\nLANGUAGE: jsx\nCODE:\n```\nreturn <Camera {...props} fps={30} />\n```\n\n----------------------------------------\n\nTITLE: Drawing Shapes with Skia\nDESCRIPTION: Example demonstrating how to draw a red rectangle in the center of the frame using Skia's drawing APIs.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_SKIA.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst frameProcessor = useSkiaFrameProcessor((frame) => {\n  'worklet'\n  frame.render()\n\n  const centerX = frame.width / 2\n  const centerY = frame.height / 2\n  const rect = Skia.XYWHRect(centerX, centerY, 150, 150)\n  const paint = Skia.Paint()\n  paint.setColor(Skia.Color('red'))\n  frame.drawRect(rect, paint)\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Selecting Camera Format with Video Stabilization in React Native (Imperative API)\nDESCRIPTION: This snippet shows how to select a camera format that supports video stabilization using the Imperative API in React Native Vision Camera.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/STABILIZATION.mdx#2025-04-20_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst format = getCameraFormat(device, [\n  { videoStabilizationMode: 'cinematic-extended' }\n])\n```\n\n----------------------------------------\n\nTITLE: Setting Photo-Optimized Camera Format in React Native VisionCamera\nDESCRIPTION: Example showing how to configure the camera to use a photo-optimized format that will affect the preview resolution on Android.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PREVIEW.mdx#2025-04-20_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\n<Camera\n  {...props}\n  format={bestFormatForPhoto}\n  photo={true} // Preview will be in the photo resolution\n/>\n```\n\n----------------------------------------\n\nTITLE: Disabling Location APIs in Expo Config\nDESCRIPTION: JSON configuration to disable location services in Expo managed projects. Setting enableLocation to false will exclude location-related APIs from the build.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"my app\",\n  \"plugins\": [\n    [\n      \"react-native-vision-camera\",\n      {\n        // ...\n        \"enableLocation\": false\n      }\n    ]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Location Permission to iOS Info.plist\nDESCRIPTION: XML code to add the NSLocationWhenInUseUsageDescription key to the Info.plist file for iOS projects, which is required to access the user's location when the app is in use.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<key>NSLocationWhenInUseUsageDescription</key>\n<string>$(PRODUCT_NAME) needs access to your location.</string>\n```\n\n----------------------------------------\n\nTITLE: Installing a Community Frame Processor Plugin\nDESCRIPTION: Commands for installing a community plugin (vision-camera-image-labeler) for image labeling in Frame Processors.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\nnpm i vision-camera-image-labeler\ncd ios && pod install\n```\n\n----------------------------------------\n\nTITLE: Disabling Frame Processors in Expo Configuration for react-native-vision-camera\nDESCRIPTION: Configures the react-native-vision-camera plugin in an Expo project's configuration file to disable frame processors by setting enableFrameProcessors to false.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"my app\",\n  \"plugins\": [\n    [\n      \"react-native-vision-camera\",\n      {\n        // ...\n        \"enableFrameProcessors\": false\n      }\n    ]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Frame Processor Plugin Package in Java\nDESCRIPTION: Java implementation of a ReactPackage that registers the custom Frame Processor Plugin with the FrameProcessorPluginRegistry using a static initializer block.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport androidx.annotation.NonNull;\nimport com.facebook.react.ReactPackage;\nimport com.facebook.react.bridge.NativeModule;\nimport com.facebook.react.bridge.ReactApplicationContext;\nimport com.facebook.react.uimanager.ViewManager;\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPlugin;\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPluginRegistry;\n\npublic class FaceDetectorFrameProcessorPluginPackage implements ReactPackage {\n  // highlight-start\n  static {\n    FrameProcessorPluginRegistry.addFrameProcessorPlugin(\"detectFaces\", FaceDetectorFrameProcessorPlugin::new);\n  }\n  // highlight-end\n\n  @NonNull\n  @Override\n  public List<NativeModule> createNativeModules(@NonNull ReactApplicationContext reactContext) {\n    return Collections.emptyList();\n  }\n\n  @NonNull\n  @Override\n  public List<ViewManager> createViewManagers(@NonNull ReactApplicationContext reactContext) {\n    return Collections.emptyList();\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Camera Device Selection using Imperative API in React Native Vision Camera\nDESCRIPTION: This code demonstrates custom camera device selection using the Imperative API. It gets all available devices and then applies a custom filter function to find the best device.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst devices = Camera.getAvailableCameraDevices()\nconst device = findBestDevice(devices)\n```\n\n----------------------------------------\n\nTITLE: Configuring Location in Expo Config\nDESCRIPTION: JSON configuration for enabling location services in Expo managed projects. It includes enabling the location feature and setting the permission request text.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"my app\",\n  \"plugins\": [\n    [\n      \"react-native-vision-camera\",\n      {\n        // ...\n        \"enableLocation\": true,\n        \"locationPermissionText\": \"[my app] needs your location.\"\n      }\n    ]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Babel for Worklets Core\nDESCRIPTION: Babel configuration needed to enable the react-native-worklets-core plugin, which is required for Frame Processors.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_2\n\nLANGUAGE: js\nCODE:\n```\nmodule.exports = {\n  plugins: [\n    ['react-native-worklets-core/plugin'],\n  ],\n}\n```\n\n----------------------------------------\n\nTITLE: Listening for Camera Device Changes using Imperative API in React Native Vision Camera\nDESCRIPTION: This code demonstrates how to listen for camera device changes using the Imperative API. It adds a listener that logs device changes and finds an external camera device when the list of devices changes.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/DEVICES.mdx#2025-04-20_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst listener = Camera.addCameraDevicesChangedListener((devices) => {\n  console.log(`Devices changed: ${devices}`)\n  this.usbCamera = devices.find((d) => d.position === \"external\")\n})\n// ...\nlistener.remove()\n```\n\n----------------------------------------\n\nTITLE: Creating Frame Processor Plugin Package in Kotlin\nDESCRIPTION: Kotlin implementation of a ReactPackage that registers the custom Frame Processor Plugin with the FrameProcessorPluginRegistry using a companion object.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_5\n\nLANGUAGE: kotlin\nCODE:\n```\nimport com.facebook.react.ReactPackage\nimport com.facebook.react.bridge.NativeModule\nimport com.facebook.react.bridge.ReactApplicationContext\nimport com.facebook.react.uimanager.ViewManager\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPlugin\nimport com.mrousavy.camera.frameprocessors.FrameProcessorPluginRegistry\n\nclass FaceDetectorFrameProcessorPluginPackage : ReactPackage {\n  // highlight-start\n  companion object {\n    init {\n      FrameProcessorPluginRegistry.addFrameProcessorPlugin(\"detectFaces\") { proxy, options ->\n        FaceDetectorFrameProcessorPlugin(proxy, options)\n      }\n    }\n  }\n  // highlight-end\n\n  override fun createNativeModules(reactContext: ReactApplicationContext): List<NativeModule> {\n    return emptyList()\n  }\n\n  override fun createViewManagers(reactContext: ReactApplicationContext): List<ViewManager<*, *>> {\n    return emptyList()\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Original Module Export for VisionCamera\nDESCRIPTION: Creates a proxy file that re-exports the original Camera component and sortDevices function from the react-native-vision-camera package. This file will be the entry point for imports in the application.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/MOCKING.mdx#2025-04-20_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// vision-camera.js\n\nimport { Camera, sortDevices } from 'react-native-vision-camera'\n\nexport const VisionCamera = Camera\n```\n\n----------------------------------------\n\nTITLE: Requesting Location Permission Imperatively\nDESCRIPTION: TypeScript code to request location permission using the Camera API's imperative method, which returns the new permission status.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nconst newPermissionStatus = await Camera.requestLocationPermission()\n```\n\n----------------------------------------\n\nTITLE: Catching Exceptions from Frame Processor Plugins in JavaScript\nDESCRIPTION: Example of catching and handling exceptions thrown by Frame Processor Plugins in JavaScript code. This demonstrates how native exceptions are propagated to JavaScript.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx#2025-04-20_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  try {\n    const codes = scanCodes(frame, { codeType: 1234 })\n  } catch (e) {\n    console.log(`Error: ${e.message}`)\n  }\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for VisionCamera with Frame Processor Support\nDESCRIPTION: This CMake script sets up the build environment for the VisionCamera native module. It defines the project structure, includes necessary dependencies like ReactAndroid and fbjni, configures source files for compilation, and sets up conditional frame processor support.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/android/CMakeLists.txt#2025-04-20_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nproject(VisionCamera)\ncmake_minimum_required(VERSION 3.9.0)\n\nset(PACKAGE_NAME \"VisionCamera\")\nset(BUILD_DIR ${CMAKE_SOURCE_DIR}/build)\nset(CMAKE_VERBOSE_MAKEFILE ON)\nset(CMAKE_CXX_STANDARD 17)\n\n# Third party libraries (Prefabs)\nfind_package(ReactAndroid REQUIRED CONFIG)\nfind_package(fbjni REQUIRED CONFIG)\nfind_library(LOG_LIB log)\n\n# Enables OpenGL/EGL HardwareBuffer and EGLImageKHR APIs\nadd_definitions(-DEGL_EGLEXT_PROTOTYPES)\nadd_definitions(-DGL_GLEXT_PROTOTYPES)\n\nif (ENABLE_FRAME_PROCESSORS)\n        add_definitions(-DVISION_CAMERA_ENABLE_FRAME_PROCESSORS=true)\nelse()\n        add_definitions(-DVISION_CAMERA_ENABLE_FRAME_PROCESSORS=false)\nendif()\n\n\n# Add react-native-vision-camera sources\nadd_library(\n        ${PACKAGE_NAME}\n        SHARED\n        # Java JNI\n        src/main/cpp/VisionCamera.cpp\n        src/main/cpp/MutableJByteBuffer.cpp\n        # Frame Processor\n        src/main/cpp/frameprocessors/FrameHostObject.cpp\n        src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.cpp\n        src/main/cpp/frameprocessors/JSIJNIConversion.cpp\n        src/main/cpp/frameprocessors/VisionCameraProxy.cpp\n        src/main/cpp/frameprocessors/java-bindings/JSharedArray.cpp\n        src/main/cpp/frameprocessors/java-bindings/JFrame.cpp\n        src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.cpp\n        src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.cpp\n        src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.cpp\n        src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.cpp\n)\n\n# Header Search Paths (includes)\ntarget_include_directories(\n        ${PACKAGE_NAME}\n        PRIVATE\n        \"src/main/cpp\"\n        \"src/main/cpp/frameprocessors\"\n        \"src/main/cpp/frameprocessors/java-bindings\"\n        \"${NODE_MODULES_DIR}/react-native/ReactCommon\"\n        \"${NODE_MODULES_DIR}/react-native/ReactCommon/callinvoker\"\n        \"${NODE_MODULES_DIR}/react-native/ReactAndroid/src/main/jni/react/turbomodule\" # <-- CallInvokerHolder JNI wrapper\n)\n\n# Link everything together\ntarget_link_libraries(\n        ${PACKAGE_NAME}\n        ${LOG_LIB}                          # <-- Logcat logger\n        android                             # <-- Android JNI core\n        ReactAndroid::jsi                   # <-- RN: JSI\n        fbjni::fbjni                        # <-- fbjni\n)\n\n# Link react-native (different prefab between RN 0.75 and RN 0.76)\nif(ReactAndroid_VERSION_MINOR GREATER_EQUAL 76)\n    target_link_libraries(\n        ${PACKAGE_NAME}\n        ReactAndroid::reactnative                 # <-- RN: Native Modules umbrella prefab\n    )\nelse()\n    target_link_libraries(\n        ${PACKAGE_NAME}\n        ReactAndroid::reactnativejni              # <-- RN: JNI Utils (e.g. CallInvoker)\n    )\nendif()\n\n# Optionally also add Frame Processors here\nmessage(\"VisionCamera: Frame Processors: ${ENABLE_FRAME_PROCESSORS}!\")\nif (ENABLE_FRAME_PROCESSORS)\n    message(\"VisionCamera: Linking react-native-worklets...\")\n    find_package(react-native-worklets-core REQUIRED CONFIG)\n    target_link_libraries(\n            ${PACKAGE_NAME}\n            react-native-worklets-core::rnworklets\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Enabling Code Scanner in Expo Configuration\nDESCRIPTION: JSON configuration to enable the code scanner feature in Expo projects by adding the enableCodeScanner flag to the Expo config file.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"my app\",\n  \"plugins\": [\n    [\n      \"react-native-vision-camera\",\n      {\n        // ...\n        \"enableCodeScanner\": true\n      }\n    ]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Camera Plugin Builder CLI for iOS\nDESCRIPTION: Command to run the Vision Camera Plugin Builder CLI for iOS, which automates the plugin creation process by generating the necessary boilerplate code.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_IOS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpx vision-camera-plugin-builder@latest ios\n```\n\n----------------------------------------\n\nTITLE: Registering Frame Processor Plugin Package in MainApplication.java\nDESCRIPTION: Java code for registering a custom Frame Processor Plugin Package in the MainApplication.java file of a React Native project.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n        @Override\n        protected List<ReactPackage> getPackages() {\n          @SuppressWarnings(\"UnnecessaryLocalVariable\")\n          List<ReactPackage> packages = new PackageList(this).getPackages();\n          // ...\n          // highlight-next-line\n          packages.add(new FaceDetectorFrameProcessorPluginPackage()); // <- add\n          return packages;\n        }\n```\n\n----------------------------------------\n\nTITLE: Setting Frame Orientation in MLKit\nDESCRIPTION: Example of handling frame orientation in Swift using MLKit by setting the orientation property on MLImage.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/ORIENTATION.mdx#2025-04-20_snippet_2\n\nLANGUAGE: swift\nCODE:\n```\npublic override func callback(_ frame: Frame, withArguments _: [AnyHashable: Any]?) -> Any? {\n  let mlImage = MLImage(sampleBuffer: frame.buffer)\n  mlImage.orientation = frame.orientation\n  // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Camera Devices Debug Logger\nDESCRIPTION: Code snippet to debug available camera devices by logging their properties to the console.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nconst devices = Camera.getAvailableCameraDevices()\nconsole.log(JSON.stringify(d, null, 2))\n```\n\n----------------------------------------\n\nTITLE: Running Vision Camera Plugin Builder CLI for Android\nDESCRIPTION: Command to run the Vision Camera Plugin Builder CLI tool for automating the setup of Frame Processor Plugins on Android.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_ANDROID.mdx#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpx vision-camera-plugin-builder@latest android\n```\n\n----------------------------------------\n\nTITLE: Handling UPC-A vs EAN-13 Code Types Difference\nDESCRIPTION: Example showing how iOS reports UPC-A codes as EAN-13 type, which requires manual conversion by the developer. This demonstrates platform-specific behavior when scanning barcodes.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/CODE_SCANNING.mdx#2025-04-20_snippet_5\n\nLANGUAGE: jsx\nCODE:\n```\nconst codeScanner = useCodeScanner({\n  codeTypes: ['upc-a'], // <--  We configure for 'upc-a' types\n  onCodeScanned: (codes) => {\n    for (const code of codes) {\n      console.log(code.type); // <--  On iOS, we receive 'ean-13'\n    }\n  }\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring Low Resolution Camera Format in React Native VisionCamera\nDESCRIPTION: Code showing how to define a low resolution camera format that affects both video and preview quality using the useCameraFormat hook.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/PREVIEW.mdx#2025-04-20_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nconst lowResolutionFormat = useCameraFormat(device, [\n  { videoResolution: { width: 640, height: 480 } },\n])\n```\n\n----------------------------------------\n\nTITLE: Installing Skia Dependencies\nDESCRIPTION: Commands to install required dependencies for using Skia Frame Processors including react-native-skia and react-native-reanimated.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_SKIA.mdx#2025-04-20_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @shopify/react-native-skia\nnpm i react-native-reanimated\n```\n\n----------------------------------------\n\nTITLE: Updating Import Statements for Mocked VisionCamera\nDESCRIPTION: Shows how to update import statements in application code to use the mocked VisionCamera component instead of importing directly from the original package.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/MOCKING.mdx#2025-04-20_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// before\nimport { Camera } from 'react-native-vision-camera'\n\n// now\nimport { VisionCamera } from '/your_path_to_created_folder/vision-camera/vision-camera'\n```\n\n----------------------------------------\n\nTITLE: Installing Worklets Core for Frame Processors\nDESCRIPTION: Commands for installing the required react-native-worklets-core dependency which is necessary for Frame Processors to function.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nnpm i react-native-worklets-core\n```\n\n----------------------------------------\n\nTITLE: Camera Lifecycle Events Flow Diagram\nDESCRIPTION: Mermaid diagram showing the sequence of camera lifecycle events including initialization, preview, and start/stop events.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LIFECYCLE.mdx#2025-04-20_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngitGraph LR:\n  branch Camera\n  checkout Camera\n  commit id:\" \"\n\n  branch Preview\n\n  checkout Time\n  commit id:\"  \"\n\n  checkout Camera\n  commit id:\"onInitialized()\"\n\n  checkout Time\n  commit id:\"   \"\n  commit id:\"    \"\n\n  checkout Camera\n  commit id:\"onStarted()\"\n\n  checkout Preview\n  commit id:\"onPreviewStarted()\"\n\n  checkout Time\n  commit id:\"     \"\n  commit id:\"      \"\n  commit id:\"       \"\n  commit id:\"        \"\n\n  checkout Preview\n  commit id:\"onPreviewStopped()\"\n\n  checkout Camera\n  commit id:\"onStopped()\"\n```\n\n----------------------------------------\n\nTITLE: Installing a Frame Processor Plugin with npm\nDESCRIPTION: Basic commands to install a Vision Camera frame processor plugin using npm and CocoaPods. The installation requires running npm install followed by pod install for iOS dependencies.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_PLUGINS_COMMUNITY.mdx#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm i vision-camera-xxxxx\ncd ios && pod install\n```\n\n----------------------------------------\n\nTITLE: Implementing Frame Processor Plugin in Objective-C\nDESCRIPTION: Boilerplate code for creating a Face Detector Frame Processor Plugin in Objective-C. It demonstrates the basic structure including initialization, callback method implementation, and plugin export macros.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_IOS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: objc\nCODE:\n```\n#import <VisionCamera/FrameProcessorPlugin.h>\n#import <VisionCamera/FrameProcessorPluginRegistry.h>\n#import <VisionCamera/Frame.h>\n\n@interface FaceDetectorFrameProcessorPlugin : FrameProcessorPlugin\n@end\n\n@implementation FaceDetectorFrameProcessorPlugin\n\n- (instancetype) initWithProxy:(VisionCameraProxyHolder*)proxy\n                   withOptions:(NSDictionary* _Nullable)options {\n  self = [super initWithProxy:proxy withOptions:options];\n  return self;\n}\n\n- (id)callback:(Frame*)frame withArguments:(NSDictionary*)arguments {\n  CMSampleBufferRef buffer = frame.buffer;\n  UIImageOrientation orientation = frame.orientation;\n  // code goes here\n  return nil;\n}\n\n// highlight-start\nVISION_EXPORT_FRAME_PROCESSOR(FaceDetectorFrameProcessorPlugin, detectFaces)\n// highlight-end\n\n@end\n```\n\n----------------------------------------\n\nTITLE: Disabling Frame Processors in Android Gradle Properties\nDESCRIPTION: Configuration to disable Frame Processors in Android to reduce resource usage and compile time when not using the feature.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_11\n\nLANGUAGE: groovy\nCODE:\n```\nVisionCamera_enableFrameProcessors=false\n```\n\n----------------------------------------\n\nTITLE: iOS Dependencies Cleanup Commands\nDESCRIPTION: Shell commands to clean and rebuild all dependencies for iOS, including removing node_modules, package locks, and pod files.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nrm -rf package-lock.json && rm -rf yarn.lock && rm -rf node_modules\nrm -rf ios/Podfile.lock && rm -rf ios/Pods\nnpm i  # or \"yarn\"\ncd ios && pod repo update && pod update && pod install\n```\n\n----------------------------------------\n\nTITLE: Registering Swift Frame Processor Plugin with Objective-C\nDESCRIPTION: Objective-C code required to register a Swift Frame Processor Plugin. This bridge file exports the Swift plugin to make it accessible from the JavaScript side via the Vision Camera API.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSOR_CREATE_PLUGIN_IOS.mdx#2025-04-20_snippet_3\n\nLANGUAGE: objc\nCODE:\n```\n#import <VisionCamera/FrameProcessorPlugin.h>\n#import <VisionCamera/FrameProcessorPluginRegistry.h>\n\n#import \"YOUR_XCODE_PROJECT_NAME-Swift.h\" // <--- replace \"YOUR_XCODE_PROJECT_NAME\" with the actual value of your xcode project name\n\n// highlight-start\nVISION_EXPORT_SWIFT_FRAME_PROCESSOR(FaceDetectorFrameProcessorPlugin, detectFaces)\n// highlight-end\n```\n\n----------------------------------------\n\nTITLE: Minimal Skia Frame Processor\nDESCRIPTION: Minimal example showing basic frame rendering with a Skia Frame Processor.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_SKIA.mdx#2025-04-20_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst frameProcessor = useSkiaFrameProcessor((frame) => {\n  'worklet'\n  frame.render()\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Running Metro Bundler with Mocking Enabled\nDESCRIPTION: Shows the command-line instructions for starting Metro bundler with the RN_SRC_EXT environment variable set to use the mocked implementation files during development and testing.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/MOCKING.mdx#2025-04-20_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nRN_SRC_EXT=e2e.js react-native start\nRN_SRC_EXT=e2e.js xcodebuild <params>\nRN_SRC_EXT=e2e.js ./gradlew assembleRelease\n```\n\n----------------------------------------\n\nTITLE: iOS CocoaPods Dependencies Configuration\nDESCRIPTION: Shows how to include VisionCamera dependency in a CocoaPods podspec file and include the necessary headers in C++ code for iOS.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_PLUGIN_CPP.mdx#2025-04-20_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\ns.dependency \"VisionCamera\"\n```\n\nLANGUAGE: cpp\nCODE:\n```\n#include \"FrameProcessors/FrameHostObject.h\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Metro Bundler for Module Mocking in React Native\nDESCRIPTION: Modifies the Metro bundler configuration to override React Native modules by extending resolver.sourceExts with the RN_SRC_EXT environment variable. This allows prioritizing custom source extensions over default ones.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/MOCKING.mdx#2025-04-20_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst { getDefaultConfig } = require(\"metro-config\")\nconst { resolver: defaultResolver } = getDefaultConfig.getDefaultValues()\n\nmodule.exports = {\n  ...\n  resolver: {\n    ...defaultResolver,\n    sourceExts: [\n      process.env.RN_SRC_EXT && process.env.RN_SRC_EXT.split(','),\n      ...defaultResolver.sourceExts,\n    ],\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Xcode Tools for iOS Development\nDESCRIPTION: This command installs the Xcode command-line tools, which are necessary for iOS development.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/ios/README.md#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nxcode-select --install\n```\n\n----------------------------------------\n\nTITLE: Adding Location Permission to Android Manifest\nDESCRIPTION: XML code to add the ACCESS_FINE_LOCATION permission to the AndroidManifest.xml file, which is required to access precise location data on Android devices.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<uses-permission android:name=\"android.permission.ACCESS_FINE_LOCATION\" />\n```\n\n----------------------------------------\n\nTITLE: Android Build Cleanup Commands\nDESCRIPTION: Shell commands to clean and rebuild all dependencies for Android, including gradle clean and removing build directories.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n./android/gradlew clean\nrm -rf android/.gradle android/.idea android/app/build android/build\nrm -rf package-lock.json bun.lockb node_modules\nbun install   # or `npm i`\n```\n\n----------------------------------------\n\nTITLE: Installing SwiftFormat and SwiftLint for iOS Development\nDESCRIPTION: This command uses Homebrew to install SwiftFormat and SwiftLint, which are tools for formatting and linting Swift code respectively.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/ios/README.md#2025-04-20_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nbrew install swiftformat swiftlint\n```\n\n----------------------------------------\n\nTITLE: Android CMake Dependencies Configuration\nDESCRIPTION: Shows how to link VisionCamera library in CMakeLists.txt and include the necessary headers in C++ code for Android.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_PLUGIN_CPP.mdx#2025-04-20_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(react-native-vision-camera REQUIRED CONFIG)\n# ...\ntarget_link_libraries(\n  ${PACKAGE_NAME}\n  # ... other libs\n  react-native-vision-camera::VisionCamera\n)\n```\n\nLANGUAGE: cpp\nCODE:\n```\n#include \"frame-processor/FrameHostObject.h\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Location APIs in Podfile\nDESCRIPTION: Ruby code to add a flag in the Podfile that disables location APIs in VisionCamera. This helps avoid Apple rejecting apps that include unused privacy-sensitive APIs.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/LOCATION.mdx#2025-04-20_snippet_7\n\nLANGUAGE: ruby\nCODE:\n```\n$VCEnableLocation = false\n```\n\n----------------------------------------\n\nTITLE: Setting Up Vision Camera Playground Project\nDESCRIPTION: Commands to clone the Vision Camera repository and bootstrap the project. This is the initial setup required before running the playground on iOS or Android devices.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/example/README.md#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngit clone https://github.com/mrousavy/react-native-vision-camera\ncd react-native-vision-camera/package\nbun bootstrap\n```\n\n----------------------------------------\n\nTITLE: Installing ktlint on macOS\nDESCRIPTION: Command to install ktlint code style checker using Homebrew package manager\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/android/README.md#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nbrew install ktlint\n```\n\n----------------------------------------\n\nTITLE: Rendering App Store and Google Play Links in React\nDESCRIPTION: This code snippet shows how to create download links for iOS and Android app stores using React components. It uses inline styling and the useBaseUrl hook to resolve image paths.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/SHADOW_LENS.mdx#2025-04-20_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\n<div style={{ display: 'flex', flexDirection: 'row', alignItems: 'center' }}>\n  <a href=\"https://apps.apple.com/app/shadowlens/id6471849004\">\n    <img height={40} src={useBaseUrl(\"img/appstore.svg\")} />\n  </a>\n  <a href=\"https://play.google.com/store/apps/details?id=com.mrousavy.shadowlens\">\n    <img height={40} src={useBaseUrl(\"img/googleplay.svg\")} />\n  </a>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Using C++ Frame Processor Plugin in JavaScript\nDESCRIPTION: Demonstrates how to use the C++ Frame Processor Plugin in JavaScript code using the useFrameProcessor hook.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_PLUGIN_CPP.mdx#2025-04-20_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const result = global.myCppPlugin(frame)\n  console.log(`C++ result: ${result}`) // <-- 42\n}, [])\n```\n\n----------------------------------------\n\nTITLE: Running Android Code Style Check\nDESCRIPTION: Command to verify and auto-format Kotlin code according to project standards using bun package manager\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/android/README.md#2025-04-20_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun check-android\n```\n\n----------------------------------------\n\nTITLE: Disabling Frame Processors in iOS Podfile for react-native-vision-camera\nDESCRIPTION: Sets the VCEnableFrameProcessors flag to false in the iOS Podfile to disable frame processors in the react-native-vision-camera library.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/FRAME_PROCESSORS.mdx#2025-04-20_snippet_12\n\nLANGUAGE: ruby\nCODE:\n```\n$VCEnableFrameProcessors = false\n```\n\n----------------------------------------\n\nTITLE: Checking iOS Code Quality Before Committing\nDESCRIPTION: This command runs a script to check the iOS code for style violations and automatically fixes formatting issues before committing changes.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/package/ios/README.md#2025-04-20_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn check-ios\n```\n\n----------------------------------------\n\nTITLE: Configuring Web Crawler Access Rules in robots.txt\nDESCRIPTION: Standard robots.txt configuration that allows all web crawlers to access the entire website. It also specifies the website host URL and provides the location of the sitemap for improved crawler indexing.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/static/robots.txt#2025-04-20_snippet_0\n\nLANGUAGE: robots.txt\nCODE:\n```\n# *\nUser-agent: *\nAllow: /\n\n# Host\nHost: https://react-native-vision-camera.com\n\n# Sitemaps\nSitemap: https://react-native-vision-camera.com/sitemap.xml\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun\nDESCRIPTION: Command to install project dependencies using the Bun package manager in the root directory\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/README.md#2025-04-20_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun Package Manager\nDESCRIPTION: Commands to bootstrap the project by installing dependencies using the Bun package manager.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/CONTRIBUTING.md#2025-04-20_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd react-native-vision-camera\ncd package\nbun bootstrap\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server with Bun\nDESCRIPTION: Command to start local development server that enables live preview of changes without server restart\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/README.md#2025-04-20_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nbun start\n```\n\n----------------------------------------\n\nTITLE: Running Code Style Checks\nDESCRIPTION: Example output of running the code style validation command that checks formatting across Swift, Kotlin, C++, and JS/TS code.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/CONTRIBUTING.md#2025-04-20_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bun check-all\n   bun run v1.22.10\n   Formatting Swift code..\n   Linting Swift code..\n   Linting Kotlin code..\n   Linting C++ code..\n   Linting JS/TS code..\n   All done!\n     Done in 8.05s.\n```\n\n----------------------------------------\n\nTITLE: Building Static Website Content\nDESCRIPTION: Command to generate static website content in the build directory for deployment to static hosting services\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/README.md#2025-04-20_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nbun run build\n```\n\n----------------------------------------\n\nTITLE: Setting up Android ADB Port Forwarding\nDESCRIPTION: Command to set up port forwarding for Android Debug Bridge to enable communication with the Metro bundler.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/CONTRIBUTING.md#2025-04-20_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nadb reverse tcp:8081 tcp:8081\n```\n\n----------------------------------------\n\nTITLE: Rendering SVG Image in React\nDESCRIPTION: This code snippet demonstrates how to render an SVG image using React components. It utilizes the useBaseUrl hook to resolve the image path.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/SHADOW_LENS.mdx#2025-04-20_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n<div class=\"image-container\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"283\" height=\"535\">\n    <image href={useBaseUrl(\"img/shadowlens_screenshot.png\")} width=\"283\" height=\"535\" />\n  </svg>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Android Logcat Debug Output\nDESCRIPTION: Example of Android Logcat output showing VisionCamera initialization logs.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_5\n\nLANGUAGE: logcat\nCODE:\n```\n09:03:46 I ReactNativeJS: Running \"App\" with {\"rootTag\":11}\n09:03:47 I VisionCamera: Loading native C++ library...\n09:03:47 I VisionCamera: Installing JSI bindings...\n09:03:47 I VisionCamera: Finished installing JSI bindings!\n```\n\n----------------------------------------\n\nTITLE: Android Gradle Distribution Configuration\nDESCRIPTION: Gradle wrapper properties configuration for Android build.\nSOURCE: https://github.com/mrousavy/react-native-vision-camera/blob/main/docs/docs/guides/TROUBLESHOOTING.mdx#2025-04-20_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.5.1-all.zip\n```"
  }
]