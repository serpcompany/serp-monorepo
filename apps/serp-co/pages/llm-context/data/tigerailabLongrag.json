[
  {
    "owner": "tiger-ai-lab",
    "repo": "longrag",
    "content": "TITLE: Loading LongRAG Corpus Datasets\nDESCRIPTION: Python code to load the pre-processed NQ and HotpotQA corpus datasets from Hugging Face.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\ncorpus_nq = load_dataset(\"TIGER-Lab/LongRAG\", \"nq_corpus\")\ncorpus_hotpotqa = load_dataset(\"TIGER-Lab/LongRAG\", \"hotpot_qa_corpus\")\n```\n\n----------------------------------------\n\nTITLE: Installing LongRAG Dependencies\nDESCRIPTION: Commands for cloning the repository and installing required packages via pip.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/TIGER-AI-Lab/LongRAG.git\ncd LongRAG\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for LongRAG Project\nDESCRIPTION: Lists the required Python packages with their specific versions needed to run the LongRAG project. Includes AI model libraries (Anthropic, OpenAI, Google-GenerativeAI), data management tools (datasets, huggingface-hub), and utility libraries (tiktoken, transformers).\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nanthropic==0.28.1\ndatasets==2.19.1\ngoogle-generativeai==0.5.4\nhuggingface-hub==0.23.0\nopenai==1.14.2\ntiktoken==0.6.0\ntransformers==4.38.1\n```\n\n----------------------------------------\n\nTITLE: Running QA Evaluation\nDESCRIPTION: Script for evaluating question answering using long-context reader models.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p exp/\nsh scripts/run_eval_qa.sh\n```\n\n----------------------------------------\n\nTITLE: Running Tevatron Retrieval\nDESCRIPTION: Script to run dense retrieval using Tevatron toolkit with bge-large-en-v1.5 model.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsh scripts/run_retrieve_tevatron.sh\n```\n\n----------------------------------------\n\nTITLE: Grouping Documents\nDESCRIPTION: Script for grouping related documents into long retrieval units of 4K+ tokens.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsh scripts/group_documents.sh\n```\n\n----------------------------------------\n\nTITLE: Extracting Wikipedia Data\nDESCRIPTION: Bash script for extracting and cleaning Wikipedia dump data using WikiExtractor.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsh scripts/extract_and_clean_wiki_dump.sh\n```\n\n----------------------------------------\n\nTITLE: Processing Wikipedia Pages\nDESCRIPTION: Bash script to process Wikipedia pages and gather metadata information.\nSOURCE: https://github.com/tiger-ai-lab/longrag/blob/main/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsh scripts/process_wiki_page.sh\n```"
  }
]