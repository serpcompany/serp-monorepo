[
  {
    "owner": "assemblyai",
    "repo": "assemblyai-python-sdk",
    "content": "TITLE: Initializing AssemblyAI SDK and setting API key in Python\nDESCRIPTION: Sets the AssemblyAI API key for authentication with the SDK’s services by assigning the API key string to the settings.api_key property. This is required before making any requests with the SDK.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\naai.settings.api_key = f\"{ASSEMBLYAI_API_KEY}\"\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio Files Locally and via URLs with AssemblyAI Python SDK\nDESCRIPTION: Demonstrates how to transcribe audio from a local file path or a URL. The Transcriber class is instantiated, and its transcribe method is called with the audio source path or URL. The resulting transcript object's text property contains the transcription output.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"./my-local-audio-file.wav\")\n\nprint(transcript.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\")\n\nprint(transcript.text)\n```\n\n----------------------------------------\n\nTITLE: Asking Questions about Audio Transcripts using LeMUR with AssemblyAI Python SDK\nDESCRIPTION: Enables querying of transcript content by submitting natural language questions using the lemur.task method with a prompt or the lemur.question method with a list of LemurQuestion objects. Responses include answers aligned to each question, powered by AI models. This facilitates conversational interaction with audio data.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\naudio_file = \"https://assembly.ai/sports_injuries.mp3\"\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(audio_file)\n\nprompt = \"What is a runner's knee?\"\n\nresult = transcript.lemur.task(\n    prompt, final_model=aai.LemurModel.claude3_5_sonnet\n)\n\nprint(result.response)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/customer.mp3\")\n\n# ask some questions\nquestions = [\n    aai.LemurQuestion(question=\"What car was the customer interested in?\"),\n    aai.LemurQuestion(question=\"What price range is the customer looking for?\"),\n]\n\nresult = transcript.lemur.question(\n  final_model=aai.LemurModel.claude3_5_sonnet,\n  questions=questions)\n\nfor q in result.response:\n    print(f\"Question: {q.question}\")\n    print(f\"Answer: {q.answer}\")\n```\n\n----------------------------------------\n\nTITLE: Summarizing Transcript Content Python\nDESCRIPTION: This snippet shows how to generate a summary of the entire transcript. It uses `summarization=True` in `TranscriptionConfig`. The output is a general summary of the provided transcript.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(summarization=True)\n)\n\nprint(transcript.summary)\n```\n\nLANGUAGE: python\nCODE:\n```\nconfig=aai.TranscriptionConfig(\n  summarization=True,\n  summary_model=aai.SummarizationModel.catchy,\n  summary_type=aai.SummarizationType.headline\n)\n```\n\n----------------------------------------\n\nTITLE: Transcribing Binary Audio Data and Uploading Files with AssemblyAI Python SDK\nDESCRIPTION: Shows how to transcribe audio from raw binary data by passing it directly to the transcribe method, or by uploading binary data to obtain a URL for transcription. The upload_file method uploads raw audio data and returns a URL which can then be used to transcribe.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\n\n# Binary data is supported directly:\ntranscript = transcriber.transcribe(data)\n\n# Or: Upload data separately:\nupload_url = transcriber.upload_file(data)\ntranscript = transcriber.transcribe(upload_url)\n```\n\n----------------------------------------\n\nTITLE: Exporting Subtitles from Transcripts in SRT and VTT Formats using Python\nDESCRIPTION: Illustrates how to export subtitle files from a transcript object in two common subtitle formats: SRT and VTT. The export_subtitles_srt and export_subtitles_vtt methods generate subtitle text strings that can be saved or used for captioning videos.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\")\n\n# in SRT format\nprint(transcript.export_subtitles_srt())\n\n# in VTT format\nprint(transcript.export_subtitles_vtt())\n```\n\n----------------------------------------\n\nTITLE: Listing Sentences and Paragraphs from a Transcript using AssemblyAI SDK\nDESCRIPTION: Retrieves all sentences and paragraphs detected in a transcript. The get_sentences and get_paragraphs methods return lists of sentence and paragraph objects respectively, each with a text property. This allows access to subtitle chunks and paragraph-level data from the transcription.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\")\n\nsentences = transcript.get_sentences()\nfor sentence in sentences:\n  print(sentence.text)\n\nparagraphs = transcript.get_paragraphs()\nfor paragraph in paragraphs:\n  print(paragraph.text)\n```\n\n----------------------------------------\n\nTITLE: Performing Word Search on a Transcript using AssemblyAI Python SDK\nDESCRIPTION: Searches for occurrences of specific words within a transcript using the word_search method, which takes a list of target words. It returns match objects indicating the matched word and the count of occurrences, allowing users to find keyword frequency within the transcription text.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\")\n\nmatches = transcript.word_search([\"price\", \"product\"])\n\nfor match in matches:\n  print(f\"Found '{match.text}' {match.count} times in the transcript\")\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Spellings for Words in Transcriptions using AssemblyAI Python SDK\nDESCRIPTION: Configures custom spellings or alternative forms for specific words via TranscriptionConfig’s set_custom_spelling method by passing a dictionary mapping canonical words to list of alternative spellings. This influences transcription output according to custom vocabulary preferences.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\nconfig = aai.TranscriptionConfig()\nconfig.set_custom_spelling(\n  {\n    \"Kubernetes\": [\"k8s\"],\n    \"SQL\": [\"Sequel\"],\n  }\n)\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\", config)\n\nprint(transcript.text)\n```\n\n----------------------------------------\n\nTITLE: Uploading Audio Files to AssemblyAI using the Python SDK\nDESCRIPTION: Uploads raw audio data to AssemblyAI for transcription via the upload_file method of a Transcriber instance. It returns a URL referencing the uploaded file which can be used for subsequent transcription calls.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\nupload_url = transcriber.upload_file(data)\n```\n\n----------------------------------------\n\nTITLE: Deleting a Transcript by ID using AssemblyAI Python SDK\nDESCRIPTION: Deletes a previously created transcript resource by its ID using the static method delete_by_id on the Transcript class. This method removes the transcript from the AssemblyAI service.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscript = aai.Transcriber().transcribe(audio_url)\n\naai.Transcript.delete_by_id(transcript.id)\n```\n\n----------------------------------------\n\nTITLE: Listing and Paginating Transcripts with Filters using AssemblyAI Python SDK\nDESCRIPTION: Lists transcripts associated with the API key, returning transcript pages along with page metadata. Filter parameters like limit and status can be applied to the ListTranscriptParameters passed to list_transcripts. Pagination is supported by extracting before_id from previous page URLs and iterating until no older transcripts remain.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\n\npage = transcriber.list_transcripts()\nprint(page.page_details)  # Page details\nprint(page.transcripts)  # List of transcripts\n```\n\nLANGUAGE: python\nCODE:\n```\nparams = aai.ListTranscriptParameters(\n    limit=3,\n    status=aai.TranscriptStatus.completed,\n)\npage = transcriber.list_transcripts(params)\n```\n\nLANGUAGE: python\nCODE:\n```\ntranscriber = aai.Transcriber()\n\nparams = aai.ListTranscriptParameters()\n\npage = transcriber.list_transcripts(params)\nwhile page.page_details.before_id_of_prev_url is not None:\n    params.before_id = page.page_details.before_id_of_prev_url\n    page = transcriber.list_transcripts(params)\n```\n\n----------------------------------------\n\nTITLE: Summarizing Audio Transcripts using LeMUR AI Models with AssemblyAI Python SDK\nDESCRIPTION: Uses LeMUR's AI capabilities to provide summaries of audio transcripts. Users transcribe audio and then invoke the transcript.lemur.task method with a prompt and specify a final_model for generation. Alternatively, the specialized summarize method can be used with context and answer_format parameters for more structured summary outputs.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\naudio_file = \"https://assembly.ai/sports_injuries.mp3\"\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(audio_file)\n\nprompt = \"Provide a brief summary of the transcript.\"\n\nresult = transcript.lemur.task(\n    prompt, final_model=aai.LemurModel.claude3_5_sonnet\n)\n\nprint(result.response)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\naudio_url = \"https://assembly.ai/meeting.mp4\"\ntranscript = aai.Transcriber().transcribe(audio_url)\n\nresult = transcript.lemur.summarize(\n    final_model=aai.LemurModel.claude3_5_sonnet,\n    context=\"A GitLab meeting to discuss logistics\",\n    answer_format=\"TLDR\"\n)\n\nprint(result.response)\n```\n\n----------------------------------------\n\nTITLE: Performing LeMUR Task Python\nDESCRIPTION: This code snippet demonstrates how to convert speaker labeled utterances into LeMUR input text and use the LeMUR model for analysis. It takes a transcript's utterances, formats them, and then uses the LeMUR task to generate an analysis with feedback. Requires the `assemblyai` library and a valid API key. The expected output is the LeMUR model's response to the provided input text.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Example converting speaker label utterances into LeMUR input text\ntext = \"\"\n\nfor utt in transcript.utterances:\n    text += f\"Speaker {utt.speaker}:\\n{utt.text}\\n\"\n\nresult = aai.Lemur().task(\n  \"You are a helpful coach. Provide an analysis of the transcript \"\n  \"and offer areas to improve with exact quotes. Include no preamble. \"\n  \"Start with an overall summary then get into the examples with feedback.\",\n  input_text=text,\n  final_model=aai.LemurModel.claude3_5_sonnet\n)\n\nprint(result.response)\n```\n\n----------------------------------------\n\nTITLE: Applying LeMUR to Multiple Transcripts Python\nDESCRIPTION: This code snippet showcases using the `transcribe_group` method to transcribe multiple audio files. Then, it applies a LeMUR task for summarization to the transcription group. The `context` parameter provides instructions for the summarization. Requires the `assemblyai` library and a valid API key. The output is the LeMUR summarization response.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript_group = transcriber.transcribe_group(\n    [\n        \"https://example.org/customer1.mp3\",\n        \"https://example.org/customer2.mp3\",\n    ],\n)\n\nresult = transcript_group.lemur.task(\n  context=\"These are calls of customers asking for cars. Summarize all calls and create a TLDR.\",\n  final_model=aai.LemurModel.claude3_5_sonnet\n)\n\nprint(result.response)\n```\n\n----------------------------------------\n\nTITLE: Deleting LeMUR Data Python\nDESCRIPTION: This code snippet demonstrates how to delete data previously sent to LeMUR. It transcribes an audio file, applies a LeMUR task, and then uses the `purge_request_data` method with the `request_id` retrieved from the LeMUR response to delete the associated data.  Requires the `assemblyai` library and a valid API key. The output is the deletion result, indicating the success or failure of the operation.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\n# Create a transcript and a corresponding LeMUR request that may contain senstive information.\ntranscriber = aai.Transcriber()\ntranscript_group = transcriber.transcribe_group(\n  [\n    \"https://example.org/customer1.mp3\",\n  ],\n)\n\nresult = transcript_group.lemur.summarize(\n  context=\"Customers providing sensitive, personally identifiable information\",\n  answer_format=\"TLDR\"\n)\n\n# Get the request ID from the LeMUR response\nrequest_id = result.request_id\n\n# Now we can delete the data about this request\ndeletion_result = aai.Lemur.purge_request_data(request_id)\nprint(deletion_result)\n```\n\n----------------------------------------\n\nTITLE: Redacting PII from Transcript Python\nDESCRIPTION: This snippet shows how to redact Personally Identifiable Information (PII) from a transcript using the `assemblyai` library. It configures a `TranscriptionConfig` object specifying the PII policies to redact (e.g., credit card numbers, email addresses, etc.) and the substitution method (e.g., hash). After transcription, it is possible to redact the audio file with  `redact_pii_audio=True`. The output is the redacted transcript and (optionally) the URL for the redacted audio.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\nconfig = aai.TranscriptionConfig()\nconfig.set_redact_pii(\n  # What should be redacted\n  policies=[\n      aai.PIIRedactionPolicy.credit_card_number,\n      aai.PIIRedactionPolicy.email_address,\n      aai.PIIRedactionPolicy.location,\n      aai.PIIRedactionPolicy.person_name,\n      aai.PIIRedactionPolicy.phone_number,\n  ],\n  # How it should be redacted\n  substitution=aai.PIISubstitutionPolicy.hash,\n)\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\"https://example.org/audio.mp3\", config)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscript = aai.Transcriber().transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(\n    redact_pii=True,\n    redact_pii_policies=[aai.PIIRedactionPolicy.person_name],\n    redact_pii_audio=True\n  )\n)\n\nredacted_audio_url = transcript.get_redacted_audio_url()\ntranscript.save_redacted_audio(\"redacted_audio.mp3\")\n```\n\n----------------------------------------\n\nTITLE: Summarizing Transcript Content Over Time Python\nDESCRIPTION: This snippet demonstrates how to summarize the content of a transcript over time, utilizing auto-chapters to segment the audio. It sets `auto_chapters=True` in the `TranscriptionConfig` object. The output is a series of chapter summaries, each containing the summary, start, end, headline, and gist for the corresponding segment of the transcript.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(auto_chapters=True)\n)\n\nfor chapter in transcript.chapters:\n  print(f\"Summary: {chapter.summary}\")  # A one paragraph summary of the content spoken during this timeframe\n  print(f\"Start: {chapter.start}, End: {chapter.end}\")  # Timestamps (in milliseconds) of the chapter\n  print(f\"Healine: {chapter.headline}\")  # A single sentence summary of the content spoken during this timeframe\n  print(f\"Gist: {chapter.gist}\")  # An ultra-short summary, just a few words, of the content spoken during this timeframe\n```\n\n----------------------------------------\n\nTITLE: Detecting Content Safety in Transcript Python\nDESCRIPTION: This snippet demonstrates how to detect potentially sensitive content in a transcript. It uses `content_safety=True` in the `TranscriptionConfig`. The script iterates through the results, printing flagged text, timestamps, and content safety categories. It also prints the confidence of the model in the most common labels, and the overall severity scores. The output includes text segments and the confidence level from the model.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(content_safety=True)\n)\n\n\n# Get the parts of the transcript which were flagged as sensitive\nfor result in transcript.content_safety.results:\n  print(result.text)  # sensitive text snippet\n  print(result.timestamp.start)\n  print(result.timestamp.end)\n\n  for label in result.labels:\n    print(label.label)  # content safety category\n    print(label.confidence) # model's confidence that the text is in this category\n    print(label.severity) # severity of the text in relation to the category\n\n# Get the confidence of the most common labels in relation to the entire audio file\nfor label, confidence in transcript.content_safety.summary.items():\n  print(f\"{confidence * 100}% confident that the audio contains {label}\")\n\n# Get the overall severity of the most common labels in relation to the entire audio file\nfor label, severity_confidence in transcript.content_safety.severity_score_summary.items():\n  print(f\"{severity_confidence.low * 100}% confident that the audio contains low-severity {label}\")\n  print(f\"{severity_confidence.medium * 100}% confident that the audio contains mid-severity {label}\")\n  print(f\"{severity_confidence.high * 100}% confident that the audio contains high-severity {label}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nconfig=aai.TranscriptionConfig(\n  content_safety=True,\n  content_safety_confidence=80,  # only include labels with a confidence greater than 80%\n)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Sentiment in Transcript Python\nDESCRIPTION: This code snippet shows how to perform sentiment analysis on the transcript. It enables `sentiment_analysis=True` in the `TranscriptionConfig`. The output displays the text, sentiment (POSITIVE, NEUTRAL, or NEGATIVE), confidence, and timestamps for each sentence.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(sentiment_analysis=True)\n)\n\nfor sentiment_result in transcript.sentiment_analysis:\n  print(sentiment_result.text)\n  print(sentiment_result.sentiment)  # POSITIVE, NEUTRAL, or NEGATIVE\n  print(sentiment_result.confidence)\n  print(f\"Timestamp: {sentiment_result.start} - {sentiment_result.end}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nconfig = aai.TranscriptionConfig(sentiment_analysis=True, speaker_labels=True)\n\n# ...\n\nfor sentiment_result in transcript.sentiment_analysis:\n  print(sentiment_result.speaker)\n```\n\n----------------------------------------\n\nTITLE: Identifying Entities in Transcript Python\nDESCRIPTION: This snippet demonstrates the detection of entities within the transcript.  It sets `entity_detection=True` in the `TranscriptionConfig`. It then iterates through the entities found, printing their text, entity type, and timestamps.  The output includes the identified entities and their timestamps.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(entity_detection=True)\n)\n\nfor entity in transcript.entities:\n  print(entity.text) # i.e. \"Dan Gilbert\"\n  print(entity.entity_type) # i.e. EntityType.person\n  print(f\"Timestamp: {entity.start} - {entity.end}\")\n```\n\n----------------------------------------\n\nTITLE: Detecting Topics in Transcript Python\nDESCRIPTION: This code snippet shows how to categorize topics in a transcript using IAB classification. It sets `iab_categories=True` in the `TranscriptionConfig`. The output displays the text, timestamps, and topic labels with their relevance for each segment of the transcript.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(iab_categories=True)\n)\n\n# Get the parts of the transcript that were tagged with topics\nfor result in transcript.iab_categories.results:\n  print(result.text)\n  print(f\"Timestamp: {result.timestamp.start} - {result.timestamp.end}\")\n  for label in result.labels:\n    print(label.label)  # topic\n    print(label.relevance)  # how relevant the label is for the portion of text\n```\n\n----------------------------------------\n\nTITLE: Summarizing Transcript Topics Using AssemblyAI Python SDK\nDESCRIPTION: This snippet demonstrates how to iterate through the IAB category summary of a transcript object to report the relevance percentage of each topic in the audio. It assumes the transcript object has an 'iab_categories.summary' attribute containing topic relevance scores. The output prints each topic label alongside its corresponding audio relevance percentage. There are no explicit dependencies shown beyond having a valid transcribed 'transcript' object. This is useful for content categorization and topic extraction tasks.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfor label, relevance in transcript.iab_categories.summary.items():\n  print(f\"Audio is {relevance * 100}% relevant to {label}\")\n```\n\n----------------------------------------\n\nTITLE: Extracting Important Words and Phrases From Transcript Using AssemblyAI Python SDK\nDESCRIPTION: This snippet shows how to use the AssemblyAI Python SDK's Transcriber to transcribe an audio file with auto highlights enabled. After transcription, it iterates over 'auto_highlights.results' to print each important phrase's text, relevancy rank, occurrence count, and timestamps. The key parameters are 'auto_highlights=True' in the TranscriptionConfig. Inputs include a URL to an audio file and outputs include printed details of key phrases found in the transcript. Requires the 'assemblyai' Python package and internet access to transcribe remote audio.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscriber = aai.Transcriber()\ntranscript = transcriber.transcribe(\n  \"https://example.org/audio.mp3\",\n  config=aai.TranscriptionConfig(auto_highlights=True)\n)\n\nfor result in transcript.auto_highlights.results:\n  print(result.text) # the important phrase\n  print(result.rank) # relevancy of the phrase\n  print(result.count) # number of instances of the phrase\n  for timestamp in result.timestamps:\n    print(f\"Timestamp: {timestamp.start} - {timestamp.end}\")\n```\n\n----------------------------------------\n\nTITLE: Streaming Microphone Audio for Real-Time Transcription Using AssemblyAI Python SDK\nDESCRIPTION: This example demonstrates how to stream microphone input in real-time to AssemblyAI's real-time transcription service. It defines callback functions for session open, receiving data transcripts, errors, and session close. The RealTimeTranscriber object is instantiated with these event handlers, a 44.1 kHz sample rate, and then connected. The microphone audio stream is opened via 'aai.extras.MicrophoneStream()' and streamed to the transcriber. Users can press CTRL+C to stop. This requires hardware microphone support and the AssemblyAI SDK with real-time streaming enabled.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ndef on_open(session_opened: aai.RealtimeSessionOpened):\n  \"This function is called when the connection has been established.\"\n\n  print(\"Session ID:\", session_opened.session_id)\n\ndef on_data(transcript: aai.RealtimeTranscript):\n  \"This function is called when a new transcript has been received.\"\n\n  if not transcript.text:\n    return\n\n  if isinstance(transcript, aai.RealtimeFinalTranscript):\n    print(transcript.text, end=\"\\r\\n\")\n  else:\n    print(transcript.text, end=\"\\r\")\n\ndef on_error(error: aai.RealtimeError):\n  \"This function is called when an error occurs.\"\n\n  print(\"An error occured:\", error)\n\ndef on_close():\n  \"This function is called when the connection has been closed.\"\n\n  print(\"Closing Session\")\n\n\n# Create the Real-Time transcriber\ntranscriber = aai.RealtimeTranscriber(\n  on_data=on_data,\n  on_error=on_error,\n  sample_rate=44_100,\n  on_open=on_open, # optional\n  on_close=on_close, # optional\n)\n\n# Start the connection\ntranscriber.connect()\n\n# Open a microphone stream\nmicrophone_stream = aai.extras.MicrophoneStream()\n\n# Press CTRL+C to abort\ntranscriber.stream(microphone_stream)\n\ntranscriber.close()\n```\n\n----------------------------------------\n\nTITLE: Real-Time Transcription of a Local Audio File Using AssemblyAI Python SDK\nDESCRIPTION: This snippet illustrates performing real-time transcription from a local WAV audio file using AssemblyAI's Python SDK. The 'on_data' callback handles received transcripts printing final and partial transcripts differently. An error handler is also defined. The RealTimeTranscriber is created with 44.1 kHz sample rate, the connection opened, and the audio file streamed with a helper function supporting only WAV/PCM16 mono files. Finally, the transcriber connection is closed. Dependencies include the AssemblyAI SDK and the local audio file path.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\n\ndef on_data(transcript: aai.RealtimeTranscript):\n  \"This function is called when a new transcript has been received.\"\n\n  if not transcript.text:\n    return\n\n  if isinstance(transcript, aai.RealtimeFinalTranscript):\n    print(transcript.text, end=\"\\r\\n\")\n  else:\n    print(transcript.text, end=\"\\r\")\n\ndef on_error(error: aai.RealtimeError):\n  \"This function is called when the connection has been closed.\"\n\n  print(\"An error occured:\", error)\n\n\n# Create the Real-Time transcriber\ntranscriber = aai.RealtimeTranscriber(\n  on_data=on_data,\n  on_error=on_error,\n  sample_rate=44_100,\n)\n\n# Start the connection\ntranscriber.connect()\n\n# Only WAV/PCM16 single channel supported for now\nfile_stream = aai.extras.stream_file(\n  filepath=\"audio.wav\",\n  sample_rate=44_100,\n)\n\ntranscriber.stream(file_stream)\n\ntranscriber.close()\n```\n\n----------------------------------------\n\nTITLE: Configuring and Controlling End-of-Utterance Detection in AssemblyAI Real-Time Transcriber Using Python\nDESCRIPTION: This snippet shows how to manually force the end of an utterance to produce a final transcript immediately, configure the silence threshold in milliseconds for automatic utterance detection on RealTimeTranscriber instantiation, and dynamically update this threshold during runtime. The threshold defines silence duration to detect utterance ends, with valid range between 0 and 20000 ms. The example assumes an existing RealTimeTranscriber instance and demonstrates API usage for enhanced control over real-time transcription segmentation.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ntranscriber = aai.RealtimeTranscriber(...)\n\n# Manually end an utterance and immediately produce a final transcript.\ntranscriber.force_end_utterance()\n\n# Configure the threshold for automatic utterance detection.\ntranscriber = aai.RealtimeTranscriber(\n    ...,\n    end_utterance_silence_threshold=500\n)\n\n# Can be changed any time during a session.\n# The valid range is between 0 and 20000.\ntranscriber.configure_end_utterance_silence_threshold(300)\n```\n\n----------------------------------------\n\nTITLE: Disabling Partial Transcripts in AssemblyAI Real-Time Transcriber Using Python\nDESCRIPTION: This short snippet demonstrates how to disable the emission of partial transcripts during real-time transcription by setting 'disable_partial_transcripts=True' in the RealTimeTranscriber configuration. This affects the streaming behavior so that only final transcripts are returned. It requires using the AssemblyAI Python SDK and the RealTimeTranscriber class.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Set disable_partial_transcripts to `True`\ntranscriber = aai.RealtimeTranscriber(\n    ...,\n    disable_partial_transcripts=True\n)\n```\n\n----------------------------------------\n\nTITLE: Receiving Extra Session Information During Real-Time Transcription Using AssemblyAI Python SDK\nDESCRIPTION: This snippet defines a callback handler function 'on_extra_session_information' that is invoked when extra session-related information is received during real-time transcription. The function prints the audio duration in seconds from the received data. The RealTimeTranscriber is configured with this callback to enable handling additional session data messages. Useful for gathering metadata during streaming transcription sessions.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n# Define a callback to handle the extra session information message\ndef on_extra_session_information(data: aai.RealtimeSessionInformation):\n    \"This function is called when a session information message has been received.\"\n\n    print(data.audio_duration_seconds)\n\n# Configure the RealtimeTranscriber\ntranscriber = aai.RealtimeTranscriber(\n    ...,\n    on_extra_session_information=on_extra_session_information,\n)\n```\n\n----------------------------------------\n\nTITLE: Changing HTTP Timeout and Polling Interval Settings in AssemblyAI Python SDK\nDESCRIPTION: This snippet shows how to customize global SDK settings by modifying the default HTTP timeout for requests and the polling interval for long-running operations using the AssemblyAI Python SDK's 'settings' object. The HTTP timeout is set from 30.0 to 60.0 seconds, and the polling interval from 3.0 to 10.0 seconds. This allows controlling timeout and polling behavior across the SDK client.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\n# The HTTP timeout in seconds for general requests, default is 30.0\naai.settings.http_timeout = 60.0\n\n# The polling interval in seconds for long-running requests, default is 3.0\naai.settings.polling_interval = 10.0\n```\n\n----------------------------------------\n\nTITLE: Setting and Overriding Default Transcription Configuration in AssemblyAI Python SDK\nDESCRIPTION: This collection of snippets explains how to use the Transcriber object's configuration setup. The first snippet sets a default TranscriptionConfig with parameters such as 'punctuate' and 'format_text' disabled, which is then reused across all transcript operations. The second snippet shows overriding the Transcriber's config property after creation. The third snippet demonstrates per-operation override by passing a config instance directly to the transcribe method, allowing different configurations per request. This provides flexible and reusable transcription settings management.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nconfig = aai.TranscriptionConfig(punctuate=False, format_text=False)\n\ntranscriber = aai.Transcriber(config=config)\n\n# will use the same config for all `.transcribe*(...)` operations\ntranscriber.transcribe(\"https://example.org/audio.wav\")\n```\n\nLANGUAGE: python\nCODE:\n```\ntranscriber = aai.Transcriber()\n\n# override the `Transcriber`'s config with a new config\ntranscriber.config = aai.TranscriptionConfig(punctuate=False, format_text=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nconfig = aai.TranscriptionConfig(punctuate=False, format_text=False)\n# set a default configuration\ntranscriber = aai.Transcriber(config=config)\n\ntranscriber.transcribe(\n    \"https://example.com/audio.mp3\",\n    # overrides the above configuration on the `Transcriber` with the following\n    config=aai.TranscriptionConfig(dual_channel=True, disfluencies=True)\n)\n```\n\n----------------------------------------\n\nTITLE: Handling HTTP Status Codes and Errors in the AssemblyAI Python SDK\nDESCRIPTION: This example illustrates two ways to get HTTP status codes after performing transcription requests. One uses a try-except block catching AssemblyAIError exceptions and reading the 'status_code' attribute from the exception object. The other accesses the latest HTTP response through the default client instance's 'last_response' attribute to retrieve the status code and raw response, even if no exception is thrown. This helps with error diagnostics and handling.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_32\n\nLANGUAGE: python\nCODE:\n```\ntranscriber = aai.Transcriber()\n\n# Option 1: Catch the error\ntry:\n    transcript = transcriber.submit(\"./example.mp3\")\nexcept aai.AssemblyAIError as e:\n    print(e.status_code)\n\n# Option 2: Access the latest response through the client\nclient = aai.Client.get_default()\n\ntry:\n    transcript = transcriber.submit(\"./example.mp3\")\nexcept:\n    print(client.last_response)\n    print(client.last_response.status_code)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Existing Transcripts and Transcript Groups Using AssemblyAI Python SDK\nDESCRIPTION: This set of snippets shows how to retrieve previously created transcripts by their ID(s). The first snippet uses 'Transcript.get_by_id' to fetch a single transcript and print its ID and text. The second fetches multiple transcripts by their IDs into a 'TranscriptGroup' object, enabling combined operations such as summarization with LeMUR. Both classes also provide asynchronous variants returning Future objects for non-blocking retrieval. This supports transcript management and batch processing scenarios.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscript = aai.Transcript.get_by_id(\"<TRANSCRIPT_ID>\")\n\nprint(transcript.id)\nprint(transcript.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport assemblyai as aai\n\ntranscript_group = aai.TranscriptGroup.get_by_ids([\"<TRANSCRIPT_ID_1>\", \"<TRANSCRIPT_ID_2>\"])\n\nsummary = transcript_group.lemur.summarize(context=\"Customers asking for cars\", answer_format=\"TLDR\")\n\nprint(summary)\n```\n\n----------------------------------------\n\nTITLE: Installing AssemblyAI Python SDK using pip\nDESCRIPTION: Installs the latest version of the AssemblyAI Python SDK package using the pip package manager. This is a prerequisite step before using the SDK in Python projects.\nSOURCE: https://github.com/assemblyai/assemblyai-python-sdk/blob/master/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U assemblyai\n```"
  }
]