[
  {
    "owner": "skforecast",
    "repo": "skforecast",
    "content": "TITLE: Benchmarking with Backtesting and One-Step-Ahead in Python\nDESCRIPTION: The run_benchmark function evaluates the performance of different forecasting methods. It utilizes optional parameters for search strategies, such as grid search or Bayesian search, and applies backtesting along with one-step-ahead techniques to determine the best model based on specified metrics. The function takes in data, parameters for the forecaster, and configurations for the searches. It expects a DataFrame for data and runs the method accordingly, returning execution times and evaluation metrics.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef run_benchmark(\n    data,\n    forecaster_to_benchmark,\n    search_method = None,\n    lags_grid = None,\n    param_grid = None,\n    search_space = None,\n    end_train = None,\n    end_validation = None,\n    target = None,\n    exog_features = None,\n    steps = None,\n    metric = None\n):\n    \"\"\"\n    Compare results of grid search and bayesian search using backtesting and one-step-ahead.\n    \"\"\"\n    \n    # backtesting\n    forecaster = copy(forecaster_to_benchmark)\n    start  = time()\n    cv = TimeSeriesFold(\n            initial_train_size = len(data.loc[:end_train]),\n            steps              = steps,\n            refit              = False,\n         )\n    if search_method == 'grid_search':\n        results_1 = grid_search_forecaster(\n                        forecaster    = forecaster,\n                        y             = data.loc[:end_validation, target],\n                        exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                        cv            = cv,\n                        param_grid    = param_grid,\n                        lags_grid     = lags_grid,\n                        metric        = metric,\n                        return_best   = False,\n                        n_jobs        = 'auto',\n                        verbose       = False,\n                        show_progress = False\n                    )\n    else:\n        results_1, _ = bayesian_search_forecaster(\n                           forecaster    = forecaster,\n                           y             = data.loc[:end_validation, target],\n                           exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                           cv            = cv,\n                           search_space  = search_space,\n                           metric        = metric,\n                           n_trials      = 15,\n                           random_state  = 123,\n                           return_best   = False,\n                           n_jobs        = 'auto',\n                           verbose       = False,\n                           show_progress = False\n                       )\n\n    end = time()\n    time_1 = end - start\n    best_params = results_1.loc[0, 'params']\n    best_lags = results_1.loc[0, 'lags']\n    forecaster.set_params(best_params)\n    forecaster.set_lags(lags=best_lags)\n    cv = TimeSeriesFold(\n            initial_train_size = len(data.loc[:end_validation]),\n            steps              = steps,\n            refit              = False,\n         )\n    metric_1, _ = backtesting_forecaster(\n                      forecaster    = forecaster,\n                      y             = data.loc[:, target],\n                      exog          = data.loc[:, exog_features] if exog_features else None,\n                      cv            = cv,\n                      metric        = metric,\n                      verbose       = False,\n                      show_progress = False\n                  )\n\n    # One step ahead\n    forecaster = copy(forecaster_to_benchmark)\n    start  = time()\n    cv = OneStepAheadFold(initial_train_size = len(data.loc[:end_train]))\n    if search_method == 'grid_search':\n        results_2 = grid_search_forecaster(\n                        forecaster    = forecaster,\n                        y             = data.loc[:end_validation, target],\n                        exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                        cv            = cv,\n                        param_grid    = param_grid,\n                        lags_grid     = lags_grid,\n                        metric        = metric,\n                        return_best   = False,\n                        verbose       = False,\n                        show_progress = False\n                    )\n    else:\n        results_2, _ = bayesian_search_forecaster(\n                           forecaster    = forecaster,\n                           y             = data.loc[:end_validation, target],\n                           exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                           cv            = cv,\n                           search_space  = search_space,\n                           metric        = metric,\n                           n_trials      = 15,\n                           random_state  = 123,\n                           return_best   = False,\n                           verbose       = False,\n                           show_progress = False\n                       )\n\n    end = time()\n    time_2 = end - start\n    best_params = results_2.loc[0, 'params']\n    best_lags = results_2.loc[0, 'lags']\n    forecaster.set_params(best_params)\n    forecaster.set_lags(lags=best_lags)\n    cv = TimeSeriesFold(\n            initial_train_size = len(data.loc[:end_validation]),\n            steps              = steps,\n            refit              = False,\n         )\n    metric_2, _ = backtesting_forecaster(\n                      forecaster    = forecaster,\n                      y             = data.loc[:, target],\n                      exog          = data.loc[:, exog_features] if exog_features else None,\n                      cv            = cv,\n                      metric        = metric,\n                      verbose       = False,\n                      show_progress = False\n                  )\n\n    print(\"-----------------\")\n    print(\"Benchmark results\")\n    print(\"-----------------\")\n    print('Execution time backtesting   :', time_1)\n    print('Execution time one step ahead:', time_2)\n    print(f\"Same lags   : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n    print(f\"Same params : {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n    print(\"\")\n    print(\"Method: backtesting\")\n    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n    print(f\"    params : {results_1.loc[0, 'params']}\")\n    print(f\"    {metric}: {metric_1.loc[0, metric]}\")\n    print(\"\")\n    print(\"Method: one step ahead\")\n    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n    print(f\"    params : {results_2.loc[0, 'params']}\")\n    print(f\"    {metric}: {metric_2.loc[0, metric]}\")\n    \n    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n```\n\n----------------------------------------\n\nTITLE: Performing Grid Search for Hyperparameter Tuning\nDESCRIPTION: Executes a grid search to find optimal hyperparameters and lags for the forecasting model, testing different combinations of estimators, max depths, and lag structures using cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Grid search hyperparameter and lags\n# ==============================================================================\n# Regressor hyperparameters\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [5, 10, 15]\n}\n\n# Lags used as predictors\nlags_grid = [3, 10, [1, 2, 3, 20]]\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 10,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False,\n     )\n\nresults_grid = grid_search_forecaster(\n                   forecaster  = forecaster,\n                   y           = data,\n                   param_grid  = param_grid,\n                   lags_grid   = lags_grid,\n                   cv          = cv,\n                   metric      = 'mean_squared_error',\n                   return_best = True,\n               )\n```\n\n----------------------------------------\n\nTITLE: Implementing ForecasterRecursive with LGBMRegressor for Electricity Demand Prediction\nDESCRIPTION: Creates a ForecasterRecursive model with LGBMRegressor for electricity demand forecasting. Defines a complex search space for Bayesian optimization with multiple hyperparameters including n_estimators, max_depth, learning rate, and regularization parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# Dataset vic_electricity - ForecasterRecursive\n# ==============================================================================\nend_train = '2013-06-30 23:59:00'\nend_validation = '2013-11-30 23:59:00'\nexog_features = ['Temperature', 'Holiday']\n\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\n\ndef search_space(trial):\n    search_space  = {\n        'n_estimators' : trial.suggest_int('n_estimators', 400, 1200, step=100),\n        'max_depth'    : trial.suggest_int('max_depth', 3, 10, step=1),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n        'gamma'        : trial.suggest_float('gamma', 0, 1),\n        'reg_alpha'    : trial.suggest_float('reg_alpha', 0, 1),\n        'reg_lambda'   : trial.suggest_float('reg_lambda', 0, 1),\n        'lags'         : trial.suggest_categorical('lags', lags_grid)\n    } \n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_electricity,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'Demand',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'electricity',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Saving Grid Search Results to File in skforecast\nDESCRIPTION: Demonstrates how to save hyperparameter tuning results to a file using the output_file parameter. Results are saved in TSV format after each evaluation, allowing for partial result preservation if the process is interrupted.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Save results to file\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10  # Placeholder, the value will be overwritten\n             )\n\n# Lags used as predictors\nlags_grid = [3, 10, [1, 2, 3, 20]]\n\n# Regressor hyperparameters\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [5, 10, 15]\n}\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False\n     )\n\nresults = grid_search_forecaster(\n              forecaster    = forecaster,\n              y             = data.loc[:end_val, 'y'],\n              param_grid    = param_grid,\n              lags_grid     = lags_grid,\n              cv            = cv,\n              metric        = 'mean_squared_error',\n              return_best   = True,\n              n_jobs        = 'auto',\n              verbose       = False,\n              show_progress = True,\n              output_file   = \"results_grid_search.txt\"\n          )\n```\n\n----------------------------------------\n\nTITLE: Multi-Series Forecaster with Exogenous Variables and Window Features\nDESCRIPTION: Create a multi-series forecaster incorporating rolling features and month as an exogenous variable\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor       = LGBMRegressor(random_state=123, verbose=-1),\n    lags            = 24,\n    window_features = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n    encoding        = 'ordinal'\n)\n\nforecaster.fit(\n    series = data_exog_train[['item_1', 'item_2', 'item_3']], \n    exog   = data_exog_train[['month']]\n)\n```\n\n----------------------------------------\n\nTITLE: Splitting Train, Calibration, and Test Data\nDESCRIPTION: The snippet demonstrates how to split data into train, calibration, and test sets based on specific date ranges. It details how indexes are used to separate data and print the number of observations in each subset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Split train-calibration-test\n# ==============================================================================\nexog_features = data.columns.difference(['OT']).tolist()\nend_train = '2017-10-01 23:59:00'\nend_calibration = '2018-04-01 23:59:00'\ndata_train = data.loc[: end_train, :]\ndata_cal   = data.loc[end_train:end_calibration, :]\ndata_test  = data.loc[end_calibration:, :]\n\nprint(f\"Dates train      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\nprint(f\"Dates calibration: {data_cal.index.min()} --- {data_cal.index.max()}  (n={len(data_cal)})\")\nprint(f\"Dates test       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n```\n\n----------------------------------------\n\nTITLE: Adding a Non-Informative Feature in Python\nDESCRIPTION: This code snippet adds a non-informative feature named 'noise' to the dataset. This feature is created by generating random normally distributed values. It serves as an example to illustrate how to force the inclusion of a feature during feature selection, even if it is not relevant to the target variable.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n\"# Add non-informative feature\n# ==============================================================================\ndata['noise'] = np.random.normal(size=len(data))\"\n```\n\n----------------------------------------\n\nTITLE: Grid Search Hyperparameter Tuning with Custom Metric in skforecast\nDESCRIPTION: Performs grid search to optimize hyperparameters and lags using a custom evaluation metric. It initializes a ForecasterRecursive with LGBMRegressor, defines a lags grid and parameter grid, and uses TimeSeriesFold for cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Grid search hyperparameter and lags with custom metric\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10  # Placeholder, the value will be overwritten\n             )\n\n# Lags used as predictors\nlags_grid = [3, 10, [1, 2, 3, 20]]\n\n# Regressor hyperparameters\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [5, 10, 15]\n}\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False,\n     )\n\nresults = grid_search_forecaster(\n              forecaster    = forecaster,\n              y             = data.loc[:end_val, 'y'],\n              cv            = cv,\n              param_grid    = param_grid,\n              lags_grid     = lags_grid,\n              metric        = custom_metric,\n              return_best   = True,\n              n_jobs        = 'auto',\n              verbose       = False,\n              show_progress = True\n          )\n\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a Recursive Multi-step Forecaster\nDESCRIPTION: Initializes a ForecasterRecursive object with LGBMRegressor as the base model, configures it with 15 lags and a rolling mean feature with window size 10, then fits it to the training data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit a recursive multi-step forecaster (ForecasterRecursive)\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 15,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=10)\n             )\n\nforecaster.fit(y=data.loc[:end_train])\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Internal Regressor in Python\nDESCRIPTION: This snippet demonstrates making predictions using the internal regressor within a Forecaster object on an input matrix. It is critical for extracting forecasted values and evaluating model output.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Predict using the internal regressor\n# ============================================================================== \npredictions = forecaster.regressor.predict(X_predict)\npredictions\n```\n\n----------------------------------------\n\nTITLE: Grid Search with Pipeline Regressor\nDESCRIPTION: Performs hyperparameter grid search using a pipeline-based forecaster with multiple lags and cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npipe = Pipeline(steps=[('scaler', StandardScaler()), ('regressor', Ridge())])\nforecaster = ForecasterRecursive(\n    regressor = pipe,\n    lags = 10\n)\n\nparam_grid = {'regressor__alpha': np.logspace(-3, 5, 10)}\nlags_grid = [5, 24, [1, 2, 3, 23, 24]]\n\ncv = TimeSeriesFold(\n    steps=5, initial_train_size=len(data.loc[:'2000-04-01']), refit=False\n)\n\nresults_grid = grid_search_forecaster(\n    forecaster         = forecaster,\n    y                  = data['y'],\n    exog               = data[['exog_1', 'exog_2']],\n    param_grid         = param_grid,\n    lags_grid          = lags_grid,\n    cv                 = cv,\n    metric             = 'mean_absolute_error'\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Bayesian Search Hyperparameters with Optuna - Python\nDESCRIPTION: This snippet initializes a recursive forecaster using a LightGBM regressor and defines the search space for hyperparameters with Optuna, setting up categorical and integer parameters for optimization. It employs the TimeSeriesFold for cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Bayesian search hyperparameters and lags with Optuna\n# ==============================================================================\\nforecaster = ForecasterRecursive(\\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\\n                 lags      = 10  # Placeholder, the value will be overwritten\\n             )\\n\\n# Search space\\ndef search_space(trial):\\n    search_space  = {\\n        'lags'            : trial.suggest_categorical('lags', [3, 5]),\\n        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\\n        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\\n    }\\n    \\n    return search_space\\n\\n# Folds\\ncv = TimeSeriesFold(\\n         steps              = 12,\\n         initial_train_size = len(data.loc[:end_train]),\\n         refit              = False,\\n     )\\n\\nresults, best_trial = bayesian_search_forecaster(\\n                          forecaster            = forecaster,\\n                          y                     = data.loc[:end_val, 'y'],\\n                          search_space          = search_space,\\n                          cv                    = cv,\\n                          metric                = 'mean_absolute_error',\\n                          n_trials              = 10,\\n                          random_state          = 123,\\n                          return_best           = False,\\n                          n_jobs                = 'auto',\\n                          verbose               = False,\\n                          show_progress         = True,\\n                          kwargs_create_study   = {},\\n                          kwargs_study_optimize = {}\\n                      )\\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a Recursive Forecaster with LGBMRegressor\nDESCRIPTION: Initializes a ForecasterRecursive object with a LGBMRegressor as the base model, configuring lags and window features. The code then fits the model to the training data and stores in-sample residuals for later use in prediction intervals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 15,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=10),\n                 transformer_y   = None, \n             )\n\nforecaster.fit(y=data_train, store_in_sample_residuals=True)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Apply Different Transformations to Exogenous Variables Using ColumnTransformer in Python\nDESCRIPTION: This code snippet utilizes ColumnTransformer to apply different transformations like scaling and one-hot encoding to different exogenous variables. The setup ensures that transformations are applied accurately before fitting the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Create and fit forecaster with different transformations for each exog variable\n# ==============================================================================\\ntransformer_exog = ColumnTransformer(\\n                       [('scale_1', StandardScaler(), ['exog_1']),\\n                        ('scale_2', StandardScaler(), ['exog_2']),\\n                        ('onehot', OneHotEncoder(), ['exog_3']),\\n                       ],\\n                       remainder = 'passthrough',\\n                       verbose_feature_names_out = False\\n                   )\\n\\nforecaster = ForecasterRecursive(\\n                 regressor        = Ridge(random_state=123),\\n                 lags             = 3,\\n                 transformer_y    = None,\\n                 transformer_exog = transformer_exog\\n             )\\n\\nforecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2', 'exog_3']])\\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Implementing Grid Search for Hyperparameter Tuning in Skforecast\nDESCRIPTION: Demonstrates how to perform grid search for hyperparameter tuning in Skforecast. Creates a ForecasterRecursive model with LGBMRegressor, defines lags and parameter grids, and uses TimeSeriesFold for validation to find optimal hyperparameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Grid search hyperparameters and lags\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10  # Placeholder, the value will be overwritten\n             )\n\n# Lags used as predictors\nlags_grid = {\n    'lags_1': 3,\n    'lags_2': 10,\n    'lags_3': [1, 2, 3, 20]\n}\n\n# Regressor hyperparameters\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [5, 10, 15]\n}\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False\n     )\n\nresults = grid_search_forecaster(\n              forecaster    = forecaster,\n              y             = data.loc[:end_val, 'y'],\n              param_grid    = param_grid,\n              lags_grid     = lags_grid,\n              cv            = cv,\n              metric        = 'mean_squared_error',\n              return_best   = True,\n              n_jobs        = 'auto',\n              verbose       = False,\n              show_progress = True\n          )\nresults\n```\n\n----------------------------------------\n\nTITLE: Calculating Feature Importance in Python using SKForecast\nDESCRIPTION: Extracts feature importance scores from a forecaster model, handling both StackingRegressor and standard regressor cases. For StackingRegressor, it processes each estimator separately and concatenates results. For other regressors, it directly gets feature importances and calculates absolute values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nif forecaster.regressor.__class__.__name__ == 'StackingRegressor':\n    importancia_pred = []\n    for regressor in forecaster.regressor.estimators_:\n        try:\n            importancia = pd.DataFrame(\n                data = {\n                    'feature': forecaster.regressor.feature_names_in_,\n                    f'importance_{type(regressor).__name__}': regressor.coef_,\n                    f'importance_abs_{type(regressor).__name__}': np.abs(regressor.coef_)\n                }\n            ).set_index('feature')\n        except:\n            importancia = pd.DataFrame(\n                data = {\n                    'feature': forecaster.regressor.feature_names_in_,\n                    f'importance_{type(regressor).__name__}': regressor.feature_importances_,\n                    f'importance_abs_{type(regressor).__name__}': np.abs(regressor.feature_importances_)\n                }\n            ).set_index('feature')\n        importancia_pred.append(importancia)\n    \n    importancia_pred = pd.concat(importancia_pred, axis=1)\n    \nelse:\n    importancia_pred = forecaster.get_feature_importances()\n    importancia_pred['importance_abs'] = importancia_pred['importance'].abs()\n    importancia_pred = importancia_pred.sort_values(by='importance_abs', ascending=False)\n\nimportancia_pred.head(5)\n```\n\n----------------------------------------\n\nTITLE: Bayesian Optimization for Time Series Forecasting\nDESCRIPTION: Implements Bayesian optimization for hyperparameter tuning of a ForecasterRecursive model using LGBMRegressor. Includes custom search space definition and optimization parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\n\ndef search_space(trial):\n    search_space  = {\n        'n_estimators' : trial.suggest_int('n_estimators', 400, 1200, step=100),\n        'max_depth'    : trial.suggest_int('max_depth', 3, 10, step=1),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n        'gamma'        : trial.suggest_float('gamma', 0, 1),\n        'reg_alpha'    : trial.suggest_float('reg_alpha', 0, 1),\n        'reg_lambda'   : trial.suggest_float('reg_lambda', 0, 1),\n        'lags'         : trial.suggest_categorical('lags', lags_grid)\n    }\n\n    return search_space\n```\n\n----------------------------------------\n\nTITLE: Implementing Weighted Multivariate Forecasting\nDESCRIPTION: Demonstrates how to implement custom weights in multivariate forecasting. Includes a custom weight function that assigns weights based on date ranges and configures a forecaster with these weights.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is between '2013-01-01' and '2013-01-31', 1 otherwise.\n    \"\"\"\n    weights = np.where(\n                  (index >= '2013-01-01') & (index <= '2013-01-31'),\n                   0,\n                   1\n              )\n    \n    return weights\n\n\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 level              = 'co',\n                 lags               = 7,\n                 steps              = 7,\n                 transformer_series = StandardScaler(),\n                 weight_func        = custom_weights\n             )\n\nforecaster.fit(series=data_train)\nforecaster.predict(steps=7).head(3)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking LGBMRegressor with ForecasterRecursive on Electricity Demand Data\nDESCRIPTION: Sets up a ForecasterRecursive with LGBMRegressor for electricity demand forecasting. Uses temperature and holiday information as exogenous features, with hyperparameter tuning for n_estimators, max_depth, and learning_rate.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Dataset vic_electricity - ForecasterRecursive\n# ==============================================================================\nend_train = '2013-06-30 23:59:00'\nend_validation = '2013-11-30 23:59:00'\nexog_features = ['Temperature', 'Holiday']\n\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [3, 5],\n    'learning_rate': [0.01, 0.1]\n}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_electricity,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'Demand',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'electricity',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Implementing ForecasterRecursiveMultiSeries with Backtesting and One-Step Ahead Validation\nDESCRIPTION: Sets up a ForecasterRecursiveMultiSeries model, performs Bayesian hyperparameter optimization using both backtesting and one-step-ahead validation approaches, and compares their results. The code includes data preparation, model training, and evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n# Dataset series_dict - ForecasterRecursiveMultiSeries\n# ==============================================================================\nend_train = '2016-05-31 23:59:00'\nend_validation = '2016-07-31 23:59:00'\nlevels = ['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004']\nseries_dict_train = {k: v.loc[: end_train,] for k, v in series_dict.items()}\nexog_dict_train   = {k: v.loc[: end_train,] for k, v in exog_dict.items()}\nseries_dict_test  = {k: v.loc[end_train:,] for k, v in series_dict.items()}\nexog_dict_test    = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n\nforecaster_to_benchmark = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 encoding           = \"ordinal\",\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 series_weights     = None,\n                 differentiation    = None,\n                 dropna_from_series = False,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\n\ndef search_space(trial):\n    search_space  = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n        'max_depth'   : trial.suggest_int('max_depth', 3, 7, step=1),\n        'lags'        : trial.suggest_categorical('lags', [7, 14])\n    } \n    return search_space\n\n\n# Backtesting\nforecaster = copy(forecaster_to_benchmark)\ncv = TimeSeriesFold(\n        initial_train_size = 100,\n        steps              = 24,\n        refit              = False,\n     )\nstart  = time()\nresults_1, _ = bayesian_search_forecaster_multiseries(\n                   forecaster         = forecaster,\n                   series             = {k: v.loc[: end_validation,] for k, v in series_dict.items()},\n                   exog               = {k: v.loc[: end_validation,] for k, v in exog_dict.items()},\n                   cv                 = cv,\n                   search_space       = search_space,\n                   n_trials           = 10,\n                   metric             = metric,\n                   return_best        = False,\n                   n_jobs             = 'auto',\n                   verbose            = False,\n                   show_progress      = False,\n                   suppress_warnings  = True\n               )\nend = time()\ntime_1 = end - start\nbest_params = results_1.loc[0, 'params']\nbest_lags = results_1.loc[0, 'lags']\nforecaster.set_params(best_params)\nforecaster.set_lags(lags=best_lags)\n\ncv = TimeSeriesFold(\n        initial_train_size = 213,\n        steps              = 24,\n        refit              = False,\n     )\nmetric_1, pred_1 = backtesting_forecaster_multiseries(\n                       forecaster         = forecaster,\n                       series             = series_dict,\n                       exog               = exog_dict,\n                       cv                 = cv,\n                       levels             = levels,\n                       metric             = metric,\n                       verbose            = False,\n                       show_progress      = False,\n                       suppress_warnings  = True\n                   )\n\n# One step ahead\nforecaster = copy(forecaster_to_benchmark)\ncv = OneStepAheadFold(initial_train_size = 100)\nstart  = time()\nresults_2, _ = bayesian_search_forecaster_multiseries(\n                   forecaster         = forecaster,\n                   series             = {k: v.loc[: end_validation,] for k, v in series_dict.items()},\n                   exog               = {k: v.loc[: end_validation,] for k, v in exog_dict.items()},\n                   cv                 = cv,\n                   levels             = levels,\n                   search_space       = search_space,\n                   n_trials           = 10,\n                   metric             = metric,\n                   return_best        = False,\n                   verbose            = False,\n                   show_progress      = False,\n                   suppress_warnings  = True\n               )\nend = time()\ntime_2 = end - start\nbest_params = results_2.loc[0, 'params']\nbest_lags = results_2.loc[0, 'lags']\nforecaster.set_params(best_params)\nforecaster.set_lags(lags=best_lags)\n\ncv = TimeSeriesFold(\n        initial_train_size = 213,\n        steps              = 24,\n        refit              = False,\n     )\nmetric_2, pred_2 = backtesting_forecaster_multiseries(\n                       forecaster         = forecaster,\n                       series             = series_dict,\n                       exog               = exog_dict,\n                       cv                 = cv,\n                       levels             = levels,\n                       metric             = metric,\n                       verbose            = False,\n                       show_progress      = False,\n                       suppress_warnings  = True\n                   )\n\nprint(\"Benchmark results\")\nprint(\"-----------------\")\nprint('Execution time backtesting   :', time_1)\nprint('Execution time one step ahead:', time_2)\nprint(f\"Same lags   : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\nprint(f\"Same params : {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\nprint(\"\")\nprint(\"Method: backtesting\")\nprint(f\"    lags   : {results_1.loc[0, 'lags']}\")\nprint(f\"    params : {results_1.loc[0, 'params']}\")\nprint(f\"    {metric_1.loc[0, metric]}\")\nprint(\"\")\nprint(\"Method: one step ahead\")\nprint(f\"    lags   : {results_2.loc[0, 'lags']}\")\nprint(f\"    params : {results_2.loc[0, 'params']}\")\nprint(f\"    {metric_2.loc[0, metric]}\")\n\nresults_bayesian_search.append([\n    'series_dict',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1.loc[0, metric],\n    metric_2.loc[0, metric],\n])\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting a Forecaster with Ridge Regression in Python\nDESCRIPTION: This snippet initializes the ForecasterDirect with specified parameters including the Ridge regressor and the number of forecasting steps. It fits the forecaster to the training data and prepares it for making predictions. The snippet demonstrates how to set up a multi-step forecasting model effectively.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================\nforecaster = ForecasterDirect(\n                 regressor       = Ridge(),\n                 steps           = 36,\n                 lags            = 15,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=10)\n             )\n\nforecaster.fit(y=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Generating Predictions and Prediction Intervals for Multiple Time Series in Python\nDESCRIPTION: Demonstrates how to generate point predictions for a specific time series ('item_1') and prediction intervals for multiple series ('item_1' and 'item_2') using the trained ForecasterRecursiveMultiSeries model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Predictions and prediction intervals\n# ==============================================================================\nsteps = 24\n\n# Predictions for item_1\npredictions_item_1 = forecaster.predict(steps=steps, levels='item_1')\ndisplay(predictions_item_1.head(3))\n\n# Interval predictions for item_1 and item_2\npredictions_intervals = forecaster.predict_interval(\n    steps    = steps,\n    levels   = ['item_1', 'item_2'],\n    method   = \"conformal\",\n    interval = 0.9\n)\ndisplay(predictions_intervals.head(3))\n```\n\n----------------------------------------\n\nTITLE: Bayesian Hyperparameter Search with Optuna\nDESCRIPTION: Perform bayesian optimization for multi-series forecaster using Optuna's trial-based search space\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef search_space(trial):\n    search_space  = {\n        'lags'            : trial.suggest_categorical('lags', [24, 48]),\n        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n    }\n    return search_space\n```\n\n----------------------------------------\n\nTITLE: Performing Random Search for Hyperparameter Tuning in Python\nDESCRIPTION: This code performs a random search to find optimal hyperparameters for the MultiVariate forecaster by specifying estimator ranges and utilizing time series cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nlags_grid = [7, 14]\nparam_distributions = {\n    'n_estimators': np.arange(start=10, stop=20, step=1, dtype=int),\n    'max_depth': np.arange(start=3, stop=6, step=1, dtype=int)\n}\n\ncv = TimeSeriesFold(\n         steps              = 7,\n         initial_train_size = len(data_train),\n         refit              = False,\n     )\n\nresults = random_search_forecaster_multiseries(\n              forecaster          = forecaster,\n              series              = data,\n              lags_grid           = lags_grid,\n              param_distributions = param_distributions,\n              cv                  = cv,\n              metric              = 'mean_absolute_error',\n              aggregate_metric    = 'weighted_average',\n              n_iter              = 5,\n          )\n\nresults\n```\n\n----------------------------------------\n\nTITLE: Comparing Multiple Regression Models with Grid Search in skforecast\nDESCRIPTION: Shows how to compare different regression models (RandomForestRegressor, LGBMRegressor, Ridge) using grid search. It iterates through each model, performs hyperparameter tuning with model-specific parameter grids, and combines results for comparison.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Models to compare\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Ridge\n\nmodels = [\n    RandomForestRegressor(random_state=123), \n    LGBMRegressor(random_state=123, verbose=-1),\n    Ridge(random_state=123)\n]\n\n# Hyperparameter to search for each model\nparam_grids = {\n    'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [5, 15]},\n    'LGBMRegressor': {'n_estimators': [20, 50], 'max_depth': [5, 10]},\n    'Ridge': {'alpha': [0.01, 0.1, 1]}\n}\n\n# Lags used as predictors\nlags_grid = [3, 5]\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 3,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False,\n     )\n\ndf_results = pd.DataFrame()\nfor i, model in enumerate(models):\n\n    print(f\"Grid search for regressor: {model}\")\n    print(\"-------------------------\")\n\n    forecaster = ForecasterRecursive(\n                     regressor = model,\n                     lags      = 3\n                 )\n\n    # Regressor hyperparameters\n    param_grid = param_grids[list(param_grids)[i]]\n\n    results = grid_search_forecaster(\n                  forecaster    = forecaster,\n                  y             = data.loc[:end_val, 'y'],\n                  param_grid    = param_grid,\n                  lags_grid     = lags_grid,\n                  cv            = cv,\n                  metric        = 'mean_squared_error',\n                  return_best   = False,\n                  n_jobs        = 'auto',\n                  verbose       = False,\n                  show_progress = True\n              )\n    \n    # Create a column with model name\n    results['model'] = list(param_grids)[i]\n    \n    df_results = pd.concat([df_results, results])\n\ndf_results = df_results.sort_values(by='mean_squared_error')\ndf_results.head(10)\n```\n\n----------------------------------------\n\nTITLE: Feature Selection with SelectFromModel and SequentialFeatureSelector in Python\nDESCRIPTION: This code snippet demonstrates a two-step feature selection process. First, `SelectFromModel` is used to reduce the number of features by selecting the most important ones. Second, `SequentialFeatureSelector` is used to determine the best subset of features from this reduced set.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (autoregressive and exog) with SelectFromModel + SequentialFeatureSelector\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\n# Step 1: Select the 70% most important features with SelectFromModel\nselector_1 = SelectFromModel(\n                 estimator    = regressor,\n                 max_features = int(data.shape[1] * 0.7),\n                 threshold    = -np.inf\n             )\nselected_lags_1, selected_window_features_1, selected_exog_1 = select_features(\n    forecaster  = forecaster,\n    selector    = selector_1,\n    y           = data[\"users\"],\n    exog        = data.drop(columns=\"users\"),\n    select_only = None,\n    subsample   = 0.2,\n    verbose     = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Examining Forecaster with Best Parameters\nDESCRIPTION: Displays the ForecasterRecursive object after grid search has updated it with the best combination of lags and hyperparameters found during the tuning process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking LGBMRegressor with ForecasterRecursiveMultiSeries on Sales Data\nDESCRIPTION: Sets up a ForecasterRecursiveMultiSeries with LGBMRegressor for multi-series sales forecasting. The forecaster is configured to handle multiple item levels with day_of_week as an exogenous feature, testing different lag configurations and hyperparameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Dataset sales - ForecasterRecursiveMultiSeries\n# ==============================================================================\nend_train = '2014-05-15 23:59:00'\nend_validation = '2014-07-15 23:59:00'\nlevels = ['item_1', 'item_2', 'item_3']\nexog_features = ['day_of_week']\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 encoding           = \"ordinal\",\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 series_weights     = None,\n                 differentiation    = None,\n                 dropna_from_series = False,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nlags_grid = {\n    '24 lags': 24,\n    '48 lags': 48\n}\n\nparam_grid = {\n    'n_estimators': [50, 200],\n    'max_depth': [3, 7]\n}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark_multiseries(\n    data                    = data_sales,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    levels                  = levels,\n    exog_features           = exog_features,\n    steps                   = 36,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'sales',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Exogenous Variables in Skforecast\nDESCRIPTION: Generates 36-step ahead forecasts using the trained model, providing the required exogenous variables from the test dataset for the prediction period.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(\n                  steps = 36,\n                  exog  = data_test[['exog_1', 'exog_2']]\n              )\n\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Configuring Categorical Feature Support in ML Models\nDESCRIPTION: Examples of how to configure different ML models to support categorical features when using ordinal_category encoding.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nHistGradientBoostingRegressor(categorical_features=\"from_dtype\")\n\nXGBRegressor(enable_categorical=True)\n```\n\n----------------------------------------\n\nTITLE: Setting up Transformer for Automatic Detection of Categorical Features in Python\nDESCRIPTION: Creates a more complex pipeline that first applies ordinal encoding to categorical features and then converts them back to 'category' dtype to enable automatic detection by model. This approach allows models to identify categorical features without explicit specification.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Transformer: ordinal encoding and cast to category type\n# ==============================================================================\n# A ColumnTransformer is used to transform categorical (not numerical) features\n# using ordinal encoding. Numeric features are left untouched. Missing values\n# are coded as -1. If a new category is found in the test set, it is encoded\n# as -1. After encoding, the features are converted back to category type so that \n# they can be identified as categorical features by the regressor.\n\npipeline_categorical = make_pipeline(\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           FunctionTransformer(\n                               func=lambda x: x.astype('category'),\n                               feature_names_out= 'one-to-one'\n                           )\n                       )\n\ntransformer_exog = make_column_transformer(\n                       (\n                           pipeline_categorical,\n                           make_column_selector(dtype_exclude=np.number)\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Backtesting the Forecaster for Validation\nDESCRIPTION: Performs backtesting to validate the forecaster using TimeSeriesFold for cross-validation, evaluating model performance on historical data with specified configuration parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Backtesting\n# ==============================================================================\ncv = TimeSeriesFold(\n         steps              = 10,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = True,\n         fixed_train_size   = False\n     )\n\nmetric, predictions_backtest = backtesting_forecaster(\n                                   forecaster    = forecaster,\n                                   y             = data,\n                                   cv            = cv,\n                                   metric        = 'mean_squared_error',\n                                   verbose       = True,\n                               )\n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Search for Hyperparameter Tuning in Skforecast\nDESCRIPTION: Shows how to perform random search for hyperparameter tuning in Skforecast. Creates a ForecasterRecursive model with LGBMRegressor, defines lags grid and parameter distributions, and samples a fixed number of combinations to find optimal parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Random search hyperparameters and lags\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10  # Placeholder, the value will be overwritten\n             )\n\n# Lags used as predictors\nlags_grid = [3, 5]\n\n# Regressor hyperparameters\nparam_distributions = {\n    'n_estimators': np.arange(start=10, stop=100, step=1, dtype=int),\n    'max_depth': np.arange(start=5, stop=30, step=1, dtype=int)\n}\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False,\n     )\n\nresults = random_search_forecaster(\n              forecaster          = forecaster,\n              y                   = data.loc[:end_val, 'y'],\n              lags_grid           = lags_grid,\n              param_distributions = param_distributions,\n              cv                  = cv,\n              n_iter              = 5,\n              metric              = 'mean_squared_error',\n              return_best         = True,\n              random_state        = 123,\n              n_jobs              = 'auto',\n              verbose             = False,\n              show_progress       = True\n          )\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Bayesian Hyperparameter Optimization for Multi-Series Forecaster in Python\nDESCRIPTION: Demonstrates Bayesian optimization for hyperparameter tuning using Optuna with the ForecasterRecursiveMultiSeries model. It defines a search space for optimization and compares results across different input formats (dataframes and dictionaries) to ensure consistency.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Test Bayesian search\n# ==============================================================================\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor=LGBMRegressor(n_estimators=10, random_state=123, verbose=-1),\n    lags=14,\n    encoding=\"ordinal\",\n    dropna_from_series=False,\n    transformer_series=StandardScaler(),\n    transformer_exog=StandardScaler(),\n)\n\nlags_grid = [[5], [1, 7, 14]]\n\n\ndef search_space(trial):\n    search_space = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 2, 5),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n        \"lags\": trial.suggest_categorical(\"lags\", lags_grid),\n    }\n\n    return search_space\n\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"optuna\")\n\n    results_search_1, best_trial_1 = bayesian_search_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog,\n        search_space=search_space,\n        metric=\"mean_absolute_error\",\n        initial_train_size=len(series_train),\n        steps=10,\n        refit=False,\n        n_trials=3,\n        return_best=False,\n        show_progress=False,\n        verbose=False,\n    )\n\n    results_search_2, best_trial_2 = bayesian_search_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog_dict,\n        search_space=search_space,\n        metric=\"mean_absolute_error\",\n        initial_train_size=len(series_train),\n        steps=10,\n        refit=False,\n        n_trials=3,\n        return_best=False,\n        show_progress=False,\n        verbose=False,\n    )\n\n    results_search_3, best_trial_3 = bayesian_search_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series_dict,\n        exog=exog_dict,\n        search_space=search_space,\n        metric=\"mean_absolute_error\",\n        initial_train_size=len(series_train),\n        steps=10,\n        refit=False,\n        n_trials=3,\n        return_best=False,\n        show_progress=False,\n        verbose=False,\n    )\n\npd.testing.assert_frame_equal(results_search_1, results_search_2)\npd.testing.assert_frame_equal(results_search_1, results_search_3)\n```\n\n----------------------------------------\n\nTITLE: Hyperparameter Grid Search for StackingRegressor\nDESCRIPTION: Defines a parameter grid for each regressor within the stacking ensemble, facilitating hyperparameter optimization using grid search techniques. Examines different lags for model predictors to refine the model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Grid search of hyperparameters and lags\n# ==============================================================================param_grid = {\n    'ridge__alpha': [0.1, 1, 10],\n    'lgbm__n_estimators': [100, 500],\n    'lgbm__max_depth': [3, 5, 10],\n    'lgbm__learning_rate': [0.01, 0.1],\n    'final_estimator__alpha': [0.1, 1]\n}\n\n# Lags used as predictors\nlags_grid = [24]\n\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False, \n     )\n\nresults_grid = grid_search_forecaster(\n                   forecaster  = forecaster,\n                   y           = data['consumption'],\n                   exog        = data['month_of_year'],\n                   lags_grid   = lags_grid,\n                   param_grid  = param_grid,\n                   cv          = cv,\n                   metric      = 'mean_squared_error'\n               )\n\nresults_grid.head()\n```\n\n----------------------------------------\n\nTITLE: Predict with Exogenous Variables and Last Window\nDESCRIPTION: This code snippet shows how to use the `predict` method of a trained `ForecasterSarimax` object to generate forecasts while incorporating both exogenous variables and a 'last window' of recent data. The `last_window` and `last_window_exog` parameters provide the model with recent observed values, enabling more accurate predictions when the forecast horizon does not immediately follow the training data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\npredictions = forecaster.predict(\n                  steps            = 12,\n                  exog             = data_test[['exog_1', 'exog_2']],\n                  last_window      = data_last_window['y'],\n                  last_window_exog = data_last_window[['exog_1', 'exog_2']]\n              )\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Bayesian Search for Quantile Forecasters\nDESCRIPTION: Performs Bayesian optimization to find optimal parameters for two quantile forecasters (10th and 90th percentiles) using TimeSeriesFold cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncv = TimeSeriesFold(\n        steps              = 24,\n        initial_train_size = len(data[:end_train]),\n        refit              = False,\n    )\n\nresults_grid_q10 = bayesian_search_forecaster(\n                       forecaster   = forecaster_q10,\n                       y            = data.loc[:end_validation, 'OT'],\n                       cv           = cv,\n                       metric       = create_mean_pinball_loss(alpha=0.1),\n                       search_space = search_space,\n                       n_trials     = 10,\n                       return_best  = True\n                   )\n\nresults_grid_q90 = bayesian_search_forecaster(\n                       forecaster   = forecaster_q90,\n                       y            = data.loc[:end_validation, 'OT'],\n                       cv           = cv,\n                       metric       = create_mean_pinball_loss(alpha=0.9),\n                       search_space = search_space,\n                       n_trials     = 10,\n                       return_best  = True\n                   )\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterRecursive with Exogenous Feature Transformer\nDESCRIPTION: This code creates a ForecasterRecursive object using LGBMRegressor and the previously defined one-hot encoder for exogenous features. It then fits the forecaster on the training data, including both the target variable and exogenous features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster with a transformer for exogenous features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\n\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(random_state=123, verbose=-1),\n                 lags             = 5,\n                 transformer_exog = one_hot_encoder\n             )\n\nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Splitting Data for Training, Last Window, and Testing\nDESCRIPTION: This code snippet demonstrates how to split time series data into training, last window, and testing sets. The last window data is used to update the model with recent information before making predictions. This split allows for simulating real-world forecasting scenarios where recent data is available but retraining the entire model is not feasible.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Split data Train - Last window - Test\n# ==============================================================================\nend_train = '2005-06-01 23:59:59'\nend_last_window = '2007-06-01 23:59:59'\n\nprint(\n    f\"Train dates       : {data.index.min()} --- {data.loc[:end_train].index.max()}  \"\n    f\"(n={len(data.loc[:end_train])})\"\n)\nprint(\n    f\"Last window dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_last_window].index.max()}  \"\n    f\"(n={len(data.loc[end_train:end_last_window])})\"\n)\nprint(\n    f\"Test dates        : {data.loc[end_last_window:].index.min()} --- {data.index.max()}  \"\n    f\"(n={len(data.loc[end_last_window:])})\"\n)\ndata_train       = data.loc[:end_train]\ndata_last_window = data.loc[end_train:end_last_window]\ndata_test        = data.loc[end_last_window:]\n\n# Plot\n# ======================================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train['y'].plot(ax=ax, label='train')\ndata_last_window['y'].plot(ax=ax, label='last window')\ndata_test['y'].plot(ax=ax, label='test')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Data Preparation for Time Series Forecasting in Python\nDESCRIPTION: Demonstrates how to download a dataset, preprocess it for time series analysis, set the datetime index, and split the data into training and testing sets. The code also includes visualization of the train-test split.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n)\n\n# Data preprocessing\n# ==============================================================================\ndata['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\ndata = data.set_index('datetime')\ndata = data.asfreq('MS')\ndata = data['y']\ndata = data.sort_index()\n\n# Split train-test\n# ==============================================================================\nsteps = 36\ndata_train = data[:-steps]\ndata_test  = data[-steps:]\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(6, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Setting up Ordinal Encoding Transformer for LightGBM Categorical Features in Python\nDESCRIPTION: Creates a column transformer that applies ordinal encoding to categorical features while leaving numeric features untouched. The transformer prepares categorical variables for LightGBM by encoding them as integers with missing values coded as -1 and unknown values handled appropriately.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Transformer: ordinal encoding\n# ==============================================================================\n# A ColumnTransformer is used to transform categorical (not numerical) features\n# using ordinal encoding. Numeric features are left untouched. Missing values\n# are coded as -1. If a new category is found in the test set, it is encoded\n# as -1.\ncategorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\ntransformer_exog = make_column_transformer(\n                       (\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           categorical_features\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Predicting Steps with MultiVariate Forecaster Python\nDESCRIPTION: This snippet demonstrates how to predict future values using the MultiVariate forecaster by specifying the number of steps for prediction. The output includes the predictions for the specified steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npredictions = forecaster.predict(steps=[1, 5])\npredictions\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Multi-Series Forecasting Methods in Python\nDESCRIPTION: Function that compares grid search and Bayesian search methods using backtesting and one-step-ahead cross-validation approaches. It evaluates forecaster performance, execution time, and returns metrics for comparison.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef run_benchmark_multiseries(\n    data = None,\n    forecaster_to_benchmark = None,\n    search_method = None,\n    lags_grid = None,\n    param_grid = None,\n    search_space = None,\n    end_train = None,\n    end_validation = None,\n    levels = None,\n    exog_features = None,\n    steps = None,\n    metric = None\n):\n    \"\"\"\n    Compare results of grid search using backtesting and one-step-ahead.\n    \"\"\"\n    \n    # Backtesting\n    forecaster = copy(forecaster_to_benchmark)\n    start  = time()\n    cv = TimeSeriesFold(\n                initial_train_size = len(data.loc[:end_train]),\n                steps              = steps,\n                refit              = False,\n             )\n    if search_method == 'grid_search':\n        results_1 = grid_search_forecaster_multiseries(\n                        forecaster    = forecaster,\n                        series        = data.loc[:end_validation, levels],\n                        levels        = levels,\n                        exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                        cv            = cv,\n                        param_grid    = param_grid,\n                        lags_grid     = lags_grid,\n                        metric        = metric,\n                        return_best   = False,\n                        n_jobs        = 'auto',\n                        verbose       = False,\n                        show_progress = False\n                    )\n    else:\n        results_1, _ = bayesian_search_forecaster_multiseries(\n                           forecaster    = forecaster,\n                           series        = data.loc[:end_validation, levels],\n                           exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                           levels        = levels,\n                           search_space  = search_space,\n                           cv            = cv,\n                           metric        = metric,\n                           n_trials      = 15,\n                           random_state  = 123,\n                           return_best   = False,\n                           n_jobs        = 'auto',\n                           verbose       = False,\n                           show_progress = False\n                       )\n    end = time()\n    time_1 = end - start\n    best_params = results_1.loc[0, 'params']\n    best_lags = results_1.loc[0, 'lags']\n    forecaster.set_params(best_params)\n    forecaster.set_lags(lags=best_lags)\n    cv = TimeSeriesFold(\n            initial_train_size = len(data.loc[:end_validation]),\n            steps              = steps,\n            refit              = False,\n         )\n    metric_1, _ = backtesting_forecaster_multiseries(\n                      forecaster    = forecaster,\n                      series        = data.loc[:, levels],\n                      exog          = data.loc[:, exog_features] if exog_features else None,\n                      cv            = cv,\n                      levels        = levels,\n                      metric        = metric,\n                      verbose       = False,\n                      show_progress = False\n                  )\n\n    # One step ahead\n    forecaster = copy(forecaster_to_benchmark)\n    start  = time()\n    cv = OneStepAheadFold(initial_train_size = len(data.loc[:end_train]))\n    if search_method == 'grid_search':\n        results_2 = grid_search_forecaster_multiseries(\n                        forecaster    = forecaster,\n                        series        = data.loc[:end_validation, levels],\n                        exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                        cv            = cv,\n                        levels        = levels,\n                        param_grid    = param_grid,\n                        lags_grid     = lags_grid,\n                        metric        = metric,\n                        return_best   = False,\n                        verbose       = False,\n                        show_progress = False\n                    )\n    else:\n        results_2, _ = bayesian_search_forecaster_multiseries(\n                           forecaster    = forecaster,\n                           series        = data.loc[:end_validation, levels],\n                           exog          = data.loc[:end_validation, exog_features] if exog_features else None,\n                           cv            = cv,\n                           levels        = levels,\n                           search_space  = search_space,\n                           metric        = metric,\n                           n_trials      = 15,\n                           random_state  = 123,\n                           return_best   = False,\n                           verbose       = False,\n                           show_progress = False\n                       )\n\n    end = time()\n    time_2 = end - start\n    best_params = results_2.loc[0, 'params']\n    best_lags = results_2.loc[0, 'lags']\n    forecaster.set_params(best_params)\n    forecaster.set_lags(lags=best_lags)\n    cv = TimeSeriesFold(\n            initial_train_size = len(data.loc[:end_validation]),\n            steps              = steps,\n            refit              = False,\n         )\n    metric_2, _ = backtesting_forecaster_multiseries(\n                      forecaster    = forecaster,\n                      series        = data.loc[:, levels],\n                      exog          = data.loc[:, exog_features] if exog_features else None,\n                      cv            = cv,\n                      levels        = levels,\n                      metric        = metric,\n                      verbose       = False,\n                      show_progress = False\n                  )\n\n    print(\"Benchmark results\")\n    print(\"-----------------\")\n    print('Execution time backtesting   :', time_1)\n    print('Execution time one step ahead:', time_2)\n    print(f\"Same lags   : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n    print(f\"Same params : {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n    print(\"\")\n    print(\"Method: backtesting\")\n    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n    print(f\"    params : {results_1.loc[0, 'params']}\")\n    print(f\"    {metric_1.loc[0, metric]}\")\n    print(\"\")\n    print(\"Method: one step ahead\")\n    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n    print(f\"    params : {results_2.loc[0, 'params']}\")\n    print(f\"    {metric_2.loc[0, metric]}\")\n    \n    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n```\n\n----------------------------------------\n\nTITLE: Examining Feature Importances for a Forecasting Model\nDESCRIPTION: Retrieves and displays the importance of each feature (lags and window features) used by the forecasting model. This helps to understand which historical time points or derived features have the most influence on the predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nforecaster.get_feature_importances()\n```\n\n----------------------------------------\n\nTITLE: Implement Custom Logarithmic Transformation Function with FunctionTransformer in Python\nDESCRIPTION: This snippet shows how to create custom transformation functions and implement them using Scikit-learn's FunctionTransformer to include in Forecaster setups, exemplified with a logarithmic function to transform the target variable.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Create custom transformer\n# =============================================================================\\ndef log_transform(x):\\n    \"\"\" \\n    Calculate log adding 1 to avoid calculation errors if x is very close to 0.\\n    \"\"\"\\n    return np.log(x + 1)\\n\\ndef exp_transform(x):\\n    \"\"\"\\n    Inverse of log_transform.\\n    \"\"\"\\n    return np.exp(x) - 1\\n\\ntransformer_y = FunctionTransformer(func=log_transform, inverse_func=exp_transform)\\n\\n# Create and train forecaster\n```\n\n----------------------------------------\n\nTITLE: Creating Categorical Feature Transformer Pipeline\nDESCRIPTION: Implements a transformation pipeline that handles categorical features using ordinal encoding and converts them to category type. Includes handling of unknown categories and missing values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_42\n\nLANGUAGE: python\nCODE:\n```\npipeline_categorical = make_pipeline(\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           FunctionTransformer(\n                               func=lambda x: x.astype('category'),\n                               feature_names_out= 'one-to-one'\n                           )\n                       )\n\ntransformer_exog = make_column_transformer(\n                       (\n                           pipeline_categorical,\n                           make_column_selector(dtype_exclude=np.number)\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Weights for Time Series Forecasting in Python\nDESCRIPTION: Defines a custom function to assign weights to time series data based on specific criteria, here used to nullify data influence during a known shutdown period.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Custom function to create weights\n# =================================================\ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is between 2012-06-01 and 2012-10-21.\n    \"\"\"\n    weights = np.where(\n                  (index >= '2012-06-01') & (index <= '2012-10-21'),\n                   0,\n                   1\n              )\n\n    return weights\n```\n\n----------------------------------------\n\nTITLE: Implementing ForecasterRecursiveMultiSeries with LGBMRegressor for Sales Data\nDESCRIPTION: Creates a ForecasterRecursiveMultiSeries model with LGBMRegressor for multi-series sales prediction across multiple items. Uses ordinal encoding for series identifiers and includes day_of_week as an exogenous feature, with Bayesian optimization to tune hyperparameters including lags and model-specific settings.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Dataset sales - ForecasterRecursiveMultiSeries\n# ==============================================================================\nend_train = '2014-05-15 23:59:00'\nend_validation = '2014-07-15 23:59:00'\nlevels = ['item_1', 'item_2', 'item_3']\nexog_features = ['day_of_week']\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 encoding           = \"ordinal\",\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 series_weights     = None,\n                 differentiation    = None,\n                 dropna_from_series = False,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nlags_grid = [48, 72]\n\n\ndef search_space(trial):\n    search_space  = {\n        'n_estimators' : trial.suggest_int('n_estimators', 50, 200),\n        'max_depth'    : trial.suggest_int('max_depth', 3, 10, step=1),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n        'lags'         : trial.suggest_categorical('lags', lags_grid)\n    } \n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark_multiseries(\n    data                    = data_sales,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    levels                  = levels,\n    exog_features           = exog_features,\n    steps                   = 36,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'sales',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Generating Multi-step Predictions with ForecasterDirectMultiVariate\nDESCRIPTION: Generates predictions for all forecast steps (7 days) using the fitted ForecasterDirectMultiVariate model. The steps parameter set to None indicates all steps should be predicted.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Predict with forecaster MultiVariate\n# ==============================================================================\npredictions = forecaster.predict(steps=None)  # All steps\npredictions\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterRecursiveMultiSeries\nDESCRIPTION: This snippet demonstrates how to create and fit a ForecasterRecursiveMultiSeries model using LGBMRegressor with rolling features and ordinal encoding. The model is designed to handle multiple time series simultaneously.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'sum'],\n                      window_sizes = [5, 5]\n                  )\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 5,\n                 window_features = window_features,\n                 encoding        = 'ordinal'\n             )\n\nforecaster.fit(series=data_multiseries)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Configuring Multivariate Forecaster with Transformers\nDESCRIPTION: Initializes a ForecasterDirectMultiVariate with StandardScaler transformers for multiple series. Uses LGBMRegressor as the base model with specific lags and steps configuration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 level              = 'co',\n                 lags               = 7,\n                 steps              = 7,\n                 transformer_series = {'co': StandardScaler(), 'no2': StandardScaler()}\n             )\n\nforecaster.fit(series=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Multivariate Forecasting with Skforecast\nDESCRIPTION: Imports necessary libraries for multivariate time series forecasting, including numpy, matplotlib, sklearn components, LightGBM, and various skforecast modules for preprocessing, modeling, and evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.direct import ForecasterDirectMultiVariate\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster_multiseries\nfrom skforecast.model_selection import grid_search_forecaster_multiseries\nfrom skforecast.model_selection import random_search_forecaster_multiseries\nfrom skforecast.model_selection import bayesian_search_forecaster_multiseries\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Creating LightGBM Forecaster with Automatic Categorical Feature Detection in Python\nDESCRIPTION: Instantiates a ForecasterRecursive with LightGBM regressor that uses automatic detection of categorical features. By setting 'categorical_feature': 'auto', the model will identify and properly handle features with 'category' dtype.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster with automatic detection of categorical features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(random_state=963, verbose=-1),\n                 lags             = 5,\n                 transformer_exog = transformer_exog,\n                 fit_kwargs       = {'categorical_feature': 'auto'}\n             )\n            \nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Preparing Time Series Data for Forecasting\nDESCRIPTION: Downloads and preprocesses H2O dataset for time series forecasting, setting appropriate datetime index and frequency. Splits data into train, validation, and test sets, then visualizes the splits.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n)\n\n# Data preprocessing\n# ==============================================================================\ndata['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\ndata = data.set_index('datetime')\ndata = data.asfreq('MS')\ndata = data[['y']]\ndata = data.sort_index()\n\n# Train-val-test dates\n# ==============================================================================\nend_train = '2001-01-01 23:59:00'\nend_val = '2006-01-01 23:59:00'\n\nprint(\n    f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}\"\n    f\"  (n={len(data.loc[:end_train])})\" \n)\nprint(\n    f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}\"\n    f\"  (n={len(data.loc[end_train:end_val])})\" \n)\nprint(\n    f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}\"\n    f\" (n={len(data.loc[end_val:])})\" \n)\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.loc[:end_train].plot(ax=ax, label='train')\ndata.loc[end_train:end_val].plot(ax=ax, label='validation')\ndata.loc[end_val:].plot(ax=ax, label='test')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Creating Quantile Forecasters in Python for Probabilistic Forecasting\nDESCRIPTION: This snippet defines two separate forecasters using the LightGBM regressor for quantile regression. The forecasters are designed for the 10% and 90% quantiles respectively, which are used to generate an 80% prediction interval. Each forecaster is configured with specific parameters including steps and lags.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create forecasters: one for each bound of the interval\n# ============================================================================== \n# The forecasters obtained for alpha=0.1 and alpha=0.9 produce a 80% confidence\n# interval (90% - 10% = 80%).\n\n# Forecaster for quantile 10%\nforecaster_q10 = ForecasterDirect(\n                     regressor = LGBMRegressor(\n                                     objective = 'quantile',\n                                     metric    = 'quantile',\n                                     alpha     = 0.1,\n                                     verbose   = -1\n                                 ),\n                     steps = 24,\n                     lags  = [1, 2, 3, 23, 24, 25, 47, 48, 49, 71, 72, 73]\n                 )\n                  \n# Forecaster for quantile 90%\nforecaster_q90 = ForecasterDirect(\n                     regressor = LGBMRegressor(\n                                     objective = 'quantile',\n                                     metric    = 'quantile',\n                                     alpha     = 0.9,\n                                     verbose   = -1\n                                 ),\n                     steps = 24,\n                     lags  = [1, 2, 3, 23, 24, 25, 47, 48, 49, 71, 72, 73]\n                 )\n```\n\n----------------------------------------\n\nTITLE: Performing Grid Search with Backtesting for SARIMAX Model Optimization in Python\nDESCRIPTION: This snippet demonstrates how to use grid search with time series cross-validation to find optimal SARIMAX hyperparameters. It sets up a ForecasterSarimax model, defines a parameter grid for order and trend components, and performs grid search using TimeSeriesFold cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# Grid search hyperparameter\n# ======================================================================================\nforecaster = ForecasterSarimax(\n                 regressor=Sarimax(order=(12, 1, 1), maxiter=200)\n             )\n\nparam_grid = {\n    'order': [(12, 0, 0), (12, 1, 0), (12, 1, 1)],\n    'trend': [None, 'n', 'c']\n}\n\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train, 'y']),\n         refit              = False\n     )\n\nresults_grid = grid_search_sarimax(\n                   forecaster            = forecaster,\n                   y                     = data.loc[:end_val, 'y'],\n                   param_grid            = param_grid,\n                   cv                    = cv,\n                   metric                = 'mean_absolute_error',\n                   return_best           = True,\n                   n_jobs                = 'auto',\n                   suppress_warnings_fit = True,\n                   verbose               = False,\n                   show_progress         = True\n               )\n\nresults_grid.head(5)\n```\n\n----------------------------------------\n\nTITLE: CRPS Calculation Using properscoring - Python\nDESCRIPTION: This snippet defines a function that calculates the CRPS for a true value and predicted quantiles utilizing the `crps_quadrature` function from the `properscoring` library. It includes validation for inputs, interpolation for the empirical CDF, and computes the CRPS through numerical integration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef crps_from_quantiles_properscoring(y_true, predicted_quantiles, quantile_levels):\n    \"\"\"\n    Calculate the Continuous Ranked Probability Score (CRPS) for a given true value\n    and predicted quantiles using the function crps_quadrature from the properscoring\n    library.\n\n    Parameters\n    ----------\n    y_true : float\n        The true value of the random variable.\n    predicted_quantiles : np.array\n        The predicted quantile values.\n    quantile_levels : np.array\n        The quantile levels corresponding to the predicted quantiles.\n\n    Returns\n    -------\n    float\n        The CRPS score.\n    \"\"\"\n    if len(predicted_quantiles) != len(quantile_levels):\n        raise ValueError(\n            \"The number of predicted quantiles and quantile levels must be equal.\"\n        )\n    \n    # Ensure predicted_quantiles are sorted\n    sort_idx = np.argsort(predicted_quantiles)\n    predicted_quantiles = predicted_quantiles[sort_idx]\n    quantile_levels = quantile_levels[sort_idx]\n\n    def empirical_cdf(x):\n        # Interpolate between quantile levels and quantile values\n        cdf_func = interp1d(\n            predicted_quantiles,\n            quantile_levels,\n            bounds_error=False,\n            fill_value=(0.0, 1.0),\n        )\n        return cdf_func(x)\n\n    # Integration bounds\n    xmin = np.min(predicted_quantiles) * 0.9\n    xmax = np.max(predicted_quantiles) * 1.1\n\n    # Compute CRPS\n    crps = ps.crps_quadrature(np.array([y_true]), empirical_cdf, xmin, xmax)\n\n    return crps[0]\n\ncrps_from_quantiles_properscoring(y_true, pred_quantiles, quantile_levels)\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterDirect with Skforecast in Python\nDESCRIPTION: This code creates and fits a ForecasterDirect object using a Ridge regressor to account for direct multi-step forecasting. The model is fitted on the target variable to provide direct predictions for multiple future steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================  \nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'sum'],\n                      window_sizes = [5, 5]\n                  )\n\nforecaster = ForecasterDirect(\n                 regressor       = Ridge(random_state=123),\n                 steps           = 3,\n                 lags            = 5,\n                 window_features = window_features\n             )\n\nforecaster.fit(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Creating and Training ForecasterRecursiveMultiSeries\nDESCRIPTION: Initialization and training of a multi-series forecaster using RandomForestRegressor with custom rolling skewness features and weight functions for different items.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nwindow_features = RollingSkewnessMultiSeries(window_sizes=3)\nweight_func_dict = {\n    'item_1': custom_weights_item_1,\n    'item_2': custom_weights_item_2,\n    'item_3': custom_weights_item_3\n}\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor       = RandomForestRegressor(random_state=123),\n                 lags            = 3,\n                 window_features = window_features,\n                 encoding        = 'ordinal',\n                 weight_func     = weight_func_dict\n             )\n\nforecaster.fit(series=data)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Creating ColumnTransformer with One-Hot Encoding for Categorical Features\nDESCRIPTION: This snippet creates a ColumnTransformer that applies one-hot encoding to categorical features while leaving numeric features untouched. It uses OneHotEncoder with specific parameters to handle binary features and sets the output to pandas DataFrame format.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# ColumnTransformer with one-hot encoding\n# ==============================================================================\n# A ColumnTransformer is used to transform categorical features (no numerical)\n# using one-hot encoding. Numeric features are left untouched. For binary\n# features, only one column is created.\none_hot_encoder = make_column_transformer(\n                      (\n                          OneHotEncoder(sparse_output=False, drop='if_binary'),\n                          make_column_selector(dtype_exclude=np.number)\n                      ),\n                      remainder=\"passthrough\",\n                      verbose_feature_names_out=False,\n                  ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Configuring TimeSeriesFold and Performing Backtesting with Conformal Prediction in Python\nDESCRIPTION: Sets up a TimeSeriesFold object for cross-validation and uses backtesting_forecaster to generate forecasts with conformal prediction intervals. The code configures 24-step predictions, uses the mean absolute error metric, and applies adaptive conformal prediction with out-sample residuals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# ==============================================================================\ncv = TimeSeriesFold(\n         steps              = 24, \n         initial_train_size = len(data.loc[:end_calibration]),\n         refit              = False\n     )\n\nmetric, predictions = backtesting_forecaster(\n                          forecaster              = forecaster,\n                          y                       = data['OT'],\n                          exog                    = data[exog_features],\n                          cv                      = cv,\n                          metric                  = 'mean_absolute_error',\n                          interval                = [10, 90],  # 80% prediction interval\n                          interval_method         = 'conformal',\n                          use_in_sample_residuals = False,  # Use out-sample residuals\n                          use_binned_residuals    = True    # Adaptive conformal \n                      )\npredictions.head(5)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Feature Importances from a Specific Predictor in Python\nDESCRIPTION: This snippet showcases how to obtain feature importances for a specific prediction step within the ForecasterDirect. It demonstrates the usage of the get_feature_importances method to help understand the contribution of different features to the forecasting model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nforecaster.get_feature_importances(step=1)\n```\n\n----------------------------------------\n\nTITLE: Grid Search with Multiple Evaluation Metrics in skforecast\nDESCRIPTION: Demonstrates how to use multiple metrics for model evaluation in grid search. The function accepts a list of metrics which can include built-in metrics and custom metrics, with the best model selected based on the first metric in the list.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Grid search hyperparameter and lags with multiple metrics\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10  # Placeholder, the value will be overwritten\n             )\n\n# Lags used as predictors\nlags_grid = [3, 10, [1, 2, 3, 20]]\n\n# Regressor hyperparameters\nparam_grid = {\n    'n_estimators': [50, 100],\n    'max_depth': [5, 10, 15]\n}\n\n# Folds\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False,\n     )\n\nresults = grid_search_forecaster(\n              forecaster    = forecaster,\n              y             = data.loc[:end_val, 'y'],\n              param_grid    = param_grid,\n              lags_grid     = lags_grid,\n              cv            = cv,\n              metric        = ['mean_absolute_error', mean_squared_error, custom_metric],\n              return_best   = True,\n              n_jobs        = 'auto',\n              verbose       = False,\n              show_progress = True\n          )\n\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Backtesting Results\nDESCRIPTION: Creates a plot comparing the test data with backtesting predictions to visually assess model performance across multiple evaluation windows.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Plot backtesting predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(6, 3))\ndata_test.plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Automated Calendar Feature Extraction using Feature-engine in Python\nDESCRIPTION: This snippet demonstrates how to use the DatetimeFeatures transformer from Feature-engine to automatically extract calendar features from the datetime index.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create calendar features with Feature-engine\n# ==============================================================================\nfeatures_to_extract = ['month', 'week', 'day_of_week', 'hour']\ncalendar_transformer = DatetimeFeatures(\n                           variables           = 'index',\n                           features_to_extract = features_to_extract,\n                           drop_original       = True,\n                       )\n\ncalendar_features = calendar_transformer.fit_transform(data)\ncalendar_features.head()\n```\n\n----------------------------------------\n\nTITLE: Calculating Coverage of Prediction Intervals\nDESCRIPTION: This snippet calculates the coverage of the prediction intervals using a function `calculate_coverage`. It passes the true values `y_true` and the lower and upper bounds from the `interval` DataFrame as input. The calculated coverage is then printed to the console, formatted to two decimal places. This function likely checks what percentage of the `y_true` values fall within the `lower_bound` and `upper_bound`.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncoverage = calculate_coverage(\n               y_true      = y_true,\n               lower_bound = interval[\"lower_bound\"],\n               upper_bound = interval[\"upper_bound\"],\n           )\nprint(f'Coverage: {coverage:.2f}')\n```\n\n----------------------------------------\n\nTITLE: Sequential Feature Selection after SelectFromModel in Python\nDESCRIPTION: This code snippet continues the two-step feature selection process, performing Sequential Feature Selection on the features selected by SelectFromModel in the previous step.  It first configures the forecaster with the lags selected by `SelectFromModel`, then applies `SequentialFeatureSelector` to further refine the feature set. The sequential selector uses the exog data selected from the previous step.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n\"# Step 2: Select the 25 most important features with SequentialFeatureSelector\nwindow_features_1 = RollingFeatures(\n                        stats        = ['mean'],\n                        window_sizes = 24\n                    )\nforecaster.set_lags(lags=selected_lags_1)\nforecaster.set_window_features(window_features=window_features_1)\n\nselector_2 = SequentialFeatureSelector(\n                 estimator            = regressor,\n                 n_features_to_select = 25,\n                 direction            = \\\"forward\\\",\n                 cv                   = ShuffleSplit(n_splits=1, test_size=0.3, random_state=951),\n                 scoring              = \\\"neg_mean_absolute_error\\\",\n                 n_jobs               = -1,\n             )\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster  = forecaster,\n    selector    = selector_2,\n    y           = data[\"users\"],\n    exog        = data[selected_exog_1],\n    select_only = None,\n    subsample   = 0.2,\n    verbose     = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Feature Selection with Skforecast\nDESCRIPTION: Imports necessary libraries for feature selection in time series forecasting with Skforecast, including scikit-learn feature selection modules (RFECV, SequentialFeatureSelector, SelectFromModel), LGBMRegressor as the model, and Skforecast's modules for forecasting and feature selection.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import SequentialFeatureSelector\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import ShuffleSplit\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.feature_selection import select_features\nfrom skforecast.feature_selection import select_features_multiseries\n```\n\n----------------------------------------\n\nTITLE: Forecasting with Differentiation - Python\nDESCRIPTION: This final snippet outlines the creation and training of two new forecasters configured to apply differentiation before training. It demonstrates how enabling differentiation improves model predictions by incorporating the TimeSeriesDifferentiator in the forecaster setup.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\n# Forecasting with differentiation\\n# ==============================================================================\\nsteps = len(data.loc[end_train:])\\n\\n# Forecasters\\nforecaster_rf = ForecasterRecursive(\\n                    regressor       = RandomForestRegressor(random_state=963),\\n                    lags            = 12,\\n                    differentiation = 1\\n                )\\nforecaster_gb = ForecasterRecursive(\\n                    regressor       = XGBRegressor(random_state=963),\\n                    lags            = 12,\\n                    differentiation = 1\\n                )\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Average CRPS Across Multiple Steps in Python\nDESCRIPTION: This snippet calculates the average CRPS across all forecast steps using the results from different calculation methods. It provides a summary measure of the model's performance across multiple steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Average CRPS\n# ==============================================================================\nmean_crps = predictions[['crps_from_predictions', 'properscoring', 'CRPS', 'pymc_marqueting']].mean()\nmean_crps\n```\n\n----------------------------------------\n\nTITLE: Creating ForecasterRecursiveMultiSeries\nDESCRIPTION: Initialize a multi-series forecaster with LightGBM regressor and specific configuration parameters\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor = LGBMRegressor(random_state=123, verbose=-1),\n    lags      = 24,\n    encoding  = 'ordinal'\n)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with LightGBM Forecaster in Python\nDESCRIPTION: Demonstrates how to generate predictions using the fitted LightGBM forecaster by specifying the number of steps and providing exogenous variables for the prediction period.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting LightGBM Forecaster\nDESCRIPTION: Initializes a recursive forecaster using LightGBM regressor, configuring lags and rolling window features for time series prediction\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-xgboost-lightgbm.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 8,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=[7]),\n             )\n\nforecaster.fit(y=data_train['y'], exog=data_train[['exog_1', 'exog_2']])\nforecaster\n```\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\nforecaster.predict(steps=10, exog=data_test[['exog_1', 'exog_2']])\n```\n\nLANGUAGE: python\nCODE:\n```\n# Feature importances\n# ==============================================================================\nforecaster.get_feature_importances()\n```\n\n----------------------------------------\n\nTITLE: Predicting with Internal Regressor and Reverting Transformations\nDESCRIPTION: This snippet shows the complete prediction workflow using a forecaster's internal regressor, including creating prediction input, making predictions, reverting differentiation, and applying inverse transformation to get final predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Predict using the internal regressor with transformation\n# ==============================================================================\nX_predict_transformed = forecaster.create_predict_X(steps=5)\n\n# Predict using the internal regressor\npredictions_transformed = forecaster.regressor.predict(X_predict_transformed)\n\n# Revert differentiation (only if differentiation is not None)\npredictions_transformed = forecaster.differentiator.inverse_transform_next_window(predictions_transformed)\n\n# Revert transformation (only if transformer_y is not None)\npredictions = forecaster.transformer_y.inverse_transform(predictions_transformed.reshape(-1, 1))\npredictions.ravel()[:4]\n```\n\n----------------------------------------\n\nTITLE: Transforming Exogenous Features Using Target Encoding in Python\nDESCRIPTION: Demonstrates transforming exogenous features using target encoding, which prepares the features based on their relationship to the target variable. This is particularly beneficial for categorical variables with high cardinality.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# Transform the exogenous features using the transformer outside the forecaster\n# ============================================================================== \nexog_transformed = target_encoder.fit_transform( \n                       X = data.loc[:end_train, exog_features], \n                       y = data.loc[:end_train, 'users']\n                   ) \nexog_transformed.head()\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting a Forecaster\nDESCRIPTION: This snippet initializes a ForecasterRecursive using an LGBMRegressor and prepares it with specific parameters and lag features. It is fitted on training and calibration data for further forecasting tasks.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nparams = {\n    \"max_depth\": 4,\n    \"verbose\": -1,\n    \"random_state\": 15926\n}\nlags = [1, 2, 3, 23, 24, 25, 47, 48, 49, 71, 72, 73]\nwindow_features = RollingFeatures(stats=[\"mean\"], window_sizes=24 * 3)\n\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(**params),\n                 lags            = lags,\n                 window_features = window_features,\n             )\n\nforecaster.fit(\n    y    = data.loc[:end_calibration, 'OT'],\n    exog = data.loc[:end_calibration, exog_features]\n)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Configuring Forecaster with Rolling Features for Time Series Prediction\nDESCRIPTION: Creates a ForecasterRecursive model with LGBMRegressor as the base estimator, configuring it with 48 lags and rolling window features. The model calculates mean and sum statistics over different window sizes (24 and 48 hours) for feature generation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create forecaster\n# ==============================================================================\nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'mean', 'sum'],\n                      window_sizes = [24, 48, 24]\n                  )\n\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(\n                                       n_estimators = 900,\n                                       random_state = 15926,\n                                       max_depth    = 7,\n                                       verbose      = -1\n                                   ),\n                 lags            = 48,\n                 window_features = window_features\n             )\n```\n\n----------------------------------------\n\nTITLE: Visualizing Prediction Intervals for Time Series Forecasts\nDESCRIPTION: Creates a plot showing the prediction intervals along with the actual test data. The shaded area represents the range between the 5th and 95th percentile predictions, illustrating the forecast uncertainty.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Plot prediction interval\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\nplot_prediction_intervals(\n    predictions         = predictions,\n    y_true              = data_test,\n    target_variable     = 'y',\n    title               = \"Prediction intervals\",\n    kwargs_fill_between = {'color': 'gray', 'alpha': 0.3, 'zorder': 1},\n    ax                  = ax\n)\nax.legend(loc='upper left');\n```\n\n----------------------------------------\n\nTITLE: Fit ForecasterRecursiveMultiSeries Model\nDESCRIPTION: This code initializes and fits a `ForecasterRecursiveMultiSeries` model using LightGBM as the regressor. It defines rolling window features, specifies the number of lags, sets the encoding method, and then fits the model to the training data, suppressing warnings during the fitting process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n\"# Fit forecaster\n# ==============================================================================\nregressor = LGBMRegressor(random_state=123, verbose=-1, max_depth=5)\nwindow_features = RollingFeatures(stats=['mean', 'mean'], window_sizes=[7, 14])\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = regressor, \n                 lags               = 14, \n                 window_features    = window_features,\n                 encoding           = \\\"ordinal\\\", \n                 dropna_from_series = False\n             )\n\nforecaster.fit(series=series_dict_train, exog=exog_dict_train, suppress_warnings=True)\nforecaster\"\n```\n\n----------------------------------------\n\nTITLE: Bayesian Hyperparameter Tuning for ForecasterRecursiveMultiSeries using Optuna\nDESCRIPTION: This snippet demonstrates how to perform Bayesian hyperparameter tuning and lags selection for ForecasterRecursiveMultiSeries using Optuna. It defines the search space, sets up the cross-validation strategy, and executes the search process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1), \n                 lags               = 14, \n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[7, 14]),\n                 encoding           = \"ordinal\", \n                 dropna_from_series = False\n             )\n\n# Search space\ndef search_space(trial):\n    search_space  = {\n        'lags'            : trial.suggest_categorical('lags', [7, 14]),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 30),\n        'max_depth'       : trial.suggest_int('max_depth', 3, 7)\n    }\n\n    return search_space\n\ncv = TimeSeriesFold(\n         steps              = 24,\n         initial_train_size = len(series_dict_train[\"id_1000\"]),\n     )\n\nresults, best_trial = bayesian_search_forecaster_multiseries(\n    forecaster        = forecaster,\n    series            = series_dict,\n    exog              = exog_dict,\n    search_space      = search_space,\n    cv                = cv,\n    levels            = None,\n    metric            = 'mean_absolute_error',\n    n_trials          = 10,\n    suppress_warnings = True\n)\n\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Applying Cyclical Encoding to Calendar Features in Python\nDESCRIPTION: This snippet demonstrates how to apply cyclical encoding to calendar features using the CyclicalFeatures transformer from Feature-engine, which helps represent cyclic patterns in time data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Cyclical encoding\n# ==============================================================================\nfeatures_to_encode = [\n    \"month\",\n    \"week\",\n    \"day_of_week\",\n    \"hour\",\n]\nmax_values = {\n    \"month\": 12,\n    \"week\": 52,\n    \"day_of_week\": 7,\n    \"hour\": 24,\n}\ncyclical_encoder = CyclicalFeatures(\n    variables     = features_to_encode,\n    max_values    = max_values,\n    drop_original = True\n)\n\ncyclical_features = cyclical_encoder.fit_transform(calendar_features)\ncyclical_features.head(3)\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices without NaN Values in ForecasterRecursiveMultiSeries\nDESCRIPTION: This snippet creates training matrices using ForecasterRecursiveMultiSeries with dropna_from_series set to True. It shows how NaN values are removed and displays the resulting matrices.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nregressor = LGBMRegressor(random_state=123, verbose=-1, max_depth=5)\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = regressor, \n                 lags               = 3, \n                 encoding           = \"ordinal\", \n                 dropna_from_series = True\n             )\n\nX, y = forecaster.create_train_X_y(series=series_dict_nan)\n\ndisplay(X.head(3))\nprint(\"Observations per series:\")\nprint(X['_level_skforecast'].value_counts())\nprint(\"\")\nprint(\"NaNs per series:\")\nprint(X.isnull().sum())\n```\n\n----------------------------------------\n\nTITLE: Summarizing and Visualizing Benchmark Results\nDESCRIPTION: Calls a function to summarize and visualize the benchmarking results comparing Bayesian search using backtesting versus one-step-ahead approaches. The results are plotted and saved to an image file.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Results\n# ==============================================================================\nsummarize_results(\n    results   = results_bayesian_search,\n    metric    = metric,\n    plot      = True,\n    fig_size  = (8, 6),\n    title     = 'Bayesian search using backtesting vs one-step-ahead',\n    save_plot = \"../img/bayesian_search_benchmarck.png\"\n)\n```\n\n----------------------------------------\n\nTITLE: Skforecast Utility Functions Reference\nDESCRIPTION: A collection of utility functions for data preprocessing, validation, transformation, forecaster management, and multivariate time series operations. These functions handle tasks like saving/loading forecasters, initializing parameters, checking inputs, preprocessing data, and managing optional dependencies.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/utils.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nskforecast.utils.utils.save_forecaster\nskforecast.utils.utils.load_forecaster\nskforecast.utils.utils.initialize_lags\nskforecast.utils.utils.initialize_weights\nskforecast.utils.utils.initialize_transformer_series\nskforecast.utils.utils.check_select_fit_kwargs\nskforecast.utils.utils.check_y\nskforecast.utils.utils.check_exog\nskforecast.utils.utils.get_exog_dtypes\nskforecast.utils.utils.check_exog_dtypes\nskforecast.utils.utils.check_interval\nskforecast.utils.utils.check_predict_input\nskforecast.utils.utils.check_residuals_input\nskforecast.utils.utils.preprocess_y\nskforecast.utils.utils.preprocess_last_window\nskforecast.utils.utils.preprocess_exog\nskforecast.utils.utils.cast_exog_dtypes\nskforecast.utils.utils.exog_to_direct\nskforecast.utils.utils.exog_to_direct_numpy\nskforecast.utils.utils.expand_index\nskforecast.utils.utils.transform_numpy\nskforecast.utils.utils.transform_series\nskforecast.utils.utils.transform_dataframe\nskforecast.utils.utils.check_optional_dependency\nskforecast.utils.utils.multivariate_time_series_corr\nskforecast.utils.utils.select_n_jobs_fit_forecaster\nskforecast.utils.utils.check_preprocess_series\nskforecast.utils.utils.check_preprocess_exog_multiseries\nskforecast.utils.utils.align_series_and_exog_multiseries\nskforecast.utils.utils.prepare_levels_multiseries\nskforecast.utils.utils.preprocess_levels_self_last_window_multiseries\nskforecast.utils.utils.prepare_steps_direct\nskforecast.utils.utils.set_skforecast_warnings\n```\n\n----------------------------------------\n\nTITLE: Creating MultiVariate Forecaster in Python\nDESCRIPTION: This snippet shows how to create a MultiVariate forecaster using the LightGBM regressor and specifies features such as steps, lags, and window features for training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 level              = 'co',\n                 steps              = 7,\n                 lags               = 7,\n                 window_features    = RollingFeatures(stats=['mean'], window_sizes=[7])\n             )\n```\n\n----------------------------------------\n\nTITLE: Backtesting to Obtain Out-Sample Residuals\nDESCRIPTION: Utilizes TimeSeriesFold for cross-validation and backtesting_forecaster to assess the model's performance on calibration data. Results in the calculation of out-sample residuals for further use in prediction interval calibration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Backtesting on calibration data to obtain out-sample residuals\n# ==============================================================================\ncv = TimeSeriesFold(\n         steps              = 24, \n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False\n     )\n\n_, predictions_cal = backtesting_forecaster(\n                         forecaster    = forecaster,\n                         y             = data.loc[:end_calibration, 'OT'],\n                         exog          = data.loc[:end_calibration, exog_features],\n                         cv            = cv,\n                         metric        = 'mean_absolute_error',\n                         n_jobs        = 'auto',\n                         verbose       = False,\n                         show_progress = True\n                     )\n```\n\n----------------------------------------\n\nTITLE: Multi-Series Forecasting with Different Transformers\nDESCRIPTION: Creates a ForecasterRecursiveMultiSeries with different transformers for each series using a dictionary configuration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n    lags               = 24,\n    encoding           = 'ordinal',\n    transformer_series = {'item_1': StandardScaler(), 'item_2': MinMaxScaler(), '_unknown_level': StandardScaler()},\n    transformer_exog   = None\n)\n\nforecaster.fit(series=data)\n```\n\n----------------------------------------\n\nTITLE: Backtesting the Forecasting Model on Test Data\nDESCRIPTION: Performs backtesting of the forecasting model using specified cross-validation parameters and evaluation metric (mean squared error) to assess predictive performance on unseen data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n# Backtesting on test data\n# ==============================================================================cv = TimeSeriesFold(\n         steps              = 12,  # Forecast horizon\n         initial_train_size = len(data.loc[:end_validation]),\n         refit              = False, \n     )\n\nmetric, predictions = backtesting_forecaster(\n                          forecaster = forecaster,\n                          y          = data['consumption'],\n                          exog       = data['month_of_year'],\n                          cv         = cv,\n                          metric     = 'mean_squared_error',\n                          n_jobs     = 'auto',\n                          verbose    = False\n                      )        \n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Fetching and Preparing Time Series Data in Python\nDESCRIPTION: This snippet fetches a dataset using the fetch_dataset function and processes it by converting datetime strings to datetime objects, setting the datetime as the index, and splitting the data into training and testing datasets. The output is a processed time series ready for forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================\ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n)\n\n# Data preprocessing\n# ==============================\ndata['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\ndata = data.set_index('datetime')\ndata = data.asfreq('MS')\ndata = data['y']\ndata = data.sort_index()\n\n# Split train-test\n# ==============================\nsteps = 36\ndata_train = data[:-steps]\ndata_test  = data[-steps:]\n\n# Plot\n# ==============================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(6, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Visualizing Air Quality Time Series Data\nDESCRIPTION: Creates a multi-panel plot showing the first three air quality metrics in the dataset, with separate colors for training and test data to visualize the temporal patterns.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Plot time series\n# ==============================================================================\nset_dark_theme()\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 5), sharex=True)\nfor i, col in enumerate(data.columns[:3]):\n    data_train[col].plot(ax=axes[i], label='train')\n    data_test[col].plot(ax=axes[i], label='test')\n    axes[i].set_ylabel('Concentration(ug/m^3)', fontsize=8)\n    axes[i].set_title(col)\n    axes[i].legend(loc='upper right')\n\nfig.tight_layout()\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterDirectMultiVariate with LGBMRegressor\nDESCRIPTION: Sets up a ForecasterDirectMultiVariate model with LGBMRegressor, defines a Bayesian search space, and runs a benchmark on sales data. Results from the benchmark are stored for later comparison.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# ==============================================================================\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 steps              = 5,\n                 level              = 'item_1',\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nlags_grid = [48, 72]\n\n\ndef search_space(trial):\n    search_space  = {\n        'n_estimators' : trial.suggest_int('n_estimators', 50, 200),\n        'max_depth'    : trial.suggest_int('max_depth', 3, 10, step=1),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n        'lags'         : trial.suggest_categorical('lags', lags_grid)\n    }\n\n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark_multiseries(\n    data                    = data_sales,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    levels                  = levels,\n    exog_features           = exog_features,\n    steps                   = 5,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'sales',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Initializing Multi-Series Forecaster with LGBMRegressor\nDESCRIPTION: Creates a ForecasterRecursiveMultiSeries instance with an LGBMRegressor as the base model. The forecaster uses 24 lags and rolling mean features with different window sizes (24, 48, and 72).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Create forecaster\n# ==============================================================================\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor       = LGBMRegressor(n_estimators=900, random_state=159, max_depth=7, verbose=-1),\n    lags            = 24,\n    window_features = RollingFeatures(stats=['mean', 'mean', 'mean'], window_sizes=[24, 48, 72])\n)\n```\n\n----------------------------------------\n\nTITLE: MultiSeries Recursive Forecaster with Cross-Validation\nDESCRIPTION: Implements ForecasterRecursiveMultiSeries with grid search optimization, including both backtesting and one-step-ahead validation approaches. Uses TimeSeriesFold and OneStepAheadFold for cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nend_train = '2016-05-31 23:59:00'\nend_validation = '2016-07-31 23:59:00'\nlevels = ['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004']\nseries_dict_train = {k: v.loc[: end_train,] for k, v in series_dict.items()}\nexog_dict_train   = {k: v.loc[: end_train,] for k, v in exog_dict.items()}\nseries_dict_test  = {k: v.loc[end_train:,] for k, v in series_dict.items()}\nexog_dict_test    = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n\nforecaster_to_benchmark = ForecasterRecursiveMultiSeries(\n                              regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                              lags               = 24,\n                              encoding           = \"ordinal\",\n                              transformer_series = None,\n                              transformer_exog   = None,\n                              weight_func        = None,\n                              series_weights     = None,\n                              differentiation    = None,\n                              dropna_from_series = False,\n                              fit_kwargs         = None,\n                              forecaster_id      = None\n                          )\n```\n\n----------------------------------------\n\nTITLE: Setting up ForecasterRecursiveMultiSeries with Transformations\nDESCRIPTION: Initializes a recursive forecaster with feature transformations, including standardization and differentiation. Configures LGBM regressor with rolling features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nwindow_features = RollingFeatures(\n    stats        = ['mean', 'sum'],\n    window_sizes = [5, 5]\n)\n\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n    lags               = 5,\n    window_features    = window_features,\n    encoding           = 'ordinal',\n    transformer_series = StandardScaler(),\n    differentiation    = 1\n)\n\nforecaster.fit(series=data_multiseries)\n```\n\n----------------------------------------\n\nTITLE: Applying Differentiation with TimeSeriesDifferentiator - Python\nDESCRIPTION: This snippet demonstrates how to use the TimeSeriesDifferentiator to fit a time series and transform it into its differenced form. The original time series and the differenced output are printed for comparison, illustrating the effect of differentiation on the data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\n# Differentiation with TimeSeriesDifferentiator\\n# ==============================================================================\\ny = np.array([5, 8, 12, 10, 14, 17, 21, 19], dtype=float)\\ndiffenciator = TimeSeriesDifferentiator()\\ndiffenciator.fit(y)\\ny_diff = diffenciator.transform(y)\\n\\nprint(f\"Original time series   : {y}\")\\nprint(f\"Differenced time series: {y_diff}\")\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Train-Test Sets and Visualization\nDESCRIPTION: Splits the time series data into training and testing sets based on a specific cutoff date, then prints information about both sets and creates a visualization of the train-test split.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Data partition train-test\n# ==============================================================================\nend_train = '2005-06-01 23:59:00'\nprint(\n    f\"Train dates : {data.index.min()} --- {data.loc[:end_train].index.max()}  \" \n    f\"(n={len(data.loc[:end_train])})\"\n)\nprint(\n    f\"Test dates  : {data.loc[end_train:].index.min()} --- {data.index.max()}  \"\n    f\"(n={len(data.loc[end_train:])})\"\n)\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.loc[:end_train].plot(ax=ax, label='train')\ndata.loc[end_train:].plot(ax=ax, label='test')\nax.legend()\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Multi-Series Forecasting with Shared Transformer\nDESCRIPTION: Initializes a ForecasterRecursiveMultiSeries with LGBMRegressor and StandardScaler for multiple time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n    lags               = 24,\n    encoding           = 'ordinal',\n    transformer_series = StandardScaler(),\n    transformer_exog   = None\n)\nforecaster.fit(series=data)\n```\n\n----------------------------------------\n\nTITLE: Training Forecasting Models without Differentiation - Python\nDESCRIPTION: This snippet creates and trains two autoregressive forecasters using a Random Forest model and an XGBoost model. It captures performance metrics indicating prediction error when no differentiation is applied to the time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\n# Forecasting without differentiation\\n# ==============================================================================\\nsteps = len(data.loc[end_train:])\\n\\n# Forecasters\\nforecaster_rf = ForecasterRecursive(\\n                    regressor = RandomForestRegressor(random_state=963),\\n                    lags      = 12\\n                )\\nforecaster_gb = ForecasterRecursive(\\n                    regressor = XGBRegressor(random_state=963),\\n                    lags      = 12\\n                )\\n\\n# Train\\nforecaster_rf.fit(data.loc[:end_train])\\nforecaster_gb.fit(data.loc[:end_train])\\n\\n# Predict\\npredictions_rf = forecaster_rf.predict(steps=steps)\\npredictions_gb = forecaster_gb.predict(steps=steps)\\n\\n# Error\\nerror_rf = mean_absolute_error(data.loc[end_train:], predictions_rf)\\nerror_gb = mean_absolute_error(data.loc[end_train:], predictions_gb)\\nprint(f\"Error (MAE) Random Forest: {error_rf:.2f}\")\\nprint(f\"Error (MAE) Gradient Boosting: {error_gb:.2f}\")\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Accessing the Optimized SARIMAX Model after Grid Search in Python\nDESCRIPTION: This snippet shows how to access the optimized ForecasterSarimax model after grid search. With return_best=True, the forecaster is automatically updated with the best hyperparameters and trained on the entire dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Interval Coverage and Area\nDESCRIPTION: Computes the empirical coverage of the prediction intervals and the total area between the upper and lower bounds.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncoverage = calculate_coverage(\n               y_true      = data.loc[end_validation:, 'OT'],\n               lower_bound = predictions_q10[\"pred\"], \n               upper_bound = predictions_q90[\"pred\"]\n           )\nprint(f\"Predicted interval coverage: {round(100 * coverage, 2)} %\")\n\narea = (predictions_q90[\"pred\"] - predictions_q10[\"pred\"]).sum()\nprint(f\"Area of the interval: {round(area, 2)}\")\n```\n\n----------------------------------------\n\nTITLE: Create and Fit ForecasterSarimax with Exogenous Variables\nDESCRIPTION: This code snippet demonstrates how to create a `ForecasterSarimax` object with a specified SARIMAX model and then fit it to training data, including exogenous variables. The `fit` method trains the forecaster using the provided time series data (`y`) and exogenous variables (`exog`).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterSarimax(\n                 regressor=Sarimax(order=(12, 1, 1), seasonal_order=(0, 0, 0, 0), maxiter=200),\n             )\n\nforecaster.fit(\n    y                 = data_train['y'], \n    exog              = data_train[['exog_1', 'exog_2']],\n    suppress_warnings = True\n)\n```\n\n----------------------------------------\n\nTITLE: Grid Search Hyperparameter Tuning for Multi-Series Forecaster in Python\nDESCRIPTION: Implements grid search for hyperparameter tuning of a LightGBM-based recursive multi-series forecaster. It defines a parameter grid for model hyperparameters and a lags grid, then tests consistency of results across different input formats.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Test Grid Search\n# ==============================================================================\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor=LGBMRegressor(n_estimators=10, random_state=123, verbose=-1),\n    lags=14,\n    encoding=\"ordinal\",\n    dropna_from_series=False,\n    transformer_series=StandardScaler(),\n)\n\nlags_grid = [[5], [1, 7, 14]]\n\nparam_grid = {\n    \"learning_rate\": [0.1],\n    \"n_estimators\": [10, 20],\n    \"max_depth\": [2, 5],\n}\n\n\nresults_search_1 = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series,\n    exog=exog,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=\"mean_absolute_error\",\n    initial_train_size=len(series_train),\n    steps=10,\n    refit=False,\n    return_best=False,\n    show_progress=False,\n    verbose=False,\n)\n\n\nresults_search_2 = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series,\n    exog=exog_dict,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=\"mean_absolute_error\",\n    initial_train_size=len(series_train),\n    steps=10,\n    refit=False,\n    return_best=False,\n    show_progress=False,\n    verbose=False,\n)\n\nresults_search_3 = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series_dict,\n    exog=exog_dict,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=\"mean_absolute_error\",\n    initial_train_size=len(series_train),\n    steps=10,\n    refit=False,\n    return_best=False,\n    show_progress=False,\n    verbose=False,\n)\n\npd.testing.assert_frame_equal(results_search_1, results_search_2)\npd.testing.assert_frame_equal(results_search_1, results_search_3)\n```\n\n----------------------------------------\n\nTITLE: Generating Prediction Intervals using Bootstrapping\nDESCRIPTION: Demonstrates how to create prediction intervals that quantify the uncertainty in forecasts. The code uses bootstrapping with 100 iterations to estimate the 5th and 95th percentiles, providing a 90% confidence interval for the predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Predict intervals\n# ==============================================================================\npredictions = forecaster.predict_interval(\n                    steps    = 36,\n                    interval = [5, 95],\n                    method   = 'bootstrapping',\n                    n_boot   = 100\n             )\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Creating Calendar-Based Exogenous Features\nDESCRIPTION: Generates time-based features from the dataset index to serve as exogenous variables in the forecasting model. These features include month, day of week, day of month, week of year, and various calendar flags.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Create exogenous features based on the calendar\n# ==============================================================================\ndata[\"month\"] = data.index.month\ndata[\"day_of_week\"] = data.index.dayofweek\ndata[\"day_of_month\"] = data.index.day\ndata[\"week_of_year\"] = data.index.isocalendar().week\ndata[\"quarter\"] = data.index.quarter\ndata[\"is_month_start\"] = data.index.is_month_start.astype(int)\ndata[\"is_month_end\"] = data.index.is_month_end.astype(int)\ndata[\"is_quarter_start\"] = data.index.is_quarter_start.astype(int)\ndata[\"is_quarter_end\"] = data.index.is_quarter_end.astype(int)\ndata[\"is_year_start\"] = data.index.is_year_start.astype(int)\ndata[\"is_year_end\"] = data.index.is_year_end.astype(int)\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices with Skforecast in Python\nDESCRIPTION: This snippet demonstrates how to create training matrices using a Skforecast forecaster. The function `create_train_X_y` is used to generate training data, which is pivotal for understanding model behavior and training effectively.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create training matrices\n# ============================================================================== \nX_train, y_train = forecaster.create_train_X_y(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting LightGBM Forecaster with Explicit Categorical Features in Python\nDESCRIPTION: Creates a ForecasterRecursive with LightGBM regressor that explicitly specifies categorical features. The fit_kwargs parameter passes the categorical_feature argument to the underlying LightGBM model during training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster indicating the categorical features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(random_state=963, verbose=-1),\n                 lags             = 5,\n                 transformer_exog = transformer_exog,\n                 fit_kwargs       = {'categorical_feature': categorical_features}\n             )\n \nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Backtesting SARIMAX Model\nDESCRIPTION: This code snippet demonstrates how to perform backtesting of a `ForecasterSarimax` model using a `TimeSeriesFold` cross-validation strategy. The backtesting process evaluates the model's performance on historical data by iteratively training and predicting on different subsets of the data. It requires the definition of a custom `backtesting_sarimax` function.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterSarimax(\n                 regressor=Sarimax(order=(12, 1, 1), seasonal_order=(0, 0, 0, 0), maxiter=200),\n             )\n\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data_train),\n         refit              = True,\n         fixed_train_size   = False,\n     )\n\nmetric, predictions = backtesting_sarimax(\n                          forecaster            = forecaster,\n                          y                     = data['y'],\n                          exog                  = data[['exog_1', 'exog_2']],\n                          cv                    = cv,\n                          metric                = 'mean_absolute_error',\n                          n_jobs                = 'auto',\n                          suppress_warnings_fit = True,\n                          verbose               = True,\n                          show_progress         = True\n                      )\n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterRecursive in Python\nDESCRIPTION: Basic structure for creating a ForecasterRecursive object with key parameters including regressor, lags, window features, transformers, weight function, differentiation, and additional keyword arguments.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.recursive import ForecasterRecursive\n\nforecaster = ForecasterRecursive(\n    regressor        = None,\n    lags             = None,\n    window_features  = None,\n    transformer_y    = None,\n    transformer_exog = None,\n    weight_func      = None,\n    differentiation  = None,\n    fit_kwargs       = None,\n    binner_kwargs    = None,\n    forecaster_id    = None\n)\n```\n\n----------------------------------------\n\nTITLE: Internal Differentiation with Forecaster\nDESCRIPTION: Implements time series forecasting using internal differentiation within the ForecasterRecursive class.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor       = RandomForestRegressor(random_state=963),\n                 lags            = 15,\n                 differentiation = 1\n             )\n\nforecaster.fit(y=data.loc[:end_train])\npredictions_2 = forecaster.predict(steps=steps)\npredictions_2.head(5)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Cyclical Encoding for Hour in Python\nDESCRIPTION: This snippet creates a scatter plot to visualize the cyclical encoding of the hour feature, demonstrating how sine and cosine transformations represent the cyclic nature of hours in a day.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Plot value of sin and cos for each hour\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(3.5, 3))\nsp = ax.scatter(\n         cyclical_features[\"hour_sin\"],\n         cyclical_features[\"hour_cos\"],\n         c    = calendar_features['hour'],\n         cmap = 'viridis'\n     )\nax.set(\n    xlabel=\"sin(hour)\",\n    ylabel=\"cos(hour)\",\n)\n_ = fig.colorbar(sp)\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Creating Transformer for XGBoost Categorical Features\nDESCRIPTION: Configures a column transformer for XGBoost that applies ordinal encoding to categorical features while preserving numeric features. The transformer handles unknown values appropriately for XGBoost.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n# Transformer: ordinal encoding\n# ==============================================================================\n# A ColumnTransformer is used to transform categorical (no numerical) features\n# using ordinal encoding. Numeric features are left untouched. Missing values\n# are coded as -1. If a new category is found in the test set, it is encoded\n# as -1.\ncategorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\ntransformer_exog = make_column_transformer(\n                       (\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           categorical_features\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Bike Sharing Data for Time Series Forecasting\nDESCRIPTION: This snippet preprocesses the bike sharing dataset by setting the datetime index, converting frequency to hourly, sorting the index, and converting categorical variables to string type. It also selects specific columns for analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Preprocess data\n# ==============================================================================\ndata['date_time'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d %H:%M:%S')\ndata = data.set_index('date_time')\ndata = data.asfreq('H')\ndata = data.sort_index()\ndata['holiday'] = data['holiday'].astype(int)\ndata = data[['holiday', 'weather', 'temp', 'hum', 'users']]\ndata[['holiday', 'weather']] = data[['holiday', 'weather']].astype(str)\nprint(data.dtypes)\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Metric Function for Time Series Evaluation in Python\nDESCRIPTION: Defines a custom evaluation metric that calculates mean squared error only for predictions in the last three months of the year. This function filters the data using the month attribute of the time index and applies the mean_squared_error function.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef custom_metric(y_true, y_pred):\n    \"\"\"\n    Calculate the mean squared error using only the predicted values of the last\n    3 months of the year.\n    \"\"\"\n    mask = y_true.index.month.isin([10, 11, 12])\n    metric = mean_squared_error(y_true[mask], y_pred[mask])\n    \n    return metric\n```\n\n----------------------------------------\n\nTITLE: Creating Lagged and Window Features with Feature-Engine\nDESCRIPTION: This snippet creates lagged and window features for 'temp' and 'windspeed' using LagFeatures and WindowFeatures from the feature-engine library. The transformations include creating the last 3 lagged values and computing the mean over a 24-hour window, which is then combined into a preprocessing pipeline.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\n# Create lagged features and rolling windows features from exogenous variables\n# ============================================================================== \nlag_transformer = LagFeatures( \n                    variables = [\"temp\", \"windspeed\"], \n                    periods   = [1, 2, 3], \n                  )\n\nwf_transformer = WindowFeatures( \n                    variables      = [\"temp\", \"windspeed\"], \n                    window         = [\"24h\"], \n                    functions      = [\"mean\"], \n                    freq           = \"h\", \n                    missing_values = \"ignore\", \n                    drop_na        = False, \n                )\n\nexog_transformer = make_pipeline( \n                        wf_transformer, \n                        lag_transformer \n                   )\n\nexog_transformer\n```\n\n----------------------------------------\n\nTITLE: Reversing Differentiation - Python\nDESCRIPTION: This code shows how to reverse the differentiation process using the inverse_transform method of the TimeSeriesDifferentiator. It illustrates the restoration of the original time series values from the differenced data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\ndiffenciator.inverse_transform(y_diff)\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterDirectMultiVariate with Rolling Features\nDESCRIPTION: Sets up a forecaster with rolling window features and Ridge regression for multivariate time series prediction. Configures window statistics and sizes for feature generation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nwindow_features = RollingFeatures(\n    stats        = ['mean', 'sum'],\n    window_sizes = [5, 5]\n)\n\nforecaster = ForecasterDirectMultiVariate(\n    regressor       = Ridge(random_state=123),\n    level           = 'co',\n    steps           = 3,\n    lags            = 3,\n    window_features = window_features\n)\n\nforecaster.fit(series=data_multivariate)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Backtesting a Multi-Series Forecasting Model in Python\nDESCRIPTION: Performs backtesting on a multi-series forecasting model using TimeSeriesFold for cross-validation. It calculates performance metrics for each level (time series) and provides aggregated metrics across all series to evaluate model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Backtesting multiple time series\n# ==============================================================================\ncv = TimeSeriesFold(\n         steps              = 24,\n         initial_train_size = len(data_train),\n         refit              = True\n     )\n\nmetrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n    forecaster            = forecaster,\n    series                = data,\n    exog                  = None,\n    cv                    = cv,\n    levels                = None,\n    metric                = 'mean_absolute_error',\n    add_aggregated_metric = True\n)\n\nprint(\"Backtest metrics\")\ndisplay(metrics_levels)\nprint(\"\")\nprint(\"Backtest predictions\")\nbacktest_predictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Conducting Bayesian Hyperparameter Search in Python for Quantile Regression Models\nDESCRIPTION: This snippet outlines the process of performing a Bayesian search to optimize hyperparameters for quantile regressors. It emphasizes the importance of using the pinball loss metric, which is suitable for validating quantile regression models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Bayesian search of hyper-parameters and lags for each quantile forecaster\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterRecursive with Explicit Categorical Features\nDESCRIPTION: Instantiates a ForecasterRecursive with HistGradientBoostingRegressor that explicitly defines categorical features. The forecaster is fit on training data with exogenous variables including categorical features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster indicating the categorical features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor = HistGradientBoostingRegressor(\n                                 categorical_features = categorical_features,\n                                 random_state = 963\n                             ),\n                 lags = 5,\n                 transformer_exog = transformer_exog\n             )\n            \nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Backtesting with Optimized StackingRegressor\nDESCRIPTION: Conducts backtesting to evaluate the forecasting model using an optimized version of the StackingRegressor, with hyperparameters obtained from grid search. Aims to verify model enhancements and accuracy.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Backtesting on test data\n# ==============================================================================cv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_validation]),\n         refit              = False, \n     )\n\nmetric, predictions = backtesting_forecaster(\n                          forecaster = forecaster,\n                          y          = data['consumption'],\n                          exog       = data['month_of_year'],\n                          cv         = cv,\n                          metric     = 'mean_squared_error'\n                      )        \n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Creating Forecaster with Stacking Regressor\nDESCRIPTION: Initializes a ForecasterRecursive instance using the previously created StackingRegressor as the regressor. Uses the last 12 months as predictors to model time series behavior efficiently.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Create forecaster\n# ==============================================================================forecaster = ForecasterRecursive(\n                 regressor = stacking_regressor,\n                 lags      = 12  # Last 12 months used as predictors\n             )\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Features with a Rolling Skewness Class\nDESCRIPTION: This snippet defines a custom class, RollingSkewness, to compute rolling skewness features over specified window sizes, used for feature engineering in time series models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Custom class to create rolling skewness features\n# ============================================================================== \nfrom scipy.stats import skew\n\n\nclass RollingSkewness():\n    \"\"\"\n    Custom class to create rolling skewness features.\n    \"\"\"\n\n    def __init__(self, window_sizes, features_names: list = 'rolling_skewness'):\n        \n        if not isinstance(window_sizes, list):\n            window_sizes = [window_sizes]\n        self.window_sizes = window_sizes\n        self.features_names = features_names\n\n    def transform_batch(self, X: pd.Series) -> pd.DataFrame:\n        \n        rolling_obj = X.rolling(window=self.window_sizes[0], center=False, closed='left')\n        rolling_skewness = rolling_obj.skew()\n        rolling_skewness = pd.DataFrame({\n                               self.features_names: rolling_skewness\n                           }).dropna()\n\n        return rolling_skewness\n\n    def transform(self, X: np.ndarray) -> np.ndarray:\n        \n        X = X[~np.isnan(X)]\n        if len(X) > 0:\n            rolling_skewness = np.array([skew(X, bias=False)])\n        else:\n            rolling_skewness = np.array([np.nan])\n        \n        return rolling_skewness\n```\n\n----------------------------------------\n\nTITLE: Calculating Rolling Window Mean for Time Series Data in Python\nDESCRIPTION: This snippet shows how to calculate a rolling window mean for time series data using pandas. It computes a 4-hour rolling mean, ensuring no data leakage by using appropriate parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/time-series-aggregation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Rolling mean for 4 hours\n# ==============================================================================\ndata.rolling(window=4, min_periods=4, closed='left', center=False).mean()\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a ForecasterEquivalentDate Model\nDESCRIPTION: Initializes and trains a ForecasterEquivalentDate model for baseline forecasting using a 12-month offset with a 2-period lookback and mean aggregation function.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterEquivalentDate(\n                 offset    = pd.DateOffset(months=12),\n                 n_offsets = 2,\n                 agg_func  = np.mean\n             )\n\nforecaster.fit(y=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Weights for Multi-Series Forecasting in Python\nDESCRIPTION: Demonstrates how to create and apply custom weight functions and series weights to a ForecasterRecursiveMultiSeries model. The example includes a function that assigns zero weight to specific date ranges and configures different weights for multiple series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is between '2013-01-01' and '2013-01-31', 1 otherwise.\n    \"\"\"\n    weights = np.where(\n                  (index >= '2013-01-01') & (index <= '2013-01-31'),\n                   0,\n                   1\n              )\n    \n    return weights\n\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n                 encoding           = 'ordinal',\n                 transformer_series = StandardScaler(),\n                 weight_func        = custom_weights,\n                 series_weights     = {'item_1': 1., 'item_2': 2., 'item_3': 1.}  # Same as {'item_2': 2.}\n             )\n\nforecaster.fit(series=data_train)\nforecaster.predict(steps=24).head(3)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with XGBoost Categorical Forecaster\nDESCRIPTION: Generates predictions for 3 future time steps using the XGBoost forecaster with categorical features properly defined.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_39\n\nLANGUAGE: python\nCODE:\n```\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Feature Selection (Only Exog) with RFECV in Python\nDESCRIPTION: This code snippet demonstrates feature selection using RFECV, focusing only on exogenous features. The `select_only` parameter is set to `'exog'`, ensuring only the exog features are evaluated by the selector. All autoregressive features are included in the outputs.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (only exog) with scikit-learn RFECV\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = RFECV(\n    estimator=regressor, step=1, cv=3, min_features_to_select=25, n_jobs=-1\n)\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster  = forecaster,\n    selector    = selector,\n    y           = data[\"users\"],\n    exog        = data.drop(columns=\"users\"),\n    select_only = 'exog',\n    subsample   = 0.5,\n    verbose     = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting a ForecasterDirectMultiVariate Model\nDESCRIPTION: Initializes a ForecasterDirectMultiVariate model with LGBMRegressor as the base regressor, targeting the 'co' variable with a 7-day forecast horizon and 7 lags. The model includes rolling mean features with a 7-day window.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster MultiVariate\n# ==============================================================================\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 level              = 'co',\n                 steps              = 7,\n                 lags               = 7,\n                 window_features    = RollingFeatures(stats=['mean'], window_sizes=[7]),\n                 transformer_series = None,\n                 transformer_exog   = None\n             )\n\nforecaster.fit(series=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Predicting with Skforecast in Python\nDESCRIPTION: This snippet demonstrates how to make predictions using a forecaster in the Skforecast library. It shows predicting future steps with optional exogenous data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Benchmarking ForecasterDirectMultiVariate Performance\nDESCRIPTION: Script that benchmarks performance of ForecasterDirectMultiVariate using multiple regressors (Ridge, LGBMRegressor, HistGradientBoostingRegressor) across different operations. Measures execution times for fitting, backtesting, and grid search in both parallel and sequential modes. Includes visualization of performance improvements.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(\"----------------------------\")\nprint(\"ForecasterDirectMultiVariate\")\nprint(\"----------------------------\")\nsteps = 5\nlags = 10\nregressors = [\n    Ridge(random_state=77, alpha=0.1),\n    LGBMRegressor(random_state=77, n_jobs=1, n_estimators=50, max_depth=5, verbose=-1),\n    LGBMRegressor(random_state=77, n_jobs=-1, n_estimators=50, max_depth=5, verbose=-1),\n    HistGradientBoostingRegressor(random_state=77, max_iter=50, max_depth=5,),\n]\nparam_grids = [\n    {'alpha': [0.1, 0.1, 0.1]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'max_iter': [50, 50], 'max_depth': [5, 5]}\n]\nlags_grid = [50, 50, 50]\nelapsed_times = []\n\nfor regressor, param_grid in zip(regressors, param_grids):\n    print(\"\")\n    print(regressor, param_grid)\n    print(\"\")\n    forecaster = ForecasterDirectMultiVariate(\n                     regressor        = regressor,\n                     lags             = lags,\n                     steps            = steps,\n                     level            = \"series_1\",\n                     transformer_exog = StandardScaler()\n                 )\n    \n    print(\"Profiling fit\")\n    start = time.time()\n    forecaster.fit(series=multi_series, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling create_train_X_y\")\n    start = time.time()\n    _ = forecaster.create_train_X_y(series=multi_series, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n\n    print(\"Profiling backtesting refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             steps              = steps,\n             initial_train_size = int(len(y) * 0.9),\n             refit              = True,\n             fixed_train_size   = False,\n         )\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n\n    print(\"Profiling backtesting refit no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             steps              = steps,\n             initial_train_size = int(len(y) * 0.9),\n             refit              = False,\n         )\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)    \n    \n    print(\"Profiling GridSearch no refit parallel\")\n    start = time.time()\n    results_grid = grid_search_forecaster_multiseries(\n                       forecaster    = forecaster,\n                       series        = multi_series,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = -1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling GridSearch no refit no parallel\")\n    start = time.time()\n    results_grid = grid_search_forecaster_multiseries(\n                       forecaster    = forecaster,\n                       series        = multi_series,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = 1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n\nmethods = [\n    \"fit\",\n    \"create_train_X_y\",\n    \"backtest_refit_parallel\",\n    \"backtest_refit_noparallel\",\n    \"backtest_no_refit_parallel\",\n    \"backtest_no_refit_noparallel\",\n    \"gridSearch_no_refit_parallel\",\n    \"gridSearch_no_refit_noparallel\"\n]\n\nresults = pd.DataFrame({\n    \"regressor\": np.repeat(np.array([str(regressor) for regressor in regressors]), len(methods)),\n    \"method\": np.tile(methods, len(regressors)),\n    \"elapsed_time\": elapsed_times\n})\nresults[\"regressor\"] = results[\"regressor\"].str.replace(\"\\n              \", \" \")\nresults['parallel'] = results.method.str.contains(\"_parallel\")\nresults['method'] = results.method.str.replace(\"_parallel\", \"\")\nresults['method'] = results.method.str.replace(\"_noparallel\", \"\")\nresults = results.sort_values(by=[\"regressor\", \"method\", \"parallel\"])\n\nresults_pivot = results.pivot_table(index=[\"regressor\", \"method\"], columns=\"parallel\", values=\"elapsed_time\").reset_index()\nresults_pivot.columns.name = None\nresults_pivot[\"pct_improvement\"] = (results_pivot[False] - results_pivot[True]) / results_pivot[False] * 100\ndisplay(results_pivot)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nbars = sns.barplot(data=results_pivot.dropna(), x=\"method\", y=\"pct_improvement\", hue=\"regressor\", ax=ax)\nfor container in bars.containers:\n    ax.bar_label(container, fmt='%.1f', padding=3, fontsize=8)\nax.set_title(\"Parallel vs Sequential (ForecasterDirectMultiVariate)\")\nax.set_ylabel(\"Percent improvement\")\nax.set_xlabel(\"Method\")\nax.legend(fontsize=8, loc='lower left', bbox_to_anchor=(0, -0.31), ncols=1);\n```\n\n----------------------------------------\n\nTITLE: Backtesting with External Differentiation\nDESCRIPTION: Performs backtesting using external differentiation preprocessing and handles the reverting of differentiation for each fold.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsteps = 5\nforecaster_1 = ForecasterRecursive(\n                   regressor = RandomForestRegressor(random_state=963),\n                   lags      = 15\n               )\n\ncv = TimeSeriesFold(\n         steps                 = steps,\n         initial_train_size    = len(data_diff.loc[:end_train]),\n         refit                 = True,\n         fixed_train_size      = False, \n         allow_incomplete_fold = True\n     )\n\n_, predictions_1 = backtesting_forecaster(\n                       forecaster    = forecaster_1,\n                       y             = data_diff,\n                       cv            = cv,\n                       metric        = 'mean_squared_error',\n                       n_jobs        = 'auto',\n                       verbose       = False,\n                       show_progress = True\n                   )\n```\n\n----------------------------------------\n\nTITLE: Creating and Training ForecasterSarimax Model in Python\nDESCRIPTION: This code creates a ForecasterSarimax object using a Sarimax model with specified order and seasonal order. It then fits the model to the training data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit ForecasterSarimax\n# ==============================================================================\nforecaster = ForecasterSarimax(\n                 regressor=Sarimax(order=(12, 1, 1), seasonal_order=(0, 0, 0, 0), maxiter=200),\n             )\n\nforecaster.fit(y=data_train['y'], suppress_warnings=True)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Training ARIMA Model with skforecast in Python\nDESCRIPTION: This code demonstrates how to create and fit an ARIMA model using the skforecast library. It uses the Sarimax class with order (1,1,1) and prints a summary of the fitted model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# ARIMA model with skforecast.Sarimax\n# ==============================================================================\narima = Sarimax(order=(1, 1, 1))\narima.fit(y=data_train['y'])\narima.summary()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Forecasting Results\nDESCRIPTION: Creates a plot comparing the training data, test data, and model predictions to visually assess forecasting performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(6, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Evaluating Prediction Error with Incomplete Exogenous Data in Python\nDESCRIPTION: Calculates the MSE for predictions made with a model trained on incomplete exogenous data to verify that performance is maintained despite missing initial values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================================================================\nerror_mse = mean_squared_error(\n                y_true = data_test['y'],\n                y_pred = predictions\n            )\n\nprint(f\"Test error (MSE): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Predictions Against Actual Values in Python\nDESCRIPTION: This snippet provides code to plot the training data, test data, and predictions on one graph for a clear visual comparison. It uses Matplotlib for visualization to help evaluate the performance of the forecasting model against actual observations.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================\nfig, ax = plt.subplots(figsize=(6, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Checking Time Series Index Frequency in Python\nDESCRIPTION: This code snippet shows how to check the frequency of a time series index in pandas. It prints the frequency of the dataset's index.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/time-series-aggregation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Index Frequency\n# ==============================================================================\nprint(f\"Frequency: {data.index.freq}\")\n```\n\n----------------------------------------\n\nTITLE: Plotting Prediction Intervals\nDESCRIPTION: Creates visualization of the prediction intervals showing the actual values and the 80% confidence interval bounds.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.loc[end_validation:, 'OT'].plot(ax=ax, label='Real value', color='orange')\nax.fill_between(\n    data.loc[end_validation:].index,\n    pred_intervals['lower_bound'],\n    pred_intervals['upper_bound'],\n    color = 'gray',\n    alpha = 0.6,\n    zorder = 1,\n    label = '80% prediction interval'\n)\nax.set_xlabel('')\nax.set_title(\"Predicted intervals\")\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Extracting Training Matrices for Steps with Skforecast in Python\nDESCRIPTION: This code illustrates the extraction of training matrices for specific steps in the forecast using the ForecasterDirect method. Key steps include creating the whole training matrix and filtering it for specific forecast steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Create the whole train matrix\n# ============================================================================== \nX_train, y_train = forecaster.create_train_X_y(y=data['y'])\n\n# Extract X and y for step 1\nX_train_1, y_train_1 = forecaster.filter_train_X_y_for_step(\n                           step          = 1,\n                           X_train       = X_train,\n                           y_train       = y_train,\n                           remove_suffix = False\n                       )\n\nX_train_1.head(4)\n```\n\nLANGUAGE: python\nCODE:\n```\n# Target variable matrix for step 1\n# ============================================================================== \ny_train_1.head(3)\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Type List for XGBoost\nDESCRIPTION: Builds a list of feature types ('c' for categorical, 'q' for numeric) by examining column data types and comparing against known categorical features. This list will be used to configure XGBoost.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nfeature_types = [\n    \"c\" if X_train[col].dtype.name in [\"object\", \"category\"] or col in categorical_features\n    else \"q\"\n    for col in X_train.columns\n]\nfeature_types\n```\n\n----------------------------------------\n\nTITLE: Setting up ForecasterDirect with Ridge for Electricity Demand Forecasting\nDESCRIPTION: Configures a ForecasterDirect model with Ridge regression and StandardScaler for electricity demand prediction. Uses a specialized lags structure including hourly and daily patterns (1, 2, 3, 23, 24, 25, 167, 168, 169) for capturing both short-term and weekly seasonality.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Dataset vic_electricity - ForecasterDirect\n# ==============================================================================\nforecaster = ForecasterDirect(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 lags          = 10,\n                 steps         = 24\n             )\n\nlags_grid = (48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169))\n\n\ndef search_space(trial):\n    search_space  = {\n        'alpha': trial.suggest_float('alpha', 0.001, 1000, log=True),\n        'lags' : trial.suggest_categorical('lags', lags_grid)\n    }\n\n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_electricity,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'Demand',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'electricity',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Analyzing Distribution of Out-Sample Residuals\nDESCRIPTION: The snippet calculates and plots the distribution of out-sample residuals, distinguishing between positive and negative residuals to evaluate the forecasting model's performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n# Distribution of out-sample residuals\n# ==============================================================================\nresiduals = data.loc[predictions_cal.index, 'OT'] - predictions_cal['pred']\nprint(pd.Series(np.where(residuals < 0, 'negative', 'positive')).value_counts())\nplt.rcParams.update({'font.size': 8})\n_ = plot_residuals(residuals=residuals, figsize=(7, 4))\n```\n\n----------------------------------------\n\nTITLE: Extracting Categorical Features from XGBoost Model\nDESCRIPTION: Retrieves information about which features were actually treated as categorical by the XGBoost model by accessing the booster's feature types and feature names.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_40\n\nLANGUAGE: python\nCODE:\n```\n# Print the features considered as categorical by the forecaster\n# ==============================================================================\nfeature_types = np.array(forecaster.regressor.get_booster().feature_types)\nfeatures_in_model = np.array(forecaster.regressor.get_booster().feature_names)\nfeatures_in_model[feature_types == 'c']\n```\n\n----------------------------------------\n\nTITLE: Creating a Pipeline for Automatic Categorical Feature Detection\nDESCRIPTION: Builds a transformation pipeline that applies ordinal encoding to categorical columns and converts them to category dtype, allowing automatic detection by models. It uses column selectors to identify non-numeric features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n# Transformer: ordinal encoding and cast to category type\n# ==============================================================================\n# A ColumnTransformer is used to transform categorical (not numerical) features\n# using ordinal encoding. Numeric features are left untouched. Missing values\n# are coded as -1. If a new category is found in the test set, it is encoded\n# as -1. After encoding, the features are converted back to category type so that \n# they can be identified as categorical features by the regressor.\n\npipeline_categorical = make_pipeline(\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           FunctionTransformer(\n                               func=lambda x: x.astype('category'),\n                               feature_names_out= 'one-to-one'\n                           )\n                       )\n\ntransformer_exog = make_column_transformer(\n                       (\n                           pipeline_categorical,\n                           make_column_selector(dtype_exclude=np.number)\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Generating Prediction Intervals with ForecasterSarimax in Python\nDESCRIPTION: This code demonstrates how to generate prediction intervals using the ForecasterSarimax model. It predicts 36 steps ahead with a 95% confidence interval.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Predict intervals\n# ==============================================================================\npredictions = forecaster.predict_interval(steps=36, alpha=0.05)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Error in Python\nDESCRIPTION: This snippet demonstrates how to assess the prediction error of the model by calculating the Mean Squared Error (MSE) between the actual test data and the predicted values. It provides insight on how well the forecasting model performs.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================\npredictions = forecaster.predict(steps=36)\nerror_mse = mean_squared_error(\n                y_true = data_test,\n                y_pred = predictions\n            )\nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Loading Forecaster Model with Custom Functions\nDESCRIPTION: Loading the saved forecaster model and required custom functions from external files.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom rolling_skewness import RollingSkewnessMultiSeries\nfrom custom_weights_item_1 import custom_weights_item_1\nfrom custom_weights_item_2 import custom_weights_item_2\nfrom custom_weights_item_3 import custom_weights_item_3\n\nforecaster_loaded = load_forecaster(\n    'forecaster_multiseries_custom_features.joblib', verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Bayesian Hyperparameter Search with Optuna in Python\nDESCRIPTION: This code demonstrates how to perform Bayesian hyperparameter optimization using Optuna for the MultiVariate forecaster, including a custom search space definition.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirectMultiVariate(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 level           = 'co',\n                 steps           = 7,\n                 lags            = 7,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=[7])\n             )\n\ndef search_space(trial):\n    search_space  = {\n        'lags'            : trial.suggest_categorical('lags', [7, 14]),\n        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1., 10),\n        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n    }\n\n    return search_space\n\ncv = TimeSeriesFold(\n         steps              = 7,\n         initial_train_size = len(data_train),\n         refit              = False,\n     )\n\nresults, best_trial = bayesian_search_forecaster_multiseries(\n                          forecaster            = forecaster,\n                          series                = data,\n                          search_space          = search_space,\n                          cv                    = cv,\n                          metric                = 'mean_absolute_error',\n                          aggregate_metric      = 'weighted_average',\n                          n_trials              = 5,\n                          kwargs_create_study   = {},\n                          kwargs_study_optimize = {}\n                      )\n\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Log Transformation with sktime and sklearn\nDESCRIPTION: Implements log transformation of time series data using sktime's LogTransformer and sklearn's FunctionTransformer. Shows how to achieve equivalent log(x+1) transformations with both libraries and validates matching results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sktime-pipelines.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Log transformation\n# ======================================================================================\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sktime.transformations.series.boxcox import LogTransformer\n\n# sktime\ntransformer_sktime = LogTransformer(offset=1)\ny_hat_sktime = transformer_sktime.fit_transform(data_train['litters'])\n\n# skforecast\ntransformer_skforecast = FunctionTransformer(func=np.log1p, inverse_func=np.expm1, validate=True)\ny_hat_skforecast = transformer_skforecast.fit_transform(data_train[['litters']]).flatten()\n\nnp.testing.assert_allclose(y_hat_sktime, y_hat_skforecast)\n```\n\n----------------------------------------\n\nTITLE: Implementing Time Series Differentiation in Multi-Series Forecasting\nDESCRIPTION: Demonstrates how to create and fit a forecaster with differentiation, showing configuration for multiple series with different differentiation orders.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 24,\n                 window_features = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n                 differentiation = 1  # Same as {'item_1': 1, 'item_2': 1, 'item_3': 1, '_unknown_level': 1}\n             )\n\nforecaster.fit(series=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Making Multi-Step Forecasts with a Trained Recursive Model\nDESCRIPTION: Uses the trained forecaster to predict 36 steps ahead using recursive forecasting. The predictions are then displayed and visualized against the actual test data to evaluate model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=36)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Fitting a Forecaster with Transformed Exogenous Features in Python\nDESCRIPTION: This snippet demonstrates fitting a forecaster with a transformer applied to exogenous features, using Skforecast. It shows the integration of a regressor and transformation pipeline.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n# Create and fit a forecaster with a transformer for exogenous features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\n\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(random_state=123, verbose=-1),\n                 lags             = 5,\n                 transformer_exog = ordinal_encoder\n             )\n\nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Training XGBoost Forecaster with reg:gamma Objective\nDESCRIPTION: This snippet creates and trains a `ForecasterRecursive` model using an `XGBRegressor` with the `reg:gamma` objective function. The objective function is set to `reg:gamma` to ensure positive output values. Backtesting is performed to evaluate the model's performance, and the mean squared error is calculated.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Create forecaster and train\n# ==============================================================================\nparams = {\n    'tree_method': 'hist',\n    'objective': 'reg:gamma'\n}\n\nforecaster = ForecasterRecursive(\n                 regressor = XGBRegressor(**params),\n                 lags      = 24,\n             )\n\n# Backtesting predictions on test data\n# ==============================================================================\nmetric, predictions = backtesting_forecaster(\n                          forecaster = forecaster,\n                          y          = data['users'],\n                          cv         = cv,\n                          metric     = 'mean_squared_error'\n                      )\n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Saving Forecaster Model with Custom Functions\nDESCRIPTION: Saving the trained forecaster model along with its custom functions to a joblib file.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nsave_forecaster(\n    forecaster, \n    file_name = 'forecaster_multiseries_custom_features.joblib', \n    save_custom_functions = True, \n    verbose = False\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing ForecasterDirectMultiVariate with Transformations\nDESCRIPTION: Creates a direct forecaster with data transformations including standardization and differentiation. Sets up Ridge regression with rolling features for multi-step prediction.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nwindow_features = RollingFeatures(\n    stats        = ['mean', 'sum'],\n    window_sizes = [5, 5]\n)\n\nforecaster = ForecasterDirectMultiVariate(\n    regressor          = Ridge(random_state=123),\n    level              = 'co',\n    steps              = 3,\n    lags               = 3,\n    window_features    = window_features,\n    transformer_series = StandardScaler(),\n    differentiation    = 1\n)\n\nforecaster.fit(series=data_multivariate)\n```\n\n----------------------------------------\n\nTITLE: Backtesting MultiVariate in Python\nDESCRIPTION: This snippet sets up a time series cross-validation for backtesting the MultiVariate forecaster and evaluates the model performance using mean absolute error as the metric.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncv = TimeSeriesFold(\n         steps                 = 7,\n         initial_train_size    = len(data_train),\n         refit                 = False,\n         allow_incomplete_fold = True\n     )\n\nmetrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n                                           forecaster = forecaster,\n                                           series     = data,\n                                           cv         = cv,\n                                           metric     = 'mean_absolute_error'\n                                       )\ndisplay(metrics_levels)\nbacktest_predictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Performing Backtesting for Time Series Forecasting in Python\nDESCRIPTION: Conducts backtesting for time series data to evaluate forecasting performance, simulating predictions in 12-day batches and calculating performance metrics.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Backtesting: predict batches of 12 days\n# =================================================\ncv = TimeSeriesFold(\n         steps              = 12,\n         initial_train_size = len(data.loc[:end_train]),\n         refit              = False\n     )\n\nmetric, predictions_backtest = backtesting_forecaster(\n                                   forecaster = forecaster,\n                                   y          = data['production'],\n                                   cv         = cv,\n                                   metric     = 'mean_absolute_error'\n                               )\n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Implementing RollingSkewnessMultiSeries Class for Feature Generation\nDESCRIPTION: Custom class that generates rolling skewness features for multiple time series. Includes initialization with window sizes and transformation methods for both batch and individual processing.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass RollingSkewnessMultiSeries():\n    def __init__(self, window_sizes, features_names: list = 'rolling_skewness'):\n        \n        if not isinstance(window_sizes, list):\n            window_sizes = [window_sizes]\n        self.window_sizes = window_sizes\n        self.features_names = features_names\n\n    def transform_batch(self, X: pd.Series) -> pd.DataFrame:\n        \n        rolling_obj = X.rolling(window=self.window_sizes[0], center=False, closed='left')\n        rolling_skewness = rolling_obj.skew()\n        rolling_skewness = pd.DataFrame({\n                               self.features_names: rolling_skewness\n                           }).dropna()\n\n        return rolling_skewness\n\n    def transform(self, X: np.ndarray) -> np.ndarray:\n        \n        X_dim = X.ndim\n        if X_dim == 1:\n            n_series = 1\n            X = X.reshape(-1, 1)\n        else:\n            n_series = X.shape[1]\n        \n        n_stats = 1\n        rolling_skewness = np.full(\n            shape=(n_series, n_stats), fill_value=np.nan, dtype=float\n        )\n        for i in range(n_series):\n            if len(X) > 0:\n                rolling_skewness[i, :] = skew(X[:, i], bias=False)\n            else:\n                rolling_skewness[i, :] = np.nan      \n\n        if X_dim == 1:\n            rolling_skewness = rolling_skewness.flatten()  \n        \n        return rolling_skewness\n```\n\n----------------------------------------\n\nTITLE: Creating a Forecaster with Custom Features\nDESCRIPTION: This snippet demonstrates the creation of a Forecaster with custom window features and weight functions using the RollingSkewness class and custom_weights function for feature engineering.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create and train forecaster\n# ============================================================================== \nwindow_features = RollingSkewness(window_sizes=3)\n\nforecaster = ForecasterRecursive(\n                 regressor       = RandomForestRegressor(random_state=123),\n                 lags            = 3,\n                 window_features = window_features,\n                 weight_func     = custom_weights,\n                 forecaster_id   = \"forecaster_custom_features\"\n             )\n\nforecaster.fit(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Simulating Data and Calculating CRPS in Python\nDESCRIPTION: This code generates simulated data (a true value and an array of predicted values) and calculates the CRPS using the crps_from_predictions function from skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simulate data: true value and and array of 100 predicted values for the same true value\n# ======================================================================================\ny_true = 500\ny_pred = np.random.normal(500, 10, 100)\ncrps_from_predictions(y_true, y_pred)\n```\n\n----------------------------------------\n\nTITLE: Time Series Matrix Transformation with Lags\nDESCRIPTION: Demonstrates how time series data is transformed into a matrix with lagged features for machine learning models, enabling predictive analysis by capturing temporal dependencies\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/introduction-forecasting/introduction-forecasting.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p style=\"text-align: center\">\n    <img src=\"../img/transform_timeseries.gif\" style=\"width: 500px;\">\n    <br>\n    <font size=\"2.5\"> <i>Time series transformation into a matrix of 5 lags and a vector with the value of the series that follows each row of the matrix</i></font>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Analyzing Internal Regressors in Skforecast in Python\nDESCRIPTION: This snippet shows how to access internal regressors for each forecast step within a ForecasterDirect model. It aids in evaluating various regressors applied in the forecasting process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Internal regressors {step: regressor}\n# ============================================================================== \nforecaster.regressors_\n```\n\n----------------------------------------\n\nTITLE: Implementing ForecasterRecursive with Ridge for Website Visits Prediction\nDESCRIPTION: Configures a ForecasterRecursive model with Ridge regression to predict website visits data. Defines training and validation periods, exogenous features based on date components, and a search space for hyperparameter tuning with Bayesian optimization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Dataset website_visits - ForecasterRecursive\n# ==============================================================================\nend_train = '2021-03-30 23:59:00'\nend_validation = '2021-06-30 23:59:00'\nexog_features = [col for col in data_website.columns if col.startswith(('month_', 'week_day_', 'month_day_'))]\n\nforecaster = ForecasterRecursive(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 lags          = 10\n             )\n\nlags_grid = [7, 14, 21, [7, 14, 21]]\n\n\ndef search_space(trial):\n    search_space  = {\n        'alpha': trial.suggest_float('alpha', 0.001, 1000, log=True),\n        'lags' : trial.suggest_categorical('lags', lags_grid)\n    } \n    \n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_website,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 7,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'website',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Error for ForecasterSarimax Model in Python\nDESCRIPTION: This snippet calculates the mean absolute error between the test data and the predictions made by the ForecasterSarimax model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================================================================\nerror_mse = mean_absolute_error(\n                y_true = data_test['y'],\n                y_pred = predictions\n            )\n\nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterRecursive with Transformations in Python\nDESCRIPTION: This snippet demonstrates the creation and fitting of a ForecasterRecursive with transformations such as scaling and differentiation. Such transformations require proper handling to ensure predictions can be reverted back to the original scale accurately.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit ForecasterRecursive\n# ============================================================================== \nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'sum'],\n                      window_sizes = [5, 5]\n                  )\n\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 5,\n                 window_features = window_features,\n                 transformer_y   = StandardScaler(),\n                 differentiation = 1\n             )\n\nforecaster.fit(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Loaded Forecaster\nDESCRIPTION: Using the loaded forecaster to make predictions for all levels 5 steps ahead.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nforecaster_loaded.predict(steps=5, levels=None)\n```\n\n----------------------------------------\n\nTITLE: Feature Selection with Sequential Feature Selector in Python\nDESCRIPTION: This code snippet demonstrates feature selection using scikit-learn's SequentialFeatureSelector. A single validation split is used to evaluate each candidate model instead of cross-validation to reduce computational cost, especially useful for large datasets.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (only exog) with scikit-learn SequentialFeatureSelector\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = SequentialFeatureSelector(\n               estimator            = forecaster.regressor,\n               n_features_to_select = 25,\n               direction            = \\\"forward\\\",\n               cv                   = ShuffleSplit(n_splits=1, test_size=0.3, random_state=951),\n               scoring              = \\\"neg_mean_absolute_error\\\",\n               n_jobs               = -1,\n           )\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster   = forecaster,\n    selector     = selector,\n    y            = data[\"users\"],\n    exog         = data.drop(columns=\"users\"),\n    select_only  = 'exog',\n    subsample    = 0.2,\n    random_state = 123,\n    verbose      = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Saving a Model with Custom Functions\nDESCRIPTION: This snippet shows how to save a forecaster model along with custom functions. The save_forecaster function is used with the save_custom_functions parameter to persist custom weights for future use.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Save model and custom function\n# ============================================================================== \nsave_forecaster(\n    forecaster, \n    file_name = 'forecaster_custom_features.joblib', \n    save_custom_functions = True, \n    verbose = False\n)\n```\n\n----------------------------------------\n\nTITLE: Predicting Future Values with ForecasterDirect\nDESCRIPTION: This code demonstrates making future predictions using a ForecasterDirect model. It creates prediction matrices for all steps, predicts using the step 1 regressor, and reverts both differentiation and transformation to get the final predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Predict using the internal regressor with transformation\n# ==============================================================================\nX_predict_transformed = forecaster.create_predict_X(steps=None)  # All steps\n\n# Predict using the internal regressor for step 1\npredictions_transformed = forecaster.regressors_[1].predict(X_predict_transformed)\n\n# Revert differentiation (only if differentiation is not None)\npredictions_transformed = forecaster.differentiator.inverse_transform_next_window(predictions_transformed)\n\n# Revert transformation (only if transformer_y is not None)\npredictions = forecaster.transformer_y.inverse_transform(predictions_transformed.reshape(-1, 1))\npredictions.ravel()[:4]\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Trained Forecaster\nDESCRIPTION: Uses the trained forecaster to predict future values for the test period and displays the first 3 predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=len(data.loc[end_train:]))\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Multiple Time Series with Train-Test Split in Python\nDESCRIPTION: Creates a visualization of multiple time series from the dataset, with each series in a separate subplot and train/test data differentiated by color, using matplotlib and the dark theme from skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Plot time series\n# ==============================================================================\nset_dark_theme()\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize=(9, 5), sharex=True)\nfor i, col in enumerate(data.columns):\n    data_train[col].plot(ax=axes[i], label='train')\n    data_test[col].plot(ax=axes[i], label='test')\n    axes[i].set_title(col)\n    axes[i].set_ylabel('sales')\n    axes[i].set_xlabel('')\n    axes[i].legend(loc='upper right')\nfig.tight_layout()\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Loaded Custom Forecaster\nDESCRIPTION: Here, predictions are made with a forecaster model loaded with custom features and functions. It demonstrates using a forecaster that relies on custom feature engineering and weight adjustments.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Predict using loaded forecaster\n# ============================================================================== \nforecaster_loaded.predict(steps=5)\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterRecursiveMultiSeries with Different Transformers\nDESCRIPTION: Shows how to initialize a forecaster with different transformers for each series using a dictionary configuration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n                 encoding           = 'ordinal',\n                 transformer_series = {'item_1': StandardScaler(), 'item_2': MinMaxScaler(), '_unknown_level': StandardScaler()},\n                 transformer_exog   = None\n             )\n\nforecaster.fit(series=data_train)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking LGBMRegressor with ForecasterRecursive on Bike Sharing Data\nDESCRIPTION: Sets up a ForecasterRecursive with LGBMRegressor for the bike sharing dataset, configures time periods, exogenous features, and hyperparameter grid for optimization. The benchmark results are captured in time metrics and performance metrics.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nend_train = '2012-03-31 23:59:00'\nend_validation = '2012-08-31 23:59:00'\nexog_features = [\n    'month_sin', 'month_cos', 'week_of_year_sin', 'week_of_year_cos', 'week_day_sin',\n    'week_day_cos', 'hour_day_sin', 'hour_day_cos', 'sunrise_hour_sin', 'sunrise_hour_cos',\n    'sunset_hour_sin', 'sunset_hour_cos', 'holiday_previous_day', 'holiday_next_day',\n    'temp_roll_mean_1_day', 'temp_roll_mean_7_day', 'temp_roll_max_1_day',\n    'temp_roll_min_1_day', 'temp_roll_max_7_day', 'temp_roll_min_7_day',\n    'temp', 'holiday'\n]\n\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 10\n             )\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [3, 5],\n    'learning_rate': [0.01, 0.1]\n}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_bike,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\n\nresults_grid_search.append([\n    'bike',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Calculating Forecast Error Metrics with Exogenous Variables in Python\nDESCRIPTION: Computes the Mean Squared Error (MSE) between the actual test values and the forecasted predictions to quantify model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================================================================\nerror_mse = mean_squared_error(\n                y_true = data_test['y'],\n                y_pred = predictions\n            )\n\nprint(f\"Test error (MSE): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Input Matrix for All Steps with Skforecast in Python\nDESCRIPTION: The code generates an input matrix for predictions across all steps using the `create_predict_X` method in a ForecasterDirect model, crucial for obtaining comprehensive forecast outputs.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Create input matrix for predict method\n# ==============================================================================  \nX_predict = forecaster.create_predict_X(steps=None)  # All steps\nX_predict\n```\n\n----------------------------------------\n\nTITLE: Fitting XGBoost Forecaster with Categorical Features\nDESCRIPTION: Fits the XGBoost forecaster with the updated categorical feature information on the training data, including exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_38\n\nLANGUAGE: python\nCODE:\n```\n# Fit forecaster\n# ==============================================================================\nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Bayesian Search on Multiseries Forecaster\nDESCRIPTION: The snippet explores the forecaster's hyperparameter space using Bayesian optimization. It uses a predefined search space and evaluates performance through cross-validation to determine optimal parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor=LGBMRegressor(n_estimators=10, random_state=123, verbose=-1, max_depth=2),\n    lags=14,\n    encoding=\\\"ordinal\\\",\n    dropna_from_series=False,\n    transformer_series=StandardScaler(),\n    transformer_exog=StandardScaler(),\n)\n\nlags_grid = [[5], [1, 7, 14]]\n\ndef search_space(trial):\n    search_space = {\n        \\\"n_estimators\\\": trial.suggest_int(\\\"n_estimators\\\", 2, 5),\n        \\\"max_depth\\\": trial.suggest_int(\\\"max_depth\\\", 2, 5),\n        \\\"lags\\\": trial.suggest_categorical(\\\"lags\\\", lags_grid),\n    }\n\n    return search_space\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\\\"ignore\\\", category=UserWarning, module=\\\"optuna\\\")\n\n    cv = TimeSeriesFold(\n        initial_train_size=len(series_dict_train[\\\"id_1000\\\"]),\n        steps=10,\n        refit=False,\n    )\n\n    results_search, best_trial = bayesian_search_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series_dict,\n        exog=exog_dict,\n        search_space=search_space,\n        metric=\\\"mean_absolute_error\\\",\n        cv=cv,\n        n_trials=3,\n        return_best=False,\n        show_progress=True,\n        verbose=False,\n        suppress_warnings=True,\n    )\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Partition Data into Training and Testing Sets\nDESCRIPTION: This code divides the time series and exogenous variables dictionaries into training and testing sets based on a specified end date (`end_train`).  A dictionary comprehension is used to iterate through each series and exogenous variable, slicing the data up to the `end_train` date for training and from `end_train` onwards for testing.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"# Partition data in train and test\n# ==============================================================================\nend_train = '2016-07-31 23:59:00'\nseries_dict_train = {k: v.loc[: end_train,] for k, v in series_dict.items()}\nexog_dict_train   = {k: v.loc[: end_train,] for k, v in exog_dict.items()}\nseries_dict_test  = {k: v.loc[end_train:,] for k, v in series_dict.items()}\nexog_dict_test    = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\"\n```\n\n----------------------------------------\n\nTITLE: One-Hot Encoding Exogenous Features with Python\nDESCRIPTION: This snippet demonstrates how to transform exogenous categorical features using one-hot encoding outside a forecaster. The transformation prepares the features for compatibility with a downstream model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Transform exogenous features using the transformer outside the forecaster\n# ============================================================================== \nexog_transformed = one_hot_encoder.fit_transform(data.loc[:end_train, exog_features]) \nexog_transformed.head()\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking Ridge with ForecasterDirect on Website Visits Data\nDESCRIPTION: Implements a ForecasterDirect with Ridge regression for the website visits dataset. The configuration aims to forecast 24 steps ahead using different lag values (7, 14, 21 days) and alpha parameter optimization through grid search.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Dataset website_visits - ForecasterDirect\n# ==============================================================================\nforecaster = ForecasterDirect(\n                 regressor = Ridge(random_state=123),\n                 steps     = 24,\n                 lags      = 10\n             )\n\nlags_grid = [7, 14, 21, [7, 14, 21]]\n\nparam_grid = {'alpha': np.logspace(-3, 3, 20)}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_website,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'website',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Creating Input Matrix for Prediction with Skforecast in Python\nDESCRIPTION: This snippet creates an input matrix for making predictions using the forecaster's `create_predict_X` method. Understanding the input matrix structure is essential for ensuring accurate and reliable forecasts.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Create input matrix for predict method\n# ============================================================================== \nX_predict = forecaster.create_predict_X(steps=5)\nX_predict\n```\n\n----------------------------------------\n\nTITLE: Training and Forecasting with Datetime-Indexed Data in Skforecast\nDESCRIPTION: Creates a ForecasterRecursive model with LGBMRegressor, fits it on datetime-indexed data, and generates predictions for 5 future steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/input-data.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 5\n             )\n\nforecaster.fit(y=data['y'])\n\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=5)\n```\n\n----------------------------------------\n\nTITLE: Backtesting Quantile Forecasters\nDESCRIPTION: Performs backtesting on test data for both quantile forecasters to generate prediction intervals using TimeSeriesFold cross-validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncv = TimeSeriesFold(\n         steps              = 24, \n         initial_train_size = len(data.loc[:end_validation]),\n         refit              = False\n     )\n\nmetric_q10, predictions_q10 = backtesting_forecaster(\n                                  forecaster = forecaster_q10,\n                                  y          = data['OT'],\n                                  cv         = cv,\n                                  metric     = create_mean_pinball_loss(alpha=0.1)\n                              )\n\nmetric_q90, predictions_q90 = backtesting_forecaster(\n                                  forecaster = forecaster_q90,\n                                  y          = data['OT'],\n                                  cv         = cv,\n                                  metric     = create_mean_pinball_loss(alpha=0.9)\n                              )\n\npred_intervals = pd.concat([predictions_q10, predictions_q90], axis=1)\npred_intervals.columns = ['lower_bound', 'upper_bound']\npred_intervals.head()\n```\n\n----------------------------------------\n\nTITLE: Missing Value Imputation\nDESCRIPTION: Performs linear interpolation to impute missing values in the time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndata['users_imputed'] = data['users'].interpolate(method='linear')\ndata_train = data.loc[: end_train, :]\ndata_test  = data.loc[end_train:, :]\n```\n\n----------------------------------------\n\nTITLE: Creating Stacking Regressor Using scikit-learn in Python\nDESCRIPTION: Constructs a StackingRegressor from different base models (Ridge and LGBMRegressor) and specifies hyperparameters for each. Utilizes k-fold cross-validation to evaluate the model ensemble.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Create stacking regressor\n# ==============================================================================params_ridge = {'alpha': 0.001}\nparams_lgbm = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'verbose': -1}\n\nestimators = [\n    ('ridge', Ridge(**params_ridge)),\n    ('lgbm', LGBMRegressor(random_state=42, **params_lgbm)),\n]\n\nstacking_regressor = StackingRegressor(\n                         estimators = estimators,\n                         final_estimator = Ridge(),\n                         cv = KFold(n_splits=5, shuffle=False)\n                     )\nstacking_regressor\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Differentiated Time Series Model\nDESCRIPTION: Uses the forecaster with differentiation to predict 36 steps ahead. The model automatically handles the inverse transformation to convert predictions back to the original scale of the time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=36)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Feature Selection (Only Autoregressive) with RFECV in Python\nDESCRIPTION: This code snippet demonstrates feature selection using RFECV, focusing solely on autoregressive features. The `select_only` parameter is set to `'autoreg'`, ensuring that only lags and window features are considered during feature elimination. All exogenous features are included in the output.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (only autoregressive) with scikit-learn RFECV\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = RFECV(\n    estimator=regressor, step=1, cv=3, min_features_to_select=25, n_jobs=-1\n)\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster  = forecaster,\n    selector    = selector,\n    y           = data[\"users\"],\n    exog        = data.drop(columns=\"users\"),\n    select_only = 'autoreg',\n    subsample   = 0.5,\n    verbose     = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices with NaN Values in ForecasterRecursiveMultiSeries\nDESCRIPTION: This code creates training matrices using ForecasterRecursiveMultiSeries with dropna_from_series set to False. It demonstrates how NaN values are handled and displays the resulting matrices.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nregressor = LGBMRegressor(random_state=123, verbose=-1, max_depth=5)\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = regressor, \n                 lags               = 3, \n                 encoding           = \"ordinal\", \n                 dropna_from_series = False\n             )\n\nX, y = forecaster.create_train_X_y(series=series_dict_nan)\n\ndisplay(X.head(3))\nprint(\"Observations per series:\")\nprint(X['_level_skforecast'].value_counts())\nprint(\"\")\nprint(\"NaNs per series:\")\nprint(X.isnull().sum())\n```\n\n----------------------------------------\n\nTITLE: Training and Comparing Random Forest and Gradient Boosting Forecasters\nDESCRIPTION: Trains Random Forest and Gradient Boosting models on time series data, makes predictions, calculates MAE, and visualizes results with matplotlib.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Train\nforecaster_rf.fit(data.loc[:end_train])\nforecaster_gb.fit(data.loc[:end_train])\n\n# Predict\npredictions_rf = forecaster_rf.predict(steps=steps)\npredictions_gb = forecaster_gb.predict(steps=steps)\n\n# Error\nerror_rf = mean_absolute_error(data.loc[end_train:], predictions_rf)\nerror_gb = mean_absolute_error(data.loc[end_train:], predictions_gb)\nprint(f\"Error (MAE) Random Forest: {error_rf:.2f}\")\nprint(f\"Error (MAE) Gradient Boosting: {error_gb:.2f}\")\n\n# Plot\nfig, ax = plt.subplots(figsize=(7, 3), sharex=True, sharey=True)\ndata.loc[:end_train].plot(ax=ax, label='train')\ndata.loc[end_train:].plot(ax=ax, label='test')\npredictions_rf.plot(ax=ax, label='Random Forest')\npredictions_gb.plot(ax=ax, label='Gradient Boosting')\nax.set_title('Forecasting with differentiation')\nax.set_xlabel('')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Handling Transformed Training Predictions in Python\nDESCRIPTION: This code snippet handles the creation and inversion of transformed training predictions with a ForecasterRecursive model. This involves predicting in the transformed scale and reverting changes such as differentiation to achieve accurate results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Training predictions with transformations\n# ==============================================================================  \nX_train_transformed, y_train_transformed = forecaster.create_train_X_y(y=data['y'])\n\n# Training predictions using the internal regressor\npredictions_transformed = forecaster.regressor.predict(X_train_transformed)\n\n# Revert differentiation (only if differentiation is not None)\npredictions_transformed = forecaster.differentiator.inverse_transform_training(predictions_transformed)\n```\n\n----------------------------------------\n\nTITLE: Feature Selection (Only Exog) with Forced Inclusion in Python\nDESCRIPTION: This code snippet performs feature selection on only exogenous features, but forces the inclusion of the 'noise' feature. The `force_inclusion` parameter is set to `[\"noise\"]`, which ensures that this feature is always included in the selected features, regardless of its relevance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (only exog) with scikit-learn RFECV\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = RFECV(\n    estimator=regressor, step=1, cv=3, min_features_to_select=10, n_jobs=-1\n)\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster      = forecaster,\n    selector        = selector,\n    y               = data[\"users\"],\n    exog            = data.drop(columns=\"users\"),\n    select_only     = 'exog',\n    force_inclusion = [\"noise\"],\n    subsample       = 0.5,\n    verbose         = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Examining Categorical Encoding Mappings in Python\nDESCRIPTION: Displays the encoding mapping between original categories and their integer codes for each categorical feature. This helps understand how the ordinal encoder has transformed categorical values to integers for the model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Show the encoding applied to the categorical features\n# ==============================================================================\nordinal_encoder = transformer_exog.named_transformers_['ordinalencoder']\nfor feature, cats in zip(categorical_features, ordinal_encoder.categories_):\n    print(f\"Feature '{feature}' categories and codes:\")\n    for code, category in enumerate(cats):\n        print(f\"  {category}: {code}\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Grid Search Results\nDESCRIPTION: Outputs the results of the grid search, showing the performance metrics for different hyperparameter and lag combinations.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Grid results\n# ==============================================================================\nresults_grid\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Time Series Data for Testing\nDESCRIPTION: Loads sample building consumption data from a parquet file and prepares training and testing datasets. Creates both DataFrame and dictionary representations of the time series and exogenous variables for testing different input formats.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Load time series same length\n# ==============================================================================\ndata = pd.read_parquet(\"../fixtures/sample_building_consumption.parquet\")\ndata = data.asfreq(\"D\")\nseries = data[[\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"]]\nexog = data[[\"sin_day_of_week\", \"cos_day_of_week\", \"air_temperature\", \"wind_speed\"]]\n\nend_train = \"2016-10-31 23:59:00\"\nseries_train = series.loc[:end_train, :].copy()\nexog_train = exog.loc[:end_train, :].copy()\nseries_test = series.loc[end_train:, :].copy()\nexog_test = exog.loc[end_train:, :].copy()\n\nseries_dict = series.to_dict(orient=\"series\")\nexog_dict = {k: exog for k in series.columns}\nseries_dict_train = series_train.to_dict(orient=\"series\")\nexog_dict_train = {k: exog_train for k in series.columns}\nseries_dict_test = series_test.to_dict(orient=\"series\")\nexog_dict_test = {k: exog_test for k in series.columns}\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices Using Skforecast in Python\nDESCRIPTION: Illustrates how to create the training matrices required for model training using Skforecast. It involves transforming the data into matrices suitable for fitting the forecasting model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Create training matrices\n# ==============================================================================\nX_train, y_train = forecaster.create_train_X_y(\n                       y    = data.loc[:end_train, 'users'],\n                       exog = data.loc[:end_train, exog_features]\n                   )\n\nprint(X_train.dtypes)\nX_train.head()\n```\n\n----------------------------------------\n\nTITLE: Initiating Recursive Time Series Forecaster with Custom Weights in Python\nDESCRIPTION: Initializes a ForecasterRecursive with a Ridge regressor, using custom weights to handle anomalies. It configures weighting to reduce the impact of specific data points during model training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Create a recursive multi-step forecaster (ForecasterRecursive)\n# ==============================================================\nforecaster = ForecasterRecursive(\n                 regressor   = Ridge(random_state=123),\n                 lags        = 21,\n                 weight_func = custom_weights\n             )\n```\n\n----------------------------------------\n\nTITLE: Initializing and Fitting the Recursive Multi-Series Forecaster\nDESCRIPTION: Creates a ForecasterRecursiveMultiSeries instance with LGBMRegressor as the underlying model and 48 lag features. Fits the model to the previously created synthetic time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor = LGBMRegressor(verbose=-1),\n    lags     = 48\n)\n\nforecaster.fit(series=series, store_in_sample_residuals=False)\n```\n\n----------------------------------------\n\nTITLE: Plot Predictions with Train, Last Window, and Test Data\nDESCRIPTION: This code snippet generates a plot that visualizes the training data, the last window data, the test data, and the model's predictions. The plot helps to assess the model's performance and identify any discrepancies between the predicted and actual values. It requires matplotlib to be imported as plt.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train['y'].plot(ax=ax, label='train')\ndata_last_window['y'].plot(ax=ax, label='last window')\ndata_test['y'].plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Loaded Forecaster\nDESCRIPTION: This snippet shows how to make predictions using a loaded forecaster model. It predicts the specified number of steps using the forecaster loaded from a joblib file.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ============================================================================== \nforecaster_loaded.predict(steps=3)\n```\n\n----------------------------------------\n\nTITLE: External Differentiation Preprocessing\nDESCRIPTION: Implements time series forecasting using external differentiation preprocessing with RandomForestRegressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndiferenciator = TimeSeriesDifferentiator(order=1)\ndata_diff = diferenciator.fit_transform(data.to_numpy())\ndata_diff = pd.Series(data_diff, index=data.index).dropna()\n\nforecaster = ForecasterRecursive(\n                 regressor = RandomForestRegressor(random_state=963),\n                 lags      = 15\n             )\nforecaster.fit(y=data_diff.loc[:end_train])\npredictions_diff = forecaster.predict(steps=steps)\n\n# Revert differentiation to obtain final predictions\nlast_value_train = data.loc[:end_train].iloc[[-1]]\npredictions_1 = pd.concat([last_value_train, predictions_diff]).cumsum()[1:]\npredictions_1 = predictions_1.asfreq('MS')\npredictions_1.name = 'pred'\npredictions_1.head(5)\n```\n\n----------------------------------------\n\nTITLE: Initialize and Fit Forecaster with Scaled Input Series in Python\nDESCRIPTION: This code initializes a ForecasterRecursive with the Ridge regression model, sets a lag, and applies a StandardScaler to the target series 'y'. It fits the forecaster using the provided exogenous data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Create and fit forecaster that scales the input series\n# ==============================================================================\\nforecaster = ForecasterRecursive(\\n                 regressor        = Ridge(random_state=123),\\n                 lags             = 3,\\n                 transformer_y    = StandardScaler(),\\n                 transformer_exog = None\\n             )\\n\\nforecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2']])\\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Create and Train XGBoost Forecaster (Version < 2.0)\nDESCRIPTION: Creates and trains an `XGBRegressor` model within a `ForecasterRecursive` object, configuring it to use the GPU if available. For XGBoost versions older than 2.0, the `tree_method` is set to `'gpu_hist'` and `gpu_id` is set to `0` to enable GPU usage. The forecaster is then fitted to the generated data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Create and train forecaster with a XGBRegressor using GPU\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = XGBRegressor(\n                                 n_estimators = 5000,\n                                 tree_method  = 'gpu_hist',\n                                 gpu_id       = 0\n                             ),\n                 lags = 20\n             )\n\nforecaster.fit(y=data)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Multi-Series Forecasting in Python\nDESCRIPTION: Imports the necessary Python libraries for multi-series forecasting, including numpy, pandas, matplotlib, sklearn components, LGBMRegressor, and skforecast modules for dataset handling, preprocessing, recursive forecasting, model selection, and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom lightgbm import LGBMRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection import (\n    TimeSeriesFold,\n    backtesting_forecaster_multiseries,\n    grid_search_forecaster_multiseries,\n    bayesian_search_forecaster_multiseries\n)\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Training Forecaster with Selected Features in Python\nDESCRIPTION: This code snippet trains a ForecasterRecursive model using the features selected in the previous step. It initializes a `RollingFeatures` object for window feature generation. The Forecaster is then fitted using the target variable (`y`) and the selected exogenous variables (`selected_exog`).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"# Train forecaster with selected features\n# ==============================================================================\nnew_window_features = RollingFeatures(\n                          stats        = ['mean'],\n                          window_sizes = 24\n                      )\n\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(\n                                       n_estimators = 900,\n                                       random_state = 15926,\n                                       max_depth    = 7,\n                                       verbose      = -1\n                                   ),\n                 lags            = selected_lags,\n                 window_features = new_window_features\n             )\n\nforecaster.fit(y=data[\"users\"], exog=data[selected_exog])\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Basic Calendar Features in Python\nDESCRIPTION: This code extracts basic calendar features such as year, month, day of the week, and hour from the datetime index of the dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create calendar features\n# ==============================================================================\ndata['year'] = data.index.year\ndata['month'] = data.index.month\ndata['day_of_week'] = data.index.dayofweek\ndata['hour'] = data.index.hour\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Calibrating Under-conservative Intervals\nDESCRIPTION: Applies conformal calibration to under-conservative intervals using ConformalIntervalCalibrator, then visualizes and validates the results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncalibrator = ConformalIntervalCalibrator(nominal_coverage=0.8, symmetric_calibration=False)\ncalibrator.fit(y_true=y_true, y_pred_interval=interval)\nprint(calibrator)\n\ninterval_calibrated = calibrator.transform(interval)\nfig, ax = plt.subplots(figsize=(7, 3.5))\ninterval.plot(ax=ax, linestyle=\"--\")\ninterval_calibrated[\"lower_bound\"].plot(ax=ax, color=\"#30a2da\", label=\"Calibrated lower bound\")\ninterval_calibrated[\"upper_bound\"].plot(ax=ax, color=\"#fc4f30\", label=\"Calibrated upper bound\")\ny_true.plot(ax=ax, label=\"True values\")\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=4)\nplt.show()\n\ncoverage = calculate_coverage(\n               y_true      = y_true,\n               lower_bound = interval_calibrated[\"lower_bound\"],\n               upper_bound = interval_calibrated[\"upper_bound\"],\n           )\nprint(f\"Coverage after calibration: {coverage:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Making Training Predictions with Multi-Series Forecaster\nDESCRIPTION: This snippet demonstrates how to use the internal regressor of a multi-series forecaster to make predictions on the training data, which helps evaluate model performance on known data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Training predictions using the internal regressor\n# ==============================================================================\npredictions_training = forecaster.regressor.predict(X_train)\npredictions_training[:4]\n```\n\n----------------------------------------\n\nTITLE: Setting Different Lags for Each Time Series in Python\nDESCRIPTION: This code creates a MultiVariate forecaster with custom lags for each time series by utilizing a dictionary structure for the lags parameter.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nlags_dict = {\n    'so2': [7, 14], 'co': 7, 'no': [7, 14], 'no2': [7, 14],\n    'pm10': [7, 14], 'nox': [7, 14], 'o3': [7, 14], 'veloc.': 3,\n    'direc.': 3, 'pm2.5': [7, 14]\n}\nforecaster = ForecasterDirectMultiVariate(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 level     = 'co',\n                 steps     = 7,\n                 lags      = lags_dict,\n             )\n\nforecaster.fit(series=data_train)\n\npredictions = forecaster.predict(steps=7)\npredictions\n```\n\n----------------------------------------\n\nTITLE: Setting Up Forecasting Intervals for Unknown Series\nDESCRIPTION: Configures forecaster to store in-sample residuals for interval prediction of unknown series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = 'ordinal'\n             )\n\nforecaster.fit(series=data_train, store_in_sample_residuals=True)\n\n# Number of in-sample residuals by bin\n# ==============================================================================\nfor k, v in forecaster.in_sample_residuals_.items():\n    print(f\"Residuals for {k}: n={len(v)}\")\n```\n\n----------------------------------------\n\nTITLE: Grid Search Multi-Series Forecaster Configuration\nDESCRIPTION: Define lags and parameter grid for hyperparameter tuning across multiple time series levels using grid search\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nlags_grid = {\n    '24 lags': 24,\n    '48 lags': 48\n}\n\nparam_grid = {\n    'n_estimators': [10, 20],\n    'max_depth': [3, 7]\n}\n\nlevels = ['item_1', 'item_2', 'item_3']\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Forecaster Using Exogenous Variables\nDESCRIPTION: Generates predictions for 3 future time steps using the fitted forecaster with exogenous variables from the test dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Time Series Differencing with sktime and skforecast\nDESCRIPTION: Demonstrates first-order differencing of time series data using both sktime's Differencer and skforecast's TimeSeriesDifferentiator classes. The code shows equivalent implementations and verifies matching results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sktime-pipelines.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# sktime\ntransformer_sktime = Differencer(lags=1)\ny_hat_sktime = transformer_sktime.fit_transform(data_train['litters'])[1:]\n\n# skforecast\ntransformer_skforecast = TimeSeriesDifferentiator(order=1)\ny_hat_skforecast = transformer_skforecast.fit_transform(data_train['litters'].to_numpy())[1:]\n\nnp.testing.assert_allclose(y_hat_sktime, y_hat_skforecast)\n```\n\n----------------------------------------\n\nTITLE: ForecasterRecursive Performance Testing Workflow\nDESCRIPTION: Executes performance tests for different forecasting methods, measuring elapsed time for fitting, creating training data, backtesting, and grid search across parallel and sequential modes\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor regressor, param_grid in zip(regressors, param_grids):\n    forecaster = ForecasterRecursive(\n        regressor        = regressor,\n        lags             = lags,\n        transformer_exog = StandardScaler()\n    )\n    # Performance profiling for various methods\n    # fit, create_train_X_y, backtesting, grid search\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices to Identify Feature Positions\nDESCRIPTION: Generates training matrices using a small sample of data to identify the positions and types of features after transformation. This helps determine which features should be marked as categorical in XGBoost.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n# Create training matrices using a sample of the training data\n# ==============================================================================\nX_train, y_train = forecaster.create_train_X_y(\n                       y    = data.loc[:end_train, 'users'][:10],\n                       exog = data.loc[:end_train, exog_features][:10]\n                   )\nX_train.head(2)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preprocessing Time Series Data - Python\nDESCRIPTION: This snippet demonstrates how to download a dataset from a URL, preprocess the data by parsing dates, and prepare it for training and testing in a forecasting context. It also prints the date ranges for training and testing sets.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\n# Download data\\n# ==============================================================================\\nurl = (\\n    'https://raw.githubusercontent.com/JoaquinAmatRodrigo/Estadistica-machine-learning-python/'\\n    'master/data/AirPassengers.csv'\\n)\\ndata = pd.read_csv(url, sep=',')\\n\\n# Data preprocessing\\n# ==============================================================================\\ndata['Date'] = pd.to_datetime(data['Date'], format='%Y-%m')\\ndata = data.set_index('Date')\\ndata = data.asfreq('MS')\\ndata = data['Passengers']\\ndata = data.sort_index()\\ndata.head(4)\\n\\n# Data partition train-test\\n# ==============================================================================\\nend_train = '1956-12-01 23:59:59'\\nprint(\\n    f\"Train dates : {data.index.min()} --- {data.loc[:end_train].index.max()}  \" \\n    f\"(n={len(data.loc[:end_train])})\")\\nprint(\\n    f\"Test dates  : {data.loc[end_train:].index.min()} --- {data.index.max()}  \"\\n    f\"(n={len(data.loc[end_train:] )})\")\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Generating Predictions with ForecasterEquivalentDate\nDESCRIPTION: Makes forecasts for the test period using the trained ForecasterEquivalentDate model and displays the first few predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=len(data_test))\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Forecasting with skforecast ARIMA Model in Python\nDESCRIPTION: This snippet shows how to make predictions using the fitted ARIMA model from skforecast. It forecasts 12 steps ahead and displays the first 4 predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Prediction\n# ==============================================================================\npredictions = arima.predict(steps=12)\npredictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data into Train and Test Sets in Python\nDESCRIPTION: Splits the complete time series dataset into training and testing subsets. The training set covers dates up to end of 2013, while the test set contains data from 2014 onward.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Split data into train-val-test\n# =================================================\ndata = data.loc['2012-01-01 00:00:00': '2014-12-30 23:00:00']\nend_train = '2013-12-31 23:59:00'\ndata_train = data.loc[: end_train, :]\ndata_test  = data.loc[end_train:, :]\n\nprint(\n    f\"Dates train : {data_train.index.min()} --- {data_train.index.max()}   \"\n    f\"(n={len(data_train)})\"\n)\nprint(\n    f\"Dates test  : {data_test.index.min()} --- {data_test.index.max()}   \"\n    f\"(n={len(data_test)})\"\n)\n```\n\n----------------------------------------\n\nTITLE: Plotting Predictions of Energy Production in Python\nDESCRIPTION: Plots the test data alongside backtest predictions to visualize forecast accuracy. This is helpful for assessing model performance and adjustments.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Predictions plot\n# =================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_test['production'].plot(ax=ax, label='test', linewidth=1)\npredictions_backtest.plot(ax=ax, label='predictions', linewidth=1)\nax.set_title('Energy production')\nax.set_xlabel(\"\")\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Recursive Forecasting in Python\nDESCRIPTION: Imports necessary Python libraries for time series forecasting including pandas for data manipulation, matplotlib for visualization, LGBMRegressor from lightgbm as the ML model, and various modules from skforecast for forecasting functionality.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.plot import plot_prediction_intervals, set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Extracting Feature Importances from Models with Exogenous Variables in Python\nDESCRIPTION: Retrieves the importance values for both lag features and exogenous variables from the trained forecaster to understand their relative impact on predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Feature importances with exogenous variables\n# ==============================================================================\nforecaster.get_feature_importances()\n```\n\n----------------------------------------\n\nTITLE: Summarizing and Visualizing Forecasting Benchmark Results in Python\nDESCRIPTION: Function for summarizing and visualizing benchmark results between different forecasting approaches. It creates comparison tables and optional plots showing execution time and accuracy metrics side by side.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef summarize_results(results, metric, title, plot=True, save_plot=None, fig_size=(8, 4)):\n    \"\"\"\n    Summarize results of benchmark.\n    \"\"\"\n\n    results = pd.DataFrame(\n        results,\n        columns=[\n            \"dataset\",\n            \"forecaster\",\n            \"time_search_backtesting\",\n            \"time_search_one_step\",\n            \"metric_backtesting\",\n            \"metric_one_step\",\n        ]\n    )\n    results['ratio_speed'] = (\n        results['time_search_backtesting'] / results['time_search_one_step']\n    ).round(2)\n    results['ratio_metric'] = (\n        results['metric_backtesting'] / results['metric_one_step']\n    ).round(2)\n    results[\"dataset_forecaster\"] = (\n        results[\"dataset\"]\n        + \" \\n \"\n        + results[\"forecaster\"].str.replace(\"Forecaster\", \"\")\n    )\n    display(results)\n\n    if plot:\n        set_dark_theme()\n        fig, axs = plt.subplots(2, 1, figsize=fig_size, sharex=True)\n        results.plot.bar(\n            x='dataset_forecaster',\n            y=['time_search_backtesting', 'time_search_one_step'],\n            ax=axs[0],\n        )\n        axs[0].set_ylabel('time (s)')\n        axs[0].legend([\"backtesting\", \"one-step-ahead\"])\n        results.plot.bar(\n            x='dataset_forecaster',\n            y=['metric_backtesting', 'metric_one_step'],\n            ax=axs[1],\n            legend=False\n        )\n        axs[1].set_ylabel(f'{metric}')\n        axs[1].set_xlabel('')\n        plt.xticks(rotation=90)\n        plt.suptitle(title)\n        plt.tight_layout()\n\n        if save_plot:\n            plt.savefig(save_plot, dpi=300, bbox_inches='tight')\n```\n\n----------------------------------------\n\nTITLE: Testing ForecasterRecursiveMultiSeries Predictions with Various Encodings\nDESCRIPTION: Tests the prediction and prediction_interval methods of ForecasterRecursiveMultiSeries using different encoding strategies and input formats. Verifies that predictions are consistent regardless of whether inputs are provided as DataFrames or dictionaries.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Test predictions\n# ==============================================================================\nparams = {\n    \"encoding\": [\"ordinal\", \"onehot\", \"ordinal_category\"],\n    \"interval\": [[5, 95]],\n    \"n_boot\": [10],\n}\n\nparams_grid = list(ParameterGrid(params))\n\nfor params in tqdm(params_grid):\n    print(f\"Paramns: {params}\")\n\n    steps = 10\n    forecaster = ForecasterRecursiveMultiSeries(\n        regressor=LinearRegression(),\n        lags=14,\n        encoding=params[\"encoding\"],\n        dropna_from_series=False,\n        transformer_series=StandardScaler(),\n        transformer_exog=StandardScaler(),\n    )\n\n    forecaster.fit(series=series_train, exog=exog_train)\n    predictions_1 = forecaster.predict(steps=steps, exog=exog_test)\n    predictions_1_interval = forecaster.predict_interval(\n        steps=steps,\n        exog=exog_test,\n        interval=params[\"interval\"],\n        n_boot=params[\"n_boot\"],\n    )\n\n    forecaster.fit(series=series_train, exog=exog_dict_train)\n    predictions_2 = forecaster.predict(steps=steps, exog=exog_dict_test)\n    predictions_2_interval = forecaster.predict_interval(\n        steps=steps,\n        exog=exog_dict_test,\n        interval=params[\"interval\"],\n        n_boot=params[\"n_boot\"],\n    )\n\n    forecaster.fit(series=series_dict_train, exog=exog_dict_train)\n    predictions_3 = forecaster.predict(steps=steps, exog=exog_dict_test)\n    predictions_3_interval = forecaster.predict_interval(\n        steps=steps,\n        exog=exog_dict_test,\n        interval=params[\"interval\"],\n        n_boot=params[\"n_boot\"],\n    )\n\n    pd.testing.assert_frame_equal(predictions_1, predictions_2)\n    pd.testing.assert_frame_equal(predictions_1, predictions_3)\n    pd.testing.assert_frame_equal(predictions_1_interval, predictions_2_interval)\n    pd.testing.assert_frame_equal(predictions_1_interval, predictions_3_interval)\n```\n\n----------------------------------------\n\nTITLE: Creating XGBoost Forecaster with Categorical Support\nDESCRIPTION: Instantiates a ForecasterRecursive using XGBRegressor with categorical feature support enabled through the enable_categorical parameter. This initial forecaster doesn't yet specify which features are categorical.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n# Create forecaster\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor = XGBRegressor(\n                                 tree_method        = 'hist',\n                                 random_state       = 12345,\n                                 enable_categorical = True,\n                             ),\n                 lags = 5,\n                 transformer_exog = transformer_exog\n             )\n```\n\n----------------------------------------\n\nTITLE: Making Step-Wise Predictions with Internal Regressor in Python\nDESCRIPTION: This snippet uses the ForecasterDirect model's internal regressor to make predictions for a specified step. It helps assess the accuracy and reliability of forecasts generated for each step.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Step 1 predictions using the internal regressor\n# ============================================================================== \npredictions = forecaster.regressors_[1].predict(X_predict)\npredictions\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Time Series Data for Forecasting\nDESCRIPTION: Fetches a fuel consumption dataset, prepares it for analysis by renaming columns and setting date index, then splits it into training and testing sets. Includes visualization of the split dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ======================================================================================\ndata = fetch_dataset('fuel_consumption')\ndata = data.rename(columns={'Gasolinas': 'litters'})\ndata.index.name = 'date'\ndata = data.loc[:'1985-01-01 00:00:00', 'litters']\ndisplay(data.head(4))\n\n# Train-test dates\n# ======================================================================================\nend_train = '1980-01-01 23:59:59'\ndata_train = data.loc[:end_train]\ndata_test  = data.loc[end_train:]\n\nprint(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\nprint(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n\n# Plot\n# ======================================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\nax.set_title('Monthly fuel consumption in Spain')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing Time Series Data with Exogenous Variables in Python\nDESCRIPTION: Downloads a dataset containing both a target variable and exogenous predictors, sets the index name to 'datetime', and creates a visualization of the data using matplotlib with dark theme.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(name='h2o_exog', raw=False)\ndata.index.name = 'datetime'\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3.5))\ndata.plot(ax=ax)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Running Backtesting with Different Refit Strategies\nDESCRIPTION: Performs backtesting of the forecaster with different refit strategies (False, True, 7, 14, 30) and measures execution time and forecast accuracy. The backtesting predicts 24 steps ahead using historical electricity demand data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrefits = [7, 14, 30]\nrefits = [False, True] + refits\nresults = []\nmetrics = []\n\nfor refit in refits:\n    tic = time.perf_counter()\n\n    metric, predictions = backtesting_forecaster(\n                            forecaster            = forecaster,\n                            y                     = data['Demand'],\n                            steps                 = 24,\n                            metric                = 'mean_absolute_error',\n                            initial_train_size    = 17482,\n                            fixed_train_size      = False,\n                            refit                 = refit,\n                            verbose               = False,\n                            show_progress         = False  \n                        )\n\n    toc = time.perf_counter()\n    results.append(toc-tic)\n    metrics.append(metric)\n\nresults = pd.DataFrame(\n              data =  {'refit value': refits, \n                       'execution time (s)': results, \n                       'metric': metrics},\n          )\n\nresults = results.sort_values(by=['seconds'])\nresults\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Train, Validation, and Test Sets in Python\nDESCRIPTION: In this snippet, the dataset is split into training, validation, and test sets based on specific date ranges. It also prints the date ranges and the number of instances in each set, which is crucial for evaluating the model's performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Split train-validation-test\n# ============================================================================== \nexog_features = data.columns.difference(['OT']).tolist()\nend_train = '2017-10-01 23:59:00'\nend_validation = '2018-04-03 23:59:00'\ndata_train = data.loc[: end_train, :]\ndata_val   = data.loc[end_train:end_validation, :]\ndata_test  = data.loc[end_validation:, :]\n\nprint(f\"Dates train      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\nprint(f\"Dates validation : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\nprint(f\"Dates test       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n```\n\n----------------------------------------\n\nTITLE: Configuring ForecasterDirect with Ridge for Website Visits Forecasting\nDESCRIPTION: Sets up a ForecasterDirect model with Ridge regression to forecast website visits 7 steps ahead. Uses StandardScaler for target transformation and performs Bayesian hyperparameter optimization to find optimal alpha and lag values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Dataset website_visits - ForecasterDirect\n# ==============================================================================\nforecaster = ForecasterDirect(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 lags          = 10,\n                 steps         = 7\n             )\n\nlags_grid = [7, 14, 21, [7, 14, 21]]\n\n\ndef search_space(trial):\n    search_space  = {\n        'alpha': trial.suggest_float('alpha', 0.001, 1000, log=True),\n        'lags' : trial.suggest_categorical('lags', lags_grid)\n    } \n    \n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_website,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 7,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'website',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Predict with Exogenous Variables using ForecasterSarimax\nDESCRIPTION: This code snippet shows how to use a trained `ForecasterSarimax` object to make predictions for a specified number of steps, incorporating exogenous variables. The `predict` method generates forecasts based on the provided steps and the future values of the exogenous variables (`exog`).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npredictions = forecaster.predict(\n                  steps = 36,\n                  exog  = data_test[['exog_1', 'exog_2']]\n              )\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Implementing Ordinal Category Encoding\nDESCRIPTION: Creates a ForecasterRecursiveMultiSeries with ordinal_category encoding using LGBMRegressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = 'ordinal_category'\n             )\n\nX, y = forecaster.create_train_X_y(series=data_train)\n\ndisplay(X.head(3))\nprint(\"\")\nprint(X.dtypes)\nprint(\"\")\nprint(X['_level_skforecast'].value_counts())\n```\n\n----------------------------------------\n\nTITLE: Implementing OneHot Encoding\nDESCRIPTION: Configures ForecasterRecursiveMultiSeries with onehot encoding using LGBMRegressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = 'onehot'\n             )\n\nX, y = forecaster.create_train_X_y(series=data_train)\n\ndisplay(X.head(3))\nprint(\"\")\nprint(X.dtypes)\nprint(\"\")\nprint(X['item_1'].value_counts())\n```\n\n----------------------------------------\n\nTITLE: Creating Training Data for Multi-Series Forecasting in Python\nDESCRIPTION: This code defines the '_create_train_X_y' method to generate training matrices for multiple time series with optional exogenous variables. The method considers various input formats, including pandas DataFrames and dictionaries, to accommodate flexibility in data representation. It incorporates both serial and parallel processing options, returning the matrices required for training time series forecasting models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/paralel_create_train_X_y.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef _create_train_X_y(\n        self,\n        series: Union[pd.DataFrame, dict],\n        exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None,\n        store_last_window: Union[bool, list]=True,\n        parallel: bool=False\n    ) -> Tuple[pd.DataFrame, pd.Series, dict, list, list, list, dict, dict]:\n        \"\"\"\n        Create training matrices from multiple time series and exogenous\n        variables. See Notes section for more details depending on the type of\n        `series` and `exog`.\n        \n        Parameters\n        ----------\n        series : pandas DataFrame, dict\n            Training time series.\n        exog : pandas Series, pandas DataFrame, dict, default `None`\n            Exogenous variable/s included as predictor/s.\n        store_last_window : bool, list, default `True`\n            Whether or not to store the last window of training data.\n\n            - If `True`, last_window is stored for all series. \n            - If `list`, last_window is stored for the series present in the list.\n            - If `False`, last_window is not stored.\n\n        Returns\n        -------\n        X_train : pandas DataFrame\n            Training values (predictors).\n        y_train : pandas Series\n            Values (target) of the time series related to each row of `X_train`.\n        series_indexes : dict\n            Dictionary with the index of each series.\n        series_col_names : list\n            Names of the series (levels) provided by the user during training.\n        series_X_train : list\n            Names of the series (levels) included in the matrix `X_train` created\n            internally for training. It can be different from `series_col_names` if\n            some series are dropped during the training process because of NaNs or\n            because they are not present in the training period.\n        exog_col_names : list\n            Names of the exogenous variables used during training.\n        exog_dtypes : dict\n            Type of each exogenous variable/s used in training. If `transformer_exog` \n            is used, the dtypes are calculated before the transformation.\n        last_window : dict\n            Last window of training data for each series. It stores the values \n            needed to predict the next `step` immediately after the training data.\n\n        Notes\n        -----\n        - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n        DataFrame, each exog is duplicated for each series. Exog must have the\n        same index as `series` (type, length and frequency).\n        - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n        or DataFrames. Each key in `exog` must be a column in `series` and the \n        values are the exog for each series. Exog must have the same index as \n        `series` (type, length and frequency).\n        - If `series` is a dict of pandas Series, `exog` must be a dict of pandas\n        Series or DataFrames. The keys in `series` and `exog` must be the same.\n        All series and exog must have a pandas DatetimeIndex with the same \n        frequency.\n        \n        \"\"\"\n\n        series_dict, series_indexes = check_preprocess_series(series=series)\n        input_series_is_dict = isinstance(series, dict)\n        series_col_names = list(series_dict.keys())\n\n        if self.fitted and not (series_col_names == self.series_col_names):\n            raise ValueError(\n                (f\"Once the Forecaster has been trained, `series` must have the \"\n                 f\"same columns as the series used during training:\\n\" \n                 f\" Got      : {series_col_names}\\n\"\n                 f\" Expected : {self.series_col_names}\")\n            )\n\n        exog_dict = {serie: None for serie in series_col_names}\n        exog_col_names = None\n        if exog is not None:\n            exog_dict, exog_col_names = check_preprocess_exog_multiseries(\n                                            input_series_is_dict = input_series_is_dict,\n                                            series_indexes       = series_indexes,\n                                            series_col_names     = series_col_names,\n                                            exog                 = exog,\n                                            exog_dict            = exog_dict\n                                        )\n\n            if self.fitted:\n                if self.exog_col_names is None:\n                    raise ValueError(\n                        (\"Once the Forecaster has been trained, `exog` must be `None` \"\n                         \"because no exogenous variables were added during training.\")\n                    )\n                else:\n                    if not set(exog_col_names) == set(self.exog_col_names):\n                        raise ValueError(\n                            (f\"Once the Forecaster has been trained, `exog` must have the \"\n                             f\"same columns as the series used during training:\\n\" \n                             f\" Got      : {exog_col_names}\\n\"\n                             f\" Expected : {self.exog_col_names}\")\n                        )\n\n        if not self.fitted:\n            self.transformer_series_ = initialize_transformer_series(\n                                           series_col_names = series_col_names,\n                                           transformer_series = self.transformer_series\n                                       )\n\n        if self.differentiation is None:\n            self.differentiator_ = {serie: None for serie in series_col_names}\n        else:\n            if not self.fitted:\n                self.differentiator_ = {serie: clone(self.differentiator) \n                                        for serie in series_col_names}\n\n        series_dict, exog_dict = align_series_and_exog_multiseries(\n                                     series_dict          = series_dict,\n                                     input_series_is_dict = input_series_is_dict,\n                                     exog_dict            = exog_dict\n                                 )\n\n        ignore_exog = True if exog is None else False\n        input_matrices = [\n            [series_dict[k], exog_dict[k], ignore_exog]\n             for k in series_dict.keys()\n        ]\n\n        if not parallel:\n            # ======================================================================\n            X_train_lags_buffer = []\n            X_train_exog_buffer = []\n            y_train_buffer = []\n            for matrices in input_matrices:\n\n                X_train_lags, X_train_exog, y_train = (\n                    self._create_train_X_y_single_series(\n                        y           = matrices[0],\n                        exog        = matrices[1],\n                        ignore_exog = matrices[2],\n                    )\n                )\n\n                X_train_lags_buffer.append(X_train_lags)\n                X_train_exog_buffer.append(X_train_exog)\n                y_train_buffer.append(y_train)\n            # ======================================================================\n        else:\n            def process_matrices(matrices):\n                return self._create_train_X_y_single_series(\n                            y           = matrices[0],\n                            exog        = matrices[1],\n                            ignore_exog = matrices[2],\n                        )\n\n            results = Parallel(n_jobs=-1)(delayed(process_matrices)(matrices) for matrices in input_matrices)\n            X_train_lags_buffer, X_train_exog_buffer, y_train_buffer = zip(*results)\n\n        X_train = pd.concat(X_train_lags_buffer, axis=0)\n        y_train = pd.concat(y_train_buffer, axis=0)\n\n        if self.fitted:\n            encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n        else:\n            encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n            for i, code in enumerate(self.encoder.categories_[0]):\n                self.encoding_mapping[code] = i\n\n        X_train = pd.concat([\n                      X_train.drop(columns='_level_skforecast'),\n                      encoded_values\n                  ], axis=1)\n\n        if self.encoding == 'onehot':\n            X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n        elif self.encoding == 'ordinal_category':\n            X_train['_level_skforecast'] = (\n                X_train['_level_skforecast'].astype('category')\n            )\n\n        del encoded_values\n\n        exog_dtypes = None\n        if exog is not None:\n\n            X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n```\n\n----------------------------------------\n\nTITLE: Comparing Training Matrices with Complete vs. Incomplete Exogenous Data in Python\nDESCRIPTION: Verifies that training matrices created with complete exogenous data are identical to those created with exogenous data missing in the initial window_size observations, confirming the models are equivalent.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Check training matrices are the same with both methods\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 15\n             )\n\nX_train_full_exog, y_train_full_exog = forecaster.create_train_X_y(\n    y    = data_train['y'],\n    exog = data_train[['exog_1', 'exog_2']]\n)\n\nX_train_no_full_exog, y_train_no_full_exog = forecaster.create_train_X_y(\n    y    = data_train['y'],\n    exog = exog_no_first_window_size[['exog_1', 'exog_2']]\n)\n\npd.testing.assert_frame_equal(X_train_full_exog, X_train_no_full_exog)\npd.testing.assert_series_equal(y_train_full_exog, y_train_no_full_exog)\n```\n\n----------------------------------------\n\nTITLE: Saving a Forecaster Model\nDESCRIPTION: This snippet shows how to save a trained forecaster model to a file using the save_forecaster function. The model is saved as a joblib file with an optional verbose output.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Save model\n# ============================================================================== \nsave_forecaster(forecaster, file_name='forecaster_001.joblib', verbose=False)\n```\n\n----------------------------------------\n\nTITLE: Plotting Data Partitions in Python\nDESCRIPTION: This snippet uses matplotlib to create a visual representation of the training, validation, and test data partitions. It sets the dark theme for the plot and adjusts various plot parameters to visualize the oil temperature data effectively.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Plot partitions\n# ============================================================================== \nset_dark_theme()\nplt.rcParams['lines.linewidth'] = 0.5\nfig, ax = plt.subplots(figsize=(8, 3))\nax.plot(data_train['OT'], label='Train')\nax.plot(data_val['OT'], label='Validation')\nax.plot(data_test['OT'], label='Test')\nax.set_title('Oil Temperature')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterRecursive with Skforecast in Python\nDESCRIPTION: This code creates and fits a ForecasterRecursive object using Skforecast with specified window features and an LGBMRegressor. The forecaster is fitted on the series' target variable. This setup is crucial for recursive predictions and model evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ============================================================================== \nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'sum'],\n                      window_sizes = [5, 5]\n                  )\n\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 5,\n                 window_features = window_features\n             )\n\nforecaster.fit(y=data['y'])\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Time Series Data with Datetime Index in Python\nDESCRIPTION: Fetches the h2o dataset, converts the date column to datetime format, sets it as the index, and assigns a monthly start frequency to the time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/input-data.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"date\"], \"header\": 0}\n)\ndata[\"date\"] = pd.to_datetime(data[\"date\"], format=\"%Y-%m-%d\")\ndata = data.set_index(\"date\")\ndata = data.asfreq(\"MS\")\ndata\n```\n\n----------------------------------------\n\nTITLE: Retrieving Feature Importances\nDESCRIPTION: Example of getting feature importance for a specific prediction step from the multivariate forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nforecaster.get_feature_importances(step=1)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Automatic Categorical Feature Detection\nDESCRIPTION: Generates predictions for 3 future time steps using the forecaster that automatically detects categorical features from data types.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Merging Time Series with Exogenous Variables\nDESCRIPTION: Creates time series data and exogenous variables with daily frequency, then merges them based on the datetime index. This demonstrates how to incorporate external variables into time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nseries_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_1')\nseries_2 = pd.Series([20, 30, 40, 50, 60, 70, 80, 90, 100, 110], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_2')\nseries = pd.concat([series_1, series_2], axis=1).melt(var_name='series', value_name='value', ignore_index=False)\nseries = series.rename_axis('datetime')\nseries = series.groupby('series').apply(lambda x: x.asfreq('D'), include_groups=False)\nseries\n\nexog = pd.DataFrame({\n    'exog_1': [1, 2, 3, 4, 5, 6, 7, 8],\n    'exog_2': [10, 20, 30, 40, 50, 60, 70, 80]\n}, index=pd.date_range(start='2000-01-01', periods=8, freq='D'))\nexog = exog.rename_axis('datetime')\n\n# merge series and exog\nseries_exog = pd.merge(series, exog, left_index=True, right_index=True, how='left')\nseries_exog\n```\n\n----------------------------------------\n\nTITLE: Predicting Intervals with In-Sample Residuals in Python\nDESCRIPTION: This code snippet predicts intervals based on in-sample residuals from the training data. It utilizes a specified random state to ensure reproducibility.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nforecaster.set_in_sample_residuals(series=data_train)\npredictions = forecaster.predict_interval(random_state=9871)\npredictions\n```\n\n----------------------------------------\n\nTITLE: Creating Training Predictions with Transformations in ForecasterDirect\nDESCRIPTION: This snippet shows how to generate training matrices, extract data for a specific step, make predictions, and revert transformations in a ForecasterDirect model. It focuses specifically on predictions for step 1.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Training predictions with transformations\n# ==============================================================================\nX_train_transformed, y_train_transformed = forecaster.create_train_X_y(y=data['y'])\n\n# Extract X and y for step 1\nX_train_transformed_1, y_train_transformed_1 = forecaster.filter_train_X_y_for_step(\n                                                   step          = 1,\n                                                   X_train       = X_train_transformed,\n                                                   y_train       = y_train_transformed,\n                                                   remove_suffix = False\n                                               )\n\n# Training predictions using the internal regressor for step 1\npredictions_transformed = forecaster.regressors_[1].predict(X_train_transformed_1)\n\n# Revert differentiation (only if differentiation is not None)\npredictions_transformed = forecaster.differentiator.inverse_transform_training(predictions_transformed)\n\n# Revert transformation (only if transformer_y is not None)\npredictions_training = forecaster.transformer_y.inverse_transform(predictions_transformed.reshape(-1, 1))\npredictions_training.ravel()[:4]\n```\n\n----------------------------------------\n\nTITLE: Training with Dictionary Exogenous Variables\nDESCRIPTION: Demonstrates creating training data using DataFrame series and dictionary-format exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nexog_train_as_dict = {\n    'item_1': exog_1_item_1_train,\n    'item_2': exog_1_item_2_train,\n    'item_3': exog_1_item_3_train\n}\n\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 4,\n                 encoding  = 'ordinal'\n             )\n\nX, y = forecaster.create_train_X_y(\n    series = data_exog_train[['item_1', 'item_2', 'item_3']], \n    exog   = exog_train_as_dict\n)\n\ndisplay(X.head(3))\nprint(\"\")\nprint(\"Column `exog_1` as different values for each item (_level_skforecast id):\")\nX['exog_1'].value_counts()\n```\n\n----------------------------------------\n\nTITLE: Hyperparameter Search with grid_search_forecaster in skforecast  0.14\nDESCRIPTION: This snippet demonstrates how to implement hyperparameter tuning using `grid_search_forecaster` in version 0.14. It introduces the `TimeSeriesFold` class for handling several parameters that were previously defined in the function itself.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.model_selection import (\n    grid_search_forecaster,\n    TimeSeriesFold\n)\n\ncv = TimeSeriesFold(\n    steps                 = 10,\n    initial_train_size    = 100,\n    fixed_train_size      = False,\n    gap                   = 0,\n    skip_folds            = None,\n    allow_incomplete_fold = True,\n    refit                 = False\n)\n\ngrid_search_forecaster(\n    forecaster         = forecaster,\n    y                  = data,\n    param_grid         = param_grid,\n    lags_grid          = lags_grid,\n    cv                 = cv,\n    metric             = 'mean_squared_error',\n    return_best        = True,\n    n_jobs             = 'auto',\n    verbose            = False,\n    show_progress      = True\n)\n```\n\n----------------------------------------\n\nTITLE: Transforming Categorical Features with OrdinalEncoder in Python\nDESCRIPTION: Creates a column transformer that applies OrdinalEncoder to categorical features, encoding unknown and missing values as -1, while passing through numeric features. The transformer maintains pandas output format.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ncategorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\ntransformer_exog = make_column_transformer(\n                       (\n                           OrdinalEncoder(\n                               dtype=int,\n                               handle_unknown=\"use_encoded_value\",\n                               unknown_value=-1,\n                               encoded_missing_value=-1\n                           ),\n                           categorical_features\n                       ),\n                       remainder=\"passthrough\",\n                       verbose_feature_names_out=False,\n                   ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating Prediction Interval Coverage and Area in Python\nDESCRIPTION: Calculates and displays two key metrics for assessing prediction intervals: coverage (percentage of actual values within the interval) and area (sum of interval widths). These metrics help evaluate the quality and efficiency of the prediction intervals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Predicted interval coverage (on test data)\n# ==============================================================================\ncoverage = calculate_coverage(\n               y_true      = data.loc[end_calibration:, 'OT'],\n               lower_bound = predictions[\"lower_bound\"], \n               upper_bound = predictions[\"upper_bound\"]\n           )\nprint(f\"Predicted interval coverage: {round(100 * coverage, 2)} %\")\n\n# Area of the interval\n# ==============================================================================\narea = (predictions[\"upper_bound\"] - predictions[\"lower_bound\"]).sum()\nprint(f\"Area of the interval: {round(area, 2)}\")\n```\n\n----------------------------------------\n\nTITLE: Inspecting Categorical Features Used by LightGBM in Python\nDESCRIPTION: Extracts and prints the features that are being treated as categorical by the LightGBM model. This code accesses the underlying booster object to retrieve categorical column indices and maps them back to feature names.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Print the features considered as categorical by the forecaster\n# ==============================================================================\nregressor = forecaster.regressor\ncat_index = regressor.booster_.params.get('categorical_column')\nif cat_index is not None:\n    features_in_model = regressor.booster_.feature_name()\n    cat_features_in_model = [features_in_model[i] for i in cat_index]\n\ncat_features_in_model\n```\n\n----------------------------------------\n\nTITLE: Visualizing Cyclical Encoding for Day of Week in Python\nDESCRIPTION: This code creates a scatter plot to visualize the cyclical encoding of the day of the week feature, showing how the sine and cosine transformations represent the cyclic nature of days.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Plot value of sin and cos for each day_of_week\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(3.5, 3))\nsp = ax.scatter(\n         cyclical_features[\"day_of_week_sin\"],\n         cyclical_features[\"day_of_week_cos\"],\n         c    = calendar_features['day_of_week'],\n         cmap = 'viridis'\n     )\nax.set(\n    xlabel=\"sin(day_of_week)\",\n    ylabel=\"cos(day_of_week)\",\n)\n_ = fig.colorbar(sp)\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Time Series Data in Python\nDESCRIPTION: This snippet demonstrates how to preprocess time series data by converting the date column to datetime format, setting it as the index, and ensuring hourly frequency.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Preprocess data\n# ==============================================================================\ndata['date_time'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d %H:%M:%S')\ndata = data.set_index('date_time')\ndata = data.asfreq('h')\ndata = data.sort_index()\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Retrieving Best Trial from Bayesian Search - Python\nDESCRIPTION: This snippet extracts information about the best trial achieved during the Bayesian search optimization. It helps in understanding which trial parameters yielded the best results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Optuna best trial in the study\n# ==============================================================================\\nbest_trial\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting Skforecast Forecaster\nDESCRIPTION: Creates a ForecasterRecursive instance with RandomForestRegressor, configures lags and window features, and fits it to the demo dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ny = load_demo_dataset()\n\nforecaster = ForecasterRecursive(\n                 regressor       = RandomForestRegressor(random_state=123),\n                 lags            = 5,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=[7])\n             )\n\nforecaster.fit(y=y)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Adding Calendar Features in Time Series Data\nDESCRIPTION: Adds a new feature 'month_of_year' to the dataset, extracted from the date index, to capture seasonality in forecasting models. Aids in improving model prediction by adding temporal context.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Calendar features\n# ==============================================================================\ndata['month_of_year'] = data.index.month\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Training ARIMA Model with statsmodels in Python\nDESCRIPTION: This code demonstrates how to create and fit an ARIMA model using the statsmodels library. It uses the SARIMAX class with order (1,1,1) and prints a summary of the fitted model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# ARIMA model with statsmodels.Sarimax\n# ==============================================================================\narima = SARIMAX(endog = data_train['y'], order = (1, 1, 1))\narima_res = arima.fit(disp=0)\narima_res.summary()\n```\n\n----------------------------------------\n\nTITLE: Plotting Multiple Time Series with NaN Values in Python\nDESCRIPTION: This snippet creates a plot of multiple time series from a dictionary, highlighting the end of the training period. It uses matplotlib to create subplots for each series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfig, axs = plt.subplots(2, 1, figsize=(8, 2.5), sharex=True)\n\nfor i, s in enumerate(series_dict_nan.values()):\n    axs[i].plot(s, label=s.name, color=colors[i])\n    axs[i].legend(loc='upper right', fontsize=8)\n    axs[i].tick_params(axis='both', labelsize=8)\n    axs[i].axvline(pd.to_datetime(end_train), color='white', linestyle='--', linewidth=1)  # End train\n\nfig.suptitle('Series in `series_dict_nan`', fontsize=15)\nplt.tight_layout()\n```\n\n----------------------------------------\n\nTITLE: Creating Forecaster with Automatic Categorical Feature Detection\nDESCRIPTION: Instantiates a ForecasterRecursive with HistGradientBoostingRegressor configured to automatically detect categorical features from data types. The forecaster uses the transformer pipeline to properly prepare exogenous features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster with automatic detection of categorical features\n# ==============================================================================\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor        = HistGradientBoostingRegressor(random_state=963, categorical_features='from_dtype'),\n                 lags             = 5,\n                 transformer_exog = transformer_exog,\n             )\n            \nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Last Window\nDESCRIPTION: Demonstrating prediction functionality using the last_window argument to generate forecasts from specific time points.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Predict with last_window\n# ==============================================================================\nlast_window = data['y'].tail(5)\nforecaster.predict(steps=3, last_window=last_window)\n```\n\n----------------------------------------\n\nTITLE: ColumnTransformer with Target Encoding in Python\nDESCRIPTION: This snippet exemplifies how a ColumnTransformer applies target encoding to categorical features, considering both numerical and categorical inputs. The transformation encodes categories based on their relationship to the target variable.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n# ColumnTransformer with target encoding\n# ============================================================================== \n# A ColumnTransformer is used to transform categorical (not numerical) features \n# using target encoding. Numeric features are left untouched. TargetEncoder \n# considers missing values, such as np.nan or None, as another category and \n# encodes them like any other category. Categories that are not seen during fit \n# are encoded with the target mean \n\ntarget_encoder = make_column_transformer( \n                     ( \n                         TargetEncoder( \n                             categories   = 'auto', \n                             target_type  = 'continuous', \n                             smooth       = 'auto', \n                             random_state = 9874 \n                         ), \n                         make_column_selector(dtype_exclude=np.number) \n                     ), \n                     remainder=\"passthrough\", \n                     verbose_feature_names_out=False, \n                 ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Loading a Model with Custom Requirements\nDESCRIPTION: This snippet demonstrates loading a model saved with custom functions. It imports necessary custom classes and functions which must be present in the environment where the model is loaded.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Load model and custom function\n# ============================================================================== \nfrom rolling_skewness import RollingSkewness  # This file has to be generated manually\nfrom custom_weights import custom_weights\n\nforecaster_loaded = load_forecaster('forecaster_custom_features.joblib', verbose=True)\n```\n\n----------------------------------------\n\nTITLE: Fetching Dataset and Initial Data Preparation\nDESCRIPTION: This code snippet fetches a specific dataset and selects relevant columns for time series forecasting. The dataset used is 'ett_m2_extended', and columns chosen relate to time-based cyclical features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Data\n# ==============================================================================\ndata = fetch_dataset(name=\"ett_m2_extended\")\ndata = data[[\n    \"OT\",\n    \"day_of_week_cos\",\n    \"day_of_week_sin\",\n    \"hour_cos\",\n    \"hour_sin\",\n    \"month_cos\",\n    \"month_sin\",\n    \"week_cos\",\n    \"week_sin\",\n    \"year\",\n]]\ndata.head(2)\n```\n\n----------------------------------------\n\nTITLE: Generating Sunlight-Related Features for Time Series in Python\nDESCRIPTION: This code uses the astral library to calculate sunrise and sunset times for a specific location, and creates features based on these times including daylight hours.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Features based on the sunligth\n# ==============================================================================\nfrom astral.sun import sun\nfrom astral import LocationInfo\n\nlocation = LocationInfo(\"Washington, D.C.\", \"USA\")\nsunrise_hour = [sun(location.observer, date=date)['sunrise'] for date in data.index]\nsunset_hour = [sun(location.observer, date=date)['sunset'] for date in data.index]\n\n# Round to the nearest hour\nsunrise_hour = pd.Series(sunrise_hour, index=data.index).dt.round(\"h\").dt.hour\nsunset_hour = pd.Series(sunset_hour, index=data.index).dt.round(\"h\").dt.hour\n\nsun_light_features = pd.DataFrame({\n                         'sunrise_hour': sunrise_hour,\n                         'sunset_hour': sunset_hour}\n                     )\nsun_light_features['daylight_hours'] = sun_light_features['sunset_hour'] - sun_light_features['sunrise_hour']\nsun_light_features.tail()\n```\n\n----------------------------------------\n\nTITLE: Exogenous Variables Preparation for Multi-Series Forecasting\nDESCRIPTION: Generate and prepare exogenous variables for multi-series forecasting, demonstrating month feature extraction\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndata_exog = data.copy()\ndata_exog['month'] = data_exog.index.month\n\nend_train = '2014-07-15 23:59:00'\ndata_exog_train = data_exog.loc[:end_train, :].copy()\ndata_exog_test  = data_exog.loc[end_train:, :].copy()\n```\n\n----------------------------------------\n\nTITLE: Backtesting Recursive Multi-Series Forecaster with Parameter Grid in Python\nDESCRIPTION: Implements backtesting for a recursive multi-series forecaster using a parameter grid to test various configurations. It creates multiple combinations of parameters using ParameterGrid and runs the backtesting function with different input formats (regular series/dataframes and dictionaries) to verify consistency of results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# ==============================================================================\nparams = {\n    \"initial_train_size\": [50, len(series_train)],\n    \"refit\": [True, False, 2],\n    \"fixed_train_size\": [True, False],\n    \"gap\": [0, 7],\n    \"levels\": [\n        None,\n        [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n        \"id_1000\",\n        [\"id_1000\", \"id_1001\"],\n    ],\n    \"metrics\": [[\"mean_absolute_error\", \"mean_squared_error\"], \"mean_absolute_error\"],\n    \"allow_incomplete_fold\": [True, False],\n}\n\nparams_grid = list(ParameterGrid(params))\n\nfor params in tqdm(params_grid):\n    print(f\"Paramns: {params}\")\n\n    forecaster = ForecasterRecursiveMultiSeries(\n        regressor=LinearRegression(),  # LGBMRegressor(n_estimators=10, random_state=123, verbose=-1),\n        lags=14,\n        encoding=\"ordinal\",\n        dropna_from_series=False,\n        transformer_series=StandardScaler(),\n        transformer_exog=StandardScaler(),\n    )\n\n    metrics_1, predictions_1 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog,\n        levels=params[\"levels\"],\n        steps=24,\n        interval=[5, 95],\n        n_boot=5,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    metrics_2, predictions_2 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog_dict,\n        levels=params[\"levels\"],\n        steps=24,\n        interval=[5, 95],\n        n_boot=5,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    metrics_3, predictions_3 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series_dict,\n        exog=exog_dict,\n        levels=params[\"levels\"],\n        steps=24,\n        interval=[5, 95],\n        n_boot=5,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    pd.testing.assert_frame_equal(metrics_1, metrics_2)\n    pd.testing.assert_frame_equal(predictions_1, predictions_2)\n    pd.testing.assert_frame_equal(metrics_1, metrics_3)\n    pd.testing.assert_frame_equal(predictions_1, predictions_3)\n```\n\n----------------------------------------\n\nTITLE: Describe Data Partition\nDESCRIPTION: This code iterates through the keys in `series_dict` and prints the length and index range of both the training and testing partitions for each series.  It includes error handling to account for cases where a series may not have either training or testing data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"# Description of each partition\n# ==============================================================================\nfor k in series_dict.keys():\n    print(f\"{k}:\")\n    try:\n        print(\n            f\"\\tTrain: len={len(series_dict_train[k])}, {series_dict_train[k].index[0]}\"\n            f\" --- {series_dict_train[k].index[-1]}\"\n        )\n    except:\n        print(\"\\tTrain: len=0\")\n    try:\n        print(\n            f\"\\tTest : len={len(series_dict_test[k])}, {series_dict_test[k].index[0]}\"\n            f\" --- {series_dict_test[k].index[-1]}\"\n        )\n    except:\n        print(\"\\tTest : len=0\")\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing Multiple Time Series with Training/Test Split\nDESCRIPTION: Creates a visualization of the five time series used in the tests. Each series is plotted in a separate subplot with a vertical line indicating the split between training and testing data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Plot series\n# ==============================================================================\nset_dark_theme()\ncolors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\nfig, axs = plt.subplots(5, 1, figsize=(8, 4), sharex=True)\nfor i, s in enumerate(series_dict.values()):\n    axs[i].plot(s, label=s.name, color=colors[i])\n    axs[i].legend(loc=\"upper right\", fontsize=8)\n    axs[i].tick_params(axis=\"both\", labelsize=8)\n    axs[i].axvline(\n        pd.to_datetime(end_train), color=\"white\", linestyle=\"--\", linewidth=1\n    )\n```\n\n----------------------------------------\n\nTITLE: Displaying Predictors and Target Matrices in Python\nDESCRIPTION: These snippets display the first few rows of the predictor and target variable matrices. This is essential for checking the structure of data prepared for model training and validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Predictors matrix\n# ============================================================================== \nX_train.head(3)\n```\n\nLANGUAGE: python\nCODE:\n```\n# Target variable matrix\n# ============================================================================== \ny_train.head(3)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Auto-Detected Categorical Features in Python\nDESCRIPTION: Shows how to generate predictions with the LightGBM forecaster using automatic categorical feature detection. The usage pattern is identical to the explicit approach, but the underlying handling differs.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Predictions\n# ==============================================================================\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Forecasting with ForecasterSarimax Model in Python\nDESCRIPTION: This snippet demonstrates how to make predictions using the fitted ForecasterSarimax model. It forecasts 36 steps ahead and displays the first 3 predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=36)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Accessing Out-of-Sample Residuals\nDESCRIPTION: Shows how to access out-of-sample residuals from the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nforecaster.out_sample_residuals_\n```\n\n----------------------------------------\n\nTITLE: Backtesting Multiseries Forecaster\nDESCRIPTION: This test evaluates the performance of the ForecasterRecursiveMultiSeries model using backtesting. It specifies various parameters like initial train size, refit policies, metrics, and allows for incomplete folds.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nparams = {\n    \\\"initial_train_size\\\": [50, len(series_dict_train[\\\"id_1000\\\"])],\n    \\\"refit\\\": [True, False, 2],\n    \\\"fixed_train_size\\\": [True, False],\n    \\\"gap\\\": [0, 7],\n    \\\"levels\\\": [\n        None,\n        [\\\"id_1000\\\", \\\"id_1001\\\", \\\"id_1002\\\", \\\"id_1003\\\", \\\"id_1004\\\"],\n        \\\"id_1000\\\",\n        [\\\"id_1000\\\", \\\"id_1001\\\"],\n    ],\n    \\\"metrics\\\": [[\\\"mean_absolute_error\\\", \\\"mean_squared_error\\\"], \\\"mean_absolute_error\\\"],\n    \\\"allow_incomplete_fold\\\": [True, False],\n}\n\nparams_grid = list(ParameterGrid(params))\n\nfor params in tqdm(params_grid):\n    print(f\\\"Paramns: {params}\\\")\n\n    forecaster = ForecasterRecursiveMultiSeries(\n        regressor=LGBMRegressor(\n            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n        ),\n        lags=14,\n        encoding=\\\"ordinal\\\",\n        dropna_from_series=False,\n        transformer_series=StandardScaler(),\n        transformer_exog=StandardScaler(),\n    )\n\n    cv = TimeSeriesFold(\n        initial_train_size=params[\\\"initial_train_size\\\"],\n        steps=24,\n        fixed_train_size=params[\\\"fixed_train_size\\\"],\n        gap=params[\\\"gap\\\"],\n        allow_incomplete_fold=params[\\\"allow_incomplete_fold\\\"],\n        refit=params[\\\"refit\\\"],\n    )\n\n    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series_dict,\n        exog=exog_dict,\n        levels=params[\\\"levels\\\"],\n        cv = cv,\n        metric=params[\\\"metrics\\\"],\n        show_progress=False,\n        suppress_warnings=True,\n        n_jobs=\\\"auto\\\"\n    )\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining Grid Search Parameters\nDESCRIPTION: Sets up hyperparameter grids for model optimization including different lag configurations and LightGBM parameters like learning rate, number of estimators, and max depth.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlags_grid = [[5], [1, 7, 14]]\n\nparam_grid = {\n    \"learning_rate\": [0.1],\n    \"n_estimators\": [10, 20],\n    \"max_depth\": [2, 5],\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Multivariate Data for Forecasting\nDESCRIPTION: This code visualizes multivariate time series data by displaying the first few rows of the dataset and creating a subplot for each variable. It helps in understanding the patterns in multiple related time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ==============================================================================\ndisplay(data_multivariate.head(3))\n\n# Plot\n# ==============================================================================\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize=(9, 4), sharex=True)\n\nfor i, col in enumerate(data_multivariate.columns[:3]):\n    data_multivariate[col].plot(ax=axes[i])\n    axes[i].set_xlabel('')\n    axes[i].set_ylabel('sales')\n    axes[i].set_title(col)\n\nfig.tight_layout()\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Predict with ForecasterRecursiveMultiSeries\nDESCRIPTION: This code uses the fitted `ForecasterRecursiveMultiSeries` model to make predictions for a specified number of steps (5 in this case). It passes the test set of exogenous variables (`exog_dict_test`) to the `predict` method and suppresses warnings.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n\"# Predict\n# ==============================================================================\npredictions = forecaster.predict(steps=5, exog=exog_dict_test, suppress_warnings=True)\npredictions\"\n```\n\n----------------------------------------\n\nTITLE: Defining Multi-Series Custom Weights Functions\nDESCRIPTION: This snippet defines multiple custom weights functions for different items, each adjusting weights specific to their respective date ranges, suitable for multi-series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Custom function to create weights for each item\n# ============================================================================== \ndef custom_weights_item_1(index):\n    \"\"\"\n    Return 0 if index is between 2012-01-01 and 2012-06-01.\n    \"\"\"\n    weights = np.where(\n        (index >= '2012-01-01') & (index <= '2012-06-01'), 0, 1\n    )\n\n    return weights\n\ndef custom_weights_item_2(index):\n    \"\"\"\n    Return 0 if index is between 2012-04-01 and 2013-01-01.\n    \"\"\"\n    weights = np.where(\n        (index >= '2012-04-01') & (index <= '2013-01-01'), 0, 1\n    )\n\n    return weights\n\ndef custom_weights_item_3(index):\n    \"\"\"\n    Return 0 if index is between 2012-06-01 and 2013-01-01.\n    \"\"\"\n    weights = np.where(\n        (index >= '2012-06-01') & (index <= '2013-01-01'), 0, 1\n    )\n\n    return weights\n```\n\n----------------------------------------\n\nTITLE: Calibrating Prediction Intervals using ConformalIntervalCalibrator\nDESCRIPTION: This snippet calibrates the prediction intervals using the `ConformalIntervalCalibrator` class. It initializes the calibrator with a nominal coverage of 0.8 and asymmetric calibration. It then fits the calibrator to the true values `y_true` and the initial prediction interval `interval`. The calibrated interval is obtained using the `transform` method and then plotted for visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Calibrate interval\n# ==============================================================================\ncalibrator = ConformalIntervalCalibrator(nominal_coverage=0.8, symmetric_calibration=False)\ncalibrator.fit(y_true=y_true, y_pred_interval=interval)\nprint(calibrator)\ninterval_calibrated = calibrator.transform(interval)\nfig, ax = plt.subplots(figsize=(7, 3.5))\ninterval.plot(ax=ax, linestyle=\"--\")\ninterval_calibrated[\"lower_bound\"].plot(ax=ax, color=\"#30a2da\", label=\"Calibrated lower bound\")\ninterval_calibrated[\"upper_bound\"].plot(ax=ax, color=\"#fc4f30\", label=\"Calibrated upper bound\")\ny_true.plot(ax=ax, label=\"True values\")\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=4)\nplt.show()\n\ncoverage = calculate_coverage(\n               y_true      = y_true,\n               lower_bound = interval_calibrated[\"lower_bound\"],\n               upper_bound = interval_calibrated[\"upper_bound\"],\n           )\nprint(f\"Coverage after calibration: {coverage:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Viewing Automatically Detected Categorical Features\nDESCRIPTION: Displays which features were detected as categorical by the regressor by using the categorical feature mask and feature names array.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n# Print the features considered as categorical by the forecaster\n# ==============================================================================\nforecaster.regressor.feature_names_in_[forecaster.regressor.is_categorical_]\n```\n\n----------------------------------------\n\nTITLE: Creating and Transforming Time Series Data in Long Format\nDESCRIPTION: Creates two time series with daily frequency, concatenates them, and transforms into a long format using pandas melt operation. Prints the frequency of the resulting index and displays the melted dataframe.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nseries_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_1')\nseries_2 = pd.Series([20, 30, 40, 50, 60, 70, 80, 90, 100, 110], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_2')\nseries = pd.concat([series_1, series_2], axis=1).melt(var_name='series', value_name='value', ignore_index=False)\nseries = series.rename_axis('datetime')\nprint(series.index.freq)\nseries\n```\n\n----------------------------------------\n\nTITLE: Training Forecaster for Unknown Series Prediction\nDESCRIPTION: Demonstrates training a forecaster with ordinal encoding for later prediction of unknown series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = 'ordinal'\n             )\n\nforecaster.fit(series=data_train)\nprint(f\"Series seen by during training: {forecaster.series_names_in_}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Baseline Forecasting with skforecast\nDESCRIPTION: Imports necessary libraries including numpy, pandas, matplotlib, sklearn metrics, and various modules from skforecast for time series forecasting and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterEquivalentDate\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices for Multi-Series Forecasting\nDESCRIPTION: This code shows how to create training matrices (X_train and y_train) from multiple time series data using the ForecasterRecursiveMultiSeries model. These matrices include features derived from lags and window functions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# Create training matrices\n# ==============================================================================\nX_train, y_train = forecaster.create_train_X_y(series=data_multiseries)\n```\n\n----------------------------------------\n\nTITLE: Updating XGBoost Regressor with Feature Types\nDESCRIPTION: Uses the forecaster's set_params method to update the XGBRegressor with the feature_types parameter, which specifies which features should be treated as categorical.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\n# Update regressor parameters\n# ==============================================================================\nforecaster.set_params({'feature_types': feature_types})\n```\n\n----------------------------------------\n\nTITLE: Time Series Visualization\nDESCRIPTION: Creates a visualization of the time series data showing train and test splits along with gaps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(8, 3.5))\ndata_train.users.plot(ax=ax, label='train', linewidth=1)\ndata_test.users.plot(ax=ax, label='test', linewidth=1)\n\nfor gap in gaps:\n    ax.plot(\n        [pd.to_datetime(gap[0]), pd.to_datetime(gap[1])],\n        [data.users[pd.to_datetime(gap[0]) - pd.Timedelta(days=1)],\n         data.users[pd.to_datetime(gap[1]) + pd.Timedelta(days=1)]],\n        color = 'red',\n        linestyle = '--',\n        label = 'gap'\n    )\n\nax.set_title('Number of users BiciMAD')\nhandles, labels = plt.gca().get_legend_handles_labels()\nby_label = dict(zip(labels, handles))\nax.legend(by_label.values(), by_label.keys(), loc='lower right');\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for CRPS Calculation in Python\nDESCRIPTION: This snippet imports the necessary libraries for calculating the Continuous Ranked Probability Score (CRPS) using various methods and libraries, including skforecast, scipy, properscoring, CRPS, and pymc_marketing.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ======================================================================================\nimport pandas as pd\nimport numpy as np\nfrom skforecast.metrics import crps_from_predictions\nfrom skforecast.metrics import crps_from_quantiles\nfrom scipy.interpolate import interp1d\nimport properscoring as ps\nfrom CRPS import CRPS\nfrom pymc_marketing.metrics import crps\n```\n\n----------------------------------------\n\nTITLE: Comparing Different Encoding Methods with Backtesting\nDESCRIPTION: Performs backtesting to compare forecasting performance across different encoding methods using time series cross-validation and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/cyclical-features-time-series.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndatasets = [\n    data_encoded_oh, data_encoded_sin_cos, data_encoded_splines, data_encoded_rbf\n]\nencoding_methods = [\n    'one hot encoding', 'sine/cosine encoding', 'spline encoding', 'rbf encoding'\n]\n\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_test['y'].plot(title=\"Time series\", label=\"test\", ax=ax)\n\nfor i, data_encoded in enumerate(datasets):\n    cv = TimeSeriesFold(\n        steps              = 365,\n        initial_train_size = len(data_encoded.loc[:end_train]),\n        refit              = False,\n    )\n    metric, predictions = backtesting_forecaster(\n        forecaster    = forecaster,\n        y             = data_encoded['y'],\n        exog          = data_encoded.drop(columns='y'),\n        cv            = cv,\n        metric        = 'mean_squared_error'\n    )\n\n    print(f\"Backtest error using {encoding_methods[i]}: {metric.at[0, 'mean_squared_error']:.2f}\")\n    predictions.plot(label=encoding_methods[i], ax=ax)\n    ax.legend(labels=['test'] + encoding_methods)\n    \nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices for Time Series Prediction\nDESCRIPTION: Creates training matrices by extracting features and targets for step 1 prediction. Demonstrates matrix filtering and preparation for model training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nX_train, y_train = forecaster.create_train_X_y(series=data_multivariate)\n\nX_train_1, y_train_1 = forecaster.filter_train_X_y_for_step(\n    step          = 1,\n    X_train       = X_train,\n    y_train       = y_train,\n    remove_suffix = False\n)\n\nprint(\"Columns :\", list(X_train_1.columns))\nX_train_1.head(3)\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Test Sets\nDESCRIPTION: Splits the air quality dataset into training and test sets based on a cutoff date, allowing for model evaluation on unseen future data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Split data into train-val-test\n# ==============================================================================\nend_train = '2023-05-31 23:59:59'\ndata_train = data.loc[:end_train, :].copy()\ndata_test  = data.loc[end_train:, :].copy()\n\nprint(\n    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  \"\n    f\"(n={len(data_train)})\"\n)\nprint(\n    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  \"\n    f\"(n={len(data_test)})\"\n)\n```\n\n----------------------------------------\n\nTITLE: Compose Multiple Transformations Using Pipelines in Python\nDESCRIPTION: Demonstrates using Scikit-learn's Pipeline to sequentially apply scaling and power transformations to the target variable and use a ColumnTransformer for various transformations on exogenous variables in the forecaster setup.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Multiple transformations using pipelines and column transformers\n# ==============================================================================\\ntransformer_y = Pipeline(\\n                    steps = [\\n                        ('scaler', StandardScaler()),\\n                        ('power', PowerTransformer(method='yeo-johnson'))\\n                    ]\\n                )\\n\\ntransformer_exog = ColumnTransformer(\\n                       [('scale_1', StandardScaler(), ['exog_1']),\\n                        ('scale_2', StandardScaler(), ['exog_2']),\\n                        ('onehot', OneHotEncoder(), ['exog_3']),\\n                       ],\\n                       remainder = 'passthrough',\\n                       verbose_feature_names_out = False\\n                   )\\n\\nforecaster = ForecasterRecursive(\\n                    regressor        = Ridge(random_state=123),\\n                    lags             = 3,\\n                    transformer_y    = transformer_y,\\n                    transformer_exog = transformer_exog\\n                )\\nforecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2', 'exog_3']])\\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Create and Train LightGBM Forecaster with GPU\nDESCRIPTION: Creates and trains an `LGBMRegressor` model within a `ForecasterRecursive` object, configuring it to use the GPU.  The `device_type` is set to `'gpu'` to enable GPU usage. The forecaster is then fitted to the generated data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Create and train forecaster with a LGBMRegressor using GPU\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(n_estimators=5000, device_type='gpu'),\n                 lags      = 20\n             )\n\nforecaster.fit(y=data)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Predicting Intervals for Unknown Series\nDESCRIPTION: Shows how to generate prediction intervals for unknown series using in-sample residuals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nforecaster.predict_interval(\n    levels                  = 'item_4',\n    steps                   = 3,\n    last_window             = last_window_item_4,\n    use_in_sample_residuals = True,\n    suppress_warnings       = False\n)\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data into Train and Test Sets in Python\nDESCRIPTION: Divides the time series data into training and testing sets based on a cutoff date, then prints the date ranges and number of observations in each set for validation purposes.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Split data into train-val-test\n# ==============================================================================\nend_train = '2014-07-15 23:59:00'\ndata_train = data.loc[:end_train, :].copy()\ndata_test  = data.loc[end_train:, :].copy()\n\nprint(\n    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n    f\"(n={len(data_train)})\"\n)\nprint(\n    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n    f\"(n={len(data_test)})\"\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Prediction Matrices for Multi-Series Forecasting\nDESCRIPTION: This code shows how to generate prediction matrices for multi-series forecasting using the create_predict_X method. It creates matrices for all levels (series) and examines the matrix for a specific item.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n# Create input matrix for predict method\n# ==============================================================================\nX_predict_dict = forecaster.create_predict_X(steps=5, levels=None)  # All levels\n\n# Check 'item_1' matrix\nX_predict_item_1 = X_predict_dict['item_1']\nX_predict_item_1.head()\n```\n\n----------------------------------------\n\nTITLE: Displaying Final Optimized Forecaster\nDESCRIPTION: Prints information about the forecaster after it has been updated with the best hyperparameters and lags found during grid search.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Print forecaster information\n# ==============================================================================\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Inspecting Auto-Detected Categorical Features in LightGBM in Python\nDESCRIPTION: Retrieves and displays the features that LightGBM identified as categorical through automatic detection. This helps verify that the correct features were detected and are being treated as categorical by the model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Print the features considered as categorical by the forecaster\n# ==============================================================================\nregressor = forecaster.regressor\ncat_index = regressor.booster_.params.get('categorical_column')\nif cat_index is not None:\n    features_in_model = regressor.booster_.feature_name()\n    cat_features_in_model = [features_in_model[i] for i in cat_index]\n    \ncat_features_in_model\n```\n\n----------------------------------------\n\nTITLE: Examining Target Variable Matrix in Multi-Series Forecasting\nDESCRIPTION: This code displays the first few rows of the target variable matrix (y_train) created for multi-series forecasting, showing the values that the model will learn to predict.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n# Target variable matrix\n# ==============================================================================\ny_train.head(3)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Fetching Data\nDESCRIPTION: This snippet imports necessary libraries and fetches the dataset required for model training. Essential libraries such as numpy, pandas, and various Skforecast modules are imported, and a dataset is fetched using Skforecast's utility. The code prepares the dataset by setting it as a monthly frequency time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.utils import save_forecaster\nfrom skforecast.utils import load_forecaster\n```\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ============================================================================== \ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"date\"], \"header\": 0}\n)\ndata['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\ndata = data.set_index('date')\ndata = data.asfreq('MS')\n```\n\n----------------------------------------\n\nTITLE: Reverting Predictions Using transform_numpy Utility\nDESCRIPTION: Alternative method using skforecast's transform_numpy utility function to inverse transform predictions. Provides more explicit control over transformation parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.utils import transform_numpy\n\npredictions = transform_numpy(\n                  array             = predictions_transformed,\n                  transformer       = forecaster.transformer_series_['item_1'],\n                  fit               = False,\n                  inverse_transform = True\n              )\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data into Train and Test Sets in Python\nDESCRIPTION: Divides the dataset into training and testing portions, with the last 36 time points reserved for testing the model's forecasting performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Split data in train and test\n# ==============================================================================\nsteps = 36\ndata_train = data.iloc[:-steps, :]\ndata_test  = data.iloc[-steps:, :]\n```\n\n----------------------------------------\n\nTITLE: Visualizing Predictions Against Actual Data\nDESCRIPTION: Creates a plot comparing the training data, test data, and the model's predictions to visually assess the forecasting performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.loc[:end_train].plot(ax=ax, label='train')\ndata.loc[end_train:].plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Calculating CRPS for Multiple Forecast Steps in Python\nDESCRIPTION: This code demonstrates how to calculate CRPS for multiple forecast steps. It generates simulated data for 40 steps with 100 bootstrap samples each, and then calculates CRPS using different methods for comparison.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# CRPS for multiple steps\n# ==============================================================================\nrng = np.random.default_rng(123)\nn_steps = 40\nn_bootstraps = 100\npredictions = pd.DataFrame({\n    'y_true': rng.normal(100, 10, n_steps),\n    'y_pred': [rng.normal(5, 5, n_bootstraps) for _ in range(n_steps)]\n})\n\npredictions['crps_from_predictions'] = predictions.apply(lambda x: crps_from_predictions(x['y_true'], x['y_pred']), axis=1)\npredictions['properscoring'] = predictions.apply(lambda x: ps.crps_ensemble(x['y_true'], x['y_pred']), axis=1)\npredictions['CRPS'] = predictions.apply(lambda x: CRPS(x['y_pred'], x['y_true']).compute()[0], axis=1)\npredictions['pymc_marqueting'] = predictions.apply(lambda x: crps(x['y_true'], x['y_pred'].reshape(-1, 1)), axis=1)\ndisplay(predictions.head())\n\nassert np.allclose(predictions['properscoring'], predictions['CRPS'])\nassert np.allclose(predictions['properscoring'], predictions['pymc_marqueting'])\nassert np.allclose(predictions['crps_from_predictions'], predictions['properscoring'])\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Dataset for Feature Selection\nDESCRIPTION: Preprocessing the bike sharing dataset by removing the 'weather' column and filtering data from 2012-01-01 onwards to reduce the data size and speed up the example.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Data selection (reduce data size to speed up the example)\n# ==============================================================================\ndata = data.drop(columns=\"weather\")\ndata = data.loc[\"2012-01-01 00:00:00\":]\n```\n\n----------------------------------------\n\nTITLE: Using Differentiation in ForecasterRecursive with Python\nDESCRIPTION: Example of applying differentiation in ForecasterRecursive. This focuses on relative rates of change rather than absolute values in the time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\nforecaster = ForecasterRecursive(\n    regressor        = LGBMRegressor(random_state=123, verbose=-1),\n    lags             = 5,\n    window_features  = None,\n    transformer_y    = None,\n    transformer_exog = None,\n    weight_func      = None,\n    differentiation  = 1\n)\n```\n\n----------------------------------------\n\nTITLE: Benchmarking ForecasterRecursiveMultiSeries with Multiple Regressors\nDESCRIPTION: Implements performance testing for different regression models (Ridge, LGBMRegressor, HistGradientBoostingRegressor) with parallel and sequential processing. Measures execution times for operations including model fitting, backtesting, and grid search. Includes visualization of performance improvements using seaborn and matplotlib.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(\"------------------------------\")\nprint(\"ForecasterRecursiveMultiSeries\")\nprint(\"------------------------------\")\nsteps = 100\nlags = 50\nregressors = [\n    Ridge(random_state=77, alpha=0.1),\n    LGBMRegressor(random_state=77, n_jobs=1, n_estimators=50, max_depth=5, verbose=-1),\n    LGBMRegressor(random_state=77, n_jobs=-1, n_estimators=50, max_depth=5, verbose=-1),\n    HistGradientBoostingRegressor(random_state=77, max_iter=50, max_depth=5,),\n]\nparam_grids = [\n    {'alpha': [0.1, 0.1, 0.1]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'max_iter': [50, 50], 'max_depth': [5, 5]}\n]\nlags_grid = [50, 50, 50]\nelapsed_times = []\n\nfor regressor, param_grid in zip(regressors, param_grids):\n    print(\"\")\n    print(regressor, param_grid)\n    print(\"\")\n    forecaster = ForecasterRecursiveMultiSeries(\n                     regressor        = regressor,\n                     lags             = lags,\n                     transformer_exog = StandardScaler()\n                 )\n    \n    print(\"Profiling fit\")\n    start = time.time()\n    forecaster.fit(series=multi_series, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling create_train_X_y\")\n    start = time.time()\n    _ = forecaster.create_train_X_y(series=multi_series, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n\n    print(\"Profiling backtesting refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             initial_train_size = len(y_train),\n             refit              = True,\n             fixed_train_size   = False,\n             steps              = steps,\n         )\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting refit and no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n            initial_train_size = len(y_train),\n            refit              = False,\n            steps              = steps,\n         )\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster_multiseries(\n                                       forecaster    = forecaster,\n                                       series        = multi_series,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)    \n    \n    print(\"Profiling GridSearch no refit parallel\")\n    start = time.time()\n    results_grid = grid_search_forecaster_multiseries(\n                       forecaster    = forecaster,\n                       series        = multi_series,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = -1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling GridSearch no refit no parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             initial_train_size = len(y_train),\n             refit              = False,\n             steps              = steps,\n         )\n    results_grid = grid_search_forecaster_multiseries(\n                       forecaster    = forecaster,\n                       series        = multi_series,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = 1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n\n\nmethods = [\n    \"fit\",\n    \"create_train_X_y\",\n    \"backtest_refit_parallel\",\n    \"backtest_refit_noparallel\",\n    \"backtest_no_refit_parallel\",\n    \"backtest_no_refit_noparallel\",\n    \"gridSearch_no_refit_parallel\",\n    \"gridSearch_no_refit_noparallel\"\n]\n\nresults = pd.DataFrame({\n    \"regressor\": np.repeat(np.array([str(regressor) for regressor in regressors]), len(methods)),\n    \"method\": np.tile(methods, len(regressors)),\n    \"elapsed_time\": elapsed_times\n})\nresults[\"regressor\"] = results[\"regressor\"].str.replace(\"\\n              \", \" \")\nresults['parallel'] = results.method.str.contains(\"_parallel\")\nresults['method'] = results.method.str.replace(\"_parallel\", \"\")\nresults['method'] = results.method.str.replace(\"_noparallel\", \"\")\nresults = results.sort_values(by=[\"regressor\", \"method\", \"parallel\"])\n\nresults_pivot = results.pivot_table(\n    index=[\"regressor\", \"method\"],\n    columns=\"parallel\",\n    values=\"elapsed_time\"\n).reset_index()\nresults_pivot.columns.name = None\nresults_pivot[\"pct_improvement\"] = (results_pivot[False] - results_pivot[True]) / results_pivot[False] * 100\ndisplay(results_pivot)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nbars = sns.barplot(data=results_pivot.dropna(), x=\"method\", y=\"pct_improvement\", hue=\"regressor\", ax=ax)\nfor container in bars.containers:\n    ax.bar_label(container, fmt='%.1f', padding=3, fontsize=8)\nax.set_title(\"Parallel vs Sequential (ForecasterRecursiveMultiSeries)\")\nax.set_ylabel(\"Percent improvement\")\nax.set_xlabel(\"Method\")\nax.legend(fontsize=8, loc='lower left', bbox_to_anchor=(0, -0.31), ncols=1);\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Time Series Data in Python\nDESCRIPTION: Fetches and preprocesses the 'fuel_consumption' dataset using skforecast, renaming and normalizing columns for consistent usage. Focuses on preparing the data for model training and evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Data\n# ==============================================================================\ndata = fetch_dataset(name = 'fuel_consumption')\ndata = data.loc[:\"2019-01-01\", ['Gasolinas']]\ndata = data.rename(columns = {'Gasolinas': 'consumption'})\ndata.index.name = 'date'\ndata['consumption'] = data['consumption'] / 100000\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries and Modules in Python\nDESCRIPTION: This snippet imports essential libraries and modules including Numpy, Pandas, LightGBM, Scikit-learn and specific components from Skforecast necessary for setting up data transformations and machine learning models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Libraries\n# ==============================================================================\\nimport numpy as np\\nimport pandas as pd\\nfrom lightgbm import LGBMRegressor\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import PowerTransformer\\nfrom sklearn.preprocessing import FunctionTransformer\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.pipeline import Pipeline\\nfrom skforecast.datasets import fetch_dataset\\nfrom skforecast.recursive import ForecasterRecursive\\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\\nfrom skforecast.model_selection import TimeSeriesFold\\nfrom skforecast.model_selection import grid_search_forecaster\n```\n\n----------------------------------------\n\nTITLE: ForecasterDirect with Parallel Processing\nDESCRIPTION: Creates a direct multi-step forecaster with automatic parallel processing configuration\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirect(\n                 regressor        = LGBMRegressor(random_state=123, verbose=-1),\n                 steps            = 5,\n                 lags             = 5,\n                 window_features  = None,\n                 transformer_y    = None,\n                 transformer_exog = None,\n                 weight_func      = None,\n                 fit_kwargs       = None,\n                 n_jobs           = 'auto',\n                 forecaster_id    = 'my_forecaster'\n             )\n```\n\n----------------------------------------\n\nTITLE: Plotting Zoomed Prediction Intervals for Time Series Forecasts in Python\nDESCRIPTION: Creates a zoomed view of prediction intervals for a specific date range ('2018-05-01' to '2018-05-15'). This allows for detailed inspection of model performance during a particular time period of interest.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Plot intervals with zoom ['2018-05-01', '2018-05-15']\n# ==============================================================================\nplot_prediction_intervals(\n    predictions         = predictions,\n    y_true              = data_test,\n    target_variable     = \"OT\",\n    initial_x_zoom      = ['2018-05-01', '2018-05-15'],\n    title               = \"Predicted intervals\",\n    kwargs_fill_between = {'color': 'gray', 'alpha': 0.4, 'zorder': 1}\n);\n```\n\n----------------------------------------\n\nTITLE: Training and Predicting with Incomplete Exogenous Data in Skforecast\nDESCRIPTION: Demonstrates that a model can be trained and used for prediction when exogenous variables are missing in the initial window_size observations, as these aren't used in creating the training matrices.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 15\n             )\n\nforecaster.fit(\n    y    = data_train['y'],\n    exog = exog_no_first_window_size[['exog_1', 'exog_2']]\n)\n\n# Predict\n# ==============================================================================\npredictions = forecaster.predict(\n                  steps = 36,\n                  exog  = data_test[['exog_1', 'exog_2']]\n              )\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Implementing Backtesting for Time Series Forecasting\nDESCRIPTION: Performs backtesting using TimeSeriesFold to evaluate the model's performance over multiple time windows, using mean absolute error as the evaluation metric.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Backtesting\n# ==============================================================================\ncv = TimeSeriesFold(\n         steps              = 15,\n         initial_train_size = len(data_train),\n         refit              = True\n     )\n\nmetric, predictions = backtesting_forecaster(\n                          forecaster = forecaster,\n                          y          = data,\n                          cv         = cv,\n                          metric     = 'mean_absolute_error'\n                      )\n\nprint(\"Backtest error:\")\nmetric\n```\n\n----------------------------------------\n\nTITLE: Displaying Backtesting Results in Markdown Format\nDESCRIPTION: Outputs the backtesting results as a markdown table for better readability, showing the relationship between refit strategies, execution time, and forecast accuracy metrics.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(results.to_markdown())\n```\n\n----------------------------------------\n\nTITLE: Applying Ordinal Encoding with ColumnTransformer in Python\nDESCRIPTION: A ColumnTransformer is used here to apply ordinal encoding to categorical features. The encoding helps in preparing data where the order of categories matters. Missing values are encoded as -1.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n# ColumnTransformer with ordinal encoding\n# ============================================================================== \n# A ColumnTransformer is used to transform categorical (not numerical) features \n# using ordinal encoding. Numeric features are left untouched. Missing values \n# are coded as -1. If a new category is found in the test set, it is encoded \n# as -1. \nordinal_encoder = make_column_transformer( \n                      ( \n                          OrdinalEncoder( \n                              handle_unknown='use_encoded_value', \n                              unknown_value=-1, \n                              encoded_missing_value=-1 \n                          ), \n                          make_column_selector(dtype_exclude=np.number) \n                      ), \n                      remainder=\"passthrough\", \n                      verbose_feature_names_out=False, \n                  ).set_output(transform=\"pandas\")\n```\n\n----------------------------------------\n\nTITLE: Loading a Forecaster Model\nDESCRIPTION: This code snippet demonstrates how to load a previously saved forecaster model from a joblib file using the load_forecaster function, with verbose output enabled to display process details.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Load model\n# ============================================================================== \nforecaster_loaded = load_forecaster('forecaster_001.joblib', verbose=True)\n```\n\n----------------------------------------\n\nTITLE: Aggregating Time Series Data to Daily Frequency\nDESCRIPTION: Resamples the air quality data to daily frequency by calculating the mean value for each day, reducing the dimensionality of the dataset for easier analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Aggregate at daily frequency to reduce dimensions\n# ==============================================================================\ndata = data.resample('D').mean()\nprint(\"Shape: \", data.shape)\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Calendar Feature Extraction in Python\nDESCRIPTION: This snippet imports the necessary libraries for working with time series data, including pandas for data manipulation, matplotlib for visualization, and custom modules for dataset fetching and feature engineering.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skforecast.datasets import fetch_dataset\nfrom feature_engine.datetime import DatetimeFeatures\nfrom feature_engine.creation import CyclicalFeatures\n```\n\n----------------------------------------\n\nTITLE: Initializing Recursive Forecaster\nDESCRIPTION: Creates a recursive forecaster using HistGradientBoostingRegressor with a single non-informative lag for evaluating cyclical features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/cyclical-features-time-series.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n    regressor = HistGradientBoostingRegressor(random_state=123),\n    lags      = [70]\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Exogenous Feature Transformer in Fitted Forecaster\nDESCRIPTION: This snippet demonstrates how to access and inspect the transformer used for exogenous features after fitting the forecaster. It prints the output feature names and displays the transformer object.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Access to the transformer used for exogenous features\n# ==============================================================================\nprint(forecaster.transformer_exog.get_feature_names_out())\nforecaster.transformer_exog\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterDirect with Multi-Step Configuration\nDESCRIPTION: Creates a direct multi-step forecaster with LightGBM regressor, configured to predict 5 steps ahead\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirect(\n                 regressor        = LGBMRegressor(random_state=123, verbose=-1),\n                 steps            = 5,\n                 lags             = 5,\n                 window_features  = None,\n                 transformer_y    = None,\n                 transformer_exog = None,\n                 weight_func      = None,\n                 fit_kwargs       = None,\n                 forecaster_id    = 'my_forecaster'\n             )\n```\n\n----------------------------------------\n\nTITLE: Initializing Performance Benchmark for ForecasterRecursive in Python\nDESCRIPTION: Configures regressors, parameter grids, and performance measurement setup for comparing different machine learning models in time series forecasting\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nregressors = [\n    Ridge(random_state=77, alpha=0.1),\n    LGBMRegressor(random_state=77, n_jobs=1, n_estimators=50, max_depth=5, verbose=-1),\n    LGBMRegressor(random_state=77, n_jobs=-1, n_estimators=50, max_depth=5, verbose=-1),\n    HistGradientBoostingRegressor(random_state=77, max_iter=50, max_depth=5,),\n]\n```\n\n----------------------------------------\n\nTITLE: Fetching Best Trial from Bayesian Search in Python\nDESCRIPTION: This snippet retrieves the best trial information from the Bayesian search results, allowing examination of the parameters that yielded the best model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nbest_trial\n```\n\n----------------------------------------\n\nTITLE: Testing Prediction with Recursive Forecaster\nDESCRIPTION: This snippet uses a grid of parameters to test predictions using the ForecasterRecursiveMultiSeries model. It evaluates different encoding methods and prediction intervals while fitting the model with training data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nparams = {\n    \\\"encoding\\\": [\\\"ordinal\\\", \\\"onehot\\\", \\\"ordinal_category\\\"],\n    \\\"dropna_from_series\\\": [False, True],\n    \\\"interval\\\": [[5, 95]],\n    \\\"n_boot\\\": [10],\n}\n\nparams_grid = list(ParameterGrid(params))\n\nfor params in tqdm(params_grid):\n    print(f\\\"Paramns: {params}\\\")\n\n    forecaster = ForecasterRecursiveMultiSeries(\n        regressor=LGBMRegressor(\n            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n        ),\n        lags=14,\n        encoding=params[\\\"encoding\\\"],\n        dropna_from_series=params[\\\"dropna_from_series\\\"],\n        transformer_series=StandardScaler(),\n        transformer_exog=StandardScaler(),\n    )\n    forecaster.fit(\n        series=series_dict_train, exog=exog_dict_train, suppress_warnings=True,\n        store_in_sample_residuals=True\n    )\n    predictions = forecaster.predict(\n        steps=5, exog=exog_dict_test, suppress_warnings=True\n    )\n    predictions_int = forecaster.predict_interval(\n        steps=5,\n        exog=exog_dict_test,\n        interval=params[\\\"interval\\\"],\n        n_boot=params[\\\"n_boot\\\"],\n        suppress_warnings=True,\n    )\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing Forecasting Results with Exogenous Variables in Python\nDESCRIPTION: Creates a plot comparing the training data, test data, and model predictions to visually evaluate forecasting performance when using exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3.5))\ndata_train['y'].plot(ax=ax, label='train')\ndata_test['y'].plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend()\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking Ridge with ForecasterDirect on Electricity Demand Data\nDESCRIPTION: Implements a ForecasterDirect with Ridge regression and StandardScaler for electricity demand forecasting. The forecaster is configured to predict 24 steps ahead using temperature and holiday as exogenous features, with alpha parameter tuning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Dataset vic_electricity - ForecasterDirect\n# ==============================================================================\nforecaster = ForecasterDirect(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 steps         = 24,\n                 lags          = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\nparam_grid = {'alpha': np.logspace(-3, 3, 20)}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_electricity,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'Demand',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'electricity',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Creating Predictors for Custom Features in skforecast  0.14\nDESCRIPTION: This snippet initializes a `RollingFeatures` object to create custom feature sets based on a specified window size. This is used with the `ForecasterRecursive` forecaster in version 0.14 and above.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.preprocessing import RollingFeatures\n\nrolling = RollingFeatures(\n    ststs        = ['mean', 'std', 'min', 'max'],\n    window_sizes = [20, 20, 20, 20]\n)\n\nforecaster = ForecasterRecursive(\n    regressor       = LGBMRegressor(random_state=123, verbose=-1),\n    lags            = 10,\n    window_features = rolling\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Recursive Forecaster with Ridge Regression\nDESCRIPTION: Initializes a recursive forecaster using Ridge regression with 24 lags to predict time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n    regressor = Ridge(random_state=123),\n    lags      = 24\n)\n```\n\n----------------------------------------\n\nTITLE: Examining Backtesting Predictions\nDESCRIPTION: Displays the first few rows of the backtesting predictions dataframe to inspect the forecast values across different time periods.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Backtesting predictions\n# ==============================================================================\npredictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Fetching Data for Multi-Series Forecasting\nDESCRIPTION: This snippet fetches sales data for different items, preparing it for use with ForecasterRecursiveMultiSeries for multi-series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Data download\n# ============================================================================== \ndata = fetch_dataset(name=\"items_sales\")\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Fetching and Preparing Data in Python\nDESCRIPTION: This snippet fetches a dataset named 'ett_m2_extended' and selects specific columns for use in modeling. It prepares the data for subsequent steps in the forecasting process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ============================================================================== \ndata = fetch_dataset(name=\"ett_m2_extended\")\ndata = data[[\n    \"OT\",\n    \"day_of_week_cos\",\n    \"day_of_week_sin\",\n    \"hour_cos\",\n    \"hour_sin\",\n    \"month_cos\",\n    \"month_sin\",\n    \"week_cos\",\n    \"week_sin\",\n    \"year\",\n]]\ndata.head(2)\n```\n\n----------------------------------------\n\nTITLE: Forecaster Training and Backtesting\nDESCRIPTION: Creates and trains a ForecasterRecursive model with custom weights and performs backtesting using TimeSeriesFold.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor   = LGBMRegressor(random_state=123, verbose=-1),\n                 lags        = 14,\n                 weight_func = custom_weights\n             )\n\ncv = TimeSeriesFold(\n        steps              = 7,\n        initial_train_size = len(data.loc[:end_train]),\n        refit              = True,\n        fixed_train_size   = False,\n     )\nmetric, predictions = backtesting_forecaster(\n                            forecaster    = forecaster,\n                            y             = data.users_imputed,\n                            cv            = cv,\n                            metric        = 'mean_absolute_error',\n                            verbose       = False,\n                            show_progress = True\n                        )\n\nmetric\n```\n\n----------------------------------------\n\nTITLE: Fetching and Preparing Dataset with Pandas\nDESCRIPTION: This code snippet demonstrates fetching a dataset using the 'fetch_dataset' function, selecting particular columns for analysis, and displaying the first few rows of the dataset. It prepares the dataset for feature extraction by focusing on exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# ==============================================================================\ndata = fetch_dataset(name='bike_sharing', raw=False)\ndata = data.loc[:, ['users', 'holiday', 'temp', 'windspeed']]\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Executing Backtesting Grid Search\nDESCRIPTION: Performs grid search with backtesting cross-validation strategy for multi-series forecasting. Uses TimeSeriesFold for validation with specified initial train size.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ncv = TimeSeriesFold(\n        initial_train_size=len(series_dict_train[\"id_1000\"]),\n        steps=1,\n        refit=False,\n    )\n\nresults_backtesting = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series_dict,\n    exog=exog_dict,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=metrics,\n    cv=cv,\n    return_best=False,\n    show_progress=True,\n    verbose=False,\n    suppress_warnings=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Plotting Test Data and Predictions with Matplotlib\nDESCRIPTION: This snippet uses Matplotlib to plot the 'users' column from the `data_test` DataFrame and the 'pred' column from the `predictions` DataFrame on the same axes. This allows for visual comparison of the test data and the model's predictions. The plot includes a legend to distinguish the two lines.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_test['users'].plot(ax=ax, label='test')\npredictions['pred'].plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Configuring Environment in Python\nDESCRIPTION: This snippet imports necessary libraries like pandas for data processing, matplotlib for plotting, and skforecast for time series forecasting, and sets up warning configurations. It is essential for preparing the environment before data manipulation and modeling.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Data processing\n# ============================================================================== \nimport pandas as pd\nfrom skforecast.datasets import fetch_dataset\n\n# Plots\n# ============================================================================== \nimport matplotlib.pyplot as plt\nfrom skforecast.plot import set_dark_theme\n\n# Modelling and Forecasting\n# ============================================================================== \nfrom lightgbm import LGBMRegressor\nfrom skforecast.direct import ForecasterDirect\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.model_selection import bayesian_search_forecaster\nfrom skforecast.metrics import calculate_coverage\nfrom skforecast.metrics import create_mean_pinball_loss\n\n# Configuration\n# ============================================================================== \nimport warnings\nwarnings.filterwarnings('once')\n```\n\n----------------------------------------\n\nTITLE: Initializing Multi-Series Forecaster with LightGBM\nDESCRIPTION: Configures a recursive multi-series forecaster using LightGBM regressor with standardization and ordinal encoding. Sets up initial parameters including lags, scaling, and base model configuration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor=LGBMRegressor(n_estimators=10, random_state=123, verbose=-1, max_depth=2),\n    lags=14,\n    encoding=\"ordinal\",\n    dropna_from_series=False,\n    transformer_series=StandardScaler(),\n    transformer_exog=StandardScaler(),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Time Series Forecasting\nDESCRIPTION: Imports necessary Python libraries for time series analysis, including skforecast, scikit-learn, LightGBM, and data manipulation libraries. Sets up warning filters for smooth execution.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport platform\nimport psutil\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom copy import copy\nimport sklearn\nimport skforecast\nimport lightgbm\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.plot import set_dark_theme\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.direct import ForecasterDirect\nfrom skforecast.model_selection import TimeSeriesFold, OneStepAheadFold\nfrom skforecast.model_selection import grid_search_forecaster\nfrom skforecast.model_selection import bayesian_search_forecaster\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.direct import ForecasterDirectMultiVariate\nfrom skforecast.model_selection import backtesting_forecaster_multiseries\nfrom skforecast.model_selection import grid_search_forecaster_multiseries\nfrom skforecast.model_selection import bayesian_search_forecaster_multiseries\nfrom skforecast.preprocessing import series_long_to_dict\nfrom skforecast.preprocessing import exog_long_to_dict\n\n# Warnings\n# ==============================================================================\nimport warnings\nfrom skforecast.exceptions import IgnoredArgumentWarning\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore', category=IgnoredArgumentWarning)\n```\n\n----------------------------------------\n\nTITLE: Resampling Time Series Data from 30 Minutes to Hourly in Python\nDESCRIPTION: This code demonstrates how to resample time series data from 30-minute intervals to hourly intervals using pandas. It aggregates demand by sum and other columns by mean, avoiding data leakage.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/time-series-aggregation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Aggregate data from 30 minutes to 1 hour\n# ==============================================================================\ndata = data.resample(rule='1h', closed='left', label ='right').agg({\n           'Demand': 'sum',\n           'Temperature': 'mean',\n           'Holiday': 'mean'\n       })\n\ndata\n```\n\n----------------------------------------\n\nTITLE: ForecasterRecursive with Binning Configuration\nDESCRIPTION: Creates a recursive forecaster with quantile-based binning using 10 bins for prediction intervals\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(),\n                 lags             = 5,\n                 window_features  = None,\n                 transformer_y    = None,\n                 transformer_exog = None,\n                 weight_func      = None,\n                 differentiation  = None,\n                 fit_kwargs       = None,\n                 binner_kwargs    = {'n_bins': 10}\n             )\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting with Exogenous Variables in Python\nDESCRIPTION: Imports necessary libraries for time series forecasting including pandas, matplotlib, LGBMRegressor, sklearn metrics and pipelines, feature engineering tools, and skforecast components.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import make_pipeline\nfrom feature_engine.timeseries.forecasting import WindowFeatures\nfrom feature_engine.timeseries.forecasting import LagFeatures\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Create and Train XGBoost Forecaster (Version >= 2.0)\nDESCRIPTION: Creates and trains an `XGBRegressor` model within a `ForecasterRecursive` object, configuring it to use the GPU if available.  The `tree_method` is set to `'hist'` and `device` is set to `'cuda'` to enable GPU usage in XGBoost version 2.0 or later.  The forecaster is then fitted to the generated data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Create and train forecaster with a XGBRegressor using GPU\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = XGBRegressor(\n                                 n_estimators = 5000,\n                                 tree_method  = 'hist',\n                                 device       = 'cuda'\n                             ),\n                 lags = 20\n             )\n\nforecaster.fit(y=data)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Lags with None in Python\nDESCRIPTION: This snippet creates a forecaster with specified lags while allowing some series to not have any lags by setting the lags to None, demonstrating flexibility in the model configuration.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nlags_dict = {\n    'so2': [7, 14], 'co': None, 'no': [7, 14], 'no2': [7, 14],\n    'pm10': [7, 14], 'nox': [7, 14], 'o3': [7, 14], 'veloc.': 3,\n    'direc.': 3, 'pm2.5': [7, 14]\n}\nforecaster = ForecasterDirectMultiVariate(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 level     = 'co',\n                 lags      = lags_dict,\n                 steps     = 7,\n             )\n\nforecaster.fit(series=data_train)\n\npredictions = forecaster.predict(steps=7)\npredictions\n```\n\n----------------------------------------\n\nTITLE: Adding Window Features to ForecasterRecursive in Python\nDESCRIPTION: Demonstration of including window features in ForecasterRecursive. This allows for additional predictors based on previous values of the series, such as moving averages.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom lightgbm import LGBMRegressor\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\n\nwindow_features = RollingFeatures(\n    stats        = ['mean', 'mean', 'min', 'max'],\n    window_sizes = [20, 10, 10, 10]\n)\n\nforecaster = ForecasterRecursive(\n    regressor       = LGBMRegressor(random_state=123, verbose=-1),\n    lags            = 5,\n    window_features = window_features\n)\n```\n\n----------------------------------------\n\nTITLE: Plotting Backtesting Predictions for Multiple Time Series\nDESCRIPTION: This code creates a plot of the original time series along with their backtesting predictions. It handles cases where predictions might not be available for some series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfig, axs = plt.subplots(5, 1, figsize=(8, 4), sharex=True)\n\nfor i, s in enumerate(series_dict.keys()):\n    axs[i].plot(series_dict[s], label=series_dict[s].name, color=colors[i])\n    axs[i].axvline(pd.to_datetime(end_train), color='white', linestyle='--', linewidth=1)  # End train\n    try:\n        axs[i].plot(backtest_predictions[s], label='prediction', color=\"white\")\n    except:\n        pass\n    axs[i].legend(loc='upper right', fontsize=8)\n    axs[i].tick_params(axis='both', labelsize=8)\n\nfig.suptitle('Backtest Predictions', fontsize=15)\nplt.tight_layout()\n```\n\n----------------------------------------\n\nTITLE: Plotting Time Series Data in Python\nDESCRIPTION: Visualizes time series data using matplotlib, depicting the training and test sets. Highlights a shutdown period with a shaded region for clarity.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Time series plot\n# =================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train['production'].plot(ax=ax, label='train', linewidth=1)\ndata_test['production'].plot(ax=ax, label='test', linewidth=1)\nax.axvspan(\n    pd.to_datetime('2012-06'),\n    pd.to_datetime('2012-10'), \n    label=\"Shutdown\",\n    color=\"gray\",\n    alpha=0.3\n)\nax.set_title('Energy production')\nax.set_xlabel(\"\")\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Plotting Test Data and Predictions with Matplotlib\nDESCRIPTION: This snippet uses Matplotlib to plot the 'users' column from the `data_test` DataFrame and the 'pred' column from the `predictions` DataFrame on the same axes. This allows for visual comparison of the test data and the model's predictions. The plot includes a legend to distinguish the two lines.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_test['users'].plot(ax=ax, label='test')\npredictions['pred'].plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Error on Test Data\nDESCRIPTION: Computes and displays the Mean Squared Error (MSE) between the predicted values and the actual test data to quantify model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error on test data\n# ==============================================================================\nerror_mse = mean_squared_error(\n                y_true = data.loc[end_train:],\n                y_pred = predictions\n            )\nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting XGBoost Forecaster\nDESCRIPTION: Initializes a recursive forecaster using XGBoost regressor, configuring lags and rolling window features for time series prediction\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-xgboost-lightgbm.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor       = XGBRegressor(random_state=123, enable_categorical=True),\n                 lags            = 8,\n                 window_features = RollingFeatures(stats=['mean'], window_sizes=[7]),\n             )\n\nforecaster.fit(y=data_train['y'], exog=data_train[['exog_1', 'exog_2']])\nforecaster\n```\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================================================================\nforecaster.predict(steps=10, exog=data_test[['exog_1', 'exog_2']])\n```\n\nLANGUAGE: python\nCODE:\n```\n# Feature importances\n# ==============================================================================\nforecaster.get_feature_importances()\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Hyperparameter Tuning in Skforecast\nDESCRIPTION: Imports necessary libraries for time series forecasting, including numpy, pandas, matplotlib, LGBMRegressor, skforecast components for recursive forecasting, and model selection utilities for hyperparameter tuning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.plot import set_dark_theme\nfrom skforecast.model_selection import (\n    TimeSeriesFold,\n    OneStepAheadFold,\n    grid_search_forecaster,\n    random_search_forecaster,\n    bayesian_search_forecaster\n)\n```\n\n----------------------------------------\n\nTITLE: Identifying Negative Predictions in XGBoost Output\nDESCRIPTION: This snippet identifies negative predictions in the `predictions` DataFrame. It filters the DataFrame to show only the rows where the 'pred' column has values less than 0. This helps in identifying and addressing potential issues with the model's predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Negative predictions\npredictions[predictions.pred < 0]\n```\n\n----------------------------------------\n\nTITLE: Accessing Series Transformers\nDESCRIPTION: Shows how to access and inspect the fitted transformers for each series through the transformers_series_ attribute.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfor k, v in forecaster.transformer_series_.items():\n    print(f\"Series {k}: {v} mean={v.mean_}, scale={v.scale_}\")\n```\n\n----------------------------------------\n\nTITLE: Import Libraries for skforecast\nDESCRIPTION: This code imports the necessary libraries for time series forecasting using skforecast, including numpy, pandas, matplotlib, lightgbm, and specific modules from skforecast for plotting, preprocessing, recursive forecasting, and model selection.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMRegressor\nfrom skforecast.plot import set_dark_theme\nfrom skforecast.preprocessing import series_long_to_dict, exog_long_to_dict, RollingFeatures\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection import (\n    TimeSeriesFold,\n    backtesting_forecaster_multiseries,\n    bayesian_search_forecaster_multiseries\n)\"\n```\n\n----------------------------------------\n\nTITLE: Checking Exogenous Feature Selection in Python\nDESCRIPTION: This code snippet checks if all exogenous features are selected when `select_only = 'autoreg'` is used during feature selection. It verifies that the number of selected exogenous features matches the total number of exogenous features in the dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n\"# Check all exogenous features are selected\n# ==============================================================================\nlen(selected_exog) == data.drop(columns=\"users\").shape[1]\"\n```\n\n----------------------------------------\n\nTITLE: Pipeline Integration as Regressor\nDESCRIPTION: Demonstrates using a scikit-learn Pipeline combining StandardScaler and Ridge regression as the forecaster regressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\npipe = Pipeline(steps=[('scaler', StandardScaler()), ('regressor', Ridge())])\n\nforecaster = ForecasterRecursive(\n    regressor = pipe,\n    lags      = 10\n)\n\nforecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2']])\n```\n\n----------------------------------------\n\nTITLE: Printing Categorical Features Used by HistGradientBoostingRegressor\nDESCRIPTION: Retrieves and displays the names of features that were treated as categorical by the regressor by accessing the boolean mask and feature names from the model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n# Print the features considered as categorical by the forecaster\n# ==============================================================================\nforecaster.regressor.feature_names_in_[forecaster.regressor.is_categorical_]\n```\n\n----------------------------------------\n\nTITLE: Data Import and Preprocessing for Time Series Analysis\nDESCRIPTION: Loads and preprocesses multiple time series datasets including bike sharing, sales data, website visits, and electricity consumption. Includes data transformation and feature engineering steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Import data\n# ==============================================================================\ndata_bike = fetch_dataset('bike_sharing_extended_features', verbose=False)\n\ndata_sales = fetch_dataset(name=\"items_sales\", verbose=False)\ndata_sales = data_sales * 100\ndata_sales['day_of_week'] = data_sales.index.dayofweek\n\ndata_website = fetch_dataset(name=\"website_visits\", raw=True, verbose=False)\ndata_website['date'] = pd.to_datetime(data_website['date'], format='%d/%m/%y')\ndata_website = data_website.set_index('date')\ndata_website = data_website.asfreq('1D')\ndata_website = data_website.sort_index()\ndata_website['month'] = data_website.index.month\ndata_website['month_day'] = data_website.index.day\ndata_website['week_day'] = data_website.index.day_of_week\ndata_website = pd.get_dummies(data_website, columns=['month', 'week_day', 'month_day'], dtype='int64')\n\ndata_electricity = fetch_dataset(name='vic_electricity', raw=False, verbose=False)\ndata_electricity = data_electricity.drop(columns=\"Date\")\ndata_electricity = (\n    data_electricity\n    .resample(rule=\"h\", closed=\"left\", label=\"right\")\n    .agg({\n        \"Demand\": \"mean\",\n        \"Temperature\": \"mean\",\n        \"Holiday\": \"mean\",\n    })\n)\ndata_electricity = data_electricity.loc['2012-01-01 00:00:00': '2013-12-30 23:00:00'].copy()\n\nseries_dict = pd.read_csv(\n    'https://raw.githubusercontent.com/skforecast/skforecast-datasets/main/data/demo_multi_series.csv'\n)\nexog_dict = pd.read_csv(\n    'https://raw.githubusercontent.com/skforecast/skforecast-datasets/main/data/demo_multi_series_exog.csv'\n)\nseries_dict['timestamp'] = pd.to_datetime(series_dict['timestamp'])\nexog_dict['timestamp'] = pd.to_datetime(exog_dict['timestamp'])\nseries_dict = series_long_to_dict(\n    data      = series_dict,\n    series_id = 'series_id',\n    index     = 'timestamp',\n    values    = 'value',\n    freq      = 'D'\n)\nexog_dict = exog_long_to_dict(\n    data      = exog_dict,\n    series_id = 'series_id',\n    index     = 'timestamp',\n    freq      = 'D'\n)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Multi-Series Data for Forecasting\nDESCRIPTION: This code visualizes multi-series data by creating a subplot for each series. It displays the first few rows of the dataset and creates line plots for each time series to visually inspect the data patterns.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ==============================================================================\ndisplay(data_multiseries.head(3))\n\n# Plot\n# ==============================================================================\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize=(9, 4), sharex=True)\n\nfor i, col in enumerate(data_multiseries.columns):\n    data_multiseries[col].plot(ax=axes[i])\n    axes[i].set_xlabel('')\n    axes[i].set_ylabel('sales')\n    axes[i].set_title(col)\n\nfig.tight_layout()\nplt.show();\n```\n\n----------------------------------------\n\nTITLE: Visualizing Intervals and True Values with Matplotlib\nDESCRIPTION: This snippet uses matplotlib to plot the generated prediction intervals and true values. It displays the lower and upper bounds of the `interval` DataFrame using dashed lines and plots the `y_true` Series as a solid line, adding a legend for clarity.  The axes labels are removed for a cleaner visualization and the plot is displayed using `plt.show()`.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfig, ax = plt.subplots(figsize=(7, 3))\ninterval.plot(ax=ax, linestyle=\"--\")\ny_true.plot(ax=ax, label='True values')\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=3)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Plotting Predictions from ForecasterSarimax Model in Python\nDESCRIPTION: This code creates a plot comparing the training data, test data, and predictions from the ForecasterSarimax model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train['y'].plot(ax=ax, label='train')\ndata_test['y'].plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Creating Example Exogenous Variables\nDESCRIPTION: Creates example exogenous variables with different values for each series using pandas Series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nexog_1_item_1_train = pd.Series([1] * len(data_exog_train), name='exog_1', index=data_exog_train.index)\nexog_1_item_2_train = pd.Series([10] * len(data_exog_train), name='exog_1', index=data_exog_train.index)\nexog_1_item_3_train = pd.Series([100] * len(data_exog_train), name='exog_1', index=data_exog_train.index)\n\nexog_1_item_1_test = pd.Series([1] * len(data_exog_test), name='exog_1', index=data_exog_test.index)\nexog_1_item_2_test = pd.Series([10] * len(data_exog_test), name='exog_1', index=data_exog_test.index)\nexog_1_item_3_test = pd.Series([100] * len(data_exog_test), name='exog_1', index=data_exog_test.index)\n```\n\n----------------------------------------\n\nTITLE: Verifying Rolling Mean Calculation for Specific Timestamp in Python\nDESCRIPTION: This code snippet demonstrates how to verify the rolling mean calculation for a specific timestamp. It calculates the mean of the first 4 hours of data to confirm the rolling mean result.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/time-series-aggregation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# '2011-12-31 18:00:00' mean\n# ==============================================================================\ndata.iloc[0:4, :].mean()\n```\n\n----------------------------------------\n\nTITLE: Creating Training Data with DataFrame Inputs\nDESCRIPTION: Shows how to create training data when both series and exogenous variables are provided as DataFrames.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 4,\n                 encoding           = 'ordinal',\n                 transformer_series = StandardScaler()\n             )\n\nX, y = forecaster.create_train_X_y(\n    series = data_exog_train[['item_1', 'item_2', 'item_3']], \n    exog   = data_exog_train[['month']]\n)\nX.head(3)\n```\n\n----------------------------------------\n\nTITLE: Installing skforecast with All Optional Dependencies\nDESCRIPTION: Installs the full version of skforecast including all optional dependencies for extended functionality. This provides access to all features without needing to install dependencies separately.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast[full]\n```\n\n----------------------------------------\n\nTITLE: Predicting Unknown Series\nDESCRIPTION: Shows how to predict values for a new series not seen during training using last window data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nlast_window_item_4 = pd.DataFrame(\n    data    = [23.46, 22.3587, 29.348],\n    columns = ['item_4'],\n    index   = pd.date_range(start=\"2014-07-13\", periods=3, freq=\"D\"),\n)\n\nforecaster.predict(\n    levels            = 'item_4', \n    steps             = 3, \n    last_window       = last_window_item_4,\n    suppress_warnings = False\n)\n```\n\n----------------------------------------\n\nTITLE: Step-Wise Training Predictions using Skforecast in Python\nDESCRIPTION: This snippet calculates training predictions for a specified step using the associated internal regressor within a ForecasterDirect model, facilitating step-wise analysis of forecasting effectiveness.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Step 1 training predictions using the internal regressor\n# ============================================================================== \npredictions_training = forecaster.regressors_[1].predict(X_train_1)\npredictions_training[:4]\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting with Categorical Features\nDESCRIPTION: This snippet imports the necessary libraries for handling categorical features in time series forecasting. It includes numpy, pandas, matplotlib, scikit-learn, LightGBM, and XGBoost, as well as various preprocessing and forecasting modules from skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport lightgbm\nimport xgboost\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import TargetEncoder\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.compose import make_column_selector\nfrom sklearn.pipeline import make_pipeline\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nplt.style.use('fivethirtyeight')\nplt.rcParams['lines.linewidth'] = 1.5\ncolor = '\\033[1m\\033[38;5;208m' \nprint(f\"{color}Version scikit-learn: {sklearn.__version__}\")\nprint(f\"{color}Version lightgbm: {lightgbm.__version__}\")\nprint(f\"{color}Version xgboost: {xgboost.__version__}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Forecasting and Data Processing in Python\nDESCRIPTION: Imports necessary libraries for data processing (numpy, pandas), modeling (lightgbm, scikit-learn), and forecasting (skforecast). It includes warning suppression for cleaner output.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Data processing\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\n\n# Modelling and Forecasting\n# ==============================================================================\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import KFold\n\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.model_selection import grid_search_forecaster\n\n# Warnings\n# ==============================================================================\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Time Series Data with Pandas in Python\nDESCRIPTION: Downloads and preprocesses time series data related to energy production from an external source. It formats dates, sets the index, and sorts the dataset in preparation for analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Data download\n# ================================================\nurl = (\n    'https://raw.githubusercontent.com/skforecast/skforecast-datasets/refs/heads/'\n    'main/data/energy_production_shutdown.csv'\n)\ndata = pd.read_csv(url, sep=',')\n\n# Data preprocessing\n# ================================================\ndata['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\ndata = data.set_index('date')\ndata = data.asfreq('D')\ndata = data.sort_index()\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Simulating and Plotting Under-conservative Intervals\nDESCRIPTION: Creates synthetic data with under-conservative prediction intervals and calculates initial coverage. Uses numpy for data generation and matplotlib for visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.default_rng(42)\ninterval = pd.DataFrame({\n        'lower_bound': np.sin(np.linspace(0, 4 * np.pi, 100)),\n        'upper_bound': np.sin(np.linspace(0, 4 * np.pi, 100)) + 5\n    },\n    index=pd.date_range(start='2024-01-01', periods=100, freq='D')\n)\ny_true = (interval['lower_bound'] + interval['upper_bound']) / 2 + rng.normal(0, 0.5, 100)\ny_true.name = \"series_1\"\ny_true.iloc[1::5] = interval.iloc[1::5, 0] - rng.normal(1, 1, 20)\ny_true.iloc[3::5] = interval.iloc[1::5, 1] + rng.normal(1, 1, 20)\n\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ninterval.plot(ax=ax, linestyle=\"--\")\ny_true.plot(ax=ax, label='True values')\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=3)\nplt.show()\n\ncoverage = calculate_coverage(\n    y_true=y_true,\n    lower_bound=interval[\"lower_bound\"],\n    upper_bound=interval[\"upper_bound\"],\n)\nprint(f'Coverage: {coverage:.2f}')\n```\n\n----------------------------------------\n\nTITLE: Creating Training Matrices for LightGBM Model Inspection in Python\nDESCRIPTION: Demonstrates how to extract the training matrices used by the forecaster. This can be useful for understanding the format of data fed to the model and for further analysis or debugging.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# Create training matrices\n# ==============================================================================\nX_train, y_train = forecaster.create_train_X_y(\n                       y    = data.loc[:end_train, 'users'],\n                       exog = data.loc[:end_train, exog_features]\n                   )\nX_train.head()\n```\n\n----------------------------------------\n\nTITLE: Checking Window Size Requirements for Exogenous Variables in Skforecast\nDESCRIPTION: Determines the minimum window size required by the forecaster to create predictors, which helps understand how many initial observations can have missing exogenous data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Window required by the Forecaster to create predictors\n# ==============================================================================\nwindow_size = forecaster.window_size\nprint(\"Window size required by the Forecaster:\", window_size)\n```\n\n----------------------------------------\n\nTITLE: Creating ForecasterRecursive with LGBMRegressor in Python\nDESCRIPTION: Example of initializing a ForecasterRecursive using LightGBM's LGBMRegressor as the underlying model. This demonstrates how to use a specific machine learning regressor with Skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\nforecaster = ForecasterRecursive(\n    regressor = LGBMRegressor(random_state=123, verbose=-1),\n    lags      = None\n)\n```\n\n----------------------------------------\n\nTITLE: Profiling Backtesting with Pyinstrument\nDESCRIPTION: Uses pyinstrument to profile the performance of backtesting_forecaster_multiseries function. The function evaluates the forecaster's performance using mean absolute error across multiple time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%%pyinstrument\n_ = backtesting_forecaster_multiseries(\n    forecaster    = forecaster,\n    series        = series,\n    cv            = cv,\n    metric        = \"mean_absolute_error\",\n    show_progress = False,\n    add_aggregated_metric = True\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Time Series Dataset for Forecasting in Python\nDESCRIPTION: This code fetches a dataset named 'h2o_exog' using skforecast's fetch_dataset function and sets the index name to 'datetime'.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(name=\"h2o_exog\")\ndata.index.name = 'datetime'\n```\n\n----------------------------------------\n\nTITLE: Setting Skforecast Warning Style with Warning Demo\nDESCRIPTION: Sets warning style to skforecast-specific format and demonstrates DataTransformationWarning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nset_warnings_style(\"skforecast\")\nwarnings.warn(\"deprecated\", DataTransformationWarning)\n```\n\n----------------------------------------\n\nTITLE: Predicting Unknown Series Without Encoding\nDESCRIPTION: Demonstrates prediction of unknown series when no encoding is used.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nforecaster.predict(\n    levels            = 'item_4', \n    steps             = 3, \n    last_window       = last_window_item_4,\n    suppress_warnings = False\n)\n```\n\n----------------------------------------\n\nTITLE: Making Time Series Predictions\nDESCRIPTION: Generates predictions for future time steps using the fitted forecaster model with exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nforecaster.predict(steps=3, exog=data_test[exog_features])\n```\n\n----------------------------------------\n\nTITLE: Display Head of Training Features and Target in Python\nDESCRIPTION: This simple snippet outputs the first four rows of the transformed training data matrices 'X_train' and 'y_train' to verify the transformation results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nX_train.head(4)\n```\n\nLANGUAGE: Python\nCODE:\n```\ny_train.head(4)\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data into Train and Test Sets\nDESCRIPTION: This code splits the bike sharing dataset into training and test sets based on specific date ranges. It defines start and end dates for the training and test periods and prints information about the resulting splits.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Split train-test\n# ==============================================================================\nstart_train = '2012-06-01 00:00:00'\nend_train = '2012-07-31 23:59:00'\nend_test = '2012-08-15 23:59:00'\ndata_train = data.loc[start_train:end_train, :]\ndata_test  = data.loc[end_train:end_test, :]\n\nprint(\n    f\"Dates train : {data_train.index.min()} --- {data_train.index.max()}\"\n    f\"  (n={len(data_train)})\"\n)\nprint(\n    f\"Dates test  : {data_test.index.min()} --- {data_test.index.max()}\"\n    f\"  (n={len(data_test)})\"\n)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Time Series Data\nDESCRIPTION: This code loads multiseries time series and exogenous data from CSV files, then processes and converts them into dictionaries. Missing values are introduced into the series, and certain columns are dropped from the exogenous data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nseries = pd.read_csv(\\\"../fixtures/sample_multi_series.csv\\\")\nexog = pd.read_csv(\\\"../fixtures/sample_multi_series_exog.csv\\\")\nseries[\\\"timestamp\\\"] = pd.to_datetime(series[\\\"timestamp\\\"])\nexog[\\\"timestamp\\\"] = pd.to_datetime(exog[\\\"timestamp\\\"])\n\nseries_dict = series_long_to_dict(\n    data=series, series_id=\\\"series_id\\\", index=\\\"timestamp\\\", values=\\\"value\\\", freq=\\\"D\\\"\n)\nexog_dict = exog_long_to_dict(\n    data=exog, series_id=\\\"series_id\\\", index=\\\"timestamp\\\", freq=\\\"D\\\"\n)\nseries_dict[\\\"id_1002\\\"].at[\\\"2016-02-01\\\"] = np.nan\nseries_dict[\\\"id_1002\\\"].at[\\\"2016-05-01\\\"] = np.nan\nexog_dict[\\\"id_1000\\\"] = exog_dict[\\\"id_1000\\\"].drop(\n    columns=[\\\"air_temperature\\\", \\\"wind_speed\\\"]\n)\nexog_dict[\\\"id_1003\\\"] = exog_dict[\\\"id_1003\\\"].drop(columns=[\\\"cos_day_of_week\\\"])\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Window Size Information\nDESCRIPTION: Shows the calculation of window size based on maximum lag and window features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Max lag            : \", forecaster.max_lag)\nprint(\"Max window size wf : \", forecaster.max_size_window_features)\nprint(\"Window size        : \", forecaster.window_size)\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting Time Series Forecaster\nDESCRIPTION: Initializes and fits a recursive forecaster using XGBoost with categorical feature support and custom transformer for exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nexog_features = ['holiday', 'weather', 'temp', 'hum']\nforecaster = ForecasterRecursive(\n                 regressor = XGBRegressor(\n                                 enable_categorical=True,\n                                 tree_method='hist',\n                                 random_state=963\n                             ),\n                 lags = 5,\n                 transformer_exog = transformer_exog\n             )\n            \nforecaster.fit(\n    y    = data.loc[:end_train, 'users'],\n    exog = data.loc[:end_train, exog_features]\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Forecaster Lags\nDESCRIPTION: Shows how to access the configured lags used as predictors in the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nforecaster.lags\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterRecursive with LightGBM and Categorical Features\nDESCRIPTION: Creates a recursive forecaster using LGBMRegressor with categorical feature specification and 5 lags\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(),\n                 lags             = 5,\n                 window_features  = None,\n                 transformer_y    = None,\n                 transformer_exog = None,\n                 weight_func      = None,\n                 differentiation  = None,\n                 fit_kwargs       = {'categorical_feature': ['exog_1', 'exog_2']}\n             )\n```\n\n----------------------------------------\n\nTITLE: Downloading Data Using Skforecast in Python\nDESCRIPTION: This code snippet demonstrates downloading various datasets using Skforecast's `fetch_dataset` method. The data includes single series and multiple series datasets, which are necessary for model fitting and predictions. Ensure that the datasets are properly formatted and aligned with the models used.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data single series\n# ==============================================================================   \ndata = fetch_dataset(\n    name=\"h2o\", kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n)\nprint(\"\")\n\ndata['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\ndata = data.set_index('datetime')\ndata = data.asfreq('MS')\ndata = data.sort_index()\n\n# Download data ForecasterRecursiveMultiSeries\n# ==============================================================================\ndata_multiseries = fetch_dataset(name=\"items_sales\")\nprint(\"\")\n\n# Download data ForecasterDirectMultiVariate\n# ==============================================================================\ndata_multivariate = fetch_dataset(name=\"air_quality_valencia_no_missing\")\n```\n\n----------------------------------------\n\nTITLE: Setting up Time Series Cross-Validation\nDESCRIPTION: Configures a TimeSeriesFold cross-validation with an initial training size of 80% of the data and forecasting steps of 24 periods. No refitting is performed between folds.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncv = TimeSeriesFold(\n     initial_train_size=int(len(series) * 0.8),\n     steps = 24,\n     refit = False\n)\n```\n\n----------------------------------------\n\nTITLE: ForecasterRecursive with Forecaster ID\nDESCRIPTION: Creates a recursive forecaster with a custom identifier and specific LightGBM regressor configuration\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n                 regressor        = LGBMRegressor(random_state=123, verbose=-1),\n                 lags             = 5,\n                 window_features  = None,\n                 transformer_y    = None,\n                 transformer_exog = None,\n                 weight_func      = None,\n                 differentiation  = None,\n                 fit_kwargs       = None,\n                 binner_kwargs    = None,\n                 forecaster_id    = 'my_forecaster'\n             )\n```\n\n----------------------------------------\n\nTITLE: Creating Logarithmic Transformer with Scikit-learn\nDESCRIPTION: Uses FunctionTransformer to create a custom logarithmic transformation that can be integrated directly into the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntransformer_y = FunctionTransformer(\n    func=np.log1p, \n    inverse_func=np.expm1, \n    validate=True\n)\n\nforecaster = ForecasterRecursive(\n    regressor        = Ridge(random_state=123),\n    lags             = 24,\n    transformer_y    = transformer_y,\n    transformer_exog = None\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Time Series Differentiation - Python\nDESCRIPTION: This code snippet imports essential libraries needed for time series differentiation using the TimeSeriesDifferentiator class. The NumPy library is used for numerical operations, while the skforecast library provides the TimeSeriesDifferentiator class for preprocessing time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\n# Libraries\n# ==============================================================================\\nimport numpy as np\\nfrom skforecast.preprocessing import TimeSeriesDifferentiator\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Error for Time Series Forecasts\nDESCRIPTION: Evaluates the model's performance by calculating the mean squared error (MSE) between the predicted values and the actual test data. This metric provides a quantitative measure of forecast accuracy.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================================================================\nerror_mse = mean_squared_error(\n                y_true = data_test,\n                y_pred = predictions\n            )\nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Grid Search Configuration in Python\nDESCRIPTION: Code snippet setting up a results storage list and defining the evaluation metric for a grid search operation in a forecasting benchmark.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Results\n# ==============================================================================\nresults_grid_search = []\nmetric = 'mean_absolute_error'\n```\n\n----------------------------------------\n\nTITLE: Accessing Last Window Data\nDESCRIPTION: Shows how to access the last window of data seen during training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nforecaster.last_window_\n```\n\n----------------------------------------\n\nTITLE: Simulating Missing Exogenous Data in Initial Periods in Python\nDESCRIPTION: Creates a modified exogenous dataset that omits the first window_size observations, simulating a scenario where exogenous data is only available after an initial period.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Simulate data\n# ==============================================================================\nexog_no_first_window_size = data_train[['exog_1', 'exog_2']].copy()\nexog_no_first_window_size = exog_no_first_window_size.iloc[window_size:, :]\n\n# Plot\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3.5))\ndata_train[['y']].plot(ax=ax)\nexog_no_first_window_size.plot(ax=ax)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterDirect with Ridge and Running Bayesian Search on Bike Sharing Data\nDESCRIPTION: Sets up a ForecasterDirect model with Ridge regression for the bike sharing dataset. Defines a search space for Bayesian optimization including alpha parameter and lag values, then runs a benchmark to evaluate model performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirect(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 steps         = 24,\n                 lags          = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\n\ndef search_space(trial):\n    search_space  = {\n        'alpha': trial.suggest_float('alpha', 0.001, 1000, log=True),\n        'lags' : trial.suggest_categorical('lags', lags_grid)\n    }\n\n    return search_space\n\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_bike,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'bayesian_search',\n    search_space            = search_space,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\n\nresults_bayesian_search.append([\n    'bike_sharing',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Displaying Regressor Parameters\nDESCRIPTION: Shows how to retrieve the detailed parameters of the configured regressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nforecaster.regressor.get_params(deep=True)\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Custom Metric Function\nDESCRIPTION: Benchmarks a custom metric wrapper that adds y_train argument compatibility to the mean_absolute_error function, comparing performance against the direct use of the sklearn function.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.metrics import add_y_train_argument\n\ncustom_metric = add_y_train_argument(mean_absolute_error)\n\nstart = time.time()\nfor i in range(500):\n    mean_absolute_error(y_true, y_pred)\nprint(time.time() - start)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking Ridge with ForecasterDirect on Bike Sharing Data\nDESCRIPTION: Implements a ForecasterDirect forecaster with Ridge regression and StandardScaler for the bike sharing dataset. The configuration includes hyperparameter tuning for lag selection and Ridge alpha parameter, forecasting 24 steps ahead.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Dataset bike_sharing_extended_features - ForecasterDirect\n# ==============================================================================\nforecaster = ForecasterDirect(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 steps         = 24,\n                 lags          = 10\n             )\n\nlags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n\nparam_grid = {'alpha': np.logspace(-3, 3, 20)}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_bike,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 24,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'bike',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Initialize Forecaster with Transformer\nDESCRIPTION: Creates a ForecasterRecursive instance with Ridge regression and a transformer for the target variable.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n    regressor     = Ridge(random_state=123),\n    lags          = 3,\n    transformer_y = transformer_y\n)\n\nforecaster.fit(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Testing Backtesting Functionality with Different Parameters\nDESCRIPTION: Tests the backtesting_forecaster_multiseries function with various combinations of parameters like initial_train_size, refit strategy, fixed_train_size, gap, and metrics. Validates that results are consistent across different input formats.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Test backtesting\n# ==============================================================================\nparams = {\n    \"initial_train_size\": [50, len(series_train)],\n    \"refit\": [True, False, 2],\n    \"fixed_train_size\": [True, False],\n    \"gap\": [0, 7],\n    \"levels\": [\n        None,\n        [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n        \"id_1000\",\n        [\"id_1000\", \"id_1001\"],\n    ],\n    \"metrics\": [[\"mean_absolute_error\", \"mean_squared_error\"], \"mean_absolute_error\"],\n    \"allow_incomplete_fold\": [True, False],\n}\n\nparams_grid = list(ParameterGrid(params))\n\nfor params in tqdm(params_grid):\n    print(f\"Paramns: {params}\")\n\n    forecaster = ForecasterRecursiveMultiSeries(\n        regressor=LinearRegression(),  # LGBMRegressor(n_estimators=10, random_state=123, verbose=-1),\n        lags=14,\n        encoding=\"ordinal\",\n        dropna_from_series=False,\n        transformer_series=StandardScaler(),\n        transformer_exog=StandardScaler(),\n    )\n\n    metrics_1, predictions_1 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog,\n        levels=params[\"levels\"],\n        steps=24,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    metrics_2, predictions_2 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series,\n        exog=exog_dict,\n        levels=params[\"levels\"],\n        steps=24,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    metrics_3, predictions_3 = backtesting_forecaster_multiseries(\n        forecaster=forecaster,\n        series=series_dict,\n        exog=exog_dict,\n        levels=params[\"levels\"],\n        steps=24,\n        metric=params[\"metrics\"],\n        initial_train_size=params[\"initial_train_size\"],\n        fixed_train_size=params[\"fixed_train_size\"],\n        gap=params[\"gap\"],\n        allow_incomplete_fold=params[\"allow_incomplete_fold\"],\n        refit=params[\"refit\"],\n        n_jobs=\"auto\",\n        verbose=False,\n        show_progress=False,\n    )\n\n    pd.testing.assert_frame_equal(\n        metrics_1,\n        metrics_2,\n    )\n    pd.testing.assert_frame_equal(predictions_1, predictions_2)\n    pd.testing.assert_frame_equal(metrics_1, metrics_3)\n    pd.testing.assert_frame_equal(predictions_1, predictions_3)\n```\n\n----------------------------------------\n\nTITLE: Implementing RBF Encoding for Time Series Data\nDESCRIPTION: Creates and applies Repeating Basis Function (RBF) encoding to day_of_year data, transforming it into multiple RBF features with periodic patterns.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/cyclical-features-time-series.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nrbf = RepeatingBasisFunction(\n    n_periods   = 12,\n    remainder   = 'drop',\n    column      = 'day_of_year',\n    input_range = (1, 366)\n)\nrbf_month = rbf.fit_transform(data[['day_of_year']])\nrbf_month = pd.DataFrame(\n    data    = rbf_month,\n    index   = data.index,\n    columns = [f\"rbf_{i}\" for i in range(rbf_month.shape[1])]\n)\nrbf_month.head(3)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Fetching Dataset for Time Series Analysis in Python\nDESCRIPTION: This snippet demonstrates how to import necessary libraries and fetch a dataset for time series analysis. It uses pandas and a custom dataset fetching function from skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/time-series-aggregation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nfrom skforecast.datasets import fetch_dataset\n\n# Download data\n# ==============================================================================\ndata = fetch_dataset(name='vic_electricity')\ndata = data[['Demand', 'Temperature', 'Holiday']]\ndata.head(5)\n```\n\n----------------------------------------\n\nTITLE: Configuring Evaluation Metrics\nDESCRIPTION: Defines multiple evaluation metrics for model assessment including MAE, MSE, MAPE, MASE, and RMSSE.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nmetrics = [\n        \"mean_absolute_error\",\n        \"mean_squared_error\",\n        mean_absolute_percentage_error,\n        mean_absolute_scaled_error,\n        root_mean_squared_scaled_error,\n    ]\n```\n\n----------------------------------------\n\nTITLE: Accessing Forecaster Regressor\nDESCRIPTION: Demonstrates how to access the configured regressor object from the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nforecaster.regressor\n```\n\n----------------------------------------\n\nTITLE: Comparing CRPS Calculations from Different Libraries in Python\nDESCRIPTION: This snippet compares the CRPS calculation results from different libraries: properscoring, CRPS, and pymc_marketing. It demonstrates how to use these libraries to compute CRPS for the same set of true and predicted values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# properscoring, CRPS, pymc-mar\n# ==============================================================================\nprint(f\"properscoring : {ps.crps_ensemble(y_true, y_pred)}\")\nprint(f\"CRPS          : {CRPS(y_pred, y_true).compute()[0]}\")\nprint(f\"pymc-marketing: {crps(y_true, y_pred.reshape(-1, 1))}\")\n```\n\n----------------------------------------\n\nTITLE: Drop Exogenous Variables from Dictionary\nDESCRIPTION: This snippet demonstrates how to selectively remove exogenous variables for specific series within the `exog_dict` dictionary.  The `drop` method is used on the pandas DataFrames associated with series 'id_1000' and 'id_1003' to remove specified columns.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n\"# Drop some exogenous variables for series 'id_1000' and 'id_1003'\n# ==============================================================================\nexog_dict['id_1000'] = exog_dict['id_1000'].drop(columns=['air_temperature', 'wind_speed'])\nexog_dict['id_1003'] = exog_dict['id_1003'].drop(columns=['cos_day_of_week'])\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Parallelization Testing in skforecast\nDESCRIPTION: This code snippet imports necessary libraries for testing parallelization in skforecast, including system information modules, forecasting libraries, data manipulation tools, and various forecaster implementations from skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport platform\nimport psutil\nimport skforecast\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport sklearn\nimport time\nimport warnings\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\n\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.direct import ForecasterDirect\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.direct import ForecasterDirectMultiVariate\n\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.model_selection import grid_search_forecaster\nfrom skforecast.model_selection import grid_search_forecaster_multiseries\nfrom skforecast.model_selection import backtesting_forecaster_multiseries\n```\n\n----------------------------------------\n\nTITLE: Displaying Window Features Information\nDESCRIPTION: Prints detailed information about window features including names, sizes and feature classes.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Window features names   : \", forecaster.window_features_names)\nprint(\"Max window size wf      : \", forecaster.max_size_window_features)\nprint(\"Window features classes : \", forecaster.window_features_class_names)\n```\n\n----------------------------------------\n\nTITLE: Reading Grid Search Results from File in Python\nDESCRIPTION: Shows how to read the saved grid search results from a tab-separated values file. The results are imported into a pandas DataFrame for further analysis or visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Read results file\n# ==============================================================================\npd.read_csv(\"results_grid_search.txt\", sep=\"\\t\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Lags Information\nDESCRIPTION: Prints detailed information about the lags configuration including names and maximum lag value.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Lags names : \", forecaster.lags_names)\nprint(\"Max lag    : \", forecaster.max_lag)\n```\n\n----------------------------------------\n\nTITLE: Applying Daily Frequency to Grouped Time Series\nDESCRIPTION: Groups the long-format time series by the 'series' column and applies daily frequency to each group using the asfreq method, maintaining the time series properties.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nseries = series.groupby('series').apply(lambda x: x.asfreq('D'), include_groups=False)\nseries\n```\n\n----------------------------------------\n\nTITLE: Displaying Data and Plots with Skforecast in Python\nDESCRIPTION: This snippet displays a sample of the dataframe and generates a plot using matplotlib with a dark theme set by Skforecast's `set_dark_theme` function. It helps visualize the initial state of the time series data being analyzed.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ==============================================================================  \ndisplay(data.head(3))\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(6, 3))\ndata['y'].plot(ax=ax)\nax.legend()\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Installing skforecast with SARIMAX Support\nDESCRIPTION: Installs skforecast with the statsmodels dependency needed for SARIMAX models. This enables seasonal autoregressive integrated moving average models with exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast[sarimax]\n```\n\n----------------------------------------\n\nTITLE: Training Forecaster Model\nDESCRIPTION: Initializing and training a ForecasterRecursive model with RandomForestRegressor and specific lag parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Train forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor     = RandomForestRegressor(random_state=123),\n                 lags          = 5,\n                 forecaster_id = 'forecasting_series_y'\n             )\n\nforecaster.fit(y=data_train['y'])\n```\n\n----------------------------------------\n\nTITLE: Training Predictions with Skforecast in Python\nDESCRIPTION: This snippet calculates training predictions using the forecaster's internal regressor. The predictions help evaluate the model's fit on the training data, assisting in performance tuning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Training predictions using the internal regressor\n# ==============================================================================  \npredictions_training = forecaster.regressor.predict(X_train)\npredictions_training[:4]\n```\n\n----------------------------------------\n\nTITLE: Display Exogenous Variables for Each Series\nDESCRIPTION: This code iterates through the keys in the `series_dict` and prints the column names of the exogenous variables associated with each series from the `exog_dict`. If a series does not have associated exogenous variables, it prints a message indicating that.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n\"# Exogenous variables for each series\n# ==============================================================================\nfor k in series_dict.keys():\n    print(f\"{k}:\")\n    try:\n        print(f\"\\t{exog_dict[k].columns.to_list()}\")\n    except:\n        print(\"\\tNo exogenous variables\")\"\n```\n\n----------------------------------------\n\nTITLE: Plotting Data Partitions\nDESCRIPTION: The code plots the train, calibration, and test data for visualization purposes. Matplotlib is used for creating the plots, which outline the data distribution over specified partitions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Plot partitions\n# ==============================================================================\nset_dark_theme()\nplt.rcParams['lines.linewidth'] = 0.5\nfig, ax = plt.subplots(figsize=(8, 3))\nax.plot(data_train['OT'], label='Train')\nax.plot(data_cal['OT'], label='Calibration')\nax.plot(data_test['OT'], label='Test')\nax.set_title('Oil Temperature')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Creating Synthetic Time Series Data\nDESCRIPTION: Generates a synthetic dataset of 500 time series with 1,000 hourly observations each, using random normal distribution. The data is structured as a DataFrame with DatetimeIndex.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nn = 1_000\nn_series = 500\nseries = pd.DataFrame(\n    np.random.normal(0, 1, n * n_series).reshape(n, n_series),\n    index=pd.date_range('2020-01-01', periods=n, freq='h'),\n    columns=[f'series_{i}' for i in range(n_series)]\n)\n```\n\n----------------------------------------\n\nTITLE: Profiling Backtesting with Line Profiler\nDESCRIPTION: Creates a wrapper function to profile _backtesting_forecaster_multiseries using line_profiler. This provides line-by-line execution time analysis of the backtesting implementation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Profiling backtesting_forecaster_multiseries()\n# ==============================================================================\nfrom skforecast.model_selection._validation import _backtesting_forecaster_multiseries\ndef funt_to_profile(forecaster, series, cv, metric, show_progress, add_aggregated_metric):\n    _backtesting_forecaster_multiseries(\n        forecaster    = forecaster,\n        series        = series,\n        cv            = cv,\n        metric        = metric,\n        show_progress = show_progress,\n        add_aggregated_metric = False\n    )\n\n%lprun -f _backtesting_forecaster_multiseries funt_to_profile(forecaster, series, cv, \"mean_absolute_error\", False, False)\n```\n\n----------------------------------------\n\nTITLE: Suppressing Warnings During Model Fitting in ForecasterRecursiveMultiSeries\nDESCRIPTION: This code demonstrates how to suppress warnings during the fit method of ForecasterRecursiveMultiSeries by setting suppress_warnings to True.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nforecaster.fit(series=series_dict_nan, suppress_warnings=True)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Displaying Categorical Feature Encoding Details\nDESCRIPTION: Extracts the ordinal encoder from the transformer and prints the mapping between original category values and their encoded numeric representations for each categorical feature.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Show the encoding applied to the categorical features\n# ==============================================================================\nordinal_encoder = transformer_exog.named_transformers_['ordinalencoder']\nfor feature, cats in zip(categorical_features, ordinal_encoder.categories_):\n    print(f\"Feature '{feature}' categories and codes:\")\n    for code, category in enumerate(cats):\n        print(f\"  {category}: {code}\")\n```\n\n----------------------------------------\n\nTITLE: Loading Time Series Dataset for Forecasting in Python\nDESCRIPTION: Fetches a sales dataset for multiple items using the skforecast library's fetch_dataset function and displays the first few rows of the dataframe to inspect the data structure.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Data download\n# ==============================================================================\ndata = fetch_dataset(name=\"items_sales\")\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Accessing Weight Function Source Code in Forecaster\nDESCRIPTION: Shows how to retrieve the source code of the weight function stored in the forecaster object.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nprint(forecaster.source_code_weight_func)\n```\n\n----------------------------------------\n\nTITLE: Converting Datetime-Indexed Data to RangeIndex in Python\nDESCRIPTION: Resets the datetime index of the data to a regular integer RangeIndex by dropping the original datetime index, demonstrating how to prepare non-datetime indexed data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/input-data.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Data without datetime index\n# ==============================================================================\ndata = data.reset_index(drop=True)\ndata\n```\n\n----------------------------------------\n\nTITLE: Loading Sales Data for Feature Selection\nDESCRIPTION: Fetches a sample dataset named 'items_sales' to be used for demonstrating multi-series feature selection.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ==============================================================================\ndata = fetch_dataset(name=\"items_sales\")\n```\n\n----------------------------------------\n\nTITLE: Training Forecaster Without Encoding\nDESCRIPTION: Shows how to train a forecaster without encoding for predicting unknown series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = None\n             )\n\nforecaster.fit(series=data_train)\n```\n\n----------------------------------------\n\nTITLE: Build LightGBM with GPU Support\nDESCRIPTION: Navigates to the LightGBM directory, creates a build directory, configures the build with GPU support by specifying the OpenCL library and include directory, and then compiles the code.  The `cmake` command configures the build, `-DUSE_GPU=1` enables GPU support, and `make -j$(nproc)` compiles the code using all available processors for faster compilation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n\"\"\"bash\n%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Create Sample Data with Missing Values\nDESCRIPTION: This code creates a sample dataset with interspersed missing values (NaNs) in the `series_dict_nan` dictionary for the 'id_1000' and 'id_1003' series.  Specific date ranges and individual dates are selected and their values set to `np.nan`.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n\"# Sample data with interspersed NaNs\n# ==============================================================================\nseries_dict_nan = {\n    'id_1000': series_dict['id_1000'].copy(),\n    'id_1003': series_dict['id_1003'].copy()\n}\n\n# Create NaNs\nseries_dict_nan['id_1000'].loc['2016-03-01':'2016-04-01',] = np.nan\nseries_dict_nan['id_1000'].loc['2016-05-01':'2016-05-07',] = np.nan\nseries_dict_nan['id_1003'].loc['2016-07-01',] = np.nan\"\n```\n\n----------------------------------------\n\nTITLE: Installing skforecast with Deep Learning Support\nDESCRIPTION: Installs skforecast with keras and matplotlib dependencies for deep learning forecasting models. This enables building and training neural network models for time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast[deeplearning]\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Predictions\nDESCRIPTION: Demonstrates how to process predictions when there are missing values in the original data. The code identifies valid indices and sets predictions to NaN where original data is missing.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbacktest_levels = ['level_1', 'level_2']\nbacktest_predictions_grouped = backtest_predictions.groupby('level', sort=False)\nfor level, indices in backtest_predictions_grouped.groups.items():\n    if level in backtest_levels:\n        valid_index = series[level].dropna().index\n        print(valid_index)\n        valid_index = pd.MultiIndex.from_product([valid_index, [level]], names=['idx', 'level'])\n        print(valid_index)\n        no_valid_index = indices.difference(valid_index, sort=False)\n        print(no_valid_index)\n        backtest_predictions.loc[no_valid_index, 'pred'] = np.nan\n\nbacktest_predictions = (\n        backtest_predictions\n        .reset_index('level')\n        .rename_axis(None, axis=0)\n    )\n\nbacktest_predictions\n```\n\n----------------------------------------\n\nTITLE: Loading Air Quality Dataset for Forecasting\nDESCRIPTION: Fetches a pre-processed air quality dataset from Valencia with no missing values using Skforecast's fetch_dataset function.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Data download\n# ==============================================================================\ndata = fetch_dataset(name=\"air_quality_valencia_no_missing\")\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for Forecasting - Python\nDESCRIPTION: This code snippet includes libraries for data manipulation and visualization, as well as the setup of the forecasting models. It establishes the necessary imports for managing time series data and utilizing different forecasting algorithms.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Python\\n# Data manipulation\\n# ==============================================================================\\nimport numpy as np\\nimport pandas as pd\\n\\n# Plots\\n# ==============================================================================\\nimport matplotlib.pyplot as plt\\nfrom skforecast.plot import set_dark_theme\\n\\n# Modelling and Forecasting\\n# ==============================================================================\\nfrom xgboost import XGBRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import StandardScaler\\nfrom skforecast.recursive import ForecasterRecursive\\nfrom skforecast.preprocessing import TimeSeriesDifferentiator\\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_forecaster\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for ARIMA and SARIMAX Forecasting in Python\nDESCRIPTION: This snippet imports necessary libraries for time series forecasting, including matplotlib, scikit-learn, skforecast, and statsmodels. It also suppresses warnings for cleaner output.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.sarimax import Sarimax\nfrom skforecast.recursive import ForecasterSarimax\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_sarimax, grid_search_sarimax\nfrom skforecast.plot import set_dark_theme\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n----------------------------------------\n\nTITLE: Importing Forecasters for skforecast < 0.14\nDESCRIPTION: This code snippet imports `ForecasterAutoreg` and `ForecasterAutoregMultiSeries` from the old Skforecast library structure. It's meant for users still on versions earlier than 0.14 who need to maintain backward compatibility.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.ForecasterAutoreg import ForecasterAutoreg\nfrom skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n```\n\n----------------------------------------\n\nTITLE: Printing Source Code of Custom Weight Function in Python\nDESCRIPTION: Prints the source code of the custom weight function used in the forecaster. This is useful for logging and documentation purposes.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nprint(forecaster.source_code_weight_func)\n```\n\n----------------------------------------\n\nTITLE: Defining Search Space for Bayesian Optimization\nDESCRIPTION: Creates a search space function for hyperparameter optimization of the forecasting model. Parameters include n_estimators, max_depth, and learning_rate.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-quantile-regression.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef search_space(trial):\n    search_space  = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n        'max_depth': trial.suggest_int('max_depth', 3, 10, step=1),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1)\n    }\n\n    return search_space\n```\n\n----------------------------------------\n\nTITLE: Hyperparameter Search with grid_search_forecaster in skforecast < 0.14\nDESCRIPTION: This code snippet outlines how to perform hyperparameter tuning using the `grid_search_forecaster` function while specifying various parameters, which was the standard approach before version 0.14.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.model_selection import (\n    grid_search_forecaster\n)\n\ngrid_search_forecaster(\n    forecaster            = forecaster,\n    y                     = data,\n    param_grid            = param_grid,\n    lags_grid             = lags_grid,\n    steps                 = 10,\n    refit                 = False,\n    metric                = 'mean_squared_error',\n    initial_train_size    = 100,\n    fixed_train_size      = False,\n    allow_incomplete_fold = True,\n    return_best           = True,\n    n_jobs                = 'auto',\n    verbose               = False,\n    show_progress         = True\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting\nDESCRIPTION: Imports all necessary libraries for time series forecasting, including numpy and pandas for data manipulation, matplotlib for visualization, and skforecast components for forecasting. Also imports various regression models from scikit-learn and LightGBM.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skforecast.ForecasterAutoreg import ForecasterAutoreg\nfrom skforecast.model_selection import backtesting_forecaster\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport time\nfrom lightgbm import LGBMRegressor\nimport seaborn as sns\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterAutoregMultiSeries in Python\nDESCRIPTION: This snippet initializes a 'ForecasterAutoregMultiSeries' object with a 'RandomForestRegressor' as the regressor. It utilizes the 'StandardScaler' for series transformation. The core purpose is setting up the forecaster with specified lags and optional configurations to handle autoregressive forecasting for multiple time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/paralel_create_train_X_y.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterAutoregMultiSeries(\n                 regressor          = RandomForestRegressor(random_state=123),\n                 lags               = 3,\n                 encoding           = 'ordinal',\n                 transformer_series = StandardScaler(),\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 series_weights     = None,\n                 differentiation    = None,\n                 dropna_from_series = False,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nself = forecaster\n```\n\n----------------------------------------\n\nTITLE: Displaying Backtest Predictions in Python\nDESCRIPTION: Displays the first few predictions from the backtest results, providing insight into forecast accuracy and data handling.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Backtest predictions\n# =================================================\npredictions_backtest.head()\n```\n\n----------------------------------------\n\nTITLE: Identifying Categorical Features in Model\nDESCRIPTION: Extracts and displays the features that are treated as categorical by the XGBoost model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nfeature_types = np.array(forecaster.regressor.get_booster().feature_types)\nfeatures_in_model = np.array(forecaster.regressor.get_booster().feature_names)\nfeatures_in_model[feature_types == 'c']\n```\n\n----------------------------------------\n\nTITLE: Creating Predictors for Custom Features in skforecast < 0.14\nDESCRIPTION: This function creates 10 lagged features along with the moving average, standard deviation, minimum, and maximum over a rolling window of 20. It's intended for use with the `ForecasterAutoregCustom` forecaster prior to version 0.14.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\nimport numpy as np\n\ndef create_predictors(y):\n    \"\"\"\n    Create first 10 lags of a time series.\n    Calculate moving average with window 20.\n    Calculate the moving standard deviation with window 20.\n    Calculate moving minimum and maximum with window 20.\n    \"\"\"\n    lags = y[-1:-11:-1]\n    mean = np.mean(y[-20:])\n    std = np.std(y[-20:])\n    min_val = np.min(y[-20:])\n    max_val = np.max(y[-20:])\n\n    predictors = np.hstack([lags, mean, std, min_val, max_val])\n\n    return predictors\n\nfeature_names = [f\"lag {i}\" for i in range(1, 11)] + [\n    \"moving_avg_20\",\n    \"moving_std_20\",\n    \"moving_min_20\",\n    \"moving_max_20\",\n]\n\nforecaster = ForecasterAutoregCustom(\n    regressor       = LGBMRegressor(random_state=123, verbose=-1),\n    fun_predictors  = create_predictors,\n    name_predictors = feature_names,\n    window_size     = 20\n)\n```\n\n----------------------------------------\n\nTITLE: Combining Original and RBF Encoded Data\nDESCRIPTION: Merges the original data with RBF encoded features while removing redundant columns.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/cyclical-features-time-series.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndata_encoded_rbf = pd.concat([data, rbf_month], axis=1)\ndata_encoded_rbf = data_encoded_rbf.drop(columns=['day_of_year', 'month'])\ndata_encoded_rbf.head(3)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Gradient Boosting Forecasting\nDESCRIPTION: Imports essential libraries for time series forecasting using gradient boosting models, including XGBoost, LightGBM, and skforecast components\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-xgboost-lightgbm.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\n```\n\n----------------------------------------\n\nTITLE: Generating Test Data for Parallelization Testing\nDESCRIPTION: This code generates test data for parallelization experiments: a single time series (y), exogenous variables (exog), and multiple time series (multi_series). It uses numpy's random number generator with a fixed seed for reproducibility.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Data\n# ==============================================================================\nn = 5_000\nrgn = np.random.default_rng(seed=123)\ny = pd.Series(rgn.random(size=(n)), name=\"y\")\nexog = pd.DataFrame(rgn.random(size=(n, 10)))\nexog.columns = [f\"exog_{i}\" for i in range(exog.shape[1])]\nmulti_series = pd.DataFrame(rgn.random(size=(n, 10)))\nmulti_series.columns = [f\"series_{i + 1}\" for i in range(multi_series.shape[1])]\ny_train = y[:-int(n / 2)]\ndisplay(y.head())\ndisplay(exog.head())   \ndisplay(multi_series.head())\n```\n\n----------------------------------------\n\nTITLE: Load Time Series and Exogenous Data\nDESCRIPTION: This snippet loads time series data and exogenous variables from CSV files hosted on GitHub, using pandas.  The 'timestamp' column is converted to datetime objects, and the first few rows of each DataFrame are displayed for inspection.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"# Load time series of multiple lengths and exogenous variables\n# ==============================================================================\nseries = pd.read_csv(\n    'https://raw.githubusercontent.com/skforecast/skforecast-datasets/main/data/demo_multi_series.csv'\n)\nexog = pd.read_csv(\n    'https://raw.githubusercontent.com/skforecast/skforecast-datasets/main/data/demo_multi_series_exog.csv'\n)\n\nseries['timestamp'] = pd.to_datetime(series['timestamp'])\nexog['timestamp'] = pd.to_datetime(exog['timestamp'])\n\ndisplay(series.head())\nprint(\"\")\ndisplay(exog.head())\"\n```\n\n----------------------------------------\n\nTITLE: Generating Missing Value Gaps\nDESCRIPTION: Creates artificial gaps in the time series data by setting specific date ranges to NaN values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ngaps = [\n    ['2020-09-01', '2020-10-10'],\n    ['2020-11-08', '2020-12-15'],\n]\n\nfor gap in gaps:\n    data.loc[gap[0]:gap[1]] = np.nan\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting\nDESCRIPTION: Imports necessary libraries for data manipulation, machine learning, and forecasting, including scikit-learn, XGBoost, and skforecast modules.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge, GammaRegressor\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_forecaster\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Electricity Demand Data\nDESCRIPTION: Downloads Victoria electricity demand data from GitHub, converts the time column to datetime format, sets it as index, and resamples the data from 30-minute intervals to hourly intervals using mean aggregation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Descarga de data\n# ==============================================================================\nurl = ('https://raw.githubusercontent.com/skforecast/skforecast/master/' +\n       'data/vic_elec.csv')\ndata = pd.read_csv(url, sep=',')\ndata['Time'] = pd.to_datetime(data['Time'], format='%Y-%m-%dT%H:%M:%SZ')\ndata = data.set_index('Time')\ndata = data.asfreq('30min')\ndata = data.sort_index()\ndata = data.drop(columns='Date')\ndata = data.resample(rule='H', closed='left', label ='right').mean()\nlen(data)\n```\n\n----------------------------------------\n\nTITLE: Display Backtesting Predictions\nDESCRIPTION: This code snippet displays the first few rows of the predictions obtained from the backtesting process. This allows for examining the predicted values and comparing them to the actual values to assess the model's performance.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\npredictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Metric for Hyperparameter Tuning - Python\nDESCRIPTION: This snippet explains how to create a custom metric function that can be utilized for hyperparameter optimization. The function must accept true and predicted values and return a numeric result. This allows for tailored evaluation metrics based on specific requirements.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Custom metric\n```\n\n----------------------------------------\n\nTITLE: Checking Inclusion of Forced Feature in Python\nDESCRIPTION: This code snippet verifies that the 'noise' feature has been included in the `selected_exog` list after forcing its inclusion during feature selection. This check confirms that the `force_inclusion` parameter worked as expected.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n\"# Check if \\\"noise\\\" is in selected_exog\n# ==============================================================================\n\\\"noise\\\" in selected_exog\"\n```\n\n----------------------------------------\n\nTITLE: Store Out-Sample Residuals in the Forecaster\nDESCRIPTION: Demonstrates how to store calculated out-sample residuals within the ForecasterRecursive object using the set_out_sample_residuals() method for future calibration use.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Store out-sample residuals in the forecaster\n# ==============================================================================\nforecaster.set_out_sample_residuals(\n    y_true = data.loc[predictions_cal.index, 'OT'], \n    y_pred = predictions_cal['pred']\n)\n```\n\n----------------------------------------\n\nTITLE: Data Preprocessing and Training Data Setup\nDESCRIPTION: Converting date strings to datetime, setting date index, and preparing training data subset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Data preprocessing\n# ==============================================================================\ndata['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\ndata = data.set_index('date')\ndata = data.asfreq('MS')\ndata_train = data.loc[:'2005-01-01']\ndata_train.tail()\n```\n\n----------------------------------------\n\nTITLE: Displaying Ordinal Encoder Categories and Codes\nDESCRIPTION: Prints the mapping between categorical features and their encoded values from an ordinal encoder transformer.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nordinal_encoder = transformer_exog.named_transformers_['ordinalencoder']\nfor feature, cats in zip(categorical_features, ordinal_encoder.categories_):\n    print(f\"Feature '{feature}' categories and codes:\")\n    for code, category in enumerate(cats):\n        print(f\"  {category}: {code}\")\n```\n\n----------------------------------------\n\nTITLE: Exogenous Variables Description\nDESCRIPTION: This section lists the exogenous variables available for each series in the dataset. If no exogenous variables are present for a series, it indicates that information as well.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nfor k in series_dict.keys():\n    print(f\\\"{k}:\\\")\n    try:\n        print(f\\\"\\t{exog_dict[k].columns.to_list()}\\\")\n    except:\n        print(f\\\"\\tNo exogenous variables\\\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Applying Transformers in ForecasterRecursive with Python\nDESCRIPTION: Example of using scikit-learn's StandardScaler as transformers for both the time series and exogenous variables in ForecasterRecursive. This allows for data pre-processing transformations.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\nforecaster = ForecasterRecursive(\n    regressor        = LGBMRegressor(random_state=123, verbose=-1),\n    lags             = 5,\n    window_features  = None,\n    transformer_y    = StandardScaler(),\n    transformer_exog = StandardScaler()\n)\n```\n\n----------------------------------------\n\nTITLE: Display Backtest Predictions\nDESCRIPTION: Shows the first 4 rows of the backtesting predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npredictions.head(4)\n```\n\n----------------------------------------\n\nTITLE: Checking System Information and Library Versions\nDESCRIPTION: This code prints the versions of key libraries (Python, scikit-learn, skforecast, pandas, numpy, scipy) and system information including processor type, platform, operating system details, and available CPU cores.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Versions\n# ==============================================================================\nprint(f\"Python version      : {platform.python_version()}\")\nprint(f\"scikit-learn version: {sklearn.__version__}\")\nprint(f\"skforecast version  : {skforecast.__version__}\")\nprint(f\"pandas version      : {pd.__version__}\")\nprint(f\"numpy version       : {np.__version__}\")\nprint(f\"scipy version       : {scipy.__version__}\")\nprint(\"\")\n\n# System information\n# ==============================================================================\nprint(f\"Processor type: {platform.processor()}\")\nprint(f\"Platform type: {platform.platform()}\")\nprint(f\"Operating system: {platform.system()}\")\nprint(f\"Operating system release: {platform.release()}\")\nprint(f\"Operating system version: {platform.version()}\")\nprint(f\"Number of physical cores: {psutil.cpu_count(logical=False)}\")\nprint(f\"Number of logical cores: {psutil.cpu_count(logical=True)}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Skforecast Dependencies\nDESCRIPTION: Imports required libraries including RandomForestRegressor from sklearn and various Skforecast modules for time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.ensemble import RandomForestRegressor\nfrom skforecast.datasets import load_demo_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\n```\n\n----------------------------------------\n\nTITLE: Installing Basic skforecast Package with pip\nDESCRIPTION: Installs the basic version of skforecast with core dependencies using pip. This includes essential libraries like numpy, pandas, scikit-learn, and other required packages.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast\n```\n\n----------------------------------------\n\nTITLE: Backtesting Forecaster in skforecast < 0.14\nDESCRIPTION: This demonstrates the old method of conducting backtesting using the `backtesting_forecaster` function which utilizes various parameters for training size and folds in versions prior to 0.14.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.model_selection import (\n    backtesting_forecaster\n)\n\nbacktesting_forecaster(\n    forecaster            = forecaster,\n    y                     = y,\n    steps                 = 10,\n    initial_train_size    = 100,\n    metric                = 'mean_absolute_error',\n    fixed_train_size      = True,\n    gap                   = 0,\n    skip_folds            = None,\n    allow_incomplete_fold = True,\n    refit                 = False,\n    n_jobs                = 'auto',\n    verbose               = False,\n    show_progress         = True\n)\n```\n\n----------------------------------------\n\nTITLE: Directory Structure - skforecast >= 0.14\nDESCRIPTION: Shows the reorganized directory structure after version 0.14, with forecasting models grouped into logical modules like recursive, direct, and deep_learning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n|-- skforecast\n    |-- recursive\n        |-- _forecaster_recursive.py              -> ForecasterRecursive\n        |-- _forecaster_recursive_multiseries.py  -> ForecasterRecursiveMultiSeries\n        |-- _forecaster_sarimax.py                -> ForecasterSarimax\n        |-- _forecaster_equivalent_date.py        -> ForecasterEquivalentDate\n    |-- direct\n        |-- _forecaster_direct.py                 -> ForecasterDirect\n        |-- _forecaster_direct_multivariate.py    -> ForecasterDirectMultiVariate\n    |-- deep_learning\n        |-- _forecaster_rnn.py                    -> ForecasterRnn\n    |-- base\n        |-- _forecaster_base.py                   -> ForecasterBase\n    |-- sarimax\n        |-- _sarimax.py                           -> Sarimax\n```\n\n----------------------------------------\n\nTITLE: Calibrating Over-conservative Intervals\nDESCRIPTION: Applies conformal calibration to over-conservative intervals to reduce coverage to desired level, then visualizes and validates results.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncalibrator = ConformalIntervalCalibrator(nominal_coverage=0.7, symmetric_calibration=False)\ncalibrator.fit(y_true=y_true, y_pred_interval=interval)\nprint(calibrator)\ninterval_calibrated = calibrator.transform(interval)\nfig, ax = plt.subplots(figsize=(7, 3.5))\ninterval.plot(ax=ax, linestyle=\"--\")\ninterval_calibrated[\"lower_bound\"].plot(ax=ax, color=\"#30a2da\", label=\"Calibrated lower bound\")\ninterval_calibrated[\"upper_bound\"].plot(ax=ax, color=\"#fc4f30\", label=\"Calibrated upper bound\")\ny_true.plot(ax=ax, label=\"True values\")\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=4)\nplt.show()\n\ncoverage = calculate_coverage(\n               y_true      = y_true,\n               lower_bound = interval_calibrated[\"lower_bound\"],\n               upper_bound = interval_calibrated[\"upper_bound\"],\n           )\nprint(f\"Coverage after calibration: {coverage:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Forecasting\nDESCRIPTION: Importing necessary Python libraries including pandas, matplotlib, sklearn, and skforecast components for time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.utils import save_forecaster\nfrom skforecast.utils import load_forecaster\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Loading Demo Dataset in skforecast\nDESCRIPTION: Loads a demonstration dataset from skforecast for time series forecasting examples and displays the first 5 rows to preview the data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = load_demo_dataset()\ndata.head(5)\n```\n\n----------------------------------------\n\nTITLE: Initializing Environment for Testing\nDESCRIPTION: This snippet imports necessary Python libraries and sets up the environment by adjusting the system path to include the project's root directory. This is crucial for module imports and functionality related to skforecast and other dependencies.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\npath = str(Path.cwd().parent.parent)\nsys.path.insert(1, path)\nprint(path)\n\nimport numpy as np\nimport pandas as pd\nimport joblib\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom skforecast.plot import set_dark_theme\nimport skforecast\nimport lightgbm\nimport sklearn\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom skforecast.metrics import mean_absolute_scaled_error\nfrom skforecast.metrics import root_mean_squared_scaled_error\nfrom skforecast.preprocessing import series_long_to_dict\nfrom skforecast.preprocessing import exog_long_to_dict\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection import (\n    TimeSeriesFold,\n    OneStepAheadFold,\n    backtesting_forecaster_multiseries,\n    bayesian_search_forecaster_multiseries,\n    grid_search_forecaster_multiseries\n)\nimport warnings\nimport sys\n\nprint(f\\\"Python version: {sys.version}\\\")\nprint(f\\\"skforecast version: {skforecast.__version__}\\\")\nprint(f\\\"lightgbm version: {lightgbm.__version__}\\\")\nprint(f\\\"sklearn version: {sklearn.__version__}\\\")\nprint(f\\\"Last execution: {pd.Timestamp.now()}\\\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Calculate Mean Absolute Error\nDESCRIPTION: This code snippet calculates the Mean Absolute Error (MAE) between the predicted values and the true values in the test set. The `mean_absolute_error` function from `sklearn.metrics` is used to compute the error, providing a measure of the model's predictive accuracy.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nerror_mse = mean_absolute_error(\n                y_true = data_test['y'],\n                y_pred = predictions\n            )\n\nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Lags in ForecasterRecursive with Python\nDESCRIPTION: Example of creating a ForecasterRecursive with 5 lags. Lags are used to transform time series data into a matrix where each value is associated with previous time steps.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\nforecaster = ForecasterRecursive(\n    regressor = LGBMRegressor(random_state=123, verbose=-1),\n    lags      = 5\n)\n```\n\n----------------------------------------\n\nTITLE: Installing skforecast with Plotting Support\nDESCRIPTION: Installs skforecast with dependencies for visualization capabilities including matplotlib, seaborn, and statsmodels. This enables creating plots and visualizations of time series forecasts.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast[plotting]\n```\n\n----------------------------------------\n\nTITLE: Including ForecasterSarimax, TimeSeriesFold, and OneStepAheadFold Classes\nDESCRIPTION: References to classes that now have added _repr_html_ method to display objects in HTML format in interactive environments.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterSarimax]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[TimeSeriesFold]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[OneStepAheadFold]\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Values in RBF Encoding\nDESCRIPTION: Identifies the location of maximum values for each RBF feature in the encoded data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/cyclical-features-time-series.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrbf_month.idxmax()\n```\n\n----------------------------------------\n\nTITLE: Importing ForecasterRecursiveMultiSeries, ForecasterDirect, ForecasterDirectMultiVariate Modules\nDESCRIPTION: References to core forecaster modules that now support binned residuals feature and conformal prediction framework. These classes are part of the skforecast library's main forecasting functionality.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterRecursiveMultiSeries]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterDirect]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterDirectMultiVariate]\n```\n\n----------------------------------------\n\nTITLE: Importing Skforecast Dataset Functions\nDESCRIPTION: Reference to the core dataset loading functions in skforecast. The module provides both fetch_dataset for retrieving remote datasets and load_demo_dataset for loading built-in example data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/datasets.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.datasets import load_demo_dataset\n```\n\n----------------------------------------\n\nTITLE: Documenting ForecasterRecursive Class in Python using Numpydoc Format\nDESCRIPTION: Comprehensive docstring example for the ForecasterRecursive class that demonstrates proper numpydoc formatting including parameters, attributes, and detailed descriptions. Shows how to document a scikit-learn compatible recursive forecasting class.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/CONTRIBUTING.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass ForecasterRecursive(ForecasterBase):\n    \"\"\"\n    This class turns any regressor compatible with the scikit-learn API into a recursive autoregressive (multi-step) forecaster.\n    \n    Parameters\n    ----------\n    regressor : regressor or pipeline compatible with the scikit-learn API\n        An instance of a regressor or pipeline compatible with the scikit-learn API.\n    lags : int, list, numpy ndarray, range, default None\n        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.\n    \n        - `int`: include lags from 1 to `lags` (included).\n        - `list`, `1d numpy ndarray` or `range`: include only lags present in `lags`, all elements must be int.\n        - `None`: no lags are included as predictors. \n    window_features : object, list, default None\n        Instance or list of instances used to create window features. Window features are created from the original time series and are included as predictors.\n    transformer_y : object transformer (preprocessor), default None\n        An instance of a transformer (preprocessor) compatible with the scikit-learn preprocessing API with methods: fit, transform, fit_transform and inverse_transform. ColumnTransformers are not allowed since they do not have inverse_transform method. The transformation is applied to `y` before training the forecaster. \n    transformer_exog : object transformer (preprocessor), default None\n        An instance of a transformer (preprocessor) compatible with the scikit-learn preprocessing API. The transformation is applied to `exog` before training the forecaster. `inverse_transform` is not available when using ColumnTransformers.\n    weight_func : Callable, default None\n        Function that defines the individual weights for each sample based on the index. For example, a function that assigns a lower weight to certain dates. Ignored if `regressor` does not have the argument `sample_weight` in its `fit` method. The resulting `sample_weight` cannot have negative values.\n    differentiation : int, default None\n        Order of differencing applied to the time series before training the forecaster.\n        If `None`, no differencing is applied. The order of differentiation is the number\n        of times the differencing operation is applied to a time series. Differencing\n        involves computing the differences between consecutive data points in the series.\n        Differentiation is reversed in the output of `predict()` and `predict_interval()`.\n        **WARNING: This argument is newly introduced and requires special attention. It\n        is still experimental and may undergo changes.**\n    fit_kwargs : dict, default None\n        Additional arguments to be passed to the `fit` method of the regressor.\n    binner_kwargs : dict, default None\n        Additional arguments to pass to the `QuantileBinner` used to discretize \n        the residuals into k bins according to the predicted values associated \n        with each residual. Available arguments are: `n_bins`, `method`, `subsample`,\n        `random_state` and `dtype`. Argument `method` is passed internally to the\n        function `numpy.percentile`.\n        **New in version 0.14.0**\n    forecaster_id : str, int, default None\n        Name used as an identifier of the forecaster.\n    \n    Attributes\n    ----------\n    regressor : regressor or pipeline compatible with the scikit-learn API\n        An instance of a regressor or pipeline compatible with the scikit-learn API.\n    lags : numpy ndarray\n        Lags used as predictors.\n    lags_names : list\n        Names of the lags used as predictors.\n    max_lag : int\n        Maximum lag included in `lags`.\n    window_features : list\n        Class or list of classes used to create window features.\n    window_features_names : list\n        Names of the window features to be included in the `X_train` matrix.\n    window_features_class_names : list\n        Names of the classes used to create the window features.\n    max_size_window_features : int\n        Maximum window size required by the window features.\n    window_size : int\n        The window size needed to create the predictors. It is calculated as the \n        maximum value between `max_lag` and `max_size_window_features`. If \n        differentiation is used, `window_size` is increased by n units equal to \n        the order of differentiation so that predictors can be generated correctly.\n    transformer_y : object transformer (preprocessor)\n        An instance of a transformer (preprocessor) compatible with the scikit-learn\n        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.\n        ColumnTransformers are not allowed since they do not have inverse_transform method.\n        The transformation is applied to `y` before training the forecaster.\n    transformer_exog : object transformer (preprocessor)\n        An instance of a transformer (preprocessor) compatible with the scikit-learn\n        preprocessing API. The transformation is applied to `exog` before training the\n        forecaster. `inverse_transform` is not available when using ColumnTransformers.\n    weight_func : Callable\n        Function that defines the individual weights for each sample based on the\n        index. For example, a function that assigns a lower weight to certain dates.\n        Ignored if `regressor` does not have the argument `sample_weight` in its `fit`\n        method. The resulting `sample_weight` cannot have negative values.\n    differentiation : int\n        Order of differencing applied to the time series before training the forecaster.\n        If `None`, no differencing is applied. The order of differentiation is the number\n        of times the differencing operation is applied to a time series. Differencing\n        involves computing the differences between consecutive data points in the series.\n        Differentiation is reversed in the output of `predict()` and `predict_interval()`.\n        **WARNING: This argument is newly introduced and requires special attention. It\n        is still experimental and may undergo changes.**\n        **New in version 0.10.0**\n    binner : sklearn.preprocessing.KBinsDiscretizer\n        `KBinsDiscretizer` used to discretize residuals into k bins according \n        to the predicted values associated with each residual.\n        **New in version 0.12.0**\n    binner_intervals_ : dict\n        Intervals used to discretize residuals into k bins according to the predicted\n        values associated with each residual.\n        **New in version 0.12.0**\n    binner_kwargs : dict\n        Additional arguments to pass to the `QuantileBinner` used to discretize \n        the residuals into k bins according to the predicted values associated \n        with each residual. Available arguments are: `n_bins`, `method`, `subsample`,\n        `random_state` and `dtype`. Argument `method` is passed internally to the\n        function `numpy.percentile`.\n        **New in version 0.14.0**\n    source_code_weight_func : str\n        Source code of the custom function used to create weights.\n    differentiation : int\n        Order of differencing applied to the time series before training the \n        forecaster.\n    differentiation_max : int\n        Maximum order of differentiation. For this Forecaster, it is equal to\n        the value of the `differentiation` parameter.\n    differentiator : TimeSeriesDifferentiator\n        Skforecast object used to differentiate the time series.\n    last_window_ : pandas DataFrame\n        This window represents the most recent data observed by the predictor\n        during its training phase. It contains the values needed to predict the\n        next step immediately after the training data. These values are stored\n        in the original scale of the time series before undergoing any transformations\n        or differentiation. When `differentiation` parameter is specified, the\n        dimensions of the `last_window_` are expanded as many values as the order\n        of differentiation. For example, if `lags` = 7 and `differentiation` = 1,\n        `last_window_` will have 8 values.\n    index_type_ : type\n        Type of index of the input used in training.\n    index_freq_ : str\n        Frequency of Index of the input used in training.\n    training_range_ : pandas Index\n        First and last values of index of the data used during training.\n    exog_in_ : bool\n        If the forecaster has been trained using exogenous variable/s.\n    exog_names_in_ : list\n        Names of the exogenous variables used during training.\n    exog_type_in_ : type\n        Type of exogenous data (pandas Series or DataFrame) used in training.\n    exog_dtypes_in_ : dict\n        Type of each exogenous variable/s used in training. If `transformer_exog` \n        is used, the dtypes are calculated before the transformation.\n    X_train_window_features_names_out_ : list\n        Names of the window features included in the matrix `X_train` created\n        internally for training.\n    X_train_exog_names_out_ : list\n        Names of the exogenous variables included in the matrix `X_train` created\n        internally for training. It can be different from `exog_names_in_` if\n        some exogenous variables are transformed during the training process.\n    X_train_features_names_out_ : list\n        Names of columns of the matrix created internally for training.\n    fit_kwargs : dict\n        Additional arguments to be passed to the `fit` method of the regressor.\n    in_sample_residuals_ : numpy ndarray\n        Residuals of the model when predicting training data. Only stored up to\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries with Skforecast in Python\nDESCRIPTION: This snippet imports necessary libraries for data handling, plotting, preprocessing, and using the Skforecast library to work with time series data. Dependencies include pandas, matplotlib, sklearn, LightGBM, and the Skforecast library. Ensure all libraries are installed in your environment before running the script.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom lightgbm import LGBMRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\nfrom skforecast.direct import ForecasterDirect, ForecasterDirectMultiVariate\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Test Sets\nDESCRIPTION: This snippet partitions the multiseries and exogenous data into training and test sets based on a specified end date for the training data. This is crucial to prepare the datasets for modeling and evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nend_train = \\\"2016-07-31 23:59:00\\\"\nseries_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\nexog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\nseries_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\nexog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Skforecast Time Series Forecasting\nDESCRIPTION: Imports all necessary libraries and modules required for time series forecasting with skforecast. This includes typing utilities, data processing libraries like numpy and pandas, scikit-learn components, and various utility functions from the skforecast package.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/paralel_create_train_X_y.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Union, Tuple, Optional, Callable\nimport warnings\nimport logging\nimport sys\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import clone\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom copy import copy\nimport inspect\nfrom joblib import Parallel, delayed\n\nimport skforecast\nfrom skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\nfrom skforecast.ForecasterBase import ForecasterBase\nfrom skforecast.exceptions import MissingValuesWarning\nfrom skforecast.exceptions import IgnoredArgumentWarning\nfrom skforecast.utils import initialize_lags\nfrom skforecast.utils import initialize_weights\nfrom skforecast.utils import initialize_transformer_series\nfrom skforecast.utils import check_select_fit_kwargs\nfrom skforecast.utils import check_preprocess_series\nfrom skforecast.utils import check_preprocess_exog_multiseries\nfrom skforecast.utils import align_series_and_exog_multiseries\nfrom skforecast.utils import get_exog_dtypes\nfrom skforecast.utils import check_exog_dtypes\nfrom skforecast.utils import check_interval\nfrom skforecast.utils import check_predict_input\nfrom skforecast.utils import preprocess_last_window\nfrom skforecast.utils import expand_index\nfrom skforecast.utils import transform_series\nfrom skforecast.utils import transform_dataframe\nfrom skforecast.utils import set_skforecast_warnings\nfrom skforecast.preprocessing import TimeSeriesDifferentiator\n\n\n# Libraries\n```\n\n----------------------------------------\n\nTITLE: Reverting Transformations in Training Predictions\nDESCRIPTION: This code snippet demonstrates how to revert transformations applied to training predictions in a forecaster model. It reshapes the transformed predictions and applies inverse transformation using the forecaster's transformer_y attribute.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Revert transformation (only if transformer_y is not None)\npredictions_training = forecaster.transformer_y.inverse_transform(predictions_transformed.reshape(-1, 1))\npredictions_training.ravel()[:4]\n```\n\n----------------------------------------\n\nTITLE: Get Feature Importances\nDESCRIPTION: This code snippet retrieves and displays the feature importances of the model. This can be useful for understanding which features are most influential in the model's predictions.  The feature importances may be based on how the Sarimax model internally handles features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nforecaster.get_feature_importances()\n```\n\n----------------------------------------\n\nTITLE: One-Step-Ahead Cross-Validation\nDESCRIPTION: Executes grid search using one-step-ahead cross-validation strategy and compares results with backtesting approach.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ncv = OneStepAheadFold(\n    initial_train_size=len(series_dict_train[\"id_1000\"]),\n)\nresults_one_step_ahead = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series_dict,\n    exog=exog_dict,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=metrics,\n    cv=cv,\n    return_best=False,\n    show_progress=True,\n    verbose=False,\n    suppress_warnings=True,\n)\n\npd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)\n```\n\n----------------------------------------\n\nTITLE: Installing Latest Development Version from GitHub\nDESCRIPTION: Installs the latest (potentially unstable) development version of skforecast directly from the master branch on GitHub. Useful for accessing the newest features.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/skforecast/skforecast@master\n```\n\n----------------------------------------\n\nTITLE: Generate Random Data\nDESCRIPTION: Generates a pandas Series containing 1,000,000 random numbers drawn from a normal distribution. This series serves as input data for training the forecasting model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Data\n# ==============================================================================\ndata = pd.Series(np.random.normal(size=1000000))\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Using exog_long_to_dict Function\nDESCRIPTION: Reference to the exog_long_to_dict function that has been updated with a new consolidate_dtypes argument to ensure data type consistency across series when handling NaN values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n[exog_long_to_dict]\n```\n\n----------------------------------------\n\nTITLE: Citation formats for skforecast\nDESCRIPTION: Various citation formats for referencing skforecast in academic publications, including Zenodo, APA style, and BibTeX format.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/more/about-skforecast.md#2025-04-21_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@software{skforecast,\nauthor = {Amat Rodrigo, Joaquin and Escobar Ortiz, Javier},\ntitle = {skforecast},\nversion = {0.15.1},\nmonth = {3},\nyear = {2025},\nlicense = {BSD-3-Clause},\nurl = {https://skforecast.org/},\ndoi = {10.5281/zenodo.8382788}\n}\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Time Series Data in Python with SKForecast\nDESCRIPTION: Function that preprocesses time series data by separating values and index. Handles different index types with specific rules for DatetimeIndex and RangeIndex. Returns a tuple containing numpy array of values and processed pandas Index.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/CONTRIBUTING.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_y(\n    y: pd.Series\n) -> tuple[np.ndarray, pd.Index]:\n    \"\"\"\n    Return values and index of series separately. Index is overwritten \n    according to the next rules:\n    \n        - If index is of type `DatetimeIndex` and has frequency, nothing is \n        changed.\n        - If index is of type `RangeIndex`, nothing is changed.\n        - If index is of type `DatetimeIndex` but has no frequency, a \n        `RangeIndex` is created.\n        - If index is not of type `DatetimeIndex`, a `RangeIndex` is created.\n    \n    Parameters\n    ----------\n    y : pandas Series, pandas DataFrame\n        Time series.\n    return_values : bool, default True\n        If `True` return the values of `y` as numpy ndarray. This option is \n        intended to avoid copying data when it is not necessary.\n\n    Returns\n    -------\n    y_values : None, numpy ndarray\n        Numpy array with values of `y`.\n    y_index : pandas Index\n        Index of `y` modified according to the rules.\n    \n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Listing Forecaster Attributes\nDESCRIPTION: Iterates through and prints all attributes stored in the forecaster object.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfor attribute, value in forecaster.__dict__.items():\n    print(attribute)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Time Series Data\nDESCRIPTION: This code snippet sets up a plot to visualize each time series along with a vertical line indicating the end of the training period. The plot utilizes a dark theme for better visibility.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nset_dark_theme()\ncolors = plt.rcParams[\\\"axes.prop_cycle\\\"].by_key()[\\\"color\\\"]\nfig, axs = plt.subplots(5, 1, figsize=(8, 4), sharex=True)\nfor i, s in enumerate(series_dict.values()):\n    axs[i].plot(s, label=s.name, color=colors[i])\n    axs[i].legend(loc=\\\"upper right\\\", fontsize=8)\n    axs[i].tick_params(axis=\\\"both\\\", labelsize=8)\n    axs[i].axvline(\n        pd.to_datetime(end_train), color=\\\"white\\\", linestyle=\\\"--\\\", linewidth=1\n    )\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Preparing Inputs for Metric Calculation\nDESCRIPTION: Captures the output of _backtesting_forecaster_multiseries to use as input for the metrics calculation function. The output includes predictions, fold information, and metric configurations.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# returns = {\n#         'series'                :series,\n#         'predictions'           :backtest_predictions[['level', 'pred']],\n#         'folds'                 :folds,\n#         'span_index'            :span_index,\n#         'window_size'           :forecaster.window_size,\n#         'metrics'               :metrics,\n#         'levels'                :levels,\n#         'add_aggregated_metric' :add_aggregated_metric\n#     }\n\n#     return returns\n\n\nfrom skforecast.model_selection._validation import _backtesting_forecaster_multiseries\ninputs_calculate_metrics = _backtesting_forecaster_multiseries(\n    forecaster    = forecaster,\n    series        = series,\n    cv            = cv,\n    metric        = [\"mean_absolute_error\"],\n    show_progress = False,\n    add_aggregated_metric = True\n)\n```\n\n----------------------------------------\n\nTITLE: Alternative Method for Reverting Data Transformation\nDESCRIPTION: This snippet shows how to use the transform_numpy utility function from skforecast to apply inverse transformation to predictions. This is an alternative to using the transformer_y attribute directly.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.utils import transform_numpy\n\npredictions = transform_numpy(\n                  array             = predictions_transformed,\n                  transformer       = forecaster.transformer_y,\n                  fit               = False,\n                  inverse_transform = True\n              )\n```\n\n----------------------------------------\n\nTITLE: Installing Skforecast using pip\nDESCRIPTION: Command for installing the basic version of Skforecast with core dependencies using pip package manager.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast\n```\n\n----------------------------------------\n\nTITLE: Importing skforecast and Supporting Libraries\nDESCRIPTION: Imports specific modules from skforecast for recursive forecasting and model selection, along with LGBMRegressor from lightgbm. Also loads profiling extensions for performance analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_forecaster_multiseries\nfrom lightgbm import LGBMRegressor\n%load_ext pyinstrument\n%load_ext line_profiler\n```\n\n----------------------------------------\n\nTITLE: Save Load Skforecast Warning Class\nDESCRIPTION: A custom warning class for issues related to saving and loading skforecast models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.SaveLoadSkforecastWarning\n```\n\n----------------------------------------\n\nTITLE: Simulating Over-conservative Intervals\nDESCRIPTION: Generates synthetic data with over-conservative prediction intervals and calculates initial coverage probability.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.default_rng(42)\ninterval = pd.DataFrame({\n        'lower_bound': np.sin(np.linspace(0, 4 * np.pi, 100)),\n        'upper_bound': np.sin(np.linspace(0, 4 * np.pi, 100)) + 5\n    },\n    index=pd.date_range(start='2024-01-01', periods=100, freq='D')\n)\ny_true = (interval['lower_bound'] + interval['upper_bound']) / 2 + rng.normal(0, 0.5, 100)\ny_true.name = \"series_1\"\ny_true.iloc[1::9] = interval.iloc[1::9, 0] - rng.normal(1, 1, 11)\ny_true.iloc[3::9] = interval.iloc[1::9, 1] + rng.normal(1, 1, 11)\n\nfig, ax = plt.subplots(figsize=(7, 3))\ninterval.plot(ax=ax, linestyle=\"--\")\ny_true.plot(ax=ax, label='True values')\nax.set_yticklabels([])\nax.set_xticklabels([])\nax.legend(loc=\"upper right\", fontsize=8, ncol=3)\nplt.show()\n\ncoverage = calculate_coverage(\n               y_true      = y_true,\n               lower_bound = interval[\"lower_bound\"],\n               upper_bound = interval[\"upper_bound\"],\n           )\nprint(f'Coverage: {coverage:.2f}')\n```\n\n----------------------------------------\n\nTITLE: Searching Links in Documentation Files\nDESCRIPTION: Script to search for specific text/links in Jupyter notebooks and markdown files within a directory. Uses nbformat to parse notebook files and includes functionality to search through markdown cells.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport nbformat\n\ndef search_text_in_files(directory, search_text_base):\n    notebooks_with_text = []\n    markdown_files_with_text = []\n\n    # Recorre todos los archivos de la carpeta\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            if file.endswith(\".ipynb\"):\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    nb = nbformat.read(f, as_version=4)\n                    \n                    # Recorre todas las celdas del notebook\n                    for cell in nb.cells:\n                        if cell.cell_type == 'markdown':\n                            if search_text_base in cell.source:\n                                notebooks_with_text.append(file_path)\n                                break\n            elif file.endswith(\".md\"):\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    if search_text_base in content:\n                        markdown_files_with_text.append(file_path)\n\n    return notebooks_with_text, markdown_files_with_text\n```\n\n----------------------------------------\n\nTITLE: Benchmarking sklearn's mean_absolute_error Function\nDESCRIPTION: Benchmarks the performance of sklearn's mean_absolute_error function on NumPy arrays, measuring execution time over 500 iterations on large input arrays.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# example of using sklearn metric mean_absolute_error\nfrom sklearn.metrics import mean_absolute_error\nimport time\n\ny_true = pd.Series(np.random.normal(0, 1, 10_0000))\ny_pred = pd.Series(np.random.normal(0, 1, 10_0000))\n\nstart = time.time()\nfor i in range(500):\n    mean_absolute_error(y_true.to_numpy(), y_pred.to_numpy())\nprint(time.time() - start)\n```\n\n----------------------------------------\n\nTITLE: Checking User Guide Links in Python\nDESCRIPTION: This snippet checks all links in a user guides list for broken links using the 'check_links_ignoring_nav_links' function. It collects the results into a list for final output display. The expected input is a list of user guide links, and the output is a consolidated list of broken links printed to the console.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Check all links in user guides list\n# ============================================================================== \nbroken_links_user_guides = []\nfor link in links_user_guides:\n    broken_links = check_links_ignoring_nav_links(link)\n    broken_links_user_guides.extend(broken_links)\n\nprint(\"\")\nprint(\"\")\nprint(Style.BRIGHT + Fore.RED + \"Resumen de enlaces rotos:\")\nprint(\"-\" * 80)\nprint(\"\\n\".join(broken_links_user_guides) + Style.RESET_ALL)\n```\n\n----------------------------------------\n\nTITLE: Index Warning Class in Skforecast\nDESCRIPTION: A custom warning class for issues related to indexes in time series data in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.IndexWarning\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting in Python\nDESCRIPTION: Imports essential libraries for time series forecasting, data manipulation, and visualization, including pandas, numpy, matplotlib, and components from the skforecast library.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/weighted-time-series-forecasting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Libraries\n# ================================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_forecaster\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Results Visualization and Summary\nDESCRIPTION: Summarizes and visualizes the benchmark results comparing different forecasting approaches using the specified metric.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nsummarize_results(\n    results   = results_grid_search,\n    metric    = metric,\n    plot      = True,\n    fig_size  = (8, 6),\n    title     = 'Grid search using backtesting vs one-step-ahead',\n    save_plot = \"../img/grid_search_benchmarck.png\"\n)\n```\n\n----------------------------------------\n\nTITLE: Profiling Metrics Calculation with Pyinstrument\nDESCRIPTION: Uses pyinstrument to profile the performance of _calculate_metrics_backtesting_multiseries function, providing an alternative visualization of the performance bottlenecks.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n%%pyinstrument\n_ = _calculate_metrics_backtesting_multiseries(**inputs_calculate_metrics)\n```\n\n----------------------------------------\n\nTITLE: Importing ForecasterRecursive Class in Python\nDESCRIPTION: This snippet shows how to import the ForecasterRecursive class from the skforecast library. It is used for recursive time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/ForecasterRecursive.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom skforecast.recursive._forecaster_recursive import ForecasterRecursive\n```\n\n----------------------------------------\n\nTITLE: Configuring Jupyter Environment for Skforecast Development\nDESCRIPTION: Sets up the Jupyter notebook environment by enabling autoreload extension and adding the parent directory to the system path to allow importing modules from the parent directory.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\nsys.path.insert(1, str(Path.cwd().parent))\nstr(Path.cwd().parent)\n```\n\n----------------------------------------\n\nTITLE: Link Validation Script\nDESCRIPTION: Script to check and validate links in web pages, excluding navigation links and specific CSS classes. Uses requests and BeautifulSoup to parse HTML and verify link accessibility.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\nfrom colorama import Fore, Style\n\ndef check_links_ignoring_nav_links(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        print(f\"[OK] Pgina accesible: {url}\")\n    except requests.exceptions.RequestException as e:\n        print(\n            Style.BRIGHT + Fore.RED + \n            f\"[ERROR] No se pudo acceder a {url}: {e}\"\n            + Style.RESET_ALL\n        )\n        return [url]\n\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    links = soup.find_all(\"a\", href=True)\n    classes_no_to_visit = [\n        'md-header__button', 'md-logo', \"md-nav__link\", \"md-tabs__link\",\n        'md-source', 'md-social__link', 'autorefs-external'\n    ]\n\n    broken_links = []\n    for link in links:\n        class_link = link.get(\"class\", [])\n        if any(class_no_to_visit in class_link for class_no_to_visit in classes_no_to_visit):\n            continue\n\n        href = link['href']\n        if href[0] == \"#\":\n            continue\n\n        full_url = urljoin(url, href)\n\n        try:\n            link_response = requests.get(full_url)\n            link_response.raise_for_status()\n            print(f\"  [OK] Enlace accesible: {class_link} - {full_url}\")\n        except requests.exceptions.RequestException:\n            print(\n                Style.BRIGHT + Fore.RED + \n                f\"  [ERROR] Enlace roto o inaccesible: {full_url}\" \n                + Style.RESET_ALL\n            )\n            broken_links.append(\n                f\"[ERROR] Enlace roto o inaccesible en {url}: {full_url}\"\n            )\n\n    return broken_links\n```\n\n----------------------------------------\n\nTITLE: Profiling Backtesting with Prediction Intervals\nDESCRIPTION: Profiles backtesting_forecaster_multiseries with prediction intervals enabled, which adds bootstrap sampling and binned residuals to generate confidence intervals for forecasts.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n%%pyinstrument\n_ = backtesting_forecaster_multiseries(\n    forecaster           = forecaster,\n    series               = series,\n    cv                   = cv,\n    metric               = \"mean_absolute_error\",\n    interval             = [10, 90],\n    n_boot               = 10,\n    use_binned_residuals = True,\n    show_progress        = False\n)\n```\n\n----------------------------------------\n\nTITLE: Ignored Argument Warning Class in Skforecast\nDESCRIPTION: A custom warning class for when arguments are ignored in function calls in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.IgnoredArgumentWarning\n```\n\n----------------------------------------\n\nTITLE: Grid Search on Multiseries Forecaster\nDESCRIPTION: This section uses grid search to test different hyperparameter combinations for the forecaster model. The results are then compared to determine the best performing set.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nforecaster = ForecasterRecursiveMultiSeries(\n    regressor=LGBMRegressor(n_estimators=10, random_state=123, verbose=-1, max_depth=2),\n    lags=14,\n    encoding=\\\"ordinal\\\",\n    dropna_from_series=False,\n    transformer_series=StandardScaler(),\n    transformer_exog=StandardScaler(),\n)\n\nlags_grid = [[5], [1, 7, 14]]\n\nparam_grid = {\n    \\\"learning_rate\\\": [0.1],\n    \\\"n_estimators\\\": [10, 20],\n    \\\"max_depth\\\": [2, 5],\n}\n\ncv = TimeSeriesFold(\n        initial_train_size=len(series_dict_train[\\\"id_1000\\\"]),\n        steps=10,\n        refit=False,\n    )\n\nresults_search = grid_search_forecaster_multiseries(\n    forecaster=forecaster,\n    series=series_dict,\n    exog=exog_dict,\n    lags_grid=lags_grid,\n    param_grid=param_grid,\n    metric=\\\"mean_absolute_error\\\",\n    cv=cv,\n    return_best=False,\n    show_progress=True,\n    verbose=False,\n    suppress_warnings=True,\n)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Profiling Metrics Calculation with Line Profiler\nDESCRIPTION: Creates a wrapper function to profile _calculate_metrics_backtesting_multiseries using line_profiler. This analyzes the performance of calculating metrics across multiple series and folds.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Profiling _create_train_X_y()\n# ==============================================================================\nfrom skforecast.model_selection._utils import _calculate_metrics_backtesting_multiseries\ndef funt_to_profile(inputs_calculate_metrics):\n    _calculate_metrics_backtesting_multiseries(**inputs_calculate_metrics)\n\n%lprun -f _calculate_metrics_backtesting_multiseries funt_to_profile(inputs_calculate_metrics)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Bike Sharing Dataset\nDESCRIPTION: Fetches bike sharing dataset, selects users column, and prepares training and testing data splits for time series forecasting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = fetch_dataset(\"bike_sharing\")\ndata = data[['users']].iloc[:1000].copy()\n\nend_train = '2011-01-31 23:59:00'\ndata_train = data.loc[: end_train, :]\ndata_test  = data.loc[end_train:, :]\n```\n\n----------------------------------------\n\nTITLE: Using Backtesting Functions\nDESCRIPTION: References to backtesting functions that now use conformal prediction framework as default for probabilistic forecasting and binned residuals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n[backtesting_forecaster_multiseries]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[backtesting_forecaster]\n```\n\n----------------------------------------\n\nTITLE: Restoring Frequency in Time Series with Missing Data\nDESCRIPTION: Applies daily frequency to the time series with missing data using groupby and asfreq operations, which highlights the gaps in the data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nseries_dropped = series_dropped.groupby('series').apply(lambda x: x.asfreq('D'), include_groups=False)\nseries_dropped\n```\n\n----------------------------------------\n\nTITLE: Creating Time Series with Missing Data\nDESCRIPTION: Creates two time series, converts them to long format, and removes a specific date ('2000-01-02') to demonstrate handling of missing data points in time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nseries_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_1')\nseries_2 = pd.Series([20, 30, 40, 50, 60, 70, 80, 90, 100, 110], index=pd.date_range(start='2000-01-01', periods=10, freq='D'), name='series_2')\nseries = pd.concat([series_1, series_2], axis=1).melt(var_name='series', value_name='value', ignore_index=False)\nseries = series.rename_axis('datetime')\nrow_to_drop = '2000-01-02'\nseries_dropped = series.loc[series.index != row_to_drop]\nseries_dropped\n```\n\n----------------------------------------\n\nTITLE: Configuring IPython Environment and Path Setup for Skforecast Development\nDESCRIPTION: Sets up the IPython environment with autoreload extension to automatically reload modules during development. It also adds the parent directory to the system path to allow importing modules from the parent directory.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/paralel_create_train_X_y.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\nsys.path.insert(1, str(Path.cwd().parent))\nstr(Path.cwd().parent)\n```\n\n----------------------------------------\n\nTITLE: Referencing skforecast preprocessing module components in markdown\nDESCRIPTION: Markdown references to various classes and functions in the skforecast preprocessing module, including RollingFeatures, series conversion utilities, differentiators, binners, and calibrators.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/preprocessing.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `preprocessing`\n\n::: skforecast.preprocessing.preprocessing.RollingFeatures\n::: skforecast.preprocessing.preprocessing.series_long_to_dict\n::: skforecast.preprocessing.preprocessing.exog_long_to_dict\n::: skforecast.preprocessing.preprocessing.TimeSeriesDifferentiator\n::: skforecast.preprocessing.preprocessing.QuantileBinner\n::: skforecast.preprocessing.preprocessing.ConformalIntervalCalibrator\n```\n\n----------------------------------------\n\nTITLE: Unknown Level Warning Class in Skforecast\nDESCRIPTION: A custom warning class for unknown level specifications in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.UnknownLevelWarning\n```\n\n----------------------------------------\n\nTITLE: Importing Skforecast Dataset Module\nDESCRIPTION: Imports the fetch_dataset function from skforecast.datasets module to access predefined time series datasets.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/datasets.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nfrom skforecast.datasets import fetch_dataset\n```\n\n----------------------------------------\n\nTITLE: Initializing Autoregressive Forecaster with LGBMRegressor\nDESCRIPTION: Creates an autoregressive forecaster using LGBMRegressor as the underlying model with 24 lags, which means the model will use the past 24 hours of data to make predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Backtesting forecaster\n# ==============================================================================\nforecaster = ForecasterAutoreg(\n                 regressor = LGBMRegressor(random_state=123),\n                 lags      = 24 \n             )\n```\n\n----------------------------------------\n\nTITLE: Citing Skforecast Using Zenodo Format\nDESCRIPTION: Shows how to cite Skforecast in scientific publications using the Zenodo citation format. Includes author names, version, and DOI information.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/README.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nAmat Rodrigo, Joaquin, & Escobar Ortiz, Javier. (2025). skforecast (v0.15.1). Zenodo. https://doi.org/10.5281/zenodo.8382788\n```\n\n----------------------------------------\n\nTITLE: Missing Values Warning Class in Skforecast\nDESCRIPTION: A custom warning class for missing values in time series data in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.MissingValuesWarning\n```\n\n----------------------------------------\n\nTITLE: Check GPU Availability and Print Information\nDESCRIPTION: Detects and prints information about the available GPU (if any) using the `torch` library. This includes the device name, memory usage (allocated and cached). It also prints CPU RAM information using the `psutil` library.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Print information abput the GPU and CPU\n# ==============================================================================\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0) / 1024**3, 1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_cached(0) / 1024**3, 1), 'GB')\n\nprint(f\"CPU RAM Free: {psutil.virtual_memory().available / 1024**3:.2f} GB\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Loading Raw Dataset\nDESCRIPTION: Retrieves the raw bike_sharing dataset without any preprocessing by setting raw=True parameter.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/datasets.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Download raw data \n# ==============================================================================\ndata = fetch_dataset(name=\"bike_sharing\", raw=True)\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Directory Structure - skforecast < 0.14\nDESCRIPTION: Shows the original flat directory structure of skforecast package before version 0.14, with separate files for different forecasting models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n|-- skforecast\n    |-- ForecasterAutoreg\n        |-- ForecasterAutoreg.py              -> ForecasterAutoreg \n    |-- ForecasterAutoregCustom.py\n        |-- ForecasterAutoregCustom.py        -> ForecasterAutoregCustom\n    |-- ForecasterAutoregDirect\n        |-- ForecasterAutoregDirect.py        -> ForecasterAutoregDirect\n    |-- ForecasterAutoregMultiSeries\n        |-- ForecasterAutoregMultiSeries.py   -> ForecasterAutoregMultiSeries\n    |-- ForecasterAutoregMultiVariate\n        |-- ForecasterAutoregMultiVariate.py  -> ForecasterAutoregMultiVariate\n    |-- ForecasterRnn\n        |-- ForecasterRnn.py                  -> ForecasterRnn\n    |-- ForecsaterBase\n        |-- ForecasterBase.py                 -> ForecasterBase\n    |-- ForecasterSarimax\n        |-- ForecasterSarimax.py              -> ForecasterSarimax\n    |-- Sarimax\n        |-- Sarimax.py                        -> Sarimax\n```\n\n----------------------------------------\n\nTITLE: Remove LightGBM Installation\nDESCRIPTION: Removes any existing LightGBM installation to ensure a clean installation process, particularly when installing from source.  This is performed using a shell command within the Colab environment.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Libraries for Conformal Interval Calibration\nDESCRIPTION: Imports required libraries including numpy, pandas, matplotlib and Skforecast components for interval calibration and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skforecast.plot import set_dark_theme\nfrom skforecast.metrics import calculate_coverage\nfrom skforecast.preprocessing import ConformalIntervalCalibrator\n```\n\n----------------------------------------\n\nTITLE: Skforecast Style UserWarning Example\nDESCRIPTION: Shows UserWarning behavior with skforecast warning style.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwarnings.warn(\"deprecated\", UserWarning)\n```\n\n----------------------------------------\n\nTITLE: Train-Test Data Split\nDESCRIPTION: Splits the time series data into training and testing sets based on specified date ranges.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata = data.loc['2020-06-01': '2021-06-01']\nend_train = '2021-03-01'\ndata_train = data.loc[: end_train, :]\ndata_test  = data.loc[end_train:, :]\n\nprint(f\"Dates train : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\nprint(f\"Dates test  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n```\n\n----------------------------------------\n\nTITLE: Profiling ForecasterDirect Fit and Backtesting Methods - Python\nDESCRIPTION: This snippet profiles the fitting and backtesting methods of the ForecasterDirect using multiple regressors and evaluates elapsed time for different execution strategies (parallel vs non-parallel). It initializes several regressors, sets parameter grids, and measures performance during fitting, training data creation, and various backtesting methods.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"----------------\")\nprint(\"ForecasterDirect\")\nprint(\"----------------\")\nsteps = 10\nlags = 10\nregressors = [\n    Ridge(random_state=77, alpha=0.1),\n    LGBMRegressor(random_state=77, n_jobs=1, n_estimators=50, max_depth=5, verbose=-1),\n    LGBMRegressor(random_state=77, n_jobs=-1, n_estimators=50, max_depth=5, verbose=-1),\n    HistGradientBoostingRegressor(random_state=77, max_iter=50, max_depth=5,)\n]\nparam_grids = [\n    {'alpha': [0.1, 0.1, 0.1]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'n_estimators': [50, 50], 'max_depth': [5, 5]},\n    {'max_iter': [50, 50], 'max_depth': [5, 5]}\n]\nlags_grid = [50, 50, 50]\nelapsed_times = []\n\nfor regressor, param_grid in zip(regressors, param_grids):\n    print(\"\")\n    print(regressor, param_grid)\n    print(\"\")\n    forecaster = ForecasterDirect(\n                     regressor        = regressor,\n                     steps            = steps,\n                     lags             = lags,\n                     transformer_exog = StandardScaler()\n                 )\n    \n    print(\"Profiling fit\")\n    start = time.time()\n    forecaster.fit(y=y, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling create_train_X_y\")\n    start = time.time()\n    _ = forecaster.create_train_X_y(y=y, exog=exog)\n    end = time.time()\n    elapsed_times.append(end - start)\n\n    print(\"Profiling backtesting refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             steps              = steps,\n             initial_train_size = int(len(y) * 0.9),\n             refit              = True,\n             fixed_train_size   = False,\n         )\n    metric, backtest_predictions = backtesting_forecaster(\n                                       forecaster    = forecaster,\n                                       y             = y,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting refit no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster(\n                                       forecaster    = forecaster,\n                                       y             = y,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit parallel\")\n    start = time.time()\n    cv = TimeSeriesFold(\n             steps              = steps,\n             initial_train_size = int(len(y) * 0.9),\n             refit              = False,\n         )\n    metric, backtest_predictions = backtesting_forecaster(\n                                       forecaster    = forecaster,\n                                       y             = y,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = -1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling backtesting no refit no parallel\")\n    start = time.time()\n    metric, backtest_predictions = backtesting_forecaster(\n                                       forecaster    = forecaster,\n                                       y             = y,\n                                       exog          = exog,\n                                       cv            = cv,\n                                       metric        = 'mean_squared_error',\n                                       interval      = None,\n                                       n_boot        = 500,\n                                       random_state  = 123,\n                                       verbose       = False,\n                                       show_progress = False,\n                                       n_jobs        = 1\n                                   )\n    end = time.time()\n    elapsed_times.append(end - start)    \n    \n    print(\"Profiling GridSearch no refit parallel\")\n    start = time.time()\n    results_grid = grid_search_forecaster(\n                       forecaster    = forecaster,\n                       y             = y,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = -1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n    \n    print(\"Profiling GridSearch no refit no parallel\")\n    start = time.time()\n    results_grid = grid_search_forecaster(\n                       forecaster    = forecaster,\n                       y             = y,\n                       exog          = exog,\n                       cv            = cv,\n                       param_grid    = param_grid,\n                       lags_grid     = lags_grid,\n                       metric        = 'mean_squared_error',\n                       return_best   = False,\n                       verbose       = False,\n                       show_progress = False,\n                       n_jobs        = 1\n                   )\n    end = time.time()\n    elapsed_times.append(end - start)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Weights in ForecasterRecursive with Python\nDESCRIPTION: Demonstration of using custom weights in ForecasterRecursive. This allows assigning different importance to different time periods in the time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-parameters.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is between 2012-06-01 and 2012-10-21.\n    \"\"\"\n    weights = np.where(\n        (index >= '2012-06-01') & (index <= '2012-10-21'),\n         0,\n         1\n    )\n\n    return weights\n\nforecaster = ForecasterRecursive(\n    regressor        = LGBMRegressor(random_state=123, verbose=-1),\n    lags             = 5,\n    window_features  = None,\n    transformer_y    = None,\n    transformer_exog = None,\n    weight_func      = custom_weights\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Benchmarking Ridge with ForecasterRecursive on Website Visits Data\nDESCRIPTION: Sets up a ForecasterRecursive with Ridge regression and StandardScaler for the website visits dataset. Includes calendar-based exogenous features, different lag configurations (7, 14, 21 days), and alpha parameter tuning using grid search.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Dataset website_visits - ForecasterRecursive\n# ==============================================================================\nend_train = '2021-03-30 23:59:00'\nend_validation = '2021-06-30 23:59:00'\nexog_features = [col for col in data_website.columns if col.startswith(('month_', 'week_day_', 'month_day_'))]\n\nforecaster = ForecasterRecursive(\n                 regressor     = Ridge(random_state=123),\n                 transformer_y = StandardScaler(),\n                 lags          = 10\n             )\n\nlags_grid = [7, 14, 21, [7, 14, 21]]\n\nparam_grid = {'alpha': np.logspace(-3, 3, 20)}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark(\n    data                    = data_website,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    target                  = 'users',\n    exog_features           = exog_features,\n    steps                   = 7,\n    metric                  = metric\n)\nresults_grid_search.append([\n    'website',\n    type(forecaster).__name__,\n    time_1,\n    time_2,\n    metric_1,\n    metric_2,\n])\n```\n\n----------------------------------------\n\nTITLE: Including FontAwesome Script\nDESCRIPTION: HTML script tag to include the FontAwesome icon library via CDN for use in the documentation interface.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/examples/examples_english.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n```\n\n----------------------------------------\n\nTITLE: Import Required Libraries for Forecasting\nDESCRIPTION: The snippet imports necessary libraries for data preprocessing, plotting, and modeling time series data. Dependencies include NumPy, Pandas, Matplotlib, and Skforecast's specialized functions for forecasting and evaluation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Data processing\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nfrom skforecast.datasets import fetch_dataset\n\n# Plots\n# ==============================================================================\nimport matplotlib.pyplot as plt\nfrom skforecast.plot import set_dark_theme, plot_residuals, plot_prediction_intervals\n\n# Modelling and Forecasting\n# ==============================================================================\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.model_selection import TimeSeriesFold, backtesting_forecaster\nfrom skforecast.metrics import calculate_coverage\n\n# Configuration\n# ==============================================================================\nimport warnings\nwarnings.filterwarnings('once')\n```\n\n----------------------------------------\n\nTITLE: Checking General Links in Python\nDESCRIPTION: This snippet performs a similar operation as the previous one but checks all links in a general list. It collects broken links found into a separate list, which is then outputted to the console. The input is a list of general links, with the expected output being a list of broken links printed clearly.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Check all links in general list\n# ============================================================================== \nbroken_links_general = []\nfor link in links_general:\n    broken_links = check_links_ignoring_nav_links(link)\n    broken_links_general.extend(broken_links)\n\nprint(\"\")\nprint(\"\")\nprint(Style.BRIGHT + Fore.RED + \"Resumen de enlaces rotos:\")\nprint(\"-\" * 80)\nprint(\"\\n\".join(broken_links_general) + Style.RESET_ALL)\n```\n\n----------------------------------------\n\nTITLE: Accessing Index of a Specific Series\nDESCRIPTION: Demonstrates how to access the datetime index of a specific series ('series_1') from the grouped time series data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nseries.loc['series_1'].index\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Importing Libraries for ForecasterRecursiveMultiSeries Testing\nDESCRIPTION: Configures the development environment by importing required libraries and setting up the Python path. Displays version information for key dependencies like skforecast, lightgbm, and sklearn.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\npath = str(Path.cwd().parent.parent)\nsys.path.insert(1, path)\nprint(path)\n\nimport numpy as np\nimport pandas as pd\nimport joblib\nimport matplotlib.pyplot as plt\nfrom skforecast.plot import set_dark_theme\nfrom tqdm.notebook import tqdm\nimport skforecast\nimport lightgbm\nimport sklearn\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import ParameterGrid\nfrom skforecast.preprocessing import series_long_to_dict\nfrom skforecast.preprocessing import exog_long_to_dict\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\nfrom skforecast.model_selection_multiseries import (\n    bayesian_search_forecaster_multiseries,\n)\nfrom skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\nimport warnings\nimport sys\n\nprint(f\"Python version: {sys.version}\")\nprint(f\"skforecast version: {skforecast.__version__}\")\nprint(f\"lightgbm version: {lightgbm.__version__}\")\nprint(f\"sklearn version: {sklearn.__version__}\")\nprint(f\"Last execution: {pd.Timestamp.now()}\")\n```\n\n----------------------------------------\n\nTITLE: Testing Backtesting with Prediction Intervals\nDESCRIPTION: Stub for testing backtesting with prediction intervals functionality. This snippet only contains a comment indicating planned testing for interval-based predictions in backtesting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_same_length_withouth_nans.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Test backtesting with intervals\n```\n\n----------------------------------------\n\nTITLE: Implementing calculate_lag_autocorrelation Function\nDESCRIPTION: Reference to a new function in the plot module that calculates the autocorrelation and partial autocorrelation of a time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n[calculate_lag_autocorrelation]\n```\n\n----------------------------------------\n\nTITLE: Results DataFrame and Visualization - Python\nDESCRIPTION: This snippet processes the elapsed times into a DataFrame for results comparison and visualizes the performance improvement of parallel execution over sequential execution for each method using a bar plot.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmethods = [\n    \"fit\",\n    \"create_train_X_y\",\n    \"backtest_refit_parallel\",\n    \"backtest_refit_noparallel\",\n    \"backtest_no_refit_parallel\",\n    \"backtest_no_refit_noparallel\",\n    \"gridSearch_no_refit_parallel\",\n    \"gridSearch_no_refit_noparallel\"\n]\n\nresults = pd.DataFrame({\n    \"regressor\": np.repeat(np.array([str(regressor) for regressor in regressors]), len(methods)),\n    \"method\": np.tile(methods, len(regressors)),\n    \"elapsed_time\": elapsed_times\n})\nresults[\"regressor\"] = results[\"regressor\"].str.replace(\"\\n              \", \" \")\nresults['parallel'] = results.method.str.contains(\"_parallel\")\nresults['method'] = results.method.str.replace(\"_parallel\", \"\")\nresults['method'] = results.method.str.replace(\"_noparallel\", \"\")\nresults = results.sort_values(by=[\"regressor\", \"method\", \"parallel\"])\n\nresults_pivot = results.pivot_table(\n    index=[\"regressor\", \"method\"],\n    columns=\"parallel\",\n    values=\"elapsed_time\"\n).reset_index()\nresults_pivot.columns.name = None\nresults_pivot[\"pct_improvement\"] = (results_pivot[False] - results_pivot[True]) / results_pivot[False] * 100\ndisplay(results_pivot)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nbars = sns.barplot(data=results_pivot.dropna(), x=\"method\", y=\"pct_improvement\", hue=\"regressor\", ax=ax)\nfor container in bars.containers:\n    ax.bar_label(container, fmt='%.1f', padding=3, fontsize=8)\nax.set_title(\"Parallel vs Sequential (ForecasterDirect)\")\nax.set_ylabel(\"Percent improvement\")\nax.set_xlabel(\"Method\")\nax.legend(fontsize=8, loc='lower left', bbox_to_anchor=(0, -0.31), ncols=1);\n```\n\n----------------------------------------\n\nTITLE: Dataset Preparation for ForecasterRecursive in Python\nDESCRIPTION: Code comment indicating preparation for a benchmark test using the bike_sharing_extended_features dataset with a ForecasterRecursive model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Dataset bike_sharing_extended_features - ForecasterRecursive\n```\n\n----------------------------------------\n\nTITLE: Triggering DataTransformationWarning\nDESCRIPTION: Demonstrates raising a custom DataTransformationWarning with a deprecated message.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwarnings.warn(\"deprecated\", DataTransformationWarning)\n```\n\n----------------------------------------\n\nTITLE: Log Transformation of Time Series Data\nDESCRIPTION: Applies logarithmic transformation to the time series data using numpy's log1p function to ensure positive predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata_log = np.log1p(data)\ndata_train_log = np.log1p(data_train)\ndata_test_log  = np.log1p(data_test)\n```\n\n----------------------------------------\n\nTITLE: Method Aliasing Example\nDESCRIPTION: Example of function aliasing pattern used in the codebase\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nbacktesting_forecaster_multivariate = backtesting_forecaster_multiseries\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Environment with Autoreload for skforecast\nDESCRIPTION: Configures the Python environment by enabling autoreload extension and adding the parent directory to the system path to allow importing from the skforecast package.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\nsys.path.insert(1, str(Path.cwd().parent))\nstr(Path.cwd().parent)\n```\n\n----------------------------------------\n\nTITLE: Documentation Path Management\nDESCRIPTION: Script for managing documentation paths and URLs, including functionality to convert file extensions and generate complete documentation links. Handles both general documentation and user guides paths.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nbase_url = \"https://skforecast.org/0.15.1/\"\n# base_url = \"https://dev.skforecast.org/0.15.0/\"\n\n# Lista de rutas extradas del archivo mkdocs.yml\npaths_general = [\n    \"\",\n    \"examples/examples_english.md\",\n    \"examples/examples_spanish.md\",\n    # ... other paths\n]\n\ndef change_extension_to_html(path):\n    if path.endswith(\".md\") or path.endswith(\".ipynb\"):\n        return path.rsplit(\".\", 1)[0] + \".html\"\n    return path\n```\n\n----------------------------------------\n\nTITLE: Retrieving Forecaster Identifier\nDESCRIPTION: This short snippet retrieves and displays the forecaster_id from a forecaster instance, which is used to identify the forecaster in model management.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Forecaster identifier\n# ============================================================================== \nforecaster.forecaster_id\n```\n\n----------------------------------------\n\nTITLE: Referencing Deprecated ForecasterAutoregCustom and ForecasterAutoregMultiSeriesCustom Classes\nDESCRIPTION: References to classes that have been removed in version 0.15.0 after being deprecated in version 0.14.0. Their functionality is now available through the window_features argument in other forecaster classes.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterAutoregCustom]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[ForecasterAutoregMultiSeriesCustom]\n```\n\n----------------------------------------\n\nTITLE: Generate Random Data for LightGBM\nDESCRIPTION: Generates a pandas Series containing 1,000,000 random numbers drawn from a normal distribution. This series serves as input data for training the LightGBM forecasting model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Data\n# ==============================================================================\ndata = pd.Series(np.random.normal(size=1000000))\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Exogenous Variable Transformation in Time Series\nDESCRIPTION: Illustrates how additional external variables can be incorporated into time series data for more comprehensive predictive modeling\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/introduction-forecasting/introduction-forecasting.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<p style=\"text-align: center\">\n    <img src=\"../img/matrix_transformation_with_exog_variable.png\" style=\"width: 500px;\">\n    <br>\n    <font size=\"2.5\"> <i>Time series transformation including an exogenous variable</i></font>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Data Transformation Warning Class in Skforecast\nDESCRIPTION: A custom warning class for issues related to data transformations in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.DataTransformationWarning\n```\n\n----------------------------------------\n\nTITLE: Setting up Jupyter Environment with Path Configuration and Basic Imports for skforecast\nDESCRIPTION: This code initializes a Jupyter notebook by enabling autoreload, configuring the Python path to include the parent directory of the current working directory, and importing essential data science libraries (NumPy and pandas).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/00_template.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\npath = str(Path.cwd().parent)\nprint(path)\nsys.path.insert(1, path)\n\nimport numpy as np\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Missing Exogenous Variables Warning Class in Skforecast\nDESCRIPTION: A custom warning class for when exogenous variables are missing in skforecast models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.MissingExogWarning\n```\n\n----------------------------------------\n\nTITLE: Install Boost Library\nDESCRIPTION: Installs the Boost library, which is a prerequisite for building LightGBM with GPU support. This command utilizes apt-get, a package manager commonly used in Debian-based Linux distributions, including the ones in Google Colab.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n!apt-get install -y -qq libboost-all-dev\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Data Download and Initial Display\nDESCRIPTION: Downloads the BiciMAD dataset using skforecast's fetch_dataset function and displays the first 3 rows.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = fetch_dataset(\"bicimad\")\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Generating Prediction Intervals and True Values with NumPy and Pandas\nDESCRIPTION: This snippet generates a pandas DataFrame named `interval` containing upper and lower bounds using NumPy's `linspace` and `sin` functions, indexed by date. It also creates a `y_true` pandas Series representing true values, derived from the interval and incorporating random noise. Outliers are added to the true values based on the interval bounds, further simulating real-world scenarios.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-calibrate-intervals.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.default_rng(42)\ninterval = pd.DataFrame({\n        'lower_bound': np.sin(np.linspace(0, 4 * np.pi, 100)),\n        'upper_bound': np.sin(np.linspace(0, 4 * np.pi, 100)) + 5\n    },\n    index=pd.date_range(start='2024-01-01', periods=100, freq='D')\n)\ny_true = (interval['lower_bound'] + interval['upper_bound']) / 2 + rng.normal(0, 0.5, 100)\ny_true.name = \"series_1\"\ny_true.iloc[1::6] = interval.iloc[1::6, 0] - rng.normal(1, 1, 17)\ny_true.iloc[3::4] = interval.iloc[1::4, 1] + rng.normal(3, 2, 25)\n```\n\n----------------------------------------\n\nTITLE: Citing Skforecast Using APA Format\nDESCRIPTION: Shows how to cite Skforecast in scientific publications using the APA citation format. Includes author names, year, version, and DOI information.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/README.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nAmat Rodrigo, J., & Escobar Ortiz, J. (2025). skforecast (Version 0.15.1) [Computer software]. https://doi.org/10.5281/zenodo.8382788\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment with Autoreload and Importing Base Libraries\nDESCRIPTION: Configures Jupyter notebook with autoreload extension, adds the parent directory to the system path, and imports fundamental Python libraries for data manipulation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\npath = str(Path.cwd().parent)\nprint(path)\nsys.path.insert(1, path)\n\nimport numpy as np\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Evaluating Forecast Error with Mean Squared Error\nDESCRIPTION: Calculates and displays the mean squared error (MSE) between the model's predictions and the actual test data to quantify forecast accuracy.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-baseline.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Prediction error\n# ==============================================================================\nerror_mse = mean_squared_error(\n                y_true = data_test,\n                y_pred = predictions\n            )\n            \nprint(f\"Test error (mse): {error_mse}\")\n```\n\n----------------------------------------\n\nTITLE: Apply Uniform Transformation to Exogenous Variables in Python\nDESCRIPTION: This snippet sets up a ForecasterRecursive to scale all exogenous variables using StandardScaler, and fits the forecaster with appropriate target and exogenous data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Create and fit forecaster with same tranformation for all exogenous variables\n# ==============================================================================\\nforecaster = ForecasterRecursive(\\n                 regressor        = Ridge(random_state=123),\\n                 lags             = 3,\\n                 transformer_y    = None,\\n                 transformer_exog = StandardScaler()\\n             )\\n\\nforecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2']])\\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Citing Skforecast Using BibTeX Format\nDESCRIPTION: Shows how to cite Skforecast in scientific publications using the BibTeX citation format. Includes all necessary fields for bibliography management systems.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@software{skforecast,\nauthor = {Amat Rodrigo, Joaquin and Escobar Ortiz, Javier},\ntitle = {skforecast},\nversion = {0.15.1},\nmonth = {3},\nyear = {2025},\nlicense = {BSD-3-Clause},\nurl = {https://skforecast.org/},\ndoi = {10.5281/zenodo.8382788}\n}\n```\n\n----------------------------------------\n\nTITLE: Plot Time Series Data\nDESCRIPTION: This code generates a plot of the time series data stored in the `series_dict` dictionary using matplotlib.  It iterates through the series, plotting each one on a separate subplot and adding a vertical line to indicate the end of the training data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"# Plot series\n# ==============================================================================\nset_dark_theme()\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\nfig, axs = plt.subplots(5, 1, figsize=(8, 4), sharex=True)\n\nfor i, s in enumerate(series_dict.values()):\n    axs[i].plot(s, label=s.name, color=colors[i])\n    axs[i].legend(loc='upper right', fontsize=8)\n    axs[i].tick_params(axis='both', labelsize=8)\n    axs[i].axvline(pd.to_datetime(end_train), color='white', linestyle='--', linewidth=1)  # End train\n\nfig.suptitle('Series in `series_dict`', fontsize=15)\nplt.tight_layout()\"\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preprocessing Time Series Dataset\nDESCRIPTION: Downloads example dataset and prepares training and testing data for forecasting, splitting the data into train and test sets\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-xgboost-lightgbm.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(\"h2o_exog\")\n```\n\nLANGUAGE: python\nCODE:\n```\n# Data preprocessing\n# ==============================================================================\ndata.index.name = 'date'\nsteps = 36\ndata_train = data.iloc[:-steps, :]\ndata_test  = data.iloc[-steps:, :]\n```\n\n----------------------------------------\n\nTITLE: Colorama Text Formatting Demo\nDESCRIPTION: Simple demonstration of using Colorama library to format console text output with different colors and styles.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_search_link_in_notebooks.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom colorama import Fore, Style\n\nprint(\"Esto es un texto normal\")\nprint(Fore.RED + \"Este texto es rojo\" + Style.RESET_ALL)\nprint(Fore.GREEN + \"Este texto es verde\" + Style.RESET_ALL)\nprint(Fore.BLUE + \"Este texto es azul\" + Style.RESET_ALL)\nprint(Style.BRIGHT + Fore.RED + \"Este texto es rojo en negrita\" + Style.RESET_ALL)\nprint(\"Esto es un texto normal\")\n```\n\n----------------------------------------\n\nTITLE: Function Call Example\nDESCRIPTION: Example of a function call pattern with the new n_jobs parameter for parallelization\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nfit(n_jobs='auto')\n```\n\n----------------------------------------\n\nTITLE: Running Specific Module Tests in Skforecast\nDESCRIPTION: Command to run tests for a specific module during development\nSOURCE: https://github.com/skforecast/skforecast/blob/master/CONTRIBUTING.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ pytest new_module/tests/test_module.py\n```\n\n----------------------------------------\n\nTITLE: System Information and Version Check\nDESCRIPTION: Prints version information for key libraries and system specifications including Python version, hardware details, and operating system information.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Versions\n# ==============================================================================\nprint(f\"Python version      : {platform.python_version()}\")\nprint(f\"scikit-learn version: {sklearn.__version__}\")\nprint(f\"skforecast version  : {skforecast.__version__}\")\nprint(f\"lightgbm version    : {lightgbm.__version__}\")\nprint(f\"pandas version      : {pd.__version__}\")\nprint(f\"numpy version       : {np.__version__}\")\nprint(\"\")\n\n# System information\n# ==============================================================================\nprint(f\"Machine type: {platform.machine()}\")\nprint(f\"Processor type: {platform.processor()}\")\nprint(f\"Platform type: {platform.platform()}\")\nprint(f\"Operating system: {platform.system()}\")\nprint(f\"Operating system release: {platform.release()}\")\nprint(f\"Operating system version: {platform.version()}\")\nprint(f\"Number of physical cores: {psutil.cpu_count(logical=False)}\")\nprint(f\"Number of logical cores: {psutil.cpu_count(logical=True)}\")\n```\n\n----------------------------------------\n\nTITLE: Accessing In-Sample Residuals\nDESCRIPTION: Demonstrates how to fit the forecaster with residuals storage and access the in-sample residuals.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nforecaster.fit(y=y, store_in_sample_residuals=True)\n\nprint(\"Length:\", len(forecaster.in_sample_residuals_))\nforecaster.in_sample_residuals_[:5]\n```\n\n----------------------------------------\n\nTITLE: Performance Results Visualization and Analysis\nDESCRIPTION: Creates a pivoted performance results table and generates a bar plot to visualize percentage improvement between parallel and sequential execution modes for different methods and regressors\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parallelization-skforecast.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nresults_pivot = results.pivot_table(\n    index=[\"regressor\", \"method\"],\n    columns=\"parallel\",\n    values=\"elapsed_time\"\n).reset_index()\nresults_pivot[\"pct_improvement\"] = (results_pivot[False] - results_pivot[True]) / results_pivot[False] * 100\n```\n\n----------------------------------------\n\nTITLE: Accessing Window Features\nDESCRIPTION: Shows how to access the configured window features used for additional time series characteristics.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/forecaster-attributes.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nforecaster.window_features\n```\n\n----------------------------------------\n\nTITLE: Configure OpenCL Vendor and Remove LightGBM Source\nDESCRIPTION: Configures the OpenCL vendor by creating a directory and specifying the NVIDIA OpenCL library path. Then, the LightGBM source directory is removed to free up space after installation. This step is crucial for ensuring that LightGBM can properly utilize the NVIDIA GPU via OpenCL. The removal of the source directory helps to clean up the environment after the installation is complete.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Reverting Predictions Using Forecaster Transformer\nDESCRIPTION: Uses the forecaster's built-in transformer to inverse transform predictions from their transformed state back to original scale. Reshapes predictions and extracts first 4 values.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_36\n\nLANGUAGE: python\nCODE:\n```\npredictions = forecaster.transformer_series_['co'].inverse_transform(\n    predictions_transformed.reshape(-1, 1)\n)\npredictions.ravel()[:4]\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Weights Function\nDESCRIPTION: This snippet defines a custom weights function, custom_weights, that assigns a weight of 0 to indices within a specified date range, used to influence model training.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Custom function to create weights\n# ============================================================================== \ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is between 2004-01-01 and 2005-01-01.\n    \"\"\"\n    weights = np.where(\n                  (index >= '2004-01-01') & (index <= '2005-01-01'),\n                   0,\n                   1\n              )\n\n    return weights\n```\n\n----------------------------------------\n\nTITLE: Describing Partitioned Data\nDESCRIPTION: This code prints a description of each series partition, including their lengths and start-end timestamps for both train and test datasets. This helps in understanding how the data was split.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/tests_integration/ForecasterAuoregMultiseries/test_series_have_different_length_different_exog.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\nfor k in series_dict.keys():\n    print(f\\\"{k}:\\\")\n    try:\n        print(\n            f\\\"\\tTrain: len={len(series_dict_train[k])}, {series_dict_train[k].index[0]}\\\"\n            f\\\" --- {series_dict_train[k].index[-1]}\\\"\n        )\n    except:\n        print(f\\\"\\tTrain: len=0\\\")\n    try:\n        print(\n            f\\\"\\tTest : len={len(series_dict_test[k])}, {series_dict_test[k].index[0]}\\\"\n            f\\\" --- {series_dict_test[k].index[-1]}\\\"\n        )\n    except:\n        print(f\\\"\\tTest : len=0\\\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Test Dependencies for Skforecast\nDESCRIPTION: Command to install test dependencies specified in pyproject.toml file\nSOURCE: https://github.com/skforecast/skforecast/blob/master/CONTRIBUTING.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -r skforecast[test]\n```\n\n----------------------------------------\n\nTITLE: Predicting with Dictionary Exogenous Variables\nDESCRIPTION: Shows how to fit the model and make predictions using DataFrame series and dictionary-format exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nforecaster.fit(\n    series = data_exog_train[['item_1', 'item_2', 'item_3']], \n    exog   = exog_train_as_dict\n)\n\nexog_pred_as_dict = {\n    'item_1': exog_1_item_1_test,\n    'item_2': exog_1_item_2_test,\n    'item_3': exog_1_item_3_test\n}\n\npredictions = forecaster.predict(steps=24, exog=exog_pred_as_dict)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Running Complete Test Suite in Skforecast\nDESCRIPTION: Command to run all unit tests from the project root directory with verbose output\nSOURCE: https://github.com/skforecast/skforecast/blob/master/CONTRIBUTING.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pytest -vv\n```\n\n----------------------------------------\n\nTITLE: Including Font Awesome Icons for Tutorial Links in HTML\nDESCRIPTION: HTML script tag to include Font Awesome icons library which is used throughout the page to style the tutorial links with relevant icons.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/examples/examples_spanish.md#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n```\n\n----------------------------------------\n\nTITLE: Custom Weight Function Implementation\nDESCRIPTION: Defines a custom function to assign weights to observations, giving zero weight to imputed values and values within 14 days after imputation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef custom_weights(index):\n    \"\"\"\n    Return 0 if index is in any gap.\n    \"\"\"\n    gaps = [\n        ['2020-09-01', '2020-10-10'],\n        ['2020-11-08', '2020-12-15'],\n    ]\n    \n    missing_dates = [pd.date_range(\n                        start = pd.to_datetime(gap[0]) + pd.Timedelta('14d'),\n                        end   = pd.to_datetime(gap[1]) + pd.Timedelta('14d'),\n                        freq  = 'D'\n                    ) for gap in gaps]\n    missing_dates = pd.DatetimeIndex(np.concatenate(missing_dates))   \n    weights = np.where(index.isin(missing_dates), 0, 1)\n\n    return weights\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Skforecast Time Series Forecasting in Python\nDESCRIPTION: Imports the necessary libraries for working with Skforecast, including pandas for data manipulation, LGBMRegressor as the regression model, and Skforecast's dataset fetching and forecasting components.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/input-data.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport pandas as pd\nfrom lightgbm import LGBMRegressor\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.recursive import ForecasterRecursive\n```\n\n----------------------------------------\n\nTITLE: Deprecation Notice Example\nDESCRIPTION: Example of renamed method reference showing the deprecation pattern used in the codebase\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nget_feature_importance() # Deprecated in 0.8.0\nget_feature_importances() # New method name\n```\n\n----------------------------------------\n\nTITLE: Creating a Forecaster with Time Series Differentiation\nDESCRIPTION: Demonstrates how to create a recursive forecaster that uses time series differentiation. This approach models the changes between consecutive observations rather than the absolute values, which can be beneficial for non-stationary time series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor       = LGBMRegressor(random_state=123, verbose=-1),\n                 lags            = 15,\n                 differentiation = 1\n             )\n\nforecaster.fit(y=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Default Style UserWarning Example\nDESCRIPTION: Shows UserWarning behavior with default warning style.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwarnings.warn(\"deprecated\", UserWarning)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting with skforecast\nDESCRIPTION: Imports necessary libraries including matplotlib for visualization, LGBMRegressor as the base model, and various skforecast modules for forecasting, preprocessing, model selection, and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/quick-start-skforecast.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================================================================\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom skforecast.datasets import load_demo_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\nfrom skforecast.model_selection import grid_search_forecaster\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Setting Default Warning Style with Warning Demo\nDESCRIPTION: Sets warning style to default and demonstrates both DataTransformationWarning and UserWarning.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nset_warnings_style(\"default\")\nwarnings.warn(\"deprecated\", DataTransformationWarning)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Time Series Predictions in Python\nDESCRIPTION: Creates a plot that compares the training data, test data, and model predictions. This visualization helps to assess the accuracy of the forecasting model and identify any patterns or trends that the model may have missed.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/autoregresive-forecaster.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Plot predictions\n# ==============================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata_train.plot(ax=ax, label='train')\ndata_test.plot(ax=ax, label='test')\npredictions.plot(ax=ax, label='predictions')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Inspect Train Matrices After Transformation in Python\nDESCRIPTION: This snippet checks whether the data transformations have been applied correctly by inspecting the first few rows of the resulting training matrices 'X_train' and 'y_train'.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n# Inspect training matrices\n# ==============================================================================\\nX_train, y_train = forecaster.create_train_X_y(\\n                       y    = data['y'],\\n                       exog = data[['exog_1', 'exog_2', 'exog_3']]\\n                   )\n```\n\n----------------------------------------\n\nTITLE: Preprocess Data for Skforecast Models in Python\nDESCRIPTION: This snippet preprocesses the dataset by setting the index name to 'date', adds a new categorical feature 'exog_3', and outputs the first few rows of the modified dataset for inspection.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Data preprocessing\n# ==============================================================================\\ndata.index.name = 'date'\\n# Add an extra categorical variable\\ndata['exog_3'] = ([\"A\"] * int(len(data) / 2)) + ([\"B\"] * (int(len(data) / 2) + 1))\\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Install LightGBM Python Package\nDESCRIPTION: Installs the LightGBM Python package from the built source code. This includes precompiling the Python bindings for improved performance. It navigates to the `python-package` directory within the LightGBM source and uses `setup.py` to install the package.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n!cd LightGBM/python-package/;python3 setup.py install --precompile\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Download Data Using Skforecast in Python\nDESCRIPTION: This snippet fetches a dataset named 'h2o_exog' from Skforecast's datasets module, which is intended for further data preprocessing and training in forecasting models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/sklearn-transformers-and-pipeline.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Download data\n# ==============================================================================\\ndata = fetch_dataset(\"h2o_exog\")\n```\n\n----------------------------------------\n\nTITLE: Clone LightGBM Repository\nDESCRIPTION: Clones the LightGBM repository from GitHub, including all submodules, allowing for installation from source. This provides more control over build options and GPU support.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n!git clone --recursive https://github.com/Microsoft/LightGBM\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Time Series Dataset for Feature Selection Example\nDESCRIPTION: Fetches the bike sharing dataset with extended features from Skforecast's dataset collection. This dataset will be used to demonstrate the feature selection techniques.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(name=\"bike_sharing_extended_features\")\ndata.head(3)\n```\n\n----------------------------------------\n\nTITLE: Installing Skforecast with Core Dependencies\nDESCRIPTION: Command to install the basic version of skforecast with core dependencies using pip. Additional installation options can be found in the complete installation guide.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast\n```\n\n----------------------------------------\n\nTITLE: Extracting Training Matrix y in Python\nDESCRIPTION: This code snippet retrieves the target training matrix y, allowing inspection of the format and content of the target variable used for model fitting.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ny_train_step_1.head(4)\n```\n\n----------------------------------------\n\nTITLE: Creating Profile Cards with HTML for Team Members\nDESCRIPTION: HTML markup for displaying team member profiles with avatars, names, email addresses, and LinkedIn links in a card format. The structure uses nested div elements with CSS classes for styling the profile container and individual profile cards.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/more/consulting.md#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"profile-container\">\n\n  <div class=\"profile-card\">\n    <div class=\"profile-avatar\">\n      <img src=\"https://github.com/JoaquinAmatRodrigo.png\" alt=\"Joaqun Amat Rodrigo\">\n    </div>\n    <div class=\"profile-info\">\n      <strong>Joaqun Amat Rodrigo</strong>\n      <div class=\"email-info\">j.amatrodrigo@gmail.com</div>\n      <a href=\"https://www.linkedin.com/in/joaquin-amat-rodrigo\" class=\"linkedin-link\" target=\"_blank\" rel=\"noopener noreferrer\">LinkedIn</a>\n    </div>\n  </div>\n\n  <div class=\"profile-card\">\n    <div class=\"profile-avatar\">\n      <img src=\"https://github.com/JavierEscobarOrtiz.png\" alt=\"Javier Escobar Ortiz\">\n    </div>\n    <div class=\"profile-info\">\n      <strong>Javier Escobar Ortiz</strong>\n      <div class=\"email-info\">javier.escobar.ortiz@gmail.com</div>\n      <a href=\"https://www.linkedin.com/in/javier-escobar-ortiz\" class=\"linkedin-link\" target=\"_blank\" rel=\"noopener noreferrer\">LinkedIn</a>\n    </div>\n  </div>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Import Libraries for LightGBM\nDESCRIPTION: Imports necessary libraries for working with LightGBM, including numpy, pandas, LightGBM, and skforecast for recursive forecasting. This snippet sets up the environment for subsequent operations using these libraries.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport time\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Inspecting Trained Transformers\nDESCRIPTION: Demonstrates how to inspect the parameters of trained transformers for each series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfor k, v in forecaster.transformer_series_.items():\n    if v is not None:\n        print(f\"Series {k}: {v.get_params()}\")\n    else:\n        print(f\"Series {k}: {v}\")\n```\n\n----------------------------------------\n\nTITLE: Downloading Dataset\nDESCRIPTION: Fetching the h2o dataset using skforecast's fetch_dataset function with specific column naming parameters.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data\n# ==============================================================================\ndata = fetch_dataset(\n    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"date\"], \"header\": 0}\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Data with Missing Values\nDESCRIPTION: Creates a small sample dataset with missing values to demonstrate how predictions are handled. The data includes two time series with some missing values in one series.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Create sample data\ndates = pd.date_range(start='2020-01-01', periods=10, freq='D')\nseries = pd.DataFrame({\n    'level_1': np.random.rand(10),\n    'level_2': np.random.rand(10)\n}, index=dates)\n\nbacktest_predictions = series.copy()\nbacktest_predictions = backtest_predictions.melt(ignore_index=False, value_name='pred', var_name='level')\nbacktest_predictions = (\n        backtest_predictions\n        .rename_axis('idx', axis=0)\n        .set_index('level', append=True)\n    )\nseries.loc['2020-01-05':'2020-01-09', 'level_1'] = np.nan\ndisplay(series)\ndisplay(backtest_predictions)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating DataFrame Grouping Operations\nDESCRIPTION: Shows basic pandas DataFrame groupby operations, creating a sample DataFrame with categorical and numeric data and extracting a specific group using get_group method.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/profiling_backtesting.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndata = {\n    'Category': ['A', 'B', 'A', 'B', 'A', 'C', 'C'],\n    'Value': [10, 20, 30, 40, 50, 60, 70]\n}\n\ndf = pd.DataFrame(data)\n\n# Group by 'Category'\ngrouped = df.groupby('Category', as_index=False)['Value']\ngrouped.get_group('A')\n```\n\n----------------------------------------\n\nTITLE: Residuals Usage Warning Class in Skforecast\nDESCRIPTION: A custom warning class for improper usage of residuals in skforecast models.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.ResidualsUsageWarning\n```\n\n----------------------------------------\n\nTITLE: Skforecast Version Warning Class\nDESCRIPTION: A custom warning class for version compatibility issues in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.SkforecastVersionWarning\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Forecasting\nDESCRIPTION: Imports necessary libraries including skforecast, pandas, numpy, sklearn, lightgbm and various skforecast modules. Also loads profiling extensions pyinstrument and line_profiler for performance analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/long_format_multiseries.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport platform\nimport psutil\nimport skforecast\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\nfrom skforecast.model_selection import grid_search_forecaster_multiseries\nfrom skforecast.utils.utils import align_series_and_exog_multiseries\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\nfrom skforecast.preprocessing import series_long_to_dict\nfrom skforecast.preprocessing import exog_long_to_dict\nfrom skforecast.datasets import fetch_dataset\n\n%load_ext pyinstrument\n%load_ext line_profiler\n```\n\n----------------------------------------\n\nTITLE: Method Declaration Example\nDESCRIPTION: Example of new method signature with store_in_sample_residuals parameter\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nfit(store_in_sample_residuals=True)\n```\n\n----------------------------------------\n\nTITLE: Using the RollingFeatures Class with New ewm Statistic\nDESCRIPTION: Reference to the RollingFeatures class that now supports exponential weighted mean (ewm) statistic, with configurable alpha parameter.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n[RollingFeatures]\n```\n\n----------------------------------------\n\nTITLE: Triggering Standard UserWarning\nDESCRIPTION: Shows how to raise a standard Python UserWarning for comparison.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwarnings.warn(\"deprecated\", UserWarning)\n```\n\n----------------------------------------\n\nTITLE: Importing Skforecast Warning Components\nDESCRIPTION: Imports custom warning classes and warning style configuration from skforecast.exceptions module.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.exceptions import DataTransformationWarning, set_warnings_style\nimport warnings\n```\n\n----------------------------------------\n\nTITLE: Long Training Warning Class in Skforecast\nDESCRIPTION: A custom warning class for excessively long training operations in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.LongTrainingWarning\n```\n\n----------------------------------------\n\nTITLE: DataType Warning Class in Skforecast\nDESCRIPTION: A custom warning class for data type related issues in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.DataTypeWarning\n```\n\n----------------------------------------\n\nTITLE: Grid Search with Multiple Metrics for Multi-Series Forecasting\nDESCRIPTION: Implements grid search with multiple evaluation metrics including a custom metric for last quarter performance, supporting different aggregation methods.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 24,\n                 encoding  = 'ordinal'\n             )\n\n\ndef custom_metric(y_true, y_pred):\n    \"\"\"\n    Calculate the mean absolute error using only the predicted values of the last\n    3 months of the year.\n    \"\"\"\n    mask = y_true.index.month.isin([10, 11, 12])\n    metric = mean_absolute_error(y_true[mask], y_pred[mask])\n    \n    return metric\n\n\nlags_grid = [24, 48]\nparam_grid = {\n    'n_estimators': [10, 20],\n    'max_depth': [3, 7]\n}\n\ncv = TimeSeriesFold(\n         steps              = 24,\n         initial_train_size = len(data_train),\n         refit              = True,\n     )\n\nresults = grid_search_forecaster_multiseries(\n              forecaster         = forecaster,\n              series             = data,\n              exog               = None,\n              lags_grid          = lags_grid,\n              param_grid         = param_grid,\n              cv                 = cv,\n              levels             = None,\n              metric             = [mean_absolute_error, custom_metric, 'mean_squared_error'],\n              aggregate_metric   = ['weighted_average', 'average', 'pooling']\n          )\n\nresults\n```\n\n----------------------------------------\n\nTITLE: Creating Train-Validation-Test Split for Time Series Data in Python\nDESCRIPTION: This code snippet demonstrates how to split time series data into train, validation, and test sets using date ranges, and then visualizes these splits with matplotlib. It prints the date ranges and sizes of each partition.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# Train-validation-test data\n# ======================================================================================\nend_train = '2001-01-01 23:59:00'\nend_val = '2006-01-01 23:59:00'\n\nprint(f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}  (n={len(data.loc[:end_train])})\") \nprint(f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}  (n={len(data.loc[end_train:end_val])})\") \nprint(f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}  (n={len(data.loc[end_val:])})\") \n\n# Plot\n# ======================================================================================\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.loc[:end_train, 'y'].plot(ax=ax, label='train')\ndata.loc[end_train:end_val, 'y'].plot(ax=ax, label='validation')\ndata.loc[end_val:, 'y'].plot(ax=ax, label='test')\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Initializing ForecasterRecursiveMultiSeries with Standard Scaler Transformation\nDESCRIPTION: Demonstrates how to create a forecaster with the same transformation (StandardScaler) applied to all series. Uses LGBMRegressor with rolling features and ordinal encoding.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n                 encoding           = 'ordinal',\n                 transformer_series = StandardScaler(),\n                 transformer_exog   = None\n             )\n\nforecaster.fit(series=data_train)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Using Gamma Regression for Positive Predictions\nDESCRIPTION: Demonstrates an alternative approach using GammaRegressor with a different link function to prevent negative predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/non-negative-predictions.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursive(\n    regressor = GammaRegressor(alpha=1, max_iter=100000),\n    lags      = 20,\n)\n```\n\n----------------------------------------\n\nTITLE: Backtesting with Internal Differentiation\nDESCRIPTION: Performs backtesting using internal differentiation within the forecaster, with differentiation specified in the cv object.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/time-series-differentiation.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nforecaster_2 = ForecasterRecursive(\n                   regressor       = RandomForestRegressor(random_state=963),\n                   lags            = 15,\n                   differentiation = 1\n               )\n\ncv = TimeSeriesFold(\n         steps                 = steps,\n         initial_train_size    = len(data.loc[:end_train]),\n         refit                 = True,\n         fixed_train_size      = False, \n         allow_incomplete_fold = True,\n         differentiation       = 1\n     )\n\n_, predictions_2 = backtesting_forecaster(\n                       forecaster    = forecaster_2,\n                       y             = data,\n                       cv            = cv,\n                       metric        = 'mean_squared_error',\n                       n_jobs        = 'auto',\n                       verbose       = False,\n                       show_progress = True\n                   )\n```\n\n----------------------------------------\n\nTITLE: Calculating CRPS Score from Quantiles - Python\nDESCRIPTION: This snippet implements the calculation of the Continuous Ranked Probability Score (CRPS) from provided quantiles and a true value. It constructs the empirical CDF from quantiles and computes the CRPS as the squared difference between the two distributions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/probabilistic-forecasting-crps-score.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# CRPS score from quantiles\n# ============================================================================== \ny_true = 3.0\n\nquantile_levels = np.array([\n    0.00, 0.025, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55,\n    0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.975, 1.00\n])\npred_quantiles = np.array([\n    0.1, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5,\n    8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5\n])\n\ncrps_from_quantiles(y_true, pred_quantiles, quantile_levels)\n```\n\n----------------------------------------\n\nTITLE: Calculating Prediction Intervals Using Conformal Method\nDESCRIPTION: This code snippet shows how to calculate prediction intervals with the ForecasterRecursive using out-sample residuals. It utilizes conformal prediction methods with specified interval settings.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Prediction intervals\n# ==============================================================================\nforecaster.predict_interval(\n    steps                   = 24,\n    exog                    = data.loc[end_calibration:, exog_features],\n    interval                = [10, 90],\n    method                  = 'conformal',\n    use_in_sample_residuals = False,\n    use_binned_residuals    = True\n)\n```\n\n----------------------------------------\n\nTITLE: Grid Search with Multiple Metrics\nDESCRIPTION: Shows how to perform grid search with multiple evaluation metrics including a custom metric. Configures cross-validation and parameter grid for optimization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirectMultiVariate(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 level     = 'co',\n                 lags      = 7,\n                 steps     = 7\n             )    \n\ndef custom_metric(y_true, y_pred):\n    \"\"\"\n    Calculate the mean absolute error using only the predicted values of the last\n    3 months of the year.\n    \"\"\"\n    mask = y_true.index.month.isin([10, 11, 12])\n    metric = mean_absolute_error(y_true[mask], y_pred[mask])\n    \n    return metric\n\ncv = TimeSeriesFold(\n         steps              = 7,\n         initial_train_size = len(data_train),\n         refit              = False,\n     )\n\nlags_grid = [7, 14]\nparam_grid = {'alpha': [0.01, 0.1, 1]}\n\nresults = grid_search_forecaster_multiseries(\n              forecaster       = forecaster,\n              series           = data,\n              lags_grid        = lags_grid,\n              param_grid       = param_grid,\n              cv               = cv,\n              metric           = [mean_absolute_error, custom_metric, 'mean_squared_error'],\n              aggregate_metric = 'weighted_average',\n          )\n\nresults\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Data Handling and Modeling in Python\nDESCRIPTION: This snippet imports essential libraries including Pandas for data manipulation, Matplotlib for plotting, and several modules from scikit-learn and skforecast for performing regression and forecasting tasks. These libraries are necessary for data handling, model training, and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Libraries\n# ==============================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom skforecast.datasets import fetch_dataset\nfrom skforecast.preprocessing import RollingFeatures\nfrom skforecast.direct import ForecasterDirect\nfrom skforecast.plot import set_dark_theme\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a Forecaster\nDESCRIPTION: This snippet demonstrates how to create and train a ForecasterRecursive using a RandomForestRegressor. The forecaster is then trained on the dataset with a specified number of lags.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/save-load-forecaster.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create and train forecaster\n# ============================================================================== \nforecaster = ForecasterRecursive(\n                 regressor     = RandomForestRegressor(random_state=123),\n                 lags          = 5,\n                 forecaster_id = \"forecaster_001\"\n             )\n\nforecaster.fit(y=data['y'])\nforecaster.predict(steps=3)\n```\n\n----------------------------------------\n\nTITLE: Initializing Python Environment and Dependencies\nDESCRIPTION: Sets up the Python environment with autoreload, configures system path, and imports essential libraries like numpy and pandas.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/set_warnings_style.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\nimport sys\nfrom pathlib import Path\npath = str(Path.cwd().parent)\nprint(path)\nsys.path.insert(1, path)\n\nimport numpy as np\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Training and Forecasting with Non-Datetime Indexed Data in Skforecast\nDESCRIPTION: Fits the ForecasterRecursive model on data without a datetime index and generates predictions for 5 steps ahead, showing Skforecast's ability to work with regular integer-indexed data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/input-data.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Fit - Predict\n# ==============================================================================\nforecaster.fit(y=data['y'])\nforecaster.predict(steps=5)\n```\n\n----------------------------------------\n\nTITLE: Creating and Fitting ForecasterDirect with Transformation and Differentiation\nDESCRIPTION: This code demonstrates how to initialize a ForecasterDirect model with window features, a Ridge regressor, transformations, and differentiation. The model is then fitted to a time series dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit ForecasterDirect\n# ==============================================================================\nwindow_features = RollingFeatures(\n                      stats        = ['mean', 'sum'],\n                      window_sizes = [5, 5]\n                  )\n\nforecaster = ForecasterDirect(\n                 regressor       = Ridge(random_state=123),\n                 steps           = 3,\n                 lags            = 5,\n                 window_features = window_features,\n                 transformer_y   = StandardScaler(),\n                 differentiation = 1\n             )\n\nforecaster.fit(y=data['y'])\n```\n\n----------------------------------------\n\nTITLE: Feature Selection (Autoregressive and Exog) with RFECV in Python\nDESCRIPTION: This code snippet demonstrates feature selection using Recursive Feature Elimination with Cross-Validation (RFECV) from scikit-learn, combined with a LightGBM regressor. It selects the best subset of both autoregressive and exogenous features for a time series forecasting model. The `select_features` function is used to perform the selection based on the provided forecaster, selector, target variable (`y`), and exogenous variables (`exog`).\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"# Feature selection (autoregressive and exog) with scikit-learn RFECV\n# ==============================================================================\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = RFECV(\n    estimator=regressor, step=1, cv=3, min_features_to_select=25, n_jobs=-1\n)\n\nselected_lags, selected_window_features, selected_exog = select_features(\n    forecaster      = forecaster,\n    selector        = selector,\n    y               = data[\"users\"],\n    exog            = data.drop(columns=\"users\"),\n    select_only     = None,\n    force_inclusion = None,\n    subsample       = 0.5,\n    random_state    = 123,\n    verbose         = True,\n)\"\n```\n\n----------------------------------------\n\nTITLE: Plotting Prediction Intervals for Time Series Forecasts in Python\nDESCRIPTION: Visualizes the prediction intervals generated from the forecasting model using the plot_prediction_intervals function. The function displays both the actual values and the predicted intervals with customizable styling options.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/probabilistic-forecasting-conformal-prediction.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Plot intervals\n# ==============================================================================\nplot_prediction_intervals(\n    predictions         = predictions,\n    y_true              = data_test,\n    target_variable     = \"OT\",\n    title               = \"Predicted intervals\",\n    kwargs_fill_between = {'color': 'gray', 'alpha': 0.4, 'zorder': 1}\n)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with Differentiated Multi-Series Model\nDESCRIPTION: Shows how to generate predictions using a fitted forecaster with differentiation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_34\n\nLANGUAGE: python\nCODE:\n```\npredictions = forecaster.predict(steps=24)\npredictions.head(3)\n```\n\n----------------------------------------\n\nTITLE: Implementing No Encoding\nDESCRIPTION: Sets up ForecasterRecursiveMultiSeries without encoding using LGBMRegressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = None\n             )\n\nX, y = forecaster.create_train_X_y(series=data_train)\n\ndisplay(X.head(3))\nprint(\"\")\nprint(X.dtypes)\n```\n\n----------------------------------------\n\nTITLE: Performing Feature Selection with RFECV in Multi-Series Context\nDESCRIPTION: Applies Recursive Feature Elimination with Cross-Validation (RFECV) to select the most relevant features for the multi-series forecaster. The selection includes both autoregressive features and exogenous variables, with options to subsample the data for efficiency.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# Feature selection (autoregressive and exog) with scikit-learn RFECV\n# ==============================================================================\nseries_columns = [\"item_1\", \"item_2\", \"item_3\"]\nexog_columns = [col for col in data.columns if col not in series_columns]\nregressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n\nselector = RFECV(\n    estimator=regressor, step=1, cv=3, min_features_to_select=25, n_jobs=-1\n)\n\nselected_lags, selected_window_features, selected_exog = select_features_multiseries(\n    forecaster      = forecaster,\n    selector        = selector,\n    series          = data[series_columns],\n    exog            = data[exog_columns],\n    select_only     = None,\n    force_inclusion = None,\n    subsample       = 0.5,\n    random_state    = 123,\n    verbose         = True,\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting Training Matrix X in Python\nDESCRIPTION: This snippet demonstrates how to extract the training data matrices (X and y) used by the forecaster when fitting the model, which helps in understanding the model's training process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nX_train, y_train = forecaster.create_train_X_y(series=data_train)\n\nX_train_step_1, y_train_step_1 = forecaster.filter_train_X_y_for_step(\n                                     step    = 1,\n                                     X_train = X_train,\n                                     y_train = y_train,\n                                 )\n\nX_train_step_1.head(4)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Forecaster Model\nDESCRIPTION: Examples of saving trained forecaster model to disk and loading it back for future use.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecaster-in-production.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Save Forecaster\n# ==============================================================================\nsave_forecaster(forecaster, file_name='forecaster_001.joblib', verbose=False)\n\n# Load Forecaster\n# ==============================================================================\nforecaster_loaded = load_forecaster('forecaster_001.joblib', verbose=True)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Refit Strategy Impact on Performance\nDESCRIPTION: Creates a dual-axis plot to visualize how different refit strategies affect both execution time and forecast accuracy. The primary y-axis shows execution time in seconds, while the secondary y-axis shows the forecast error metric.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/dev/01_backtesting_execution_time.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfig, ax = plt.subplots(figsize=(7, 4))\nax.plot(results['refit_value'].astype(str).to_numpy(), results['seconds'], marker='.')\nax2 =ax.twinx()\nsns.pointplot(x=results['refit_value'].astype(str).to_numpy(), y=results['metric'], \n              join=False, ax=ax2)\n# ax2.plot(results['refit_value'].astype(str).to_numpy(), results['metric'], marker='.')\n\nax.set_xlabel('length of series')\nax.set_ylabel('time (seconds)')\nax.set_title('Profiling create_train_X_y()')\nax.legend(title='number of lags');\n```\n\n----------------------------------------\n\nTITLE: Referencing ForecasterDirectMultiVariate for Sales Data\nDESCRIPTION: A commented reference to the ForecasterDirectMultiVariate model for sales data forecasting. This appears to be a placeholder or a comment indicating another type of model that could be used for the sales dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# Dataset sales - ForecasterDirectMultiVariate\n```\n\n----------------------------------------\n\nTITLE: Applying Transformations to Dataset\nDESCRIPTION: The transformed dataset is produced by applying the previously defined transformations using fit_transform, which integrates lagged and window features into the original dataset, making it ready for backtesting using exogenous variables.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\ndata = exog_transformer.fit_transform(data)\ndata.head(5)\n```\n\n----------------------------------------\n\nTITLE: Splitting Time Series Data for Training, Validation, and Testing\nDESCRIPTION: Splits the dataset into training, validation, and test sets based on specified dates for evaluating model performance while preventing data leakage and ensuring reliable validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/stacking-ensemble-models-forecasting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Split train-validation-test\n# ==============================================================================\nend_train = '2007-12-01 23:59:00'\nend_validation = '2012-12-01 23:59:00'\ndata_train = data.loc[: end_train, :]\ndata_val   = data.loc[end_train:end_validation, :]\ndata_test  = data.loc[end_validation:, :]\n\nprint(f\"Dates train      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\nprint(f\"Dates validation : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\nprint(f\"Dates test       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Time Series Forecasting\nDESCRIPTION: Imports necessary Python libraries including pandas, numpy, matplotlib, and skforecast components for time series analysis and visualization.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/forecasting-time-series-with-missing-values.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skforecast.plot import set_dark_theme\nfrom skforecast.datasets import fetch_dataset\nfrom lightgbm import LGBMRegressor\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.model_selection import TimeSeriesFold\nfrom skforecast.model_selection import backtesting_forecaster\n```\n\n----------------------------------------\n\nTITLE: Importing and Using ForecasterDirectMultiVariate Class in Python\nDESCRIPTION: Reference documentation for the ForecasterDirectMultiVariate class from the skforecast.direct._forecaster_direct_multivariate module. This class implements direct forecasting methods for multivariate time series prediction.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/ForecasterDirectMultiVariate.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.direct._forecaster_direct_multivariate import ForecasterDirectMultiVariate\n```\n\n----------------------------------------\n\nTITLE: Performing Backtesting with ForecasterRecursiveMultiSeries\nDESCRIPTION: This snippet shows how to perform backtesting using ForecasterRecursiveMultiSeries. It includes setting up the forecaster, defining the cross-validation strategy, and executing the backtesting process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = regressor, \n                 lags               = 14, \n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[7, 14]),\n                 encoding           = \"ordinal\", \n                 dropna_from_series = False\n             )\n\ncv = TimeSeriesFold(\n         steps              = 24,\n         initial_train_size = len(series_dict_train[\"id_1000\"])\n     )\n\nmetrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n    forecaster            = forecaster,\n    series                = series_dict,\n    exog                  = exog_dict,\n    cv                    = cv,\n    levels                = None,\n    metric                = \"mean_absolute_error\",\n    add_aggregated_metric = True,\n    suppress_warnings     = True\n)\n\ndisplay(metrics_levels)\nbacktest_predictions\n```\n\n----------------------------------------\n\nTITLE: Importing Forecasters for skforecast  0.14\nDESCRIPTION: This code snippet shows the updated imports for `ForecasterRecursive` and `ForecasterRecursiveMultiSeries` in Skforecast version 0.14 and later, replacing earlier classes to reflect the new library structure.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.recursive import ForecasterRecursive\nfrom skforecast.recursive import ForecasterRecursiveMultiSeries\n```\n\n----------------------------------------\n\nTITLE: Loading Preprocessed Dataset\nDESCRIPTION: Fetches the bike_sharing dataset with default preprocessing applied, returning a pandas DataFrame with datetime index and defined frequency.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/datasets.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Download data \n# ==============================================================================\ndata = fetch_dataset(name=\"bike_sharing\")\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Implementing ConformalIntervalCalibrator Class\nDESCRIPTION: Reference to the new ConformalIntervalCalibrator class used for conformal calibration of prediction intervals using the conformal prediction framework.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/releases/releases.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[ConformalIntervalCalibrator]\n```\n\n----------------------------------------\n\nTITLE: Predicting a Subset of Forecast Steps\nDESCRIPTION: Incomplete code snippet showing the comment for predicting only a subset of the forecast steps instead of all steps. This would allow focusing on specific time horizons of interest.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/dependent-multi-series-multivariate-forecasting.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Predict only a subset of steps\n```\n\n----------------------------------------\n\nTITLE: Initializing MultiVariate Direct Forecaster with Grid Search\nDESCRIPTION: Sets up a ForecasterDirectMultiVariate model with LGBMRegressor and performs grid search optimization across different lag values and model parameters. Includes benchmark execution with backtesting and one-step-ahead validation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/faq/parameters-search-backtesting-vs-one-step-ahead.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterDirectMultiVariate(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 steps              = 5,\n                 level              = 'item_1',\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nlags_grid = {\n    '24 lags': 24,\n    '48 lags': 48\n}\n\nparam_grid = {\n    'n_estimators': [50, 200],\n    'max_depth': [3, 7]\n}\n\ntime_1, time_2, metric_1, metric_2 = run_benchmark_multiseries(\n    data                    = data_sales,\n    forecaster_to_benchmark = forecaster,\n    search_method           = 'grid_search',\n    lags_grid               = lags_grid,\n    param_grid              = param_grid,\n    end_train               = end_train,\n    end_validation          = end_validation,\n    levels                  = levels,\n    exog_features           = exog_features,\n    steps                   = 5,\n    metric                  = metric\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Version of skforecast\nDESCRIPTION: Installs a specific version (0.15.1) of the skforecast package. This is useful when you need compatibility with other libraries or want to use a stable, known version.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/quick-start/how-to-install.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install skforecast==0.15.1\n```\n\n----------------------------------------\n\nTITLE: Transform Data to Dictionary Format for skforecast\nDESCRIPTION: This code transforms the loaded time series and exogenous variables from a \"long format\" DataFrame into dictionaries suitable for use with `ForecasterRecursiveMultiSeries`. The `series_long_to_dict` and `exog_long_to_dict` functions are used to convert the DataFrames, specifying the column names for series IDs, timestamps, and values, as well as the frequency.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/multi-series-with-different-length-and-different_exog.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"# Transform series and exog to dictionaries\n# ==============================================================================\nseries_dict = series_long_to_dict(\n    data      = series,\n    series_id = 'series_id',\n    index     = 'timestamp',\n    values    = 'value',\n    freq      = 'D'\n)\n\nexog_dict = exog_long_to_dict(\n    data      = exog,\n    series_id = 'series_id',\n    index     = 'timestamp',\n    freq      = 'D'\n)\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Training a ForecasterRecursiveMultiSeries Model in Python\nDESCRIPTION: Instantiates and trains a ForecasterRecursiveMultiSeries model using LGBMRegressor as the base regressor, with 24 lags and rolling features for time series forecasting across multiple series simultaneously.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create and train ForecasterRecursiveMultiSeries\n# ==============================================================================\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n                 lags               = 24,\n                 window_features    = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 48]),\n                 encoding           = 'ordinal',\n                 transformer_series = None,\n                 transformer_exog   = None,\n                 weight_func        = None,\n                 series_weights     = None,\n                 differentiation    = None,\n                 dropna_from_series = False,\n                 fit_kwargs         = None,\n                 forecaster_id      = None\n             )\n\nforecaster.fit(series=data_train, store_in_sample_residuals=True)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: One Step Ahead Validation Warning Class in Skforecast\nDESCRIPTION: A custom warning class for issues in one-step-ahead validation processes in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.OneStepAheadValidationWarning\n```\n\n----------------------------------------\n\nTITLE: Examining Predictors Matrix in Multi-Series Forecasting\nDESCRIPTION: This snippet shows how to examine the first few rows of the predictors matrix (X_train) created for multi-series forecasting. It displays the feature columns including lags, rolling features, and the series encoding column.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Predictors matrix\n# ==============================================================================\nX_train.head(3)\n```\n\n----------------------------------------\n\nTITLE: Downloading Time Series Dataset in Python\nDESCRIPTION: This code fetches a bike sharing dataset using a custom function and selects relevant columns for analysis.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/calendar-features.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading data\n# ==============================================================================\ndata = fetch_dataset(name=\"bike_sharing\", raw=True)\ndata = data[['date_time', 'users']]\ndata.head()\n```\n\n----------------------------------------\n\nTITLE: Making Predictions for a Specific Series in Multi-Series Forecasting\nDESCRIPTION: This snippet demonstrates how to make predictions for a specific series ('item_1') using the internal regressor of a multi-series forecaster. It shows the process of applying the model to a single series in isolation.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/training-and-prediction-matrices.ipynb#2025-04-21_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n# Predict 'item_1' using the internal regressor\n# ==============================================================================\npredictions_item_1 = forecaster.regressor.predict(X_predict_item_1)\npredictions_item_1\n```\n\n----------------------------------------\n\nTITLE: Checking Autoregressive Feature Selection in Python\nDESCRIPTION: This code snippet checks that all autoregressive features are selected when using `select_only = 'exog'` during feature selection. It verifies that the number of selected lags and window features matches the total number of lags and window features in the forecaster.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n\"# Check all autoregressive features are selected\n# ==============================================================================\nprint(\"Same lags :\", len(selected_lags) == len(forecaster.lags))\nprint(\"Same window features :\", len(selected_window_features) == len(forecaster.window_features))\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Bayesian Search with One-Step Ahead Validation - Python\nDESCRIPTION: This snippet demonstrates how to perform Bayesian search using a OneStepAheadFold for cross-validation, which speeds up the validation process by considering only one-step-ahead predictions. The search space for hyperparameters is defined similarly to the previous example.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/hyperparameter-tuning-and-lags-selection.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Bayesian search with OneStepAheadFold\\n# ==============================================================================\\nforecaster = ForecasterRecursive(\\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\\n                 lags      = 10  # Placeholder, the value will be overwritten\\n             )\\n\\n# Search space\\ndef search_space(trial):\\n    search_space  = {\\n        'lags'            : trial.suggest_categorical('lags', [3, 5]),\\n        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\\n        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\\n    }\\n    \\n    return search_space\\n\\n# Folds\\ncv = OneStepAheadFold(initial_train_size = len(data.loc[:end_train]))\\n\\nresults, best_trial = bayesian_search_forecaster(\\n                          forecaster            = forecaster,\\n                          y                     = data.loc[:end_val, 'y'],\\n                          search_space          = search_space,\\n                          cv                    = cv,\\n                          metric                = 'mean_absolute_error',\\n                          n_trials              = 10,\\n                          random_state          = 123,\\n                          return_best           = False,\\n                          n_jobs                = 'auto',\\n                          verbose               = False,\\n                          show_progress         = True,\\n                          kwargs_create_study   = {},\\n                          kwargs_study_optimize = {}\\n                      )\\nresults.head(4)\n```\n\n----------------------------------------\n\nTITLE: Preparing Train-Test Split for Time Series Data in Python\nDESCRIPTION: This snippet splits the time series data into training and testing sets based on a specified end date for the training set. It also prints information about the date ranges and number of samples in each set.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Train-test dates\n# ==============================================================================\nend_train = '2005-06-01 23:59:59'\nprint(\n    f\"Train dates : {data.index.min()} --- {data.loc[:end_train].index.max()}  \"\n    f\"(n={len(data.loc[:end_train])})\"\n)\nprint(\n    f\"Test dates  : {data.loc[end_train:].index.min()} --- {data.loc[:].index.max()}  \"\n    f\"(n={len(data.loc[end_train:])})\"\n)\ndata_train = data.loc[:end_train]\ndata_test  = data.loc[end_train:]\n\n# Plot\n# ==============================================================================\nset_dark_theme()\nfig, ax = plt.subplots(figsize=(7, 3))\ndata.plot(ax=ax)\nax.legend();\n```\n\n----------------------------------------\n\nTITLE: Configuring Warning Style in Skforecast\nDESCRIPTION: The set_warnings_style function used to configure how warnings are displayed in skforecast.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/api/exceptions.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nskforecast.exceptions.exceptions.set_warnings_style\n```\n\n----------------------------------------\n\nTITLE: Training Forecaster with Selected Features\nDESCRIPTION: Updates the forecaster with the selected lags and window features, then trains it using the filtered set of features. This demonstrates how to apply the results of feature selection to create a more efficient model.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/feature-selection.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Train forecaster with selected features\n# ==============================================================================\nnew_window_features = RollingFeatures(stats=['mean', 'mean'], window_sizes=[24, 72])\nforecaster.set_lags(lags=selected_lags)\nforecaster.set_window_features(window_features=new_window_features)\n\nforecaster.fit(series=data[series_columns], exog=data[selected_exog])\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Forecasting with statsmodels ARIMA Model in Python\nDESCRIPTION: This snippet shows how to make predictions using the fitted ARIMA model from statsmodels. It forecasts 12 steps ahead and displays the first 4 predictions.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Prediction\n# ==============================================================================\npredictions = arima_res.get_forecast(steps=12)\npredictions.predicted_mean.head(4)\n```\n\n----------------------------------------\n\nTITLE: Training a Recursive Forecaster with Exogenous Variables in Python\nDESCRIPTION: Creates and fits a ForecasterRecursive model using LGBMRegressor as the base algorithm, with 15 lag features and two exogenous variables ('exog_1' and 'exog_2') from the training dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/exogenous-variables.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit forecaster\n# ==============================================================================\nforecaster = ForecasterRecursive(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 15\n             )\nforecaster.fit(\n    y    = data_train['y'],\n    exog = data_train[['exog_1', 'exog_2']]\n)\nforecaster\n```\n\n----------------------------------------\n\nTITLE: Implementing Ordinal Encoding\nDESCRIPTION: Sets up ForecasterRecursiveMultiSeries with ordinal encoding using LGBMRegressor.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/independent-multi-time-series-forecasting.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nforecaster = ForecasterRecursiveMultiSeries(\n                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n                 lags      = 3,\n                 encoding  = 'ordinal'\n             )\n\nX, y = forecaster.create_train_X_y(series=data_train)\n\ndisplay(X.head(3))\nprint(\"\")\nprint(X.dtypes)\nprint(\"\")\nprint(X['_level_skforecast'].value_counts())\n```\n\n----------------------------------------\n\nTITLE: Backtesting Forecaster in skforecast  0.14\nDESCRIPTION: This snippet shows the new procedure for performing backtesting using an instance of `TimeSeriesFold`. It allows reusing the same folds across multiple methods, simplifying the process.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/migration-guide.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom skforecast.model_selection import (\n    TimeSeriesFold,\n    backtesting_forecaster\n)\n\ncv = TimeSeriesFold(\n    steps                 = 10,\n    initial_train_size    = 100,\n    fixed_train_size      = True,\n    gap                   = 0,\n    skip_folds            = None,\n    allow_incomplete_fold = True,\n    refit                 = False\n)\n\nbacktesting_forecaster(\n    forecaster            = forecaster,\n    y                     = y,\n    cv                    = cv,\n    metric                = 'mean_absolute_error',\n    n_jobs                = 'auto',\n    verbose               = False,\n    show_progress         = True\n)\n```\n\n----------------------------------------\n\nTITLE: Import Libraries for XGBoost\nDESCRIPTION: Imports necessary libraries for working with XGBoost, including numpy, pandas, XGBoost, torch for GPU detection, and skforecast for recursive forecasting. This snippet sets up the environment for subsequent operations using these libraries.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/skforecast-in-GPU.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"python\n# Libraries\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nimport time\nfrom xgboost import XGBRegressor\nimport torch\nimport os\nimport sys\nimport psutil\nfrom skforecast.recursive import ForecasterRecursive\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Bike Sharing Dataset for Time Series Analysis\nDESCRIPTION: This code fetches the bike sharing dataset using the skforecast.datasets module. The dataset contains information on bicycle rental service usage, weather variables, and holiday data.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/categorical-features.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading data\n# ==============================================================================\ndata = fetch_dataset(name='bike_sharing', raw=True)\n```\n\n----------------------------------------\n\nTITLE: Retrieving In-Sample Predictions from SARIMAX Model in Python\nDESCRIPTION: This code demonstrates how to create a ForecasterSarimax model, fit it on training data, and access the in-sample predictions (fitted values). These predictions are useful for evaluating model accuracy on the training dataset.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/forecasting-sarimax-arima.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# Create and fit ForecasterSarimax (skforecast)\n# ==============================================================================\nforecaster = ForecasterSarimax(\n                 regressor=Sarimax(order=(12, 1, 1), maxiter=200),\n             )\nforecaster.fit(y=data_train['y'], suppress_warnings=True)\n\n# In-sample Predictions\n# ==============================================================================\nforecaster.regressor.sarimax_res.fittedvalues\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a Forecaster in Python\nDESCRIPTION: This snippet demonstrates how to make predictions using the fitted ForecasterDirect model. It shows how to predict a specific subset of steps or all steps as defined during initialization, highlighting how to utilize the predict method effectively based on user requirements.\nSOURCE: https://github.com/skforecast/skforecast/blob/master/docs/user_guides/direct-multi-step-forecasting.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Predict\n# ==============================\n# Predict only a subset of steps\npredictions = forecaster.predict(steps=[1, 5])\ndisplay(predictions)\n\n# Predict all steps defined in the initialization.\npredictions = forecaster.predict()\ndisplay(predictions.head(3))\n```"
  }
]