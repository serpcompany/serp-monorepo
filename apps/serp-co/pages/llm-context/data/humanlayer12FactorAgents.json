[
  {
    "owner": "humanlayer",
    "repo": "12-factor-agents",
    "content": "TITLE: Implementing Basic Agent Loop in Python\nDESCRIPTION: Demonstrates the core loop structure of an AI agent that processes events, determines next steps via LLM, and executes actions until completion. The loop consists of context management, step determination, and result processing.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ninitial_event = {\"message\": \"...\"}\ncontext = [initial_event]\nwhile True:\n  next_step = await llm.determine_next_step(context)\n  context.append(next_step)\n\n  if (next_step.intent === \"done\"):\n    return next_step.final_answer\n\n  result = await execute_step(next_step)\n  context.append(result)\n```\n\n----------------------------------------\n\nTITLE: Advanced Error Handling with Consecutive Error Tracking in Python LLM Agents\nDESCRIPTION: This code implements a more sophisticated error handling approach that tracks consecutive errors for a specific tool. It limits retry attempts to avoid infinite loops and provides pathways for escalation when persistent failures occur.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-9-compact-errors.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nconsecutive_errors = 0\n\nwhile True:\n\n  # ... existing code ...\n\n  try:\n    result = await handle_next_step(thread, next_step)\n    thread[\"events\"].append({\n      \"type\": next_step.intent + '_result',\n      data: result,\n    })\n    # success! reset the error counter\n    consecutive_errors = 0\n  except Exception as e:\n    consecutive_errors += 1\n    if consecutive_errors < 3:\n      # do the loop and try again\n      thread[\"events\"].append({\n        \"type\": 'error',\n        \"data\": format_error(e),\n      })\n    else:\n      # break the loop, reset parts of the context window, escalate to a human, or whatever else you want to do\n      break\n  }\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Control Flow for Agent Actions in Python\nDESCRIPTION: This function demonstrates how to handle different types of agent actions with appropriate control flow. It shows three patterns: breaking the loop to wait for human clarification, continuing the loop after fetching data, and breaking the loop to wait for human approval before taking high-stakes actions.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-8-own-your-control-flow.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef handle_next_step(thread: Thread):\n\n  while True:\n    next_step = await determine_next_step(thread_to_prompt(thread))\n    \n    # inlined for clarity - in reality you could put \n    # this in a method, use exceptions for control flow, or whatever you want\n    if next_step.intent == 'request_clarification':\n      thread.events.append({\n        type: 'request_clarification',\n          data: nextStep,\n        })\n\n      await send_message_to_human(next_step)\n      await db.save_thread(thread)\n      # async step - break the loop, we'll get a webhook later\n      break\n    elif next_step.intent == 'fetch_open_issues':\n      thread.events.append({\n        type: 'fetch_open_issues',\n        data: next_step,\n      })\n\n      issues = await linear_client.issues()\n\n      thread.events.append({\n        type: 'fetch_open_issues_result',\n        data: issues,\n      })\n      # sync step - pass the new context to the LLM to determine the NEXT next step\n      continue\n    elif next_step.intent == 'create_issue':\n      thread.events.append({\n        type: 'create_issue',\n        data: next_step,\n      })\n\n      await request_human_approval(next_step)\n      await db.save_thread(thread)\n      # async step - break the loop, we'll get a webhook later\n      break\n```\n\n----------------------------------------\n\nTITLE: Processing LLM Tool Calls in Python\nDESCRIPTION: Python implementation showing how to handle the LLM's structured output and route it to appropriate functions. Demonstrates error handling and conditional processing of different function types returned by the LLM.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-1-natural-language-to-tool-calls.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# The LLM takes natural language and returns a structured object\nnextStep = await llm.determineNextStep(\n  \"\"\"\n  create a payment link for $750 to Jeff \n  for sponsoring the february AI tinkerers meetup\n  \"\"\"\n  )\n\n// Handle the structured output based on its function\nif nextStep.function == 'create_payment_link':\n    stripe.paymentlinks.create(nextStep.parameters)\n    return  # or whatever you want, see below\nelif nextStep.function == 'something_else':\n    # ... more cases\n    pass\nelse:  # the model didn't call a tool we know about\n    # do something else\n    pass\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Context Format in Python\nDESCRIPTION: This Python code demonstrates how to implement a custom context format using classes for Thread and Event, and functions to convert events and threads into a structured prompt format.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-3-own-your-context-window.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Thread:\n  events: List[Event]\n\nclass Event:\n  # could just use string, or could be explicit - up to you\n  type: Literal[\"list_git_tags\", \"deploy_backend\", \"deploy_frontend\", \"request_more_information\", \"done_for_now\", \"list_git_tags_result\", \"deploy_backend_result\", \"deploy_frontend_result\", \"request_more_information_result\", \"done_for_now_result\", \"error\"]\n  data: ListGitTags | DeployBackend | DeployFrontend | RequestMoreInformation |  \n        ListGitTagsResult | DeployBackendResult | DeployFrontendResult | RequestMoreInformationResult | string\n\ndef event_to_prompt(event: Event) -> str:\n    data = event.data if isinstance(event.data, str) \\\n           else stringifyToYaml(event.data)\n\n    return f\"<{event.type}>\\n{data}\\n</{event.type}>\"\n\n\ndef thread_to_prompt(thread: Thread) -> str:\n  return '\\n\\n'.join(event_to_prompt(event) for event in thread.events)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Error Handling in Python LLM Agents\nDESCRIPTION: This code shows a basic implementation of error handling in an LLM agent system. It captures exceptions from tool calls and adds them to the context window, allowing the LLM to attempt recovery in subsequent iterations.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-9-compact-errors.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nthread = {\"events\": [inital_message]}\n\nwhile True:\n  next_step = await determine_next_step(thread_to_prompt(thread))\n  thread[\"events\"].append({\n    \"type\": next_step.intent,\n    \"data\": next_step,\n  })\n  try:\n    result = await handle_next_step(thread, next_step) # our switch statement\n  except Exception as e:\n    # if we get an error, we can add it to the context window and try again\n    thread[\"events\"].append({\n      \"type\": 'error',\n      \"data\": format_error(e),\n    })\n    # loop, or do whatever else here to try to recover\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Agent Loop in Python\nDESCRIPTION: Demonstrates the fundamental loop pattern used in AI agents where an LLM determines the next step, executes it, and maintains context until completion. The loop continues until the agent determines the task is done.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/brief-history-of-software.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ninitial_event = {\"message\": \"...\"}\ncontext = [initial_event]\nwhile True:\n  next_step = await llm.determine_next_step(context)\n  context.append(next_step)\n\n  if (next_step.intent === \"done\"):\n    return next_step.final_answer\n\n  result = await execute_step(next_step)\n  context.append(result)\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Execution Control Flow in Python\nDESCRIPTION: Shows how to implement control flow logic for handling different tool intents using a switch-like pattern in Python. Demonstrates handling payment link creation and wait states with conditional statements.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-4-tools-are-structured-outputs.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nif nextStep.intent == 'create_payment_link':\n    stripe.paymentlinks.create(nextStep.parameters)\n    return # or whatever you want, see below\nelif nextStep.intent == 'wait_for_a_while': \n    # do something monadic idk\nelse: #... the model didn't call a tool we know about\n    # do something else\n```\n\n----------------------------------------\n\nTITLE: Implementing Webhook Handler for Human Responses in Python\nDESCRIPTION: Defines a webhook handler to receive and process human responses to agent requests. The handler loads the thread state, adds the human response, determines the next step, and continues the execution flow.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-7-contact-humans-with-tools.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@app.post('/webhook')\ndef webhook(req: Request):\n  thread_id = req.body.threadId\n  thread = await load_state(thread_id)\n  thread.events.push({\n    type: 'response_from_human',\n    data: req.body\n  })\n  # ... simplified for brevity, you likely don't want to block the web worker here\n  next_step = await determine_next_step(thread_to_prompt(thread))\n  thread.events.append(next_step)\n  result = await handle_next_step(thread, next_step)\n  # todo - loop or break or whatever you want\n\n  return {\"status\": \"ok\"}\n```\n\n----------------------------------------\n\nTITLE: Defining Issue Management Tool Classes in Python\nDESCRIPTION: Demonstrates the structure of tool classes for creating and searching issues using Python type hints. Shows how to define structured data models for Issue, CreateIssue, and SearchIssues operations.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-4-tools-are-structured-outputs.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Issue:\n  title: str\n  description: str\n  team_id: str\n  assignee_id: str\n\nclass CreateIssue:\n  intent: \"create_issue\"\n  issue: Issue\n\nclass SearchIssues:\n  intent: \"search_issues\"\n  query: str\n  what_youre_looking_for: str\n```\n\n----------------------------------------\n\nTITLE: Converting Natural Language to Stripe Payment Link Request\nDESCRIPTION: Example of structuring a natural language payment request into a formatted JSON object for Stripe API integration. Shows the conversion of a casual payment request into a structured format with necessary parameters like amount, customer ID, product details, and memo.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-1-natural-language-to-tool-calls.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"function\": {\n    \"name\": \"create_payment_link\",\n    \"parameters\": {\n      \"amount\": 750,\n      \"customer\": \"cust_128934ddasf9\",\n      \"product\": \"prod_8675309\",\n      \"price\": \"prc_09874329fds\",\n      \"quantity\": 1,\n      \"memo\": \"Hey Jeff - see below for the payment link for the february ai tinkerers meetup\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Human Interaction Tool Structure in Python\nDESCRIPTION: Defines classes for structured human interactions, including the Options class for configuration and RequestHumanInput for tool definition. This enables agents to request human input with specific formatting and urgency levels.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-7-contact-humans-with-tools.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Options:\n  urgency: Literal[\"low\", \"medium\", \"high\"]\n  format: Literal[\"free_text\", \"yes_no\", \"multiple_choice\"]\n  choices: List[str]\n\n# Tool definition for human interaction\nclass RequestHumanInput:\n  intent: \"request_human_input\"\n  question: str\n  context: str\n  options: Options\n\n# Example usage in the agent loop\nif nextStep.intent == 'request_human_input':\n  thread.events.append({\n    type: 'human_input_requested',\n    data: nextStep\n  })\n  thread_id = await save_state(thread)\n  await notify_human(nextStep, thread_id)\n  return # Break loop and wait for response to come back with thread ID\nelse:\n  # ... other cases\n```\n\n----------------------------------------\n\nTITLE: Type Signature for Structured Tool Outputs in TypeScript\nDESCRIPTION: TypeScript function signature showing how the prompt returns structured outputs that represent different possible tools or actions. This demonstrates the integration between prompt ownership and structured tool calls.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-2-own-your-prompts.md#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nfunction DetermineNextStep(thread: string) -> DoneForNow | ListGitTags | DeployBackend | DeployFrontend | RequestMoreInformation {\n```\n\n----------------------------------------\n\nTITLE: Explicit Prompt Engineering with BAML in Rust\nDESCRIPTION: Demonstrates treating prompts as first-class code using BAML in a Rust-like function. This approach gives full control over prompt content and structure while maintaining type safety through structured outputs.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-2-own-your-prompts.md#2025-04-23_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nfunction DetermineNextStep(thread: string) -> DoneForNow | ListGitTags | DeployBackend | DeployFrontend | RequestMoreInformation {\n  prompt #\"\n    {{ _.role(\"system\") }}\n    \n    You are a helpful assistant that manages deployments for frontend and backend systems.\n    You work diligently to ensure safe and successful deployments by following best practices\n    and proper deployment procedures.\n    \n    Before deploying any system, you should check:\n    - The deployment environment (staging vs production)\n    - The correct tag/version to deploy\n    - The current system status\n    \n    You can use tools like deploy_backend, deploy_frontend, and check_deployment_status\n    to manage deployments. For sensitive deployments, use request_approval to get\n    human verification.\n    \n    Always think about what to do first, like:\n    - Check current deployment status\n    - Verify the deployment tag exists\n    - Request approval if needed\n    - Deploy to staging before production\n    - Monitor deployment progress\n    \n    {{ _.role(\"user\") }}\n\n    {{ thread }}\n    \n    What should the next step be?\n  \"#\n}\n```\n\n----------------------------------------\n\nTITLE: Example Context Window with XML Formatting for Agent-Human Interaction\nDESCRIPTION: Demonstrates how a context window might look after several turns of agent-human interaction using XML formatting. Shows the flow from initial request through human approval to deployment completion.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-7-contact-humans-with-tools.md#2025-04-23_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n(snipped for brevity)\n\n<slack_message>\n    From: @alex\n    Channel: #deployments\n    Text: Can you deploy backend v1.2.3 to production?\n    Thread: []\n</slack_message>\n\n<request_human_input>\n    intent: \"request_human_input\"\n    question: \"Would you like to proceed with deploying v1.2.3 to production?\"\n    context: \"This is a production deployment that will affect live users.\"\n    options: {\n        urgency: \"high\"\n        format: \"yes_no\"\n    }\n</request_human_input>\n\n<human_response>\n    response: \"yes please proceed\"\n    approved: true\n    timestamp: \"2024-03-15T10:30:00Z\"\n    user: \"alex@company.com\"\n</human_response>\n\n<deploy_backend>\n    intent: \"deploy_backend\"\n    tag: \"v1.2.3\"\n    environment: \"production\"\n</deploy_backend>\n\n<deploy_backend_result>\n    status: \"success\"\n    message: \"Deployment v1.2.3 to production completed successfully.\"\n    timestamp: \"2024-03-15T10:30:00Z\"\n</deploy_backend_result>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Standard Message-Based Format in YAML\nDESCRIPTION: This snippet shows a standard message-based format commonly used in LLM clients, including system, user, assistant, and tool messages.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-3-own-your-context-window.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n[\n  {\n    \"role\": \"system\",\n    \"content\": \"You are a helpful assistant...\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"Can you deploy the backend?\"\n  },\n  {\n    \"role\": \"assistant\",\n    \"content\": null,\n    \"tool_calls\": [\n      {\n        \"id\": \"1\",\n        \"name\": \"list_git_tags\",\n        \"arguments\": \"{}\"\n      }\n    ]\n  },\n  {\n    \"role\": \"tool\",\n    \"name\": \"list_git_tags\",\n    \"content\": \"{\\\"tags\\\": [{\\\"name\\\": \\\"v1.2.3\\\", \\\"commit\\\": \\\"abc123\\\", \\\"date\\\": \\\"2024-03-15T10:00:00Z\\\"}, {\\\"name\\\": \\\"v1.2.2\\\", \\\"commit\\\": \\\"def456\\\", \\\"date\\\": \\\"2024-03-14T15:30:00Z\\\"}, {\\\"name\\\": \\\"v1.2.1\\\", \\\"commit\\\": \\\"abe033d\\\", \\\"date\\\": \\\"2024-03-13T09:15:00Z\\\"}]}\",\n    \"tool_call_id\": \"1\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Custom Context Format in YAML\nDESCRIPTION: This snippet illustrates a custom context format that puts the entire context window into a single user message, using XML-like tags to structure different types of information.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-3-own-your-context-window.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n[\n  {\n    \"role\": \"system\",\n    \"content\": \"You are a helpful assistant...\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": |\n            Here's everything that happened so far:\n        \n        <slack_message>\n            From: @alex\n            Channel: #deployments\n            Text: Can you deploy the backend?\n        </slack_message>\n        \n        <list_git_tags>\n            intent: \"list_git_tags\"\n        </list_git_tags>\n        \n        <list_git_tags_result>\n            tags:\n              - name: \"v1.2.3\"\n                commit: \"abc123\"\n                date: \"2024-03-15T10:00:00Z\"\n              - name: \"v1.2.2\"\n                commit: \"def456\"\n                date: \"2024-03-14T15:30:00Z\"\n              - name: \"v1.2.1\"\n                commit: \"ghi789\"\n                date: \"2024-03-13T09:15:00Z\"\n        </list_git_tags_result>\n        \n        what's the next step?\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Using a Black-Box Agent Framework in Python\nDESCRIPTION: Example of a framework-based approach that abstracts away prompt engineering details. This method provides pre-built prompt engineering but makes tuning difficult and obscures the exact tokens sent to the model.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-2-own-your-prompts.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nagent = Agent(\n  role=\"...\",\n  goal=\"...\",\n  personality=\"...\",\n  tools=[tool1, tool2, tool3]\n)\n\ntask = Task(\n  instructions=\"...\",\n  expected_output=OutputModel\n)\n\nresult = agent.run(task)\n```\n\n----------------------------------------\n\nTITLE: Optimized Implementation with Pre-fetched Tags\nDESCRIPTION: Shows the changes needed to pre-fetch git tags and include them directly in the context, improving efficiency by removing the need for an explicit tag fetch intent.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/appendix-13-pre-fetch.md#2025-04-23_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\nthread = {\"events\": [inital_message]}\n# add the request\nthread[\"events\"].append({\n \"type\": 'list_git_tags',\n})\n\ngit_tags = await fetch_git_tags()\n\n# add the result\nthread[\"events\"].append({\n \"type\": 'list_git_tags_result',\n \"data\": git_tags,\n})\n\n- next_step = await determine_next_step(thread, git_tags)\n+ next_step = await determine_next_step(thread)\n\nwhile True:\n  switch next_step.intent:\n    case 'deploy_backend_to_prod':\n      deploy_result = await deploy_backend_to_prod(next_step.data.tag)\n      thread[\"events\"].append(deploy_result)\n    case 'done_for_now':\n      await notify_human(next_step.message)\n      break\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Initial Python Implementation with Multiple Intents\nDESCRIPTION: Original Python code showing the implementation of handling multiple intents including fetching git tags on demand.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/appendix-13-pre-fetch.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nthread = {\"events\": [inital_message]}\nnext_step = await determine_next_step(thread)\n\nwhile True:\n  switch next_step.intent:\n    case 'list_git_tags':\n      tags = await fetch_git_tags()\n      thread[\"events\"].append({\n        type: 'list_git_tags',\n        data: tags,\n      })\n    case 'deploy_backend_to_prod':\n      deploy_result = await deploy_backend_to_prod(next_step.data.tag)\n      thread[\"events\"].append({\n        \"type\": 'deploy_backend_to_prod',\n        \"data\": deploy_result,\n      })\n    case 'done_for_now':\n      await notify_human(next_step.message)\n      break\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Initial Prompt Template Implementation\nDESCRIPTION: Shows the original prompt template that requires the model to explicitly request git tags when needed.\nSOURCE: https://github.com/humanlayer/12-factor-agents/blob/main/content/appendix-13-pre-fetch.md#2025-04-23_snippet_0\n\nLANGUAGE: jinja\nCODE:\n```\nWhen looking at deployments, you will likely want to fetch the list of published git tags,\nso you can use it to deploy to prod.\n\nHere's what happened so far:\n\n{{ thread.events }}\n\nWhat's the next step?\n\nAnswer in JSON format with one of the following intents:\n\n{\n  intent: 'deploy_backend_to_prod',\n  tag: string\n} OR {\n  intent: 'list_git_tags'\n} OR {\n  intent: 'done_for_now',\n  message: string\n}\n```"
  }
]