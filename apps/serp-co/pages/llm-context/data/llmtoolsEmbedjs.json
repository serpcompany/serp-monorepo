[
  {
    "owner": "llm-tools",
    "repo": "embedjs",
    "content": "TITLE: Using Paid LLMs and Embeddings (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates building a RAG application using paid models from OpenAI. It uses `OpenAiEmbeddings` and preconfigured `SIMPLE_MODELS.OPENAI_GPT4_O`. The code loads data from web URLs and then queries the model.  It requires the `OPENAI_API_KEY` environment variable to be set. Dependencies: `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-loader-web`, and `@llm-tools/embedjs-hnswlib`.  The `OPENAI_API_KEY` parameter is required.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/quickstart.mdx#_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nimport { RAGApplicationBuilder, SIMPLE_MODELS } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\n//Replace this with your OpenAI key\nprocess.env.OPENAI_API_KEY = \"sk-xxxx\"\n\nconst ragApplication = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait ragApplication.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait ragApplication.addLoader(new WebLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Elon_Musk' }));\n\nawait ragApplication.query('What is the net worth of Elon Musk today?')\n//Answer: The net worth of Elon Musk today is $258.7 billion.\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI GPT-4o RAG Application in TypeScript\nDESCRIPTION: This code snippet initializes a RAG application using the GPT-4o language model from OpenAI. It configures the application with the OpenAI model and embeddings, a vector database (HNSWDb), and a web loader to fetch data from a URL. The application then queries the model to answer a question about the loaded content. It depends on the `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-loader-web`, and `@llm-tools/embedjs-hnswlib` packages. The `modelName` parameter in `OpenAi` constructor specifies the OpenAI model to use.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/faq.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport 'dotenv/config';\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAi, OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst llmApplication = await new RAGApplicationBuilder()\n    .setModel(new OpenAi({ modelName: 'gpt-4o' }))\n    .setEmbeddingModel(new OpenAiEmbeddings())\n    .setVectorDatabase(new HNSWDb())\n    .build();\n\nawait llmApplication.addLoader(new WebLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Tesla,_Inc.' }));\n\nconsole.log(await llmApplication.query('Who founded Tesla?'));\n```\n\n----------------------------------------\n\nTITLE: Initializing Local Ollama RAG Application in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize a RAG application using a local Ollama model. It uses `OllamaEmbeddings` and sets up a RAG application by specifying the model and base URL for Ollama. It also adds a web loader to include content from two different URLs and finally queries the model. This example requires `@llm-tools/embedjs` and `embedjs-ollama` packages. The `modelName` parameter in `Ollama` constructor specifies the Ollama model to use and `baseUrl` configures the Ollama instance URL.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/faq.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OllamaEmbeddings } from '@llm-tools/embedjs-ollama';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\nconst ragApplication = await new RAGApplicationBuilder()\n    .setModel(new Ollama({ modelName: \"llama3.2\", baseUrl: 'http://localhost:11434' }))\n    .setEmbeddingModel(new OllamaEmbeddings({ model: 'nomic-embed-text', baseUrl: 'http://localhost:11434' }))\n    .build();\n\nawait ragApplication.addLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' })\nawait ragApplication.addLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Elon_Musk' })\n\nawait ragApplication.query('What is the net worth of Elon Musk today?')\n```\n\n----------------------------------------\n\nTITLE: Creating a RAG Pipeline with EmbedJs in TypeScript\nDESCRIPTION: This code initializes a Retrieval-Augmented Generation (RAG) application using EmbedJs. It sets up the pipeline with OpenAI's GPT-4 model, OpenAI embeddings, and HNSW vector database for efficient information retrieval.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/question-answering.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAi } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n```\n\n----------------------------------------\n\nTITLE: Using Pinecone with EmbedJS\nDESCRIPTION: This code snippet demonstrates how to use the PineconeDb class with EmbedJS to build a RAG application. It initializes the PineconeDb with project name, namespace, and index specifications, then sets the embedding model and language model. It adds a web loader to ingest data from a specified URL and queries the model to get information about the data source. An OpenAI API key is also required.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/pinecone.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { PineconeDb } from '@llm-tools/embedjs-pinecone';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(new PineconeDb({\n    projectName: '<name>',\n    namespace: '<name>',\n    indexSpec: {\n        pod: {\n            podType: 'p1.x1',\n            environment: 'us-east1-gcp',\n        },\n    },\n}))\n.build();\n\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Initializing LanceDB Vector Database with EmbedJs in TypeScript\nDESCRIPTION: Demonstrates setting up a Retrieval-Augmented Generation (RAG) application using EmbedJs in TypeScript, integrating LanceDB as a local vector database. The snippet shows how to import necessary modules, configure the OpenAI embedding model, specify the LanceDB path, add a web data loader with URL content, and issue a query. It requires the OpenAI API key to be set in the environment as 'OPENAI_API_KEY'. The example highlights key components like RAGApplicationBuilder, OpenAiEmbeddings, LanceDb, and WebLoader, showcasing end-to-end vector search and data retrieval flow.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/lancedb.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { LanceDb } from '@llm-tools/embedjs-lancedb';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(\n    new LanceDb({\n        path: './lmdb',\n    }),\n)\n.build();\n\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using LibSQL Vector Database in EmbedJs (TypeScript)\nDESCRIPTION: Illustrates initializing a RAG application using `RAGApplicationBuilder` from `@llm-tools/embedjs`. It configures `LibSqlDb` as the vector database, specifying a local file path (`./data.db`), sets `OpenAiEmbeddings` for embeddings, and defines a model. The example then adds data using `WebLoader` and performs a query. Requires the `OPENAI_API_KEY` environment variable to be set.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/libsql.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { LibSqlDb } from '@llm-tools/embedjs-libsql';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setVectorDatabase(new LibSqlDb({ path: './data.db' }))\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.build();\n\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Configuring RAGApplicationBuilder with Web Loader in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates creating a new RAG application instance, setting the language model to OpenAI GPT-4, choosing an embedding model and vector database, and adding a WebLoader with specified URL or content. It relies on imported modules from the embedjs library and demonstrates typical setup steps for a web-based retrieval-augmented application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/web-page.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new WebLoader({ urlOrContent: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Configuring Sitemap Loader with EmbedJS Framework in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize a RAGApplicationBuilder from the EmbedJS framework, specifying the use of an OpenAI model, embedding generation, and approximate nearest neighbor vector search via HNSWDb. It then adds a SitemapLoader pointing to a user-specified XML sitemap URL, automating ingestion of sitemap-listed web pages. Dependencies include @llm-tools/embedjs, @llm-tools/embedjs-openai, @llm-tools/embedjs-hnswlib, and @llm-tools/embedjs-loader-sitemap which must all be installed and properly configured.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/sitemap.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new SitemapLoader({ url: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Loading Sitemap Data using addLoader in Embedjs (TypeScript)\nDESCRIPTION: Shows how to configure a RAGApplicationBuilder and utilize `addLoader` with `SitemapLoader` to load all URLs listed within a specified sitemap XML file. Dependencies include `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-hnswlib`, and `@llm-tools/embedjs-loader-sitemap`. The `SitemapLoader` takes the sitemap URL as the `url` parameter.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/add-loader.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O) // Assuming SIMPLE_MODELS is defined elsewhere\n.setEmbeddingModel(new OpenAiEmbeddings()) \n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait app.addLoader(new SitemapLoader({ url: 'https://js.langchain.com/sitemap.xml' })); // Corrected invalid double quote\n//Add loader completed with 11024 new entries for 6c8d1a7b-ea34-4927-8823-xba29dcfc5ad\n```\n\n----------------------------------------\n\nTITLE: Customizing Chunk Size and Overlap for Built-In Loaders in embedjs with TypeScript\nDESCRIPTION: Demonstrates how to customize chunk size and chunk overlap parameters when initializing built-in loaders such as DocxLoader in embedjs. The snippet also shows the setup of a retrieval-augmented generation (RAG) application with OpenAI embeddings and HNSW vector database. Key dependencies include RAGApplicationBuilder, OpenAiEmbeddings, HNSWDb, and DocxLoader. The addLoader method accepts a loader instance with configurable chunkSize and chunkOverlap to control how data is split into chunks for embedding and indexing.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/custom.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { DocxLoader } from '@llm-tools/embedjs-loader-msoffice';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new DocxLoader({ filePathOrUrl: '...', chunkOverlap: 100, chunkSize: 20 }))\n```\n\n----------------------------------------\n\nTITLE: Initializing RAGApplication with EmbedJs Builder in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize a RAGApplication using the EmbedJs RAGApplicationBuilder. It requires the '@llm-tools/embedjs' package for the builder, '@llm-tools/embedjs-openai' for the OpenAiEmbeddings model, and '@llm-tools/embedjs-hnswlib' for the HNSWDb vector database. Methods like setModel, setEmbeddingModel, and setVectorDatabase configure the core components and must be provided valid instances as parameters. The build() method is asynchronous and returns the configured RAGApplication ready for use. Inputs include model type, embedding model instance, and vector database instance; the output is a RAGApplication object. This approach expects all dependencies to be installed and importable at runtime.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/overview.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\n//app is of type RAGApplication\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n```\n\n----------------------------------------\n\nTITLE: Using Open Source LLMs and Embeddings (TypeScript)\nDESCRIPTION: This TypeScript code demonstrates building and using a Retrieval Augmented Generation (RAG) application with open-source LLMs and embeddings using the `Ollama` integration. It uses `Ollama` for both the LLM (`llama3.2`) and the embedding model (`nomic-embed-text`). It loads data from URLs, builds a vector database, and then queries the model.  Dependencies: `@llm-tools/embedjs`, `@llm-tools/embedjs-ollama`, `@llm-tools/embedjs-loader-web`, and `@llm-tools/embedjs-hnswlib`. Requires an Ollama server running locally.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/quickstart.mdx#_snippet_1\n\nLANGUAGE: ts\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OllamaEmbeddings, Ollama } from '@llm-tools/embedjs-ollama';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst ragApplication = await new RAGApplicationBuilder()\n.setModel(new Ollama({ modelName: \"llama3.2\", baseUrl: 'http://localhost:11434' }))\n.setEmbeddingModel(new OllamaEmbeddings({ model: 'nomic-embed-text', baseUrl: 'http://localhost:11434' }))\n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait ragApplication.addLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' })\nawait ragApplication.addLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Elon_Musk' })\n\nawait ragApplication.query('What is the net worth of Elon Musk today?')\n//Answer: The net worth of Elon Musk today is $258.7 billion.\n```\n\n----------------------------------------\n\nTITLE: Initializing a RAG Application with EmbedJS in TypeScript\nDESCRIPTION: This snippet demonstrates how to build a RAG (Retrieval-Augmented Generation) application using EmbedJS with TypeScript. It imports necessary classes for the application builder, OpenAI embeddings, HNSW vector database, and the MSOffice PPT loader. The application is configured with a GPT-4 OpenAI model, embedding model, and vector database. Finally, a local PPTX file loader is added using a specified file path or URL. Dependencies include the EmbedJS core, MSOffice loader addon, OpenAI embedding library, and the HNSWlib database wrapper.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/ppt.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { PptLoader } from '@llm-tools/embedjs-loader-msoffice';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new LocalPathLoader({ filePathOrUrl: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Using Excel Loader with embedjs in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to import necessary classes from embedjs and its related packages, build a RAG application with specific models and a vector database, and then add the ExcelLoader instance to the application, specifying the path or URL to the .xlsx file.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/excel.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { ExcelLoader } from '@llm-tools/embedjs-loader-msoffice';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new ExcelLoader({ filePathOrUrl: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Application with Confluence Loader in TypeScript\nDESCRIPTION: Example of building a RAG application with EmbedJS that uses the ConfluenceLoader to import content from specified Confluence spaces. The code demonstrates how to configure OpenAI embeddings, HNSW vector database, and add the Confluence loader with authentication.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/confluence.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { ConfluenceLoader } from '@llm-tools/embedjs-loader-confluence';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new ConfluenceLoader({ spaceNames: ['...', '...'], confluenceToken: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Loading a CSV File from a URL in EmbedJS Using TypeScript\nDESCRIPTION: This snippet illustrates setting up an EmbedJS retrieval-augmented generation application where CSV data is loaded from a remote URL. The configuration mirrors the local example but replaces the file path with a URL to fetch CSV data remotely. This enables dynamic ingestion of CSV content hosted online with the same embedding and vector database setup.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/csv.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { CsvLoader } from '@llm-tools/embedjs-loader-csv';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new CsvLoader({ filePathOrUrl: 'https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv' }))\n```\n\n----------------------------------------\n\nTITLE: Loading XML Data from URL into EmbedJS\nDESCRIPTION: This snippet shows how to configure the EmbedJS application to load XML data directly from a remote URL. It facilitates fetching and parsing externally hosted XML files for use within the application ecosystem.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/xml.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\napp.addLoader(new XmlLoader({ filePathOrUrl: 'https://www.w3schools.com/xml/plant_catalog.xml' }))\n```\n\n----------------------------------------\n\nTITLE: Building a RAG Application with EmbedJs and OpenAI\nDESCRIPTION: Example of creating a Retrieval-Augmented Generation (RAG) application using EmbedJs with OpenAI embeddings. This code demonstrates setting up the model, adding document loaders, and querying the application, with all interactions automatically logged to LangSmith.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/integration/langsmith.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\n\n//Replace this with your OpenAI key\nprocess.env.OPENAI_API_KEY = \"sk-xxxx\"\n\n//Build a new application\nconst ragApplication = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.build();\n\n//Add new documents\nragApplication.addLoader('https://www.forbes.com/profile/elon-musk')\nragApplication.addLoader('https://en.wikipedia.org/wiki/Elon_Musk')\n\n//Query your app\nawait ragApplication.query('What is the net worth of Elon Musk today?')\n```\n\n----------------------------------------\n\nTITLE: Loading Local PDF Files with embedjs in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to set up a Retrieval Augmented Generation (RAG) application using embedjs to load a PDF file from the local file system. It imports necessary modules including RAGApplicationBuilder, OpenAiEmbeddings, HNSWDb, and PdfLoader. The code configures the application with GPT-4o as the language model, OpenAI embeddings, and HNSWLib as the vector database, then adds a PDF loader with a specified local file path. Key parameters: filePathOrUrl (string path to the local PDF). Password-protected PDFs are not supported.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/pdf.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { PdfLoader } from '@llm-tools/embedjs-loader-pdf';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new PdfLoader({ filePathOrUrl: '/path/to/file.pdf' }))\n```\n\n----------------------------------------\n\nTITLE: Configuring AstraDB Vector Database in TypeScript\nDESCRIPTION: This code illustrates how to instantiate an AstraDB client within a TypeScript application using embedjs. It sets up a connection to AstraDB by specifying the API endpoint, application token, and collection name. The configuration is used to enable vector-based querying within an LLM application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/astradb.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { AstraDb } from '@llm-tools/embedjs-astradb';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(\n    new AstraDb({\n        endpoint: \"<ASTRA_DB_API_ENDPOINT>\",\n        apiKey: \"<ASTRA_DB_APP_TOKEN>\",\n        collectionName: \"documents\"\n    })\n)\n.build();\n```\n\n----------------------------------------\n\nTITLE: Using EmbedJS .search() Function - TypeScript\nDESCRIPTION: This TypeScript code demonstrates how to use the `.search()` function within a RAG application built with EmbedJS.  It initializes a RAGApplicationBuilder, configures the model, embedding model, vector database, and adds a SitemapLoader for a website. The code then calls the `.search()` function with a query and shows the expected output, which is an array of chunks containing relevant information, scores, page content, and metadata.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/search.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n```ts Code example\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OllamaEmbeddings } from '@llm-tools/embedjs-ollama';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\nconst ragApplication = await new RAGApplicationBuilder()\n.setModel(new Ollama({ modelName: \"llama3.2\", baseUrl: 'http://localhost:11434' }))\n.setEmbeddingModel(new OllamaEmbeddings({ model: 'nomic-embed-text', baseUrl: 'http://localhost:11434' }))\n.setVectorDatabase(new HNSWDb())\n.build();\n\n//Add Next.JS Website and docs\napp.addLoader(new SitemapLoader({ url: \"https://nextjs.org/sitemap.xml\" }))\n\napp.search(\"Summarize the features of Next.js 14?\")\n/*[\n  {\n    'score': 0.99,\n    'pageContent': 'Next.js 14 | Next.jsBack to BlogThursday, October 26th 2023Next.js 14Posted byLee Robinson@leeerobTim Neutkens@timneutkensAs we announced at Next.js Conf, Next.js 14 is our most focused release with: Turbopack: 5,000 tests passing for App & Pages Router 53% faster local server startup 94% faster code updates with Fast Refresh Server Actions (Stable): Progressively enhanced mutations Integrated with caching & revalidating Simple function calls, or works natively with forms Partial Prerendering',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5af',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ac',\n      'source': 'https://nextjs.org/blog/next-14'\n    }\n  },\n  {\n    'score': 0.98,\n    'pageContent': 'Next.js 13.3 | Next.jsBack to BlogThursday, April 6th 2023Next.js 13.3Posted byDelba de Oliveira@delba_oliveiraTim Neutkens@timneutkensNext.js 13.3 adds popular community-requested features, including: File-Based Metadata API: Dynamically generate sitemaps, robots, favicons, and more. Dynamic Open Graph Images: Generate OG images using JSX, HTML, and CSS. Static Export for App Router: Static / Single-Page Application (SPA) support for Server Components. Parallel Routes and Interception: Advanced',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5a1',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ae',\n      'source': 'https://nextjs.org/blog/next-13-3'\n    }\n  },\n  {\n    'score': 0.98,\n    'pageContent': 'Upgrading: Version 14 | Next.js MenuUsing App RouterFeatures available in /appApp Router.UpgradingVersion 14Version 14 Upgrading from 13 to 14 To update to Next.js version 14, run the following command using your preferred package manager: Terminalnpm i next@latest react@latest react-dom@latest eslint-config-next@latest Terminalyarn add next@latest react@latest react-dom@latest eslint-config-next@latest Terminalpnpm up next react react-dom eslint-config-next -latest Terminalbun add next@latest',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5a2',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ad',\n      'source': 'https://nextjs.org/docs/app/building-your-application/upgrading/version-14'\n    }\n  }\n]*/\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring RAGApplicationBuilder with LlamaCpp Model in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates initializing a Retrieval-Augmented Generation (RAG) application using EmbedJS, importing the necessary RAGApplicationBuilder and LlamaCpp modules. It sets the model to a local GGUF Llama 3.1 file, which should exist at the specified path. The example requires both @llm-tools/embedjs and @llm-tools/embedjs-llama-cpp as dependencies, and expects inputs for modelPath. The output is an application instance configured to use the LlamaCpp backend; proper error handling for missing models or incorrect paths is advised.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/llama-cpp.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { LlamaCpp } from '@llm-tools/embedjs-llama-cpp';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new LlamaCpp({\n    modelPath: \"../models/llama-3.1-8b-instruct-hf-q4_k_m.gguf\",\n}))\n```\n\n----------------------------------------\n\nTITLE: Initializing Mistral RAG Application in TypeScript\nDESCRIPTION: This code snippet initializes a RAG application using the Mistral language model. It sets up the application with Mistral, a vector database (HNSWDb), and a web loader to ingest data from a specified URL. The application then queries the model with a question about the ingested content.  It requires the `@llm-tools/embedjs`, `@llm-tools/embedjs-mistral`, `@llm-tools/embedjs-loader-web`, and `@llm-tools/embedjs-hnswlib` packages.  The `modelName` parameter in the `Mistral` constructor specifies the Mistral model to use.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/faq.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport 'dotenv/config';\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { Mistral } from '@llm-tools/embedjs-mistral';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst llmApplication = await new RAGApplicationBuilder()\n    .setModel(new Mistral({ modelName: 'mistral-medium' }))\n    .setVectorDatabase(new HNSWDb())\n    .build();\n\nawait llmApplication.addLoader(new WebLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Tesla,_Inc.' }));\n\nconsole.log(await llmApplication.query('Who founded Tesla?'));\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI with Managed Identity in TypeScript\nDESCRIPTION: This code snippet illustrates how to authenticate AzureOpenAi using Azure Managed Identity via DefaultAzureCredential and a bearer token provider. It requires the @azure/identity package for authentication and demonstrates configuring the model using Azure Active Directory tokens for enhanced security.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/azure-openai.mdx#_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nimport {\n  DefaultAzureCredential,\n  getBearerTokenProvider\n} from \"@azure/identity\";\nimport { AzureOpenAi } from '@llm-tools/embedjs-openai';\n\nconst credentials = new DefaultAzureCredential();\nconst azureADTokenProvider = getBearerTokenProvider(\n  credentials,\n  \"https://cognitiveservices.azure.com/.default\"\n);\n\nconst app = new AzureOpenAi({\n  azureADTokenProvider,\n  azureOpenAIApiInstanceName: \"<your_instance_name>\",\n  azureOpenAIApiDeploymentName: \"<your_deployment_name>\",\n  azureOpenAIApiVersion: \"<api_version>\"\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing RAG Application with EmbedJS, OpenAI Embeddings, HNSWLib, and TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize a retrieval-augmented generation (RAG) application using the EmbedJS framework. It imports core classes including RAGApplicationBuilder, OpenAiEmbeddings, HNSWDb vectorstore, and a WebLoader for loading web data. The snippet requires an environment variable OPENAI_API_KEY containing a valid API key. It builds the application by setting the embedding model to OpenAI embeddings, selects a GPT-4 based OpenAI model for generation, and configures HNSWLib as the in-memory vector database. After building the app, it adds a web loader to ingest content from a URL and executes a query to retrieve information about the specified topic. Expected inputs include the environment variable and the web URL, while outputs consist of query results from the vectorstore enhancing response relevance. Limitation: the sample uses a placeholder API key and a preset SIMPLE_MODELS constant which should be defined or imported.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/hnswlib.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(new HNSWDb())\n.build();\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Using Redis as Data Store in @llm-tools/embedjs (TypeScript example)\nDESCRIPTION: This code demonstrates how to configure Redis as a data store within a RAG application by importing necessary classes, creating a new application builder, and setting the RedisStore with configuration options. It requires @llm-tools/embedjs and @llm-tools/embedjs-redis dependencies.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/redis.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { RedisStore } from '@llm-tools/embedjs-redis';\n\nconst app = await new RAGApplicationBuilder()\n.setStore(new RedisStore({ ... }))\n```\n\n----------------------------------------\n\nTITLE: Integrating MongoDB and OpenAI for RAG (TypeScript)\nDESCRIPTION: This TypeScript snippet illustrates how to set up a RAG application using the embedjs library with OpenAI embeddings and MongoDB as the vector database. It initializes `RAGApplicationBuilder` to configure the embedding model, language model, and vector database (MongoDB). Key parameters include the OpenAI API key (set in the environment), the MongoDB connection string, and the URL to load data from. The `WebLoader` is used to load data, and finally, a query is performed.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/mongodb.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { MongoDb } from '@llm-tools/embedjs-mongodb';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(new MongoDb({\n    connectionString: 'mongodb+srv://<username>:<password>@<url>',\n})),\n.build();\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Creating and configuring a RAG application with YouTubeLoader in TypeScript\nDESCRIPTION: This code demonstrates how to import necessary modules, instantiate a RAGApplicationBuilder, configure it with OpenAI embeddings and HNSWDb vector database, build the application, and add a YoutubeLoader with a specified video ID or URL. The setup enables embedding YouTube videos within the application context, relying on dependencies like @llm-tools/embedjs, @llm-tools/embedjs-openai, and @llm-tools/embedjs-hnswlib.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-video.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { YoutubeLoader } from '@llm-tools/embedjs-loader-youtube';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new YoutubeLoader({ videoIdOrUrl: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Initializing EmbedJS with Hugging Face Embeddings (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to import and configure the Hugging Face embedding model within an embedjs workflow. The example imports RAGApplicationBuilder, HuggingFaceEmbeddings, and HNSWDb, then initializes the builder and assigns the Hugging Face embedding model. '@llm-tools/embedjs' and '@llm-tools/embedjs-huggingface' must be installed. API key must be set in the environment. The setEmbeddingModel method can accept optional parameters specifying a different Hugging Face model. Input is the instantiated objects, and output is a configured RAGApplicationBuilder instance.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/huggingface.mdx#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { HuggingFaceEmbeddings } from '@llm-tools/embedjs-huggingface';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new HuggingFaceEmbeddings())\n```\n\n----------------------------------------\n\nTITLE: Configure RAG Application with Markdown Loader - TypeScript\nDESCRIPTION: Demonstrates how to build a RAG application using the embedjs RAGApplicationBuilder. It configures the application with a model (GPT-4o), OpenAI embeddings, an HNSWLib vector database, and crucially, adds the MarkdownLoader. The MarkdownLoader is initialized with a placeholder for the file path or URL.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/markdown.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { MarkdownLoader } from '@llm-tools/embedjs-loader-markdown';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new MarkdownLoader({ filePathOrUrl: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama Embeddings in EmbedJs (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to initialize and configure Ollama embeddings within an EmbedJs RAG application. It imports `RAGApplicationBuilder` and `OllamaEmbeddings`, then creates a new builder instance, setting the embedding model to use Ollama. Key parameters include `modelName` (specifying the desired Ollama embedding model) and `baseUrl` (the URL of the running local Ollama instance). This requires the `@llm-tools/embedjs` and `@llm-tools/embedjs-ollama` packages to be installed and a local Ollama server running at the specified URL.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/ollama.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OllamaEmbeddings } from '@llm-tools/embedjs-ollama';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OllamaEmbeddings({\n    modelName: \"...\",\n    baseUrl: 'http://localhost:11434'\n}))\n```\n\n----------------------------------------\n\nTITLE: Building and Querying RAG App with Qdrant (TypeScript)\nDESCRIPTION: This TypeScript snippet shows how to instantiate and configure a RAG application using the `RAGApplicationBuilder`. It sets up `QdrantDb` for vector storage, `OpenAiEmbeddings` for creating vectors, and `WebLoader` for data ingestion. The code demonstrates adding a data source and then querying the application. Requires `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-qdrant`, and `@llm-tools/embedjs-loader-web` installed. Environment variable `OPENAI_API_KEY` must be set, and Qdrant API key, URL, and cluster name are required for `QdrantDb`.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/qdrant.mdx#_snippet_1\n\nLANGUAGE: ts\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { QdrantDb } from '@llm-tools/embedjs-qdrant';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setVectorDatabase(new QdrantDb({ apiKey: '...', url: '...', clusterName: '...' }))\n.build();\n\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Initializing Retrieval-Augmented Generation (RAG) Application with embedjs in TypeScript\nDESCRIPTION: This TypeScript snippet shows the setup of a RAG application builder using the embedjs framework. It imports core components for model management, embedding creation with OpenAI embeddings, a HNSW vector database for similarity search, and a DocxLoader for ingesting DOCX documents. The builder configures the model to a simplified OpenAI GPT-4 schema, sets the embedding model, vector database, and finally adds a loader pointing to a DOCX file path or URL, preparing the app for document retrieval tasks.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/docx.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { DocxLoader } from '@llm-tools/embedjs-loader-msoffice';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new DocxLoader({ filePathOrUrl: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Initializing Vertex AI Gecko Embeddings with embedjs in TypeScript\nDESCRIPTION: This TypeScript snippet shows how to initialize the GeckoEmbeddings model from the @llm-tools/embedjs-vertexai package within the RAGApplicationBuilder provided by @llm-tools/embedjs. It also imports and references the HNSWDb vector database from @llm-tools/embedjs-hnswlib, allowing for building a retrieval-augmented generation system. Proper Vertex AI authentication must be configured before usage.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/vertexai.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { GeckoEmbeddings } from '@llm-tools/embedjs-vertexai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n  .setEmbeddingModel(new GeckoEmbeddings())\n```\n\n----------------------------------------\n\nTITLE: Initializing RAGApplicationBuilder with JsonLoader in TypeScript\nDESCRIPTION: This snippet shows how to initialize an RAGApplicationBuilder instance by configuring it with an OpenAI GPT-4 based model, setting up embedding with OpenAiEmbeddings, and connecting to an HNSWDb vector database. It then demonstrates adding a JsonLoader to load JSON data represented as an object. Dependencies include '@llm-tools/embedjs', '@llm-tools/embedjs-openai', and '@llm-tools/embedjs-hnswlib'. The snippet assumes the JSON object to be loaded is passed directly to JsonLoader. The expected input is a JSON object, and the output is an RAGApplication instance ready to work with ingested JSON data and embeddings.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/json.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder, JsonLoader } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new JsonLoader({ object: {...} }))\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB Store in a RAG Application - TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to set up MongoDB as the primary data store using the RAGApplicationBuilder from the embedjs framework. It imports required modules and configures the application to use MongoStore with user-specified connection options. Ensure that you have installed both @llm-tools/embedjs and @llm-tools/embedjs-mongodb. The MongoStore constructor expects an options object which should include MongoDB connection parameters (e.g., URI, database name). This code must be used in an async context.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/mongodb.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { MongoStore } from '@llm-tools/embedjs-mongodb';\n\nconst app = await new RAGApplicationBuilder()\n.setStore(new MongoStore({ ... }))\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Application with Weaviate and OpenAI in TypeScript\nDESCRIPTION: This code demonstrates building a Retrieval-Augmented Generation (RAG) application using EmbedJS with Weaviate as the vector database and OpenAI for embeddings. It shows configuration, data loading from a web page, and querying the system.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/weaviate.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { WeaviateDb } from '@llm-tools/embedjs-weaviate';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\n// set OPENAI_API_KEY in your env\nprocess.env.OPENAI_API_KEY = \"sk-xxx\";\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new WeaviateDb({ host: '...', apiKey: '...', className: '...', scheme: '...' }))\n.build();\n\n\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Initializing RAG App with Azure OpenAI Embeddings using Managed Identity (TypeScript)\nDESCRIPTION: Shows an alternative method to configure `AzureOpenAiEmbeddings` using Azure Managed Identity for authentication instead of an API key. It utilizes the `@azure/identity` package to obtain a token provider and passes it along with the Azure instance, deployment, and API version details.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/azure-openai.mdx#_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nimport {\n  DefaultAzureCredential,\n  getBearerTokenProvider,\n} from \"@azure/identity\";\nimport { AzureOpenAiEmbeddings } from '@llm-tools/embedjs-openai';\n\nconst credentials = new DefaultAzureCredential();\nconst azureADTokenProvider = getBearerTokenProvider(\n  credentials,\n  \"https://cognitiveservices.azure.com/.default\"\n);\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new AzureOpenAiEmbeddings({\n    azureADTokenProvider,\n    azureOpenAIApiInstanceName: \"<your_instance_name>\",\n    azureOpenAIApiEmbeddingsDeploymentName: \"<your_embeddings_deployment_name>\",\n    azureOpenAIApiVersion: \"<api_version>\",\n}))\n```\n\n----------------------------------------\n\nTITLE: Resetting EmbedJS RAG Application Data (TypeScript)\nDESCRIPTION: This TypeScript code snippet demonstrates how to reset an EmbedJS RAG application to a clean state. It imports necessary modules, initializes the application with a specified language model (SIMPLE_MODELS.OPENAI_GPT4_O), embedding model (OpenAiEmbeddings), and vector database (HNSWDb). Finally, it calls the `reset()` method to wipe the application's data.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/reset.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait app.reset();\n```\n\n----------------------------------------\n\nTITLE: Initializing Ollama Model with EmbedJS - TypeScript\nDESCRIPTION: This TypeScript snippet initializes an Ollama model within a RAG application using the `RAGApplicationBuilder` and `Ollama` classes from the `@llm-tools/embedjs` and `@llm-tools/embedjs-ollama` packages.  It sets the model name to \"llama3\" and the base URL to \"http://localhost:11434\", which assumes that Ollama is running locally on the specified port.  The `RAGApplicationBuilder` and `Ollama` classes must be imported from the appropriate libraries.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/ollama.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { Ollama } from '@llm-tools/embedjs-ollama';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new Ollama({\n    modelName: \"llama3\",\n    baseUrl: 'http://localhost:11434'\n}))\n```\n\n----------------------------------------\n\nTITLE: Loading Webpage Data using addLoader in Embedjs (TypeScript)\nDESCRIPTION: Demonstrates initializing a RAGApplicationBuilder with OpenAI models and an HNSWDb vector store, then using `addLoader` with `WebLoader` to ingest data from a specific webpage URL. Requires installing `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-hnswlib`, and `@llm-tools/embedjs-loader-web`. The `WebLoader` is instantiated with the target URL in the `urlOrContent` property.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/add-loader.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O) // Assuming SIMPLE_MODELS is defined elsewhere\n.setEmbeddingModel(new OpenAiEmbeddings()) \n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\n//Add loader completed with 4 new entries for 6c8d1a7b-ea34-4927-8823-xba29dcfc5ac\n```\n\n----------------------------------------\n\nTITLE: Configuring RAGApplicationBuilder with LmdbStore in TypeScript\nDESCRIPTION: Partial example showing how to set up a RAG application with LMDB for local storage. The code imports necessary components and configures the LmdbStore with a specified file path.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/lmdb.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { LmdbStore } from '@llm-tools/embedjs-lmdb';\n\nconst app = await new RAGApplicationBuilder()\n.setStore(new LmdbStore({ path: path.resolve('./store') }))\n```\n\n----------------------------------------\n\nTITLE: Loading and Querying Remote PDFs with embedjs in TypeScript\nDESCRIPTION: This TypeScript example extends the RAG application setup by showing how to load a PDF directly from a remote URL using the PdfLoader in embedjs. After initializing the application and attaching the loader with a public PDF URL, it demonstrates querying the document for content. Inputs: filePathOrUrl (string URL to the remote PDF), question (string query for the app). Outputs: Answer retrieved from the loaded document. Dependencies include embedjs core, OpenAI embedding model, HNSWLib, and PdfLoader. Password-protected PDFs remain unsupported.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/pdf.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { PdfLoader } from '@llm-tools/embedjs-loader-pdf';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\nawait app.addLoader(new PdfLoader({ filePathOrUrl: 'https://arxiv.org/pdf/1706.03762.pdf' }))\nawait app.query(\"What is the paper 'attention is all you need' about?\");\n```\n\n----------------------------------------\n\nTITLE: Building and Querying EmbedJS RAG Application (TypeScript)\nDESCRIPTION: This snippet demonstrates how to build a Retrieval Augmented Generation (RAG) application using EmbedJS, configure it with Ollama models and HNSWLib database, add data from web loaders, and then perform queries using the .query() method. It shows examples of a simple query and a query with a conversation ID.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/query.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OllamaEmbeddings } from '@llm-tools/embedjs-ollama';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst ragApplication = await new RAGApplicationBuilder()\n.setModel(new Ollama({ modelName: \"llama3.2\", baseUrl: 'http://localhost:11434' }))\n.setEmbeddingModel(new OllamaEmbeddings({ model: 'nomic-embed-text', baseUrl: 'http://localhost:11434' }))\n.setVectorDatabase(new HNSWDb())\n.build();\n\nragApplication.addLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' })\nragApplication.addLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Elon_Musk' })\n\nawait ragApplication.query('What is the net worth of Elon Musk today?')\nawait ragApplication.query('Who is Elon Musk?' { conversationId: '1' })\n/*\n\n*/\n```\n\n----------------------------------------\n\nTITLE: Initializing embedjs with OpenAI Embeddings in TypeScript\nDESCRIPTION: Example code demonstrating how to import necessary modules and initialize the embedjs RAG application with OpenAI embeddings, specifying the model name. This setup prepares the system for embedding tasks using OpenAI's models.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/openai.mdx#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new OpenAiEmbeddings({\n    model: 'text-embedding-3-large'\n}))\n```\n\n----------------------------------------\n\nTITLE: Initializing Azure OpenAI with API key in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize an AzureOpenAi instance using an API key, specifying the model to be used. It requires the @llm-tools/embedjs and @llm-tools/embedjs-openai packages. The code is designed for use in TypeScript to facilitate GPT-4 model deployment.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/azure-openai.mdx#_snippet_1\n\nLANGUAGE: ts\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { AzureOpenAi } from '@llm-tools/embedjs-openai';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new AzureOpenAi({ model: \"gpt-4o\" }))\n```\n\n----------------------------------------\n\nTITLE: Loading XML File from Local Path into EmbedJS\nDESCRIPTION: This snippet demonstrates how to add an XML loader to the EmbedJS application for loading data from a local file specified by its file path or URL. It enables parsing and processing of local XML files within the application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/xml.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\napp.addLoader(new XmlLoader({ filePathOrUrl: '/path/to/file.xml' }))\n```\n\n----------------------------------------\n\nTITLE: Installing Vertex AI EmbedJS Addon with npm Bash\nDESCRIPTION: This Bash snippet installs the @llm-tools/embedjs-vertexai addon package needed to access Vertex AI embedding models. It requires Node.js and npm to be available in the environment. The output is the addon installed into the current node_modules directory, enabling usage of Vertex AI embeddings in embedjs projects.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/vertexai.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-vertexai\n```\n\n----------------------------------------\n\nTITLE: Using Cohere Embeddings\nDESCRIPTION: This code demonstrates how to use the `CohereEmbeddings` class with the `RAGApplicationBuilder`. It imports necessary modules and sets the embedding model to a new instance of `CohereEmbeddings`. This allows the RAG application to use Cohere's embedding model for generating vector embeddings.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/cohere.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { CohereEmbeddings } from '@llm-tools/embedjs-cohere';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new CohereEmbeddings())\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Data Loader by Extending BaseLoader Interface in TypeScript\nDESCRIPTION: Defines a CustomLoader class extending the BaseLoader interface with a generic type parameter for custom metadata. The constructor initializes the loader with a unique identifier. The asynchronous generator method getChunks is declared but not implemented, meant to yield data chunks during loading. Dependencies include the BaseLoader interface, and this snippet serves as a template for creating custom data source loaders in the embedjs ecosystem.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/custom.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nclass CustomLoader extends BaseLoader<{ customChunkMetadata: string }> {\n    constructor() {\n        super('uniqueId');\n    }\n\n    async *getChunks() {\n        throw new Error('Method not implemented.');\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama Addon for EmbedJs (Bash)\nDESCRIPTION: This command uses npm (Node Package Manager) to install the '@llm-tools/embedjs-ollama' package. This package provides the necessary integration for using Ollama embeddings within the EmbedJs framework. Requires Node.js and npm to be installed.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/ollama.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-ollama\n```\n\n----------------------------------------\n\nTITLE: Initializing RAG App with Azure OpenAI Embeddings (TypeScript)\nDESCRIPTION: Demonstrates the basic configuration of the embedjs RAG application builder to use `AzureOpenAiEmbeddings`. This snippet assumes that the necessary connection details (instance name, deployment name, API key, version) are provided via environment variables as shown in the environment variable setup snippet.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/azure-openai.mdx#_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { AzureOpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new AzureOpenAiEmbeddings({\n    model: 'text-embedding-3-large'\n}))\n```\n\n----------------------------------------\n\nTITLE: Deleting Loader with uniqueId in EmbedJS\nDESCRIPTION: This TypeScript snippet demonstrates how to use the `deleteLoader()` method to remove data associated with a specific loader, identified by its unique ID. It assumes that loaders have been previously added using `addLoader()` with `WebLoader` and `SitemapLoader` from `@llm-tools/embedjs`, `@llm-tools/embedjs-openai`, `@llm-tools/embedjs-hnswlib`, `@llm-tools/embedjs-redis`, `@llm-tools/embedjs-loader-web`, and `@llm-tools/embedjs-loader-sitemap`.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/delete-loader.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { RedisStore } from '@llm-tools/embedjs-redis';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.setStore(\n    new RedisStore({\n        host: this.configService.get('REDIS_HOST'),\n        port: this.configService.get('REDIS_PORT'),\n        password: this.configService.get('REDIS_PASSWORD'),\n    }),\n)\n.build();\n\nconst { uniqueId: forbesId } = await app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nconst { uniqueId: sitemapId } = await app.addLoader(new SitemapLoader({ url: '\"https://js.langchain.com/sitemap.xml' }));\n\nawait app.deleteLoader(forbesId);\n```\n\n----------------------------------------\n\nTITLE: Loading YouTube Channel Videos with EmbedJS (TypeScript)\nDESCRIPTION: This TypeScript snippet demonstrates how to load videos from a YouTube channel using the `YoutubeChannelLoader`. It initializes a `RAGApplicationBuilder`, sets the model, embedding model, and vector database.  It then adds the `YoutubeChannelLoader`, which takes a `youtubeChannelId` as a parameter.  The specific channel ID ('...') would be replaced with the actual ID.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-channel.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { YoutubeChannelLoader } from '@llm-tools/embedjs-loader-youtube';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new YoutubeChannelLoader({ youtubeChannelId: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key\nDESCRIPTION: Sets the Anthropic API key as an environment variable.  This key is required to authenticate requests to the Anthropic Claude models. Replace \"<Your key>\" with your actual API key obtained from the Anthropic console.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/anthropic.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nANTHROPIC_API_KEY=\"<Your key>\"\n```\n\n----------------------------------------\n\nTITLE: Configuring EmbedJS Application for XML Data Loading\nDESCRIPTION: This snippet defines the setup process for an EmbedJS application, including model selection, embedding model, and vector database configuration. It prepares the application environment for XML data loading by instantiating RAGApplicationBuilder and setting appropriate models.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/xml.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n```\n\n----------------------------------------\n\nTITLE: Initializing RAG Application with Youtube Search Loader - TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to build a RAGApplication using embedjs and add the YoutubeSearchLoader. The loader is initialized with a 'youtubeSearchString' parameter to specify the search query for fetching YouTube videos. Requires installation of embedjs, openai, hnswlib, and youtube loader packages.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-search.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { YoutubeSearchLoader } from '@llm-tools/embedjs-loader-youtube';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new YoutubeSearchLoader({ youtubeSearchString: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenAI model in RAG application with TypeScript\nDESCRIPTION: Demonstrates how to initialize a RAG (Retrieval-Augmented Generation) application using embedjs with an OpenAI model. The example sets up the text-davinci-003 model using the OpenAi class from the embedjs-openai package.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/openai.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAi } from '@llm-tools/embedjs-openai';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new OpenAi({ model: \"text-davinci-003\" }))\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral EmbedJS Addon via npm\nDESCRIPTION: This snippet demonstrates how to install the Mistral addon for EmbedJS using npm package manager. It is essential to install this package before using Mistral models in your application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/mistral.mdx#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nnpm install @llm-tools/embedjs-mistral\n```\n\n----------------------------------------\n\nTITLE: Example Usage of AstraDB with LLM Application in TypeScript\nDESCRIPTION: This snippet shows how to add a web content loader and execute a query in an AstraDB-backed LLM application. It demonstrates initializing loaders, performing queries, and integrating AstraDB for data retrieval, enabling context-aware AI responses.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/astradb.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n//add data source and start query it\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.query('Tell me about Elon Musk');\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Example command to set the OPENAI_API_KEY environment variable in Bash, necessary for authenticating requests to OpenAI services.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/openai.mdx#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nOPENAI_API_KEY=\"<Your key>\"\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama Addon - Bash\nDESCRIPTION: This snippet installs the `@llm-tools/embedjs-ollama` package using npm. This package provides the necessary integration for using Ollama models with the EmbedJS library.  It is a prerequisite for utilizing the Ollama functionality in the application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/ollama.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-ollama\n```\n\n----------------------------------------\n\nTITLE: Setting Pinecone API Key\nDESCRIPTION: This command sets the Pinecone API key as an environment variable. Replace `<your api key>` with your actual Pinecone API key obtained from the Pinecone dashboard. This API key is essential for authenticating your application with the Pinecone service.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/pinecone.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nPINECONE_API_KEY=<your api key>\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key as environment variable\nDESCRIPTION: Sets the OpenAI API key as an environment variable for authentication with the OpenAI service. The key must be obtained from the OpenAI API Portal.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/openai.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=\"<Your key>\"\n```\n\n----------------------------------------\n\nTITLE: Ingesting Data Sources for RAG Pipeline in TypeScript\nDESCRIPTION: This snippet demonstrates how to populate a RAG pipeline with data from multiple sources. It uses the SitemapLoader to ingest content from the Next.JS website documentation and forum, incorporating over 15,000 pages of data for the knowledge base.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/question-answering.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\n//Add Next.JS Website and docs\napp.addLoader(new SitemapLoader({ url: \"https://nextjs.org/sitemap.xml\" }))\n\n//Add Next.JS Forum data\napp.addLoader(new SitemapLoader({ url: \"https://nextjs-forum.com/sitemap.xml\" }))\n```\n\n----------------------------------------\n\nTITLE: Setting Hugging Face API Key in Bash\nDESCRIPTION: Demonstrates how to set the environment variable HUGGINGFACEHUB_API_KEY in a bash shell. This API key is necessary for authenticating requests to Hugging Face services when running inference with LLM models in embedjs. Users must replace \"<Your hf key>\" with their actual Hugging Face token.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/huggingface.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nHUGGINGFACEHUB_API_KEY=\"<Your hf key>\"\n```\n\n----------------------------------------\n\nTITLE: Authenticating Google Cloud via gcloud CLI (Bash)\nDESCRIPTION: Authenticates the local environment for Google Cloud access using the gcloud command-line tool. This command initiates a login flow to obtain application-default credentials.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/vertexai.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngcloud auth application-default login\n```\n\n----------------------------------------\n\nTITLE: Installing Anthropic EmbedJS Addon\nDESCRIPTION: Installs the `@llm-tools/embedjs-anthropic` package using npm. This package provides the necessary integration components to use Anthropic's Claude models with EmbedJS. It requires Node.js and npm to be installed.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/anthropic.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-anthropic\n```\n\n----------------------------------------\n\nTITLE: Installing LMDB addon package for embedjs\nDESCRIPTION: Command to install the LMDB addon for embedjs using npm, which enables local disk storage functionality.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/lmdb.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-lmdb\n```\n\n----------------------------------------\n\nTITLE: Installing MSOffice Loader with Bash\nDESCRIPTION: This command installs the required npm package for loading Microsoft Office files (including Excel) into your embedjs project. It adds the @llm-tools/embedjs-loader-msoffice dependency to your project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/excel.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-msoffice\n```\n\n----------------------------------------\n\nTITLE: Setting Hugging Face API Key in Environment (Bash)\nDESCRIPTION: This Bash snippet sets the HUGGINGFACEHUB_API_KEY environment variable required for authenticating with the Hugging Face Inference API. Replace <Your hf key> with your actual API token obtained from your Hugging Face account. The environment variable must be available for any process using the Hugging Face inference endpoints; lack of this credential will prevent API access.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/huggingface.mdx#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nHUGGINGFACEHUB_API_KEY=\"<Your hf key>\"\n```\n\n----------------------------------------\n\nTITLE: Using Anthropic Model in RAGApplicationBuilder\nDESCRIPTION: Demonstrates how to integrate the Anthropic Claude model within a RAG application using the EmbedJS framework. It imports necessary modules from `@llm-tools/embedjs` and `@llm-tools/embedjs-anthropic`, then sets the model using the `setModel` method. Replace \"...\" with the desired Claude model name.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/anthropic.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { Anthropic } from '@llm-tools/embedjs-anthropic';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new Anthropic({ modelName: \"...\" }))\n```\n\n----------------------------------------\n\nTITLE: Installing MongoDB Addon (npm install)\nDESCRIPTION: This code snippet demonstrates the installation of the MongoDB addon for embedjs using npm.  This addon is necessary for interacting with MongoDB databases. It is essential to install this package to use MongoDB as your vector database.  The command installs the `@llm-tools/embedjs-mongodb` package.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/mongodb.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-mongodb\n```\n\n----------------------------------------\n\nTITLE: Installing Cohere Addon\nDESCRIPTION: This command installs the `@llm-tools/embedjs-cohere` package, which provides the `CohereEmbeddings` class.  This package is a dependency for using Cohere's embedding model within EmbedJS.  It must be installed before using the `CohereEmbeddings` class in your code.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/cohere.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-cohere\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI addon for embedjs\nDESCRIPTION: Installs the OpenAI addon package for embedjs using npm. This package is required to use OpenAI models with the embedjs library.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/openai.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-openai\n```\n\n----------------------------------------\n\nTITLE: Configuring Mistral Model with EmbedJS in TypeScript\nDESCRIPTION: This snippet shows how to import necessary classes, instantiate a new RAGApplicationBuilder, and set up a Mistral model with an access token and model name. The setup enables the application to interact with Mistral's API for AI functionalities, requiring a valid API key and specified model parameters.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/mistral.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { Mistral } from '@llm-tools/embedjs-mistral';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new Mistral({ accessToken: \"<YOUR_MISTRAL_TOKEN_HERE>\", modelName: \"...\" }))\n```\n\n----------------------------------------\n\nTITLE: Installing embedjs-openai Package via npm\nDESCRIPTION: Command to install the @llm-tools/embedjs-openai package, which provides OpenAI embedding model integration for embedjs, ensuring dependencies are properly included in the project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/openai.mdx#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nnpm install @llm-tools/embedjs-openai\n```\n\n----------------------------------------\n\nTITLE: Configuring LlamaCpp Embeddings in EmbedJs with TypeScript\nDESCRIPTION: This code demonstrates how to initialize EmbedJs with the LlamaCpp embeddings by importing necessary classes, creating a new application builder, and setting up the embedding model with a specified local model path. It outlines the integration process and the key configuration parameter, modelPath.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/llama-cpp.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { LlamaCppEmbeddings } from '@llm-tools/embedjs-llama-cpp';\n\nconst app = await new RAGApplicationBuilder()\n.setEmbeddingModel(new LlamaCppEmbeddings({\n    modelPath: \"./models/nomic-embed-text-v1.5.f16.gguf\",\n}))\n```\n\n----------------------------------------\n\nTITLE: Setting LangSmith Environment Variables in Bash\nDESCRIPTION: Configuration of required environment variables for integrating LangSmith with EmbedJs. These variables enable tracing, set the API endpoint, provide authentication, and specify the project for monitoring LLM applications.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/integration/langsmith.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Setting environment variable for LangChain Tracing V2 integration.\nexport LANGCHAIN_TRACING_V2=true\n\n# Setting the API endpoint for LangChain.\nexport LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n\n# Replace '<your-api-key>' with your LangChain API key.\nexport LANGCHAIN_API_KEY=<your-api-key>\n\n# Replace '<your-project>' with your LangChain project name, or it defaults to \"default\".\nexport LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to \"default\"\n```\n\n----------------------------------------\n\nTITLE: Initializing RAGApplicationBuilder with VertexAI (TypeScript)\nDESCRIPTION: Demonstrates how to initialize an embedjs RAG application using `RAGApplicationBuilder` and configure it to use a specific Vertex AI model (Gemini 1.5 Pro). It imports necessary classes and sets the model provider. Note: The import `Ollama` seems unused in the snippet, while `VertexAI` is used directly in `setModel`. Requires prior installation of the `@llm-tools/embedjs-vertexai` package and successful Google Cloud authentication.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/vertexai.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { Ollama } from '@llm-tools/embedjs-vertexai';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new VertexAI({ modelName: 'gemini-1.5-pro-preview-0409'}))\n```\n\n----------------------------------------\n\nTITLE: Install Markdown Loader - Bash\nDESCRIPTION: Installs the required npm package '@llm-tools/embedjs-loader-markdown'. This package provides the 'MarkdownLoader' class needed to process Markdown and MDX files within the embedjs framework. It is a necessary dependency before using the loader in your application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/markdown.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-markdown\n```\n\n----------------------------------------\n\nTITLE: Installing Weaviate Addon for EmbedJS\nDESCRIPTION: This command installs the Weaviate addon for EmbedJS, which allows integration with the Weaviate vector database.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/weaviate.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-weaviate\n```\n\n----------------------------------------\n\nTITLE: Setting Cohere API Key\nDESCRIPTION: This snippet shows how to set the Cohere API key as an environment variable. Replace `<YOUR_KEY>` with the actual API key obtained from the Cohere-AI dashboard. This key is necessary for authenticating requests to the Cohere API.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/cohere.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nCOHERE_API_KEY=\"<YOUR_KEY>\"\n```\n\n----------------------------------------\n\nTITLE: Installing LlamaCpp EmbedJs Addon with Bash\nDESCRIPTION: This snippet shows how to install the LlamaCpp addon package for EmbedJs using npm. It helps set up the project to support local LlamaCpp embeddings, which are needed for subsequent configuration.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/llama-cpp.mdx#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nnpm install @llm-tools/embedjs-llama-cpp\n```\n\n----------------------------------------\n\nTITLE: Installing PDF Loader Addon with npm in Bash\nDESCRIPTION: This snippet shows the command to install the @llm-tools/embedjs-loader-pdf package using npm, which is required to add PDF-loading capabilities to the embedjs framework. No special configuration is needed; simply run this command in your project directory. This command makes the PdfLoader dependency available for subsequent TypeScript usage.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/pdf.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-pdf\n```\n\n----------------------------------------\n\nTITLE: Installing Pinecone addon\nDESCRIPTION: This command installs the `@llm-tools/embedjs-pinecone` package using npm.  This package provides the necessary classes and functions to integrate Pinecone as a vector database within your EmbedJS application. It must be installed before using PineconeDb in your project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/pinecone.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-pinecone\n```\n\n----------------------------------------\n\nTITLE: Initializing Hugging Face Model in embedjs with TypeScript\nDESCRIPTION: Provides a TypeScript example of how to initialize and configure an embedjs RAGApplicationBuilder with a Hugging Face model. It imports the necessary classes, creates a new HuggingFace instance with a specified model name, and assigns it to the application builder. This snippet assumes the Hugging Face API key is set in the environment and that the addon package is installed.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/huggingface.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { HuggingFace } from '@llm-tools/embedjs-huggingface';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(new HuggingFace({ modelName: \"...\" }))\n```\n\n----------------------------------------\n\nTITLE: Adding Data Sources to the RAG Pipeline Using SitemapLoader\nDESCRIPTION: This snippet shows how to incorporate website and forum data into the pipeline by adding SitemapLoader instances pointing to respective sitemap URLs. Dependencies include '@llm-tools/embedjs-loader-sitemap'. It expands the data accessible for semantic search.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/semantic-search.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\n//Add Next.JS Website and docs\napp.addLoader(new SitemapLoader({ url: \"https://nextjs.org/sitemap.xml\" }))\n\n//Add Next.JS Forum data\napp.addLoader(new SitemapLoader({ url: \"https://nextjs-forum.com/sitemap.xml\" }))\n```\n\n----------------------------------------\n\nTITLE: Initializing RAGApplicationBuilder with directory loader in TypeScript\nDESCRIPTION: This snippet shows how to create a new RAGApplicationBuilder instance, configure it with a model, embeddings, and database, then add a LocalPathLoader with a specified directory path. It demonstrates setting up an application capable of loading multiple files from a directory and its subdirectories for processing. Dependencies include @llm-tools/embedjs and related modules for model, embedding, and database functionalities.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/directory.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new LocalPathLoader({ path: '...' }))\n```\n\n----------------------------------------\n\nTITLE: Installing LlamaCpp Addon via npm in Bash\nDESCRIPTION: This snippet shows how to install the @llm-tools/embedjs-llama-cpp npm package required for enabling local LlamaCpp model support in EmbedJS projects. Use this command in your project root; ensure Node.js and npm are installed beforehand. This step is a prerequisite for any LlamaCpp integration in EmbedJS-based workflows.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/llama-cpp.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-llama-cpp\n```\n\n----------------------------------------\n\nTITLE: Installing Huggingface Addon via npm\nDESCRIPTION: Shows the command to install the embedjs Hugging Face addon package using npm. This package provides the necessary integration to utilize Hugging Face models within the embedjs framework. Installation is a prerequisite before importing and using the Hugging Face class in TypeScript code.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/huggingface.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-huggingface\n```\n\n----------------------------------------\n\nTITLE: Creating a RAG Application Pipeline with EmbedJs in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize a RAG pipeline using EmbedJs by setting up the model, embedding model, and vector database. Dependencies include '@llm-tools/embedjs' modules. It helps establish a foundational application for semantic search tasks.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/semantic-search.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n```\n\n----------------------------------------\n\nTITLE: Installing Web Addon via NPM\nDESCRIPTION: This command installs the @llm-tools/embedjs-loader-web package using npm, enabling web page data loading capabilities in the embedjs ecosystem.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/web-page.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-web\n```\n\n----------------------------------------\n\nTITLE: Configuring RAGApplicationBuilder with LibSqlStore - TypeScript\nDESCRIPTION: Demonstrates importing the RAGApplicationBuilder from '@llm-tools/embedjs' and LibSqlStore from '@llm-tools/embedjs-libsql', then initializing a new application with LibSqlStore set as the storage backend. The 'path' parameter specifies the location of the local database file (e.g., './data.db'). TypeScript runtime with async/await support is required; ensure the invoked method is in an async context. The output is a configured app instance with LibSQL persistence.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/libsql.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { LibSqlStore } from '@llm-tools/embedjs-libsql';\n\nconst app = await new RAGApplicationBuilder()\n.setStore(new LibSqlStore({ path: './data.db' }))\n```\n\n----------------------------------------\n\nTITLE: Loading a Local CSV File in EmbedJS Using TypeScript\nDESCRIPTION: This snippet demonstrates initializing a retrieval-augmented generation application with the EmbedJS framework in TypeScript. It configures the model to use OpenAI GPT-4, sets up OpenAiEmbeddings, and an HNSW vector database. The CSV loader is added with a local file path or URL pointing to the local CSV file. This setup processes CSV data by extracting headers and lines as embeddings for retrieval tasks.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/csv.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { CsvLoader } from '@llm-tools/embedjs-loader-csv';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new CsvLoader({ filePathOrUrl: '/path/to/file.csv' }))\n```\n\n----------------------------------------\n\nTITLE: Loading an Image from a Local File using LLM Embedjs\nDESCRIPTION: This snippet demonstrates initializing the LLM application with specific models and databases, then adding an image loader for a local JPEG file. It highlights setup for image description and embedding processes, requiring model, embedding, and database dependencies.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/image.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { ImageLoader } from '@llm-tools/embedjs-loader-image';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new ImageLoader({ filePathOrUrl: '/path/to/file.jpeg' }))\n```\n\n----------------------------------------\n\nTITLE: Installing Confluence Loader for EmbedJS\nDESCRIPTION: Command to install the Confluence loader addon for EmbedJS using npm. This package enables the integration of Confluence content into EmbedJS applications.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/confluence.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-confluence\n```\n\n----------------------------------------\n\nTITLE: Deleting a Conversation Thread with embedjs in TypeScript\nDESCRIPTION: Demonstrates how to delete a specific conversation from the database using embedjs in TypeScript. This example sets up a RAGApplication with LibSqlStore, LibSqlDb, OpenAiEmbeddings, and loads web data for querying before deleting the conversation identified by 'default'. Required dependencies include '@llm-tools/embedjs', '@llm-tools/embedjs-libsql', '@llm-tools/embedjs-openai', and '@llm-tools/embedjs-loader-web'. The key input is the conversationId, which is passed as a string, with 'default' used to delete conversations created without explicit IDs. Output is handled via logs and the conversation thread is removed upon completion.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/delete-conversation.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport 'dotenv/config';\nimport path from 'node:path';\nimport { RAGApplicationBuilder, SIMPLE_MODELS } from '@llm-tools/embedjs';\nimport { LibSqlDb, LibSqlStore } from '@llm-tools/embedjs-libsql';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\n\nconst databasePath = path.resolve('./examples/libsql/data.db');\nconst ragApplication = await new RAGApplicationBuilder()\n    .setStore(new LibSqlStore({ path: databasePath }))\n    .setVectorDatabase(new LibSqlDb({ path: databasePath }))\n    .setEmbeddingModel(new OpenAiEmbeddings())\n    .setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n    .build();\n\nawait ragApplication.addLoader(new WebLoader({ urlOrContent: 'https://en.wikipedia.org/wiki/Elon_Musk' }));\nconsole.log(await ragApplication.query('Was Elon Musk the founder of Tesla originally?'));\nconsole.log(await ragApplication.query('What is the net worth of Elon Musk today?'));\n\nawait app.deleteConversation('default');\n```\n\n----------------------------------------\n\nTITLE: Rendering CardGroup and Card Components with EmbedJS JSX\nDESCRIPTION: This JSX snippet renders a CardGroup container with three columns and includes a Card component representing a Slack community invite. It uses properties such as title, icon, href, and color to customize the card's appearance and behavior. The snippet depends on React or a similar framework to interpret JSX and render UI components. The href value is a placeholder \"TODO\", which should be replaced with a valid URL. The Card displays child text prompting users to join the Slack community.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/_snippets/get-help.mdx#_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={3}>\n    <Card title=\"Slack\" icon=\"slack\" href=\"TODO\" color=\"#4A154B\">\n        Join our slack community\n    </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Installing EmbedJS CSV Loader Addon Using npm\nDESCRIPTION: This snippet shows the command to install the CSV loader addon for the EmbedJS framework via npm. This addon enables the loading and parsing of CSV files within the EmbedJS pipeline to facilitate embedding and retrieval tasks.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/csv.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-csv\n```\n\n----------------------------------------\n\nTITLE: Installing LLM Tools Package (Bash)\nDESCRIPTION: This snippet installs the `@llm-tools/embedjs` package using npm. This package is the core dependency for building the AI application.  The command uses `npm i` to install the package into the current project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/get-started/quickstart.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @llm-tools/embedjs\n```\n\n----------------------------------------\n\nTITLE: Citing EmbedJs using BibTeX\nDESCRIPTION: This BibTeX entry provides a citation format for referencing the EmbedJs repository. It includes the author, title, year, publisher, and journal information. It is intended for academic or formal use where proper attribution is required.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/contribution/dev.mdx#_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{embedJs,\n  author = {Adhityan K V},\n  title = {EmbedJs: The Open Source RAG Framework},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/llm-tools/embedjs}},\n}\n```\n\n----------------------------------------\n\nTITLE: Installing @llm-tools/embedjs-loader-youtube via npm\nDESCRIPTION: This snippet shows how to install the YouTube loader package as a dependency using npm, essential for integrating YouTube video embedding into the application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-video.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-youtube\n```\n\n----------------------------------------\n\nTITLE: Customizing Mintlify Port - Bash\nDESCRIPTION: This snippet demonstrates how to run the Mintlify documentation server on a custom port. The command `mintlify dev --port 3333` overrides the default port 3000 and uses port 3333 instead. The `--port` flag is used to specify the desired port number. This is useful for avoiding port conflicts or running multiple Mintlify instances simultaneously. Requires Mintlify CLI and that the desired port is available.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/contribution/docs.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmintlify dev --port 3333\n```\n\n----------------------------------------\n\nTITLE: Re-installing Mintlify Dependencies (Shell)\nDESCRIPTION: This command re-installs Mintlify's necessary dependencies. It is suggested as a troubleshooting step if the `mintlify dev` command fails to run, potentially resolving issues related to corrupted or missing dependencies.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmintlify install\n```\n\n----------------------------------------\n\nTITLE: Installing MSOffice addon for embedjs with npm\nDESCRIPTION: Installs the MSOffice loader addon required for processing DOCX files within the embedjs framework. This command requires a Node.js environment with npm available and adds the package '@llm-tools/embedjs-loader-msoffice' to the project dependencies to enable DOCX file loading capabilities.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/docx.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-msoffice\n```\n\n----------------------------------------\n\nTITLE: Loading Text with TextLoader and RAGApplicationBuilder - TypeScript\nDESCRIPTION: This TypeScript snippet showcases the process of loading text data into an application built using the `@llm-tools/embedjs` library. It utilizes `TextLoader` to supply a string, which is subsequently incorporated into the application. The code also includes initializing the `RAGApplicationBuilder` with an OpenAI model, embedding model, and an HNSWDb vector database. The text provided is not processed, meaning it will not be parsed or transformed before being used within the application.  The `TextLoader` takes an object containing the `text` property, which should be the string to load.  The output is the text data loaded into the application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/text.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n```ts\nimport { RAGApplicationBuilder, TextLoader } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.build();\n\napp.addLoader(new TextLoader({ text: '...' }))\n```\n```\n\n----------------------------------------\n\nTITLE: Installing MSOffice Addon for EmbedJS using Bash\nDESCRIPTION: This snippet shows the command to install the MSOffice loader addon for the EmbedJS framework via npm. It is a prerequisite to enable loading and processing PPTX files within EmbedJS applications.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/ppt.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-msoffice\n```\n\n----------------------------------------\n\nTITLE: Installing Image Loader Addon for LLM Tools\nDESCRIPTION: This snippet shows how to install the '@llm-tools/embedjs-loader-image' package necessary for enabling image loading capabilities within the LLM tools framework.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/image.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-image\n```\n\n----------------------------------------\n\nTITLE: Including external store tip documentation\nDESCRIPTION: This snippet references an external Markdown document that likely contains additional tips or guidance for using missing or unsupported data stores within EmbedJs. It helps users understand limitations or setup procedures related to data persistence.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/overview.mdx#_snippet_1\n\nLANGUAGE: MDX\nCODE:\n```\n<Snippet file=\"missing-store-tip.mdx\" />\n```\n\n----------------------------------------\n\nTITLE: Displaying GitHub Issue Link using Card Components\nDESCRIPTION: This snippet utilizes CardGroup and Card components, likely within a documentation framework or UI library, to present a styled link. It creates a clickable card prompting users to open a feature request issue on the embedJs GitHub repository, configuring the card's title, icon, link URL, and color.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/_snippets/missing-model-tip.mdx#_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={2}>\n    <Card\n        title=\"GitHub\"\n        icon=\"github\"\n        href=\"https://github.com/llm-tools/embedJs/issues/new?assignees=&labels=&projects=&template=feature_request.yml\"\n        color=\"#181717\"\n    >\n        Open an issue on our GitHub\n    </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with npm\nDESCRIPTION: This command installs the necessary dependencies for the EmbedJs project using npm (Node Package Manager). It is a prerequisite for making changes to the codebase. The command should be executed in the root directory of the forked repository.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/contribution/dev.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Verifying Build Pipeline with npm (Shell)\nDESCRIPTION: This shell command executes the build pipeline script named 'build:pipeline' defined in the project's `package.json` file using npm. It's a required step in the contribution process to ensure that code changes build successfully before submitting a pull request. Requires Node.js and npm to be installed.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm run build:pipeline\n```\n\n----------------------------------------\n\nTITLE: Running the Mintlify Development Server (Shell)\nDESCRIPTION: This command starts the Mintlify local development server using npx. It should be executed from the root directory of the documentation project (where `mint.json` is located) to preview documentation changes locally before publishing.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpx mintlify dev\n```\n\n----------------------------------------\n\nTITLE: Querying the RAG Application in TypeScript\nDESCRIPTION: This code shows how to test the RAG pipeline by submitting a query about Next.js 14. The application will process the query, retrieve relevant information from the ingested data sources, and generate a response summarizing the features of Next.js 14.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/question-answering.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\napp.query(\"Summarize the features of Next.js 14?\")\n```\n\n----------------------------------------\n\nTITLE: Using RAGApplicationBuilder to Get Loaders - TypeScript\nDESCRIPTION: This TypeScript code snippet demonstrates the usage of `RAGApplicationBuilder` to add loaders and retrieve them using the `getLoaders()` method. It initializes the builder with an OpenAI model, an embedding model, an HNSWDb vector database, and a Redis store. It adds loaders for a webpage and a sitemap and then prints the output from the getLoaders method. The expected output is an array of loader objects with their unique IDs and metadata.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/api-reference/methods/get-loaders.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n```ts\nimport { RAGApplicationBuilder } from '@llm-tools/embedjs';\nimport { OpenAiEmbeddings } from '@llm-tools/embedjs-openai';\nimport { HNSWDb } from '@llm-tools/embedjs-hnswlib';\nimport { RedisStore } from '@llm-tools/embedjs-redis';\nimport { WebLoader } from '@llm-tools/embedjs-loader-web';\nimport { SitemapLoader } from '@llm-tools/embedjs-loader-sitemap';\n\nconst app = await new RAGApplicationBuilder()\n.setModel(SIMPLE_MODELS.OPENAI_GPT4_O)\n.setEmbeddingModel(new OpenAiEmbeddings())\n.setVectorDatabase(new HNSWDb())\n.setStore(\n    new RedisStore({\n        host: this.configService.get('REDIS_HOST'),\n        port: this.configService.get('REDIS_PORT'),\n        password: this.configService.get('REDIS_PASSWORD'),\n    }),\n)\n.build();\n\nawait app.addLoader(new WebLoader({ urlOrContent: 'https://www.forbes.com/profile/elon-musk' }));\nawait app.addLoader(new SitemapLoader({ url: \\\"https://js.langchain.com/sitemap.xml\\\" }));\n\nconsole.log(await app.getLoaders())\n/*\n[\n    {\n        \"uniqueId\": \"6c8d1a7b-ea34-4927-8823-xba29dcfc5ac\",\n        \"type\": \"WebLoader\",\n        loaderMetadata: {\n            urlOrContent: \"https://www.forbes.com/profile/elon-musk\"\n        }\n    },\n    {\n        \"uniqueId\": \"6c8d1a7b-ea34-4927-8823-xba29dcfc5ad\",\n        \"type\": \"SitemapLoader\",\n        loaderMetadata: {\n            url: \"https://www.forbes.com/profile/elon-musk\"\n        }\n    }\n]\n*/\n```\n```\n\n----------------------------------------\n\nTITLE: Testing Semantic Search over Ingested Data in EmbedJs Application\nDESCRIPTION: This snippet demonstrates how to perform a search query within the embedded data sources, returning an array of matching document chunks with associated scores, content, and metadata. It highlights core search functionality and output format, utilizing the app.search() method.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/use-cases/semantic-search.mdx#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\napp.search(\"Summarize the features of Next.js 14?\")\n/*[\n  {\n    'score': 0.99,\n    'pageContent': 'Next.js 14 | Next.jsBack to BlogThursday, October 26th 2023Next.js 14Posted byLee Robinson@leeerobTim Neutkens@timneutkensAs we announced at Next.js Conf, Next.js 14 is our most focused release with: Turbopack: 5,000 tests passing for App & Pages Router 53% faster local server startup 94% faster code updates with Fast Refresh Server Actions (Stable): Progressively enhanced mutations Integrated with caching & revalidating Simple function calls, or works natively with forms Partial Prerendering',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5af',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ac',\n      'source': 'https://nextjs.org/blog/next-14'\n    }\n  },\n  {\n    'score': 0.98,\n    'pageContent': 'Next.js 13.3 | Next.jsBack to BlogThursday, April 6th 2023Next.js 13.3Posted byDelba de Oliveira@delba_oliveiraTim Neutkens@timneutkensNext.js 13.3 adds popular community-requested features, including: File-Based Metadata API: Dynamically generate sitemaps, robots, favicons, and more. Dynamic Open Graph Images: Generate OG images using JSX, HTML, and CSS. Static Export for App Router: Static / Single-Page Application (SPA) support for Server Components. Parallel Routes and Interception: Advanced',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5a1',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ae',\n      'source': 'https://nextjs.org/blog/next-13-3'\n    }\n  },\n  {\n    'score': 0.98,\n    'pageContent': 'Upgrading: Version 14 | Next.js MenuUsing App RouterFeatures available in /appApp Router.UpgradingVersion 14Version 14 Upgrading from 13 to 14 To update to Next.js version 14, run the following command using your preferred package manager: Terminalnpm i next@latest react@latest react-dom@latest eslint-config-next@latest Terminalyarn add next@latest react@latest react-dom@latest eslint-config-next@latest Terminalpnpm up next react react-dom eslint-config-next -latest Terminalbun add next@latest',\n    'metadata': {\n      'id': '6c8d1a7b-ea34-4927-8823-daa29dcfc5a2',\n      'uniqueLoaderId': '6c8d1a7b-ea34-4927-8823-xba29dcfc5ad',\n      'source': 'https://nextjs.org/docs/app/building-your-application/upgrading/version-14'\n    }\n  }\n]*/\n```\n\n----------------------------------------\n\nTITLE: Installing MongoDB Addon with npm - Bash\nDESCRIPTION: This snippet demonstrates how to install the official embedjs MongoDB addon using npm. Installing the package @llm-tools/embedjs-mongodb is required before you can use MongoDB as a datastore in your embedjs-based application. Run this command in your project directory prior to any TypeScript integration.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/mongodb.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-mongodb\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Environment Variables (Bash)\nDESCRIPTION: Sets the necessary environment variables required for the `@llm-tools/embedjs-openai` addon to connect to Azure OpenAI. This method uses an API key for authentication. Ensure you replace the placeholder values with your actual Azure OpenAI instance details and API key.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/azure-openai.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_OPENAI_API_INSTANCE_NAME=<YOUR_INSTANCE_NAME>\nAZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=<YOUR_EMBEDDINGS_DEPLOYMENT_NAME>\nAZURE_OPENAI_API_VERSION=\"2024-02-01\" #or a newer version\nAZURE_OPENAI_API_KEY=<YOUR_KEY>\n```\n\n----------------------------------------\n\nTITLE: Authenticating Google Cloud via Service Account Key (Bash)\nDESCRIPTION: Sets the required environment variable `GOOGLE_APPLICATION_CREDENTIALS` to the file path of a service account JSON key. This method authenticates applications running in environments where the gcloud CLI is not ideal.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/vertexai.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nGOOGLE_APPLICATION_CREDENTIALS=\"<Path to credentials.json>\"\n```\n\n----------------------------------------\n\nTITLE: Installing embedjs Vertex AI Addon (Bash)\nDESCRIPTION: Installs the specific npm package required to use Google Vertex AI models within the embedjs framework. This command should be run in the project's root directory.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/vertexai.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-vertexai\n```\n\n----------------------------------------\n\nTITLE: Installing LanceDB Addon using npm Bash\nDESCRIPTION: Installs the LanceDB addon package for EmbedJs with npm. This command is a prerequisite step to enable LanceDB integration in an EmbedJs project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/lancedb.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-lancedb\n```\n\n----------------------------------------\n\nTITLE: Installing HNSWLib Addon for EmbedJS Using Bash\nDESCRIPTION: This snippet provides the command to install the HNSWLib addon package for EmbedJS using npm. It requires npm to be installed and assumes a Node.js environment. The installed package enables usage of the HNSWLib vectorstore in EmbedJS projects.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/hnswlib.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-hnswlib\n```\n\n----------------------------------------\n\nTITLE: Installing Sitemap Loader Addon with npm in Bash\nDESCRIPTION: This bash command installs the @llm-tools/embedjs-loader-sitemap package using npm. The SitemapLoader is required to enable sitemap XML ingestion into EmbedJS-compatible projects. The user must have Node.js and npm installed; no additional parameters are necessary.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/sitemap.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-sitemap\n```\n\n----------------------------------------\n\nTITLE: Installing YouTube Addon for EmbedJS (Bash)\nDESCRIPTION: This command installs the YouTube addon for the EmbedJS library. It uses npm, the Node.js package manager, to download and install the necessary package. The dependency `@llm-tools/embedjs-loader-youtube` is installed which enables the functionality to load YouTube channel videos.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-channel.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-youtube\n```\n\n----------------------------------------\n\nTITLE: Installing Azure OpenAI Addon (Bash)\nDESCRIPTION: Command to install the specific npm package that provides Azure OpenAI integration for embedjs. This package is a prerequisite for using Azure OpenAI embeddings within your embedjs application.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/azure-openai.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-openai\n```\n\n----------------------------------------\n\nTITLE: Installing XML Loader Addon for EmbedJS\nDESCRIPTION: This snippet shows how to install the EmbedJS XML loader addon via npm, which is a prerequisite to enable XML data processing within EmbedJS applications.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/xml.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-xml\n```\n\n----------------------------------------\n\nTITLE: Installing embedjs Hugging Face Addon (Bash)\nDESCRIPTION: This Bash command installs the @llm-tools/embedjs-huggingface addon from npm, a dependency used to interface with Hugging Face embedding models via embedjs. Running this command ensures the addon is available for use in your JavaScript or TypeScript project. Requires a working npm environment and an initialized Node.js project.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/embeddings/huggingface.mdx#_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\nnpm install @llm-tools/embedjs-huggingface\n```\n\n----------------------------------------\n\nTITLE: Installing Youtube Search Loader NPM Package - Bash\nDESCRIPTION: This command installs the necessary npm package containing the YoutubeSearchLoader. It is a prerequisite for using the loader in your project. Ensure Node.js and npm are installed on your system.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/data-sources/youtube-search.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-loader-youtube\n```\n\n----------------------------------------\n\nTITLE: Installing AstraDB EmbedJS Package via npm in Bash\nDESCRIPTION: This snippet demonstrates how to install the AstraDB embedjs package using npm, which is a prerequisite for integrating AstraDB into a JavaScript project. It ensures the package is available for importing in your code.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/astradb.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-astradb\n```\n\n----------------------------------------\n\nTITLE: Installing the EmbedJs LibSQL Extension (npm)\nDESCRIPTION: Installs the necessary npm package `@llm-tools/embedjs-libsql` to enable LibSQL integration within an EmbedJs application. This package provides the `LibSqlDb` class for vector storage.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/libsql.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-libsql\n```\n\n----------------------------------------\n\nTITLE: Installing Redis addon for @llm-tools/embedjs\nDESCRIPTION: This snippet shows the command to install the Redis addon package for @llm-tools/embedjs using npm, enabling Redis support as a data store for applications.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/redis.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-redis\n```\n\n----------------------------------------\n\nTITLE: Installing @llm-tools/embedjs-openai package using npm\nDESCRIPTION: This snippet shows how to install the OpenAI addon package necessary for integrating Azure OpenAI services into a JavaScript or TypeScript project. It simplifies setup by managing dependencies via npm.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/llms/azure-openai.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-openai\n```\n\n----------------------------------------\n\nTITLE: Installing LibSQL Addon for embedjs - Bash\nDESCRIPTION: Installs the @llm-tools/embedjs-libsql package using npm, enabling LibSQL-based storage support for the embedjs framework. Requires Node.js/npm to be installed on the local environment prior to execution. Execute this command in your project's root directory to add the dependency; no code changes will occur until the package is imported.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/libsql.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-libsql\n```\n\n----------------------------------------\n\nTITLE: Installing Pinecone Addon with npm (Bash)\nDESCRIPTION: This command installs the `@llm-tools/embedjs-pinecone` package using npm. This package provides the integration layer for using Pinecone as a vector database backend with `@llm-tools/embedjs`. Note that while this document is about Qdrant, this specific snippet shows the installation for Pinecone, likely an error in the source text. It is typically run in the project's terminal.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/vector-databases/qdrant.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @llm-tools/embedjs-pinecone\n```\n\n----------------------------------------\n\nTITLE: Running Mintlify Documentation Server - Bash\nDESCRIPTION: This snippet demonstrates how to start the Mintlify documentation server in development mode.  It assumes that Mintlify is installed and the user is in the `docs/` directory. The command `npx mintlify dev` starts a local server, typically on port 3000. The output is the documentation website available at http://localhost:3000.  No specific dependencies beyond the Mintlify CLI are required.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/contribution/docs.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx mintlify dev\n```\n\n----------------------------------------\n\nTITLE: Displaying supported data stores using React components\nDESCRIPTION: This React code snippet renders a group of cards, each representing a supported data store for EmbedJs. It provides navigation links to detailed documentation for each store type, helping users select or learn about available persistence options.\nSOURCE: https://github.com/llm-tools/embedjs/blob/main/docs/components/stores/overview.mdx#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\n<CardGroup cols={4}>\n    <Card title=\"LMDB\" href=\"/components/stores/lmdb\" />\n    <Card title=\"LibSQL\" href=\"/components/stores/libsql\" />\n    <Card title=\"MongoDB\" href=\"/components/stores/mongodb\" />\n    <Card title=\"Redis\" href=\"/components/stores/redis\" />\n</CardGroup>\n```"
  }
]