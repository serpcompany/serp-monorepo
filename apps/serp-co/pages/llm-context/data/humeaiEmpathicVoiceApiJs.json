[
  {
    "owner": "humeai",
    "repo": "empathic-voice-api-js",
    "content": "TITLE: Basic Implementation of Hume's EmbeddedVoice React Component\nDESCRIPTION: Example React component demonstrating how to implement the EmbeddedVoice widget with toggle functionality. Shows authentication with an API key, handling messages through callbacks, and controlling widget visibility state.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed-react/README.md#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport React, { useState } from 'react';\nimport { EmbeddedVoice } from '@humeai/voice-embed-react';\n\nfunction App() {\n  const apiKey = process.env.HUME_API_KEY || '';\n  const [isEmbedOpen, setIsEmbedOpen] = useState(false);\n\n  return (\n    <div>\n      <button onClick={() => setIsEmbedOpen(true)}>Open Widget</button>\n      <EmbeddedVoice\n        auth={{ type: 'apiKey', value: apiKey }}\n        onMessage={(msg) => console.log('Message received: ', msg)}\n        onClose={() => setIsEmbedOpen(false)}\n        isEmbedOpen={isEmbedOpen}\n      />\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Basic VoiceProvider Setup\nDESCRIPTION: Example showing how to implement the VoiceProvider component with basic configuration including API key authentication.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport { VoiceProvider } from '@humeai/voice-react';\n\nfunction App() {\n  const apiKey = process.env.HUME_API_KEY;\n\n  return (\n    <VoiceProvider\n      auth={{ type: 'apiKey', value: apiKey }}\n      configId={/* Optional: Your EVI Configuration ID */}\n    >\n      {/* ... */}\n    </VoiceProvider>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring EmbeddedVoice Instance\nDESCRIPTION: Example of how to create and configure an instance of the EmbeddedVoice component. This code imports the necessary types and the EmbeddedVoice class, then instantiates it with configuration options.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed/README.md#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport {\n  type CloseHandler,\n  EmbeddedVoice as EA,\n  type EmbeddedVoiceConfig,\n  type TranscriptMessageHandler,\n} from '@humeai/voice-embed';\n\nconst embeddedVoice = EA.create({\n  // Configuration options\n});\n```\n\n----------------------------------------\n\nTITLE: Start Call Button Implementation\nDESCRIPTION: Example of creating a button component that uses the useVoice hook to initiate a voice call.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useVoice } from '@humeai/voice-react';\n\nexport function StartCallButton() {\n  const { connect } = useVoice();\n\n  return <button onClick={() => connect()}>Start Call</button>;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining AudioConstraints Type in TypeScript\nDESCRIPTION: Specifies the AudioConstraints type, which includes optional boolean flags for echo cancellation, noise suppression, and automatic gain control when configuring audio input.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nexport type AudioConstraints = {\n  /** Reduce echo from the input (if supported). Defaults to `true`. */\n  echoCancellation?: boolean;\n  /** Suppress background noise (if supported). Defaults to `true`.*/\n  noiseSuppression?: boolean;\n  /** Automatically adjust microphone gain (if supported). Defaults to `true`. */\n  autoGainControl?: boolean;\n};\n```\n\n----------------------------------------\n\nTITLE: Defining ConnectOptions Type in TypeScript\nDESCRIPTION: Defines the ConnectOptions type, which includes optional audioConstraints for customizing microphone stream settings when connecting to the voice client.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nexport type ConnectOptions = {\n  /** Custom audio constraints passed to navigator.getUserMedia to get the microphone stream */\n  audioConstraints?: AudioConstraints;\n};\n```\n\n----------------------------------------\n\nTITLE: Configuring ESLint Parser Options for TypeScript in React Vite Project\nDESCRIPTION: This snippet demonstrates how to configure the top-level parserOptions property in an ESLint configuration file for a React TypeScript project. It sets the ECMAScript version, defines the source type as module, and specifies the TypeScript configuration files to use for type-aware linting.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/examples/vite-app-embed/README.md#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport default {\n  // other rules...\n  parserOptions: {\n    ecmaVersion: 'latest',\n    sourceType: 'module',\n    project: ['./tsconfig.json', './tsconfig.node.json'],\n    tsconfigRootDir: __dirname,\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Setting up Local Development with Turborepo\nDESCRIPTION: Commands for setting up local development environment using Turborepo. This installs all dependencies with pnpm and starts the development server for all SDK packages and example applications.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Running Next.js Development Server with Package Managers\nDESCRIPTION: Commands to start the Next.js development server using different package managers. After running any of these commands, the application will be available at http://localhost:3000.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/examples/next-app/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Installing Hume Voice Embed React Package\nDESCRIPTION: Command to install the @humeai/voice-embed-react package using npm. This adds the package to the project dependencies, making it available for import in React components.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed-react/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @humeai/voice-embed-react\n```\n\n----------------------------------------\n\nTITLE: Installing Voice React Package\nDESCRIPTION: NPM command to install the @humeai/voice-react package in a project.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @humeai/voice-react\n```\n\n----------------------------------------\n\nTITLE: Installing Empathic Voice Embed SDK via npm\nDESCRIPTION: Command to install the @humeai/voice-embed package to your project using npm. This will add the package to your project's dependencies.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @humeai/voice-embed\n```\n\n----------------------------------------\n\nTITLE: Importing Voice Provider\nDESCRIPTION: Example of importing the VoiceProvider component from the package.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { VoiceProvider } from '@humeai/voice-react';\n```\n\n----------------------------------------\n\nTITLE: Importing EmbeddedVoice Component in JavaScript/TypeScript\nDESCRIPTION: Basic import statement to bring in the EmbeddedVoice component from the @humeai/voice-embed package into your JavaScript or TypeScript code.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed/README.md#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { EmbeddedVoice } from '@humeai/voice-embed';\n```\n\n----------------------------------------\n\nTITLE: Importing EmbeddedVoice Component from Hume Package\nDESCRIPTION: Code snippet showing how to import the EmbeddedVoice component from the @humeai/voice-embed-react package for use in a React application.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed-react/README.md#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { EmbeddedVoice } from '@humeai/voice-embed-react';\n```\n\n----------------------------------------\n\nTITLE: Checking Node Version\nDESCRIPTION: Command to verify the installed Node.js version, which must be v18.0.0 or higher.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/react/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnode --version\n```\n\n----------------------------------------\n\nTITLE: Verifying Node.js Version for Empathic Voice Embed SDK\nDESCRIPTION: Command to check the Node.js version installed on your system. The package requires Node.js v18.0.0 or higher to function properly.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnode --version\n```\n\n----------------------------------------\n\nTITLE: Verifying Node.js Version for Hume Voice Embed Integration\nDESCRIPTION: Command to check the installed Node.js version to ensure compatibility with the @humeai/voice-embed-react package. The package requires Node.js v18.0.0 or higher.\nSOURCE: https://github.com/humeai/empathic-voice-api-js/blob/main/packages/embed-react/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnode --version\n```"
  }
]