[
  {
    "owner": "pydantic",
    "repo": "logfire",
    "content": "TITLE: Instrumenting FastAPI with Logfire in Python\nDESCRIPTION: This example demonstrates how to instrument a FastAPI application with Logfire. It shows the setup of a simple FastAPI app with a User model, configures Logfire, and instruments FastAPI with just two lines of code.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/why.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nimport logfire\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\nlogfire.configure()\nlogfire.instrument_fastapi(app)\n\n\nclass User(BaseModel):\n    name: str\n    country_code: str\n    dob: date\n\n\n@app.post('/')\nasync def add_user(user: User):\n    # we would store the user here\n    return {'message': f'{user.name} added'}\n```\n\n----------------------------------------\n\nTITLE: Integrating Logfire with FastAPI\nDESCRIPTION: Example of how to integrate Logfire with a FastAPI application. It demonstrates configuration, instrumentation, and a simple endpoint.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/fastapi.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\nlogfire.configure()\nlogfire.instrument_fastapi(app)\n\n\n@app.get(\"/hello\")\nasync def hello(name: str):\n    return {\"message\": f\"hello {name}\"}\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Using f-strings with Logfire in Python 3.11+\nDESCRIPTION: Demonstrates the use of f-strings with Logfire, which automatically sets span names and attributes in Python 3.11+. This feature simplifies logging with variable data.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlogfire.info(f'Hello {name}')\n```\n\n----------------------------------------\n\nTITLE: Implementing Logfire with a Standard Python Logger Example\nDESCRIPTION: Complete example showing how to integrate Logfire with a standard Python logger in a main.py file. This demonstrates configuring Logfire and using a logger instance to record an error message.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/integrate.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom logging import basicConfig, getLogger\n\nimport logfire\n\nlogfire.configure()\nbasicConfig(handlers=[logfire.LogfireLoggingHandler()])\n\nlogger = getLogger(__name__)\nlogger.error(\"Hello %s!\", \"Fred\")\n```\n\n----------------------------------------\n\nTITLE: Integrating Logfire with FastAPI\nDESCRIPTION: Example showing how to integrate Logfire with FastAPI, including configuration, instrumentation, and a sample endpoint with Pydantic models.\nSOURCE: https://github.com/pydantic/logfire/blob/main/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\nlogfire.configure()\nlogfire.instrument_fastapi(app)\n# next, instrument your database connector, http library etc. and add the logging handler\n\nclass User(BaseModel):\n    name: str\n    country_code: str\n\n@app.post('/')\nasync def add_user(user: User):\n    # we would store the user here\n    return {'message': f'{user.name} added'}\n```\n\n----------------------------------------\n\nTITLE: Creating a Histogram Metric for Request Duration in Python\nDESCRIPTION: This snippet shows how to create a histogram metric to measure request durations. Histogram metrics are useful for tracking the distribution of values like response times, file sizes, or item counts.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nhistogram = logfire.metric_histogram(\n    'request_duration',\n    unit='ms',  # (1)!\n    description='Duration of requests'\n)\n\nfor duration in [10, 20, 30, 40, 50]:\n    histogram.record(duration)\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire with Python Standard Library Logging\nDESCRIPTION: This snippet shows how to configure Logfire to work with Python's standard library logging. It sets up a basic configuration using Logfire's LogfireLoggingHandler and demonstrates logging an error message.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/logging.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom logging import basicConfig, getLogger\n\nimport logfire\n\nlogfire.configure()\nbasicConfig(handlers=[logfire.LogfireLoggingHandler()])\n\nlogger = getLogger(__name__)\n\nlogger.error(\"Hello %s!\", \"Fred\")\n# 10:05:06.855 Hello Fred!\n```\n\n----------------------------------------\n\nTITLE: Instrumenting OpenAI Agents with Function Tools and HTTPX\nDESCRIPTION: Advanced example of instrumenting OpenAI Agents with custom function tools and nested HTTP requests using HTTPX. This demonstrates how Logfire captures the entire execution chain including external API calls.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/openai.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom typing_extensions import TypedDict\n\nimport logfire\nfrom httpx import AsyncClient\nfrom agents import RunContextWrapper, Agent, function_tool, Runner\n\nlogfire.configure()\nlogfire.instrument_openai_agents()\n\n\nclass Location(TypedDict):\n    lat: float\n    long: float\n\n\n@function_tool\nasync def fetch_weather(ctx: RunContextWrapper[AsyncClient], location: Location) -> str:\n    \"\"\"Fetch the weather for a given location.\n\n    Args:\n        ctx: Run context object.\n        location: The location to fetch the weather for.\n    \"\"\"\n    r = await ctx.context.get('https://httpbin.org/get', params=location)\n    return 'sunny' if r.status_code == 200 else 'rainy'\n\n\nagent = Agent(name='weather agent', tools=[fetch_weather])\n\n\nasync def main():\n    async with AsyncClient() as client:\n        logfire.instrument_httpx(client)\n        result = await Runner.run(agent, 'Get the weather at lat=51 lng=0.2', context=client)\n    print(result.final_output)\n\n\nif __name__ == '__main__':\n    import asyncio\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating an Up-Down Counter Metric for Active Users in Python\nDESCRIPTION: This example demonstrates an up-down counter that can track both increments and decrements, useful for monitoring active user counts. The counter increases when users log in and decreases when they log out.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nactive_users = logfire.metric_up_down_counter(\n    'active_users',\n    unit='1',  # (1)!\n    description='Number of active users'\n)\n\ndef user_logged_in():\n    active_users.add(1)\n\ndef user_logged_out():\n    active_users.add(-1)\n```\n\n----------------------------------------\n\nTITLE: Nested Spans with Logfire and Logging in Python\nDESCRIPTION: This snippet shows the use of nested spans in Logfire and how they respect the highest level of error logging. It demonstrates how nested spans display colors based on their log levels in the Live view.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nwith logfire.span('Outer span'):\n    with logfire.span('Inner span'):\n        logfire.info('This is an info message')\n        logfire.error('This is an error message')\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Scrubbing Patterns in Logfire SDK (Python)\nDESCRIPTION: This example shows how to add custom patterns for scrubbing sensitive data. It uses the ScrubbingOptions class to define extra patterns and demonstrates how different types of data will be redacted based on these patterns.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/scrubbing.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(scrubbing=logfire.ScrubbingOptions(extra_patterns=['my_pattern']))\n\nlogfire.info('Hello', data={\n    'key_matching_my_pattern': 'This string will be redacted because its key matches',\n    'other_key': 'This string will also be redacted because it matches MY_PATTERN case-insensitively',\n    'password': 'This will be redacted because custom patterns are combined with the default patterns',\n})\n```\n\n----------------------------------------\n\nTITLE: Creating a Counter Metric with Exception Tracking in Python\nDESCRIPTION: This example shows how to create a counter metric with a unit and description to track exceptions. The counter is incremented each time an exception is caught, providing a way to monitor error frequency.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\ncounter = logfire.metric_counter(\n    'exceptions',\n    unit='1',  # (1)!\n    description='Number of exceptions caught'\n)\n\ntry:\n    raise Exception('oops')\nexcept Exception:\n    counter.add(1)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting OpenAI Client with Logfire\nDESCRIPTION: Basic example of how to instrument the OpenAI SDK client to monitor chat completions. This captures the duration of API calls, conversation details, and response metrics including token usage.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/openai.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nimport logfire\n\nclient = openai.Client()\n\nlogfire.configure()\nlogfire.instrument_openai(client)  # (1)!\n\nresponse = client.chat.completions.create(\n    model='gpt-4',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'Please write me a limerick about Python logging.'},\n    ],\n)\nprint(response.choices[0].message)\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual Tracing with Logfire in Python\nDESCRIPTION: A basic example of manual tracing using Logfire, showing how to configure Logfire, log messages, create spans, and capture variables including date objects.\nSOURCE: https://github.com/pydantic/logfire/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom datetime import date\n\nlogfire.configure()\nlogfire.info('Hello, {name}!', name='world')\n\nwith logfire.span('Asking the user their {question}', question='age'):\n    user_input = input('How old are you [YYYY-mm-dd]? ')\n    dob = date.fromisoformat(user_input)\n    logfire.debug('{dob=} {age=!r}', dob=dob, age=date.today() - dob)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting AIOHTTP Client with Logfire in Python\nDESCRIPTION: Demonstrates how to configure Logfire, instrument the AIOHTTP client, and make an asynchronous HTTP request. This creates a span for each request made by the AIOHTTP client.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/aiohttp.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nimport aiohttp\n\n\nlogfire.configure()\nlogfire.instrument_aiohttp_client()\n\n\nasync def main():\n    async with aiohttp.ClientSession() as session:\n        await session.get(\"https://httpbin.org/get\")\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Instrumenting ASGI Application with Logfire in Python\nDESCRIPTION: This example demonstrates how to instrument an ASGI application using Logfire. It configures Logfire, defines a simple ASGI app that returns 'Hello, world!', wraps the app with logfire.instrument_asgi(), and runs it using Uvicorn.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/asgi.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n\nlogfire.configure()\n\n\nasync def app(scope, receive, send):\n    assert scope[\"type\"] == \"http\"\n    await send(\n        {\n            \"type\": \"http.response.start\",\n            \"status\": 200,\n            \"headers\": [(b\"content-type\", b\"text/plain\"), (b\"content-length\", b\"13\")],\n        }\n    )\n    await send({\"type\": \"http.response.body\", \"body\": b\"Hello, world!\"})\n\napp = logfire.instrument_asgi(app)\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Suppressing Instrumentation in Logfire with Python\nDESCRIPTION: This example shows how to use the suppress_instrumentation context manager to suppress spans from a specific part of the code, such as HTTPX client requests.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/suppress.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nimport logfire\n\nlogfire.configure()\n\nclient = httpx.Client()\nlogfire.instrument_httpx(client)\n\n# The span generated will be sent to Logfire.\nclient.get(\"https://httpbin.org/get\")\n\n# The span generated will NOT be sent to Logfire.\nwith logfire.suppress_instrumentation():\n    client.get(\"https://httpbin.org/get\")\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Specific SQLite3 Connection with Logfire in Python\nDESCRIPTION: Shows how to instrument a specific SQLite3 connection using Logfire. It configures Logfire, creates a connection, instruments it, and performs database operations.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/sqlite3.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport sqlite3\n\nimport logfire\n\nlogfire.configure()\n\nwith sqlite3.connect(':memory:') as connection:\n    connection = logfire.instrument_sqlite3(connection)\n    cursor = connection.cursor()\n\n    cursor.execute('CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)')\n    cursor.execute(\"INSERT INTO users (name) VALUES ('Alice')\")\n\n    cursor.execute('SELECT * FROM users')\n    print(cursor.fetchall())\n    # > [(1, 'Alice')]\n```\n\n----------------------------------------\n\nTITLE: Instrumenting OpenAI Streaming Responses with Rich UI\nDESCRIPTION: Example of instrumenting streaming responses from OpenAI with real-time rendering in the terminal using Rich. Creates two spans - one for the initial request and one for the streamed response.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/openai.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nimport logfire\nfrom rich.console import Console\nfrom rich.live import Live\nfrom rich.markdown import Markdown\n\nclient = openai.AsyncClient()\nlogfire.configure()\nlogfire.instrument_openai(client)\n\nasync def main():\n    console = Console()\n    with logfire.span('Asking OpenAI to write some code'):\n        response = await client.chat.completions.create(\n            model='gpt-4',\n            messages=[\n                {'role': 'system', 'content': 'Reply in markdown one.'},\n                {'role': 'user', 'content': 'Write Python to show a tree of files 🤞.'},\n            ],\n            stream=True\n        )\n        content = ''\n        with Live('', refresh_per_second=15, console=console) as live:\n            async for chunk in response:\n                if chunk.choices[0].delta.content is not None:\n                    content += chunk.choices[0].delta.content\n                    live.update(Markdown(content))\n\nif __name__ == '__main__':\n    import asyncio\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Flask Application with Logfire\nDESCRIPTION: A minimal example demonstrating how to integrate Logfire with a Flask application. It configures Logfire, creates a Flask app, instruments it, and defines a simple route.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/flask.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom flask import Flask\n\n\nlogfire.configure()\n\napp = Flask(__name__)\nlogfire.instrument_flask(app)\n\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello!\"\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Streaming Anthropic Responses with Logfire and Rich in Python\nDESCRIPTION: This snippet shows how to instrument streaming responses from Anthropic using Logfire. It uses Rich's Live and Markdown types to render the response in real-time in the terminal.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/anthropic.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport anthropic\nimport logfire\nfrom rich.console import Console\nfrom rich.live import Live\nfrom rich.markdown import Markdown\n\nclient = anthropic.AsyncAnthropic()\nlogfire.configure()\nlogfire.instrument_anthropic(client)\n\n\nasync def main():\n    console = Console()\n    with logfire.span('Asking Anthropic to write some code'):\n        response = client.messages.stream(\n            max_tokens=1000,\n            model='claude-3-haiku-20240307',\n            system='Reply in markdown one.',\n            messages=[{'role': 'user', 'content': 'Write Python to show a tree of files 🤞.'}],\n        )\n        content = ''\n        with Live('', refresh_per_second=15, console=console) as live:\n            async with response as stream:\n                async for chunk in stream:\n                    if chunk.type == 'content_block_delta':\n                        content += chunk.delta.text\n                        live.update(Markdown(content))\n\n\nif __name__ == '__main__':\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Redis Client with Logfire in Python\nDESCRIPTION: Python script demonstrating how to configure Logfire, instrument Redis, and perform synchronous and asynchronous Redis operations.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/redis.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nimport redis\n\n\nlogfire.configure()\nlogfire.instrument_redis()\n\nclient = redis.StrictRedis(host=\"localhost\", port=6379)\nclient.set(\"my-key\", \"my-value\")\n\nasync def main():\n    client = redis.asyncio.Redis(host=\"localhost\", port=6379)\n    await client.get(\"my-key\")\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating an Up-Down Counter Callback Metric for Active Users in Python\nDESCRIPTION: This example shows an up-down counter callback metric that automatically tracks the number of active users. It uses a callback function to retrieve the active user count and reports it as an observation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n\ndef get_active_users() -> int:\n    ...\n\n\ndef active_users_callback(options: CallbackOptions) -> Iterable[Observation]:\n    active_users = get_active_users()\n    yield Observation(active_users, {})\n\n\nlogfire.metric_up_down_counter_callback(\n    'active_users',\n    unit='1',\n    callbacks=[active_users_callback],\n    description='Number of active users',\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Spans and Logs with Logfire in Python\nDESCRIPTION: Demonstrates how to create a span and log within it using Logfire. The example shows timing operations and logging info within a span.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nimport logfire\n\nlogfire.configure()\n\nwith logfire.span('This is a span'):\n    time.sleep(1)\n    logfire.info('This is an info log')\n    time.sleep(2)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Synchronous Stripe Requests with Logfire in Python\nDESCRIPTION: This code shows how to instrument synchronous Stripe requests using Logfire. It configures Logfire and instruments the requests library, which is used by default for synchronous Stripe API calls.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/stripe.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport logfire\nfrom stripe import StripeClient\n\nlogfire.configure()\nlogfire.instrument_requests()\n\nclient = StripeClient(api_key=os.getenv('STRIPE_SECRET_KEY'))\n\nclient.customers.list()\n```\n\n----------------------------------------\n\nTITLE: Querying BigQuery with Logfire Instrumentation in Python\nDESCRIPTION: This example shows how to use the Google Cloud BigQuery client with Logfire instrumentation. It sets up the Logfire configuration and performs a simple query on a public BigQuery dataset.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/bigquery.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.cloud import bigquery\n\nimport logfire\n\nlogfire.configure()\n\nclient = bigquery.Client()\nquery = \"\"\"\nSELECT name\nFROM `bigquery-public-data.usa_names.usa_1910_2013`\nWHERE state = \"TX\"\nLIMIT 100\n\"\"\"\nquery_job = client.query(query)\nprint(list(query_job.result()))\n```\n\n----------------------------------------\n\nTITLE: Instrumenting asyncpg with Logfire in Python\nDESCRIPTION: This Python script demonstrates how to use Logfire to instrument asyncpg. It connects to a PostgreSQL database, creates a table, inserts data, and queries the data while using Logfire for logging and instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/asyncpg.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nimport asyncpg\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_asyncpg()\n\n\nasync def main():\n    connection: asyncpg.Connection = await asyncpg.connect(\n        user='user', password='secret', database='database', host='0.0.0.0', port=5432\n    )\n\n    with logfire.span('Create table and insert data'):\n        await connection.execute('CREATE TABLE IF NOT EXISTS test (id serial PRIMARY KEY, num integer, data varchar);')\n\n        # Insert some data\n        await connection.execute('INSERT INTO test (num, data) VALUES ($1, $2)', 100, 'abc')\n        await connection.execute('INSERT INTO test (num, data) VALUES ($1, $2)', 200, 'def')\n\n        # Query the data\n        for record in await connection.fetch('SELECT * FROM test'):\n            logfire.info('Retrieved {record=}', record=record)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire with Python's Standard Logging Module\nDESCRIPTION: Minimal configuration for integrating Logfire with Python's standard library logging module using LogfireLoggingHandler.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/integrate.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom logging import basicConfig\n\nimport logfire\n\nlogfire.configure()\nbasicConfig(handlers=[logfire.LogfireLoggingHandler()])\n```\n\n----------------------------------------\n\nTITLE: Instrumenting SQLAlchemy Engine with Logfire\nDESCRIPTION: Python script demonstrating how to configure Logfire and instrument a SQLAlchemy engine. This creates a span for every query executed by the engine.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/sqlalchemy.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom sqlalchemy import create_engine\n\nlogfire.configure()\n\nengine = create_engine(\"sqlite:///:memory:\")\nlogfire.instrument_sqlalchemy(engine=engine)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting PydanticAI with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to configure Logfire, instrument PydanticAI, create a roulette agent, and run the agent with different inputs. It shows the use of the `logfire.instrument_pydantic_ai()` method and the creation of a tool function for the agent.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/pydanticai.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom pydantic_ai import Agent, RunContext\n\nlogfire.configure()\nlogfire.instrument_pydantic_ai()\n\nroulette_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=int,\n    result_type=bool,\n    system_prompt=(\n        'Use the `roulette_wheel` function to see if the '\n        'customer has won based on the number they provide.'\n    ),\n)\n\n\n@roulette_agent.tool\nasync def roulette_wheel(ctx: RunContext[int], square: int) -> str:\n    \"\"\"check if the square is a winner\"\"\"\n    return 'winner' if square == ctx.deps else 'loser'\n\n\n# Run the agent\nsuccess_number = 18\nresult = roulette_agent.run_sync('Put my money on square eighteen', deps=success_number)\nprint(result.data)\n#> True\n\nresult = roulette_agent.run_sync('I bet five is the winner', deps=success_number)\nprint(result.data)\n#> False\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Asynchronous Stripe Requests with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to instrument asynchronous Stripe requests using Logfire. It configures Logfire, instruments the httpx library (used for async requests), and shows an example of an async Stripe API call within a Logfire span.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/stripe.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport os\n\nimport logfire\nfrom stripe import StripeClient\n\nlogfire.configure()\nlogfire.instrument_httpx()     # for asynchronous requests\n\nclient = StripeClient(api_key=os.getenv('STRIPE_SECRET_KEY'))\n\nasync def main():\n    with logfire.span('list async'):\n        await client.customers.list_async()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire SDK via Command Line\nDESCRIPTION: Command to install the Logfire SDK package using pip. This is the first step after creating a Logfire account and project.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nlogfire -h\n```\n\n----------------------------------------\n\nTITLE: Instrumenting a Function with Logfire Decorator in Python\nDESCRIPTION: This snippet demonstrates how to use the `@logfire.instrument` decorator to wrap a function in a logging span. By default, it captures function arguments as attributes, and it can be customized with a custom span name.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(x, y):\n    with logfire.span('my_function', x=x, y=y):\n        ...\n\n@logfire.instrument()\ndef my_function(x, y):\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\n@logfire.instrument('Applying my_function to {x=} and {y=}')\ndef my_function(x, y):\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\nmy_function(3, 4)\n# Logs: Applying my_function to x=3 and y=4\n```\n\n----------------------------------------\n\nTITLE: Customizing Scrubbing with Callback in Logfire SDK (Python)\nDESCRIPTION: This snippet illustrates how to use a callback function to fine-tune the scrubbing process. The callback function allows for preventing certain data from being redacted based on custom logic.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/scrubbing.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\ndef scrubbing_callback(match: logfire.ScrubMatch):\n    # `my_safe_value` often contains the string 'password' but it's not actually sensitive.\n    if match.path == ('attributes', 'my_safe_value') and match.pattern_match.group(0) == 'password':\n        # Return the original value to prevent redaction.\n        return match.value\n\nlogfire.configure(scrubbing=logfire.ScrubbingOptions(callback=scrubbing_callback))\n```\n\n----------------------------------------\n\nTITLE: Instrumenting PyMongo with Logfire (Synchronous)\nDESCRIPTION: Python script demonstrating how to use Logfire to instrument PyMongo operations. It configures Logfire, instruments PyMongo, connects to a MongoDB database, inserts a document, and performs a query.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/pymongo.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom pymongo import MongoClient\n\nlogfire.configure()\nlogfire.instrument_pymongo()\n\nclient = MongoClient()\ndb = client[\"database\"]\ncollection = db[\"collection\"]\ncollection.insert_one({\"name\": \"MongoDB\"})\ncollection.find_one()\n```\n\n----------------------------------------\n\nTITLE: Testing Observability with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to test spans and log emissions in a Pytest environment using the `Logfire` library. The `CaptureLogfire` fixture is used to capture spans in memory for verification. It also showcases using the `inline_snapshot` package for handling large snapshot outputs during testing.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/testing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\n\nimport logfire\nfrom inline_snapshot import snapshot\nfrom logfire.testing import CaptureLogfire\n\n\ndef test_observability(capfire: CaptureLogfire) -> None:\n    with pytest.raises(Exception):\n        with logfire.span('a span!'):\n            logfire.info('a log!')\n            raise Exception('an exception!')\n\n    exporter = capfire.exporter\n\n    assert exporter.exported_spans_as_dict() == snapshot(  # (1)!\n        [\n            {\n                'name': 'a log!',\n                'context': {'trace_id': 1, 'span_id': 3, 'is_remote': False},\n                'parent': {'trace_id': 1, 'span_id': 1, 'is_remote': False},\n                'start_time': 2000000000,\n                'end_time': 2000000000,\n                'attributes': {\n                    'logfire.span_type': 'log',\n                    'logfire.level_num': 9,\n                    'logfire.msg_template': 'a log!',\n                    'logfire.msg': 'a log!',\n                    'code.filepath': 'test.py',\n                    'code.lineno': 123,\n                    'code.function': 'test_observability',\n                },\n            },\n            {\n                'name': 'a span!',\n                'context': {'trace_id': 1, 'span_id': 1, 'is_remote': False},\n                'parent': None,\n                'start_time': 1000000000,\n                'end_time': 4000000000,\n                'attributes': {\n                    'code.filepath': 'test.py',\n                    'code.lineno': 123,\n                    'code.function': 'test_observability',\n                    'logfire.msg_template': 'a span!',\n                    'logfire.span_type': 'span',\n                    'logfire.msg': 'a span!',\n                },\n                'events': [\n                    {\n                        'name': 'exception',\n                        'timestamp': 3000000000,\n                        'attributes': {\n                            'exception.type': 'Exception',\n                            'exception.message': 'an exception!',\n                            'exception.stacktrace': 'Exception: an exception!',\n                            'exception.escaped': 'True',\n                        },\n                    }\n                ],\n            },\n        ]\n    )\n\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Celery Worker and Beat with Logfire\nDESCRIPTION: Extended Python code that instruments both Celery worker and beat processes using Logfire. It configures Logfire for both processes, sets up a periodic task, and defines the task function.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/celery.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom celery import Celery\nfrom celery.signals import worker_init, beat_init\n\n\n@worker_init.connect()\ndef init_worker(*args, **kwargs):\n    logfire.configure(service_name=\"worker\")\n    logfire.instrument_celery()\n\n@beat_init.connect()  # (1)!\ndef init_beat(*args, **kwargs):\n    logfire.configure(service_name=\"beat\")  # (2)!\n    logfire.instrument_celery()\n\napp = Celery(\"tasks\", broker=\"redis://localhost:6379/0\")\napp.conf.beat_schedule = {  # (3)!\n    \"add-every-30-seconds\": {\n        \"task\": \"tasks.add\",\n        \"schedule\": 30.0,\n        \"args\": (16, 16),\n    },\n}\n\n@app.task\ndef add(x: int, y: int):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Automatic Pydantic Validation Recording with Logfire in Python\nDESCRIPTION: This code snippet shows how to configure Logfire to automatically record information about Pydantic model validations. It sets up Logfire, instruments Pydantic, and creates several User instances to demonstrate the automatic recording.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/why.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nimport logfire\nfrom pydantic import BaseModel\n\nlogfire.configure()\nlogfire.instrument_pydantic()\n\nclass User(BaseModel):\n    name: str\n    country_code: str\n    dob: date\n\nUser(name='Anne', country_code='USA', dob='2000-01-01')\nUser(name='Ben', country_code='USA', dob='2000-02-02')\nUser(name='Charlie', country_code='GBR', dob='1990-03-03')\n```\n\n----------------------------------------\n\nTITLE: Integrating Magentic with Logfire for LLM Observability\nDESCRIPTION: This code snippet demonstrates how to use Magentic with Logfire instrumentation to create a superhero using an LLM. It shows configuration of Logfire, defining a Pydantic model with validation, and creating a chatprompt-decorated function that interacts with OpenAI's GPT-4o model. The example includes retry logic and validation to ensure proper response formatting.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/magentic.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nimport logfire\nfrom magentic import chatprompt, OpenaiChatModel, SystemMessage, UserMessage\nfrom pydantic import BaseModel, Field\nfrom pydantic.functional_validators import AfterValidator\n\nlogfire.configure()\nlogfire.instrument_openai()\n\n\ndef assert_upper(value: str) -> str:\n    if not value.isupper():\n        raise ValueError('Value must be upper case')\n    return value\n\n\nclass Superhero(BaseModel):\n    name: Annotated[str, AfterValidator(assert_upper)]\n    powers: list[str]\n    city: Annotated[str, Field(examples=[\"New York, NY\"])]\n\n\n@chatprompt(\n    SystemMessage('You are professor A, in charge of the A-people.'),\n    UserMessage('Create a new superhero named {name}.'),\n    model=OpenaiChatModel(\"gpt-4o\"),\n    max_retries=3,\n)\ndef make_superhero(name: str) -> Superhero: ...\n\n\nhero = make_superhero(\"The Bark Night\")\nprint(hero)\n```\n\n----------------------------------------\n\nTITLE: Automatic Context Propagation with ThreadPoolExecutor in Python\nDESCRIPTION: Demonstrates Logfire's automatic patching of ThreadPoolExecutor to propagate context to child threads. It shows how logs and spans in child threads are correctly associated with the parent span.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/distributed-tracing.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom concurrent.futures import ThreadPoolExecutor\n\nlogfire.configure()\n\n\n@logfire.instrument(\"Doubling {x}\")\ndef double(x: int):\n    return x * 2\n\n\nwith logfire.span(\"Doubling everything\") as span:\n    executor = ThreadPoolExecutor()\n    results = list(executor.map(double, range(3)))\n    span.set_attribute(\"results\", results)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Celery Worker with Logfire\nDESCRIPTION: Python code demonstrating how to instrument a Celery worker using Logfire. It configures Logfire, sets up Celery with Redis as broker, and defines a sample task.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/celery.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom celery import Celery\nfrom celery.signals import worker_init\n\n\n@worker_init.connect()  # (1)!\ndef init_worker(*args, **kwargs):\n    logfire.configure(service_name=\"worker\")  # (2)!\n    logfire.instrument_celery()\n\napp = Celery(\"tasks\", broker=\"redis://localhost:6379/0\")  # (3)!\n\n@app.task\ndef add(x: int, y: int):\n    return x + y\n\nadd.delay(42, 50)  # (4)!\n```\n\n----------------------------------------\n\nTITLE: Extracting Structured Task Details using OpenAI's GPT-4 with Logfire and Pydantic\nDESCRIPTION: This snippet shows how to use Mirascope with OpenAI's GPT-4 model to extract structured information from text. It demonstrates the integration of Logfire for logging and Pydantic for model validation, providing enhanced observability for LLM-based information extraction.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/mirascope.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Literal, Type\n\nimport logfire\nfrom mirascope.core import openai, prompt_template\nfrom mirascope.integrations.logfire import with_logfire\nfrom pydantic import BaseModel\n\nlogfire.configure()\nlogfire.instrument_pydantic()\n\n\nclass TaskDetails(BaseModel):\n    description: str\n    due_date: str\n    priority: Literal[\"low\", \"normal\", \"high\"]\n\n\n@with_logfire()\n@openai.call(\"gpt-4o-mini\", response_model=TaskDetails)\n@prompt_template(\"Extract the details from the following task: {task}\")\ndef extract_task_details(task: str): ...\n\n\ntask = \"Submit quarterly report by next Friday. Task is high priority.\"\ntask_details = extract_task_details(task)  # this will be logged automatically with logfire\nassert isinstance(task_details, TaskDetails)\nprint(task_details)\n# > description='Submit quarterly report' due_date='next Friday' priority='high'\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Starlette Application with Logfire\nDESCRIPTION: A minimal example of a Starlette application instrumented with Logfire. It sets up a simple route, configures Logfire, and instruments the Starlette app. The example uses Uvicorn as the ASGI server.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/starlette.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom starlette.applications import Starlette\nfrom starlette.responses import PlainTextResponse\nfrom starlette.requests import Request\nfrom starlette.routing import Route\n\nlogfire.configure()\n\n\nasync def home(request: Request) -> PlainTextResponse:\n    return PlainTextResponse(\"Hello, world!\")\n\n\napp = Starlette(routes=[Route(\"/\", home)])\nlogfire.instrument_starlette(app)\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Configuring Python OpenTelemetry Exporter without Environment Variables\nDESCRIPTION: Python code snippet that shows how to programmatically configure the OpenTelemetry exporter without relying on environment variables. This approach explicitly sets the endpoint URL and authorization header.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nexporter = OTLPSpanExporter(\n    endpoint='https://logfire-api.pydantic.dev/v1/traces',\n    headers={'Authorization': 'your-write-token'},\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenTelemetry Tracing in Rust\nDESCRIPTION: Rust implementation of OpenTelemetry tracing that configures an OTLP exporter and creates a simple span. The code shows both environment variable-based configuration and programmatic configuration options with detailed comments.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nuse opentelemetry::\n    global::ObjectSafeSpan,\n    trace::{Tracer, TracerProvider},\n};\n\nfn main() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n    let otlp_exporter = opentelemetry_otlp::new_exporter()\n        .http()\n        .with_protocol(opentelemetry_otlp::Protocol::HttpBinary)\n        // If you don't want to export environment variables, you can also configure\n        // programmatically like so:\n        //\n        // (You'll need to add `use opentelemetry_otlp::WithExportConfig;` to the top of the\n        // file to access the `.with_endpoint` method.)\n        //\n        // .with_endpoint(\"https://logfire-api.pydantic.dev/v1/traces\")\n        // .with_headers({\n        //     let mut headers = std::collections::HashMap::new();\n        //     headers.insert(\n        //         \"Authorization\".into(),\n        //         \"your-write-token\".into(),\n        //     );\n        //     headers\n        // })\n        ;\n\n    let tracer_provider = opentelemetry_otlp::new_pipeline()\n        .tracing()\n        .with_exporter(otlp_exporter)\n        .install_simple()?;\n    let tracer = tracer_provider.tracer(\"my_tracer\");\n\n    tracer.span_builder(\"Hello World\").start(&tracer).end();\n\n    Ok()\n}\n```\n\n----------------------------------------\n\nTITLE: Synchronous Logfire Query Client Usage in Python\nDESCRIPTION: Shows how to use the LogfireQueryClient to execute SQL queries synchronously and retrieve data in various formats including JSON, Arrow, and CSV.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/query-api.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom io import StringIO\n\nimport polars as pl\nfrom logfire.experimental.query_client import LogfireQueryClient\n\n\ndef main():\n    query = \"\"\"\n    SELECT start_timestamp\n    FROM records\n    LIMIT 1\n    \"\"\"\n\n    with LogfireQueryClient(read_token='<your_read_token>') as client:\n        # Load data as JSON, in column-oriented format\n        json_cols = client.query_json(sql=query)\n        print(json_cols)\n\n        # Load data as JSON, in row-oriented format\n        json_rows = client.query_json_rows(sql=query)\n        print(json_rows)\n\n        # Retrieve data in arrow format, and load into a polars DataFrame\n        # Note that JSON columns such as `attributes` will be returned as\n        # JSON-serialized strings\n        df_from_arrow = pl.from_arrow(client.query_arrow(sql=query))\n        print(df_from_arrow)\n\n        # Retrieve data in CSV format, and load into a polars DataFrame\n        # Note that JSON columns such as `attributes` will be returned as\n        # JSON-serialized strings\n        df_from_csv = pl.read_csv(StringIO(client.query_csv(sql=query)))\n        print(df_from_csv)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire with TOML\nDESCRIPTION: This code snippet demonstrates how to configure Logfire using the `pyproject.toml` configuration file. The keys in the configuration file map directly to the parameters required in the `logfire.configure()` method, which allows for easy setup of project-specific configurations like project name and console color preferences.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/configuration.md#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[tool.logfire]\\nproject_name = \"My Project\"\\nconsole_colors = \"never\"\n```\n\n----------------------------------------\n\nTITLE: Instrumenting a WSGI Application with Logfire\nDESCRIPTION: This example demonstrates how to use Logfire to instrument a simple WSGI application. It configures Logfire, defines a basic WSGI app, instruments it using logfire.instrument_wsgi(), and runs it using wsgiref's simple server.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/wsgi.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom wsgiref.simple_server import make_server\n\nimport logfire\n\n\nlogfire.configure()\n\ndef app(env, start_response):\n    start_response('200 OK', [('Content-Type','text/html')])\n    return [b\"Hello World\"]\n\napp = logfire.instrument_wsgi(app)\n\nwith make_server(\"\", 8000, app) as httpd:\n    print(\"Serving on port 8000...\")\n\n    # Serve until process is killed\n    httpd.serve_forever()\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire in Django settings\nDESCRIPTION: Python code to add to Django's settings.py file for configuring and instrumenting Django with Logfire. This uses the OpenTelemetry Django Instrumentation package.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/django.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n# ...All the other settings...\n\n# Add the following lines at the end of the file\nlogfire.configure()\nlogfire.instrument_django()\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenTelemetry Tracing in NodeJS\nDESCRIPTION: JavaScript module that initializes the OpenTelemetry SDK for NodeJS and creates a simple trace span. The code demonstrates configuring the trace exporter, span processor, and resource attributes for service identification.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport {NodeSDK} from \"@opentelemetry/sdk-node\";\nimport {OTLPTraceExporter} from \"@opentelemetry/exporter-trace-otlp-proto\";\nimport {BatchSpanProcessor} from \"@opentelemetry/sdk-trace-node\";\nimport {trace} from \"@opentelemetry/api\";\nimport {Resource} from \"@opentelemetry/resources\";\nimport {ATTR_SERVICE_NAME} from \"@opentelemetry/semantic-conventions\";\n\nconst traceExporter = new OTLPTraceExporter();\nconst spanProcessor = new BatchSpanProcessor(traceExporter);\nconst resource = new Resource({[ATTR_SERVICE_NAME]: \"my_service\"});\nconst sdk = new NodeSDK({spanProcessor, resource});\nsdk.start();\n\nconst tracer = trace.getTracer(\"my_tracer\");\ntracer.startSpan(\"Hello World\").end();\n\nsdk.shutdown().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Psycopg and Executing SQL Queries with Logfire\nDESCRIPTION: This Python script demonstrates how to instrument Psycopg with Logfire, connect to a PostgreSQL database, and execute SQL queries. It includes examples of creating a table, inserting data, and querying the data.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/psycopg.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nimport psycopg\n\nlogfire.configure()\n\n# To instrument the whole module:\nlogfire.instrument_psycopg(psycopg)\n# or\nlogfire.instrument_psycopg('psycopg')\n# or just instrument whichever modules (psycopg and/or psycopg2) are installed:\nlogfire.instrument_psycopg()\n\nconnection = psycopg.connect(\n    'dbname=database user=user password=secret host=0.0.0.0 port=5432'\n)\n\n# Or instrument just the connection:\nlogfire.instrument_psycopg(connection)\n\nwith logfire.span('Create table and insert data'), connection.cursor() as cursor:\n    cursor.execute(\n        'CREATE TABLE IF NOT EXISTS test (id serial PRIMARY KEY, num integer, data varchar);'\n    )\n\n    # Insert some data\n    cursor.execute('INSERT INTO test (num, data) VALUES (%s, %s)', (100, 'abc'))\n    cursor.execute('INSERT INTO test (num, data) VALUES (%s, %s)', (200, 'def'))\n\n    # Query the data\n    cursor.execute('SELECT * FROM test')\n```\n\n----------------------------------------\n\nTITLE: Configuring Log Levels in Python with Logfire\nDESCRIPTION: This snippet shows how to configure the minimum log level for console logging using Logfire. It sets the `min_log_level` to 'debug', allowing more detailed logging output.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(console=logfire.ConsoleOptions(min_log_level='debug'))\n```\n\n----------------------------------------\n\nTITLE: Recording Pydantic Models with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to configure Logfire and use it to record Pydantic model instances. It shows the creation of a User model and logging an instance of it using Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/why.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nimport logfire\nfrom pydantic import BaseModel\n\nlogfire.configure()\n\nclass User(BaseModel):\n    name: str\n    country_code: str\n    dob: date\n\nuser = User(name='Anne', country_code='USA', dob='2000-01-01')\nlogfire.info('user processed: {user!r}', user=user)\n```\n\n----------------------------------------\n\nTITLE: Capturing Only Response Headers with Custom Response Hook\nDESCRIPTION: Example showing how to create a custom response hook that selectively captures only the response headers in the spans created by Logfire's HTTPX instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nimport logfire\nfrom opentelemetry.trace import Span\nfrom logfire.integrations.httpx import RequestInfo, ResponseInfo\n\n\ndef capture_response_headers(span: Span, request: RequestInfo, response: ResponseInfo):\n    headers = response.headers\n    span.set_attributes(\n        {f'http.response.header.{header_name}': headers.get_list(header_name)\n        for header_name in headers.keys()}\n    )\n\n\nlogfire.configure()\nlogfire.instrument_httpx(response_hook=capture_response_headers)\n\nclient = httpx.Client()\nclient.get('https://httpbin.org/get')\n```\n\n----------------------------------------\n\nTITLE: Custom Module Filtering for Auto-tracing\nDESCRIPTION: Example showing how to create a custom filter function that traces only application modules while excluding standard library and third-party packages. The function checks if the module's filename starts with the Python library root path.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-auto-tracing.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\nimport logfire\n\nPYTHON_LIB_ROOT = str(pathlib.Path(pathlib.__file__).parent)\n\n\ndef should_trace(module: logfire.AutoTraceModule) -> bool:\n    return not module.filename.startswith(PYTHON_LIB_ROOT)\n\n\nlogfire.install_auto_tracing(should_trace)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting MySQL with Logfire in Python\nDESCRIPTION: This Python script demonstrates how to use Logfire to instrument MySQL operations. It connects to a MySQL database, creates a table, inserts data, and queries the data while using Logfire to create spans for each operation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/mysql.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nimport mysql.connector\n\nlogfire.configure()\n\n# To instrument the whole module:\nlogfire.instrument_mysql()\n\nconnection = mysql.connector.connect(\n    host=\"localhost\",\n    user=\"user\",\n    password=\"secret\",\n    database=\"database\",\n    port=3306,\n    use_pure=True,\n)\n\n# Or instrument just the connection:\n# connection = logfire.instrument_mysql(connection)\n\nwith logfire.span('Create table and insert data'), connection.cursor() as cursor:\n    cursor.execute(\n        'CREATE TABLE IF NOT EXISTS test (id INT AUTO_INCREMENT PRIMARY KEY, num integer, data varchar(255));'\n    )\n\n    # Insert some data\n    cursor.execute('INSERT INTO test (num, data) VALUES (%s, %s)', (100, 'abc'))\n    cursor.execute('INSERT INTO test (num, data) VALUES (%s, %s)', (200, 'def'))\n\n    # Query the data\n    cursor.execute('SELECT * FROM test')\n    results = cursor.fetchall()  # Fetch all rows\n    for row in results:\n        print(row)  # Print each row\n```\n\n----------------------------------------\n\nTITLE: Measuring File Sizes with Logfire Spans in Python\nDESCRIPTION: This snippet demonstrates how to use Logfire spans to measure the total size of files in the current directory. It uses nested spans to measure overall execution time and individual file reading times.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/concepts.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nimport logfire\n\nlogfire.configure()\n\ncwd = Path.cwd()\ntotal_size = 0\n\nwith logfire.span('counting size of {cwd=}', cwd=cwd):\n    for path in cwd.iterdir():\n        if path.is_file():\n            with logfire.span('reading {path}', path=path.relative_to(cwd)):\n                total_size += len(path.read_bytes())\n\n    logfire.info('total size of {cwd} is {size} bytes', cwd=cwd, size=total_size)\n```\n\n----------------------------------------\n\nTITLE: Implementing FastAPI Health Check Endpoint with Logfire Integration\nDESCRIPTION: Sets up a FastAPI application with a health check endpoint at /health and configures Logfire monitoring. Includes service name configuration and FastAPI instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/detect-service-is-down.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom fastapi import FastAPI\n\nlogfire.configure(service_name=\"backend\")\napp = FastAPI()\nlogfire.instrument_fastapi(app)\n\n@app.get(\"/health\")\nasync def health():\n    return {\"status\": \"ok\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring Background Rate Sampling in Logfire\nDESCRIPTION: This example shows how to use the background_rate parameter to keep a fraction of all traces, regardless of whether they meet tail sampling criteria. It demonstrates keeping 30% of info logs and all error logs.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(sampling=logfire.SamplingOptions.level_or_duration(background_rate=0.3))\n\nfor x in range(10):\n    logfire.info(f'info {x}')\nfor x in range(5):\n    logfire.error(f'error {x}')\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Individual HTTPX Clients\nDESCRIPTION: Example showing how to instrument specific HTTPX client instances rather than instrumenting the entire package, allowing for more granular control over which clients are traced.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nimport httpx\nimport logfire\n\nlogfire.configure()\n\nurl = 'https://httpbin.org/get'\n\nwith httpx.Client() as client:\n    logfire.instrument_httpx(client)\n    client.get(url)\n\n\nasync def main():\n    async with httpx.AsyncClient() as client:\n        logfire.instrument_httpx(client)\n        await client.get(url)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenTelemetry Tracing in Go\nDESCRIPTION: Go implementation that sets up OpenTelemetry tracing with the HTTP exporter for sending telemetry data to Logfire. This example creates a tracer provider with a batch span processor and generates a simple 'Hello World' span.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_8\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"context\"\n    \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\"\n    \"go.opentelemetry.io/otel/sdk/trace\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    traceExporter, _ := otlptracehttp.New(ctx)\n    batchSpanProcessor := trace.NewBatchSpanProcessor(traceExporter)\n    tracerProvider := trace.NewTracerProvider(trace.WithSpanProcessor(batchSpanProcessor))\n    tracer := tracerProvider.Tracer(\"my_tracer\")\n\n    ctx, span := tracer.Start(ctx, \"Hello World\")\n    span.End()\n\n    tracerProvider.Shutdown(ctx)\n}\n```\n\n----------------------------------------\n\nTITLE: Capturing User Input and Calculating Age with Logfire Spans in Python\nDESCRIPTION: This example uses Logfire spans to measure the execution time of asking for a user's birthday, capturing the input, and calculating their age. It demonstrates how to use spans for context and debug logging for detailed information.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/concepts.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nimport logfire\n\nlogfire.configure()\n\nwith logfire.span('Asking the user for their {question}', question='birthday'):\n    user_input = input('When were you born [YYYY-mm-dd]? ')\n    dob = date.fromisoformat(user_input)\n    logfire.debug('{dob=} {age=!r}', dob=dob, age=date.today() - dob)\n```\n\n----------------------------------------\n\nTITLE: Safe Logging of User Details in Logfire SDK (Python)\nDESCRIPTION: This snippet shows the recommended way to log user details safely using message templates. It uses the Logfire SDK's built-in formatting to ensure sensitive data is properly scrubbed.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/scrubbing.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlogfire.info('User details: {user}', user=User(id=123, password='secret'))\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Amazon Bedrock Anthropic Calls with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to instrument Anthropic LLM calls to Amazon Bedrock using Logfire. It configures the AnthropicBedrock client with AWS credentials and instruments it with Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/anthropic.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport anthropic\nimport logfire\n\nclient = anthropic.AnthropicBedrock(\n    aws_region='us-east-1',\n    aws_access_key='access-key',\n    aws_secret_key='secret-key',\n)\n\nlogfire.configure()\nlogfire.instrument_anthropic(client)\n```\n\n----------------------------------------\n\nTITLE: Configuring Full System Metrics Collection with Logfire in Python\nDESCRIPTION: Shows the comprehensive configuration for collecting detailed system metrics, including CPU, memory, disk, network, and process-specific data.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/system-metrics.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlogfire.instrument_system_metrics({\n    'system.cpu.simple_utilization': None,\n    'system.cpu.time': ['idle', 'user', 'system', 'irq', 'softirq', 'nice', 'iowait', 'steal', 'interrupt', 'dpc'],\n    'system.cpu.utilization': ['idle', 'user', 'system', 'irq', 'softirq', 'nice', 'iowait', 'steal', 'interrupt', 'dpc'],\n    'system.memory.usage': ['available', 'used', 'free', 'active', 'inactive', 'buffers', 'cached', 'shared', 'wired', 'slab', 'total'],\n    'system.memory.utilization': ['available', 'used', 'free', 'active', 'inactive', 'buffers', 'cached', 'shared', 'wired', 'slab'],\n    'system.swap.usage': ['used', 'free'],\n    'system.swap.utilization': ['used'],\n    'system.disk.io': ['read', 'write'],\n    'system.disk.operations': ['read', 'write'],\n    'system.disk.time': ['read', 'write'],\n    'system.network.dropped.packets': ['transmit', 'receive'],\n    'system.network.packets': ['transmit', 'receive'],\n    'system.network.errors': ['transmit', 'receive'],\n    'system.network.io': ['transmit', 'receive'],\n    'system.thread_count': None,\n    'process.context_switches': ['involuntary', 'voluntary'],\n    'process.runtime.gc_count': None,\n    'process.open_file_descriptor.count': None,\n    'process.cpu.time': ['user', 'system'],\n    'process.cpu.utilization': None,\n    'process.cpu.core_utilization': None,\n    'process.memory.usage': None,\n    'process.memory.virtual': None,\n    'process.thread.count': None,\n    'process.runtime.memory': ['rss', 'vms'],\n    'process.runtime.cpu.time': ['user', 'system'],\n    'process.runtime.thread_count': None,\n    'process.runtime.cpu.utilization': None,\n    'process.runtime.context_switches': ['involuntary', 'voluntary'],\n})\n```\n\n----------------------------------------\n\nTITLE: Excluding Functions from Auto-tracing\nDESCRIPTION: Example demonstrating how to use the @no_auto_trace decorator to exclude specific functions and classes from being automatically traced. The decorator prevents the function and any nested functions from being traced.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-auto-tracing.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n@logfire.no_auto_trace\ndef my_function():\n    # Nested functions will also be excluded\n    def inner_function():\n        ...\n\n    return other_function()\n\n\n# This function is *not* excluded from auto-tracing.\n# It will still be traced even when called from the excluded `my_function` above.\ndef other_function():\n    ...\n\n\n# All methods of a decorated class will also be excluded\n@no_auto_trace\nclass MyClass:\n    def my_method(self):\n        ...\n```\n\n----------------------------------------\n\nTITLE: Setting Up Auto-tracing in a Python Application\nDESCRIPTION: Example showing how to configure Logfire's auto-tracing before importing application modules. This sets up tracing for all modules in the 'app' package with a minimum duration threshold of 0.01 seconds.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-auto-tracing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.install_auto_tracing(modules=['app'], min_duration=0.01)\n\nfrom app.main import main\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Direct HTTP Request to Logfire API using Python requests\nDESCRIPTION: Demonstrates how to make a direct HTTP GET request to the Logfire API using the Python requests library, including authentication and query execution.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/query-api.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# Define the base URL and your read token\nbase_url = 'https://logfire-api.pydantic.dev'\nread_token = '<your_read_token_here>'\n\n# Set the headers for authentication\nheaders = {'Authorization': f'Bearer {read_token}'}\n\n# Define your SQL query\nquery = \"\"\"\nSELECT start_timestamp\nFROM records\nLIMIT 1\n\"\"\"\n\n# Prepare the query parameters for the GET request\nparams = {\n    'sql': query\n}\n\n# Send the GET request to the Logfire API\nresponse = requests.get(f'{base_url}/v1/query', params=params, headers=headers)\n\n# Check the response status\nif response.status_code == 200:\n    print(\"Query Successful!\")\n    print(response.json())\nelse:\n    print(f\"Failed to execute query. Status code: {response.status_code}\")\n    print(response.text)\n```\n\n----------------------------------------\n\nTITLE: Using Generator as Context Manager with Logfire Span in Python\nDESCRIPTION: Shows how to safely use a generator as a context manager with Logfire span, which ensures proper closure of the span even in case of exceptions.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import contextmanager\n\nimport logfire\n\nlogfire.configure()\n\n\n@contextmanager\ndef my_context():\n    with logfire.span('Context manager span'):\n        yield\n\n\ntry:\n    with my_context():\n        logfire.info('Inside context manager')\n        raise ValueError()\nexcept Exception:\n    logfire.exception('Error!')\nlogfire.info('After context manager')\n```\n\n----------------------------------------\n\nTITLE: Manual Context Propagation with Logfire in Python\nDESCRIPTION: Demonstrates how to manually propagate context using Logfire's wrapper around OpenTelemetry. It shows creating a parent span, getting its context, and attaching it to a child log in another execution environment.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/distributed-tracing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom logfire.propagate import attach_context, get_context\nimport logfire\n\nlogfire.configure()\n\nwith logfire.span('parent'):\n    ctx = get_context()\n\nprint(ctx)\n\n# Attach the context in another execution environment\nwith attach_context(ctx):\n    logfire.info('child')  # This log will be a child of the parent span.\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Logfire Query Client Usage in Python\nDESCRIPTION: Demonstrates how to use the AsyncLogfireQueryClient to execute SQL queries and retrieve data in various formats including JSON, Arrow, and CSV.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/query-api.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom io import StringIO\n\nimport polars as pl\nfrom logfire.experimental.query_client import AsyncLogfireQueryClient\n\n\nasync def main():\n    query = \"\"\"\n    SELECT start_timestamp\n    FROM records\n    LIMIT 1\n    \"\"\"\n\n    async with AsyncLogfireQueryClient(read_token='<your_read_token>') as client:\n        # Load data as JSON, in column-oriented format\n        json_cols = await client.query_json(sql=query)\n        print(json_cols)\n\n        # Load data as JSON, in row-oriented format\n        json_rows = await client.query_json_rows(sql=query)\n        print(json_rows)\n\n        # Retrieve data in arrow format, and load into a polars DataFrame\n        # Note that JSON columns such as `attributes` will be returned as\n        # JSON-serialized strings\n        df_from_arrow = pl.from_arrow(await client.query_arrow(sql=query))\n        print(df_from_arrow)\n\n        # Retrieve data in CSV format, and load into a polars DataFrame\n        # Note that JSON columns such as `attributes` will be returned as\n        # JSON-serialized strings\n        df_from_csv = pl.read_csv(StringIO(await client.query_csv(sql=query)))\n        print(df_from_csv)\n\n\nif __name__ == '__main__':\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Including Third-Party Modules in Pydantic Instrumentation\nDESCRIPTION: Example of enabling Logfire instrumentation for third-party modules like OpenAI\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlogfire.instrument_pydantic(include={'openai'})\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire for Source Code Linking in Python\nDESCRIPTION: This snippet demonstrates how to configure Logfire to link to a source code repository. It uses the logfire.CodeSource class to specify the repository URL, revision, and root path.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/link-to-code-source.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(\n    code_source=logfire.CodeSource(\n        repository='https://github.com/pydantic/logfire',  #(1)!\n        revision='<hash of commit used on release>',  #(2)!\n        root_path='/root/path',  #(3)!\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Span Message After Creation in Logfire\nDESCRIPTION: Shows how to set a span's message after it has been created but before it finishes. This allows for dynamic message creation based on the span's operations.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith logfire.span('Calculating...') as span:\n    result = 1 + 2\n    span.message = f'Calculated: {result}'\n```\n\n----------------------------------------\n\nTITLE: Instrumenting OpenAI Agents Framework\nDESCRIPTION: Basic example showing how to instrument the OpenAI Agents framework with Logfire. This captures the agent's conversation and processing steps when generating a haiku about recursion.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/openai.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom agents import Agent, Runner\n\nlogfire.configure()\nlogfire.instrument_openai_agents()\n\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\nprint(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Customizing SQL Commenter Options\nDESCRIPTION: This example demonstrates how to customize SQL Commenter options by excluding specific keys from being added to the SQL comments.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/psycopg.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_psycopg(enable_commenter=True, commenter_options={'db_driver': False, 'dbapi_threadsafety': False})\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire as a Loguru Sink in Python\nDESCRIPTION: This snippet demonstrates how to set up Logfire as a sink for Loguru by configuring Logfire and adding its handler to Loguru's configuration. It shows how to emit a simple log message with a parameter.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/loguru.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom loguru import logger\n\nlogfire.configure()\n\nlogger.configure(handlers=[logfire.loguru_handler()])\nlogger.info('Hello, {name}!', name='World')\n```\n\n----------------------------------------\n\nTITLE: Setting Attributes on Spans in Logfire\nDESCRIPTION: Demonstrates how to set attributes on a span after it has been created but before it finishes. This is useful for adding data that becomes available during the span's lifetime.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith logfire.span('Calculating...') as span:\n    result = 1 + 2\n    span.set_attribute('result', result)\n```\n\n----------------------------------------\n\nTITLE: Customizing FastAPI Logging with Logfire\nDESCRIPTION: Example of how to customize the logging behavior of Logfire with FastAPI by using a request_attributes_mapper function.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/fastapi.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\napp = ...\n\n\ndef request_attributes_mapper(request, attributes):\n    if attributes[\"errors\"]:\n        # Only log validation errors, not valid arguments\n        return {\n            \"errors\": attributes[\"errors\"],\n            \"my_custom_attribute\": ...,\n        }\n    else:\n        # Don't log anything for valid requests\n        return None\n\n\nlogfire.configure()\nlogfire.instrument_fastapi(app, request_attributes_mapper=request_attributes_mapper)\n```\n\n----------------------------------------\n\nTITLE: Configuring Structlog with Logfire Processor in Python\nDESCRIPTION: This snippet demonstrates how to configure Structlog with Logfire's processor. It sets up the Structlog configuration, creates a logger, and shows an example of logging with a custom User object. The Logfire processor is added to the Structlog configuration to enable Logfire logging.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/structlog.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport structlog\nimport logfire\n\nlogfire.configure()\n\nstructlog.configure(\n    processors=[\n        structlog.contextvars.merge_contextvars,\n        structlog.processors.add_log_level,\n        structlog.processors.StackInfoRenderer(),\n        structlog.dev.set_exc_info,\n        structlog.processors.TimeStamper(fmt='%Y-%m-%d %H:%M:%S', utc=False),\n        logfire.StructlogProcessor(),\n        structlog.dev.ConsoleRenderer(),\n    ],\n)\nlogger = structlog.get_logger()\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n\n\nlogger.info('Login', user=User(id=42, name='Fred'))\n#> 2024-03-22 12:57:33 [info     ] Login                          user=User(id=42, name='Fred')\n```\n\n----------------------------------------\n\nTITLE: Enabling SQL Commenter with Logfire\nDESCRIPTION: This snippet shows how to enable SQL Commenter functionality in Logfire to add comments to SQL queries for enriching database logs with additional context.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/psycopg.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_psycopg(enable_commenter=True)\n```\n\n----------------------------------------\n\nTITLE: Configuring Default System Metrics Collection with Logfire in Python\nDESCRIPTION: Demonstrates the default configuration for system metrics collection, including CPU utilization, memory usage, and swap utilization.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/system-metrics.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlogfire.instrument_system_metrics({\n    'process.runtime.cpu.utilization': None,  # (1)!\n    'system.cpu.simple_utilization': None,  # (2)!\n    'system.memory.utilization': ['available'],  # (3)!\n    'system.swap.utilization': ['used'],  # (4)!\n})\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Tail Sampling in Logfire with Python\nDESCRIPTION: This code snippet demonstrates how to define a custom tail sampling function and configure Logfire to use it. The function determines sampling rates based on span duration and log level, allowing for fine-grained control over which traces are kept.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n\ndef get_tail_sample_rate(span_info):\n    if span_info.duration >= 1:\n        return 0.5  # (1)!\n\n    if span_info.level > 'warn':  # (2)!\n        return 0.3  # (3)!\n\n    return 0.1  # (4)!\n\n\nlogfire.configure(\n    sampling=logfire.SamplingOptions(\n        head=0.5,  # (5)!\n        tail=get_tail_sample_rate,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Requests with Logfire in Python\nDESCRIPTION: This example demonstrates how to use Logfire to instrument the 'requests' library. It configures Logfire, instruments requests, and then makes a GET request to httpbin.org.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/requests.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nimport requests\n\nlogfire.configure()\nlogfire.instrument_requests()\n\nrequests.get(\"https://httpbin.org/get\")\n```\n\n----------------------------------------\n\nTITLE: Manual Exception Recording in Logfire Spans\nDESCRIPTION: Shows how to manually record a handled exception within a Logfire span. This is useful when you want to log an exception without letting it propagate.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith logfire.span('This is a span') as span:\n    try:\n        raise ValueError('Catch this error, but record it')\n    except ValueError as e:\n        span.record_exception(e)\n```\n\n----------------------------------------\n\nTITLE: Implementing Logger Propagation in Python\nDESCRIPTION: This function propagates logging configurations from a parent logger to its children. It recursively updates the levels and handlers of child loggers based on the parent's configuration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/api/propagate.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef propagate(logger: logging.Logger) -> None:\n    \"\"\"Propagate logger configuration to children.\"\"\"\n    for name in list(logging.root.manager.loggerDict.keys()):\n        if name.startswith(f\"{logger.name}.\"):\n            child = logging.getLogger(name)\n            child.setLevel(logger.level)\n            for handler in logger.handlers:\n                if handler not in child.handlers:\n                    child.addHandler(handler)\n            propagate(child)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting the HTTPX Package Globally\nDESCRIPTION: Example showing how to instrument the entire HTTPX package with Logfire to trace all HTTP requests automatically, including both synchronous and asynchronous clients.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nimport httpx\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_httpx()\n\nurl = \"https://httpbin.org/get\"\n\nwith httpx.Client() as client:\n    client.get(url)\n\n\nasync def main():\n    async with httpx.AsyncClient() as client:\n        await client.get(url)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Masking Sensitive URL Parameters in AIOHTTP Client Instrumentation\nDESCRIPTION: Demonstrates how to use the url_filter argument to hide sensitive information in URL parameters when instrumenting the AIOHTTP client. This function masks specific query parameters considered sensitive.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/aiohttp.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom yarl import URL\n\ndef mask_url(url: URL) -> str:\n    sensitive_keys = {\"username\", \"password\", \"token\", \"api_key\", \"api_secret\", \"apikey\"}\n    masked_query = {key: \"*****\" if key in sensitive_keys else value for key, value in url.query.items()}\n    return str(url.with_query(masked_query))\n\nlogfire.instrument_aiohttp_client(url_filter=mask_url)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Head Sampling in Logfire\nDESCRIPTION: This example demonstrates how to implement custom head sampling in Logfire using an OpenTelemetry Sampler. It shows a custom sampler that excludes spans based on their name and uses ParentBased sampling.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.sdk.trace.sampling import (\n    ALWAYS_OFF,\n    ALWAYS_ON,\n    ParentBased,\n    Sampler,\n)\n\nimport logfire\n\n\nclass MySampler(Sampler):\n    def should_sample(\n            self,\n            parent_context,\n            trace_id,\n            name,\n            *args,\n            **kwargs,\n    ):\n        if name == 'exclude me':\n            sampler = ALWAYS_OFF\n        else:\n            sampler = ALWAYS_ON\n        return sampler.should_sample(\n            parent_context,\n            trace_id,\n            name,\n            *args,\n            **kwargs,\n        )\n\n    def get_description(self):\n        return 'MySampler'\n\n\nlogfire.configure(\n    sampling=logfire.SamplingOptions(\n        head=ParentBased(\n            MySampler(),\n        )\n    )\n)\n\nwith logfire.span('keep me'):\n    logfire.info('kept child')\n\nwith logfire.span('exclude me'):\n    logfire.info('excluded child')\n```\n\n----------------------------------------\n\nTITLE: Creating a Counter Callback Metric for CPU Time in Python\nDESCRIPTION: This example implements a counter callback metric that automatically measures CPU time at regular intervals. It parses system data and reports observations with different CPU states as attributes.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom opentelemetry.metrics import CallbackOptions, Observable\n\n\ndef cpu_time_callback(options: CallbackOptions) -> Iterable[Observation]:\n    observations = []\n    with open(\"/proc/stat\") as procstat:\n        procstat.readline()  # skip the first line\n        for line in procstat:\n            if not line.startswith(\"cpu\"):\n                break\n            cpu, user_time, nice_time, system_time = line.split()\n            observations.append(\n                Observation(int(user_time) // 100, {\"cpu\": cpu, \"state\": \"user\"})\n            )\n            observations.append(\n                Observation(int(nice_time) // 100, {\"cpu\": cpu, \"state\": \"nice\"})\n            )\n            observations.append(\n                Observation(int(system_time) // 100, {\"cpu\": cpu, \"state\": \"system\"})\n            )\n    return observations\n\nlogfire.metric_counter_callback(\n    'system.cpu.time',\n    unit='s',\n    callbacks=[cpu_time_callback],\n    description='CPU time',\n)\n```\n\n----------------------------------------\n\nTITLE: Redacting Sensitive HTTP Headers in OpenTelemetry\nDESCRIPTION: Example of setting an environment variable to redact the Authorization header value in OpenTelemetry instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/index.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nOTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SANITIZE_FIELDS=\"Authorization\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Random Head Sampling in Logfire\nDESCRIPTION: This snippet demonstrates how to configure random head sampling in Logfire to keep 50% of traces. It uses a loop to create spans and logs, showing how the sampling affects which traces are kept.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(sampling=logfire.SamplingOptions(head=0.5))\n\nfor x in range(10):\n    with logfire.span(f'span {x}'):\n        logfire.info(f'log {x}')\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire to Export Traces to Jaeger\nDESCRIPTION: Python code that configures Logfire to send traces to a locally running Jaeger instance instead of the default Logfire backend. It sets the OpenTelemetry traces endpoint and creates a sample span with a log message.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-backends.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport logfire\n\n# Jaeger only supports traces, not metrics, so only set the traces endpoint\n# to avoid errors about failing to export metrics.\n# Use port 4318 for HTTP, not 4317 for gRPC.\ntraces_endpoint = 'http://localhost:4318/v1/traces'\nos.environ['OTEL_EXPORTER_OTLP_TRACES_ENDPOINT'] = traces_endpoint\n\nlogfire.configure(\n    # Setting a service name is good practice in general, but especially\n    # important for Jaeger, otherwise spans will be labeled as 'unknown_service'\n    service_name='my_logfire_service',\n\n    # Sending to Logfire is on by default regardless of the OTEL env vars.\n    # Keep this line here if you don't want to send to both Jaeger and Logfire.\n    send_to_logfire=False,\n)\n\nwith logfire.span('This is a span'):\n    logfire.info('Logfire logs are also actually just spans!')\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Anthropic API Calls with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to instrument an Anthropic client with Logfire. It configures Logfire, instruments the Anthropic client, and makes a sample API call to create a message.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/anthropic.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport anthropic\nimport logfire\n\nclient = anthropic.Anthropic()\n\nlogfire.configure()\nlogfire.instrument_anthropic(client)  # (1)!\n\nresponse = client.messages.create(\n    max_tokens=1000,\n    model='claude-3-haiku-20240307',\n    system='You are a helpful assistant.',\n    messages=[{'role': 'user', 'content': 'Please write me a limerick about Python logging.'}],\n)\nprint(response.content[0].text)\n```\n\n----------------------------------------\n\nTITLE: Safe Generator Usage with External Logfire Span in Python\nDESCRIPTION: Demonstrates a safe way to use generators with Logfire by moving the span outside the generator function.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n\n\ndef generate_items():\n    for i in range(3):\n        yield i\n\n\ndef main():\n    items = generate_items()\n    with logfire.span('Generating items'):\n        for item in items:\n            logfire.info(f'Got item {item}')\n            break\n    logfire.info('After processing items')\n\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Capturing HTTP Headers with Logfire HTTPX Instrumentation\nDESCRIPTION: Example demonstrating how to enable HTTP header capture in Logfire's HTTPX instrumentation by setting the capture_headers parameter to True.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_httpx(capture_headers=True)\n\nclient = httpx.Client()\nclient.get(\"https://httpbin.org/get\")\n```\n\n----------------------------------------\n\nTITLE: Querying Logfire Records for Alerts with SQL\nDESCRIPTION: SQL query to set up an alert that triggers when an exception occurs in the 'api' service with a specific route. The query filters records by exception status, service name, and HTTP route attribute.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/alerts.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM records  -- (1)!\nWHERE\n    is_exception and  -- (2)!\n    service_name = 'api' and  -- (3)!\n    attributes->>'http.route' = '/members/{user_id}'  -- (4)!\n```\n\n----------------------------------------\n\nTITLE: Creating Simple Trace Spans with Python OpenTelemetry\nDESCRIPTION: Python script that initializes an OpenTelemetry tracer and creates a single span named 'Hello World'. This example demonstrates the basic setup of the tracer provider, span processor, and exporter for sending trace data to Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nexporter = OTLPSpanExporter()\nspan_processor = BatchSpanProcessor(exporter)\ntracer_provider = TracerProvider()\ntracer_provider.add_span_processor(span_processor)\ntracer = tracer_provider.get_tracer('my_tracer')\n\ntracer.start_span('Hello World').end()\n```\n\n----------------------------------------\n\nTITLE: Recommending Books using Anthropic's Claude Model with Logfire Integration\nDESCRIPTION: This snippet demonstrates how to use Mirascope's @with_logfire decorator with Anthropic's Claude model to recommend books. It shows the integration of Logfire for automatic logging of LLM interactions.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/mirascope.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom mirascope.core import anthropic, prompt_template\nfrom mirascope.integrations.logfire import with_logfire\n\nlogfire.configure()\n\n\n@with_logfire()\n@anthropic.call(\"claude-3-5-sonnet-20240620\")\n@prompt_template(\"Please recommend some {genre} books\")\ndef recommend_books(genre: str): ...\n\n\nresponse = recommend_books(\"fantasy\")  # this will automatically get logged with logfire\nprint(response.content)\n# > Certainly! Here are some popular and well-regarded fantasy books and series: ...\n```\n\n----------------------------------------\n\nTITLE: Creating a Context Manager for Generator with Logfire Span in Python\nDESCRIPTION: Shows how to create a context manager that wraps a generator function with a Logfire span, ensuring proper closure and usage.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import closing, contextmanager\n\nimport logfire\n\nlogfire.configure()\n\n\n@contextmanager\ndef generate_items():\n    def generator():\n        with logfire.span('Generating items'):\n            for i in range(3):\n                yield i\n\n    with closing(generator()) as items:\n        yield items\n\n\ndef main():\n    with generate_items() as items:\n        for item in items:\n            logfire.info(f'Got item {item}')\n            break\n    logfire.info('After processing items')\n\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for OpenTelemetry with Logfire\nDESCRIPTION: Shell commands to set the required environment variables for connecting OpenTelemetry exports to the Logfire backend. These variables configure the endpoint URL and authentication headers needed for the connection.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install opentelemetry-exporter-otlp\nexport OTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\nexport OTEL_EXPORTER_OTLP_HEADERS='Authorization=your-write-token'\n```\n\n----------------------------------------\n\nTITLE: Logfire SQL Alert Query for Service Health Monitoring\nDESCRIPTION: SQL query for Logfire alerts that monitors health check endpoint calls. Detects if the backend service is down by checking for absence of health check calls within a specified timeframe.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/detect-service-is-down.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    CASE\n        WHEN COUNT(*) = 0 THEN 'backend is down'\n        ELSE 'backend is up'\n    END AS message\nFROM\n    records\nWHERE\n    service_name = 'backend' and span_name = 'GET /health';\n```\n\n----------------------------------------\n\nTITLE: Instrumenting SQLite3 Module with Logfire in Python\nDESCRIPTION: Demonstrates how to instrument the entire SQLite3 module using Logfire. It configures Logfire, instruments SQLite3, and performs basic database operations.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/sqlite3.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport sqlite3\n\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_sqlite3()\n\nwith sqlite3.connect(':memory:') as connection:\n    cursor = connection.cursor()\n\n    cursor.execute('CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)')\n    cursor.execute(\"INSERT INTO users (name) VALUES ('Alice')\")\n\n    cursor.execute('SELECT * FROM users')\n    print(cursor.fetchall())\n    # > [(1, 'Alice')]\n```\n\n----------------------------------------\n\nTITLE: Using @logfire.instrument with Context Manager for Generators in Python\nDESCRIPTION: Demonstrates the correct usage of @logfire.instrument decorator with a generator function that is also a context manager, using the allow_generator parameter.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import contextmanager\n\nimport logfire\n\nlogfire.configure()\n\n\n@contextmanager  # note the order\n@logfire.instrument('Context manager span', allow_generator=True)\ndef my_context():\n    yield\n\n\ntry:\n    with my_context():\n        logfire.info('Inside context manager')\n        raise ValueError()\nexcept Exception:\n    logfire.exception('Error!')\nlogfire.info('After context manager')\n```\n\n----------------------------------------\n\nTITLE: Basic Logging with Logfire in Python\nDESCRIPTION: Simple Python example that initializes Logfire and logs a basic message. The configure() method must be called once before logging to initialize Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/index.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()  # (1)!\nlogfire.info('Hello, {name}!', name='world')  # (2)!\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Tags to Pydantic Model Instrumentation\nDESCRIPTION: Example of adding custom tags to traces and metrics for a Pydantic model\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\n\nclass Foo(\n  BaseModel,\n  plugin_settings={'logfire': {'record': 'all', 'tags': ('tag1', 'tag2')}}\n):\n```\n\n----------------------------------------\n\nTITLE: Creating and Using a Counter Metric in Python with Logfire\nDESCRIPTION: This snippet demonstrates how to create a counter metric named 'messages_sent' and increment it by 1 each time a message is sent. Counter metrics are used to measure the frequency of events.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n# Create a counter metric\nmessages_sent = logfire.metric_counter('messages_sent')\n\n# Increment the counter\ndef send_message():\n    messages_sent.add(1)\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire Environment in Python\nDESCRIPTION: Sets up Logfire with a specific environment name, which helps distinguish data from different deployment contexts like local, staging, or production. The environment name is typically retrieved from an environment variable.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/environments.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(environment='local')  # (1)!\n```\n\n----------------------------------------\n\nTITLE: Creating a Gauge Metric for Temperature Measurement in Python\nDESCRIPTION: This snippet shows how to create a gauge metric to measure temperature. Gauge metrics track the current value of a measurement without accumulating values over time, ideal for real-time monitoring.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\ntemperature = logfire.metric_gauge(\n    'temperature',\n    unit='°C',\n    description='Temperature'\n)\n\ndef set_temperature(value: float):\n    temperature.set(value)\n```\n\n----------------------------------------\n\nTITLE: Suppressing BigQuery Instrumentation in Python\nDESCRIPTION: This snippet demonstrates how to opt-out of automatic BigQuery instrumentation using Logfire's suppress_scopes method.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/bigquery.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.suppress_scopes(\"google.cloud.bigquery.opentelemetry_tracing\")\n```\n\n----------------------------------------\n\nTITLE: Setting OpenTelemetry Resource Attributes for Source Code Linking\nDESCRIPTION: This snippet shows how to configure source code linking using OpenTelemetry resource attributes. It sets the repository URL, revision, and root path using the OTEL_RESOURCE_ATTRIBUTES environment variable.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/link-to-code-source.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nOTEL_RESOURCE_ATTRIBUTES=vcs.repository.url.full=https://github.com/pydantic/platform\nOTEL_RESOURCE_ATTRIBUTES=${OTEL_RESOURCE_ATTRIBUTES},vcs.repository.ref.revision=main\nOTEL_RESOURCE_ATTRIBUTES=${OTEL_RESOURCE_ATTRIBUTES},vcs.root.path=.\n```\n\n----------------------------------------\n\nTITLE: Using logfire-api for Custom Integrations in Python\nDESCRIPTION: Example demonstrating how to use the logfire-api package to create custom integrations with Logfire. The logfire-api is a lightweight shim package that matches Logfire's API without dependencies, allowing package maintainers to integrate with Logfire without requiring users to install it.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire_api as logfire\n\nlogfire.info(\"Hello, Logfire!\")\n```\n\n----------------------------------------\n\nTITLE: Automatic Exception Recording in Logfire Spans\nDESCRIPTION: Illustrates how Logfire automatically records exceptions that cause a span to exit. This feature helps in tracking and debugging errors within spans.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n\nwith logfire.span('This is a span'):\n    raise ValueError('This is an error')\n```\n\n----------------------------------------\n\nTITLE: Initializing System Metrics Collection with Logfire in Python\nDESCRIPTION: Configures Logfire and initializes system metrics collection using the instrument_system_metrics() method.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/system-metrics.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n\nlogfire.instrument_system_metrics()\n```\n\n----------------------------------------\n\nTITLE: Configuring RBAC for OpenTelemetry Collector\nDESCRIPTION: This YAML configuration sets up the necessary RBAC (Role-Based Access Control) for the OpenTelemetry collector. It creates a ServiceAccount, ClusterRole, and ClusterRoleBinding to give the collector permissions to access pod logs and metadata.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/otel-collector.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: otel-collector\n  namespace: default\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-rolebinding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: otel-collector-role\nsubjects:\n- kind: ServiceAccount\n  name: otel-collector\n  namespace: default\n```\n\n----------------------------------------\n\nTITLE: Changing Span Levels in Logfire in Python\nDESCRIPTION: This snippet illustrates how to change the logging level of a span both when creating it and after it has started. It uses the `span.set_level` method to adjust the logging level.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nwith logfire.span('Doing a thing') as span:\n    success = do_thing()\n    if not success:\n        span.set_level('error')\n```\n\n----------------------------------------\n\nTITLE: Logging with Positional Arguments in Structlog with Python\nDESCRIPTION: This snippet illustrates how positional arguments are handled when logging with Structlog. It shows that positional arguments are not collected as attributes by the Logfire processor, as they are already part of the event message when the processor is called.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/structlog.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlogger.error('Hello %s!', 'Fred')\n#> 2024-03-22 13:39:26 [error    ] Hello Fred!\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire with Conditional Data Sending in Python\nDESCRIPTION: This code snippet demonstrates how to configure Logfire to conditionally send data based on the presence of a write token. It uses the 'if-token-present' option to only send data when a token is available.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/create-write-tokens.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlogfire.configure(send_to_logfire='if-token-present')\n```\n\n----------------------------------------\n\nTITLE: Attaching Attributes to Logs in Logfire\nDESCRIPTION: Shows how to add structured data as attributes to logs in Logfire. This example attaches a 'name' attribute to an info log.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlogfire.info('Hello', name='world')\n```\n\n----------------------------------------\n\nTITLE: Initializing Logfire Pydantic Instrumentation\nDESCRIPTION: Basic Python code to initialize Logfire instrumentation for Pydantic models\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.instrument_pydantic()  # Defaults to record='all'\n```\n\n----------------------------------------\n\nTITLE: Capturing Only Request Headers with Custom Request Hook\nDESCRIPTION: Example showing how to create a custom request hook that selectively captures only the request headers in the spans created by Logfire's HTTPX instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nimport logfire\nfrom logfire.integrations.httpx import RequestInfo\nfrom opentelemetry.trace import Span\n\n\ndef capture_request_headers(span: Span, request: RequestInfo):\n    headers = request.headers\n    span.set_attributes(\n        {\n            f'http.request.header.{header_name}': headers.get_list(header_name)\n            for header_name in headers.keys()\n        }\n    )\n\n\nlogfire.configure()\nlogfire.instrument_httpx(request_hook=capture_request_headers)\n\nclient = httpx.Client()\nclient.get(\"https://httpbin.org/get\")\n```\n\n----------------------------------------\n\nTITLE: Logging Exceptions without Spans in Logfire\nDESCRIPTION: Demonstrates how to log exceptions using Logfire without creating a span. This is useful for recording errors in parts of the code not wrapped in spans.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    raise ValueError('This is an error')\nexcept ValueError:\n    logfire.exception('Something went wrong')\n```\n\n----------------------------------------\n\nTITLE: Creating a Gauge Callback Metric for Room Temperatures in Python\nDESCRIPTION: This snippet demonstrates a gauge callback metric that automatically collects temperature readings from different rooms. It uses a callback function to gather temperature data and yields observations with room attributes.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-metrics.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\n\ndef get_temperature(room: str) -> float:\n    ...\n\n\ndef temperature_callback(options: CallbackOptions) -> Iterable[Observation]:\n    for room in [\"kitchen\", \"living_room\", \"bedroom\"]:\n        temperature = get_temperature(room)\n        yield Observation(temperature, {\"room\": room})\n\n\nlogfire.metric_gauge_callback(\n    'temperature',\n    unit='°C',\n    callbacks=[temperature_callback],\n    description='Temperature',\n)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Tail Sampling Memory Usage in Logfire\nDESCRIPTION: This snippet illustrates how tail sampling affects memory usage in Logfire. It shows that spans are kept in memory until the duration threshold is exceeded, at which point all spans are logged at once.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nimport logfire\n\nlogfire.configure(sampling=logfire.SamplingOptions.level_or_duration())\n\nwith logfire.span('span'):\n    for x in range(1, 10):\n        time.sleep(1)\n        logfire.info(f'info {x}')\n```\n\n----------------------------------------\n\nTITLE: Loguru Sensitive Data Handling Limitation Example\nDESCRIPTION: This snippet illustrates a limitation in the Logfire-Loguru integration where sensitive data passed as parameters to Loguru's logger will not be scrubbed in the formatted message.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/loguru.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlogger.info('Foo: {bar}', bar='secret_value')\n# > 14:58:26.085 Foo: secret_value\n```\n\n----------------------------------------\n\nTITLE: Inspecting Project for OpenTelemetry Instrumentation\nDESCRIPTION: This snippet demonstrates how to inspect a project for missing OpenTelemetry instrumentation packages using the `logfire inspect` command. It helps identify which packages need to be installed for optimal instrumentation.  The command analyzes the project and suggests missing packages.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire inspect\n```\n```\n\n----------------------------------------\n\nTITLE: Deploying OpenTelemetry Collector as DaemonSet\nDESCRIPTION: This YAML configuration deploys the OpenTelemetry collector as a DaemonSet in Kubernetes. It includes a ConfigMap for the collector's configuration and a DaemonSet specification. The collector is configured to collect logs from all pods, parse JSON logs, and send them to Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/otel-collector.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otel-collector-config\ndata:\n  config.yaml: |-\n    receivers:\n      filelog:\n        include_file_path: true\n        include:\n          - /var/log/pods/*/*/*.log\n        exclude:\n          # Exclude logs from all containers named otel-collector\n          - /var/log/pods/*/otel-collector/*.log\n        operators:\n          - id: container-parser\n            type: container\n          - id: json_parser\n            type: json_parser\n            if: 'hasPrefix(body, \"{\\\"')'\n            parse_from: body\n            parse_to: attributes\n            parse_ints: true\n            timestamp:\n              parse_from: attributes.timestamp\n              layout_type: strptime\n              layout: \"%Y-%m-%dT%H:%M:%S.%f%z\"\n            severity:\n              parse_from: attributes.level\n              overwrite_text: true\n    exporters:\n      debug:\n      otlphttp:\n        endpoint: \"https://logfire-api.pydantic.dev\"\n        headers:\n          Authorization: \"Bearer ${env:LOGFIRE_TOKEN}\"\n    service:\n      pipelines:\n        logs:\n          receivers: [filelog]\n          exporters: [debug, otlphttp]\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: otel-collector\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  selector:\n    matchLabels:\n      app: opentelemetry\n      component: otel-collector\n  template:\n    metadata:\n      labels:\n        app: opentelemetry\n        component: otel-collector\n    spec:\n      serviceAccountName: otel-collector\n      terminationGracePeriodSeconds: 1\n      containers:\n      - name: otel-collector\n        image: otel/opentelemetry-collector-contrib:0.119.0\n        env:\n        - name: LOGFIRE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: logfire-token\n              key: logfire-token\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - mountPath: /var/log\n          name: varlog\n          readOnly: true\n        - mountPath: /var/lib/docker/containers\n          name: varlibdockercontainers\n          readOnly: true\n        - mountPath: /etc/otelcol-contrib/config.yaml\n          name: data\n          subPath: config.yaml\n          readOnly: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: data\n        configMap:\n          name: otel-collector-config\n```\n\n----------------------------------------\n\nTITLE: Configuring Tail Sampling by Level and Duration in Logfire\nDESCRIPTION: This example shows how to set up tail sampling based on log level and span duration. It demonstrates keeping traces with error logs and long-running spans while excluding others.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nimport logfire\n\nlogfire.configure(sampling=logfire.SamplingOptions.level_or_duration())\n\nfor x in range(3):\n    # None of these are logged\n    with logfire.span('excluded span'):\n        logfire.info(f'info {x}')\n\n    # All of these are logged\n    with logfire.span('included span'):\n        logfire.error(f'error {x}')\n\nfor t in range(1, 10, 2):\n    with logfire.span(f'span with duration {t}'):\n        time.sleep(t)\n```\n\n----------------------------------------\n\nTITLE: Configuring Stripe Logging with Logfire in Python\nDESCRIPTION: This code snippet shows how to add logging instrumentation to Stripe using Logfire. It configures basic logging with a Logfire handler and sets the logging level to INFO for Stripe-related logs.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/stripe.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom logging import basicConfig\n\nimport logfire\nfrom stripe import StripeClient\n\nlogfire.configure()\nbasicConfig(handlers=[logfire.LogfireLoggingHandler()], level='INFO')\n\nclient = StripeClient(api_key=os.getenv('STRIPE_SECRET_KEY'))\n\nclient.customers.list()\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire MCP Server in Claude Desktop\nDESCRIPTION: JSON configuration for integrating the Logfire MCP server with Claude Desktop. This configuration should be added to the ~/claude_desktop_config.json file.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/mcp-server.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"logfire\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"logfire-mcp\",\n      ],\n      \"env\": {\n        \"LOGFIRE_READ_TOKEN\": \"your_token\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Scrubbing in Logfire SDK (Python)\nDESCRIPTION: This snippet demonstrates how to completely disable the scrubbing feature in the Logfire SDK. It uses the configure method with the scrubbing parameter set to False.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/scrubbing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(scrubbing=False)\n```\n\n----------------------------------------\n\nTITLE: Adjusting Log Level for Specific Logger in Python\nDESCRIPTION: This snippet demonstrates how to reduce log verbosity by setting a higher log level for a specific logger. It uses the 'apscheduler' logger as an example, setting its log level to WARNING to suppress less important logs.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/logging.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlogger = logging.getLogger(\"apscheduler\")\nlogger.setLevel(logging.WARNING)\n```\n\n----------------------------------------\n\nTITLE: Combining Head and Tail Sampling in Logfire\nDESCRIPTION: This snippet demonstrates how to combine head and tail sampling in Logfire. It configures sampling to keep 10% of traces, applying tail sampling criteria only to those selected traces.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/sampling.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(sampling=logfire.SamplingOptions.level_or_duration(head=0.1))\n```\n\n----------------------------------------\n\nTITLE: Logging with Variable Levels in Python Using Logfire\nDESCRIPTION: This snippet provides an example of logging messages with specific log levels using `logfire.log`. It shows how to log an info level message, which can also be done with logfire's predefined log level functions.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlogfire.log('info', 'This is an info log')  # Equivalent to logfire.info('This is an info log')\n```\n\n----------------------------------------\n\nTITLE: Resetting Exported Spans with Logfire in Python\nDESCRIPTION: Provides an example of how to reset the exported spans in a test using the `CaptureLogfire` fixture's `exporter.clear()` method. It shows verifying logs before and after clearing the captured spans.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/testing.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom logfire.testing import CaptureLogfire\n\n\ndef test_reset_exported_spans(capfire: CaptureLogfire) -> None:\n    exporter = capfire.exporter\n\n    assert len(exporter.exported_spans) == 0\n\n    logfire.info('First log!')\n    assert len(exporter.exported_spans) == 1\n    assert exporter.exported_spans[0].name == 'First log!'\n\n    logfire.info('Second log!')\n    assert len(exporter.exported_spans) == 2\n    assert exporter.exported_spans[1].name == 'Second log!'\n\n    exporter.clear()\n    assert len(exporter.exported_spans) == 0\n\n    logfire.info('Third log!')\n    assert len(exporter.exported_spans) == 1\n    assert exporter.exported_spans[0].name == 'Third log!'\n\n```\n\n----------------------------------------\n\nTITLE: Problematic Async Generator Usage with Logfire Span in Python\nDESCRIPTION: Shows an example of incorrect usage of an async generator function with Logfire span, which can result in exceptions and unexpected behavior.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nimport logfire\n\nlogfire.configure()\n\n\nasync def generate_items():\n    with logfire.span('Generating items'):\n        for i in range(3):\n            yield i\n\n\nasync def main():\n    items = generate_items()\n    async for item in items:\n        logfire.info(f'Got item {item}')\n        break\n    logfire.info('After processing items')\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Logfire CLI\nDESCRIPTION: This snippet demonstrates how to authenticate with Logfire using the `logfire auth` command. It requires the Logfire CLI to be installed.  The authentication process involves selecting a data region and logging in through a browser window.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire auth\n```\n```\n\n----------------------------------------\n\nTITLE: Suppressing Scopes in Logfire with Python\nDESCRIPTION: This snippet demonstrates how to suppress spans and metrics from a specific OpenTelemetry scope, such as BigQuery instrumentation, using the suppress_scopes method.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/suppress.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.suppress_scopes(\"google.cloud.bigquery.opentelemetry_tracing\")\n```\n\n----------------------------------------\n\nTITLE: Testing System Metrics Collection with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to test system metrics collection using the `CaptureLogfire` fixture's `metrics_reader` to access in-memory metric data. It verifies that expected system metrics such as swap usage, disk operations, and CPU utilization are being collected.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/testing.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom typing import cast\n\nfrom opentelemetry.sdk.metrics.export import MetricsData\n\nfrom logfire.testing import CaptureLogfire\n\n\ndef test_system_metrics_collection(capfire: CaptureLogfire) -> None:\n    exported_metrics = json.loads(cast(MetricsData, capfire.metrics_reader.get_metrics_data()).to_json())  # type: ignore\n\n    metrics_collected = {\n        metric['name']\n        for resource_metric in exported_metrics['resource_metrics']\n        for scope_metric in resource_metric['scope_metrics']\n        for metric in scope_metric['metrics']\n    }\n\n    # collected metrics vary by platform, etc.\n    # assert that we at least collected _some_ of the metrics we expect\n    assert metrics_collected.issuperset(\n        {\n            'system.swap.usage',\n            'system.disk.operations',\n            'system.memory.usage',\n            'system.cpu.utilization',\n        }\n    ), metrics_collected\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Airflow for OpenTelemetry Collector in INI\nDESCRIPTION: Configures Airflow's airflow.cfg file to send OpenTelemetry data to a local OpenTelemetry Collector. Includes settings for metrics and traces, specifying the collector's host and port.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/airflow.md#2025-04-21_snippet_3\n\nLANGUAGE: ini\nCODE:\n```\n[metrics]\notel_on = True\notel_host = localhost\notel_port = 4318\notel_prefix = airflow\notel_interval_milliseconds = 30000  # The interval between exports, defaults to 60000\notel_ssl_active = False\n\n[traces]\notel_on = True\notel_host = localhost\notel_port = 4318\notel_prefix = airflow\notel_ssl_active = False\notel_task_log_event = True\n```\n\n----------------------------------------\n\nTITLE: Context Structure Example in Python\nDESCRIPTION: Shows the structure of a context object returned by get_context(). It includes a traceparent with version, trace_id, span_id, and trace_flags fields.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/distributed-tracing.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{'traceparent': '00-d1b9e555b056907ee20b0daebf62282c-7dcd821387246e1c-01'}\n```\n\n----------------------------------------\n\nTITLE: Querying User Data from PostgreSQL Database - SQL\nDESCRIPTION: This SQL snippet retrieves user names and their birth years from the Logfire database for users located in the USA. It uses the PostgreSQL JSON functions to extract data from a JSON-like structure stored in the attributes column of the records table. The expected input is a database containing user attributes, and the output will be a list of user names and their birth years.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/why.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT attributes->'result'->>'name' as name, extract(year from (attributes->'result'->>'dob')::date) as \"birth year\"\nFROM records\nWHERE attributes->'result'->>'country_code' = 'USA';\n```\n\n----------------------------------------\n\nTITLE: Instrumenting FastAPI with URL Exclusion in Python\nDESCRIPTION: Example of instrumenting a FastAPI application with Logfire, excluding the base URL from tracing using a regex pattern.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/index.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\n\nimport logfire\n\napp = FastAPI()\n\nlogfire.configure()\nlogfire.instrument_fastapi(app, excluded_urls='^https?://[^/]+/$')\n\nif __name__ == '__main__':\n    import uvicorn\n\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Configuring Model-Specific Plugin Settings\nDESCRIPTION: Example of setting up Logfire plugin settings for a specific Pydantic model using PluginSettings\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom logfire.integrations.pydantic import PluginSettings\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel, plugin_settings=PluginSettings(logfire={'record': 'failure'})):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Filtering User Traces in Live View - SQL\nDESCRIPTION: This SQL snippet filters the live view to display traces related to users named 'Ben' in the Logfire database. It directly queries the attributes of records based on the specified user's name. The expected input is a database with relevant users and their traces, and the output will indicate whether traces belong to the user 'Ben'.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/why.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nattributes->'result'->>'name' = 'Ben'\n```\n\n----------------------------------------\n\nTITLE: Excluding Modules from Pydantic Instrumentation\nDESCRIPTION: Example of excluding specific modules from Logfire instrumentation\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlogfire.instrument_pydantic(exclude={'app.api.v1'})\n```\n\n----------------------------------------\n\nTITLE: Creating Records Table Schema in SQL\nDESCRIPTION: This SQL snippet defines the schema for the 'records' table used in Logfire. It includes various columns for timestamps, trace information, span details, attributes, and process information.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/live.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE records AS (\n    start_timestamp timestamp with time zone,\n    created_at timestamp with time zone,\n    trace_id text,\n    span_id text,\n    parent_span_id text,\n    kind span_kind,\n    end_timestamp timestamp with time zone,\n    level smallint,\n    span_name text,\n    message text,\n    attributes_json_schema text,\n    attributes jsonb,\n    tags text[],\n    otel_links jsonb,\n    otel_events jsonb,\n    is_exception boolean,\n    otel_status_code status_code,\n    otel_status_message text,\n    otel_scope_name text,\n    otel_scope_version text,\n    otel_scope_attributes jsonb,\n    service_namespace text,\n    service_name text,\n    service_version text,\n    service_instance_id text,\n    process_pid integer\n)\n```\n\n----------------------------------------\n\nTITLE: Instrumenting LlamaIndex with OpenTelemetry and Logfire\nDESCRIPTION: Example showing how to instrument LlamaIndex with OpenTelemetry to enable tracing and monitoring. This code demonstrates the integration with LlamaIndex and OpenAI to perform a query on web data with full instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/llamaindex.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.readers.web import SimpleWebPageReader\nfrom opentelemetry.instrumentation.llamaindex import LlamaIndexInstrumentor\n\nlogfire.configure()\nLlamaIndexInstrumentor().instrument()\n\n# URL for Pydantic's main concepts page\nurl = 'https://docs.pydantic.dev/latest/concepts/models/'\n\n# Load the webpage\ndocuments = SimpleWebPageReader(html_to_text=True).load_data([url])\n\n# Create index from documents\nindex = VectorStoreIndex.from_documents(documents)\n\n# Initialize the LLM\nquery_engine = index.as_query_engine(llm=OpenAI())\n\n# Get response\nresponse = query_engine.query('Can I use RootModels without subclassing them? Show me an example.')\nprint(str(response))\n\"\"\"\nYes, you can use RootModels without subclassing them. Here is an example:\n\n```python\nfrom pydantic import RootModel\n\nPets = RootModel[list[str]]\n\nmy_pets = Pets.model_validate(['dog', 'cat'])\n\nprint(my_pets[0])\n#> dog\nprint([pet for pet in my_pets])\n#> ['dog', 'cat']\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire Pydantic Plugin in TOML\nDESCRIPTION: Configuration settings in pyproject.toml to enable the Logfire Pydantic plugin\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/pydantic.md#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[tool.logfire]\npydantic_plugin_record = \"all\"\n```\n\n----------------------------------------\n\nTITLE: Setting OTEL_EXPORTER_OTLP_HEADERS for Logfire in Bash\nDESCRIPTION: Sets the OTEL_EXPORTER_OTLP_HEADERS environment variable with the Logfire write token for authentication in Airflow's OpenTelemetry integration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/airflow.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport OTEL_EXPORTER_OTLP_HEADERS=\"Authorization=${LOGFIRE_TOKEN}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire MCP Server in Cline Chatbot Platform\nDESCRIPTION: JSON configuration for setting up the Logfire MCP server in Cline chatbot platform. This should be added to the cline_mcp_settings.json file.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/mcp-server.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"logfire\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"logfire-mcp\",\n      ],\n      \"env\": {\n        \"LOGFIRE_READ_TOKEN\": \"your_token\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying HTTP Request Duration Percentiles in SQL\nDESCRIPTION: SQL query to compute percentiles (50th, 90th, 95th, 99th) for HTTP request durations using time buckets and approximate percentile functions.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/index.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nWITH dataset AS (\n  SELECT\n    time_bucket('%time_bucket_duration%', start_timestamp) AS x,\n    (extract(ms from end_timestamp - start_timestamp)) as duration_ms\n  FROM records\n  WHERE attributes ? 'http.method'\n)\nSELECT\n  x,\n  approx_percentile_cont(duration_ms, 0.50) as percentile_50,\n  approx_percentile_cont(duration_ms, 0.90) as percentile_90,\n  approx_percentile_cont(duration_ms, 0.95) as percentile_95,\n  approx_percentile_cont(duration_ms, 0.99) as percentile_99\nFROM dataset\nGROUP BY x\nORDER BY x\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Motor with Logfire (Asynchronous)\nDESCRIPTION: Python script showing how to use Logfire to instrument Motor (asynchronous MongoDB driver) operations. It configures Logfire, instruments PyMongo, connects to a MongoDB database asynchronously, inserts a document, and performs a query.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/pymongo.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport logfire\nfrom motor.motor_asyncio import AsyncIOMotorClient\n\nlogfire.configure()\nlogfire.instrument_pymongo()\n\nasync def main():\n    client = AsyncIOMotorClient()\n    db = client[\"database\"]\n    collection = db[\"collection\"]\n    await collection.insert_one({\"name\": \"MongoDB\"})\n    await collection.find_one()\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Metrics Table Schema Definition in SQL\nDESCRIPTION: This SQL CREATE TABLE statement defines the schema for the metrics table, which contains metric data for analysis.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/explore.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE metrics AS (\n    recorded_timestamp timestamp with time zone,\n    metric_name text,\n    metric_type text,\n    unit text,\n    start_timestamp timestamp with time zone,\n    aggregation_temporality public.aggregation_temporality,\n    is_monotonic boolean,\n    metric_description text,\n    scalar_value double precision,\n    histogram_min double precision,\n    histogram_max double precision,\n    histogram_count integer,\n    histogram_sum double precision,\n    exp_histogram_scale integer,\n    exp_histogram_zero_count integer,\n    exp_histogram_zero_threshold double precision,\n    exp_histogram_positive_bucket_counts integer[],\n    exp_histogram_positive_bucket_counts_offset integer,\n    exp_histogram_negative_bucket_counts integer[],\n    exp_histogram_negative_bucket_counts_offset integer,\n    histogram_bucket_counts integer[],\n    histogram_explicit_bounds double precision[],\n    attributes jsonb,\n    otel_scope_name text,\n    otel_scope_version text,\n    otel_scope_attributes jsonb,\n    service_namespace text,\n    service_name text,\n    service_version text,\n    service_instance_id text,\n    process_pid integer\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Logfire Query Clients in Python\nDESCRIPTION: Import statement for the synchronous and asynchronous Logfire query clients from the experimental namespace.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/query-api.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom logfire.experimental.query_client import AsyncLogfireQueryClient, LogfireQueryClient\n```\n\n----------------------------------------\n\nTITLE: Capturing Specific HTTP Headers in OpenTelemetry\nDESCRIPTION: Example of setting an environment variable to capture specific request headers (content-type and X-prefixed) in OpenTelemetry instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/index.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST=\"content-type,X-.*\"\n```\n\n----------------------------------------\n\nTITLE: Rust Cargo Configuration for OpenTelemetry\nDESCRIPTION: Cargo.toml configuration for a Rust project using OpenTelemetry. This file specifies the necessary dependencies for OpenTelemetry tracing with HTTP protocol and reqwest client, including the required rustls feature for secure connections.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[package]\nname = \"otel-example\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nopentelemetry = { version = \"*\", default-features = false, features = [\"trace\"] }\n# Note: `reqwest-rustls` feature is necessary else you'll have a cryptic failure to export;\n# see https://github.com/open-telemetry/opentelemetry-rust/issues/2169\nopentelemetry-otlp = { version = \"*\", default-features = false, features = [\"trace\", \"http-proto\", \"reqwest-blocking-client\", \"reqwest-rustls\"] }\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Async OpenAI Image Generation\nDESCRIPTION: Example of instrumenting an asynchronous OpenAI image generation call. The code captures the API request details and opens the generated image in a web browser.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/openai.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nimport logfire\n\nasync def main():\n    client = openai.AsyncClient()\n    logfire.configure()\n    logfire.instrument_openai(client)\n\n    response = await client.images.generate(\n        prompt='Image of R2D2 running through a desert in the style of cyberpunk.',\n        model='dall-e-3',\n    )\n    url = response.data[0].url\n    import webbrowser\n    webbrowser.open(url)\n\nif __name__ == '__main__':\n    import asyncio\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating a New Logfire Project\nDESCRIPTION: This snippet shows how to create a new Logfire project using the `logfire projects new <project-name>` command. The `<project-name>` placeholder needs to be replaced with desired name. The command initiates the project creation process, and requires following on-screen instructions.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire projects new <project-name>\n```\n```\n\n----------------------------------------\n\nTITLE: Listing Logfire Projects\nDESCRIPTION: This snippet demonstrates how to list the Logfire projects you have access to using the `logfire projects list` command. It displays the organization and project names.  The command retrieves and displays project information.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire projects list\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Logfire Organization Structure using Mermaid\nDESCRIPTION: This snippet uses Mermaid syntax to define the relationships between Organizations, Users, OrganizationMembers, Projects, and ProjectMembers in Logfire. It defines the classes and their attributes, as well as the relationships between them, such as composition and aggregation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/organization-structure.md#2025-04-21_snippet_0\n\nLANGUAGE: Mermaid\nCODE:\n```\nclassDiagram\n  Organization <-- OrganizationMember\n  User <-- OrganizationMember\n  User <-- ProjectMember\n  Organization <-- Project\n  Project <-- ProjectMember\n\n  class Organization {\n    UUID id\n    string name\n  }\n\n  class User {\n    UUID id\n    string name\n  }\n\n  class OrganizationMember {\n    UUID user_id\n    UUID organization_id\n    string role ['admin', 'member', 'guest']\n  }\n\n  class Project {\n    UUID id\n    UUID organization_id\n    string name\n  }\n\n  class ProjectMember {\n    UUID user_id\n    UUID project_id\n    string role ['admin', 'member']\n  }\n```\n\n----------------------------------------\n\nTITLE: Authenticating Logfire in Local Environment\nDESCRIPTION: Command to authenticate your local development environment with Logfire. Upon successful authentication, credentials are stored in ~/.logfire/default.toml.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/index.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nlogfire auth\n```\n\n----------------------------------------\n\nTITLE: Testing Exported Spans with Logfire in Python\nDESCRIPTION: This example shows how to test the names of exported spans using the `CaptureLogfire` fixture from the Logfire testing module. It illustrates how to access and assert on the captured spans using the in-built methods.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/testing.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom logfire.testing import CaptureLogfire\n\n\ndef test_exported_spans(capfire: CaptureLogfire) -> None:\n    with logfire.span('a span!'):\n        logfire.info('a log!')\n\n    exporter = capfire.exporter\n\n    expected_span_names = ['a span! (pending)', 'a log!', 'a span!']\n    span_names = [span.name for span in exporter.exported_spans]\n\n    assert span_names == expected_span_names\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire Module Documentation in YAML\nDESCRIPTION: This YAML configuration sets up documentation options for the Logfire module. It specifies which members to show, which filters to apply, and how to display headings and paths.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/api/logfire.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n::: logfire\n    options:\n        show_root_toc_entry: false\n        members: false\n\n\n::: logfire.Logfire\n    options:\n        show_root_heading: true\n        show_root_full_path: false\n        exclude:\n        filters:\n            - \"!instrument_redis\"\n            - \"!instrument_pymongo\"\n            - \"!instrument_psycopg\"\n            - \"!^with_trace_sample_rate$\"\n            - \"!^_[^_]\"\n\n\n::: logfire\n    options:\n        show_root_toc_entry: false\n        show_docstring_description: true\n        filters: [\"!^Logfire$\", \"!^_[^_]\"]\n```\n\n----------------------------------------\n\nTITLE: Running Logfire MCP Server with Token Authentication\nDESCRIPTION: Command to start the Logfire MCP server using a read token for authentication. The uvx command downloads and runs the logfire-mcp package from PyPI.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/mcp-server.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLOGFIRE_READ_TOKEN=<your-token> uvx logfire-mcp\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Logfire Token\nDESCRIPTION: This shell command creates a Kubernetes Secret to store the Logfire write token. The token is used by the OpenTelemetry collector to authenticate with Logfire when sending logs.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/otel-collector.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create secret generic logfire-token --from-literal=logfire-token=your-write-token\n```\n\n----------------------------------------\n\nTITLE: Setting Logfire Token for Production Environment\nDESCRIPTION: Command to set up the Logfire write token as an environment variable for production use. This stores the token in .logfire/logfire_credentials.json in the current directory.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/index.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport LOGFIRE_TOKEN=<your-write-token>\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream with OpenTelemetry and Logfire using Redis Broker\nDESCRIPTION: This snippet shows how to set up a FastStream application with OpenTelemetry instrumentation using Logfire and Redis broker. It demonstrates configuring Logfire, setting up a Redis broker with telemetry middleware, defining message handlers, and performing a test publish operation after startup.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/faststream.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.redis.opentelemetry import RedisTelemetryMiddleware\n\nimport logfire\n\nlogfire.configure()\n\nbroker = RedisBroker(middlewares=(RedisTelemetryMiddleware(),))\n\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test-channel\")\n@broker.publisher(\"another-channel\")\nasync def handle():\n    return \"Hi!\"\n\n\n@broker.subscriber(\"another-channel\")\nasync def handle_next(msg: str):\n    assert msg == \"Hi!\"\n\n\n@app.after_startup\nasync def test():\n    await broker.publish(\"\", channel=\"test-channel\")\n```\n\n----------------------------------------\n\nTITLE: Running Redis for Celery broker\nDESCRIPTION: Docker command to run Redis, which will be used as a broker for Celery in the example.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/celery.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm -d -p 6379:6379 redis\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Logfire\nDESCRIPTION: Command to authenticate with Logfire services using the CLI tool.\nSOURCE: https://github.com/pydantic/logfire/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nlogfire auth\n```\n\n----------------------------------------\n\nTITLE: Setting up PostgreSQL Database with Docker\nDESCRIPTION: This command creates a PostgreSQL database using Docker, setting up the necessary environment variables and exposing the default PostgreSQL port.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/asyncpg.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name postgres \\\n    -e POSTGRES_USER=user \\\n    -e POSTGRES_PASSWORD=secret \\\n    -e POSTGRES_DB=database \\\n    -p 5432:5432 \\\n    -d postgres\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire via pip\nDESCRIPTION: Command to install the Logfire Python package using pip package manager.\nSOURCE: https://github.com/pydantic/logfire/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install logfire\n```\n\n----------------------------------------\n\nTITLE: Initializing Stripe Client for Synchronous and Asynchronous Requests in Python\nDESCRIPTION: This snippet demonstrates how to initialize a Stripe client and make both synchronous and asynchronous requests using the stripe Python library. It uses requests for synchronous and httpx for asynchronous calls.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/stripe.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom stripe import StripeClient\n\nclient = StripeClient(api_key='<your_secret_key>')\n\n# Synchronous request\nclient.customers.list()  # uses `requests`\n\n# Asynchronous request\nasync def main():\n    await client.customers.list_async()  # uses `httpx`\n\nif __name__ == '__main__':\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Setting up PostgreSQL Database with Docker\nDESCRIPTION: This command initializes a PostgreSQL database using Docker, setting up user credentials and exposing the database on port 5432.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/psycopg.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --name postgres \\\n    -e POSTGRES_USER=user \\\n    -e POSTGRES_PASSWORD=secret \\\n    -e POSTGRES_DB=database \\\n    -p 5432:5432 \\\n    -d postgres\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Starlette extra\nDESCRIPTION: Command to install Logfire with the Starlette extra dependency. This is a prerequisite for instrumenting Starlette applications with Logfire.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/starlette.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install uvicorn\n```\n\n----------------------------------------\n\nTITLE: Setting up Redis Server using Docker\nDESCRIPTION: Docker command to initialize a Redis server container, exposing it on port 6379.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/redis.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name redis -p 6379:6379 -d redis:latest\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Flask Extra\nDESCRIPTION: Command to install Logfire with the Flask extra dependency.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/flask.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['flask']) }}\n```\n\n----------------------------------------\n\nTITLE: Querying Exception Spans in SQL\nDESCRIPTION: This SQL query selects message, start timestamp, duration, and attributes for all spans with exceptions from the records table.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/explore.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  message,\n  start_timestamp,\n  EXTRACT(EPOCH FROM (end_timestamp - start_timestamp)) * 1000 AS duration_ms,\n  attributes\nFROM records\nWHERE is_exception\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with PyMongo support\nDESCRIPTION: Command to install Logfire with PyMongo extra using a package manager. The actual command is represented by a placeholder.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/pymongo.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['pymongo']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with FastAPI support\nDESCRIPTION: Command to install Logfire with FastAPI integration using pip. The actual command is represented by a placeholder.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/fastapi.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['fastapi']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with HTTPX Support\nDESCRIPTION: Command to install Logfire with HTTPX integration support using the extras parameter.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/httpx.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['httpx']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Celery support\nDESCRIPTION: Command to install Logfire with Celery integration support using pip.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/celery.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['celery']) }}\n```\n\n----------------------------------------\n\nTITLE: Using Message Templates in Logfire\nDESCRIPTION: Illustrates how to use message templates with Logfire. This example shows logging with a template string and a variable attribute.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/add-manual-tracing.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n\nfor name in ['Alice', 'Bob', 'Carol']:\n    logfire.info('Hello {name}', name=name)\n```\n\n----------------------------------------\n\nTITLE: Navigating to example directory - Bash\nDESCRIPTION: This command changes the directory to the Cloudflare Worker example for running Logfire integration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/cloudflare-worker/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/javascript/cloudflare-worker\n```\n\n----------------------------------------\n\nTITLE: Installing Uvicorn for running FastAPI\nDESCRIPTION: Command to install Uvicorn, which is required to run the FastAPI example.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/fastapi.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install uvicorn\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with SQLAlchemy Support\nDESCRIPTION: Command to install Logfire with SQLAlchemy extra. This ensures that the necessary dependencies for SQLAlchemy instrumentation are included.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/sqlalchemy.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['sqlalchemy']) }}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Rust Project for OpenTelemetry\nDESCRIPTION: Shell commands to create a new Rust project and set the required environment variables for OpenTelemetry integration with Logfire. These commands initialize the project structure and configure the OpenTelemetry endpoint.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ncargo new --bin otel-example && cd otel-example\nexport OTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\nexport OTEL_EXPORTER_OTLP_HEADERS='Authorization=your-write-token'\n```\n\n----------------------------------------\n\nTITLE: Specifying Region During Authentication\nDESCRIPTION: This snippet demonstrates how to specify the data region (EU or US) during authentication using the `--region` flag. It avoids the interactive prompt for region selection.  The region is specified directly in the command.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire --region eu auth\n```\n```\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire --region eu auth\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with ASGI Support\nDESCRIPTION: This snippet shows how to install Logfire with the ASGI extra. The actual installation command is represented by a placeholder that would be populated dynamically.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/asgi.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['asgi']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with WSGI Support\nDESCRIPTION: This snippet shows how to install Logfire with the 'wsgi' extra, which includes necessary dependencies for WSGI instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/wsgi.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['wsgi']) }}\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire settings - TOML\nDESCRIPTION: This configuration in the wrangler.toml file sets environment variables for the Logfire write token and optional API base URL.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/cloudflare-worker/README.md#2025-04-21_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[vars]\nLOGFIRE_WRITE_TOKEN=\"your-write-token\"\nLOGFIRE_BASE_URL=\"https://logfire-api.pydantic.dev/\"\n```\n\n----------------------------------------\n\nTITLE: Using a Logfire Project\nDESCRIPTION: This snippet shows how to set the current project to be used by Logfire using the `logfire projects use <project-name>` command.  The `<project-name>` should be replaced with the actual project name. This sets the context for subsequent Logfire operations.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire projects use <project-name>\n```\n```\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire projects use backend\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Requests Support in Python\nDESCRIPTION: This snippet shows how to install Logfire with the 'requests' extra, which is necessary for instrumenting the requests library.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/requests.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['requests']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with System Metrics Support in Python\nDESCRIPTION: Installs the Logfire package with the 'system-metrics' extra to enable system metric collection functionality.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/system-metrics.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['system-metrics']) }}\n```\n\n----------------------------------------\n\nTITLE: Setting up MySQL Database with Docker\nDESCRIPTION: This bash command sets up a MySQL database using Docker, creating a container with specified environment variables and port mapping.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/mysql.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name mysql \\\n    -e MYSQL_ROOT_PASSWORD=secret \\\n    -e MYSQL_DATABASE=database \\\n    -e MYSQL_USER=user \\\n    -e MYSQL_PASSWORD=secret \\\n    -p 3306:3306 \\\n    -d mysql\n```\n\n----------------------------------------\n\nTITLE: Cleaning Logfire Files\nDESCRIPTION: This snippet shows how to clean most of the files created by Logfire using the `logfire clean` command. It doesn't remove logs or authentication information. The command removes temporary files and caches.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire clean\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with AIOHTTP support in Python\nDESCRIPTION: Command to install Logfire with AIOHTTP extra. This is a placeholder that will be replaced with the actual installation command.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/http-clients/aiohttp.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['aiohttp']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with AWS Lambda Support in Python\nDESCRIPTION: Command to install Logfire with the 'aws-lambda' extra for AWS Lambda support. This is a placeholder that will be replaced with the actual installation command.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/aws-lambda.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['aws-lambda']) }}\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire MCP Server in Cursor IDE\nDESCRIPTION: JSON configuration for setting up the Logfire MCP server in Cursor IDE. This configuration should be placed in the .cursor/mcp.json file in the project root.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/mcp-server.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"logfire\": {\n      \"command\": \"uvx\",\n      \"args\": [\"logfire-mcp\", \"--read-token=YOUR-TOKEN\"],\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Problematic Generator Usage with Logfire Span in Python\nDESCRIPTION: Demonstrates incorrect usage of a generator function with Logfire span, which can lead to unexpected behavior when iteration is interrupted.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n\n\ndef generate_items():\n    with logfire.span('Generating items'):\n        for i in range(3):\n            yield i\n\n\n# Or equivalently:\n@logfire.instrument('Generating items')\ndef generate_items():\n    for i in range(3):\n        yield i\n\n\ndef main():\n    items = generate_items()\n    for item in items:\n        logfire.info(f'Got item {item}')\n        # break\n    logfire.info('After processing items')\n\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry instrumentation for LlamaIndex\nDESCRIPTION: Command to install the opentelemetry-instrumentation-llamaindex package using pip.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/llms/llamaindex.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install opentelemetry-instrumentation-llamaindex\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with SQLite3 Support in Python\nDESCRIPTION: Instructions for installing Logfire with SQLite3 extra. This snippet is a placeholder for the actual installation command.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/sqlite3.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{{ install_logfire(extras=['sqlite3']) }}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for HTTP Header Capture in OpenTelemetry\nDESCRIPTION: Example of setting environment variables to capture all request and response headers in OpenTelemetry instrumentation.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST=\".*\"\nOTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_RESPONSE=\".*\"\n```\n\n----------------------------------------\n\nTITLE: Using closing() with Generator and Logfire Span in Python\nDESCRIPTION: Demonstrates how to use the closing() context manager to ensure proper closure of a generator and its associated Logfire span.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/advanced/generators.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import closing\n\nimport logfire\n\nlogfire.configure()\n\n\ndef generate_items():\n    with logfire.span('Generating items'):\n        for i in range(3):\n            yield i\n\n\ndef main():\n    with closing(generate_items()) as items:\n        for item in items:\n            logfire.info(f'Got item {item}')\n            break\n    logfire.info('After processing items')\n\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Preparing Release with Version Update in Python\nDESCRIPTION: This snippet demonstrates how to execute the command to prepare a release by updating the version number in the 'pyproject.toml' files and modifying CHANGELOG.md. It ensures that the versioning and documentation are synchronized correctly before a release is made.\nSOURCE: https://github.com/pydantic/logfire/blob/main/release/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nuv run release/prepare.py {VERSION}\n```\n\n----------------------------------------\n\nTITLE: Using Logfire Inspect Command in Bash\nDESCRIPTION: This command uses the Logfire CLI to inspect your project and identify missing OpenTelemetry instrumentation components.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/onboarding-checklist/integrate.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nlogfire inspect\n```\n\n----------------------------------------\n\nTITLE: Sending a request to the Express server\nDESCRIPTION: Sends a network request to the local Express server using curl to trigger the OpenTelemetry instrumentation and report traces to Logfire. This command tests the successful setup of the integration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/express/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://localhost:8080/rolldice\n```\n\n----------------------------------------\n\nTITLE: Querying Live View by Trace ID in SQL\nDESCRIPTION: This SQL query demonstrates how to look up data for a specific trace ID in the Live View.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/explore.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ntrace_id = '7bda3ddf6e6d4a0c8386093209eb0bfc' -- replace with a real trace_id of your own\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies - Bash\nDESCRIPTION: This command installs the necessary Node.js dependencies needed for the Cloudflare Worker example using npm.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/cloudflare-worker/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Running Jaeger Docker Container for OpenTelemetry Collection\nDESCRIPTION: Command to start a minimal Jaeger container that can receive OpenTelemetry traces via HTTP on port 4318 and provides a UI on port 16686.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-backends.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm \\\n  -p 16686:16686 \\\n  -p 4318:4318 \\\n  jaegertracing/all-in-one:latest\n```\n\n----------------------------------------\n\nTITLE: Pushing Release Changes with Python\nDESCRIPTION: This command runs a script that creates a pull request with the changes made during the release preparation, adds a label for quick identification, and opens a draft release on GitHub. It streamlines the process of moving changes to the main branch.\nSOURCE: https://github.com/pydantic/logfire/blob/main/release/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nuv run release/push.py\n```\n\n----------------------------------------\n\nTITLE: Unsafe Logging of User Details in Logfire SDK (Python)\nDESCRIPTION: This example demonstrates an unsafe way of logging user details where sensitive information might be exposed. It directly converts a user object to a string, potentially revealing sensitive data like passwords.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/scrubbing.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nuser = User(id=123, password='secret')\nlogfire.info('User details: ' + str(user))\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Express example directory and installing dependencies\nDESCRIPTION: Changes the current directory to the Express example within the cloned repository and installs the project's dependencies using npm. This ensures that all necessary packages are available for running the example.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/express/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/javascript/express\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Running Cloudflare Worker - Bash\nDESCRIPTION: This command starts the Cloudflare Worker locally, allowing for testing of the Logfire integration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/cloudflare-worker/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Records Table Schema Definition in SQL\nDESCRIPTION: This SQL CREATE TABLE statement defines the schema for the records table, which contains all spans and logs from traced requests.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/explore.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE records AS (\n    start_timestamp timestamp with time zone,\n    created_at timestamp with time zone,\n    trace_id text,\n    span_id text,\n    parent_span_id text,\n    kind span_kind,\n    end_timestamp timestamp with time zone,\n    level smallint,\n    span_name text,\n    message text,\n    attributes_json_schema text,\n    attributes jsonb,\n    tags text[],\n    otel_links jsonb,\n    otel_events jsonb,\n    is_exception boolean,\n    otel_status_code status_code,\n    otel_status_message text,\n    otel_scope_name text,\n    otel_scope_version text,\n    otel_scope_attributes jsonb,\n    service_namespace text,\n    service_name text,\n    service_version text,\n    service_instance_id text,\n    process_pid integer\n)\n```\n\n----------------------------------------\n\nTITLE: Example .env file configuration\nDESCRIPTION: Defines the environment variables required for the Logfire integration, including the base URL, write token, and Express server port. Replace `your-write-token` with the actual Logfire write token.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/express/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Used for reporting traces to Logfire\nLOGFIRE_BASE_URL=https://logfire-api.pydantic.dev/\n# The write token for your project\nLOGFIRE_WRITE_TOKEN=your-write-token\nEXPRESS_PORT=8080\n```\n\n----------------------------------------\n\nTITLE: Querying CPU Metrics in SQL\nDESCRIPTION: This SQL query selects all columns from the metrics table for the 'system.cpu.time' metric within the last hour.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/guides/web-ui/explore.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM metrics\nWHERE metric_name = 'system.cpu.time'\n  AND recorded_timestamp > now() - interval '1 hour'\n```\n\n----------------------------------------\n\nTITLE: Setting Logfire Project for Development\nDESCRIPTION: Command to set your current Logfire project in development. Should be run from the root directory of your application.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/index.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nlogfire projects use <first-project>\n```\n\n----------------------------------------\n\nTITLE: Cleaning Logfile Files and Logs\nDESCRIPTION: This snippet shows how to clean both the standard Logfire files and the logs using the `logfire clean --logs` command. It builds upon the basic `clean` command. The `--logs` flag ensures log files are also removed.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/reference/cli.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nlogfire clean --logs\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Django support\nDESCRIPTION: Command to install Logfire with Django integration. An additional command is provided for asynchronous Django support.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/web-frameworks/django.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['django']) }}\n```\n\nLANGUAGE: shell\nCODE:\n```\n{{ install_logfire(extras=['django,asgi']) }}\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire with Redis Support in Python\nDESCRIPTION: Command to install Logfire with Redis extra dependencies using pip.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/redis.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{ install_logfire(extras=['redis']) }}\n```\n\n----------------------------------------\n\nTITLE: Running MongoDB using Docker\nDESCRIPTION: Docker command to start a MongoDB instance for testing purposes. It runs the latest MongoDB image and exposes port 27017.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/databases/pymongo.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name mongo -p 27017:27017 -d mongo:latest\n```\n\n----------------------------------------\n\nTITLE: Installing NodeJS Dependencies and Running OpenTelemetry Example\nDESCRIPTION: Shell commands to initialize a NodeJS project, install required OpenTelemetry dependencies, and run the tracing example. These commands set up the necessary environment variables and project configuration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nexport OTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\nexport OTEL_EXPORTER_OTLP_HEADERS='Authorization=your-write-token'\n\nnpm init es6 -y # creates package.json with type module\nnpm install @opentelemetry/sdk-node\nnode main.js\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Running Go OpenTelemetry Example\nDESCRIPTION: Shell commands to set up environment variables, initialize a Go module, and run an OpenTelemetry example in Go. These commands configure the Logfire endpoint, authentication, and service name attributes.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/alternative-clients.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nexport OTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\nexport OTEL_EXPORTER_OTLP_HEADERS='Authorization=your-write-token'\n\n# Optional, but otherwise you will see the service name set to `unknown_service:otel_example`\nexport OTEL_RESOURCE_ATTRIBUTES=\"service.name=my_service\"\n\ngo mod init otel_example\ngo mod tidy\ngo run .\n```\n\n----------------------------------------\n\nTITLE: Configuring Airflow for OpenTelemetry in INI\nDESCRIPTION: Configures Airflow's airflow.cfg file to enable OpenTelemetry for metrics and traces, specifying Logfire as the backend. Includes settings for host, port, SSL, and export intervals.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/airflow.md#2025-04-21_snippet_1\n\nLANGUAGE: ini\nCODE:\n```\n[metrics]\notel_on = True\notel_host = logfire-api.pydantic.dev\notel_port = 443\notel_prefix = airflow\notel_interval_milliseconds = 30000  # The interval between exports, defaults to 60000\notel_ssl_active = True\n\n[traces]\notel_on = True\notel_host = logfire-api.pydantic.dev\notel_port = 443\notel_prefix = airflow\notel_ssl_active = True\notel_task_log_event = True\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Collector for Airflow and Logfire in YAML\nDESCRIPTION: Defines the configuration for an OpenTelemetry Collector to receive data from Airflow and export it to Logfire. Includes receivers, exporters, processors, and service pipelines for traces and metrics.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/airflow.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: \"0.0.0.0:4317\"\n      http:\n        endpoint: \"0.0.0.0:4318\"\n\nexporters:\n  debug:\n  otlphttp:\n    endpoint: https://logfire-api.pydantic.dev/\n    compression: gzip\n    headers:\n      Authorization: \"Bearer ${env:LOGFIRE_TOKEN}\"\n\nprocessors:\n  batch:\n    timeout: 1s\n    send_batch_size: 32768\n\nextensions:\n  health_check:\n    endpoint: \"0.0.0.0:13133\"\n\nservice:\n  extensions: [health_check]\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlphttp]\n    metrics:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlphttp]\n```\n\n----------------------------------------\n\nTITLE: Defining Kubernetes Deployments for Log-Emitting Applications\nDESCRIPTION: This YAML configuration defines two Kubernetes Deployments: 'plain-app' which emits unstructured logs, and 'json-app' which emits structured JSON logs. Both applications are simple busybox containers that continuously output logs.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/how-to-guides/otel-collector.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: plain-app\n  namespace: default\n  labels:\n    app: plain-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: plain-app\n  template:\n    metadata:\n      labels:\n        app: plain-app\n    spec:\n      terminationGracePeriodSeconds: 1\n      containers:\n        - name: plain-app\n          image: busybox\n          command: [\"sh\", \"-c\", \"while true; do echo 'Hello World'; sleep 1; done\"]\n          resources:\n            limits:\n              memory: \"64Mi\"\n              cpu: \"500m\"\n            requests:\n              memory: \"64Mi\"\n              cpu: \"500m\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: json-app\n  namespace: default\n  labels:\n    app: json-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: json-app\n  template:\n    metadata:\n      labels:\n        app: json-app\n    spec:\n      terminationGracePeriodSeconds: 1\n      containers:\n        - name: json-app\n          image: busybox\n          command:\n            - \"sh\"\n            - \"-c\"\n            - |\n              while true; do\n                now=$(date -u '+%Y-%m-%dT%H:%M:%SZ')\n                echo \"{\\\"message\\\":\\\"Hello world!\\\",\\\"level\\\":\\\"warn\\\",\\\"timestamp\\\":\\\"$now\\\"}\"\n                sleep 1\n              done\n          resources:\n            limits:\n              memory: \"64Mi\"\n              cpu: \"500m\"\n            requests:\n              memory: \"64Mi\"\n              cpu: \"500m\"\n```\n\n----------------------------------------\n\nTITLE: Cloning repository - Bash\nDESCRIPTION: This command clones the Logfire project repository from GitHub to your local machine for further setup.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/cloudflare-worker/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pydantic/logfire.git\n```\n\n----------------------------------------\n\nTITLE: Instrumenting AWS Lambda Function with Logfire in Python\nDESCRIPTION: This snippet demonstrates how to instrument an AWS Lambda function using Logfire. It includes configuring Logfire, defining a handler function, and applying the instrumentation. Note that the LOGFIRE_TOKEN environment variable must be set in the Lambda function configuration.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/aws-lambda.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()  # (1)!\n\n\ndef handler(event, context):\n    return 'Hello from Lambda'\n\nlogfire.instrument_aws_lambda(handler)\n```\n\n----------------------------------------\n\nTITLE: Cloning the Logfire repository\nDESCRIPTION: Clones the Logfire repository from GitHub to the local machine. This step is necessary to access the example project.\nSOURCE: https://github.com/pydantic/logfire/blob/main/examples/javascript/express/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pydantic/logfire.git\n```\n\n----------------------------------------\n\nTITLE: Running Celery Beat\nDESCRIPTION: Command to run the Celery beat process with the configured tasks.\nSOURCE: https://github.com/pydantic/logfire/blob/main/docs/integrations/event-streams/celery.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncelery -A tasks beat --loglevel=info\n```"
  }
]