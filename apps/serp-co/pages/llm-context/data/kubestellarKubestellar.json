[
  {
    "owner": "kubestellar",
    "repo": "kubestellar",
    "content": "TITLE: Creating and Registering First Workload Execution Cluster\nDESCRIPTION: Commands to create the first Workload Execution Cluster (WEC) named cluster1, rename its context, and register it with the OCM hub. This cluster will receive and run workloads from KubeStellar.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nk3d cluster create -p \"31080:80@loadbalancer\"  --network k3d-kubeflex cluster1\nkubectl config rename-context k3d-cluster1 cluster1\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Demo Environment with Kind\nDESCRIPTION: Command for setting up a KubeStellar demonstration environment using the automated script with Kind as the Kubernetes platform.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/refs/tags/v{{ config.ks_latest_release }}/scripts/create-kubestellar-demo-env.sh) --platform kind\n```\n\n----------------------------------------\n\nTITLE: Deploying Nginx Application in Shell\nDESCRIPTION: This command deploys an Nginx application, creating a namespace and a deployment with the necessary labels to match the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app.kubernetes.io/name: nginx\n  name: nginx\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: nginx\n  labels:\n    app.kubernetes.io/name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Checking Specific KubeStellar Prerequisites with Options\nDESCRIPTION: Example of using the check_pre_req.sh script with the --assert and --verbose flags to verify specific prerequisites (helm, argo, docker, kind) and display their version, path, and installation instructions.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/pre-reqs.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ check_pre_req.sh --assert --verbose helm argo docker kind\nChecking KubeStellar pre-requisites:\nâœ” Helm\n  version (unstructured): version.BuildInfo{Version:\"v3.14.0\", GitCommit:\"3fc9f4b2638e76f26739cd77c7017139be81d0ea\", GitTreeState:\"clean\", GoVersion:\"go1.21.5\"}\n     path: /usr/sbin/helm\nX ArgoCD CLI\n  how to install: https://argo-cd.readthedocs.io/en/stable/cli_installation/; get at least version v2\n```\n\n----------------------------------------\n\nTITLE: Creating K3D Hosting Cluster with Nginx Ingress\nDESCRIPTION: Commands to create a K3D cluster named kubeflex with nginx ingress controller. This cluster will host the KubeStellar control plane components with port 9443 exposed as 443.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nk3d cluster create -p \"9443:443@loadbalancer\" --k3s-arg \"--disable=traefik@server:*\" kubeflex\nhelm install ingress-nginx ingress-nginx --repo https://kubernetes.github.io/ingress-nginx --version 4.6.1 --namespace ingress-nginx --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for Multi-Cluster Workload Deployment in KubeStellar\nDESCRIPTION: This snippet creates a BindingPolicy in the WDS to deliver an app to all clusters. It specifies where to deploy the workload using clusterSelectors and what to deploy using downsync.objectSelectors.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {$(echo \"$label_query_both\" | tr , $'\\n' | while IFS=\"=\" read key val; do echo -n \", \\\"$key\\\": \\\"$val\\\"\"; done | tail -c +3)}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests with Make in KubeStellar\nDESCRIPTION: Executes all unit tests in the KubeStellar project using the make command. This is the simplest way to run tests and requires all prerequisites to be installed as described in the pre-reqs.md file.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/testing.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmake test\n```\n\n----------------------------------------\n\nTITLE: Creating Workload Description Space\nDESCRIPTION: Command to create a Workload Description Space (wds1) in KubeFlex. This space will be used to describe workloads that will be distributed to execution clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nkflex create wds1 -p kubestellar\n```\n\n----------------------------------------\n\nTITLE: Configuring ITSes in KubeStellar Helm Chart\nDESCRIPTION: YAML configuration for declaring Inventory and Transport Spaces (ITSes) in the values.yaml file. This snippet defines the structure for creating one or more ITSes, specifying control plane types, OCM installation options, and bootstrap secret configuration for external control planes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nITSes: # all the CPs in this list will execute the its.yaml PCH\n  - name: <its1>          # mandatory name of the control plane\n    type: <vcluster|host|external> # optional type of control plane: host, vcluster, or external (default to vcluster, if not specified)\n    install_clusteradm: true|false  # optional flag to enable/disable the installation of OCM in the control plane (default to true, if not specified)\n    bootstrapSecret: # this section is ignored unless type is \"external\"\n      name: <secret-name> # default: \"<control-plane-name>-bootstrap\"\n      namespace: <secret-namespace> # default: Helm chart installation namespace\n      key: <key-name> # default: \"kubeconfig-incluster\"\n  - name: <its2>          # mandatory name of the control plane\n    type: <vcluster|host|external> # optional type of control plane: host, vcluster, or external (default to vcluster, if not specified)\n    install_clusteradm: true|false  # optional flag to enable/disable the installation of OCM in the control plane (default to true, if not specified)\n    bootstrapSecret: # this section is ignored unless type is \"external\"\n      name: <secret-name> # default: \"<control-plane-name>-bootstrap\"\n      namespace: <secret-namespace> # default: Helm chart installation namespace\n      key: <key-name> # default: \"kubeconfig-incluster\"\n  ...\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for Nginx Deployment in Shell\nDESCRIPTION: This snippet creates a BindingPolicy to deliver an Nginx app to all clusters in 'wds1' with the label 'location-group=edge'. It specifies both where to deploy and what to deploy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Installing Helm Chart in KubeStellar Workspace\nDESCRIPTION: This snippet creates and labels a namespace, then installs a PostgreSQL Helm chart in the KubeStellar workspace. It demonstrates how to set up a multi-cluster deployment using Helm.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" create ns postgres-system\nkubectl --context \"$wds_context\" label ns postgres-system app.kubernetes.io/managed-by=Helm app.kubernetes.io/instance=postgres\nhelm --kube-context \"$wds_context\" install -n postgres-system postgres oci://registry-1.docker.io/bitnamicharts/postgresql\n```\n\n----------------------------------------\n\nTITLE: Verifying Nginx Deployment in KubeStellar WECs\nDESCRIPTION: These commands verify that the Nginx deployment has been created in both WEC clusters. They list the deployments in the nginx namespace for each cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" get deployments -n nginx\nkubectl --context \"$wec2_context\" get deployments -n nginx\n```\n\n----------------------------------------\n\nTITLE: Generating KubeStellar Derived Files with Make\nDESCRIPTION: Shell command to generate all derived files in the KubeStellar repository using the make system. This is necessary for contributors when modifying code that requires regeneration of derived files.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nmake all-generated\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Core Chart\nDESCRIPTION: Deploys KubeStellar Core chart using Helm with configuration for ITS and WDS instances.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set-json='ITSes=[{\"name\":\"its1\"}]' \\\n  --set-json='WDSes=[{\"name\":\"wds1\"}]'\n```\n\n----------------------------------------\n\nTITLE: Deploying Nginx for Resiliency Testing in KubeStellar\nDESCRIPTION: This snippet creates a new namespace and deploys an Nginx application for the resiliency test scenario in KubeStellar. It sets up the necessary resources with specific labels.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app.kubernetes.io/name: nginx-res\n  name: nginx-res\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-res-deployment\n  namespace: nginx-res\n  labels:\n    app.kubernetes.io/name: nginx-res\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-res\n  template:\n    metadata:\n      labels:\n        app: nginx-res\n    spec:\n      containers:\n      - name: nginx-res\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Initializing KubeFlex with Core Helm Chart\nDESCRIPTION: Helm command to install and initialize KubeFlex components, creating Inventory and Transport Space (ITS) and Workload Definition Spaces (WDS).\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart \\\n    --version $kubestellar_version \\\n    --set-json='ITSes=[{\"name\":\"its1\"}]' \\\n    --set-json='WDSes=[{\"name\":\"wds1\"},{\"name\":\"wds2\", \"type\":\"host\"}]' \\\n    --set-json='verbosity.default=5' # so we can debug your problem reports\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Demo Environment with k3d\nDESCRIPTION: Command for setting up a KubeStellar demonstration environment using the automated script with k3d as the Kubernetes platform.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/refs/tags/v{{ config.ks_latest_release }}/scripts/create-kubestellar-demo-env.sh) --platform k3d\n```\n\n----------------------------------------\n\nTITLE: Installing Local KubeStellar Core Chart with Helm\nDESCRIPTION: Commands to update dependencies and install local copy of KubeStellar core chart using Helm.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nhelm dependency update core-chart\nhelm upgrade --install ks-core core-chart\n```\n\n----------------------------------------\n\nTITLE: Deploying NGINX for Resiliency Testing\nDESCRIPTION: Creating a namespace and deployment for NGINX with specific labels to test propagation after control plane recovery. This validates that the system can continue functioning after a restart.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_37\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app.kubernetes.io/name: nginx-res\n  name: nginx-res\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-res-deployment\n  namespace: nginx-res\n  labels:\n    app.kubernetes.io/name: nginx-res\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-res\n  template:\n    metadata:\n      labels:\n        app: nginx-res\n    spec:\n      containers:\n      - name: nginx-res\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for Helm Chart Deployment in KubeStellar\nDESCRIPTION: This snippet creates a BindingPolicy for a Helm chart application in KubeStellar. It selects clusters based on specified labels and defines downsync rules for Helm-managed resources.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: postgres-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {$(echo \"$label_query_both\" | tr , $'\\n' | while IFS=\"=\" read key val; do echo -n \", \\\"$key\\\": \\\"$val\\\"\"; done | tail -c +3)}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\n      \"app.kubernetes.io/managed-by\": Helm,\n      \"app.kubernetes.io/instance\": postgres}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Initializing KubeFlex with kflex Command\nDESCRIPTION: This command installs the KubeFlex implementation in the cluster that kubectl is configured to access, assuming sufficient privileges.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/init-hosting-cluster.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkflex init\n```\n\n----------------------------------------\n\nTITLE: Updating KubeFlex Post-Create Hooks for KubeStellar\nDESCRIPTION: Applies KubeStellar and OCM configurations to KubeFlex post-create hooks. This ensures that KubeStellar is installed with the desired images during cluster creation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/kubestellar.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/ocm.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring WDSes in KubeStellar Helm Chart\nDESCRIPTION: YAML configuration for declaring Workload Description Spaces (WDSes) in the values.yaml file. This snippet defines the structure for creating one or more WDSes, specifying control plane types, APIGroups, and connecting to ITSes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nWDSes: # all the CPs in this list will execute the wds.yaml PCH\n  - name: <wds1>     # mandatory name of the control plane\n    type: <host|k8s> # optional type of control plane host or k8s (default to k8s, if not specified)\n    APIGroups: \"\"    # optional string holding a comma-separated list of APIGroups\n    ITSName: <its1>  # optional name of the ITS control plane, this MUST be specified if more than one ITS exists at the moment the WDS PCH starts\n  - name: <wds2>     # mandatory name of the control plane\n    type: <host|k8s> # optional type of control plane host or k8s (default to k8s, if not specified)\n    APIGroups: \"\"    # optional string holding a comma-separated list of APIGroups\n    ITSName: <its2>  # optional name of the ITS control plane, this MUST be specified if more than one ITS exists at the moment the WDS PCH starts\n  ...\n```\n\n----------------------------------------\n\nTITLE: Initializing KubeFlex and Creating OCM Space\nDESCRIPTION: Commands to initialize KubeFlex, apply KubeStellar and OCM configurations, rename the context, and create the its1 space with OCM running in it. This sets up the core infrastructure for KubeStellar.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nkflex init\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/kubestellar.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/ocm.yaml\nkubectl config rename-context k3d-kubeflex kind-kubeflex\nkflex create its1 --type vcluster -p ocm\n```\n\n----------------------------------------\n\nTITLE: Running Individual Integration Test Case\nDESCRIPTION: Executes a specific integration test by name using the go test command with filtering. This example runs only the TestCRDHandling test with a 60-second timeout and verbose output.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/testing.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngo test -v -timeout 60s -run ^TestCRDHandling$ ./test/integration/controller-manager\n```\n\n----------------------------------------\n\nTITLE: Creating a BindingPolicy with Different Downsync Clauses in YAML\nDESCRIPTION: An example of a BindingPolicy object that associates WECs with the 'location-group: edge' label to nginx workloads. It uses two different downsync clauses: one for namespaces and another with 'createOnly: true' for deployments.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/binding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx\nspec:\n  clusterSelectors:\n  - matchLabels:\n      location-group: edge\n  downsync:\n  - objectSelectors:\n    - matchLabels:\n        app.kubernetes.io/name: nginx\n    resources:\n    - namespaces\n  - createOnly: true\n    objectSelectors:\n    - matchLabels:\n        app.kubernetes.io/name: nginx\n    resources:\n    - deployments\n```\n\n----------------------------------------\n\nTITLE: Restarting Control Plane Components for Resiliency Testing\nDESCRIPTION: Commands to bring the control plane back online by scaling up the components that were previously scaled down, testing the system's ability to recover from an outage.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_35\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex scale deployment -n wds1-system kube-apiserver --replicas=1\nkubectl --context kind-kubeflex scale statefulset -n its1-system vcluster --replicas=1\nkubectl --context kind-kubeflex scale deployment -n kubeflex-system kubeflex-controller-manager --replicas=1\nkubectl --context kind-kubeflex scale deployment -n wds1-system kubestellar-controller-manager --replicas=1\nkubectl --context kind-kubeflex scale deployment -n wds1-system transport-controller --replicas=1\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for AppWrapper in KubeStellar\nDESCRIPTION: This snippet creates a BindingPolicy for the AppWrapper in the WDS. It specifies which clusters should receive the AppWrapper and what objects should be distributed based on labels.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: aw-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {$(echo \"$label_query_both\" | tr , $'\\n' | while IFS=\"=\" read key val; do echo -n \", \\\"$key\\\": \\\"$val\\\"\"; done | tail -c +3)}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/part-of\":\"my-appwrapper-app\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Verifying Application Deployment Across Clusters\nDESCRIPTION: Checks if the application has been successfully deployed to both target clusters by retrieving deployments, service accounts, and secrets in the 'nginx-sa' namespace.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_32\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" -n nginx-sa get deployments,sa,secrets\nkubectl --context \"$wec2_context\" -n nginx-sa get deployments,sa,secrets\n```\n\n----------------------------------------\n\nTITLE: Waiting for WDS Setup Completion\nDESCRIPTION: Monitors and waits for KubeStellar core components to finish setting up the WDS.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nwhile [ -z \"$(kubectl --context wds1 get crd bindingpolicies.control.kubestellar.io --no-headers -o name 2> /dev/null)\" ] ;  do\n    sleep 5\ndone\nkubectl --context wds1 wait --for condition=Established crd bindingpolicies.control.kubestellar.io\n```\n\n----------------------------------------\n\nTITLE: Verifying KubeStellar Code Generation\nDESCRIPTION: Shell command to verify that all derived files in the KubeStellar repository have been correctly generated. This check is aspired to be included in CI and requires a clean git state to function properly.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nhack/verify-codegen.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring CustomTransform for Job Objects in YAML\nDESCRIPTION: This YAML snippet defines a CustomTransform object that removes the 'suspend' field from the 'spec' of Job objects in the 'batch' API group. It demonstrates how to configure custom transformations for specific workload objects.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/transforming.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: control.kubestellar.io/v1alpha1\nkind: CustomTransform\nmetadata:\n  name: example\nspec:\n  apiGroup: batch\n  resource: jobs\n  remove:\n  - \"$.spec.suspend\"\n```\n\n----------------------------------------\n\nTITLE: Creating Inventory and Mailbox Space with OCM\nDESCRIPTION: Creates an inventory and mailbox space of type 'vcluster' running Open Cluster Management (OCM) in KubeFlex. This step includes the installation of the status add-on controller.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkflex create its1 --type vcluster -p ocm\n```\n\n----------------------------------------\n\nTITLE: Renaming K3D Container for Compatibility\nDESCRIPTION: Stops, renames, and restarts the K3D container to make it compatible with KubeStellar's internal URL lookup. This renames the default k3d-kubeflex-server-0 container to kubeflex-control-plane for consistency with Kind deployments.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker stop k3d-kubeflex-server-0\ndocker rename k3d-kubeflex-server-0 kubeflex-control-plane\ndocker start kubeflex-control-plane\n```\n\n----------------------------------------\n\nTITLE: KubeStellar Core Chart Configuration\nDESCRIPTION: YAML configuration values for customizing KubeStellar chart installation. Includes verbosity settings, KubeFlex operator configuration, and space creation options.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# Control controller log verbosity\n# The \"default\" verbosity value will be used for all controllers unless a specific controller verbosity override is specified\nverbosity:\n  default: 2\n  # Specific controller verbosity overrides:\n  # kubestellar: 6 (controller-manager)\n  # clusteradm: 6\n  # transport: 6\n\n# KubeFlex override values\nkubeflex-operator:\n  install: true # enable/disable the installation of KubeFlex by the chart (default: true)\n  installPostgreSQL: true # enable/disable the installation of the appropriate version of PostgreSQL required by KubeFlex (default: true)\n  isOpenShift: false # set this variable to true when installing the chart in an OpenShift cluster (default: false)\n  # Kind cluster specific settings:\n  domain: localtest.me # used to define the DNS domain name used from outside the KubeFlex hosting cluster to reach that cluster's Ingress endpoint (default: localtest.me)\n  externalPort: 9443 # used to set the port to access the Control Planes API (default: 9443)\n  hostContainer: kubeflex-control-plane # used to set the name of the container that runs the KubeFlex hosting cluster (default: kubeflex-control-plane, which corresponds to a Kind cluster with name kubeflex)\n\n# Determine if the Post Create Hooks should be installed by the chart\nInstallPCHs: true\n\n# List the Inventory and Transport Spaces (ITSes) to be created by the chart\n# Each ITS consists of:\n# - a mandatory unique name\n# - an optional type, which could be host, vcluster, or external (default to vcluster, if not specified)\n# - an optional install_clusteradm flag, which could be true  or false  (default to true) to enable/disable the installation of OCM in the control plane\n# - an optional bootstrapSecret secion to be used for Control Plabes of type external (more details below)\nITSes: # ==> installs ocm (optional) + ocm-status-addon\n\n# List the Workload Description Spaces (WDSes) to be created by the chart\n# Each WDS consists of a mandatory unique name and several optional parameters:\n# - type: host or k8s (default to k8s, if not specified)\n# - APIGroups: a comma separated list of APIGroups\n```\n\n----------------------------------------\n\nTITLE: Creating Workload Description Space in KubeFlex\nDESCRIPTION: Creates a Workload Description Space 'wds1' in KubeFlex. The '-p kubestellar' flag runs a post-create hook that starts a KubeStellar controller manager instance and deploys the OCM-based transport controller.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkflex create wds1 -p kubestellar\n```\n\n----------------------------------------\n\nTITLE: Configuring RBAC for AppWrapper in KubeStellar WECs\nDESCRIPTION: This snippet sets up RBAC rules in the WECs to allow the klusterlet to operate on AppWrapper resources. It creates a ClusterRole and ClusterRoleBinding for AppWrapper access.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nclusters=(\"$wec1_context\" \"$wec2_context\");\nfor cluster in \"${clusters[@]}\"; do\nkubectl --context ${cluster} apply -f - <<EOF\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: appwrappers-access\nrules:\n- apiGroups: [\"workload.codeflare.dev\"]\n  resources: [\"appwrappers\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: klusterlet-appwrappers-access\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: appwrappers-access\nsubjects:\n- kind: ServiceAccount\n  name: klusterlet-work-sa\n  namespace: open-cluster-management-agent\nEOF\ndone\n```\n\n----------------------------------------\n\nTITLE: Creating an ArgoCD Application\nDESCRIPTION: Creates a new ArgoCD application named 'nginx-sa' that deploys the nginx application from a GitHub repository to the WDS control plane in the 'nginx-sa' namespace.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\nargocd app create nginx-sa --repo https://github.com/pdettori/sample-apps.git --path nginx --dest-server https://\"${wds_cp}.${wds_cp}-system\" --dest-namespace nginx-sa\n```\n\n----------------------------------------\n\nTITLE: Listing Supported KubeStellar Prerequisites\nDESCRIPTION: Example showing how to list all the supported prerequisites that can be checked by the check_pre_req.sh script. The script supports checking for argo, brew, docker, go, helm, jq, kflex, kind, ko, kubectl, make, ocm, and yq.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/pre-reqs.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ check_pre_req.sh --list\nargo brew docker go helm jq kflex kind ko kubectl make ocm yq\n```\n\n----------------------------------------\n\nTITLE: Installing OCM CLI (clusteradm) to a Custom Directory for KubeStellar\nDESCRIPTION: This shell script installs the OCM CLI (clusteradm) to a custom directory without requiring root access. It creates a directory, sets the installation path, executes the installation script, and updates the PATH environment variable.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/pre-reqs.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p ocm\nexport INSTALL_DIR=\"$PWD/ocm\"\nbash <(curl -L https://raw.githubusercontent.com/open-cluster-management-io/clusteradm/main/install.sh) 0.10.1\nexport PATH=$PWD/ocm:$PATH\n```\n\n----------------------------------------\n\nTITLE: Creating and Registering Kind Clusters with OCM\nDESCRIPTION: Creates two kind clusters named cluster1 and cluster2, then registers them with the OCM hub using clusteradm. Uses a flags variable for internal endpoint lookup and iterates through cluster creation and registration process.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-wecs.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n: set flags to \"\" if you have installed KubeStellar on an OpenShift cluster\nflags=\"--force-internal-endpoint-lookup\"\nclusters=(cluster1 cluster2);\nfor cluster in \"${clusters[@]}\"; do\n   kind create cluster --name ${cluster}\n   kubectl config rename-context kind-${cluster} ${cluster}\n   clusteradm --context its1 get token | grep '^clusteradm join' | sed \"s/<cluster_name>/${cluster}/\" | awk '{print $0 \" --context '${cluster}' --singleton '${flags}'\"}' | sh\ndone\n```\n\n----------------------------------------\n\nTITLE: Verifying ManifestWorks Creation in Shell\nDESCRIPTION: These commands verify that ManifestWorks wrapping the objects have been created in the mailbox namespaces for both clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get manifestworks -n cluster1\nkubectl --context its1 get manifestworks -n cluster2\n```\n\n----------------------------------------\n\nTITLE: KubeStellar Component Relationship Flowchart\nDESCRIPTION: Mermaid flowchart showing relationships between KubeStellar components including repositories, container images, Helm charts, and setup processes. Illustrates dependencies and version management across components.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    subgraph osa_repo[\"ocm-status-addon@GitHub\"]\n    osa_code[OSA source code]\n    osa_hc_src[OSA Helm chart source]\n    end\n    osa_ctr_image[OSA container image] --> osa_code\n    osa_hc_repo[published OSA Helm Chart] --> osa_hc_src\n    osa_hc_src -.-> osa_ctr_image\n    osa_hc_repo -.-> osa_ctr_image\n    subgraph ks_repo[\"kubestellar@GitHub\"]\n    kcm_code[KCM source code]\n    gtc_code[\"generic transport<br>controller code\"]\n    otp_code[OTP source code]\n    ksc_hc_src[KS Core Helm chart source]\n    setup_ksc[\"'Getting Started' setup\"]\n    e2e_local[\"E2E setup<br>local\"]\n    e2e_release[\"E2E setup<br>release\"]\n    end\n    osa_repo -.-> ks_repo\n    kcm_ctr_image[KCM container image] --> kcm_code\n    otc_ctr_image[OTC container image]\n    otc_ctr_image --> gtc_code\n    otc_ctr_image --> otp_code\n    ksc_hc_repo[published KS Core chart] --> ksc_hc_src\n    ksc_hc_src -.-> osa_hc_repo\n    ksc_hc_src -.-> kcm_ctr_image\n    ksc_hc_src -.-> otc_ctr_image\n    ksc_hc_repo -.-> osa_hc_repo\n    ksc_hc_repo -.-> kcm_ctr_image\n    ksc_hc_repo -.-> otc_ctr_image\n    setup_ksc -.-> ksc_hc_repo\n    setup_ksc -.-> KubeFlex\n    e2e_local -.-> ksc_hc_src\n    e2e_local -.-> KubeFlex\n    e2e_release -.-> ksc_hc_repo\n    e2e_release -.-> KubeFlex\n```\n\n----------------------------------------\n\nTITLE: Labeling Workload Execution Clusters\nDESCRIPTION: Applies labels to managed clusters for workload selection in examples.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-hub label managedcluster cluster1 location-group=edge name=cluster1\nkubectl --context kind-hub label managedcluster cluster2 location-group=edge name=cluster2\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy with Singleton Status in KubeStellar\nDESCRIPTION: This snippet creates a BindingPolicy with the wantSingletonReportedState flag set, enabling full status updates for selected resources in KubeStellar.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-singleton-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"name\":\"cluster1\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx-singleton\"}\n    wantSingletonReportedState: true\nEOF\n```\n\n----------------------------------------\n\nTITLE: Deploying NGINX for Singleton Status Testing\nDESCRIPTION: Creating an NGINX deployment with specific labels that match the singleton BindingPolicy selector, intended to demonstrate status reporting.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-singleton-deployment\n  labels:\n    app.kubernetes.io/name: nginx-singleton\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Retrieving Argo CD Admin Password in Shell\nDESCRIPTION: This command retrieves the initial password for the 'admin' user in Argo CD. It uses kubectl to get the secret, extracts the password field, and decodes it from base64.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart-argocd.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n```\n\n----------------------------------------\n\nTITLE: Configuring KubeFlex Contexts\nDESCRIPTION: Series of commands to configure kubectl contexts for KubeFlex control planes and ensure the KubeFlex CLI's state is correct.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config use-context kind-kubeflex # this is here only to remind you, it will already be the current context if you are following this recipe exactly\nkflex ctx --set-current-for-hosting # make sure the KubeFlex CLI's hidden state is right for what the Helm chart just did\nkflex ctx --overwrite-existing-context wds1\nkflex ctx --overwrite-existing-context wds2\nkflex ctx --overwrite-existing-context its1\n```\n\n----------------------------------------\n\nTITLE: Verifying Deployment for Resiliency Testing in KubeStellar\nDESCRIPTION: This snippet checks if the Nginx deployment for the resiliency test has been created in both managed clusters, demonstrating multi-cluster deployment verification.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" get deployments -n nginx-res\nkubectl --context \"$wec2_context\" get deployments -n nginx-res\n```\n\n----------------------------------------\n\nTITLE: Applying AppWrapper Object in Shell\nDESCRIPTION: This command applies an AppWrapper object to wds2.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds2 apply -f  https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/test/yaml/0008-aw-default.yaml\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Controller and OCM Space\nDESCRIPTION: Commands to initialize KubeFlex, install KubeStellar controller, set up OCM space, and rename the context. This creates the infrastructure for KubeStellar to manage workloads across clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl edit deployment ingress-nginx-controller -n ingress-nginx\n```\n\n----------------------------------------\n\nTITLE: Creating Workload Description Space with KubeStellar\nDESCRIPTION: Creates a Workload Description Space 'wds1' in KubeFlex, running an instance of KubeStellar controller manager and OCM-based transport controller.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkflex create wds1 -p kubestellar\n```\n\n----------------------------------------\n\nTITLE: Creating Argo CD Application for EdgePlacement\nDESCRIPTION: This console snippet shows the command and output for creating an Argo CD application to manage an EdgePlacement resource in the KubeStellar WMW.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n$ argocd app create edgeplacement \\\n--repo https://github.com/edge-experiments/gitops-source.git \\\n--path kubestellar/placements/ \\\n--dest-server https://172.31.31.125:6443/clusters/root:my-org:wmw-turbo \\\n--sync-policy automated\napplication 'edgeplacement' created\n```\n\n----------------------------------------\n\nTITLE: Registering Cluster1 with OCM\nDESCRIPTION: Commands to register cluster1 with OCM, including getting the join token, applying it, waiting for the CSR, and accepting the cluster. This establishes the management relationship between the OCM hub and cluster1.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nflags=\"--force-internal-endpoint-lookup\"\nclusteradm --context its1 get token | grep '^clusteradm join' | sed \"s/<cluster_name>/cluster1/\" | awk '{print $0 \" --context \\'cluster1\\' \\'${flags}\\'\"}'  | sh\n```\n\n----------------------------------------\n\nTITLE: Adding WDS Cluster to ArgoCD\nDESCRIPTION: Script to add the WDS cluster to ArgoCD's managed clusters, including configuration and authentication steps.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nCONTEXT=wds1\nkubectl config view --minify --context=${CONTEXT} --flatten > /tmp/${CONTEXT}.kubeconfig\nkubectl config --kubeconfig=/tmp/${CONTEXT}.kubeconfig set-cluster ${CONTEXT}-cluster --server=https://${CONTEXT}.${CONTEXT}-system 2>/dev/null\nkubectl config use-context kind-kubeflex\nARGO_SERVER_POD=$(kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server -o 'jsonpath={.items[0].metadata.name}')\nkubectl cp /tmp/${CONTEXT}.kubeconfig -n argocd ${ARGO_SERVER_POD}:/tmp\nPASSWORD=$(argocd admin initial-password -n argocd | cut -d \" \" -f 1)\nkubectl exec -it -n argocd $ARGO_SERVER_POD -- argocd login argocd-server.argocd --username admin --password $PASSWORD --insecure\nkubectl exec -it -n argocd $ARGO_SERVER_POD -- argocd cluster add ${CONTEXT} --kubeconfig /tmp/${CONTEXT}.kubeconfig -y\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Core Components\nDESCRIPTION: Uses Helm chart to install KubeFlex, configure ITS, and create WDS in the hosting cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context kind-hub upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart \\\n    --version $kubestellar_version \\\n    --set-json='ITSes=[{\"name\":\"its1\", \"type\":\"host\"}]' \\\n    --set-json='WDSes=[{\"name\":\"wds1\"}]' \\\n    --set-json='verbosity.default=5'\n```\n\n----------------------------------------\n\nTITLE: Creating KubeStellar Cluster and Bootstrap Secret\nDESCRIPTION: Commands to create a KubeStellar-ready cluster and set up bootstrap secret for external cluster connection.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v$KUBESTELLAR_VERSION/scripts/create-kind-cluster-with-SSL-passthrough.sh) --name kubeflex --port 9443\n\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v$KUBESTELLAR_VERSION/scripts/create-external-bootstrap-secret.sh) --controlplane its1 --source-context kind-ext1 --address https://ext1-control-plane:6443 --verbose\n```\n\n----------------------------------------\n\nTITLE: Filtering WECs with Deployment Availability Issues in YAML\nDESCRIPTION: A YAML configuration for CombinedStatus that filters for deployments where the available replicas don't match the desired replicas, helping identify problematic WECs.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n  filter: \"obj.spec.replicas != returned.status.availableReplicas\"\n  select:\n     - name: wec\n       def: inventory.name\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Example Scenarios\nDESCRIPTION: Commands to set environment variables needed for running KubeStellar example scenarios, defining contexts and names for the different clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nhost_context=kind-kubeflex\nits_cp=its1\nits_context=its1\nwds_cp=wds1\nwds_context=wds1\nwec1_name=cluster1\nwec2_name=cluster2\nwec1_context=$wec1_name\nwec2_context=$wec2_name\nlabel_query_both=location-group=edge\nlabel_query_one=name=cluster1\n```\n\n----------------------------------------\n\nTITLE: Applying BindingPolicy for AppWrapper in Shell\nDESCRIPTION: This command applies a BindingPolicy for the AppWrapper, specifying cluster selectors and downsync rules.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds2 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: aw-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/part-of\":\"my-appwrapper-app\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Creating Argo CD Application for SyncTargets\nDESCRIPTION: This console snippet demonstrates the command and output for creating an Argo CD application to manage SyncTargets in the KubeStellar IMW.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ argocd app create synctargets \\\n--repo https://github.com/edge-experiments/gitops-source.git \\\n--path kubestellar/synctargets/ \\\n--dest-server https://172.31.31.125:6443/clusters/root:imw-turbo \\\n--sync-policy automated\napplication 'synctargets' created\n```\n\n----------------------------------------\n\nTITLE: Verifying Deployment Propagation After Restart\nDESCRIPTION: Commands to check that the NGINX deployment has been successfully propagated to both managed clusters after the control plane restart, confirming the system's resiliency.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_38\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get deployments -n nginx-res\nkubectl --context cluster2 get deployments -n nginx-res\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version Environment Variables\nDESCRIPTION: Environment variable configuration for KubeStellar deployment. Specifies the versions of KubeStellar, OCM-status-addon, and OCM-transport-plugin to be installed.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION=0.22.0\nexport OCM_STATUS_ADDON_VERSION=0.2.0-rc8\nexport OCM_TRANSPORT_PLUGIN=0.1.7\n```\n\n----------------------------------------\n\nTITLE: Creating Kind Cluster for KubeFlex\nDESCRIPTION: Command to create a Kind cluster with SSL passthrough enabled that will host KubeFlex components.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v{{ config.ks_latest_release }}/scripts/create-kind-cluster-with-SSL-passthrough.sh) --name kubeflex --port 9443\n```\n\n----------------------------------------\n\nTITLE: Restarting KubeStellar Control Plane Components for Resiliency Testing\nDESCRIPTION: This snippet restarts the previously stopped components of the KubeStellar control plane to complete the resiliency test.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system kube-apiserver --replicas=1\nkubectl --context \"$host_context\" scale statefulset -n \"$its_cp\"-system vcluster --replicas=1\nkubectl --context \"$host_context\" scale deployment -n kubeflex-system kubeflex-controller-manager --replicas=1\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system kubestellar-controller-manager --replicas=1\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system transport-controller --replicas=1\n```\n\n----------------------------------------\n\nTITLE: Checking Deployment Status Reflection in WDS1\nDESCRIPTION: Command to verify that the status of the deployment in the managed cluster is being reported back to the workspace due to the singleton status setting.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 get deployments nginx-singleton-deployment -o yaml\n```\n\n----------------------------------------\n\nTITLE: Checking KubeStellar Prerequisites\nDESCRIPTION: Script to verify required prerequisites for KubeStellar installation including kflex, ocm, helm, kubectl, docker, and kind.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl https://raw.githubusercontent.com/kubestellar/kubestellar/v{{ config.ks_latest_release }}/scripts/check_pre_req.sh) kflex ocm helm kubectl docker kind\n```\n\n----------------------------------------\n\nTITLE: Creating Helm Chart BindingPolicy for Scenario 3\nDESCRIPTION: Definition of a BindingPolicy that selects clusters with the 'location-group:edge' label and propagates objects managed by Helm with the postgres instance name.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: postgres-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\n      \"app.kubernetes.io/managed-by\": Helm,\n      \"app.kubernetes.io/instance\": postgres}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Adding KubeStellar Workspace to Argo CD\nDESCRIPTION: This console snippet demonstrates the command and output for adding a KubeStellar workspace (WMW) to Argo CD as a cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ argocd cluster add --name wmw --kubeconfig ./admin.kubeconfig workspace.kcp.io/current\nWARNING: This will create a service account `argocd-manager` on the cluster referenced by context `workspace.kcp.io/current` with full cluster level privileges. Do you want to continue [y/N]? y\nINFO[0001] ServiceAccount \"argocd-manager\" already exists in namespace \"kube-system\"\nINFO[0001] ClusterRole \"argocd-manager-role\" updated\nINFO[0001] ClusterRoleBinding \"argocd-manager-role-binding\" updated\nCluster 'https://172.31.31.125:6443/clusters/root:my-org:wmw-turbo' added\n```\n\n----------------------------------------\n\nTITLE: Defining ClusterLogForwarder with Template Expansion in YAML\nDESCRIPTION: This YAML snippet shows a ClusterLogForwarder object with template expansion enabled. It demonstrates how to use the 'control.kubestellar.io/expand-templates' annotation and template syntax for customizing the 'url' field based on WEC properties.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/transforming.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: logging.openshift.io/v1\nkind: ClusterLogForwarder\nmetadata:\n  name: instance\n  namespace: openshift-logging\n  annotations:\n    control.kubestellar.io/expand-templates: \"true\"\nspec:\n  outputs:\n    - name: remote-loki\n      type: loki\n      url: \"https://my.loki.server.com/{{{ .clusterName }}}-{{{ .clusterHash }}}\"\n...\n```\n\n----------------------------------------\n\nTITLE: Creating Control Plane Context using kflex CLI\nDESCRIPTION: Commands to add and manage control plane contexts using the kflex CLI tool, including context deletion and creation\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config delete-context $cpname\nkflex ctx $cpname\n```\n\n----------------------------------------\n\nTITLE: Applying AppWrapper Object in KubeStellar WDS\nDESCRIPTION: This command applies an AppWrapper object to the WDS. It's part of the out-of-tree workload scenario, demonstrating the deployment of a custom resource.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f  https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/test/yaml/0008-aw-default.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring KubeFlex Context\nDESCRIPTION: Sets up the required kubeconfig context for WDS access.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config use-context kind-hub\nkflex ctx --set-current-for-hosting\nkflex ctx --overwrite-existing-context wds1\n```\n\n----------------------------------------\n\nTITLE: Accepting Cluster2 in OCM\nDESCRIPTION: Command to accept the pending cluster2 in OCM. This completes the registration of the second cluster in the OCM environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm --context its1 accept --clusters cluster2\n```\n\n----------------------------------------\n\nTITLE: Waiting for Cluster2 CSR Creation\nDESCRIPTION: Command to watch for the cluster signing request (CSR) from cluster2. This ensures the registration process is proceeding correctly before accepting the second cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get csr --watch || true\n```\n\n----------------------------------------\n\nTITLE: Configuring Pod Phase Histogram Collection in YAML\nDESCRIPTION: A YAML configuration for StatusCollector that groups pods by their phase and counts occurrences. This creates a histogram showing the distribution of pod phases across WECs.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n  groupBy:\n     - name: phase\n       def: returned.status.phase\n  combinedFields:\n     - name: count\n       type: COUNT\n```\n\n----------------------------------------\n\nTITLE: Creating Inventory and Mailbox Space with OCM in KubeFlex\nDESCRIPTION: Creates an inventory & mailbox space of type 'vcluster' running OCM in KubeFlex. The '-p ocm' flag runs a post-create hook on the vcluster control plane to install OCM, including the status add-on controller.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkflex create its1 --type vcluster -p ocm\n```\n\n----------------------------------------\n\nTITLE: Creating Argo CD Application for Deployment\nDESCRIPTION: This console snippet demonstrates the command and output for creating an Argo CD application to manage a Deployment (cpumemload) in the KubeStellar WMW.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ argocd app create cpumemload \\\n--repo https://github.com/edge-experiments/gitops-source.git \\\n--path kubestellar/workloads/cpumemload/ \\\n--dest-server https://172.31.31.125:6443/clusters/root:my-org:wmw-turbo \\\n--sync-policy automated\napplication 'cpumemload' created\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for Resiliency Testing\nDESCRIPTION: Definition of a BindingPolicy targeting edge clusters for deploying NGINX resources with specific labels after the control plane restart.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_36\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-res-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx-res\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables\nDESCRIPTION: Defines shell variables required for example scenarios execution.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nhost_context=kind-hub\nits_cp=its1\nits_context=${host_context}\nwds_cp=wds1\nwds_context=wds1\nwec1_name=cluster1\nwec2_name=cluster2\nwec1_context=kind-$wec1_name\nwec2_context=kind-$wec2_name\nlabel_query_both=location-group=edge\nlabel_query_one=name=cluster1\n```\n\n----------------------------------------\n\nTITLE: Installing OCM CLI (clusteradm) for KubeStellar\nDESCRIPTION: This shell command installs the OCM CLI (clusteradm) version 0.10.1 required for KubeStellar. The command downloads and executes the installation script from the OCM GitHub repository.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/pre-reqs.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -L https://raw.githubusercontent.com/open-cluster-management-io/clusteradm/main/install.sh) 0.10.1\n```\n\n----------------------------------------\n\nTITLE: Installing AppWrapper CRD in KubeStellar WDS and WECs\nDESCRIPTION: This snippet installs the AppWrapper CustomResourceDefinition in the WDS and WECs. It's part of the setup for the out-of-tree workload scenario.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nclusters=(\"$wds_context\" \"$wec1_context\" \"$wec2_context\");\n  for cluster in \"${clusters[@]}\"; do\n  kubectl --context ${cluster} apply -f https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/config/crd/bases/workload.codeflare.dev_appwrappers.yaml\ndone\n```\n\n----------------------------------------\n\nTITLE: Upgrading Existing Installation with Additional Control Planes\nDESCRIPTION: Command to upgrade existing KubeStellar installation with additional WDS while preserving existing configuration.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set-json='ITSes=[{\"name\":\"its1\"}]' \\\n  --set-json='WDSes=[{\"name\":\"wds1\"},{\"name\":\"wds2\"}]'\n```\n\n----------------------------------------\n\nTITLE: Checking KubeStellar Controller Status in Shell\nDESCRIPTION: This command checks that the KubeStellar controller for wds2 has started.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get deployments.apps -n wds2-system kubestellar-controller-manager\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Core with ITS and WDS Configuration\nDESCRIPTION: Command to install KubeStellar core with configured ITS and WDS control planes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set-json='ITSes=[{\"name\":\"its1\"}]' \\\n  --set-json='WDSes=[{\"name\":\"wds1\"}]'\n```\n\n----------------------------------------\n\nTITLE: Verifying AppWrapper Delivery in Shell\nDESCRIPTION: These commands check that the AppWrapper has been delivered to both clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get appwrappers\nkubectl --context cluster2 get appwrappers\n```\n\n----------------------------------------\n\nTITLE: Configuring Resource Exclusions in Argo CD\nDESCRIPTION: This YAML snippet shows how to configure resource exclusions in the Argo CD ConfigMap to exclude ClusterWorkspace resources from discovery and sync.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndata:\n  resource.exclusions: |\n    - apiGroups:\n      - \"tenancy.kcp.io\"\n      kinds:\n      - \"ClusterWorkspace\"\n      clusters:\n      - \"*\"\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for ArgoCD ServiceAccount\nDESCRIPTION: Applies a BindingPolicy to wds1 that configures workload syncing for ArgoCD-managed resources labeled with 'nginx-sa' to clusters with the 'edge' location-group label.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_40\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: argocd-sa-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"argocd.argoproj.io/instance\":\"nginx-sa\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Stopping Control Plane Components for Resiliency Testing\nDESCRIPTION: Commands to simulate a control plane outage by scaling down all the relevant deployments and statefulsets in the KubeFlex and KubeStellar environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_34\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex scale deployment -n wds1-system kube-apiserver --replicas=0\nkubectl --context kind-kubeflex scale statefulset -n its1-system vcluster --replicas=0\nkubectl --context kind-kubeflex scale deployment -n kubeflex-system kubeflex-controller-manager --replicas=0\nkubectl --context kind-kubeflex scale deployment -n wds1-system kubestellar-controller-manager --replicas=0\nkubectl --context kind-kubeflex scale deployment -n wds1-system transport-controller --replicas=0\n```\n\n----------------------------------------\n\nTITLE: Deploying Nginx Application in KubeStellar WDS\nDESCRIPTION: This snippet deploys an Nginx application in the WDS. It creates a namespace and a deployment for Nginx, which will be distributed to the selected clusters based on the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app.kubernetes.io/name: nginx\n  name: nginx\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: nginx\n  labels:\n    app.kubernetes.io/name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Verifying Helm Chart Visibility in Managed Clusters\nDESCRIPTION: Commands to confirm that after labeling the Helm metadata secret, the Helm release is now visible when running Helm commands in the managed clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\nhelm list --kube-context cluster1 -n postgres-system\nhelm list --kube-context cluster2 -n postgres-system\n```\n\n----------------------------------------\n\nTITLE: Running Basic Ginkgo E2E Tests for KubeStellar\nDESCRIPTION: Basic command to run the E2E test suite with ginkgo. Uses KFLEX_DISABLE_CHATTY to suppress kubeflex logging and includes verbose output and trace options.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/ginkgo/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nKFLEX_DISABLE_CHATTY=true ginkgo --vv --trace --no-color\n```\n\n----------------------------------------\n\nTITLE: Installing ArgoCD on KubeFlex Cluster\nDESCRIPTION: Commands to create ArgoCD namespace and deploy ArgoCD components in the KubeFlex hosting cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex create namespace argocd\nkubectl --context kind-kubeflex apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n```\n\n----------------------------------------\n\nTITLE: Accepting Cluster1 in OCM\nDESCRIPTION: Command to accept the pending cluster1 in OCM. This completes the registration process and establishes cluster1 as a managed cluster in the OCM environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm --context its1 accept --clusters cluster1\n```\n\n----------------------------------------\n\nTITLE: Waiting for ITS Initialization\nDESCRIPTION: Commands to wait for the Inventory and Transport Space (ITS) to complete initialization through OCM's clusteradm tool.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex wait controlplane.tenancy.kflex.kubestellar.org/its1 --for 'jsonpath={.status.postCreateHooks.its-with-clusteradm}=true' --timeout 90s\nkubectl --context kind-kubeflex wait -n its1-system job.batch/its-with-clusteradm --for condition=Complete --timeout 150s\n```\n\n----------------------------------------\n\nTITLE: Checking Deployments and StatefulSets in Kubernetes Hosting Cluster\nDESCRIPTION: Retrieves and displays all deployments and statefulsets across all namespaces in the Kubernetes hosting cluster. This command is used to verify the correct setup of KubeStellar components.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex get deployments,statefulsets --all-namespaces\n```\n\n----------------------------------------\n\nTITLE: Transport Controller Interface Requirements in Go\nDESCRIPTION: Interface definition for Transport Controller plugins, requiring namespace management for WECs, object wrapping capabilities, agent support for pulling wrapped objects, and cluster inventory representation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/architecture.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ninterface {\n    // Create/delete namespace for WEC in ITS\n    ManageWECNamespace()\n    \n    // Wrap multiple objects into single wrapped object\n    WrapObjects(objects []runtime.Object) (*runtime.Object, error)\n    \n    // Agent capabilities for pulling and applying wrapped objects\n    PullAndApplyObjects()\n    \n    // Cluster inventory representation\n    GetClusterInventory() ClusterInventory\n}\n```\n\n----------------------------------------\n\nTITLE: Installing KubeStellar Core Chart\nDESCRIPTION: Helm command to install KubeStellar core chart with specific configurations for OpenShift and host-type ITSes and WDSes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set \"kubeflex-operator.isOpenShift=true\" \\\n  --set-json='ITSes=[{\"name\":\"its0\",\"type\":\"host\"}]' \\\n  --set-json='WDSes=[{\"name\":\"wds0\",\"type\":\"host\"}]'\n```\n\n----------------------------------------\n\nTITLE: Installing Python Requirements for Documentation in Shell\nDESCRIPTION: This shell command installs the Python requirements for the documentation system using pip.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Scaling the Singleton Deployment\nDESCRIPTION: Command to scale the deployment from 1 to 2 replicas in the WDS1 workspace to test if the change propagates to the managed cluster and if the status reflects back.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_31\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 scale deployment nginx-singleton-deployment --replicas=2\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Generated Workload Objects\nDESCRIPTION: Commands to navigate to the clusterloader2 directory and run the cleanup script to remove workload objects.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncd $CL2_DIR\n./cleanup.sh\n```\n\n----------------------------------------\n\nTITLE: Running KubeStellar Snapshot Script\nDESCRIPTION: A command to download and execute the KubeStellar snapshot script, which captures relevant system state for troubleshooting. The script collects logs, API objects, and other diagnostic information into an archive file.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/troubleshooting.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/refs/heads/main/scripts/kubestellar-snapshot.sh) -V -Y -L\n```\n\n----------------------------------------\n\nTITLE: Confirming and Labeling Cluster1\nDESCRIPTION: Commands to confirm cluster1 is accepted and to label it for the BindingPolicy. The labels determine which workloads will be distributed to this cluster based on placement rules.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get managedclusters\nkubectl --context its1 label managedcluster cluster1 location-group=edge name=cluster1\n```\n\n----------------------------------------\n\nTITLE: Checking and Labeling Managed Clusters\nDESCRIPTION: Commands to verify the managed clusters are in the OCM inventory and apply location-group and name labels to them.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-wecs.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get managedclusters\nkubectl --context its1 label managedcluster cluster1 location-group=edge name=cluster1\nkubectl --context its1 label managedcluster cluster2 location-group=edge name=cluster2\n```\n\n----------------------------------------\n\nTITLE: Creating Singleton Status BindingPolicy for Scenario 4\nDESCRIPTION: Definition of a BindingPolicy with the experimental wantSingletonReportedState flag enabled, targeting only cluster1 for deployment with specific labels.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-singleton-bpolicy\nspec:\n  wantSingletonReportedState: true\n  clusterSelectors:\n  - matchLabels: {\"name\":\"cluster1\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx-singleton\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Custom Transform Cache Data Structure in Go\nDESCRIPTION: Cache implementation for efficient application of CustomTransform objects, defining relations for USES, INSTRUCTIONS, and SPECS with their corresponding data types and keys.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/architecture.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype customTransformCollectionImpl struct {\n    bindingNameToGroupResources map[string][]metav1.GroupResource\n    grToTransformData struct {\n        bindingsThatCare []string\n        removes []jsonpath.Query\n        ctNames []string\n    }\n    ctNameToSpec map[string]CustomTransformSpec\n}\n```\n\n----------------------------------------\n\nTITLE: Import Control Plane Contexts Script\nDESCRIPTION: Command to download and execute the import-cp-contexts.sh script for importing KubeFlex Control Planes\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v$KUBESTELLAR_VERSION/scripts/import-cp-contexts.sh) --merge\n```\n\n----------------------------------------\n\nTITLE: Applying BindingPolicy to the Workload Deployment Service\nDESCRIPTION: Creates a BindingPolicy named 'argocd-sa-bpolicy' that targets clusters matching specified labels. This policy synchronizes objects labeled with the ArgoCD instance 'nginx-sa' to the selected clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_27\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: argocd-sa-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {$(echo \"$label_query_both\" | tr , $'\\n' | while IFS=\"=\" read key val; do echo -n \", \\\"$key\\\": \\\"$val\\\"\"; done | tail -c +3)}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"argocd.argoproj.io/instance\":\"nginx-sa\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Teardown for Scenario 4\nDESCRIPTION: Commands to remove the singleton BindingPolicy and the deployment created for the singleton status testing.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_33\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 delete bindingpolicies nginx-singleton-bpolicy\nkubectl --context wds1 delete deployments nginx-singleton-deployment\n```\n\n----------------------------------------\n\nTITLE: Example CombinedStatus Object in YAML\nDESCRIPTION: This YAML snippet shows an example of a CombinedStatus object resulting from the 'count-wecs' StatusCollector. It includes metadata and the result of the count operation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: control.kubestellar.io/v1alpha1\nkind: CombinedStatus\nmetadata:\n  creationTimestamp: \"2024-11-07T20:15:27Z\"\n  generation: 1\n  labels:\n    status.kubestellar.io/api-group: apps\n    status.kubestellar.io/binding-policy: nginx-bindingpolicy\n    status.kubestellar.io/name: nginx-deployment\n    status.kubestellar.io/namespace: nginx\n    status.kubestellar.io/resource: deployments\n  name: 0990056b-ccbc-4c46-b0fe-366ef3a2de5e.332d2c17-7b55-44f6-9a6e-21445523c808\n  namespace: nginx\n  resourceVersion: \"604\"\n  uid: cc167004-073e-4a20-9857-449f692e9643\nresults:\n- columnNames:\n  - count\n  name: count-wecs\n  rows:\n  - columns:\n    - float: \"2\"\n      type: Number\n```\n\n----------------------------------------\n\nTITLE: Deploying OCM Transport Controller\nDESCRIPTION: Helm command to install the OCM-based transport controller. This controller is responsible for transporting workloads from the Workload Description Space to the OCM infrastructure for distribution to execution clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context kind-kubeflex upgrade --install ocm-transport-plugin oci://ghcr.io/kubestellar/ocm-transport-plugin/chart/ocm-transport-plugin --version ${OCM_TRANSPORT_PLUGIN} \\\n --set transport_cp_name=its1 \\\n --set wds_cp_name=wds1 \\\n -n wds1-system\n```\n\n----------------------------------------\n\nTITLE: Approving Cluster Registration\nDESCRIPTION: Commands to approve the Certificate Signing Requests for both clusters to complete their registration with the OCM hub.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-wecs.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm --context its1 accept --clusters cluster1\nclusteradm --context its1 accept --clusters cluster2\n```\n\n----------------------------------------\n\nTITLE: Checking Secret Distribution\nDESCRIPTION: Verifies the creation and distribution of secrets across WDS and target clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_46\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 -n nginx-sa get secrets\nkubectl --context cluster1 -n nginx-sa get secrets\nkubectl --context cluster2 -n nginx-sa get secrets\n```\n\n----------------------------------------\n\nTITLE: Removing KubeFlex Hidden State\nDESCRIPTION: Command to remove the KubeFlex preferences from kubeconfig file. This can be used when troubleshooting context-related issues, allowing subsequent kflex ctx commands to work with the current context.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kflex-extension.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nyq -i 'del(.preferences)' ${KUBECONFIG:-$HOME/.kube/config}\n```\n\n----------------------------------------\n\nTITLE: Syncing ArgoCD Application via CLI\nDESCRIPTION: Synchronizes the 'nginx-sa' application using the ArgoCD CLI, which triggers the deployment to the target clusters based on the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_31\n\nLANGUAGE: shell\nCODE:\n```\nargocd app sync nginx-sa\n```\n\n----------------------------------------\n\nTITLE: Tearing Down Multi-Cluster Workload Deployment in KubeStellar\nDESCRIPTION: These commands remove the Nginx deployment and BindingPolicy from the WDS, effectively cleaning up the resources created in Scenario 1.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" delete ns nginx\nkubectl --context \"$wds_context\" delete bindingpolicies nginx-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Editing Workload Configuration File\nDESCRIPTION: Command to edit the long-duration experiment configuration file to customize workload parameters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nvi long-duration-exp-config.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating Kind Cluster for KubeStellar\nDESCRIPTION: Creates a new local Kind cluster with SSL passthrough configuration required for KubeStellar setup.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/scripts/create-kind-cluster-with-SSL-passthrough.sh) --name kubeflex --port 9443\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version\nDESCRIPTION: Sets the KubeStellar version as an environment variable for installation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubestellar_version={{ config.ks_latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Checking Certificate Signing Requests\nDESCRIPTION: Command to check the status of Certificate Signing Requests (CSRs) for the newly created clusters in the OCM hub context.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-wecs.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get csr\n```\n\n----------------------------------------\n\nTITLE: Configuring WEC Properties with ConfigMap in YAML\nDESCRIPTION: This YAML snippet defines a ConfigMap in the 'customization-properties' namespace to provide WEC-specific properties. It shows how to set the 'clusterHash' property for the 'virgo' WEC, which can be used in template expansion.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/transforming.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: customization-properties\n  name: virgo\ndata:\n  clusterHash: 1001-dead-beef\n...\n```\n\n----------------------------------------\n\nTITLE: Configuring Argo CD Application in YAML\nDESCRIPTION: This YAML snippet defines an Argo CD application configuration within the KubeStellar Core chart values. It specifies details such as the application name, source repository, target revision, destination WDS, and sync policy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart-argocd.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nargo-cd:\n  applications: # list of Argo CD applications to be create\n  - name: scenario-6 # required, must be unique\n    project: default # default: default\n    repoURL: https://github.com/pdettori/sample-apps.git\n    targetRevision: HEAD # default: HEAD\n    path: nginx\n    destinationWDS: wds1\n    destinationNamespace: nginx-sa # default: default\n    syncPolicy: auto # default: manual\n```\n\n----------------------------------------\n\nTITLE: Basic Ginkgo Test Execution\nDESCRIPTION: Command to run the performance tests using Ginkgo testing framework with verbose output.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/performance/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nginkgo -v\n```\n\n----------------------------------------\n\nTITLE: Labeling Helm Metadata Secret for Multi-Cluster Propagation\nDESCRIPTION: This snippet labels the Helm metadata Secret to enable its propagation to managed clusters. It allows Helm to recognize its releases in the managed clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" label secret -n postgres-system $(kubectl --context \"$wds_context\" get secrets -n postgres-system -l name=postgres -l owner=helm  -o jsonpath='{.items[0].metadata.name}') app.kubernetes.io/managed-by=Helm app.kubernetes.io/instance=postgres\n```\n\n----------------------------------------\n\nTITLE: Removing KubeFlex ClusterRoleBinding\nDESCRIPTION: Command to delete the admin role binding for the KubeFlex manager, needed if this step hasn't been completed previously.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex delete clusterrolebinding kubeflex-manager-cluster-admin-rolebinding\n```\n\n----------------------------------------\n\nTITLE: Setting Up External OCM Cluster\nDESCRIPTION: Commands to create and initialize a Kind cluster with OCM installation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nkind create cluster --name ext1\n\nclusteradm init\n```\n\n----------------------------------------\n\nTITLE: Creating ArgoCD Application\nDESCRIPTION: Creates a new ArgoCD application pointing to a sample nginx repository with specific destination parameters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_42\n\nLANGUAGE: shell\nCODE:\n```\nargocd app create nginx-sa --repo https://github.com/pdettori/sample-apps.git --path nginx --dest-server https://wds1.wds1-system --dest-namespace nginx-sa\n```\n\n----------------------------------------\n\nTITLE: Switching Kubernetes Context to Hosting Cluster\nDESCRIPTION: Changes the current kubectl context to the hosting cluster and sets the namespace to 'argocd'. This is required for using the ArgoCD CLI to create applications.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config use-context \"$host_context\"\nkubectl config set-context --current --namespace=argocd\n```\n\n----------------------------------------\n\nTITLE: Registering Cluster2 with OCM\nDESCRIPTION: Commands to register cluster2 with OCM using the join token. Similar to cluster1 registration, this establishes cluster2 as a managed cluster in the OCM environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nflags=\"--force-internal-endpoint-lookup\"\nclusteradm --context its1 get token | grep '^clusteradm join' | sed \"s/<cluster_name>/cluster2/\" | awk '{print $0 \" --context \\'cluster2\\' \\'${flags}\\'\"}'  | sh\n```\n\n----------------------------------------\n\nTITLE: Enabling SSL Passthrough in Nginx Ingress Controller\nDESCRIPTION: Command to edit the nginx ingress controller deployment to enable SSL passthrough, which is required for KubeFlex hosting.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/acquire-hosting-cluster.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl edit deployment ingress-nginx-controller -n ingress-nginx\n```\n\n----------------------------------------\n\nTITLE: Verifying StatefulSet Creation in Multiple Clusters\nDESCRIPTION: This snippet checks if the StatefulSet has been created in both managed clusters after deploying the Helm chart. It demonstrates how to verify multi-cluster deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" get statefulsets -n postgres-system\nkubectl --context \"$wec2_context\" get statefulsets -n postgres-system\n```\n\n----------------------------------------\n\nTITLE: Collecting Full Status with Retrieval Time in YAML\nDESCRIPTION: A YAML configuration for CombinedStatus that produces a listing of object status paired with WEC name and retrieval timestamp, providing comprehensive status information.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n  select:\n     - name: wec\n       def: inventory.name\n     - name: status\n       def: returned.status\n     - name: retrievalTime\n       def: propagation.lastReturnedUpdateTimestamp\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Metrics Directory Structure in Console\nDESCRIPTION: Shows the expected directory structure after running the metrics collection script, with separate directories for each namespace and files for different object types.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n.\nâ”œâ”€â”€ perf-exp-0\nâ”‚   â”œâ”€â”€ appliedmanifestworks\nâ”‚   â”œâ”€â”€ configmaps-wds1\nâ”‚   â”œâ”€â”€ configmaps-wec\nâ”‚   â”œâ”€â”€ deployments-wds1\nâ”‚   â”œâ”€â”€ deployments-wec\nâ”‚   â”œâ”€â”€ manifestworks\nâ”‚   â”œâ”€â”€ secrets-wds1\nâ”‚   â”œâ”€â”€ secrets-wec\nâ”‚   â”œâ”€â”€ services-wds1\nâ”‚   â”œâ”€â”€ services-wec\nâ”‚   â””â”€â”€ workstatuses\nâ””â”€â”€ perf-exp-1\n   â”œâ”€â”€ appliedmanifestworks\n   â”œâ”€â”€ configmaps-wds1\n   â”œâ”€â”€ configmaps-wec\n   â”œâ”€â”€ deployments-wds1\n   â”œâ”€â”€ deployments-wec\n   â”œâ”€â”€ manifestworks\n   â”œâ”€â”€ secrets-wds1\n   â”œâ”€â”€ secrets-wec\n   â”œâ”€â”€ services-wds1\n   â”œâ”€â”€ services-wec\n   â””â”€â”€ workstatuses\n```\n\n----------------------------------------\n\nTITLE: Visualizing KubeStellar Publishing Flow\nDESCRIPTION: A Mermaid flowchart showing the publishing workflow for KubeStellar components including KCM and OTC container images, Helm charts, and their dependencies, omitting clusteradm and Helm CLI images for simplicity.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    osa_hc_repo[published OSA Helm Chart]\n    subgraph ks_repo[\"kubestellar@GitHub\"]\n    kcm_code[KCM source code]\n    otc_code[OTC source code]\n    ksc_hc_src[KS Core Helm chart source]\n    setup_ksc[\"'Getting Started' setup\"]\n    e2e_local[\"E2E setup<br>local\"]\n    e2e_release[\"E2E setup<br>release\"]\n    end\n    kcm_ctr_image[KCM container image] --> kcm_code\n    otc_ctr_image[OTC container image]\n    otc_ctr_image --> otc_code\n    ksc_hc_repo[published KS Core chart] --> ksc_hc_src\n    ksc_hc_src -.-> osa_hc_repo\n    ksc_hc_src -.-> otc_ctr_image\n    ksc_hc_src -.-> kcm_ctr_image\n    ksc_hc_repo -.-> osa_hc_repo\n    ksc_hc_repo -.-> otc_ctr_image\n    ksc_hc_repo -.-> kcm_ctr_image\n    setup_ksc -.-> ksc_hc_repo\n    setup_ksc -.-> KubeFlex\n    e2e_local -.-> ksc_hc_src\n    e2e_local -.-> KubeFlex\n    e2e_release -.-> ksc_hc_repo\n    e2e_release -.-> KubeFlex\n```\n\n----------------------------------------\n\nTITLE: Retrieving ArgoCD Initial Password\nDESCRIPTION: Commands to switch context and retrieve the initial admin password for ArgoCD.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config use-context kind-kubeflex\nargocd admin initial-password -n argocd\n```\n\n----------------------------------------\n\nTITLE: Setting Argo CD Application via Helm CLI\nDESCRIPTION: This Helm CLI command sets up an Argo CD application using the --set-json flag. It provides a minimal configuration for the application, including name, repository URL, path, destination WDS, and namespace.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart-argocd.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n--set-json='argo-cd.applications=[ { \"name\": \"scenario-6\", \"repoURL\": \"https://github.com/pdettori/sample-apps.git\", \"path\": \"nginx\", \"destinationWDS\": \"wds1\", \"destinationNamespace\": \"nginx-sa\" } ]'\n```\n\n----------------------------------------\n\nTITLE: Applying KubeStellar and OCM Post-Create Hooks in Kubernetes\nDESCRIPTION: Updates the post-create-hooks in KubeFlex to install KubeStellar with the desired images. These commands apply configuration files for KubeStellar and OCM from the specified GitHub repository.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/kubestellar.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubestellar/kubestellar/v${KUBESTELLAR_VERSION}/config/postcreate-hooks/ocm.yaml\n```\n\n----------------------------------------\n\nTITLE: Opening Rancher Desktop Configuration File\nDESCRIPTION: Command to open the Rancher Desktop configuration override file to modify system parameters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/installation-errors.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nvi \"~/Library/Application Support/rancher-desktop/lima/_config/override.yaml\"\n```\n\n----------------------------------------\n\nTITLE: Verifying AppWrapper Deployment in KubeStellar WECs\nDESCRIPTION: These commands check if the AppWrapper has been successfully delivered to both WEC clusters. They list all AppWrapper objects in each cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" get appwrappers\nkubectl --context \"$wec2_context\" get appwrappers\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment Available Replicas Histogram in YAML\nDESCRIPTION: A YAML configuration for CombinedStatus that groups deployments by their number of available replicas and counts occurrences, creating a histogram of replica availability.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n  groupBy:\n     - name: numAvailable\n       def: returned.status.availableReplicas\n  combinedFields:\n     - name: count\n       type: COUNT\n```\n\n----------------------------------------\n\nTITLE: Configuring ArgoCD Instance Labels\nDESCRIPTION: Command to configure ArgoCD to label resources with a specific instance label key.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex patch cm -n argocd argocd-cm -p '{\"data\": {\"application.instanceLabelKey\": \"argocd.argoproj.io/instance\"}}'\n```\n\n----------------------------------------\n\nTITLE: Specifying Kubernetes Python Client Version\nDESCRIPTION: This line specifies the exact version of the Kubernetes Python client library to be installed. It requires version 30.1.0 of the kubernetes package, which is likely used for interacting with Kubernetes clusters programmatically.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/common/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nkubernetes==30.1.0\n```\n\n----------------------------------------\n\nTITLE: Checking KubeStellar Prerequisites\nDESCRIPTION: Command to verify that all required software prerequisites are installed before proceeding with KubeStellar setup.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl https://raw.githubusercontent.com/kubestellar/kubestellar/v{{ config.ks_latest_release }}/scripts/check_pre_req.sh) kflex ocm helm kubectl docker kind\n```\n\n----------------------------------------\n\nTITLE: Teardown BindingPolicy and AppWrappers for Scenario 2\nDESCRIPTION: Commands to remove binding policies and AppWrappers from the WDS2 workspace and managed clusters. This cleanup sequence requires validation that all AppWrappers are deleted before proceeding with further cleanup steps.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds2 delete bindingpolicies aw-bpolicy\nkubectl --context wds2 delete appwrappers --all\n```\n\n----------------------------------------\n\nTITLE: Configuring BindingPolicy with StatusCollector in YAML\nDESCRIPTION: This YAML snippet shows a BindingPolicy object that references the 'count-wecs' StatusCollector. It selects clusters with the label 'location-group: edge' and objects with the label 'app.kubernetes.io/name: nginx'.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: example-binding-policy\nspec:\n  clusterSelectors:\n  - matchLabels: {\"location-group\":\"edge\"}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx\"}\n    statusCollectors: [ count-wecs ]\n```\n\n----------------------------------------\n\nTITLE: Applying KubeStellar Controller Manager Helm Chart in Shell\nDESCRIPTION: This command applies the KubeStellar controller-manager Helm chart with options to allow only delivery of objects with API group 'workload.codeflare.dev'.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context kind-kubeflex upgrade --install -n wds2-system kubestellar oci://ghcr.io/kubestellar/kubestellar/controller-manager-chart --version ${KUBESTELLAR_VERSION} --set ControlPlaneName=wds2 --set APIGroups=workload.codeflare.dev\n```\n\n----------------------------------------\n\nTITLE: Switching Kubernetes Context to WDS Space in Bash\nDESCRIPTION: Sets the current kubectl context to the target Workload Distribution Space (WDS) named 'wds1' for deploying the workload.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config use-context wds1\n```\n\n----------------------------------------\n\nTITLE: Examining KubeFlex Context Configuration\nDESCRIPTION: Command to inspect the KubeFlex preferences stored in kubeconfig file using yq. Shows the hidden state where KubeFlex stores the context name for accessing the hosting cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kflex-extension.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nmspreitz@mjs13 kubestellar % yq .preferences ${KUBECONFIG:-$HOME/.kube/config}\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring WDS2 in Shell\nDESCRIPTION: These commands create a second Workload Description Space (WDS) based on the hosting cluster and install the OCM Transport Plugin.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nkflex create wds2 -t host\n\nhelm --kube-context kind-kubeflex upgrade --install ocm-transport-plugin oci://ghcr.io/kubestellar/ocm-transport-plugin/chart/ocm-transport-plugin --version ${OCM_TRANSPORT_PLUGIN} \\\n    --set transport_cp_name=its1 \\\n    --set wds_cp_name=wds2 \\\n    -n wds2-system\n```\n\n----------------------------------------\n\nTITLE: Deploying Nginx for Singleton Status Testing in KubeStellar\nDESCRIPTION: This snippet creates a new Nginx deployment for testing the singleton status feature in KubeStellar. It sets up a deployment with specific labels for the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-singleton-deployment\n  labels:\n    app.kubernetes.io/name: nginx-singleton\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: public.ecr.aws/nginx/nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n```\n\n----------------------------------------\n\nTITLE: Running Metrics Collection Script with Python\nDESCRIPTION: Command format for running the Python metrics collection script, which gathers creation and update timestamps for benchmark workload objects across various environments.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npython3 metrics_collector.py <kubeconfig> <wds-context-name> <its-context-name> <wec-context-name> <number-of-namespaces> <output-directory> <exp-type>\n```\n\n----------------------------------------\n\nTITLE: Installing Modified OCM Quick Start\nDESCRIPTION: Executes modified OCM Quick Start script that includes NGINX Ingress Controller with SSL passthrough enabled.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl -L https://raw.githubusercontent.com/kubestellar/kubestellar/refs/tags/v{{ config.ks_latest_release }}/scripts/ocm-local-up-for-ingress.sh | bash\n```\n\n----------------------------------------\n\nTITLE: Creating Kind Hosting Cluster with KubeFlex\nDESCRIPTION: Initializes a Kind hosting cluster with nginx ingress controller and KubeFlex controller-manager. This command sets up the base infrastructure for KubeStellar deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkflex init --create-kind\n```\n\n----------------------------------------\n\nTITLE: Creating a K3D Cluster for KubeFlex Hosting\nDESCRIPTION: Commands to create a K3D hosting cluster with nginx ingress controller, disable the default traefik, and install the nginx ingress controller using helm.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/acquire-hosting-cluster.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nk3d cluster create -p \"9443:443@loadbalancer\" --k3s-arg \"--disable=traefik@server:*\" kubeflex\nhelm install ingress-nginx ingress-nginx --repo https://kubernetes.github.io/ingress-nginx --version 4.12.1 --namespace ingress-nginx --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Installing Core Chart with External ITS\nDESCRIPTION: Command to install KubeStellar core chart using an external cluster as ITS.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install core-chart oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set-json='ITSes=[{\"name\":\"its1\",\"type\":\"external\",\"install_clusteradm\":false}]' \\\n  --set-json='WDSes=[{\"name\":\"wds1\"}]'\n```\n\n----------------------------------------\n\nTITLE: Required Linux System Parameters\nDESCRIPTION: Minimum sysctl parameter values required for Kind to function properly with Rancher Desktop.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kind-config.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nfs.inotify.max_user_watches = 524288\nfs.inotify.max_user_instances = 512\n```\n\n----------------------------------------\n\nTITLE: Cleanup Previous Installations\nDESCRIPTION: Commands to remove previous KubeStellar and OCM installations by deleting kind clusters and kubectl contexts.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/start-from-ocm.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkind delete cluster --name hub\nkind delete cluster --name cluster1\nkind delete cluster --name cluster2\nkubectl config delete-context cluster1\nkubectl config delete-context cluster2\n```\n\n----------------------------------------\n\nTITLE: Running Clusterloader2 Workload Generator\nDESCRIPTION: Command to execute clusterloader2 with the KubeStellar provider to generate the benchmark workload.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncd $CL2_DIR\ngo run cmd/clusterloader.go --testconfig=./testing/load/long-duration-exp-config.yaml --kubeconfig=${KUBECONFIG:-$HOME/.kube/config} --provider=ks --v=2\n```\n\n----------------------------------------\n\nTITLE: Tearing Down the Scenario\nDESCRIPTION: Deletes the ArgoCD application with cascading deletion (which removes all resources created by the app) and removes the BindingPolicy from the WDS to clean up the environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_34\n\nLANGUAGE: shell\nCODE:\n```\nargocd app delete nginx-sa --cascade\nkubectl --context \"$wds_context\" delete bindingpolicies argocd-sa-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Labeling AppWrapper in Shell\nDESCRIPTION: This command labels the AppWrapper to match the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds2 label appwrappers.workload.codeflare.dev defaultaw-schd-spec-with-timeout-1 app.kubernetes.io/part-of=my-appwrapper-app\n```\n\n----------------------------------------\n\nTITLE: Defining StatusCollector for WEC Count in YAML\nDESCRIPTION: This YAML snippet defines a StatusCollector object named 'count-wecs' that counts the number of Work Execution Clusters (WECs). It specifies a single combined field 'count' using the COUNT aggregation type.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: control.kubestellar.io/v1alpha1\nkind: StatusCollector\nmetadata:\n  name: count-wecs\nspec:\n  combinedFields:\n     - name: count\n       type: COUNT\n  limit: 10\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding Grafana Service\nDESCRIPTION: Command to set up port forwarding for accessing the Grafana UI locally\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context kind-kubeflex port-forward -n ks-monitoring svc/grafana 3000:80\n```\n\n----------------------------------------\n\nTITLE: Rancher Desktop Override Configuration\nDESCRIPTION: YAML configuration to persist sysctl parameter changes in Rancher Desktop.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kind-config.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nprovision:\n- mode: system\n  script: |\n    #!/bin/sh\n    echo \"fs.inotify.max_user_watches=524288\" > /etc/sysctl.d/fs.inotify.conf\n    echo \"fs.inotify.max_user_instances=512\" >> /etc/sysctl.d/fs.inotify.conf\n    sysctl -p /etc/sysctl.d/fs.inotify.conf\n```\n\n----------------------------------------\n\nTITLE: Configuring KubeFlex Control Plane Contexts\nDESCRIPTION: Sets up kubeconfig contexts for accessing KubeFlex Control Planes using kflex CLI.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config delete-context its1 || true\nkflex ctx its1\nkubectl config delete-context wds1 || true\nkflex ctx wds1\nkflex ctx # switch back to the initial context\n```\n\n----------------------------------------\n\nTITLE: Configuring WEC Monitoring\nDESCRIPTION: Command to configure monitoring for a Workload Execution Cluster\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./configure-monitoring-wec.sh --wec-cluster-context cluster1\n```\n\n----------------------------------------\n\nTITLE: Tearing Down AppWrapper Deployment in KubeStellar\nDESCRIPTION: These commands remove the AppWrapper BindingPolicy and all AppWrapper objects from the WDS. It's the first step in cleaning up the out-of-tree workload scenario.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" delete bindingpolicies aw-bpolicy\nkubectl --context \"$wds_context\" delete appwrappers --all\n```\n\n----------------------------------------\n\nTITLE: Raising Permissions for KubeFlex Controller Manager in Shell\nDESCRIPTION: This command creates a ClusterRoleBinding to give cluster-admin permissions to the KubeFlex controller manager.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex apply -f - <<EOF\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubeflex-manager-cluster-admin-rolebinding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubeflex-controller-manager\n  namespace: kubeflex-system\nEOF\n```\n\n----------------------------------------\n\nTITLE: Initializing KubeFlex with Kind Cluster in Shell\nDESCRIPTION: Creates a Kind hosting cluster with nginx ingress controller and KubeFlex controller-manager installed. This command is used when setting up a new environment from scratch.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkflex init --create-kind\n```\n\n----------------------------------------\n\nTITLE: Error Message from Kind Cluster Creation\nDESCRIPTION: Example error output when Kubestellar installation fails during cluster2 creation due to insufficient system parameters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kind-config.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nError: hub oriented command should not running against non-hub cluster\nCreating cluster \"cluster2\" ...\n...\nERROR: failed to create cluster: failed to init node with kubeadm: command \"docker exec --privileged cluster2-control-plane kubeadm init --skip-phases=preflight --config=/kind/kubeadm.conf --skip-token-print --v=6\" failed with error: exit status 1\nCommand Output: I1008 16:11:20.743111 134 initconfiguration.go:255] loading configuration from \"/kind/kubeadm.conf\"\n...\n[config] WARNING: Ignored YAML document with GroupVersionKind kubeadm.k8s.io/v1beta3, Kind=JoinConfiguration\n...\n```\n\n----------------------------------------\n\nTITLE: Installing AppWrapper CRD in Shell\nDESCRIPTION: This command installs the AppWrapper Custom Resource Definition in the WDS and the Workload Execution Clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nclusters=(wds2 cluster1 cluster2);\n  for cluster in \"${clusters[@]}\"; do\n  kubectl --context ${cluster} apply -f https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/config/crd/bases/workload.codeflare.dev_appwrappers.yaml\ndone\n```\n\n----------------------------------------\n\nTITLE: Example Metrics Collection Command in Bash\nDESCRIPTION: Example command for running the metrics collection script with specific parameter values, targeting contexts wds1, its1, and cluster1 with 2 namespaces.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\npython3 metrics_collector.py $HOME/.kube/config wds1 its1 cluster1 2 $HOME/data s\n```\n\n----------------------------------------\n\nTITLE: Removing RBAC for AppWrapper in KubeStellar WECs\nDESCRIPTION: This snippet removes the RBAC rules created for AppWrapper access in the WECs. It deletes the ClusterRole and ClusterRoleBinding that were set up earlier.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nfor cluster in \"$wec1_context\" \"$wec2_context\"; do\n  kubectl --context $cluster delete clusterroles appwrappers-access\n  kubectl --context $cluster delete clusterrolebindings klusterlet-appwrappers-access\ndone\n```\n\n----------------------------------------\n\nTITLE: Cleaning up Previous KubeStellar K3D Installation\nDESCRIPTION: Commands to remove previous K3D clusters and contexts for KubeStellar deployment. This ensures a clean installation environment by deleting existing clusters named kubeflex, cluster1, and cluster2.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nk3d cluster delete kubeflex\nk3d cluster delete cluster1\nk3d cluster delete cluster2\nkubectl config delete-context kubeflex || true\nkubectl config delete-context cluster1 || true\nkubectl config delete-context cluster2 || true\n```\n\n----------------------------------------\n\nTITLE: Initializing KubeFlex with Kind Cluster Creation\nDESCRIPTION: Command to create a kind cluster with an Ingress controller that has SSL passthrough enabled, install KubeFlex, and set the current kubeconfig context to access the cluster as admin.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/acquire-hosting-cluster.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkflex init --create-kind\n```\n\n----------------------------------------\n\nTITLE: Teardown for Scenario 5\nDESCRIPTION: Commands to clean up the resources created during the resiliency testing scenario by removing the namespace and BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_39\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 delete ns nginx-res\nkubectl --context wds1 delete bindingpolicies nginx-res-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Scaling Deployment for Singleton Status Testing in KubeStellar\nDESCRIPTION: This snippet scales the Nginx deployment from 1 to 2 replicas in the KubeStellar workspace to test the singleton status update feature.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" scale deployment nginx-singleton-deployment --replicas=2\n```\n\n----------------------------------------\n\nTITLE: Configuring WDS Space Monitoring\nDESCRIPTION: Command to configure Prometheus and Pyroscope for monitoring WDS space\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./configure-monitoring-wds.sh --kubeflex-hosting-cluster-context kind-kubeflex\n```\n\n----------------------------------------\n\nTITLE: Checking OCM ManagedClusterAddons Availability\nDESCRIPTION: Command to check if the managedclusteraddons resource is available in the its1 context. This ensures that OCM is properly installed before proceeding with the status addon installation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 api-resources | grep managedclusteraddons\n```\n\n----------------------------------------\n\nTITLE: Uninstall KubeStellar Core Chart\nDESCRIPTION: Commands for uninstalling the KubeStellar Core chart and cleaning up associated clusters\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nhelm uninstall ks-core\n```\n\nLANGUAGE: shell\nCODE:\n```\nkind delete cluster --name kubeflex\n```\n\nLANGUAGE: shell\nCODE:\n```\n/usr/local/bin/k3s-uninstall.sh\n```\n\n----------------------------------------\n\nTITLE: Watching ManifestWork Objects in ITS with Timestamps\nDESCRIPTION: A shell command that monitors ManifestWork objects in an ITS (Infrastructure Target Space) with timestamps prefixed to each line. This helps track the evolution of objects over time for troubleshooting purposes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/troubleshooting.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get manifestworks -A --show-managed-fields -o yaml --watch | while IFS=\"\" read line; do echo \"$(date +%T)| $line\"; done\n```\n\n----------------------------------------\n\nTITLE: Creating Kind Cluster with SSL Passthrough\nDESCRIPTION: Shell command to create a new Kind cluster with SSL passthrough configured for KubeStellar setup. Includes port configuration and cluster naming.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v$KUBESTELLAR_VERSION/scripts/create-kind-cluster-with-SSL-passthrough.sh) --name kubeflex --port 9443\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests with Customized Object Count\nDESCRIPTION: Executes integration tests for the controller-manager with a configurable number of test objects. The CONTROLLER_TEST_NUM_OBJECTS environment variable can be set to control the number of objects (defaults to 18 if not specified). Requires etcd to be installed and available on PATH.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/testing.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCONTROLLER_TEST_NUM_OBJECTS=24 go test -v ./test/integration/controller-manager &> /tmp/test.log\n```\n\n----------------------------------------\n\nTITLE: Creating BindingPolicy for Resiliency Testing in KubeStellar\nDESCRIPTION: This snippet creates a new BindingPolicy for the resiliency test scenario in KubeStellar, selecting clusters based on specified labels.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" apply -f - <<EOF\napiVersion: control.kubestellar.io/v1alpha1\nkind: BindingPolicy\nmetadata:\n  name: nginx-res-bpolicy\nspec:\n  clusterSelectors:\n  - matchLabels: {$(echo \"$label_query_both\" | tr , $'\\n' | while IFS=\"=\" read key val; do echo -n \", \\\"$key\\\": \\\"$val\\\"\"; done | tail -c +3)}\n  downsync:\n  - objectSelectors:\n    - matchLabels: {\"app.kubernetes.io/name\":\"nginx-res\"}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar and OCM-transport-plugin Versions\nDESCRIPTION: Sets environment variables for KubeStellar and OCM-transport-plugin versions. These variables are used in subsequent commands to ensure consistent versioning.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION={{ config.ks_latest_release }}\nexport OCM_TRANSPORT_PLUGIN=0.1.11\n```\n\n----------------------------------------\n\nTITLE: Installing OCM Status Addon\nDESCRIPTION: Command to install the OCM status addon in the its1 context using Helm. This component is responsible for reporting status information from managed clusters back to the hub.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context its1 upgrade --install status-addon -n open-cluster-management oci://ghcr.io/kubestellar/ocm-status-addon-chart --version v${OCM_STATUS_ADDON_VERSION}\n```\n\n----------------------------------------\n\nTITLE: Setting File Watch Limits for Docker Runtimes\nDESCRIPTION: Configuration values to add to the sysctl configuration file that increase the maximum file watches and instances.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/installation-errors.md#2025-04-22_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nfs.inotify.max_user_watches=1048576\nfs.inotify.max_user_instances=1024\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Workload Resources in Bash\nDESCRIPTION: Commands to clean up the generated workload Kubernetes API objects from the cluster after benchmark completion.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ncd $CL2_DIR\n./cleanup.sh\n```\n\n----------------------------------------\n\nTITLE: Creating K3s Cluster with SSL Passthrough\nDESCRIPTION: Shell command to create a new K3s cluster with SSL passthrough configured for KubeStellar setup. Includes port configuration.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbash <(curl -s https://raw.githubusercontent.com/kubestellar/kubestellar/v$KUBESTELLAR_VERSION/scripts/create-k3s-cluster-with-SSL-passthrough.sh) --port 9443\n```\n\n----------------------------------------\n\nTITLE: Verifying Redis Container Status\nDESCRIPTION: Command to check if the Redis container is running.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker ps | grep redis\n```\n\n----------------------------------------\n\nTITLE: Generate Individual Kubeconfig Files\nDESCRIPTION: Script to create separate kubeconfig files for each KubeFlex Control Plane in the hosting cluster\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\necho \"Creating a kubeconfig for each KubeFlex Control Plane:\"\nfor cpname in `kubectl get controlplane -o name`; do\n  cpname=${cpname##*/}\n  echo \"Getting the kubeconfig of \\\"$cpname\\\" ==> \\\"kubeconfig-$cpname\\\"...\"\n  if [[ \"$(kubectl get controlplane $cpname -o=jsonpath='{.spec.type}')\" == \"host\" ]] ; then\n    kubectl config view --minify --flatten > \"kubeconfig-$cpname\"\n  else\n    kubectl get secret $(kubectl get controlplane $cpname -o=jsonpath='{.status.secretRef.name}') \\\n      -n $(kubectl get controlplane $cpname -o=jsonpath='{.status.secretRef.namespace}') \\\n      -o=jsonpath=\"{.data.$(kubectl get controlplane $cpname -o=jsonpath='{.status.secretRef.key}')}\" \\\n      | base64 -d > \"kubeconfig-$cpname\"\n  fi\n  curname=$(kubectl --kubeconfig \"kubeconfig-$cpname\" config current-context)\n  if [ \"$curname\" != \"$cpname\" ]\n  then kubectl --kubeconfig \"kubeconfig-$cpname\" config rename-context \"$curname\" $cpname\n  fi\ndone\n```\n\n----------------------------------------\n\nTITLE: Batch Control Plane Context Creation Script\nDESCRIPTION: Shell script to automatically add all Control Planes as contexts to the current kubeconfig using kflex\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\necho \"Getting the kubeconfig of all Control Planes...\"\nfor cpname in `kubectl get controlplane -o name`; do\n  cpname=${cpname##*/}\n  echo \"Getting the kubeconfig of Control Planes \\\"$cpname\\\"...\"\n  kflex ctx $cpname\ndone\n```\n\n----------------------------------------\n\nTITLE: Installing Monitoring Tools in Hosting Cluster\nDESCRIPTION: Command to deploy monitoring tools in a Kubernetes hosting cluster using the installation script\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd monitoring\n./install-ks-monitoring.sh --cluster-context kind-kubeflex --set core\n```\n\n----------------------------------------\n\nTITLE: Creating Configuration File for Docker Runtimes\nDESCRIPTION: Command to create a new system configuration file for Docker runtimes to adjust file watch limits.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/installation-errors.md#2025-04-22_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nsudo vi /etc/sysctl.d/99-sysctl.conf\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubernetes Context for ArgoCD\nDESCRIPTION: Sets the kubectl context to the hosting cluster and ArgoCD namespace for application deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_41\n\nLANGUAGE: shell\nCODE:\n```\nkubectl config use-context kind-kubeflex\nkubectl config set-context --current --namespace=argocd\n```\n\n----------------------------------------\n\nTITLE: Creating and Registering Second Workload Execution Cluster\nDESCRIPTION: Commands to create a second Workload Execution Cluster (WEC) named cluster2 and rename its context. This provides another target cluster for workload distribution.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nk3d cluster create -p \"31180:80@loadbalancer\"  --network k3d-kubeflex cluster2\nkubectl config rename-context k3d-cluster2 cluster2\n```\n\n----------------------------------------\n\nTITLE: Creating Frontend Environment Configuration\nDESCRIPTION: Command to copy the example environment file to create a .env file for frontend configuration.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp example.env .env\n```\n\n----------------------------------------\n\nTITLE: Checking Git Remote Configuration\nDESCRIPTION: Command to view the configured remote repositories for the local git repository\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit remote -v\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Version of KubeStellar Core Chart\nDESCRIPTION: Command to install a specific version of KubeStellar core chart from OCI registry.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install ks-core oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION\n```\n\n----------------------------------------\n\nTITLE: Installing Monitoring Tools in WEC Cluster\nDESCRIPTION: Command to deploy monitoring tools in a Workload Execution Cluster\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./install-ks-monitoring.sh --cluster-context cluster1 --set wec --kubeflex-hosting-cluster-context kind-kubeflex\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version as Environment Variable\nDESCRIPTION: Command to set the KubeStellar version as an environment variable for use in subsequent commands.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubestellar_version={{ config.ks_latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Removing Legacy Status Addon Components\nDESCRIPTION: Commands to remove existing status-addon-controller and status-addon-agent from the environment before upgrading\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm --kube-context its1 -n open-cluster-management delete status-addon\nkubectl --context its1 -n cluster1 delete manifestwork addon-addon-status-deploy-0\n```\n\n----------------------------------------\n\nTITLE: Verifying Deployments Across Clusters\nDESCRIPTION: Checks the status of deployments, service accounts, and secrets across multiple clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_45\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 -n nginx-sa get deployments,sa,secrets\nkubectl --context cluster2 -n nginx-sa get deployments,sa,secrets\n```\n\n----------------------------------------\n\nTITLE: Full Cleanup for Scenario 2\nDESCRIPTION: Final cleanup steps to uninstall the KubeStellar components, remove the AppWrapper CRDs from all clusters, and delete the WDS2 workspace using KubeFlex.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context kind-kubeflex uninstall -n wds2-system kubestellar\n\nclusters=(wds2 cluster1 cluster2);\n  for cluster in \"${clusters[@]}\"; do\n  kubectl --context ${cluster} delete -f https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/config/crd/bases/workload.codeflare.dev_appwrappers.yaml\ndone\n\nkflex delete wds2\n```\n\n----------------------------------------\n\nTITLE: Setting Upstream Remote Repository\nDESCRIPTION: Command to add the upstream remote pointing to the main KubeStellar repository\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit remote add upstream git@github.com:kubestellar/kubestellar.git\n```\n\n----------------------------------------\n\nTITLE: Adding New Control Plane with Separate Chart Installation\nDESCRIPTION: Command to add new WDS using a separate chart installation while avoiding KubeFlex and PCH reinstallation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install add-wds2 oci://ghcr.io/kubestellar/kubestellar/core-chart --version $KUBESTELLAR_VERSION \\\n  --set='kubeflex-operator.install=false,InstallPCHs=false' \\\n  --set-json='WDSes=[{\"name\":\"wds2\"}]'\n```\n\n----------------------------------------\n\nTITLE: Testing Helm's Ability to Fetch Public Charts from ghcr.io\nDESCRIPTION: This command tests whether Helm can fetch a public chart from ghcr.io. If this command fails, it indicates a problem with Helm's authentication to the registry, often due to Docker configuration issues.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-helm-ghcr.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm show chart oci://ghcr.io/kubestellar/kubestellar/core-chart\n```\n\n----------------------------------------\n\nTITLE: Kind Cluster Deletion Command\nDESCRIPTION: Command to delete existing Kind clusters before reinstallation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kind-config.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkind delete cluster --name <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Configuring ITS Space Monitoring\nDESCRIPTION: Command to configure monitoring for ITS space components\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./configure-monitoring-its.sh --kubeflex-hosting-cluster-context kind-kubeflex\n```\n\n----------------------------------------\n\nTITLE: Equivalent SQL Query for Pod Phase Histogram\nDESCRIPTION: The SQL equivalent of the Pod phase histogram, demonstrating how the YAML configuration translates to a SQL query that groups and counts pod phases.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT phase, COUNT(*) AS count\nFROM (SELECT <SQL expression for returned.status.phase> AS phase, *\n      FROM PerWEC)\nGROUP BY phase\nLIMIT <something>\n```\n\n----------------------------------------\n\nTITLE: Checking Deployments and StatefulSets in Hosting Cluster\nDESCRIPTION: Optional step to verify the deployment status of various components in the hosting cluster, including kubestellar-controller-manager and vcluster statefulset.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-step-by-step.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex get deployments,statefulsets --all-namespaces\n```\n\n----------------------------------------\n\nTITLE: Finding KubeFlex Release Occurrences in Repository Files\nDESCRIPTION: A shell command to search for occurrences of a specific KubeFlex version (0.6.2) throughout the repository, while excluding certain directories and file types. This helps identify all files that need to be updated when upgrading KubeFlex dependencies.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/release.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nfind * .github/workflows \\( -name \"*.svg\" -prune \\) -or \\( -path \"*venv\" -prune \\) -or \\( -path hack/tools -prune \\) -or \\( -type f -exec fgrep 0.6.2 \\{\\} \\; -print -exec echo \\; \\)\n```\n\n----------------------------------------\n\nTITLE: Frontend Environment Configuration Example\nDESCRIPTION: Example content for the .env file used to configure the frontend, including base URL, app version, and Git commit hash.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nVITE_BASE_URL=http://localhost:4000\nVITE_APP_VERSION=0.1.0\nVITE_GIT_COMMIT_HASH=$GIT_COMMIT_HASH\n```\n\n----------------------------------------\n\nTITLE: Getting Cluster Join Token\nDESCRIPTION: Command to retrieve the cluster join token for adding new clusters to the deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm get token\n```\n\n----------------------------------------\n\nTITLE: Check Current sysctl Parameters Command\nDESCRIPTION: Commands to verify current sysctl parameter values in Rancher Desktop VM.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/knownissue-kind-config.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsysctl fs.inotify.max_user_watches\nsysctl fs.inotify.max_user_instances\n```\n\n----------------------------------------\n\nTITLE: Editing Performance Test Configuration in Bash\nDESCRIPTION: Opens the performance test configuration file for editing, allowing customization of workload parameters like namespaces, cluster type, and tuningSet.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nvi performance-test-config.yaml\n```\n\n----------------------------------------\n\nTITLE: Confirming and Labeling Cluster2\nDESCRIPTION: Commands to confirm cluster2 is accepted and to label it for the BindingPolicy. The labels determine which workloads will be distributed to this cluster based on placement rules.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get managedclusters\nkubectl --context its1 label managedcluster cluster2 location-group=edge name=cluster2\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Previous KubeStellar Installations\nDESCRIPTION: Series of commands to remove previous KubeStellar demo environment installations, including deleting Kind clusters and Kubernetes configurations.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/get-started.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkind delete cluster --name kubeflex\nkind delete cluster --name cluster1\nkind delete cluster --name cluster2\nkubectl config delete-context cluster1\nkubectl config delete-context cluster2\n```\n\n----------------------------------------\n\nTITLE: Visualizing OCM Status Addon Publishing Flow\nDESCRIPTION: A Mermaid flowchart illustrating the publishing process for the OCM Status Addon, showing the relationships between source code, container images, and Helm charts with build-time and run-time dependencies.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    subgraph \"ocm-status-addon@GitHub\"\n    osa_code[OSA source code]\n    osa_hc_src[OSA Helm chart source]\n    end\n    osa_ctr_image[OSA container image] --> osa_code\n    osa_hc_repo[published OSA Helm Chart] --> osa_hc_src\n    osa_hc_src -.-> osa_ctr_image\n    osa_hc_repo -.-> osa_ctr_image\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version Environment Variable in Shell\nDESCRIPTION: Sets an environment variable to hold the desired version of KubeStellar. This variable is used in subsequent commands to ensure consistent versioning across the setup.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-kind.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION=0.23.0-alpha.2\n```\n\n----------------------------------------\n\nTITLE: Visualizing Clusteradm and Helm CLI Container Images Flow\nDESCRIPTION: A Mermaid flowchart showing the publishing workflow for the parts involving clusteradm and Helm CLI container images in the KubeStellar ecosystem.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    subgraph helm_repo[\"helm/helm@GitHub\"]\n    helm_src[\"helm source\"]\n    end\n    subgraph cladm_repo[\"ocm/clusteradm@GitHub\"]\n    cladm_src[\"clusteradm source\"]\n    end\n    subgraph ks_repo[\"kubestellar@GitHub\"]\n    ksc_hc_src[KS Core Helm chart source]\n    e2e_local[\"E2E setup<br>local\"]\n    e2e_release[\"E2E setup<br>release\"]\n    end\n    helm_image[\"ks/helm image\"] --> helm_src\n    cladm_image[\"ks/clusteradm image\"] --> cladm_src\n    ksc_hc_repo[published KS Core chart] --> ksc_hc_src\n    ksc_hc_src -.-> helm_image\n    ksc_hc_src -.-> cladm_image\n    ksc_hc_repo -.-> cladm_image\n    ksc_hc_repo -.-> helm_image\n    e2e_local -.-> ksc_hc_src\n    e2e_release -.-> ksc_hc_repo\n```\n\n----------------------------------------\n\nTITLE: Syncing ArgoCD Application via CLI\nDESCRIPTION: Synchronizes the ArgoCD application using the command line interface.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_44\n\nLANGUAGE: shell\nCODE:\n```\nargocd app sync nginx-sa\n```\n\n----------------------------------------\n\nTITLE: Listing ManagedCluster Objects in KubeStellar ITS\nDESCRIPTION: This command lists all ManagedCluster objects in the ITS that match the specified label query. It's used to verify the setup and identify relevant clusters for the scenarios.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$its_context\" get managedclusters -l \"$label_query_both\"\n```\n\n----------------------------------------\n\nTITLE: Configuring kubeconfig contexts for KubeStellar control planes using kflex\nDESCRIPTION: This snippet shows the commands needed to set up and switch between kubeconfig contexts for KubeStellar control planes. It first sets the context to the installation cluster, ensures KubeFlex CLI state is correct, and creates contexts for non-host-type control planes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/core-chart/templates/NOTES.txt#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config use-context $the_one_where_you_installed_this_chart\nkflex ctx --set-current-for-hosting # make sure the KubeFlex CLI's hidden state is right for what the Helm chart just did\n{{range $cp := (concat (.Values.ITSes | default list) (.Values.WDSes | default list) ) }}\n{{- if ne $cp.type \"host\" }}\nkflex ctx --overwrite-existing-context {{ $cp.name }}\n{{- end }}\n{{- end }}\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Environment Variables\nDESCRIPTION: Defines required environment variables for KubeStellar version and OCM transport plugin version.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION={{ config.ks_latest_release }}\nexport OCM_TRANSPORT_PLUGIN=0.1.11\n```\n\n----------------------------------------\n\nTITLE: Checking Deployments and StatefulSets in Hosting Cluster\nDESCRIPTION: Optional command to verify that all required deployments and statefulsets are running in the hosting cluster. This confirms that the KubeStellar installation is complete and functional.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex get deployments,statefulsets --all-namespaces\n```\n\n----------------------------------------\n\nTITLE: Merge Kubeconfig Files\nDESCRIPTION: Commands to merge individual kubeconfig files into the main ~/.kube/config file\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\necho \"Merging the Control Planes kubeconfigs into ~/.kube/config ...\"\ncp ~/.kube/config ~/.kube/config.bak\nKUBECONFIG=~/.kube/config:$(find . -maxdepth 1 -type f -name 'kubeconfig-*' | tr '\\n' ':') kubectl config view --flatten > ~/.kube/kubeconfig-merged\nmv ~/.kube/kubeconfig-merged ~/.kube/config\n```\n\n----------------------------------------\n\nTITLE: Deploying Updated Status Addon Controller\nDESCRIPTION: Command to install the updated version of the status-addon controller using Helm\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhelm --kube-context its1 upgrade --install ocm-status-addon -n open-cluster-management oci://ghcr.io/kubestellar/ocm-status-addon-chart --version v0.2.0-rc14\n```\n\n----------------------------------------\n\nTITLE: Renaming K3D Container for KubeFlex Compatibility\nDESCRIPTION: Commands to stop, rename, and restart the K3D container to match the expected container name for KubeFlex internal endpoint lookup, followed by verification of pod status.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/acquire-hosting-cluster.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker stop k3d-kubeflex-server-0\ndocker rename k3d-kubeflex-server-0 kubeflex-control-plane\ndocker start kubeflex-control-plane\n\n# Wait 1-2 minutes for all pods to be restarted.\n# Use the following command to confirm all are fully running:\nkubectl --context k3d-kubeflex get po -A\n```\n\n----------------------------------------\n\nTITLE: Defining Command-Line Options for kubectl-rbac-flatten in Bash\nDESCRIPTION: This snippet shows the command-line options available for the kubectl-rbac-flatten command, including API groups and resources filtering, and output format selection.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/cmd/kubectl-rbac-flatten/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n      --api-groups strings               comma-separated list of API groups to include; '*' means all (default [*])\n  -o, --output-format string             output format, either json or table (default \"table\")\n      --resources strings                comma-separated list of resources to include; '*' means all (default [*])\n```\n\n----------------------------------------\n\nTITLE: Retrieving Argo CD admin password for KubeStellar\nDESCRIPTION: This snippet shows how to obtain the Argo CD admin password from a Kubernetes secret when Argo CD is installed as part of the KubeStellar deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/core-chart/templates/NOTES.txt#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl -n {{ .Release.Namespace }} get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n```\n\n----------------------------------------\n\nTITLE: Labeling AppWrapper for BindingPolicy in KubeStellar\nDESCRIPTION: This command labels the AppWrapper object to match the BindingPolicy that will be created. It's crucial for ensuring the AppWrapper is selected for distribution to the WECs.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" label appwrappers.workload.codeflare.dev defaultaw-schd-spec-with-timeout-1 app.kubernetes.io/part-of=my-appwrapper-app\n```\n\n----------------------------------------\n\nTITLE: Testing KubeStellar Release Image\nDESCRIPTION: Command to run E2E tests using the latest released image of KubeStellar instead of a local build.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/ginkgo/README.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nKFLEX_DISABLE_CHATTY=true ginkgo --vv --trace --no-color -- -released\n```\n\n----------------------------------------\n\nTITLE: Stopping KubeStellar Control Plane Components for Resiliency Testing\nDESCRIPTION: This snippet stops various components of the KubeStellar control plane, including API servers and controllers, to test system resiliency.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system kube-apiserver --replicas=0\nkubectl --context \"$host_context\" scale statefulset -n \"$its_cp\"-system vcluster --replicas=0\nkubectl --context \"$host_context\" scale deployment -n kubeflex-system kubeflex-controller-manager --replicas=0\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system kubestellar-controller-manager --replicas=0\nkubectl --context \"$host_context\" scale deployment -n \"$wds_cp\"-system transport-controller --replicas=0\n```\n\n----------------------------------------\n\nTITLE: Opening ArgoCD UI\nDESCRIPTION: Opens the ArgoCD web interface in the default browser.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_43\n\nLANGUAGE: shell\nCODE:\n```\nopen https://argocd.localtest.me:9443\n```\n\n----------------------------------------\n\nTITLE: Verifying Deployment Creation in Shell\nDESCRIPTION: These commands verify that the Nginx deployment has been created in both clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get deployments -n nginx\nkubectl --context cluster2 get deployments -n nginx\n```\n\n----------------------------------------\n\nTITLE: Navigating to Performance Metrics Collection Directory in Bash\nDESCRIPTION: Changes directory to the KubeStellar performance common directory, where the metrics collection script is located for gathering performance data.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncd .$HOME/kubestellar/test/performance/common\n```\n\n----------------------------------------\n\nTITLE: Creating Argo CD Application for Locations\nDESCRIPTION: This console snippet shows the command and output for creating an Argo CD application to manage Locations in the KubeStellar IMW.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ argocd app create locations \\\n--repo https://github.com/edge-experiments/gitops-source.git \\\n--path kubestellar/locations/ \\\n--dest-server https://172.31.31.125:6443/clusters/root:imw-turbo \\\n--sync-policy automated\napplication 'locations' created\n```\n\n----------------------------------------\n\nTITLE: Checking ServiceAccount Secrets Across Clusters\nDESCRIPTION: Verifies that multiple syncs in ArgoCD don't create duplicate secrets for the service account in the WDS and target clusters. This checks for potential controller conflicts.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_33\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wds_context\" -n nginx-sa get secrets\nkubectl --context \"$wec1_context\" -n nginx-sa get secrets\nkubectl --context \"$wec2_context\" -n nginx-sa get secrets\n```\n\n----------------------------------------\n\nTITLE: Skipping KubeStellar Setup Phase\nDESCRIPTION: Command to run E2E tests while skipping the initial cleanup and setup phase.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/ginkgo/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nKFLEX_DISABLE_CHATTY=true ginkgo --vv --trace --no-color -- -skip-setup\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output for kubectl-rbac-flatten\nDESCRIPTION: This JSON snippet demonstrates the structure of the output when using the JSON format option. It shows an array of Tuple objects with Binding, RoleName, Subject, and Rule information.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/cmd/kubectl-rbac-flatten/README.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n[\n{\"Binding\":{\"Namespace\":\"\",\"Name\":\"cluster-admin\"},\"RoleName\":\"cluster-admin\",\"Subject\":{\"kind\":\"Group\",\"apiGroup\":\"rbac.authorization.k8s.io\",\"name\":\"system:masters\"},\"Rule\":{\"verbs\":[\"*\"],\"apiGroups\":[\"*\"],\"resources\":[\"*\"]}}\n,\n{\"Binding\":{\"Namespace\":\"\",\"Name\":\"cluster-admin\"},\"RoleName\":\"cluster-admin\",\"Subject\":{\"kind\":\"Group\",\"apiGroup\":\"rbac.authorization.k8s.io\",\"name\":\"system:masters\"},\"Rule\":{\"verbs\":[\"*\"],\"nonResourceURLs\":[\"*\"]}}\n,\n...\n]\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Resources\nDESCRIPTION: Removes the ArgoCD application and binding policy during teardown.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_47\n\nLANGUAGE: shell\nCODE:\n```\nargocd app delete nginx-sa --cascade\nkubectl --context wds1 delete bindingpolicies argocd-sa-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Equivalent SQL Query for WEC Count\nDESCRIPTION: This SQL snippet demonstrates the equivalent query to the StatusCollector 'count-wecs'. It counts all rows in the PerWEC table, which represents the number of WECs.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/combined-status.md#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) AS count FROM PerWEC LIMIT <something>\n```\n\n----------------------------------------\n\nTITLE: Creating Argo CD Application for Namespace\nDESCRIPTION: This console snippet shows the command and output for creating an Argo CD application to manage a Namespace in the KubeStellar WMW.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ argocd app create namespace \\\n--repo https://github.com/edge-experiments/gitops-source.git \\\n--path kubestellar/namespaces/ \\\n--dest-server https://172.31.31.125:6443/clusters/root:my-org:wmw-turbo \\\n--sync-policy automated\napplication 'namespace' created\n```\n\n----------------------------------------\n\nTITLE: Verifying AppWrapper Removal in KubeStellar WECs\nDESCRIPTION: These commands check if all AppWrapper objects have been removed from both WEC clusters. They're used to ensure the cleanup process is complete before proceeding.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$wec1_context\" get appwrappers -A\nkubectl --context \"$wec2_context\" get appwrappers -A\n```\n\n----------------------------------------\n\nTITLE: Testing Latest Release with Ginkgo\nDESCRIPTION: Command to run performance tests on the latest release using the -released flag with Ginkgo framework.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/performance/README.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nginkgo -v -- -released\n```\n\n----------------------------------------\n\nTITLE: Defining Tuple Structure for JSON Output in Go\nDESCRIPTION: This Go code defines the Tuple struct used for JSON output, which includes fields for Binding, RoleName, Subject, and Rule.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/cmd/kubectl-rbac-flatten/README.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype Tuple struct {\n\tBinding  NamespacedName\n\tRoleName string\n\tSubject  rbac.Subject\n\tRule     rbac.PolicyRule\n}\n```\n\n----------------------------------------\n\nTITLE: Switching Kubectl Context to WDS Space\nDESCRIPTION: Command to switch the kubectl context to a target WDS space for deploying the workload.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config use-context wds1\n```\n\n----------------------------------------\n\nTITLE: Granting Klusterlet Permissions for AppWrapper in Shell\nDESCRIPTION: These commands give permission for the Klusterlet to operate on the AppWrapper cluster resource in both clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nclusters=(cluster1 cluster2);\nfor cluster in \"${clusters[@]}\"; do\nkubectl --context ${cluster} apply -f - <<EOF\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: appwrappers-access\nrules:\n- apiGroups: [\"workload.codeflare.dev\"]\n  resources: [\"appwrappers\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: klusterlet-appwrappers-access\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: appwrappers-access\nsubjects:\n- kind: ServiceAccount\n  name: klusterlet-work-sa\n  namespace: open-cluster-management-agent\nEOF\ndone\n```\n\n----------------------------------------\n\nTITLE: Control Plane Context Usage Example\nDESCRIPTION: Example command showing how to use a specific control plane context with kubectl\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context \"$cpname\" ...\n```\n\n----------------------------------------\n\nTITLE: Displaying Kubernetes Contexts Example in Bash\nDESCRIPTION: Shows an example output of the 'kubectl config get-contexts' command displaying the required context configuration for OCP-based testing with contexts named 'kscore', 'cluster1', and 'cluster2'.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl config get-contexts\nCURRENT   NAME          CLUSTER                   AUTHINFO               NAMESPACE\n          kscore       <url>:port               <defaul-value>            default\n          cluster1     <url>:port               <defaul-value>            default\n*         cluster2     <url>:port               <defaul-value>            default\n```\n\n----------------------------------------\n\nTITLE: Skip Setup Phase Testing\nDESCRIPTION: Command to run performance tests with Ginkgo framework while skipping the setup and cleanup phases.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/performance/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nginkgo -v -- -skip-setup\n```\n\n----------------------------------------\n\nTITLE: Git Commit Message Format\nDESCRIPTION: Standardized format for git commit messages that includes a short title, problem description, and optional issue number reference.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n{Short Title}: {Problem this commit is solving and any important contextual information} {issue number if applicable}\n```\n\n----------------------------------------\n\nTITLE: Checking Monitoring Tools Deployment Status\nDESCRIPTION: Command to verify the deployment status of monitoring tools in the ks-monitoring namespace\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context kind-kubeflex -n ks-monitoring get pods\n```\n\n----------------------------------------\n\nTITLE: WEC Join Command Example\nDESCRIPTION: Example of the modified join command for connecting a WEC Raspberry Pi to the core cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm join --core-token ... --hub-apiserver https://core.local:6443 --cluster-name wec\n```\n\n----------------------------------------\n\nTITLE: Running Linting Commands\nDESCRIPTION: Make commands for checking linting issues, auto-fixing issues, and running both operations.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nmake check-lint\n\nmake fix-lint\n\nmake lint\n```\n\n----------------------------------------\n\nTITLE: Viewing All Documentation Versions Locally with Mike in Shell\nDESCRIPTION: These shell commands clone the repository, set up mike for viewing all documentation versions, and serve the docs locally.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ngit clone git@github.com:{{ config.repo_short_name }}.git\ncd {{ config.repo_default_file_path }}\ngit checkout {{ config.ks_branch }}\ncd docs\nmike set-default {{ config.ks_branch }}\ncd ..\nmake serve-docs\n```\n\n----------------------------------------\n\nTITLE: Verifying StatefulSet Propagation to Managed Clusters\nDESCRIPTION: Commands to check that the PostgreSQL StatefulSet has been successfully propagated to the edge clusters through the BindingPolicy.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get statefulsets -n postgres-system\nkubectl --context cluster2 get statefulsets -n postgres-system\n```\n\n----------------------------------------\n\nTITLE: Cloning Clusterloader2 Repository for KubeStellar Benchmarking\nDESCRIPTION: Command to clone the clusterloader2 repository, which is used as a tool for deploying benchmark workloads in a KubeStellar environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone -b release-1.31 https://github.com/kubernetes/perf-tests.git\n```\n\n----------------------------------------\n\nTITLE: Basic Git Workflow Commands\nDESCRIPTION: Common git commands for adding, committing and pushing changes to a branch\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit add (there are several options you can specify for the git add command)\n\ngit commit -m \"your message\"\n\ngit push -u origin branch-name (-u sets upstream to origin which is your remote github repository)\n```\n\n----------------------------------------\n\nTITLE: Removing AppWrapper Roles from Managed Clusters\nDESCRIPTION: Loop to remove the ClusterRoles and ClusterRoleBindings that were created for AppWrapper access in each managed cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nfor cluster in cluster1 cluster2; do\n  kubectl --context $cluster delete clusterroles appwrappers-access\n  kubectl --context $cluster delete clusterrolebindings klusterlet-appwrappers-access\ndone\n```\n\n----------------------------------------\n\nTITLE: Creating Namespace and Installing Helm Chart for Postgres\nDESCRIPTION: Commands to create a namespace for the Postgres deployment, label it appropriately for Helm management, and install the PostgreSQL chart from Bitnami's repository.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 create ns postgres-system\nkubectl --context wds1 label ns postgres-system app.kubernetes.io/managed-by=Helm app.kubernetes.io/instance=postgres\nhelm --kube-context wds1 install -n postgres-system postgres oci://registry-1.docker.io/bitnamicharts/postgresql\n```\n\n----------------------------------------\n\nTITLE: Serving Documentation Locally with MkDocs in Shell\nDESCRIPTION: This shell command uses MkDocs to serve the documentation locally for preview.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmkdocs serve\n```\n\n----------------------------------------\n\nTITLE: Verifying Replica Count in Both Clusters\nDESCRIPTION: Commands to confirm that the deployment was scaled both in the managed cluster and that the status is correctly reflected in the WDS1 workspace.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_32\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get deployment nginx-singleton-deployment\nkubectl --context wds1 get deployment nginx-singleton-deployment\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Virtual Environment for KubeStellar Benchmarks\nDESCRIPTION: Commands to set up a Python virtual environment, activate it, and install required dependencies for running KubeStellar performance tests. This creates an isolated environment with all necessary packages listed in the requirements.txt file.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd test/performance/common \npython3 -m venv .venv\n. .venv/bin/activate\npip3 install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Branch\nDESCRIPTION: Command to create and checkout a new feature branch for working on an issue\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b issue-1187\n```\n\n----------------------------------------\n\nTITLE: Tearing Down Scenario 1 in Shell\nDESCRIPTION: These optional commands remove the Nginx namespace and BindingPolicy created in Scenario 1.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 delete ns nginx\nkubectl --context wds1 delete bindingpolicies nginx-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Labeling Helm Metadata Secret for Propagation\nDESCRIPTION: Command to identify and label the Helm release secret so it will be propagated to managed clusters, enabling Helm commands to work in those clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context wds1 label secret -n postgres-system $(kubectl --context wds1 get secrets -n postgres-system -l name=postgres -l owner=helm  -o jsonpath='{.items[0].metadata.name}') app.kubernetes.io/managed-by=Helm app.kubernetes.io/instance=postgres\n```\n\n----------------------------------------\n\nTITLE: Basic Shell Command Example for Documentation\nDESCRIPTION: A shell codeblock example that will be both visible to readers and executed in CI tests. This format is used for commands that users are expected to run.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nmkdocs serve\n```\n\n----------------------------------------\n\nTITLE: Querying KubeStellar Controller Endpoints in Bash\nDESCRIPTION: These bash commands retrieve Endpoints information for KubeStellar controllers in WDS and ITS spaces, as well as in WEC clusters. They filter the output to show only controller-related entries.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context kind-kubeflex -n wds1-system get Endpoints | egrep \".*controller\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context kind-kubeflex -n its1-system get Endpoints | egrep \".*controller\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context cluster1 -n open-cluster-management-agent-addon get Endpoints\n```\n\n----------------------------------------\n\nTITLE: Navigating to KubeStellar Performance Directory in Bash\nDESCRIPTION: Command to change directory to the KubeStellar performance common directory, which contains scripts for setting up the benchmark environment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd .$HOME/kubestellar/test/performance/common\n```\n\n----------------------------------------\n\nTITLE: Pushing Changes to Remote Branch\nDESCRIPTION: Commands for pushing local changes to remote repository branch\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit push -u origin <branch-name>\n\nor \n\ngit push --force-with-lease\n```\n\n----------------------------------------\n\nTITLE: Labeling WDS2 Control Plane in Shell\nDESCRIPTION: This command labels the 'wds2' control plane as type 'wds'.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nkubectl label cp wds2 kflex.kubestellar.io/cptype=wds\n```\n\n----------------------------------------\n\nTITLE: Verifying All Pods After Container Rename\nDESCRIPTION: Command to verify that all pods are running properly after renaming the container. This ensures the cluster is functioning correctly before proceeding with KubeStellar installation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context k3d-kubeflex get po -A\n```\n\n----------------------------------------\n\nTITLE: Non-Executable Bash Example for Documentation\nDESCRIPTION: A bash codeblock that is visible to readers but not executed in CI tests. This format is typically used to show shell output or examples that shouldn't be automatically run.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nmkdocs server\n```\n\n----------------------------------------\n\nTITLE: Checking AppWrappers Status in Managed Clusters\nDESCRIPTION: Commands to verify that all AppWrappers have been removed from the managed clusters before proceeding with additional cleanup steps.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context cluster1 get appwrappers -A\nkubectl --context cluster2 get appwrappers -A\n```\n\n----------------------------------------\n\nTITLE: Setting Clusterloader2 Directory Path in Bash\nDESCRIPTION: Sets an environment variable pointing to the clusterloader2 directory from the cloned repository, which will be used by setup scripts.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport CL2_DIR=$HOME/perf-tests/clusterloader2\n```\n\n----------------------------------------\n\nTITLE: Example Git Remote Configuration\nDESCRIPTION: Complete example showing remote configuration, adding upstream, and fetching updates\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/code-management.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ git remote -v\norigin  git@github.com:fileppb/kubestellar.git (fetch)\norigin  git@github.com:fileppb/kubestellar.git (push)\n\n$ git remote add upstream git@github.com:kubestellar/kubestellar.git\n\n$ git remote -v\norigin  git@github.com:fileppb/kubestellar.git (fetch)\norigin  git@github.com:fileppb/kubestellar.git (push)\nupstream        git@github.com:kubestellar/kubestellar.git (fetch)\nupstream        git@github.com:kubestellar/kubestellar.git (push)\n\n$ git fetch upstream\nEnter passphrase for key '/c/Users/owner/.ssh/id_rsa':\nremote: Enumerating objects: 60394, done.\nremote: Counting objects: 100% (5568/5568), done.\nremote: Compressing objects: 100% (255/255), done.\nremote: Total 60394 (delta 4768), reused 5457 (delta 4706), pack-reused 54826\nReceiving objects: 100% (60394/60394), 52.38 MiB | 3.25 MiB/s, done.\nResolving deltas: 100% (34496/34496), completed with 415 local objects.\n\n$ git status\n\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n```\n\n----------------------------------------\n\nTITLE: Navigating to Load Configuration Directory in Bash\nDESCRIPTION: Changes directory to the clusterloader2 testing load directory, where workload configuration files are located for modification.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd  $CL2_DIR/testing/load/\n```\n\n----------------------------------------\n\nTITLE: Running Metrics Collection Script\nDESCRIPTION: Command to execute the Python metrics collector script that gathers timestamps for workload objects across different components.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython3 metrics_collector.py $HOME/.kube/config wds1 its1 cluster1 1 $HOME/data l 10 660\n```\n\n----------------------------------------\n\nTITLE: Hidden Bash Command for CI Testing\nDESCRIPTION: A hidden bash command that will be executed during CI testing but not displayed to readers, useful for background operations like sleep commands that are necessary for tests but not for users.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsleep 10\n```\n\n----------------------------------------\n\nTITLE: Creating Binding Policy and Namespace for Experiment\nDESCRIPTION: Commands to navigate to the load testing directory and apply the setup configuration for the experiment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncd $CL2_DIR/testing/load/\nkubectl apply -f long-duration-exp-setup.yaml\n```\n\n----------------------------------------\n\nTITLE: Setting Up Clusterloader2 for Plain Kubernetes in Bash\nDESCRIPTION: Runs the setup script for clusterloader2 in a plain Kubernetes environment, configuring it for KubeStellar performance workloads.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./setup-clusterloader2.sh\n```\n\n----------------------------------------\n\nTITLE: Cloning KubeStellar Repository and Switching Branch in Shell\nDESCRIPTION: These shell commands clone the KubeStellar repository, navigate to the docs directory, and checkout a specific branch.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone git@github.com:{{ config.repo_short_name }}.git\ncd {{ config.repo_default_file_path }}/docs\ngit checkout {{ config.ks_branch }}\n```\n\n----------------------------------------\n\nTITLE: Cloning the Performance Tests Repository in Bash\nDESCRIPTION: Command to clone the Kubernetes performance tests repository at a specific release branch, which contains the clusterloader2 tool needed for workload generation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone -b release-1.31 https://github.com/kubernetes/perf-tests.git\n```\n\n----------------------------------------\n\nTITLE: Running Clusterloader2 with KubeStellar Provider in Bash\nDESCRIPTION: Executes the clusterloader2 command with the KubeStellar provider to generate the performance workload based on the previously configured parameters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd $CL2_DIR\ngo run cmd/clusterloader.go --testconfig=./testing/load/performance-test-config.yaml --kubeconfig=${KUBECONFIG:-$HOME/.kube/config} --provider=ks --v=2\n```\n\n----------------------------------------\n\nTITLE: Defining Page Variables in Markdown Front Matter\nDESCRIPTION: Example showing how to define page-specific variables using YAML front matter at the beginning of a markdown file, which can later be referenced using page.meta syntax in Jinja templates.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n---\nshort_name: example1\nmanifest_name: 'docs/content/Coding Milestones/PoC2023q1/example1.md'\n---\n```\n\n----------------------------------------\n\nTITLE: Performance Test Results Output\nDESCRIPTION: Sample output showing the timing results for multiple test runs, measuring delays in WDS deployment, binding, manifestwork, and WEC deployment with calculated totals and averages.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/performance/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n  Run 0: wds deployment=0, binding=1, manifestwork=1, wec deployment=1, total=2\n  Run 1: wds deployment=0, binding=0, manifestwork=0, wec deployment=5, total=6\n  Run 2: wds deployment=0, binding=1, manifestwork=1, wec deployment=7, total=7\n  Run 3: wds deployment=0, binding=0, manifestwork=0, wec deployment=5, total=5\n  Run 4: wds deployment=0, binding=0, manifestwork=0, wec deployment=4, total=5\n  Run 5: wds deployment=0, binding=0, manifestwork=0, wec deployment=4, total=5\n  Run 6: wds deployment=0, binding=0, manifestwork=0, wec deployment=4, total=5\n  Run 7: wds deployment=0, binding=1, manifestwork=1, wec deployment=6, total=7\n  Run 8: wds deployment=0, binding=0, manifestwork=0, wec deployment=4, total=5\n  Run 9: wds deployment=0, binding=0, manifestwork=0, wec deployment=5, total=5\n  ----------------------------------------------------------------------------------\n  Avg:   wds deployment=0, binding=0, manifestwork=0, wec deployment=4, total=5\n```\n\n----------------------------------------\n\nTITLE: Setting Up Clusterloader2 for OpenShift in Bash\nDESCRIPTION: Runs the setup script for clusterloader2 specifically in an OpenShift environment, which may have different requirements than standard Kubernetes.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./setup-clusterloader2.sh --env ocp\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Virtual Environment for Documentation in Shell\nDESCRIPTION: These shell commands create a Python virtual environment for the documentation system and activate it.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n( cd ..; make venv )\n. venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Navigating to Clusterloader2 Load Testing Directory\nDESCRIPTION: Command to change directory to the load testing configuration directory in clusterloader2.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd  $CL2_DIR/testing/load/\n```\n\n----------------------------------------\n\nTITLE: Applying System Configuration Changes\nDESCRIPTION: Command to apply the modified system configuration that increases file watch limits without requiring a system restart.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/installation-errors.md#2025-04-22_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nsudo sysctl -p /etc/sysctl.d/99-sysctl.conf\n```\n\n----------------------------------------\n\nTITLE: Centering Images with CSS\nDESCRIPTION: This CSS snippet defines a class for centering images. It uses flexbox to horizontally and vertically center images within their container.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/kyverno.md#2025-04-22_snippet_2\n\nLANGUAGE: css\nCODE:\n```\n.centerImage\n{\n    display: block;\n    margin: auto;\n}\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Example for MkDocs Navigation\nDESCRIPTION: A YAML codeblock showing how to structure the navigation configuration in the MkDocs configuration file. This defines the menu structure of the documentation website.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nnav:\n  - Home: index.md\n  - QuickStart: Getting-Started/quickstart.md\n  - Contributing: \n      - Guidelines: Contribution guidelines/CONTRIBUTING.md\n```\n\n----------------------------------------\n\nTITLE: Teardown for Scenario 3\nDESCRIPTION: Commands to uninstall the Helm chart, delete the namespace, and remove the BindingPolicy for complete cleanup of Scenario 3.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_27\n\nLANGUAGE: shell\nCODE:\n```\nhelm --kube-context wds1 uninstall -n postgres-system postgres\nkubectl --context wds1 delete ns postgres-system\nkubectl --context wds1 delete bindingpolicies postgres-bpolicy\n```\n\n----------------------------------------\n\nTITLE: Viewing Collected Metrics Data Files\nDESCRIPTION: Commands to navigate to the output directory and view the structure of collected metric files.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd $HOME/data\ntree\n```\n\n----------------------------------------\n\nTITLE: Accepting WEC Cluster\nDESCRIPTION: Command to accept the joining WEC cluster into the KubeStellar deployment.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm accept --clusters wec\n```\n\n----------------------------------------\n\nTITLE: Configuring ArgoCD Ingress\nDESCRIPTION: YAML configuration to set up ingress rules for ArgoCD server with SSL passthrough.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context kind-kubeflex apply -f - <<EOF\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: argocd-server-ingress\n  namespace: argocd\n  annotations:\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: argocd.localtest.me\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: argocd-server\n            port:\n              name: https\nEOF\n```\n\n----------------------------------------\n\nTITLE: Example Tabular Output for kubectl-rbac-flatten\nDESCRIPTION: This snippet shows the structure of the tabular output format, displaying resource-based rules and non-resource URLs with their respective fields separated by tabs.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/cmd/kubectl-rbac-flatten/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nBINDING                                                         SUBJECT                                                        VERB               APIGROUP                        RESOURCE                                    OBJNAME\n/cluster-admin                                                  G:system:masters                                               *                  *                               *                                           *\n/ingress-nginx                                                  SA:ingress-nginx/ingress-nginx                                 list                                               configmaps                                  *\n/ingress-nginx                                                  SA:ingress-nginx/ingress-nginx                                 list                                               endpoints                                   *\n...\n\nBINDING                                       ROLE                                      SUBJECT                                          VERB   NRURL\n/cluster-admin                                cluster-admin                             G:system:masters                                 *      *\n/kubeadm:cluster-admins                       cluster-admin                             G:kubeadm:cluster-admins                         *      *\n...\n```\n\n----------------------------------------\n\nTITLE: Checking CSR Status\nDESCRIPTION: Command to check the Certificate Signing Request status for the joining cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get csr\n```\n\n----------------------------------------\n\nTITLE: Port-forwarding Pyroscope for WEC Cluster Monitoring in Bash\nDESCRIPTION: This bash command sets up port-forwarding for the Pyroscope service in a WEC cluster, allowing access to the Pyroscope UI for monitoring KubeStellar controllers in that cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context cluster1 -n ks-monitoring port-forward svc/pyroscope 9090:4040\n```\n\n----------------------------------------\n\nTITLE: Including External Markdown with Jekyll Liquid Tags\nDESCRIPTION: Uses Jekyll's Liquid templating syntax to include the GOVERNANCE.md file from the repository root. This allows the governance documentation to be maintained in a single location while being displayed in multiple parts of the documentation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/governance-inc.md#2025-04-22_snippet_0\n\nLANGUAGE: liquid\nCODE:\n```\n{%\n    include \"../../../GOVERNANCE.md\"\n%}\n```\n\n----------------------------------------\n\nTITLE: Querying Managed Clusters with Label in Shell\nDESCRIPTION: This command checks for available clusters with the label 'location-group=edge' using kubectl in the 'its1' context.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/examples.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get managedclusters -l location-group=edge\n```\n\n----------------------------------------\n\nTITLE: Querying Endpoints for KubeStellar Components in Bash\nDESCRIPTION: This bash command retrieves Endpoints information for KubeStellar spaces and API servers. It filters the output to show only relevant entries for WDS, vcluster, and kubernetes services.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context <hosting-cluster-context> get Endpoints -A | egrep \"NAME| wds| vcluster |kubernetes\"\n```\n\n----------------------------------------\n\nTITLE: Removing AppWrapper CRD from KubeStellar WDS and WECs\nDESCRIPTION: This final cleanup step removes the AppWrapper CustomResourceDefinition from the WDS and both WEC clusters, completing the teardown of the out-of-tree workload scenario.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nclusters=(\"$wds_context\" \"$wec1_context\" \"$wec2_context\");\n  for cluster in \"${clusters[@]}\"; do\n  kubectl --context ${cluster} delete -f https://raw.githubusercontent.com/project-codeflare/multi-cluster-app-dispatcher/v1.39.0/config/crd/bases/workload.codeflare.dev_appwrappers.yaml\ndone\n```\n\n----------------------------------------\n\nTITLE: Restarting Argo CD Server\nDESCRIPTION: This shell command restarts the Argo CD server deployment after making changes to the ConfigMap.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/argocd.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl -n argocd rollout restart deployment argocd-server\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Available Contexts in Console\nDESCRIPTION: Shows example output of the get-contexts command, displaying the various environments available for testing including WDS, ITS, and clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nCURRENT   NAME            CLUSTER         AUTHINFO        NAMESPACE\n             cluster1        kind-cluster1   kind-cluster1   \n             cluster2        kind-cluster2   kind-cluster2   \n             its1            its1-cluster    its1-admin      \n             kind-kubeflex   kind-kubeflex   kind-kubeflex   \n*         wds1            wds1-cluster    wds1-admin      default\n             wds2            wds2-cluster    wds2-admin      default\n```\n\n----------------------------------------\n\nTITLE: Including Markdown Content with Boundary Markers\nDESCRIPTION: Template that includes content from a CODE_OF_CONDUCT.md file, specifically the section between <!--coc-start--> and <!--coc-end--> markers\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/coc-inc.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{%\n   include-markdown \"../../../CODE_OF_CONDUCT.md\"\n   start=\"<!--coc-start-->\"\n   end=\"<!--coc-end-->\"\n%}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Host Container IP for KubeStellar Cluster in Bash\nDESCRIPTION: This bash command fetches the Endpoints information for the default namespace in a specified cluster context, used to obtain the IP address of the host container for the cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/monitoring/README.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --context <cluster-context> get Endpoints -n default\n```\n\n----------------------------------------\n\nTITLE: Logging into ArgoCD CLI\nDESCRIPTION: Command to log into ArgoCD CLI using the insecure flag for development setup.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nargocd login --insecure argocd.localtest.me:9443\n```\n\n----------------------------------------\n\nTITLE: Fetching a Pull Request Branch in Git\nDESCRIPTION: This command fetches a specific pull request from the upstream repository and creates a local branch for it. Replace 'ID' with the PR number and 'BRANCH_NAME' with your desired local branch name.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/testing-doc-prs.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit fetch upstream pull/ID/head:BRANCH_NAME\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version in Shell\nDESCRIPTION: Sets an environment variable for the KubeStellar version to be used in subsequent commands.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/core-chart.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION={{ config.ks_latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Viewing Directory Structure of Collected Metrics in Bash\nDESCRIPTION: Commands to display the tree structure of the output directories created by the metrics collection script, showing the organization of collected data files.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncd $HOME/data\ntree\n```\n\n----------------------------------------\n\nTITLE: Non-Copyable Output Example for Documentation\nDESCRIPTION: A bash codeblock that displays log output to readers without a copy button and is not executed in CI tests. This format is used for showing expected output from commands.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nI0412 15:15:57.867837   94634 shared_informer.go:282] Waiting for caches to sync for placement-translator\nI0412 15:15:57.969533   94634 shared_informer.go:289] Caches are synced for placement-translator\nI0412 15:15:57.970003   94634 shared_informer.go:282] Waiting for caches to sync for what-resolver\n```\n\n----------------------------------------\n\nTITLE: Setting Clusterloader2 Directory Environment Variable\nDESCRIPTION: Command to set the CL2_DIR environment variable pointing to the clusterloader2 directory from the cloned perf-tests repository.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport CL2_DIR=$HOME/perf-tests/clusterloader2\n```\n\n----------------------------------------\n\nTITLE: Checking Cluster Deployments Status\nDESCRIPTION: Retrieves status of all deployments and statefulsets across all namespaces.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get deployments,statefulsets --all-namespaces\n```\n\n----------------------------------------\n\nTITLE: Including LICENSE File Template in Liquid\nDESCRIPTION: A template directive that includes a LICENSE file from three directory levels up in the project structure using Liquid templating syntax.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/license-inc.md#2025-04-22_snippet_0\n\nLANGUAGE: liquid\nCODE:\n```\n{%\n   include \"../../../LICENSE\"\n%}\n```\n\n----------------------------------------\n\nTITLE: Adding File Watch Limits to Rancher Desktop Configuration\nDESCRIPTION: YAML script to add to the provision section of Rancher Desktop's configuration that increases the file watch limits.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/installation-errors.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nprovision:\n- mode: system\n  script: |\n    #!/bin/sh\n    echo \"fs.inotify.max_user_watches=1048576\" > /etc/sysctl.d/fs.inotify.conf\n    echo \"fs.inotify.max_user_instances=1024\" >> /etc/sysctl.d/fs.inotify.conf\n    sysctl -p /etc/sysctl.d/fs.inotify.conf\n```\n\n----------------------------------------\n\nTITLE: Sample Metrics Output Format in Console\nDESCRIPTION: Shows the format of the tab-delimited output files generated by the metrics collection script, containing object names, timestamps, and controller information.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nstress-pod-2\t2024-03-14 19:51:19+00:00\t2024-03-14 19:51:44+00:00\tSucceeded\tcontroller-manager\n```\n\n----------------------------------------\n\nTITLE: Example Join Command Output\nDESCRIPTION: Example of the join command format returned by the get token command.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nclusteradm join --core-token ... --hub-apiserver https://127.0.0.1:6443 --cluster-name <cluster_name>\n```\n\n----------------------------------------\n\nTITLE: Running the KubeStellar Prerequisites Check Script\nDESCRIPTION: Example of running the check_pre_req.sh script to verify all prerequisites for KubeStellar. The script verifies Docker, kubectl, KubeFlex, OCM CLI, Helm, Kind, ArgoCD CLI, Make, Go, and KO installation.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/pre-reqs.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ scripts/check_pre_req.sh\nChecking pre-requisites for using KubeStellar:\nâœ” Docker (Docker version 27.2.1-rd, build cc0ee3e)\nâœ” kubectl (v1.29.2)\nâœ” KubeFlex (Kubeflex version: v0.6.3.672cc8a 2024-09-23T16:15:47Z)\nâœ” OCM CLI (:v0.9.0-0-g56e1fc8)\nâœ” Helm (v3.16.1)\nâœ” helm can fetch public charts\nChecking additional pre-requisites for running the examples:\nâœ” Kind (kind v0.22.0 go1.22.0 darwin/arm64)\nâœ” fs.inotify.max_user_watches is 524288\nâœ” fs.inotify.max_user_instances is 512\nâœ” ArgoCD CLI (v2.10.1+a79e0ea)\nChecking pre-requisites for building KubeStellar:\nâœ” GNU Make (GNU Make 3.81)\nâœ” Go (go version go1.23.2 darwin/arm64)\nâœ” KO (0.16.0)\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Heading for Diagram Editing Instructions\nDESCRIPTION: A Markdown heading introducing the instructions for editing project pictures.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/images/image-files-readme.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# How to edit these pictures\n```\n\n----------------------------------------\n\nTITLE: Verifying GolangCI-Lint Installation\nDESCRIPTION: Command to verify the installation of GolangCI-Lint by checking its version.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ngolangci-lint --version\n```\n\n----------------------------------------\n\nTITLE: Running Redis Container for Caching\nDESCRIPTION: Docker command to run a Redis container for caching real-time WebSocket updates.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name redis -d -p 6379:6379 redis\n```\n\n----------------------------------------\n\nTITLE: Setting KubeStellar Version Variable\nDESCRIPTION: Exports the KubeStellar version as an environment variable for use in subsequent commands.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/microshift.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport KUBESTELLAR_VERSION={{ config.ks_latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Backend\nDESCRIPTION: Commands to navigate to the backend directory, download dependencies, and run the backend server.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd backend\n\ngo mod download\n\ngo run main.go\n```\n\n----------------------------------------\n\nTITLE: Documentation Links in Markdown\nDESCRIPTION: Markdown links to documentation resources, community channels, and badges displaying project status and metrics\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/readme.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[![](https://github.com/kubestellar/kubestellar/actions/workflows/docs-gen-and-push.yml/badge.svg?branch={{ config.ks_branch }})](https://github.com/kubestellar/kubestellar/actions/workflows/docs-gen-and-push.yml)&nbsp;&nbsp;&nbsp;\n[![](https://img.shields.io/badge/first--timers--only-friendly-blue.svg?style=flat-square)](https://www.firsttimersonly.com/)&nbsp;&nbsp;&nbsp;\n[![](https://github.com/kubestellar/kubestellar/actions/workflows/broken-links-crawler.yml/badge.svg)](https://github.com/kubestellar/kubestellar/actions/workflows/broken-links-crawler.yml)\n[![](https://www.bestpractices.dev/projects/8266/badge)](https://www.bestpractices.dev/projects/8266)\n[![](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/kubestellar)](https://artifacthub.io/packages/search?repo=kubestellar)\n[![](https://api.scorecard.dev/projects/github.com/kubestellar/kubestellar/badge)](https://scorecard.dev/viewer/?uri=github.com/kubestellar/kubestellar)\n```\n\n----------------------------------------\n\nTITLE: Styling Center-Aligned Images using CSS\nDESCRIPTION: A CSS style definition that centers images on the page by setting them as block elements with automatic margins.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/mvi.md#2025-04-22_snippet_0\n\nLANGUAGE: css\nCODE:\n```\n.centerImage\n{\n display: block;\n margin: auto;\n}\n```\n\n----------------------------------------\n\nTITLE: Summary-Only Test Output\nDESCRIPTION: Command to run performance tests with Ginkgo framework showing only the summary results.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/performance/README.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nginkgo -v -- -just-summary\n```\n\n----------------------------------------\n\nTITLE: Example Deployment Status Output\nDESCRIPTION: Shows expected output format for deployment and statefulset status check.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/common-setup-core-chart.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nNAMESPACE            NAME                                             READY   UP-TO-DATE   AVAILABLE   AGE\ningress-nginx        deployment.apps/ingress-nginx-controller         1/1     1            1           22h\nkube-system          deployment.apps/coredns                          2/2     2            2           22h\nkubeflex-system      deployment.apps/kubeflex-controller-manager      1/1     1            1           22h\nlocal-path-storage   deployment.apps/local-path-provisioner           1/1     1            1           22h\nwds1-system          deployment.apps/kube-apiserver                   1/1     1            1           22m\nwds1-system          deployment.apps/kube-controller-manager          1/1     1            1           22m\nwds1-system          deployment.apps/kubestellar-controller-manager   1/1     1            1           21m\nwds1-system          deployment.apps/transport-controller             1/1     1            1           21m\n\nNAMESPACE         NAME                                   READY   AGE\nits1-system       statefulset.apps/vcluster              1/1     11h\nkubeflex-system   statefulset.apps/postgres-postgresql   1/1     22h\n```\n\n----------------------------------------\n\nTITLE: Running KubeStellar E2E Tests with Additional Setup Flags\nDESCRIPTION: Example showing how to pass additional setup flags to the KubeStellar setup script through the test suite. Demonstrates setting controller manager verbosity level.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/ginkgo/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nKFLEX_DISABLE_CHATTY=true ginkgo --vv --trace --no-color -- -kubestellar-setup-flags=\"--kubestellar-controller-manager-verbosity 5\"\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Frontend\nDESCRIPTION: Commands to install frontend dependencies and start the development server.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Opening ArgoCD Web Console\nDESCRIPTION: Command to open the ArgoCD web interface in the default browser.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nopen https://argocd.localtest.me:9443\n```\n\n----------------------------------------\n\nTITLE: Installing GolangCI-Lint on Linux & macOS\nDESCRIPTION: Commands to install GolangCI-Lint and add it to the PATH on Linux and macOS systems.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncurl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.54.2\n\nexport PATH=$(go env GOPATH)/bin:$PATH\n```\n\n----------------------------------------\n\nTITLE: Versions Configuration JSON\nDESCRIPTION: JSON configuration file managing documentation versions and aliases.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_16\n\nLANGUAGE: json\nCODE:\n```\n[{\"version\": \"release-0.22.0\", \"title\": \"release-0.22.0\", \"aliases\": [\"latest\"]}, {\"version\": \"release-0.22.0-rc3\", \"title\": \"release-0.22.0-rc3\", \"aliases\": []}, {\"version\": \"release-0.21.2\", \"title\": \"release-0.21.2\", \"aliases\": []}, {\"version\": \"release-0.21.2-rc1\", \"title\": \"release-0.21.2-rc1\", \"aliases\": []}, {\"version\": \"release-0.21.1\", \"title\": \"release-0.21.1\", \"aliases\": []}, {\"version\": \"release-0.21.0\", \"title\": \"release-0.21.0\", \"aliases\": []}, {\"version\": \"release-0.14\", \"title\": \"release-0.14\", \"aliases\": []}]\n```\n\n----------------------------------------\n\nTITLE: Running Specific KubeStellar Test Cases\nDESCRIPTION: Example of running a specific test case using Ginkgo's focus parameter to target individual tests.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/ginkgo/README.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nKFLEX_DISABLE_CHATTY=true ginkgo --vv --trace --no-color --focus \"survives ITS vcluster coming down\"\n```\n\n----------------------------------------\n\nTITLE: Running Services with Docker Compose\nDESCRIPTION: Command to build and run all services using Docker Compose.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up --build\n```\n\n----------------------------------------\n\nTITLE: Visualizing GitHub Repository Dependencies for KubeStellar\nDESCRIPTION: A Mermaid flowchart showing the dependency relationships between the GitHub repositories in the kubestellar GitHub organization, where an arrow indicates that the repo at the tail depends on the repo at the head.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/packaging.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    kubestellar --> kubeflex\n    kubestellar --> ocm-status-addon\n    ocm-status-addon --> kubestellar\n```\n\n----------------------------------------\n\nTITLE: Pulling Docker Images for KubestellarUI\nDESCRIPTION: Docker commands to pull the latest and specific versions of frontend and backend images for KubestellarUI.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull quay.io/kubestellar/ui:frontend\n\ndocker pull quay.io/kubestellar/ui:backend\n\ndocker pull quay.io/kubestellar/ui:frontend-abcd1234\n\ndocker pull quay.io/kubestellar/ui:backend-abcd1234\n```\n\n----------------------------------------\n\nTITLE: Cloning KubestellarUI Repository\nDESCRIPTION: Commands to clone the KubestellarUI repository and navigate to the project directory.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/your-github-username/ui.git\n\ncd ui\n```\n\n----------------------------------------\n\nTITLE: Renaming Kubernetes Context in Bash\nDESCRIPTION: Shows how to rename a Kubernetes context using the 'kubectl config rename-context' command, which is useful when configuring the required context names for OCP-based testing.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/e2e/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl config rename-context <default-wec1-context-name> cluster1\n```\n\n----------------------------------------\n\nTITLE: CNAME Configuration\nDESCRIPTION: CNAME file content for GitHub Pages custom domain configuration.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_15\n\nLANGUAGE: text\nCODE:\n```\ndocs.kubestellar.io\n```\n\n----------------------------------------\n\nTITLE: Stopping Docker Compose Services\nDESCRIPTION: Command to stop all services running with Docker Compose.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down\n```\n\n----------------------------------------\n\nTITLE: Setting Up Clusterloader2 for Long-duration Experiments\nDESCRIPTION: Command to run the setup script for configuring clusterloader2 for long-duration experiments in KubeStellar.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./setup-clusterloader2.sh --exp l\n```\n\n----------------------------------------\n\nTITLE: Installing GolangCI-Lint on Windows\nDESCRIPTION: Commands to install GolangCI-Lint on Windows using scoop or Go install.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/ui-docs/README.md#2025-04-22_snippet_10\n\nLANGUAGE: powershell\nCODE:\n```\nscoop install golangci-lint\n```\n\nLANGUAGE: bash\nCODE:\n```\ngo install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\n```\n\n----------------------------------------\n\nTITLE: Configuring Markdown Template Front Matter\nDESCRIPTION: YAML front matter block specifying an empty title and home.html template for a markdown document.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/index.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"\"\ntemplate: home.html\n---\n```\n\n----------------------------------------\n\nTITLE: Including Security Documentation with Markdown Include Directive\nDESCRIPTION: This snippet shows how to use the include-markdown directive to embed content from another file. It specifically includes content from the SECURITY.md file, extracting only the portion between the 'security-start' and 'security-end' HTML comments.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/security/security-inc.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{%\n   include-markdown \"../../../../SECURITY.md\"\n   start=\"<!--security-start-->\"\n   end=\"<!--security-end-->\"\n%}\n```\n\n----------------------------------------\n\nTITLE: GitHub Pages Redirect HTML\nDESCRIPTION: HTML template for redirecting to the latest documentation version.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_14\n\nLANGUAGE: html\nCODE:\n```\n<!DOCTYPE html>\n<html>\n<head>\n<title>KubeStellar</title>\n<meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" >\n<meta http-equiv=\"refresh\" content=\"0; URL=https://docs.kubestellar.io/latest\" />\n</head>\n```\n\n----------------------------------------\n\nTITLE: Waiting for Cluster1 CSR Creation\nDESCRIPTION: Command to watch for the cluster signing request (CSR) from cluster1. This verification step ensures that the registration process is proceeding correctly before accepting the cluster.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/oldocs/deploy-on-k3d.md#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --context its1 get csr --watch || true\n```\n\n----------------------------------------\n\nTITLE: Installing ArgoCD CLI on MacOS\nDESCRIPTION: Command to install ArgoCD CLI using Homebrew package manager on MacOS.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbrew install argocd\n```\n\n----------------------------------------\n\nTITLE: Makefile Target for HTML Execution\nDESCRIPTION: Makefile target for executing HTML documentation tests using the newer approach.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n.PHONY: execute-html\nexecute-html: venv\n\t. $(VENV)/activate; \\\n\tcd docs; \\\n\tmkdocs build; \\\n\tscripts/execute-html.sh \"$$PWD/..\" \"generated/$(MANIFEST)/index.html\"\n```\n\n----------------------------------------\n\nTITLE: Installing ArgoCD CLI on Linux\nDESCRIPTION: Commands to download and install ArgoCD CLI on Linux systems.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/argo-to-wds1.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64\nsudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd\nrm argocd-linux-amd64\n```\n\n----------------------------------------\n\nTITLE: Checking Out a Local Branch in Git\nDESCRIPTION: This command switches to the local branch that contains the PR changes. Replace 'BRANCH_NAME' with the name you specified in the previous fetch command.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/operations/testing-doc-prs.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit checkout BRANCH_NAME\n```\n\n----------------------------------------\n\nTITLE: Makefile Target for Original Docs-Ecutable\nDESCRIPTION: Makefile target definition for running the original docs-ecutable script.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n.PHONY: docs-ecutable\ndocs-ecutable: \n\tMANIFEST=$(MANIFEST) docs/scripts/docs-ecutable.sh\n```\n\n----------------------------------------\n\nTITLE: Viewing Available Kubernetes Contexts in Bash\nDESCRIPTION: Optional command to list all available kubectl contexts, which helps verify which environments are accessible for testing.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config get-contexts\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Switching Context in Console\nDESCRIPTION: Shows the expected console output after successfully switching the kubectl context to 'wds1'.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/short-running-tests/README.md#2025-04-22_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nSwitched to context \"wds1\".\n```\n\n----------------------------------------\n\nTITLE: Simple Shell Script Example\nDESCRIPTION: Basic shell script example used to demonstrate documentation code blocks.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/README.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n#!/bin/sh\necho hello KubeStellar\n```\n\n----------------------------------------\n\nTITLE: Opening ArgoCD UI in Browser\nDESCRIPTION: Opens the ArgoCD web interface in the default browser. The interface is accessible at a local test domain on port 9443.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/direct/example-scenarios.md#2025-04-22_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\nopen https://argocd.localtest.me:9443\n```\n\n----------------------------------------\n\nTITLE: Navigating to KubeStellar Performance Testing Directory\nDESCRIPTION: Command to change directory to the performance testing common folder in the KubeStellar repository.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd $HOME/kubestellar/test/performance/common\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for MkDocs Documentation\nDESCRIPTION: This requirements file lists all Python packages needed for building KubeStellar documentation with MkDocs. It includes core dependencies, MkDocs plugins for extended functionality, and Markdown extensions for content formatting. Version constraints are specified to ensure compatibility between packages.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# Core Dependencies\nmkdocs>=1.5,<2.0\nJinja2>=3.1.5,<4.0\nMarkdown>=3.3.7,<4.0\nMarkupSafe>=2.1.2,<3.0\n\n# MkDocs Plugins\nmkdocs-material>=9.5.34,<10.0\nmkdocs-material-extensions>=1.3,<2.0\nmkdocs-awesome-pages-plugin>=2.8.0,<3.0\nmkdocs-mermaid2-plugin>=1.1.1,<2.0\nmkdocs-macros-plugin>=0.7.0,<1.0\nmkdocs-static-i18n>=0.53,<1.0\nmkdocs-open-in-new-tab>=1.0.2,<2.0\nmike>=1.1.2,<2.0\n\n# Markdown Extensions\nmarkdown-captions>=2.1.2,<3.0\npymdown-extensions>=10.2,<11.0\nPygments>=2.16,<3.0\n\n# Include Markdown Plugin\nmkdocs-include-markdown-plugin>=7.1.2,<8.0\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header Template\nDESCRIPTION: Standard copyright and license header template used in KubeStellar source files. It includes a copyright year placeholder and references to the Apache License 2.0 terms.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.go.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n/*\nCopyright YEAR The KubeStellar Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Loading Spinner in HTML\nDESCRIPTION: This snippet demonstrates how to embed a YouTube video with a loading spinner using HTML and inline JavaScript. It shows a spinner while the video loads, then replaces it with the video player.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/kyverno.md#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div id=\"spinner1\">\n  <img width=\"140\" height=\"140\" src=\"../../../images/spinner.gif\" class=\"centerImage\">\n</div>\n<iframe class=\"centerImage\" id=\"embed1\" width=\"0\" height=\"0\" src=\"https://www.youtube.com/embed/tcpequs5pVM?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen style=\"visibility:hidden;\" onload= \"document.getElementById('spinner1').style.display='none';document.getElementById('embed1').style.visibility='visible';document.getElementById('embed1').width='720';document.getElementById('embed1').height='400';\"></iframe>\n```\n\n----------------------------------------\n\nTITLE: Defining Apache License 2.0 Header for KubeStellar Project\nDESCRIPTION: This code snippet contains the Apache License 2.0 header for the KubeStellar project. It includes the copyright notice, permission to use the software under the terms of the license, and a link to the full license text.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.generatego.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n/*\nCopyright The KubeStellar Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n```\n\n----------------------------------------\n\nTITLE: Defining Apache License 2.0 Header for KubeStellar Project in Markdown\nDESCRIPTION: This snippet contains the Apache License 2.0 header text for the KubeStellar project. It specifies the copyright, permission to use, and conditions for distribution and modification of the software.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.sh.txt#2025-04-22_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Copyright YEAR The KubeStellar Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Including Security Contacts Information with Markdown Directive\nDESCRIPTION: This snippet uses a markdown include directive to incorporate security contact information from an external file named SECURITY_CONTACTS. The directive specifies start and end markers to extract only the relevant portion of the file.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/contribution-guidelines/security/security_contacts-inc.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{%\n   include-markdown \"../../../../SECURITY_CONTACTS\"\n   start=\"<!--security-contacts-start-->\"\n   end=\"<!--security-contacts-end-->\"\n%}\n```\n\n----------------------------------------\n\nTITLE: Apache 2.0 License Header Template\nDESCRIPTION: Standard Apache License 2.0 copyright header template used in KubeStellar project files. The header includes copyright notice and license terms, with a placeholder for the copyright year.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.py.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n# Copyright YEAR The KubeStellar Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Embedding Centered Image in HTML\nDESCRIPTION: This HTML snippet centers an image using a paragraph tag with alignment. The image source is a GIF file hosted on a static Wix domain, and its width is set to 600 pixels.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/common-subs/coming-soon.md#2025-04-22_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<p align=\"center\">\n<img src=\"https://static.wixstatic.com/media/141bfd_f750b94d365a406f9bf5cf080d97c1c2~mv2.gif\" width=\"600\"  />\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining Apache License 2.0 Header for KubeStellar\nDESCRIPTION: This snippet defines the Apache License 2.0 header used in KubeStellar project files. It includes placeholders for the copyright year and specifies the terms of use, distribution, and modification of the software.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.Makefile.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n# Copyright YEAR The KubeStellar Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Embedding LinkedIn Post with Loading Spinner in HTML\nDESCRIPTION: This snippet shows how to embed a LinkedIn post with a loading spinner using HTML and inline JavaScript. It displays a spinner while the post loads, then replaces it with the embedded LinkedIn content.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/docs/content/Community/partners/kyverno.md#2025-04-22_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div id=\"spinner2\">\n  <img width=\"140\" height=\"140\" src=\"../../../images/spinner.gif\" class=\"centerImage\">\n</div>\n<iframe class=\"centerImage\" id='embed2' src=\"https://www.linkedin.com/embed/feed/update/urn:li:share:7072623853629263875\" scrolling=no height=\"0\" width=\"0\" frameborder=\"0\" allowfullscreen=\"\" title=\"Kyverno and KubeStellar\" style=\"visibility:hidden;\" onload= \"document.getElementById('spinner2').style.display='none';document.getElementById('embed2').style.visibility='visible';document.getElementById('embed2').width='740';document.getElementById('embed2').height='400';\"></iframe>\n```\n\n----------------------------------------\n\nTITLE: Apache 2.0 License Header Template\nDESCRIPTION: Standard Apache License 2.0 header template with copyright notice for KubeStellar project. The YEAR placeholder gets replaced with actual copyright year during usage.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/hack/boilerplate/boilerplate.Dockerfile.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n# Copyright YEAR The KubeStellar Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Viewing Available Kubectl Contexts\nDESCRIPTION: Optional command to list all available kubectl contexts to verify WDS spaces and clusters.\nSOURCE: https://github.com/kubestellar/kubestellar/blob/main/test/performance/long-running-tests/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config get-contexts\n```"
  }
]