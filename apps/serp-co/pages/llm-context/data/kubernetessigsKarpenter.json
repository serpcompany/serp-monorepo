[
  {
    "owner": "kubernetes-sigs",
    "repo": "karpenter",
    "content": "TITLE: Defining a NodePool Resource with Karpenter v1 API\nDESCRIPTION: A complete example of the Karpenter v1 NodePool resource definition showing all available fields including template configuration, disruption settings, and resource limits. This resource defines how Karpenter provisions and manages nodes in a Kubernetes cluster.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  template:\n    metadata:\n      labels:\n        billing-team: my-team\n      annotations:\n        example.com/owner: \"my-team\"\n    spec:\n      nodeClassRef:\n        group: karpenter.k8s.aws # Updated since only a single version will be served\n        kind: EC2NodeClass\n        name: default\n      taints:\n        - key: example.com/special-taint\n          effect: NoSchedule\n      startupTaints:\n        - key: example.com/another-taint\n          effect: NoSchedule\n      requirements:\n        - key: \"karpenter.k8s.aws/instance-category\"\n          operator: In\n          values: [\"c\", \"m\", \"r\"]\n          minValues: 2 # Alpha field, added for spot best practices support\n      expireAfter: 720h | Never\n      terminationGracePeriod: 1d\n  disruption:\n    budgets:\n      - nodes: 0\n        schedule: \"0 10 * * mon-fri\"\n        duration: 16h\n        reasons:\n          - Drifted\n          - Expired\n      - nodes: 100%\n        reasons:\n          - Empty\n      - nodes: \"10%\"\n      - nodes: 5\n    consolidationPolicy: WhenUnderutilized | WhenEmpty\n    consolidateAfter: 1m | Never # Added to allow additional control over consolidation aggressiveness\n  weight: 10\n  limits:\n    cpu: \"1000\"\n    memory: 1000Gi\nstatus:\n  conditions:\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: NodeClassReady\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Ready\n  resources:\n    nodes: \"5\"\n    cpu: \"20\"\n    memory: \"8192Mi\"\n    ephemeral-storage: \"100Gi\"\n```\n\n----------------------------------------\n\nTITLE: Defining Karpenter NodeClaim API Structure\nDESCRIPTION: Complete example of the Karpenter NodeClaim API structure, including spec and status fields, demonstrating the updated v1 schema with new fields and status conditions.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodeClaim\nmetadata:\n  name: default\nspec:\n  nodeClassRef:\n    group: karpenter.k8s.aws # Updated since only a single version will be served\n    kind: EC2NodeClass\n    name: default\n  taints:\n    - key: example.com/special-taint\n      effect: NoSchedule\n  startupTaints:\n    - key: example.com/another-taint\n      effect: NoSchedule\n  requirements:\n    - key: \"karpenter.k8s.aws/instance-category\"\n      operator: In\n      values: [\"c\", \"m\", \"r\"]\n      minValues: 2\n  resources:\n    requests:\n      cpu: \"20\"\n      memory: \"8192Mi\"\n  expireAfter: 720h | Never\n  terminationGracePeriod: 1d\nstatus:\n  allocatable:\n    cpu: 1930m\n    ephemeral-storage: 17Gi\n    memory: 3055Mi\n    pods: \"29\"\n    vpc.amazonaws.com/pod-eni: \"9\"\n  capacity:\n    cpu: \"2\"\n    ephemeral-storage: 20Gi\n    memory: 3729Mi\n    pods: \"29\"\n    vpc.amazonaws.com/pod-eni: \"9\"\n  conditions:\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Launched\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Registered\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Initialized\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Drifted\n      reason: RequirementsDrifted\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Expired\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Empty\n    - lastTransitionTime: \"2024-02-02T19:54:34Z\"\n      status: \"True\"\n      type: Ready\n  nodeName: ip-192-168-71-87.us-west-2.compute.internal\n  providerID: aws:///us-west-2b/i-053c6b324e29d2275\n  imageID: ami-0b1e393fbe12f411c\n```\n\n----------------------------------------\n\nTITLE: Defining NodePool Spec with Disruption Controls in YAML\nDESCRIPTION: Example YAML configuration for the NodePool resource with the new disruption controls. It demonstrates how to configure consolidation policy, timing, and budgets for controlled scaling behaviors.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec: # This is not a complete NodePool Spec.\n  disruption:\n    consolidationPolicy: WhenUnderutilized || WhenEmpty\n    consolidateAfter: 10m || Never # metav1.Duration\n    expireAfter: 10m || Never # Equivalent to v1alpha5 TTLSecondsUntilExpired\n    budgets:\n    # On Weekdays during business hours, don't do any deprovisioning.\n    - schedule: \"0 9 * * mon-fri\"\n      duration: 8h\n      nodes: 0\n    # Every other time, only allow 10 nodes to be deprovisioned simultaneously\n    - nodes: 10\n```\n\n----------------------------------------\n\nTITLE: Example NodePool YAML with Multiple Reasons Budget\nDESCRIPTION: This YAML example demonstrates how to configure a NodePool in Karpenter using the proposed multiple reasons budget approach. It shows two budget configurations, one for specific reasons and another as a default.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  disruption:\n    budgets:\n    - schedule: \"* * * * *\"\n      reasons: [Drifted, Underutilized]\n      nodes: 10\n    - nodes: 5\n      schedule: \"* * * * *\"\n\n```\n\n----------------------------------------\n\nTITLE: Creating NodePool and KWOKNodeClass Resources\nDESCRIPTION: YAML configuration to create a NodePool with a KWOKNodeClass reference. This setup defines node requirements including architecture, OS, and capacity type, along with node expiration and disruption policies.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncat <<EOF | envsubst | kubectl apply -f -\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  template:\n    spec:\n      requirements:\n        - key: kubernetes.io/arch\n          operator: In\n          values: [\"amd64\"]\n        - key: kubernetes.io/os\n          operator: In\n          values: [\"linux\"]\n        - key: karpenter.sh/capacity-type\n          operator: In\n          values: [\"spot\"]\n      nodeClassRef:\n        name: default\n        kind: KWOKNodeClass\n        group: karpenter.kwok.sh\n      expireAfter: 720h # 30 * 24h = 720h\n  limits:\n    cpu: 1000\n  disruption:\n    consolidationPolicy: WhenEmptyOrUnderutilized\n    consolidateAfter: 10s\n---\napiVersion: karpenter.kwok.sh/v1alpha1\nkind: KWOKNodeClass\nmetadata:\n  name: default\nEOF\n```\n\n----------------------------------------\n\nTITLE: Implementing NodePool with minValues Requirements Field in Karpenter\nDESCRIPTION: Example of a NodePool specification with the proposed minValues field to enforce a minimum number of instance options. This ensures Karpenter maintains flexibility when scheduling pods, particularly beneficial for spot instances to avoid immediate interruptions after launch.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nspec:\n  template:\n    spec:\n      requirements:\n        - key: karpenter.kwok.sh/instance-family\n          operator: In\n          values: [\"c\", \"m\", \"r\"]\n          minValues: 2\n        - key: node.kubernetes.io/instance-type\n          operator: Exists\n          minValues: 10\n```\n\n----------------------------------------\n\nTITLE: Implementing Disruption Type in Go\nDESCRIPTION: Go code definition for the Disruption struct and related types. It defines the data structure for disruption controls, including budgets, consolidation policies, and timing parameters for node lifecycle management.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype Disruption struct {\n    {...}\n    // Budgets is a list of Budgets.\n    // If there are multiple active budgets, the most restrictive budget's value is respected.\n    Budgets []Budget `json:\"budgets,omitempty\" hash:\"ignore\"`\n    // ConsolidateAfter is a nillable duration, parsed as a metav1.Duration.\n    // Users can use \"Never\" to disable Consolidation.\n    ConsolidateAfter *NillableDuration `json:\"consolidateAfter\" hash:\"ignore\"`\n    // ExpireAfter is a nillable duration, parsed as a metav1.Duration.\n    // Users can use \"Never\" to disable Expiration.\n    ExpireAfter *NillableDuration `json:\"expireAfter\" hash:\"ignore\"`\n    // ConsolidationPolicy determines how Karpenter will consider nodes\n    // as candidates for Consolidation.\n    // WhenEmpty uses the same behavior as v1alpha5 TTLSecondsAfterEmpty\n    // WhenUnderutilized uses the same behavior as v1alpha5.ConsolidationEnabled: true\n    ConsolidationPolicy string `json:\"consolidationPolicy\" hash:\"ignore\"`\n}\n// Budget specifies periods of times where Karpenter will restrict the\n// number of Node Claims that can be terminated at a time.\n// Unless specified, a budget is always active.\ntype Budget struct {\n    // Nodes dictates how many NodeClaims owned by this NodePool\n    // can be terminating at once.\n    // This only respects and considers NodeClaims with the karpenter.sh/disruption taint.\n    Nodes intstr.IntOrString `json:\"nodes\" hash:\"ignore\"`\n    // Schedule specifies when a budget begins being active.\n    // Schedule uses the same syntax as a Cronjob.\n    // And can support a TZ.\n    // \"Minute Hour DayOfMonth Month DayOfWeek\"\n    // This is required if Duration is set.\n    Schedule *string `json:\"schedule,omitempty\" hash:\"ignore\"`\n    // Duration determines how long a Budget is active since each schedule hit.\n    // This is required if schedule is set.\n    Duration *metav1.Duration `json:\"duration,omitempty\" hash:\"ignore\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Querying NodeClaims with kubectl in Karpenter\nDESCRIPTION: Example showing the proposed output format for kubectl get nodeclaims command with wide output flag. Displays node claims with their instance types, capacity, zones, and other metadata across different AWS instance types.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n➜  karpenter git:(main) ✗ kubectl get nodeclaims -A -o wide\nNAME            TYPE         CAPACITY       ZONE         NODE                                            READY   AGE    ID                                      NODEPOOL  NODECLASS\ndefault-7lh6k   c6gn.large   spot           us-west-2b   ip-192-168-183-234.us-west-2.compute.internal   True    2d7h   aws:///us-west-2b/i-053c6b324e29d2275   default   default\ndefault-97v9h   c6gn.large   spot           us-west-2b   ip-192-168-71-87.us-west-2.compute.internal     True    2d7h   aws:///us-west-2a/i-053c6b324e29d2275   default   default\ndefault-fhzpm   c7gd.large   spot           us-west-2b   ip-192-168-165-122.us-west-2.compute.internal   True    2d7h   aws:///us-west-2c/i-053c6b324e29d2275   default   default\ndefault-rw4vf   c6gn.large   on-demand      us-west-2b   ip-192-168-91-38.us-west-2.compute.internal     True    2d7h   aws:///us-west-2a/i-053c6b324e29d2275   default   default\ndefault-v5qfb   c7gd.large   spot           us-west-2a   ip-192-168-58-94.us-west-2.compute.internal     True    2d7h   aws:///us-west-2b/i-053c6b324e29d2275   default   default\n```\n\n----------------------------------------\n\nTITLE: Defining Budget Struct with Multiple Reasons in Go\nDESCRIPTION: This Go struct defines a Budget type for Karpenter, including a new 'Reasons' field to specify multiple disruption reasons per budget. It includes fields for nodes, schedule, and duration, with appropriate Kubernetes validation annotations.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntype Budget struct {\n      Reasons []string `json:\"reason,omitempty\" hash:\"ignore\"`\n      Nodes string `json:\"nodes\" hash:\"ignore\"`\n      Schedule *string `json:\"schedule,omitempty\" hash:\"ignore\"`\n      Duration *metav1.Duration `json:\"duration,omitempty\" hash:\"ignore\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum Instance Types for Spot-to-Spot Consolidation\nDESCRIPTION: YAML configuration example demonstrating how to set a lower minValues for instance types, which will still respect the minimum 15 instance types required for spot-to-spot consolidation in Karpenter.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n- key: node.kubernetes.io/instance-type\n  operator: Exists\n  minValues: 3\n```\n\n----------------------------------------\n\nTITLE: Blocking Drift and Expiration, Allowing Consolidation in Karpenter NodePool (YAML)\nDESCRIPTION: This YAML snippet shows how to configure a Karpenter NodePool to fully block drift and expiration while allowing consolidation. It sets up disruption budgets to prevent drift and expiration-based disruptions but allows other types of consolidation.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: worker-pool \nspec: # This is not a complete NodePool Spec.\n  disruption:\n    consolidationPolicy: WhenUnderutilized \n    expireAfter: Never \n    budgets:\n    - nodes: 0\n      reasons: [drifted, expired] \n    - nodes: \"100%\" // All Disruption Other than drift and expiration are allowed\n```\n\n----------------------------------------\n\nTITLE: Defining NodePool for Reserved Capacity in Karpenter YAML\nDESCRIPTION: YAML configuration for a NodePool that only launches nodes using reserved capacity in Karpenter.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/capacity-reservations.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n name: reserved-only\nspec:\n requirements:\n - key: karpenter.sh/capacity-type\n   operator: In\n   values: [\"reserved\"]\n```\n\n----------------------------------------\n\nTITLE: Solution 1: NodePool with minValues in Requirements Field\nDESCRIPTION: The recommended implementation of minValues in the NodePool spec.requirements section. This approach informs the scheduler to stop bin-packing pods onto Preflight NodeClaims when flexibility drops below the specified minimum, creating another NodeClaim instead.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nspec:\n  template:\n    spec:\n      requirements:\n      - key: karpenter.kwok.sh/instance-family\n        operator: In\n        values: [\"c\", \"m\", \"r\"]\n        minValues: 2\n      - key: node.kubernetes.io/instance-type\n        operator: Exists\n        minValues: 10\n```\n\n----------------------------------------\n\nTITLE: Configuring Disruption Budgets in Karpenter NodePool (YAML)\nDESCRIPTION: This YAML snippet demonstrates the configuration of disruption budgets in a Karpenter NodePool, including settings for consolidation and drift. It showcases how to set up budgets for different schedules and node percentages.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: example-nodepool\nspec:\n  disruption:\n    defaults:\n      budgets: \n        - nodes: 10% \n          schedule: \"0 0 1 * *\"\n          duration: 1h \n    consolidation:\n      consolidationPolicy: WhenUnderutilized\n      disruptAfter: \"30m\"\n    drift:\n      budgets:\n        - nodes: \"20%\"\n          schedule: \"0 0 1 * *\"\n          duration: \"1h\"\n        - nodes: \"10%\"\n          schedule: \"0 0 * * 0\"\n          duration: \"2h\"\n        - nodes: \"50%\" \n          schedule: \"@monthly\"\n```\n\n----------------------------------------\n\nTITLE: Blocking Drift and Allowing Expiration in Karpenter NodePool (YAML)\nDESCRIPTION: This YAML configuration demonstrates how to block drift while allowing expiration in a Karpenter NodePool. It sets up disruption budgets to prevent drift-based disruptions but allows expiration and empty node consolidation.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: worker-pool \nspec: # This is not a complete NodePool Spec.\n  disruption:\n    consolidationPolicy: WhenEmpty \n    expireAfter: 7d \n    budgets:\n    - nodes: 0\n      reasons: [drifted] \n    - nodes: \"100%\" // All Disruption Other than drift(Expiration and Empty Nodes) are allowed\n```\n\n----------------------------------------\n\nTITLE: Configuring NodePool with Reserved Capacity Preference in Karpenter YAML\nDESCRIPTION: YAML configuration for a NodePool that prefers reserved capacity nodes but falls back to on-demand in Karpenter.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/capacity-reservations.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n name: prefer-reserved\nspec:\n requirements:\n   - key: karpenter.sh/capacity-type\n     operator: In\n     values: [\"on-demand\", \"reserved\"]\n```\n\n----------------------------------------\n\nTITLE: Proposed Printer Columns for Karpenter v1 NodePools\nDESCRIPTION: The expanded kubectl output format proposed for Karpenter v1 NodePools. This enhanced view includes additional columns like node count, readiness status, age, CPU, and memory allocation for better operational visibility.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n➜  karpenter git:(main) ✗ kubectl get nodepools -o wide\nNAME      NODECLASS  NODES  READY  AGE   WEIGHT  CPU  MEMORY\ndefault   default    4      True   2d7h  100     10  160Gi\nfallback  default    100    True   2d7h          5   30Gi\n```\n\n----------------------------------------\n\nTITLE: Defining NodeRegistrationHealthy Status Condition Structure in Kubernetes NodePool\nDESCRIPTION: Example YAML structure showing how the proposed NodeRegistrationHealthy status condition would appear in a NodePool's status field. This condition would indicate whether nodes can successfully register when created through this NodePool.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/noderegistrationhealthy-status-condition.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n// 'NodeRegistrationHealthy' condition indicates if a misconfiguration exists that prevents the normal, successful use of a Karpenter resource\nStatus:\n  Conditions:\n    Last Transition Time:  2025-01-13T18:57:20Z\n    Message:               \n    Observed Generation:   1\n    Reason:                NodeRegistrationHealthy\n    Status:                True\n    Type:                  NodeRegistrationHealthy\n```\n\n----------------------------------------\n\nTITLE: Defining NodeClaim Termination Grace Period in YAML\nDESCRIPTION: Example YAML definition of a NodeClaim with the terminationGracePeriod field set to 24 hours. This field indicates the maximum duration Karpenter will wait before forcefully terminating pods on a node during deletion.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodeclaim-termination-grace-period.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodeClaim\nspec:\n  terminationGracePeriod: 24h   # metav1.Duration, nil if not set\n```\n\n----------------------------------------\n\nTITLE: Implementing NodePool and NodeClaim Hash Version Annotations in YAML\nDESCRIPTION: This snippet demonstrates the proposed annotation structure for NodePool and NodeClaim resources with the new hash versioning system. It shows how both the hash value itself and the hash version would be stored as annotations to enable proper drift detection across Karpenter upgrades.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/drift-hash-versioning.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\n  annotations: \n    karpenter.sh/nodepool-hash: abcdef\n    karpenter.sh/nodepool-hash-version: v1\n    ...\n---\napiVersion: karpenter.sh/v1beta1\nkind: NodeClaim \nmetadata:\n  name: default\n  annotations: \n    karpenter.sh/nodepool-hash: abcdef\n    karpenter.sh/nodepool-hash-version: v1\n    ...\n```\n\n----------------------------------------\n\nTITLE: Default NodePool with Disruption Settings in YAML\nDESCRIPTION: Example YAML showing the defaulted values for a NodePool with disruption controls. This demonstrates how Karpenter applies default values when fields are omitted in the configuration.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  disruption:\n    consolidationPolicy: WhenUnderutilized\n    consolidateAfter: 15s\n    expireAfter: 30d\n    budgets:\n    - nodes: 10%\n```\n\n----------------------------------------\n\nTITLE: Defining RepairStatement and CloudProvider Interface in Go\nDESCRIPTION: Code snippet defining the RepairStatement struct that specifies unhealthy node conditions and toleration durations, along with an extension to the CloudProvider interface to support repair policies.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/node-repair.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntype RepairStatement struct {\n    // Type of unhealthy state that is found on the node\n    Type metav1.ConditionType \n    // Status condition of when a node is unhealthy\n    Status metav1.ConditionStatus\n    // TolerationDuration is the duration the controller will wait\n    // before attempting to terminate nodes that are marked for repair.\n    TolerationDuration time.Duration\n}\n\ntype CloudProvider interface {\n  ...\n    // RepairPolicy is for CloudProviders to define a set Unhealthy condition for Karpenter \n    // to monitor on the node. Customer will need \n    RepairPolicy() []v1.RepairPolicy\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Default NodePool in Karpenter YAML\nDESCRIPTION: YAML configuration for a default NodePool that launches all capacity types in Karpenter.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/capacity-reservations.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n name: default\nspec:\n # No additional requirements needed, launch all capacity types by default\n requirements: []\n```\n\n----------------------------------------\n\nTITLE: Defining Instance Type Dimensions for KwoK Cloud Provider\nDESCRIPTION: Specifies the parameters for generating instance types as a cartesian product of various dimensions including instance family, size, and capacity type. This creates 64 distinct instance types across 4 availability zones.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/kwok-provider.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. Instance Type Name: (family)-(size)\n    a. size: 1x, 2x, 4x, 9x, 16x, 32x, 48x, 64x, 100x, 128x, 192x, 256x\n    b. family: c (cpu), s (standard), m (memory)\n        i. c ---> 1 vCPU : 2 GiB\n        ii. s --> 1 vCPU : 4 GiB\n        iii. m -> 1 vCPU : 8 GiB\n2. Capacity Type: [on-demand, spot]\n```\n\n----------------------------------------\n\nTITLE: Displaying NodeClaim Printer Columns\nDESCRIPTION: Example of the current output when listing NodeClaims using kubectl, showing the printer columns that display key information about each NodeClaim.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n➜  karpenter git:(main) ✗ kubectl get nodeclaims -o wide\nNAME            TYPE         ZONE         NODE                                            READY   AGE    CAPACITY   NODEPOOL   NODECLASS\ndefault-7lh6k   c6gn.large   us-west-2b   ip-192-168-183-234.us-west-2.compute.internal   True    2d7h   spot       default    default\ndefault-97v9h   c6gn.large   us-west-2b   ip-192-168-71-87.us-west-2.compute.internal     True    2d7h   spot       default    default\ndefault-fhzpm   c7gd.large   us-west-2b   ip-192-168-165-122.us-west-2.compute.internal   True    2d7h   spot       default    default\ndefault-rw4vf   c6gn.large   us-west-2b   ip-192-168-91-38.us-west-2.compute.internal     True    2d7h   spot       default    default\ndefault-v5qfb   c7gd.large   us-west-2a   ip-192-168-58-94.us-west-2.compute.internal     True    2d7h   spot       default    default\n```\n\n----------------------------------------\n\nTITLE: Example AWS Cloud Provider RepairPolicy Implementation\nDESCRIPTION: Example implementation of the RepairPolicy function for the AWS Karpenter Provider that defines policies for handling Ready and NetworkUnavailable node conditions with specific toleration durations.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/node-repair.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nfunc (c *CloudProvider) RepairPolicy() []cloudprovider.RepairStatement {\n    return cloudprovider.RepairStatement{\n        {\n            Type: \"Ready\"\n            Status: corev1.ConditionFalse,\n            TrolorationDuration: \"30m\"\n        },\n        {\n            Type: \"NetworkUnavailable\"\n            Status: corev1.ConditionTrue,\n            TrolorationDuration: \"10m\"\n        },\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining minValues for Instance Types in Karpenter NodePool\nDESCRIPTION: YAML configuration example showing how to set minValues for instance types in a Karpenter NodePool. This ensures a minimum number of instance type options are maintained during scheduling and consolidation.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n- key: node.kubernetes.io/instance-type\n  operator: Exists\n  minValues: 30\n```\n\n----------------------------------------\n\nTITLE: Limiting Drift and Expiration, Allowing Aggressive Consolidation in Karpenter NodePool (YAML)\nDESCRIPTION: This YAML configuration demonstrates how to limit drift and expiration while allowing aggressive but not unbounded consolidation in a Karpenter NodePool. It sets different disruption budgets for various reasons to control node removals.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: worker-pool \nspec: # This is not a complete NodePool Spec.\n  disruption:\n    consolidationPolicy: WhenUnderutilized \n    expireAfter: 1h \n    budgets:\n    - nodes: 1\n      reasons: [drifted, expired] # Only allow Drift and Expiration to occur one at a time \n    - nodes: \"33%\" # All Consolidation actions taken either through replace or delete should be allowed to disrupt at least a third of the cluster at once\n```\n\n----------------------------------------\n\nTITLE: Current Printer Columns for Karpenter NodePools\nDESCRIPTION: The current kubectl output format for Karpenter NodePools showing limited information. This shows the basic columns available in the v1beta1 API when listing NodePools.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n➜  karpenter git:(main) ✗ kubectl get nodepools -o wide\nNAME      NODECLASS   WEIGHT\ndefault   default     100\nfallback  fallback\n```\n\n----------------------------------------\n\nTITLE: Installing Kwok Provider for Karpenter\nDESCRIPTION: Commands to install the Kwok provider and apply Karpenter configurations to the cluster. The second command can be rerun to deploy code changes.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake install-kwok\nmake apply # Run this command again to redeploy if the code has changed\n```\n\n----------------------------------------\n\nTITLE: Representing Instance Type Offerings with Reserved Capacity in YAML\nDESCRIPTION: YAML representation of instance type offerings including reserved capacity with limited availability.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/capacity-reservations.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: c5.large\nofferings:\n  - price: 0.085\n    available: 5\n    requirements:\n      ...\n      - key: karpenter.sh/capacity-type\n        operator: In\n        values: [\"reserved\"]\n  - price: 0.085\n    available: 4294967295\n    requirements:\n      ...\n      - key: karpenter.sh/capacity-type\n        operator: In\n        values: [\"on-demand\"]\n  - price: 0.0315\n    available: 4294967295\n    requirements:\n      ...\n      - key: karpenter.sh/capacity-type\n        operator: In\n        values: [\"spot\"]\n```\n\n----------------------------------------\n\nTITLE: Solution 2: minValues in EC2NodeClass API\nDESCRIPTION: Alternative implementation of minValues in the NodeClass API. This approach gives Cloud Providers control over implementing flexibility requirements, allowing them to enforce certain minimums for best practices without requiring direct user specification.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: EC2NodeClass\nspec:\n  minValues:\n    node.kubernetes.io/instance-type: 10\n    karpenter.kwok.sh/instance-family: 2\n---\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nspec:\n  template:\n    spec:\n      requirements:\n      - key: karpenter.kwok.sh/instance-family\n        operator: In\n        values: [\"c\", \"m\", \"r\"]\n      - key: node.kubernetes.io/instance-type\n        operator: Exists\n```\n\n----------------------------------------\n\nTITLE: Pricing Function Implementation for KwoK Cloud Provider\nDESCRIPTION: Defines the pricing calculation formulas for the simulated instances. Prices are based on CPU and memory resources with a discount factor applied for spot instances to reflect typical cloud provider pricing models.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/kwok-provider.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n1. price_of_base_size = (#vCPU * 0.25) + (#GiB * 0.01) # Roughly calculated based on guessing pricing functions from multiple cloud providers. \n2. on_demand_price    = size * price_of_base_size()\n3. spot_price         = on_demand_price * .7 # Some discount factor to reflect savings somewhere in the middle of the referenced CPs.\n```\n\n----------------------------------------\n\nTITLE: Example Node Condition YAML for Unhealthy Nodes\nDESCRIPTION: YAML examples showing node status conditions that would trigger node repair based on the defined repair policies, including timing calculations for when nodes would become eligible for repair.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/node-repair.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Node\nmetadata:\n  ...\nstatus:\n  condition:\n    - lastHeartbeatTime: \"2024-11-01T16:29:49Z\"\n      lastTransitionTime: \"2024-11-01T15:02:48Z\"\n      message: no connection\n      reason: Network is not available\n      status: \"False\"\n      type: NetworkUnavailable\n    ...\n    \n- The Node here will be eligible for node repair after at `2024-11-01T15:12:48Z`    \n---\napiVersion: v1\nkind: Node\nmetadata:\n  ...\nstatus:\n  condition:\n    - lastHeartbeatTime: \"2024-11-01T16:29:49Z\"\n      lastTransitionTime: \"2024-11-01T15:02:48Z\"\n      message: kubelet is posting ready status\n      reason: KubeletReady\n      status: \"False\"\n      type: NetworkUnavailable\n    - lastHeartbeatTime: \"2024-11-01T16:29:49Z\"\n      lastTransitionTime: \"2024-11-01T15:02:48Z\"\n      message: kubelet is posting ready status\n      reason: KubeletReady\n      status: \"False\"\n      type: Ready\n    ...\n    \n- The Node here will be eligible for node repair after at `2024-11-01T15:32:48Z`\n```\n\n----------------------------------------\n\nTITLE: Implementing NodeClaim Termination Grace Period in Go\nDESCRIPTION: Go struct definition for the NodeClaimSpec with the terminationGracePeriod field. The field is of type metav1.Duration and includes detailed documentation about its purpose, behavior, and validation patterns.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodeclaim-termination-grace-period.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype NodeClaimSpec struct {\n  {...}\n\t// TerminationGracePeriod is the maximum duration the controller will wait before forcefully deleting the pods on a node, measured from when deletion is first initiated.\n\t//\n\t// Warning: this feature takes precedence over a Pod's terminationGracePeriodSeconds value, and bypasses any blocked PDBs or the karpenter.sh/do-not-disrupt annotation.\n\t//\n\t// This field is intended to be used by cluster administrators to enforce that nodes can be cycled within a given time period.\n\t// When set, drifted nodes will begin draining even if there are pods blocking eviction. Draining will respect PDBs and the do-not-disrupt annotation until the TGP is reached.\n\t//\n\t// Karpenter will preemptively delete pods so their terminationGracePeriodSeconds align with the node's terminationGracePeriod.\n\t// If a pod would be terminated without being granted its full terminationGracePeriodSeconds prior to the node timeout,\n\t// that pod will be deleted at T = node timeout - pod terminationGracePeriodSeconds.\n\t//\n\t// The feature can also be used to allow maximum time limits for long-running jobs which can delay node termination with preStop hooks.\n\t// If left undefined, the controller will wait indefinitely for pods to be drained.\n\t// +kubebuilder:validation:Pattern=`^([0-9]+(s|m|h))+$`\n\t// +kubebuilder:validation:Type=\"string\"\n\t// +optional\n\tTerminationGracePeriod *metav1.Duration `json:\"terminationGracePeriod,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Solution 3: flexibility Field in NodePool Requirements\nDESCRIPTION: A third solution proposing a flexibility field instead of minValues. This enforces an exact number of instance type options rather than a minimum, which can lead to complications when exact flexibility cannot be achieved or results in sub-optimal price decisions.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodepool-requirement-flexibility.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nspec:\n  template:\n    spec:\n      requirements:\n      - key: karpenter.kwok.sh/instance-family\n        operator: In\n        values: [\"c5\", \"r3\", \"m5\"]\n        flexibility: 2\n      - key: node.kubernetes.io/instance-type\n        operator: Exists\n        flexibility: 10\n```\n\n----------------------------------------\n\nTITLE: Defining Status Conditions in Kubernetes\nDESCRIPTION: Example of the upstream Kubernetes status condition schema, showing required fields and structure for reporting resource status.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/v1-api.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nconditions:\n  - type: Initialized\n    status: \"False\"\n    observedGeneration: 1\n    lastTransitionTime: \"2024-02-02T19:54:34Z\"\n    reason: NodeClaimNotLaunched\n    message: \"NodeClaim hasn't succeeded launch\"\n```\n\n----------------------------------------\n\nTITLE: Defining Budget Struct with Single Reason in Go\nDESCRIPTION: This Go struct defines a Budget type for Karpenter with a single 'Reason' field for specifying one disruption reason per budget. It includes fields for nodes, schedule, and duration, with appropriate Kubernetes validation annotations.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ntype Budget struct {\n      Reason string `json:\"reason,omitempty\" hash:\"ignore\"`\n      Nodes string `json:\"nodes\" hash:\"ignore\"`\n      Schedule *string `json:\"schedule,omitempty\" hash:\"ignore\"`\n      Duration *metav1.Duration `json:\"duration,omitempty\" hash:\"ignore\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Example NodePool YAML with Single Reason Budget\nDESCRIPTION: This YAML example shows how to configure a NodePool in Karpenter using the proposed single reason budget approach. It demonstrates two budget configurations, one for a specific reason and another as a default.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/disruption-controls-by-reason.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  disruption:\n    budgets:\n    - schedule: \"* * * * *\"\n      reason: drifted \n      nodes: 10\n    - nodes: 5\n      schedule: \"* * * * *\"\n\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Kwok with Kind Cluster\nDESCRIPTION: Environment variable configuration for using Kwok with a Kind Kubernetes cluster. These variables specify the repository location and cluster name used for testing.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport KWOK_REPO=kind.local\nexport KIND_CLUSTER_NAME=<kind cluster name, for example, chart-testing>\n```\n\n----------------------------------------\n\nTITLE: Running Karpenter E2E Tests\nDESCRIPTION: Commands for executing end-to-end tests for the Kwok provider. The second command shows how to run a specific test case by setting the FOCUS environment variable.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake e2etests\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport FOCUS=\"<e2e case name>\"\nmake e2etests\n```\n\n----------------------------------------\n\nTITLE: Manually Forcing Node Termination with kubectl drain Command\nDESCRIPTION: Example of how cluster administrators can manually force node termination using kubectl commands. The example shows how to use the drain command with --grace-period=0 and --disable-eviction=true flags to forcefully terminate a node, bypassing Pod Disruption Budgets.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodeclaim-termination-grace-period.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl drain my-node --grace-period=0 --disable-eviction=true\n\n$ kubectl drain --help\nOptions:\n    --grace-period=-1:\n\tPeriod of time in seconds given to each pod to terminate gracefully. If negative, the default value specified\n\tin the pod will be used.\n\n    --disable-eviction=false:\n\tForce drain to use delete, even if eviction is supported. This will bypass checking PodDisruptionBudgets, use\n\twith caution.\n```\n\n----------------------------------------\n\nTITLE: Tainting Existing Nodes for Testing\nDESCRIPTION: Command to taint existing nodes with CriticalAddonsOnly:NoSchedule, which helps test Karpenter's node scaling capabilities by preventing regular workloads from being scheduled on existing nodes.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl taint nodes <existing node name> CriticalAddonsOnly:NoSchedule\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Kwok Provider\nDESCRIPTION: Commands to remove the Kwok provider and Karpenter installation from the cluster. This completely cleans up the test environment.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/kwok/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake delete\nmake uninstall-kwok\n```\n\n----------------------------------------\n\nTITLE: Defining Directory Structure for Karpenter E2E Tests\nDESCRIPTION: Lists the key directories involved in Karpenter's E2E testing infrastructure, including workflow definitions, composite actions, test suites, utilities, and testing scripts.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/test/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# E2E Testing\n\nKarpenter leverages Github Actions to run our E2E test suites. \n\n## Directories\n- `./.github/workflows`: Workflow files run within this repository. Relevant files for E2E testing are prefixed with `e2e-`\n- `./.github/actions/e2e`: Composite actions utilized by the E2E workflows\n- `./test/suites`: Directories defining test suites\n- `./test/pkg`: Common utilities and expectations\n- `./test/hack`: Testing scripts\n```\n\n----------------------------------------\n\nTITLE: Creating and Pushing Tags for Karpenter Releases with Git\nDESCRIPTION: Command examples for creating and pushing version tags to the upstream repository. Used in the Karpenter release process to trigger the Release Workflow.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/RELEASE.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit tag v<major>.<minor>.<patch>\n```\n\nLANGUAGE: bash\nCODE:\n```\ngit push upstream v<major>.<minor>.<patch>\n```\n\n----------------------------------------\n\nTITLE: DaemonSet Controller Taint Reference\nDESCRIPTION: Reference to the Kubernetes DaemonSet Controller's default taint implementation that adds tolerations to every pod, including the node.kubernetes.io/unschedulable taint.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/no-schedule-taint.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nnode.kubernetes.io/unschedulable\n```\n\n----------------------------------------\n\nTITLE: Cluster Autoscaler Custom Taint Implementation\nDESCRIPTION: Reference to Cluster Autoscaler's custom NoSchedule taint implementation used to prevent pod scheduling on nodes being deprovisioned.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/no-schedule-taint.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nkarpenter.sh/disruption=disrupting:NoSchedule\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for Contributing Guidelines\nDESCRIPTION: Structured markdown document containing guidelines and resources for contributing to Kubernetes projects, including links to important documentation, mentorship programs, and communication channels.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Contributing Guidelines\n\nWelcome to Kubernetes. We are excited about the prospect of you joining our [community](https://git.k8s.io/community)! The Kubernetes community abides by the CNCF [code of conduct](code-of-conduct.md). Here is an excerpt:\n\n_As contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities._\n\n## Getting Started\n\nWe have full documentation on how to get started contributing here:\n\n- [Contributor License Agreement](https://git.k8s.io/community/CLA.md) - Kubernetes projects require that you sign a Contributor License Agreement (CLA) before we can accept your pull requests\n- [Kubernetes Contributor Guide](https://k8s.dev/guide) - Main contributor documentation, or you can just jump directly to the [contributing page](https://k8s.dev/docs/guide/contributing/)\n- [Contributor Cheat Sheet](https://k8s.dev/cheatsheet) - Common resources for existing developers\n\n## Mentorship\n\n- [Mentoring Initiatives](https://k8s.dev/community/mentoring) - We have a diverse set of mentorship programs available that are always looking for volunteers!\n\n## Contact Information\n\n- [Slack channel](https://kubernetes.slack.com/messages/sig-k8s-infra)\n```\n\n----------------------------------------\n\nTITLE: Alternative Approach: NodePool-level Termination Grace Period\nDESCRIPTION: Alternative YAML implementation that defines the terminationGracePeriod at the NodePool level instead of on individual NodeClaims. This approach would allow cluster-wide configuration changes without requiring node replacement.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/designs/nodeclaim-termination-grace-period.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  disruption:\n    terminationGracePeriod: 24h   # metav1.Duration, nil if not set\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header for Karpenter Project\nDESCRIPTION: Standard copyright and license notice that appears at the top of source files in the Karpenter project. It specifies that the code is licensed under Apache License 2.0 and includes information about where to find the full license text.\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/hack/boilerplate.go.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n/*\nCopyright The Kubernetes Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n```\n\n----------------------------------------\n\nTITLE: Referencing Karpenter Repository Path\nDESCRIPTION: GitHub repository path reference for the Karpenter project\nSOURCE: https://github.com/kubernetes-sigs/karpenter/blob/main/contributing-guidelines.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n/kubernetes-sigs/karpenter\n```"
  }
]