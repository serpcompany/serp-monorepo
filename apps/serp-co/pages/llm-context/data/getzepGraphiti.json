[
  {
    "owner": "getzep",
    "repo": "graphiti",
    "content": "TITLE: Initializing Graphiti with Google Gemini in Python\nDESCRIPTION: This snippet shows how to initialize Graphiti with Google Gemini. It requires the `graphiti_core` library and the `google-genai` extra. The code defines the Google API key and uses it to initialize `GeminiClient` and `GeminiEmbedder`, which are then passed to the Graphiti constructor. Replace `<your-google-api-key>` with your actual Google API key.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom graphiti_core import Graphiti\nfrom graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig\nfrom graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig\n\n# Google API key configuration\napi_key = \"<your-google-api-key>\"\n\n# Initialize Graphiti with Gemini clients\ngraphiti = Graphiti(\n    \"bolt://localhost:7687\",\n    \"neo4j\",\n    \"password\",\n    llm_client=GeminiClient(\n        config=LLMConfig(\n            api_key=api_key,\n            model=\"gemini-2.0-flash\"\n        )\n    ),\n    embedder=GeminiEmbedder(\n        config=GeminiEmbedderConfig(\n            api_key=api_key,\n            embedding_model=\"embedding-001\"\n        )\n    )\n)\n\n# Now you can use Graphiti with Google Gemini\n```\n\n----------------------------------------\n\nTITLE: Initialize Graphiti Client Python\nDESCRIPTION: This code initializes the Graphiti client with connection details to a Neo4j database and an Anthropic language model client. It creates an `AnthropicClient` (with caching disabled) and then instantiates the `Graphiti` object using the Neo4j URI, username, password, and the configured LLM client.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nllm_client = AnthropicClient(cache=False)\n\nclient = Graphiti(\n    neo4j_uri,\n    neo4j_user,\n    neo4j_password,\n    llm_client=llm_client,\n)\n```\n\n----------------------------------------\n\nTITLE: Set OpenAI API Key Environment Variable\nDESCRIPTION: This command sets the OpenAI API key as an environment variable, which is required for LLM and embedding functionalities. It also sets optional Neo4j connection parameters.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/quickstart/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Required for LLM and embedding\nexport OPENAI_API_KEY=your_openai_api_key\n\n# Optional Neo4j connection parameters (defaults shown)\nexport NEO4J_URI=bolt://localhost:7687\nexport NEO4J_USER=neo4j\nexport NEO4J_PASSWORD=password\n```\n\n----------------------------------------\n\nTITLE: Installing Graphiti with Google GenAI Support\nDESCRIPTION: These commands show how to install Graphiti with support for Google's Gemini models using Poetry or UV package managers.  The `graphiti-core[google-genai]` extra installs the necessary dependencies for using Gemini with Graphiti.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npoetry add \"graphiti-core[google-genai]\"\n\n# or\n\nuv add \"graphiti-core[google-genai]\"\n```\n\n----------------------------------------\n\nTITLE: Define Tool to Query Graphiti for Shoe Data\nDESCRIPTION: Defines a LangChain tool `get_shoe_data` that queries the Graphiti graph for information about shoes. It uses the `client.search` method to search for relevant edges, centering the search around a specified `manybirds_node_uuid` to prioritize shoe-related data, and returns the results as a string of facts.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@tool\nasync def get_shoe_data(query: str) -> str:\n    \"\"\"Search the graphiti graph for information about shoes\"\"\"\n    edge_results = await client.search(\n        query,\n        center_node_uuid=manybirds_node_uuid,\n        num_results=10,\n    )\n    return edges_to_facts_string(edge_results)\n\n\ntools = [get_shoe_data]\ntool_node = ToolNode(tools)\n```\n\n----------------------------------------\n\nTITLE: Clear Data and Build Indices Python\nDESCRIPTION: This asynchronous snippet clears existing data from the Neo4j database connected to the Graphiti client, builds necessary indices and constraints to optimize graph operations, and then ingests product data using the `ingest_products_data` function.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nawait clear_data(client.driver)\nawait client.build_indices_and_constraints()\nawait ingest_products_data(client)\n```\n\n----------------------------------------\n\nTITLE: Run LangGraph Agent Python\nDESCRIPTION: This code snippet shows how to invoke the LangGraph agent with an initial message and user context. It passes a dictionary containing the initial user message, user name, and user node UUID to the `graph.ainvoke` method, along with a configuration specifying the thread ID.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nawait graph.ainvoke(\n    {\n        'messages': [\n            {\n                'role': 'user',\n                'content': 'What sizes do the TinyBirds Wool Runners in Natural Black come in?',\n            }\n        ],\n        'user_name': user_name,\n        'user_node_uuid': user_node_uuid,\n    },\n    config={'configurable': {'thread_id': uuid.uuid4().hex}},\n)\n```\n\n----------------------------------------\n\nTITLE: Add Customer Conversation to Graphiti Python\nDESCRIPTION: This asynchronous code adds the `shoe_conversation_1` data to the graph using the `add_messages` function, prefixing the episodes with 'conversation-1'.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nawait add_messages(client, shoe_conversation_1, prefix='conversation-1')\n```\n\n----------------------------------------\n\nTITLE: Adding Episode with JSON Data\nDESCRIPTION: Example of using the `add_episode` tool to add an episode with structured JSON data. The `source` parameter is set to \"json\" to indicate that the episode body is in JSON format. This allows the server to automatically extract entities and relationships.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_12\n\nLANGUAGE: null\nCODE:\n```\nadd_episode(\nname=\"Customer Profile\",\nepisode_body=\"{\\\"company\\\": {\\\"name\\\": \\\"Acme Technologies\\\"}, \\\"products\\\": [{\\\"id\\\": \\\"P001\\\", \\\"name\\\": \\\"CloudSync\\\"}, {\\\"id\\\": \\\"P002\\\", \\\"name\\\": \\\"DataMiner\\\"}]}\",\nsource=\"json\",\nsource_description=\"CRM data\"\n)\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti Core with pip\nDESCRIPTION: This command installs the core Graphiti package using pip. It's the basic installation method for using Graphiti in a Python environment. It requires Python 3.10 or higher.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core\n```\n\n----------------------------------------\n\nTITLE: Search for Node Named John Python\nDESCRIPTION: This asynchronous snippet searches for nodes named 'John' using a specific search configuration (`NODE_HYBRID_SEARCH_RRF`). It then extracts the UUID of the first search result and stores it in the `john_uuid` variable.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom graphiti_core.search.search_config_recipes import NODE_HYBRID_SEARCH_RRF\n\nnl = await client._search('John', NODE_HYBRID_SEARCH_RRF)\n\npretty_print(nl[0])\n\njohn_uuid = nl[0].uuid\n```\n\n----------------------------------------\n\nTITLE: Define Chatbot Logic\nDESCRIPTION: Defines the core logic of the chatbot, integrating Graphiti for context retrieval and knowledge persistence. The chatbot retrieves relevant information from Graphiti based on the latest message and the user's node UUID, constructs a system message incorporating these facts, and generates a response using the language model. It also asynchronously adds the interaction to the Graphiti graph for future context.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nasync def chatbot(state: State):\n    facts_string = None\n    if len(state['messages']) > 0:\n        last_message = state['messages'][-1]\n        graphiti_query = f'{\"SalesBot\" if isinstance(last_message, AIMessage) else state[\"user_name\"]}: {last_message.content}'\n        # search graphiti using Jess's node uuid as the center node\n        # graph edges (facts) further from the Jess node will be ranked lower\n        edge_results = await client.search(\n            graphiti_query, center_node_uuid=state['user_node_uuid'], num_results=5\n        )\n        facts_string = edges_to_facts_string(edge_results)\n\n    system_message = SystemMessage(\n        content=f\"\"\"You are a skillfull shoe salesperson working for ManyBirds. Review information about the user and their prior conversation below and respond accordingly.\n        Keep responses short and concise. And remember, always be selling (and helpful!)\n\n        Things you'll need to know about the user in order to close a sale:\n        - the user's shoe size\n        - any other shoe needs? maybe for wide feet?\n        - the user's preferred colors and styles\n        - their budget\n\n        Ensure that you ask the user for the above if you don't already know.\n\n        Facts about the user and their conversation:\n        {facts_string or 'No facts about the user and their conversation'}\"\"\"\n    )\n\n    messages = [system_message] + state['messages']\n\n    response = await llm.ainvoke(messages)\n\n    # add the response to the graphiti graph.\n    # this will allow us to use the graphiti search later in the conversation\n    # we're doing async here to avoid blocking the graph execution\n    asyncio.create_task(\n        client.add_episode(\n            name='Chatbot Response',\n            episode_body=f'{state[\"user_name\"]}: {state[\"messages\"][-1]}\\nSalesBot: {response.content}',\n            source=EpisodeType.message,\n            reference_time=datetime.now(timezone.utc),\n            source_description='Chatbot',\n        )\n    )\n\n    return {'messages': [response]}\n```\n\n----------------------------------------\n\nTITLE: Search for Shoes John Purchased Python\nDESCRIPTION: This asynchronous snippet searches the graph for information about what shoes John has purchased, centering the search around John's node (`john_uuid`) and limiting the results to 3. The results are then formatted and printed.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search('What shoes has John purchased?', center_node_uuid=john_uuid, num_results=3)\n\npretty_print(r)\n```\n\n----------------------------------------\n\nTITLE: Search for Shoes John Purchased (5 results) Python\nDESCRIPTION: This asynchronous snippet searches the graph for information about what shoes John has purchased, centering the search around John's node (`john_uuid`) and limiting the results to 5. The results are then formatted and printed.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search('What shoes has John purchased?', center_node_uuid=john_uuid, num_results=5)\n\npretty_print(r)\n```\n\n----------------------------------------\n\nTITLE: Search for Customer Shoe Size Python\nDESCRIPTION: This asynchronous code performs a search using the Graphiti client to find John's shoe size, limiting the results to two. It then formats and prints the search results using the `pretty_print` function.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search(\"What is John's shoe size?\", num_results=2)\n\npretty_print(r)\n```\n\n----------------------------------------\n\nTITLE: Initializing Graphiti with Azure OpenAI in Python\nDESCRIPTION: This snippet demonstrates how to initialize Graphiti with Azure OpenAI for both LLM inference and embeddings. It requires the `openai` and `graphiti_core` libraries. The code defines the Azure OpenAI credentials (API key, API version, Azure endpoint) and uses them to create an `AsyncAzureOpenAI` client. This client is then used to initialize `OpenAIClient`, `OpenAIEmbedder`, and `OpenAIRerankerClient`, which are passed to the Graphiti constructor.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncAzureOpenAI\nfrom graphiti_core import Graphiti\nfrom graphiti_core.llm_client import OpenAIClient\nfrom graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\nfrom graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n\n# Azure OpenAI configuration\napi_key = \"<your-api-key>\"\napi_version = \"<your-api-version>\"\nazure_endpoint = \"<your-azure-endpoint>\"\n\n# Create Azure OpenAI client for LLM\nazure_openai_client = AsyncAzureOpenAI(\n    api_key=api_key,\n    api_version=api_version,\n    azure_endpoint=azure_endpoint\n)\n\n# Initialize Graphiti with Azure OpenAI clients\ngraphiti = Graphiti(\n    \"bolt://localhost:7687\",\n    \"neo4j\",\n    \"password\",\n    llm_client=OpenAIClient(\n        client=azure_openai_client\n    ),\n    embedder=OpenAIEmbedder(\n        config=OpenAIEmbedderConfig(\n            embedding_model=\"text-embedding-3-small\"  # Use your Azure deployed embedding model name\n        ),\n        client=azure_openai_client\n    ),\n    # Optional: Configure the OpenAI cross encoder with Azure OpenAI\n    cross_encoder=OpenAIRerankerClient(\n        client=azure_openai_client\n    )\n)\n\n# Now you can use Graphiti with Azure OpenAI\n```\n\n----------------------------------------\n\nTITLE: Node Centered Search if John Can Wear Wool Runners Python\nDESCRIPTION: This asynchronous code performs a node-centered search query to determine if John can wear ManyBirds Wool Runners, retrieving up to 3 results, with the search centered on the node identified by `john_uuid`. The 'fact' attribute of each result is printed to the console.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search(\n    'Can John wear ManyBirds Wool Runners?', center_node_uuid=john_uuid, num_results=3\n)\n\nprint('-' * 100)\nprint(\"Node Distance Reranking from 'John' node\")\nprint('-' * 100)\nfor record in r:\n    print(record.fact)\n```\n\n----------------------------------------\n\nTITLE: Search for Out of Stock Products Python\nDESCRIPTION: This asynchronous snippet performs a search query using the Graphiti client to find information about which products are out of stock. It then prints the fact attribute of the first search result.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search('Which products are out of stock?')\n\npretty_print(r[0])\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Client (SSE Transport)\nDESCRIPTION: Configures an MCP-compatible client to connect to the Graphiti MCP server using the SSE transport.  The URL specifies the endpoint for the server.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"graphiti\": {\n      \"transport\": \"sse\",\n      \"url\": \"http://localhost:8000/sse\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pretty Print Graphiti Entities Python\nDESCRIPTION: This function `pretty_print` formats and prints Graphiti `EntityEdge` objects or lists of `EntityEdge` objects. If given a single EntityEdge, it converts it to a dictionary, removing the 'fact_embedding' field. If given a list, it performs the same conversion on each element. If it's neither, it prints the entity directly using `pprint`.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef pretty_print(entity: EntityEdge | list[EntityEdge]):\n    if isinstance(entity, EntityEdge):\n        data = {k: v for k, v in entity.model_dump().items() if k != 'fact_embedding'}\n    elif isinstance(entity, list):\n        data = [{k: v for k, v in e.model_dump().items() if k != 'fact_embedding'} for e in entity]\n    else:\n        pprint(entity)\n        return\n    pprint(data)\n```\n\n----------------------------------------\n\nTITLE: Setup Logging Python\nDESCRIPTION: This code sets up a basic logging configuration.  It creates a logger, sets its level to INFO, creates a console handler that writes to stdout, sets the handler's level to INFO, creates a formatter, adds the formatter to the handler, and adds the handler to the logger.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef setup_logging():\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n    return logger\n\n\nlogger = setup_logging()\n```\n\n----------------------------------------\n\nTITLE: Define Customer Conversation Data Python\nDESCRIPTION: This code defines two lists, `shoe_conversation_1` and `shoe_conversation_2`, representing customer service conversations related to shoe purchases and returns. Each element in the lists represents a message in the conversation, including a timestamp.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nshoe_conversation_1 = [\n    \"SalesBot (2024-07-30T00:00:00Z): Hi, I'm ManyBirds Assistant! How can I help you today?\",\n    \"John (2024-07-30T00:01:00Z): Hi, I'm looking for a new pair of shoes.\",\n    'SalesBot (2024-07-30T00:02:00Z): Of course! What kind of material are you looking for?',\n    \"John (2024-07-30T00:03:00Z): I'm allergic to wool. Also, I'm a size 10 if that helps?\",\n    \"SalesBot (2024-07-30T00:04:00Z): We have just what you are looking for, how do you like our Men's Couriers. They have a retro silhouette look and from cotton. How about them in Basin Blue?\",\n    \"John (2024-07-30T00:05:00Z): Blue is great! Love the look. I'll take them.\",\n]\n\nshoe_conversation_2 = [\n    'SalesBot (2024-08-20T00:00:00Z): Hi John, how can I assist you today?',\n    \"John (2024-08-20T00:01:00Z): Hi, I need to return the Men's Couriers I bought recently. They're too tight for my wide feet. Hahaha.\",\n    \"SalesBot (2024-08-20T00:02:00Z): I'm sorry to hear that. We can process the return for you.\",\n]\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose\nDESCRIPTION: Starts the services defined in the `docker-compose.yml` file. This command deploys the Graphiti MCP server and Neo4j using Docker.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Interactive LangGraph Agent Python\nDESCRIPTION: This code implements an interactive conversation loop using IPython widgets. It defines an `on_submit` function to process user input and send it to the LangGraph agent. The agent's responses are displayed in an output widget.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nconversation_output = widgets.Output()\nconfig = {'configurable': {'thread_id': uuid.uuid4().hex}}\nuser_state = {'user_name': user_name, 'user_node_uuid': user_node_uuid}\n\n\nasync def process_input(user_state: State, user_input: str):\n    conversation_output.append_stdout(f'\\nUser: {user_input}\\n')\n    conversation_output.append_stdout('\\nAssistant: ')\n\n    graph_state = {\n        'messages': [{'role': 'user', 'content': user_input}],\n        'user_name': user_state['user_name'],\n        'user_node_uuid': user_state['user_node_uuid'],\n    }\n\n    try:\n        async for event in graph.astream(\n            graph_state,\n            config=config,\n        ):\n            for value in event.values():\n                if 'messages' in value:\n                    last_message = value['messages'][-1]\n                    if isinstance(last_message, AIMessage) and isinstance(\n                        last_message.content, str\n                    ):\n                        conversation_output.append_stdout(last_message.content)\n    except Exception as e:\n        conversation_output.append_stdout(f'Error: {e}')\n\n\ndef on_submit(b):\n    user_input = input_box.value\n    input_box.value = ''\n    asyncio.create_task(process_input(user_state, user_input))\n\n\ninput_box = widgets.Text(placeholder='Type your message here...')\nsubmit_button = widgets.Button(description='Send')\nsubmit_button.on_click(on_submit)\n\nconversation_output.append_stdout('Asssistant: Hello, how can I help you find shoes today?')\n\ndisplay(widgets.VBox([input_box, submit_button, conversation_output]))\n```\n\n----------------------------------------\n\nTITLE: Installing Graphiti Project Dependencies\nDESCRIPTION: This command uses `make` to install the necessary project dependencies, streamlining the setup process. It ensures that all required packages and tools are available for development.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake install\n```\n\n----------------------------------------\n\nTITLE: Running Code Quality Checks\nDESCRIPTION: This command executes a comprehensive set of checks, including formatting, linting, and testing, to ensure code quality before submitting a pull request.  It helps maintain consistency and prevent errors.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nmake check\n```\n\n----------------------------------------\n\nTITLE: Clear and Build Graphiti Indices and Constraints\nDESCRIPTION: Clears existing data and builds indices and constraints in the Graphiti database. This is typically done only on the first run or when resetting the database.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Note: This will clear the database\nawait clear_data(client.driver)\nawait client.build_indices_and_constraints()\n```\n\n----------------------------------------\n\nTITLE: Running Graphiti MCP Server with Cursor IDE (SSE)\nDESCRIPTION: Starts the Graphiti MCP server with SSE transport, custom entities enabled, and a group ID. This is required to use Graphiti within the Cursor IDE.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npython graphiti_mcp_server.py --transport sse --use-custom-entities --group-id <your_group_id>\n```\n\n----------------------------------------\n\nTITLE: Ingest Products Data into Graphiti Python\nDESCRIPTION: This asynchronous function `ingest_products_data` reads product data from a JSON file ('manybirds_products.json') and adds it to the Graphiti knowledge graph as episodes.  It extracts product details, creates `RawEpisode` objects for each product (excluding the 'images' field), and adds these episodes in bulk to the graph.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync def ingest_products_data(client: Graphiti):\n    script_dir = Path.cwd().parent\n    json_file_path = script_dir / 'data' / 'manybirds_products.json'\n\n    with open(json_file_path) as file:\n        products = json.load(file)['products']\n\n    episodes: list[RawEpisode] = [\n        RawEpisode(\n            name=product.get('title', f'Product {i}'),\n            content=str({k: v for k, v in product.items() if k != 'images'}),\n            source_description='ManyBirds products',\n            source=EpisodeType.json,\n            reference_time=datetime.now(timezone.utc),\n        )\n        for i, product in enumerate(products)\n    ]\n\n    await client.add_episode_bulk(episodes)\n```\n\n----------------------------------------\n\nTITLE: Cloning the Graphiti Repository\nDESCRIPTION: This snippet demonstrates how to clone the forked Graphiti repository locally and navigate into the project directory. It's the initial step in setting up the development environment for contributing to the project.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/getzep/graphiti\ncd graphiti\n```\n\n----------------------------------------\n\nTITLE: Ingest Products Data into Graphiti\nDESCRIPTION: Ingests product data from a JSON file into the Graphiti graph. It reads the JSON file, iterates through the products, and adds each product as an episode in Graphiti.  The episode body is a string representation of the product's key-value pairs (excluding the 'images' key).\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nasync def ingest_products_data(client: Graphiti):\n    script_dir = Path.cwd().parent\n    json_file_path = script_dir / 'data' / 'manybirds_products.json'\n\n    with open(json_file_path) as file:\n        products = json.load(file)['products']\n\n    for i, product in enumerate(products):\n        await client.add_episode(\n            name=product.get('title', f'Product {i}'),\n            episode_body=str({k: v for k, v in product.items() if k != 'images'}),\n            source_description='ManyBirds products',\n            source=EpisodeType.json,\n            reference_time=datetime.now(timezone.utc),\n        )\n\n\nawait ingest_products_data(client)\n```\n\n----------------------------------------\n\nTITLE: Create a User Node in Graphiti\nDESCRIPTION: Creates a user node in the Graphiti graph and retrieves its UUID. It adds an episode representing the user's interest in buying shoes and searches for the user node to obtain its UUID, and the ManyBirds node uuid. This UUID is used to configure the agent for personalized interactions.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom graphiti_core.search.search_config_recipes import NODE_HYBRID_SEARCH_EPISODE_MENTIONS\n\nuser_name = 'jess'\n\nawait client.add_episode(\n    name='User Creation',\n    episode_body=(f'{user_name} is interested in buying a pair of shoes'),\n    source=EpisodeType.text,\n    reference_time=datetime.now(timezone.utc),\n    source_description='SalesBot',\n)\n\n# let's get Jess's node uuid\nnl = await client._search(user_name, NODE_HYBRID_SEARCH_EPISODE_MENTIONS)\n\nuser_node_uuid = nl.nodes[0].uuid\n\n# and the ManyBirds node uuid\nnl = await client._search('ManyBirds', NODE_HYBRID_SEARCH_EPISODE_MENTIONS)\nmanybirds_node_uuid = nl.nodes[0].uuid\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Client (stdio Transport)\nDESCRIPTION: Configures an MCP-compatible client to connect to the Graphiti MCP server using the stdio transport.  Requires setting the path to `uv` and the project folder.  The environment variables specify the Neo4j connection details, the OpenAI API key, and the model to use.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"graphiti\": {\n      \"transport\": \"stdio\",\n      \"command\": \"/Users/<user>/.local/bin/uv\",\n      \"args\": [\n        \"run\",\n        \"--isolated\",\n        \"--directory\",\n        \"/Users/<user>>/dev/zep/graphiti/mcp_server\",\n        \"--project\",\n        \".\",\n        \"graphiti_mcp_server.py\",\n        \"--transport\",\n        \"stdio\"\n      ],\n      \"env\": {\n        \"NEO4J_URI\": \"bolt://localhost:7687\",\n        \"NEO4J_USER\": \"neo4j\",\n        \"NEO4J_PASSWORD\": \"password\",\n        \"OPENAI_API_KEY\": \"sk-XXXXXXXX\",\n        \"MODEL_NAME\": \"gpt-4.1-mini\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a New Branch for Changes\nDESCRIPTION: This command creates a new branch in the local Git repository to isolate changes during development.  A descriptive branch name should be used to indicate the purpose of the changes.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b your-branch-name\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Graph Service and Neo4j\nDESCRIPTION: This YAML file configures both the graph service and a Neo4j instance using Docker Compose. It defines the necessary environment variables, ports, and volumes for the services to function correctly. It also specifies the Neo4j image version and authentication details.\nSOURCE: https://github.com/getzep/graphiti/blob/main/server/README.md#_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\nversion: '3.8'\n\nservices:\ngraph:\n image: zepai/graphiti:latest\n ports:\n - \"8000:8000\"\n \n environment:\n - OPENAI_API_KEY=${OPENAI_API_KEY}\n - NEO4J_URI=bolt://neo4j:${NEO4J_PORT}\n - NEO4J_USER=${NEO4J_USER}\n - NEO4J_PASSWORD=${NEO4J_PASSWORD}\nneo4j:\n image: neo4j:5.22.0\n \n ports:\n - \"7474:7474\"  # HTTP\n - \"${NEO4J_PORT}:${NEO4J_PORT}\"  # Bolt\n volumes:\n - neo4j_data:/data\n environment:\n - NEO4J_AUTH=${NEO4J_USER}/${NEO4J_PASSWORD}\n\nvolumes:\nneo4j_data:\n```\n\n----------------------------------------\n\nTITLE: Formatting Graphiti Code\nDESCRIPTION: This command automatically formats the codebase according to project coding style guidelines using the configured formatting tool. Consistent code formatting improves readability and maintainability.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake format\n```\n\n----------------------------------------\n\nTITLE: Import Libraries and Load Environment Variables\nDESCRIPTION: Imports required Python libraries and loads environment variables from a `.env` file using the `dotenv` library. This includes libraries for asynchronous operations, JSON handling, logging, operating system interaction, path manipulation, type hinting, IPython display, and environment variable management.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport json\nimport logging\nimport os\nimport sys\nimport uuid\nfrom contextlib import suppress\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Annotated\n\nimport ipywidgets as widgets\nfrom dotenv import load_dotenv\nfrom IPython.display import Image, display\nfrom typing_extensions import TypedDict\n\nload_dotenv()\n```\n\n----------------------------------------\n\nTITLE: Pushing Changes to Remote Fork\nDESCRIPTION: This command pushes the changes from the local branch to the corresponding branch in the forked repository on GitHub. This makes the changes available for creating a pull request.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ngit push origin your-branch-name\n```\n\n----------------------------------------\n\nTITLE: Add Messages to Graphiti Python\nDESCRIPTION: This asynchronous function `add_messages` adds a list of messages to the Graphiti knowledge graph as episodes.  It iterates through the messages, adding each one as a separate episode with the given prefix, message content, source type (message), current timestamp, and source description ('Shoe conversation').\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def add_messages(client: Graphiti, messages: list[str], prefix: str = 'Message'):\n    for i, message in enumerate(messages):\n        await client.add_episode(\n            name=f'{prefix}-{i}',\n            episode_body=message,\n            source=EpisodeType.message,\n            reference_time=datetime.now(timezone.utc),\n            source_description='Shoe conversation',\n        )\n```\n\n----------------------------------------\n\nTITLE: Cloning Graphiti Repository (GitHub CLI)\nDESCRIPTION: Clones the Graphiti GitHub repository using the GitHub CLI. An alternative way to obtain the Graphiti source code.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngh repo clone getzep/graphiti\n```\n\n----------------------------------------\n\nTITLE: Import Libraries and Load Environment Variables Python\nDESCRIPTION: This code snippet imports necessary Python libraries and loads environment variables from a `.env` file. The libraries include modules for JSON handling, logging, OS interaction, date/time management, path manipulation, and specific Graphiti components.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport logging\nimport os\nimport sys\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nfrom dotenv import load_dotenv\nfrom rich.pretty import pprint\n\nfrom graphiti_core import Graphiti\nfrom graphiti_core.edges import EntityEdge\nfrom graphiti_core.llm_client.anthropic_client import AnthropicClient\nfrom graphiti_core.nodes import EpisodeType\nfrom graphiti_core.utils.bulk_utils import RawEpisode\nfrom graphiti_core.utils.maintenance.graph_data_operations import clear_data\n\nload_dotenv()\n```\n\n----------------------------------------\n\nTITLE: Add Nodes and Edges to LangGraph Python\nDESCRIPTION: This code adds nodes ('agent', 'tools') and edges to a LangGraph, defining the flow of execution. It uses `add_conditional_edges` to determine the next node based on the `should_continue` function, which decides whether to route to 'tools' or 'end'.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ngraph_builder.add_node('agent', chatbot)\ngraph_builder.add_node('tools', tool_node)\n\ngraph_builder.add_edge(START, 'agent')\ngraph_builder.add_conditional_edges('agent', should_continue, {'continue': 'tools', 'end': END})\ngraph_builder.add_edge('tools', 'agent')\n\ngraph = graph_builder.compile(checkpointer=memory)\n```\n\n----------------------------------------\n\nTITLE: Copying .env.example to .env\nDESCRIPTION: Copies the `.env.example` file to `.env`. This allows users to configure environment variables for the server.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Graph Service\nDESCRIPTION: This snippet shows the environment variables that need to be passed to the graph service for proper configuration. It includes the OpenAI API key, Neo4j user credentials, and Neo4j port number, enabling the service to connect to the necessary resources.\nSOURCE: https://github.com/getzep/graphiti/blob/main/server/README.md#_snippet_0\n\nLANGUAGE: Dockerfile\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nNEO4J_USER=your_neo4j_user\nNEO4J_PASSWORD=your_neo4j_password\nNEO4J_PORT=your_neo4j_port\n```\n\n----------------------------------------\n\nTITLE: Configure Graphiti Client\nDESCRIPTION: Configures the Graphiti client using environment variables for the Neo4j connection. It retrieves the URI, username, and password from the environment and initializes the Graphiti client.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Configure Graphiti\n\nfrom graphiti_core import Graphiti\nfrom graphiti_core.edges import EntityEdge\nfrom graphiti_core.nodes import EpisodeType\nfrom graphiti_core.utils.maintenance.graph_data_operations import clear_data\n\neo4j_uri = os.environ.get('NEO4J_URI', 'bolt://localhost:7687')\neo4j_user = os.environ.get('NEO4J_USER', 'neo4j')\neo4j_password = os.environ.get('NEO4J_PASSWORD', 'password')\n\nclient = Graphiti(\n    neo4j_uri,\n    neo4j_user,\n    neo4j_password,\n)\n```\n\n----------------------------------------\n\nTITLE: Define Continuation Function in LangGraph Python\nDESCRIPTION: This function `should_continue` determines whether the LangGraph agent should continue its execution or terminate based on the presence of tool calls in the last message. If tool calls exist, the agent continues; otherwise, it ends.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nasync def should_continue(state, config):\n    messages = state['messages']\n    last_message = messages[-1]\n    # If there is no function call, then we finish\n    if not last_message.tool_calls:\n        return 'end'\n    # Otherwise if there is, we continue\n    else:\n        return 'continue'\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti with Multiple LLM Providers\nDESCRIPTION: This command installs Graphiti with support for multiple LLM providers: Anthropic, Groq, and Google Gemini. It uses pip to install the core package along with the specified extras.  Requires API keys for the selected providers.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core[anthropic,groq,google-genai]\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Integration Tests\nDESCRIPTION: These commands set environment variables required for running integration tests.  API keys for OpenAI and Anthropic, along with Neo4j credentials, are configured for accessing external services and databases during testing.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport TEST_OPENAI_API_KEY=...\nexport TEST_OPENAI_MODEL=...\nexport TEST_ANTHROPIC_API_KEY=...\n\nexport NEO4J_URI=neo4j://...\nexport NEO4J_USER=...\nexport NEO4J_PASSWORD=...\n```\n\n----------------------------------------\n\nTITLE: Add Inventory Management Episode Python\nDESCRIPTION: This asynchronous code adds an episode representing inventory management information to the Graphiti knowledge graph. It indicates that 'Tinybirds Wool Runners' styles are out of stock until December 25, 2024.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nawait client.add_episode(\n    name='Inventory management 0',\n    episode_body=('All Tinybirds Wool Runners styles are out of stock until December 25th 2024'),\n    source=EpisodeType.text,\n    reference_time=datetime.now(timezone.utc),\n    source_description='Inventory Management Bot',\n)\n```\n\n----------------------------------------\n\nTITLE: Search if John Can Wear Wool Runners Python\nDESCRIPTION: This asynchronous code performs a search query to determine if John can wear ManyBirds Wool Runners, retrieving up to 3 results. The results are printed to the console, showing the 'fact' attribute of each record.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search('Can John wear ManyBirds Wool Runners?', num_results=3)\n\nprint('-' * 100)\nprint('Standard Reciprocal Rank Fusion Reranking')\nprint('-' * 100)\nfor record in r:\n    print(record.fact)\n```\n\n----------------------------------------\n\nTITLE: Setup Basic Logging Configuration in Python\nDESCRIPTION: Configures a basic logging setup with a console handler that outputs logs to standard output. It sets the logging level to INFO and defines a formatter for log messages.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef setup_logging():\n    logger = logging.getLogger()\n    logger.setLevel(logging.ERROR)\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n    return logger\n\n\nlogger = setup_logging()\n```\n\n----------------------------------------\n\nTITLE: Import LangChain and LangGraph Components\nDESCRIPTION: Imports necessary components from LangChain and LangGraph, including message types, tool functionality, OpenAI Chat model, memory management, graph construction, and prebuilt modules.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.messages import AIMessage, SystemMessage\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import END, START, StateGraph, add_messages\nfrom langgraph.prebuilt import ToolNode\n```\n\n----------------------------------------\n\nTITLE: Configure Neo4j Connection Details Python\nDESCRIPTION: This snippet retrieves Neo4j connection details (URI, username, and password) from environment variables. It defaults to 'bolt://localhost:7687', 'neo4j', and 'password' if the environment variables are not set.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nneo4j_uri = os.environ.get('NEO4J_URI', 'bolt://localhost:7687')\nneo4j_user = os.environ.get('NEO4J_USER', 'neo4j')\nneo4j_password = os.environ.get('NEO4J_PASSWORD', 'password')\n```\n\n----------------------------------------\n\nTITLE: Define State for LangGraph Agent\nDESCRIPTION: Defines the state for the LangGraph agent as a `TypedDict` containing the message history, username, and user node UUID.  The messages field is annotated with `add_messages` which is used by LangGraph to automatically manage the message history.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n    user_name: str\n    user_node_uuid: str\n```\n\n----------------------------------------\n\nTITLE: Search for John's Discomfort with Couriers Python\nDESCRIPTION: This asynchronous code performs a search to determine what John did regarding his discomfort with the Men's Couriers shoes, retrieving up to 5 results. The results are formatted and printed.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search(\n    'What did John do about his discomfort with the Mens Couriers shoes', num_results=5\n)\n\npretty_print(r)\n```\n\n----------------------------------------\n\nTITLE: Configure LangSmith Integration (Optional)\nDESCRIPTION: Configures LangSmith integration for tracing agent execution. It sets the environment variables `LANGCHAIN_TRACING_V2` and `LANGCHAIN_PROJECT`.  Note that `LANGCHAIN_TRACING_V2` is set to 'false' initially.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nos.environ['LANGCHAIN_TRACING_V2'] = 'false'\nos.environ['LANGCHAIN_PROJECT'] = 'Graphiti LangGraph Tutorial'\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti Core with poetry\nDESCRIPTION: This command installs the core Graphiti package using poetry. Poetry is a dependency management tool for Python projects. This installation method also requires Python 3.10 or higher.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry add graphiti-core\n```\n\n----------------------------------------\n\nTITLE: Search for Information on John Python\nDESCRIPTION: This asynchronous code performs a search query to find information about 'Who is John?', limiting the results to 5. The results are formatted and printed using the `pretty_print` function.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nr = await client.search('Who is John?', num_results=5)\n\npretty_print(r)\n```\n\n----------------------------------------\n\nTITLE: Running Graphiti Tests\nDESCRIPTION: This command executes the project's test suite to ensure that changes do not introduce regressions and that existing functionality remains intact. All tests should pass before submitting a pull request.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake test\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti with Google Gemini Support\nDESCRIPTION: This command installs Graphiti with support for Google Gemini LLM. It uses pip to install the core package along with the 'google-genai' extra. Requires a Google Gemini API key.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core[google-genai]\n```\n\n----------------------------------------\n\nTITLE: Test the Tool Node\nDESCRIPTION: Tests the functionality of the tool node by invoking it with a sample query. This helps verify that the tool node is correctly configured and can interact with the Graphiti graph.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nawait tool_node.ainvoke({'messages': [await llm.ainvoke('wool shoes')]})\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti with Groq Support\nDESCRIPTION: This command installs Graphiti with support for Groq LLM. It uses pip to install the core package along with the 'groq' extra. Requires a Groq API key.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core[groq]\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti with Anthropic Support\nDESCRIPTION: This command installs Graphiti with support for Anthropic LLM. It uses pip to install the core package along with the 'anthropic' extra. Requires an Anthropic API key.\nSOURCE: https://github.com/getzep/graphiti/blob/main/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core[anthropic]\n```\n\n----------------------------------------\n\nTITLE: Convert Entity Edges to Facts String\nDESCRIPTION: Converts a list of `EntityEdge` objects to a formatted string of facts. Each fact is prefixed with a hyphen and a newline.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef edges_to_facts_string(entities: list[EntityEdge]):\n    return '-' + '\\n- '.join([edge.fact for edge in entities])\n```\n\n----------------------------------------\n\nTITLE: Setup LangGraph Agent\nDESCRIPTION: Sets up the LangGraph graph for the agent. This includes defining the graph structure, managing memory, and defining conditional logic for routing between the agent and tools.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ngraph_builder = StateGraph(State)\n\nmemory = MemorySaver()\n```\n\n----------------------------------------\n\nTITLE: Running Graphiti Linting Checks\nDESCRIPTION: This command runs linting checks to identify potential code quality issues and enforce coding standards. Addressing linting errors ensures code adheres to best practices and project conventions.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmake lint\n```\n\n----------------------------------------\n\nTITLE: Add Second Customer Conversation to Graphiti Python\nDESCRIPTION: This asynchronous code adds the `shoe_conversation_2` data to the graph using the `add_messages` function, prefixing the episodes with 'conversation-2'.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/ecommerce/runner.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nawait add_messages(client, shoe_conversation_2, prefix='conversation-2')\n```\n\n----------------------------------------\n\nTITLE: Bind OpenAI Chat Model with Tools\nDESCRIPTION: Binds the OpenAI Chat model (`gpt-4.1-mini`) with the defined tools. This allows the agent to utilize the tools during conversation.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nllm = ChatOpenAI(model='gpt-4.1-mini', temperature=0).bind_tools(tools)\n```\n\n----------------------------------------\n\nTITLE: Committing Changes to Graphiti\nDESCRIPTION: This command commits the changes made in the local Git repository. A clear and detailed commit message is crucial for documenting the purpose and scope of the changes.\nSOURCE: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit commit -m \"Your detailed commit message\"\n```\n\n----------------------------------------\n\nTITLE: Installing uv\nDESCRIPTION: Installs the `uv` package manager using a shell script. `uv` is used for managing the virtual environment and dependencies for the Graphiti MCP server.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose (Older Version)\nDESCRIPTION: Starts the services defined in the `docker-compose.yml` file. This command is an alternative for older versions of Docker Compose.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up\n```\n\n----------------------------------------\n\nTITLE: Creating Virtual Environment with uv\nDESCRIPTION: Creates a virtual environment and installs dependencies using `uv`. This command sets up the necessary environment for running the Graphiti MCP server.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuv sync\n```\n\n----------------------------------------\n\nTITLE: Navigating to Graphiti Directory\nDESCRIPTION: Changes the current directory to the cloned Graphiti repository and prints the absolute path. Useful for confirming the location of the project files.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd graphiti && pwd\n```\n\n----------------------------------------\n\nTITLE: Running Graphiti MCP Server with uv and options\nDESCRIPTION: Runs the Graphiti MCP server using `uv` with specified options for the model and transport method.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nuv run graphiti_mcp_server.py --model gpt-4.1-mini --transport sse\n```\n\n----------------------------------------\n\nTITLE: Install Graphiti Core using pip\nDESCRIPTION: This command installs the graphiti-core package using pip, which is required for running the example.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/quickstart/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install graphiti-core\n```\n\n----------------------------------------\n\nTITLE: Cloning Graphiti Repository (GitHub)\nDESCRIPTION: Clones the Graphiti GitHub repository using git. This is the first step to setting up the Graphiti MCP server.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/getzep/graphiti.git\n```\n\n----------------------------------------\n\nTITLE: Configuring Cursor IDE (SSE Transport)\nDESCRIPTION: Configures the Cursor IDE to connect to the Graphiti MCP server using SSE transport.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"Graphiti\": {\n      \"url\": \"http://localhost:8000/sse\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Install Dependencies with pip\nDESCRIPTION: Installs the necessary Python packages for the LangGraph agent and Graphiti integration.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install graphiti-core langchain-openai langgraph ipywidgets\n```\n\n----------------------------------------\n\nTITLE: Run the quickstart Python script\nDESCRIPTION: This command executes the quickstart.py script using Python, which demonstrates the basic functionalities of Graphiti.\nSOURCE: https://github.com/getzep/graphiti/blob/main/examples/quickstart/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython quickstart.py\n```\n\n----------------------------------------\n\nTITLE: Running Graphiti MCP Server with uv\nDESCRIPTION: Runs the Graphiti MCP server using `uv`. This command starts the server with default settings.\nSOURCE: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuv run graphiti_mcp_server.py\n```"
  }
]