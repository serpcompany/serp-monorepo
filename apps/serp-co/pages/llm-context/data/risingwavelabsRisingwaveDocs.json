[
  {
    "owner": "risingwavelabs",
    "repo": "risingwave-docs",
    "content": "TITLE: SQL SELECT Command Syntax\nDESCRIPTION: The complete syntax for the SQL SELECT command, including all optional clauses like WITH, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT, and OFFSET. This defines how to structure a query to retrieve data from tables or materialized views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n[ WITH clause ]\nSELECT [ ALL | DISTINCT [ ON ( expression [, ...] ) ]] [ [table_name.]* [ EXCEPT ( [table_name.]except_column, ... ] ) ] | expression [ AS output_name ] [ , expression [ AS output_name ] ... ] ]\n    [ VALUES clause ]\n    [ FROM from_item [ , from_item ...] ]\n    [ WHERE condition ]\n    [ GROUP BY grouping_expression [ , grouping_expression ... ] ]\n    [ HAVING condition ]\n    [ ORDER BY sort_expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [ , ... ] ]\n    [ LIMIT count_number ]\n    [ OFFSET start [ ROW | ROWS ] ];\n```\n\n----------------------------------------\n\nTITLE: Creating Real-Time Data Enrichment View in SQL\nDESCRIPTION: This snippet creates a materialized view that joins real-time clickstream data with historical purchase data to generate personalized product recommendations for e-commerce users as they browse.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW personalized_recommendations AS\n  SELECT\n    c.user_id,\n    c.page_url,\n    p.recommended_product,\n    p.category\n  FROM clickstream_data c\n  JOIN purchase_history p ON c.user_id = p.user_id\n  WHERE c.page_url LIKE '%product%';\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Kinesis Source/Table with Avro Format using SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a RisingWave source or table that reads data from an AWS Kinesis stream. It specifies the Kinesis connector, stream name, AWS region, endpoint, and various authentication credentials (session token, role ARN, external ID, access key/secret key). The data is expected to be in Avro format, and the schema definition is fetched from the specified S3 URL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [IF NOT EXISTS] source_name\nWITH (\n   connector='kinesis',\n   stream='kafka',\n   aws.region='user_test_topic',\n   endpoint='172.10.1.1:9090,172.10.1.2:9090',\n   aws.credentials.session_token='AQoEXAMPLEH4aoAH0gNCAPyJxz4BlCFFxWNE1OPTgk5TthT+FvwqnKwRcOIfrRh3c/L To6UDdyJwOOvEVPvLXCrrrUtdnniCEXAMPLE/IvU1dYUg2RVAJBanLiHb4IgRmpRV3z rkuWJOgQs8IZZaIv2BXIa2R4OlgkBN9bkUDNCJiBeb/AXlzBBko7b15fjrBs2+cTQtp Z3CYWFXG8C5zqx37wnOE49mRl/+OtkIKGO7fAE',\n   aws.credentials.role.arn='arn:aws-cn:iam::602389639824:role/demo_role',\n   aws.credentials.role.external_id='demo_external_id',\n   aws.credentials.access_key_id = 'your_access_key',\n   aws.credentials.secret_access_key = 'your_secret_key'\n) FORMAT PLAIN ENCODE AVRO (\n    schema.location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/demo.avsc'\n);\n```\n\n----------------------------------------\n\nTITLE: Syntax for CREATE TABLE in RisingWave SQL\nDESCRIPTION: Provides the general syntax structure for the `CREATE TABLE` command in RisingWave. It outlines how to define table name, columns with data types, optional primary keys (column-level or table-level), default values, generated columns, watermarks, append-only property, conflict handling, inclusion of metadata fields (header, key, etc.), connector settings (`WITH` clause), and data format/encoding specifications (`FORMAT`/`ENCODE`).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n    col_name data_type [ PRIMARY KEY ] [ DEFAULT default_expr ] [ AS generation_expression ],\n    ...\n    [ PRIMARY KEY (col_name, ... ) ]\n    [ watermark_clause ]\n)\n[ APPEND ONLY ]\n[ ON CONFLICT conflict_action ]\n[INCLUDE { header | key | offset | partition | timestamp } [AS <column_name>]]\n[ WITH (\n    connector='connector_name',\n    connector_parameter='value', ...)]\n[FORMAT data_format ENCODE data_encode [ (\n    message='message',\n    schema.location='location', ...) ]\n];\n```\n\n----------------------------------------\n\nTITLE: Setting Up Multi-Source Data Ingestion for E-Commerce in SQL\nDESCRIPTION: This snippet configures multiple data sources for a real-time personalization system, connecting to both Kafka for clickstream data and PostgreSQL for historical customer data using CDC.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE clickstream_data (\n  user_id varchar,\n  page_url varchar,\n) WITH (\n  connector='kafka',\n  topic='clickstream_data',\n  properties.bootstrap.server='localhost:9092',\n  scan.startup.mode='earliest',\n) FORMAT PLAIN ENCODE JSON;\n\nCREATE SOURCE historical_customer_data WITH (\n  connector = 'postgres-cdc',\n  hostname = '127.0.0.1',\n  port = '8306',\n  username = 'root',\n  password = '123456',\n  database.name = 'mydb',\n  slot.name = 'mydb_slot'\n);\n\nCREATE TABLE purchase_history (\n  user_id varchar primary key,\n  recommended_produce varchar,\n  category varchar\n) FROM historical_customer_data TABLE 'my_schema.customer_purchases';\n```\n\n----------------------------------------\n\nTITLE: MQTT Sink Example for IoT Data\nDESCRIPTION: Practical example of creating an MQTT sink that forwards IoT sensor data from a RisingWave table to an MQTT topic. The example demonstrates configuration of server URL, topic name, data type, message retention, QoS, and JSON encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mqtt.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK mqtt_sink\nFROM iot_sensor_data\nWITH\n(\n    connector='mqtt',\n    url='tcp://mqtt-server',\n    topic= 'sink_iot_data',\n    type = 'append-only',\n    retain = 'true',\n    qos = 'at_least_once',\n) FORMAT PLAIN ENCODE JSON (\n    force_append_only='true',\n);\n```\n\n----------------------------------------\n\nTITLE: Using max function in SQL\nDESCRIPTION: Returns the maximum value of non-null inputs, or null if no non-null values are provided. Works with numeric, string, date/time, interval types, or arrays.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nmax ( expression ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Consuming RisingWave Subscription Changes in Python with psycopg2\nDESCRIPTION: This Python snippet demonstrates using the Postgres (psycopg2) driver to connect to RisingWave, declare a subscription cursor, and poll for incoming change records in a loop. It handles cases with no available data by sleeping, prints changes, and ensures the connection and cursor are closed on termination. Dependencies include `psycopg2`; key parameters configure the database connection. Inputs are subscription change events; outputs are rows printed to standard output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_12\n\nLANGUAGE: py\nCODE:\n```\nimport psycopg2\nimport time\n\ndef main():\n    # Connect to the PostgreSQL database\n    conn = psycopg2.connect(\n        host=\"localhost\",\n        port=\"4566\",\n        user=\"root\",\n        database=\"dev\"\n    )\n\n    try:\n        # Create a cursor object\n        cur = conn.cursor()\n\n        # Declare a cursor for the subscription\n        cur.execute(\"DECLARE cur SUBSCRIPTION CURSOR FOR sub_users;\")\n\n        while True:\n            # Fetch the next row from the cursor\n            cur.execute(\"FETCH NEXT FROM cur;\")\n            row = cur.fetchone()\n\n            if row is None:\n                # Sleep for 1 second if no row is fetched\n                time.sleep(1)\n                continue\n\n\t\t\t# Replace with your event handling logic\n            print(\"Row fetched:\", row)\n\n    finally:\n        # Close the cursor and connection\n        print(\"Terminated\")\n        cur.close()\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Creating a Table or Source for MQTT Ingestion in RisingWave (SQL)\nDESCRIPTION: This SQL snippet shows the generalized syntax to create a table or source in RisingWave that ingests streaming data from an MQTT broker. It demonstrates how to specify connector options (like broker URL, topic, QoS settings, and authentication), define table columns, and set the data format. Required dependencies include a running RisingWave cluster, an accessible MQTT broker, and suitable topic permissions. The snippet is template-based: users must fill actual values for broker URL, topic, and credentials as applicable. Outputs a table/source automatically synchronized with incoming MQTT messages. Limitations include correct parameterization for connection and format types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mqtt.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE { TABLE | SOURCE} [ IF NOT EXISTS ] source_name\\n(\\n   column_name data_type PRIMARY KEY,\\n   -- Add more columns if needed: column_name2 data_type2, column_name3 data_type3, ...\\n\\n   -- Define the primary key constraint if needed\\n   -- PRIMARY KEY (column_name, ...)\\n\\n)\\nWITH (\\n   connector = 'mqtt',\\n   url = '<your MQTT server>:<port>',\\n   topic = '<topic>',\\n   qos = '<qos_level>',\\n\\n   -- Optional connection parameters\\n   connect_mode = <connect_mode>,\\n   username = '<your user name>',\\n   password = '<your password>',\\n\\n   -- Delivery parameters\\n   scan.startup.mode = 'startup_mode',\\n   scan.startup.timestamp.millis = 'xxxxx'\\n)\\nFORMAT PLAIN ENCODE data_encode; -- Format options: plain (encode BYTES and JSON)\n```\n\n----------------------------------------\n\nTITLE: Granting Database Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet demonstrates how to grant privileges such as CONNECT or CREATE, or ALL PRIVILEGES, on one or more databases to a user in RisingWave. Use the optional WITH GRANT OPTION to allow the recipient to pass on privileges, and GRANTED BY to specify the granting user. Required: a valid database name and user name. Returns: grants the specified privileges to the target user for the specified database(s).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT {{CONNECT | CREATE}[, ...]| ALL [PRIVILEGES]}\nON DATABASE database_name [, ...]\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source in RisingWave using SQL\nDESCRIPTION: This example demonstrates how to create a connection to a Kafka topic named 'user_activity' using the CREATE SOURCE command. It defines the schema, specifies Kafka connector properties, and sets the data format to JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/connect-with-create-source.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE my_kafka_source (\n    user_id INT,\n    product_id VARCHAR,\n    timestamp TIMESTAMP\n) WITH (\n    connector='kafka',\n    topic='user_activity',\n    properties.bootstrap.server='broker1:9092,broker2:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Average Exam Scores\nDESCRIPTION: SQL command to create a materialized view that calculates the average score and count of scores for each exam_id from the exam_scores table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW average_exam_scores AS\nSELECT\n    exam_id,\n    AVG(score) AS average_score,\n    COUNT(score) AS total_scores\nFROM\n    exam_scores\nGROUP BY\n    exam_id;\n```\n\n----------------------------------------\n\nTITLE: Inner ASOF Join Query - SQL\nDESCRIPTION: This SQL code snippet illustrates an inner ASOF join, where the nearest record is joined based on both an equality condition and an inequality condition, typically using event times or ordered columns. Dependencies include upstream availability of measured tables (TableA and TableB) and selection of comparable fields. The query expects both matching keys and a qualifying range to join two records, outputting a selection of fields from the left table and matched closest right-side values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT A.field1 AS A_field1 \nFROM TableA ASOF JOIN TableB \nON A.field1 = B.field1 AND A.field2 <= B.field2;\n```\n\n----------------------------------------\n\nTITLE: Creating a Streaming (Connector-Backed) Table with Kafka in RisingWave SQL\nDESCRIPTION: Creates a streaming table in RisingWave that automatically ingests data from a Kafka topic. The table has an integer primary key and a VARCHAR value column, and specifies connection properties for Kafka with JSON encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE my_streaming_table (\n    id INT PRIMARY KEY,\n    value VARCHAR\n) WITH (\n    connector='kafka',\n    topic='my_topic',\n    properties.bootstrap.server='localhost:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Revoking Database Privileges in SQL\nDESCRIPTION: Syntax for revoking CONNECT, CREATE, or ALL privileges on databases from a user. The GRANTED BY clause specifies the user revoking the privileges, defaulting to root.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {{CONNECT | CREATE}[, ...]| ALL [PRIVILEGES]}\nON DATABASE database_name [, ...]\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Creating a Source in RisingWave\nDESCRIPTION: This SQL command is used to create a source in RisingWave. With shared sources, this command instantiates a single SourceExecutor immediately, which is then shared by all materialized views referencing the same source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only Sink from Append-Only Source in RisingWave\nDESCRIPTION: This SQL command creates an append-only sink in RisingWave to transfer data from an append-only source to Delta Lake. It specifies the sink type and necessary S3 configuration parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1_sink FROM t1_table\nWITH (\n    connector = 'deltalake',\n    type = 'append-only',\n    location = 's3a://my-delta-lake-bucket/path/to/table',\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY}'\n);\n```\n\n----------------------------------------\n\nTITLE: Using dense_rank() Window Function in SQL\nDESCRIPTION: The dense_rank() function returns the rank of the current row, without gaps. If some rows share the same rank, the row next to them is assigned the next consecutive rank.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ndense_rank() → integer\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    dense_rank() OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as r,\n    col1, col2\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Windowed Aggregation using Emit-on-Window-Close in SQL\nDESCRIPTION: This SQL snippet creates a materialized view `mv` performing a windowed aggregation (`MAX(foo)`) over a 1-hour tumbling window (`TUMBLE`) based on the `tm` column from table `t`. The `EMIT ON WINDOW CLOSE` clause ensures that the final maximum value for each hour window is computed and emitted only once the window closes, potentially leveraging specialized operators for better performance compared to the default emit-on-update behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv AS\nSELECT\n    window_start, MAX(foo)\nFROM TUMBLE(t, tm, INTERVAL '1 hour')\nGROUP BY window_start\nEMIT ON WINDOW CLOSE;\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View in RisingWave\nDESCRIPTION: Demonstrates how to query data from a materialized view using psycopg2.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg2\n\nconn = psycopg2.connect(host=\"localhost\", port=4566, user=\"root\", dbname=\"dev\")\nconn.autocommit = True\n\nwith conn.cursor() as cur:\n    cur.execute(\"SELECT * FROM counter;\")\n    print(cur.fetchall())\nconn.close()\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SASL/PLAIN Authentication in RisingWave SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka sink with SASL/PLAIN authentication without SSL encryption. It specifies the SASL mechanism, security protocol, and authentication credentials in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Kafka Connector in RisingWave SQL\nDESCRIPTION: This example demonstrates creating a table that connects to a Kafka topic as its data source. It includes connector configuration properties such as bootstrap servers, startup mode, and timestamp settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS table_abc (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp_millis='140000000',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating an MQTT Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink to send data from RisingWave to an MQTT topic. It defines the connection parameters including URL, topic, QoS level, authentication, and formatting options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mqtt.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='mqtt',\n   url = '<your MQTT server>:<port>',\n   topic = '<topic>',\n   qos =  '<qos_level>',\n   type = '<append-only>'\n   username = '<your user name>',\n   password = '<your password>')\nFORMAT PLAIN ENCODE data_encode -- Format options: plain (encode BYTES and JSON) (\n    force_append_only='true',\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Connection with Secrets in SQL\nDESCRIPTION: Example SQL command demonstrating how to create a Kafka connection named `conn_kafka` using secure secret management. It specifies the connection type as `kafka`, provides the bootstrap server address, and uses the `SECRET` keyword to reference pre-configured secrets for SASL username and password, enhancing security.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION conn_kafka WITH (\n    type = 'kafka',\n    properties.bootstrap.server='<broker addr>', \n    properties.sasl.mechanism='PLAIN', \n    properties.security.protocol='SASL_PLAINTEXT', \n    properties.sasl.username=SECRET <username>, \n    properties.sasl.password=SECRET <password>\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/PLAIN Authentication and SSL Encryption in RisingWave SQL\nDESCRIPTION: This snippet demonstrates creating a Kafka source with both SASL/PLAIN authentication and SSL encryption. It includes SASL credentials and SSL certificate locations in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_3 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_SSL',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Inserting Rows from a SELECT Query with RETURNING Clause in RisingWave SQL\nDESCRIPTION: Example SQL statement demonstrating how to insert rows into the `taxi_trips` table by selecting all rows (`SELECT *`) from another table named `taxi_trips_new`, assuming both tables have compatible schemas. It also utilizes the `RETURNING id` clause to return the `id` column values for each row that was successfully inserted during this operation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO taxi_trips\n    SELECT * FROM taxi_trips_new\n    RETURNING id;\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Materialized View for Filtering Flight Data in SQL\nDESCRIPTION: This SQL query creates a materialized view named `checkin_open_notification` in RisingWave. It processes data from the `combined_passenger_flight_data` table, filtering for records where the passenger has opted in (`opted_in = TRUE`) and the flight departure time is between 48 and 72 hours from the current time (`NOW()`). This view effectively selects passengers eligible for check-in notifications.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/solace.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW checkin_open_notification AS\nSELECT flight_id, passenger_ref_number, flight_number, carrier_code, departure_time, contact_info\nFROM combined_passenger_flight_data\nWHERE opted_in = TRUE\n  AND departure_time <= NOW() - INTERVAL '48 hours'\n  AND departure_time > NOW() - INTERVAL '72 hours';\n```\n\n----------------------------------------\n\nTITLE: Querying the Materialized View for Average Exam Scores\nDESCRIPTION: SQL query to retrieve all data from the average_exam_scores materialized view, which shows the current average scores and total number of scores for each exam.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM average_exam_scores;\n------\n exam_id |   average_score   | total_scores\n---------+-------------------+--------------\n     102 | 90.05000000000001 |            2\n     101 | 85.33333333333333 |            3\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating Indexes Using SQL in RisingWave\nDESCRIPTION: Illustrates the SQL syntax for creating indexes in RisingWave with optional clauses such as IF NOT EXISTS, INCLUDE, and DISTRIBUTED BY. No external dependencies are required except access to a RisingWave SQL interface. Parameters include index_name (desired index name), object_name (table or view), index_column (column(s) to index), include_column (additional columns), and distributed_column (distribution key for cluster). Inputs are table definitions and outputs are index metadata affecting subsequent query performance. Omitting INCLUDE will default to covering all columns of the table in RisingWave, differing from some other DBMSs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX [IF NOT EXISTS] index_name ON object_name ( index_column [ ASC | DESC ], [, ...] )\n[ INCLUDE ( include_column [, ...] ) ]\n[ DISTRIBUTED BY ( distributed_column [, ...] ) ];\n```\n\n----------------------------------------\n\nTITLE: Creating a User with OAuth Authentication - RisingWave SQL\nDESCRIPTION: This SQL snippet shows how to create a RisingWave user with OAuth authentication. It requires the mandatory parameters 'jwks_url' and 'issuer'; additional custom parameters may be set and will be checked against JWT claims. All keys should be in lowercase, and the system expects that all JWT headers and claims comply with the documented requirements. The result of this operation is a user account configured for OAuth-based authentication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER user_name WITH oauth (\n  jwks_url = 'xxx.com',\n  issuer = 'risingwave',\n  other_params_should_match = 'xxx',\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Tables, Sources, and Views with RisingWave SQL\nDESCRIPTION: This sequence of SQL statements creates a plain table, inserts values, defines a table sourcing data from a built-in generator using connector and format settings, and then creates several views based on these objects. It showcases integration with datagen, mapping between tables and views, and composing new views from existing objects. Key dependencies include having access to RisingWave with connector support and understanding table and view definitions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-view.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table and add some records.\n\nCREATE TABLE t1 (a int, b int, c int);\n\nINSERT INTO t1 VALUES (115, 1, 8), (585, 2, 3), (601, 3, 7);\n\n-- Create a source (whose data is generated by the built-in generator).\n\nCREATE TABLE s1 (i1 int, c1 varchar)\nWITH (\n     connector = 'datagen',\n     fields.i1.kind = 'sequence',\n     fields.i1.start = '1',\n     fields.c1.kind = 'random',\n     fields.c1.length = '16',\n     fields.c1.seed = '3',\n     datagen.rows.per.second = '10'\n ) FORMAT PLAIN ENCODE JSON;\n\n-- Create views based on the table, source, and existing views.\n\nCREATE VIEW IF NOT EXISTS v1 (a1, b1) AS SELECT a, b FROM t1;\n\nCREATE VIEW v2 AS SELECT * FROM s1 ORDER BY i1;\n\nCREATE VIEW v3 AS SELECT a1, i1, c1 FROM v1 LEFT JOIN v2 ON v1.b1=v2.i1;\n```\n\n----------------------------------------\n\nTITLE: Creating a SQL Server CDC Source in RisingWave (SQL)\nDESCRIPTION: This SQL syntax defines how to create a CDC source in RisingWave that connects to a SQL Server database. It uses the `sqlserver-cdc` connector and requires specifying connection details like hostname, port, username, password, and database name. Optional parameters like `database.encrypt` can also be included.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name WITH (\n   connector='sqlserver-cdc',\n   <field>=<value>, ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table from Kafka with All Columns and Generated Column (SQL)\nDESCRIPTION: Demonstrates creating a RisingWave table (`from_kafka`) that ingests data from a Kafka topic ('test-rw-sink-upsert-avro'). It uses `*` to include all columns from the source, defines an additional generated column (`gen_i32_field`), specifies a primary key based on an included Kafka key (`INCLUDE KEY AS some_key`), and configures the Kafka connector and UPSERT AVRO format with a schema registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Use * to represent all columns\nCREATE TABLE from_kafka (\n  *,\n  gen_i32_field INT AS int32_field + 2,\n  PRIMARY KEY (some_key)\n)\nINCLUDE KEY AS some_key\n[INCLUDE { header | offset | partition | timestamp } [AS <column_name>]]\nWITH (\n  connector = 'kafka',\n  topic = 'test-rw-sink-upsert-avro',\n  properties.bootstrap.server = 'message_queue:29092'\n)\nFORMAT upsert ENCODE AVRO (\n  schema.registry = 'http://message_queue:8081'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Nested Structures in RisingWave SQL\nDESCRIPTION: This example shows how to create a table with a STRUCT type for nested data. The table contains basic columns plus a 'fare' column that has a nested structure with multiple fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS taxi_trips(\n    id VARCHAR,\n    distance DOUBLE PRECISION,\n    duration DOUBLE PRECISION,\n    fare STRUCT<\n      initial_charge DOUBLE PRECISION,\n      subsequent_charge DOUBLE PRECISION,\n      surcharge DOUBLE PRECISION,\n      tolls DOUBLE PRECISION>);\n```\n\n----------------------------------------\n\nTITLE: Creating a PostgreSQL CDC Source in RisingWave\nDESCRIPTION: SQL syntax for creating a source in RisingWave that connects to PostgreSQL for CDC. This defines the connection parameters including hostname, port, credentials, and database information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name WITH (\n    connector='postgres-cdc',\n    <field>=<value>, ...\n);\n```\n\n----------------------------------------\n\nTITLE: Defining a Data Sink with RisingWave SQL Syntax - SQL\nDESCRIPTION: Provides the canonical SQL template for the CREATE SINK operation in RisingWave. This snippet outlines parameter placement for connector selection, data formatting, encoding, and snapshot control, serving as a reference for users integrating external data sinks. Required parameters include the sink name, data source (either table, materialized view, or SELECT query), connector type/settings, and optional formatting or snapshot policies. Inputs include the intended sink name and connector details; output is a new configured sink. All connector- and format-related options must be placed as specified—misplacement can result in errors.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-sink.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector = 'connector_name',\n   connector_parameter = 'value',\n   [ snapshot = 'true' | 'false' ],...\n)\n[ FORMAT data_format ENCODE data_encode [ (\n    format_parameter = 'value'\n) ] ];\n```\n\n----------------------------------------\n\nTITLE: Basic SQL SELECT with WHERE Clause Syntax\nDESCRIPTION: Demonstrates the fundamental syntax of a SELECT statement incorporating a WHERE clause for filtering data. The condition must evaluate to a boolean result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/where-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column1, column2, columnN\nFROM table_name\nWHERE condition\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with JSON Encoding in SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka source in RisingWave using JSON encoding. It defines two columns and specifies Kafka connection properties along with startup mode and timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Indexes in RisingWave (SQL)\nDESCRIPTION: These snippets cover creating tables and indexes, and explain how different index configurations affect query plan utilization in RisingWave. They showcase the impact of the INCLUDE clause and index coverage on query optimization, including when additional lookups may be required. The examples also display EXPLAIN output for different SELECT queries, highlighting which indexes are used in each case, and what columns are involved in scan or lookup operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(k1 INT, k2 INT, v1 INT, v2 INT, PRIMARY KEY(k1,k2));\n\n--- idx_t_k2_partial_columns doesn\\'t include column v2.\nCREATE INDEX idx_t_k2_partial_columns ON t(k2) INCLUDE (k1,v1);\n\n--- idx_t_k2_partial_columns is not utilized.\nEXPLAIN SELECT v2 FROM t WHERE k1=1;\n BatchExchange { order: [], dist: Single }\n └─BatchScan { table: t, columns: [v2], scan_ranges: [k1 = Int32(1)] }\n\n--- idx_t_k2_partial_columns is utilized.\nEXPLAIN SELECT v1 FROM t WHERE k2=1;\n BatchExchange { order: [], dist: Single }\n └─BatchScan { table: idx_t_k2_partial_columns, columns: [v1], scan_ranges: [k2 = Int32(1)] }\n\n--- idx_t_k2_partial_columns is utilized. However since it doesn\\'t include column v2, the plan requires an additional lookup join.\nEXPLAIN SELECT v2 FROM t WHERE k2=1;\n BatchLookupJoin { type: Inner, predicate: idx_t_k2_partial_columns.k1 IS NOT DISTINCT FROM t.k1 AND idx_t_k2_partial_columns.k2 IS NOT DISTINCT FROM t.k2 AND (t.k2 = 1:Int32), lookup table: t }\n └─BatchExchange { order: [], dist: Single }\n   └─BatchScan { table: idx_t_k2_partial_columns, columns: [k2, k1], scan_ranges: [k2 = Int32(1)] }\n\n--- idx_t_k2_all_columns includes all columns.\nCREATE INDEX idx_t_k2_all_columns ON t(k2);\n\n--- idx_t_k2_all_columns is utilized. Compare the plan with the one that uses idx_t_k2_partial_columns.\nEXPLAIN SELECT v2 FROM t WHERE k2=1;\n BatchExchange { order: [], dist: Single }\n └─BatchScan { table: idx_t_k2_all_columns, columns: [v2], scan_ranges: [k2 = Int32(1)] }\n```\n\n----------------------------------------\n\nTITLE: Creating Table from Kafka with Partial Schema and Generated Column (SQL)\nDESCRIPTION: Illustrates creating a RisingWave table (`t2`) by defining a partial schema (`bar INT`) explicitly, rather than using `*`. It also includes a generated column (`gen_col`) based on the defined column. The table connects to a Kafka topic ('test-rw-sink-upsert-avro') using the UPSERT AVRO format and specifies connector properties and the schema registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Specify partial schema\nCREATE TABLE t2 (bar INT, gen_col INT AS bar + 1)\nWITH (\n  connector = 'kafka',\n  topic = 'test-rw-sink-upsert-avro',\n  properties.bootstrap.server = 'message_queue:29092'\n)\nFORMAT upsert ENCODE AVRO (\n  schema.registry = 'http://message_queue:8081'\n);\n```\n\n----------------------------------------\n\nTITLE: Defining the Syntax for CREATE SOURCE in RisingWave SQL\nDESCRIPTION: Provides the general syntax structure for the `CREATE SOURCE` command in RisingWave. This template defines how to specify source name, column definitions (including optional generated columns), watermark clauses, the INCLUDE clause for metadata fields, connector configurations within the WITH clause, and data format/encoding options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name (\n    col_name data_type [ AS generation_expression ],\n    ...\n   [ watermark_clause ]\n)\n[INCLUDE { header | key | offset | partition | timestamp } [AS <column_name>]]\n[ WITH (\n    connector='connector_name',\n    connector_parameter='value', ...)]\n[FORMAT data_format ENCODE data_encode [ (\n    message='message',\n    schema.location='location', ...) ]\n];\n```\n\n----------------------------------------\n\nTITLE: Using bit_and function in SQL\nDESCRIPTION: Returns the bitwise AND of all non-null input values or null if no non-null values are provided. Works with integer data types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nbit_and ( smallint | int | bigint ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized Views with SQL\nDESCRIPTION: This snippet demonstrates the canonical syntax for creating a materialized view in SQL, leveraging the CREATE MATERIALIZED VIEW statement. It requires a valid SELECT query and an optional IF NOT EXISTS clause to prevent errors if the named view already exists. The mv_name specifies the view's name, and select_query defines the data content, with historical data being backfilled during creation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-mv.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW [IF NOT EXISTS] mv_name AS select_query;\n```\n\n----------------------------------------\n\nTITLE: Creating Fraud Detection Logic with Tumbling Windows in SQL\nDESCRIPTION: This snippet creates a materialized view that identifies suspicious credit card transactions by using tumbling windows to detect high frequency usage and large total amounts within short time periods.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW suspicious_transactions AS\n  SELECT\n    card_number,\n    COUNT(*) AS transaction_count,\n    SUM(purchase_amount) AS total_spent\n  FROM TUMBLE(transactions, purchase_time, INTERVAL '5 MINUTES')\n  GROUP BY card_number, window_end\n  HAVING COUNT(*) > 5 AND SUM(purchase_amount) > 5000;\n```\n\n----------------------------------------\n\nTITLE: Creating Source Connector from S3 Using SQL\nDESCRIPTION: Defines the general SQL DDL syntax for creating a RisingWave source connector to an S3 bucket. It supports various schema definitions, optional inclusion of metadata columns, connector parameters, and specific format and encoding details (including CSV delimiters and headers). Dependencies include access to RisingWave, SQL privileges, and AWS S3 credentials. Expected inputs are S3 connection info and format/encode details; output is a registered source object in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name\\nschema_definition\\n[INCLUDE { file | offset | payload } [AS <column_name>]]\\nWITH (\\n   connector='s3',\\n   connector_parameter='value', ...\\n)\\nFORMAT data_format ENCODE data_encode (\\n   without_header = 'true' | 'false',\\n   delimiter = 'delimiter'\\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Streaming Ingestion from Kafka\nDESCRIPTION: This SQL statement creates a materialized view that continuously ingests data from the previously defined Kafka source. It demonstrates how to set up streaming ingestion jobs in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv AS\nSELECT *\nFROM kafka_source;\n```\n\n----------------------------------------\n\nTITLE: Syntax for the COMMIT Command in SQL\nDESCRIPTION: Defines the syntax for the `COMMIT` command in SQL, used to commit the current read-only transaction in RisingWave. This command finalizes the operations performed within the transaction block initiated by `BEGIN READ ONLY` or `START TRANSACTION READ ONLY`. It takes no parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-commit.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCOMMIT;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Additional Column in RisingWave - SQL\nDESCRIPTION: This statement creates a new materialized view (cust_sales_new) that extends the original by adding a new column (sales_count), counting records per customer. Requires an orders source and is meant as the replacement view during schema evolution. The input view is read, aggregations (SUM, COUNT) are computed, and a new schema is materialized.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW cust_sales_new AS\n    SELECT\n        customer_id,\n        SUM(total_price) AS sales_amount,\n        COUNT(*) AS sales_count -- The new column\n    FROM orders\n    GROUP BY customer_id;\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave using Python\nDESCRIPTION: Illustrates how to create a materialized view in RisingWave using the `risingwave-py` SDK. The `rw.mv()` method is used to define and create a materialized view named `test_mv`. This view incrementally maintains the results of the provided SQL query, which calculates the average price per product within 10-second tumbling windows based on the 'test' table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmv = rw.mv(name=\"test_mv\",\n           stmt=\"\"\"SELECT window_start, window_end, product, ROUND(avg(price)) as avg_price\n                   FROM tumble(test, ts, interval '10 seconds') \n                   GROUP BY window_start, window_end, product\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with CSV Encoding in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka table in RisingWave using CSV encoding. It specifies CSV-specific options like 'without_header' and 'delimiter', along with Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE s0 (v1 int, v2 varchar)\nWITH (\n   connector = 'kafka',\n   topic = 'kafka_csv_topic',\n   properties.bootstrap.server = '127.0.0.1:29092',\n   scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE CSV (\n   without_header = 'true',\n   delimiter = ','\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Python UDAF for Weighted Average in RisingWave\nDESCRIPTION: Provides an example of the `CREATE AGGREGATE` command using Python. It defines a `weighted_avg` function that calculates the weighted average of two integer columns. The embedded Python code includes the necessary functions: `create_state`, `accumulate`, `retract`, and `finish` to handle the aggregation logic, including state initialization, value accumulation, value retraction (for materialized views), and final result computation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-aggregate.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n-- Python UDAF\nCREATE AGGREGATE weighted_avg(value int, weight int) RETURNS float LANGUAGE python AS $$\ndef create_state():\n    return (0, 0)\n\ndef accumulate(state, value, weight):\n    if value is None or weight is None:\n        return state\n    (s, w) = state\n    s += value * weight\n    w += weight\n    return (s, w)\n\ndef retract(state, value, weight):\n    if value is None or weight is None:\n        return state\n    (s, w) = state\n    s -= value * weight\n    w -= weight\n    return (s, w)\n\ndef finish(state):\n    (sum, weight) = state\n    if weight == 0:\n        return None\n    else:\n        return sum / weight\n$$;\n```\n\n----------------------------------------\n\nTITLE: Granting View Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet illustrates granting privileges (such as SELECT, INSERT, DELETE, UPDATE, or ALL) on views to a user, either on specific views or on all views within schema(s). Required: view and schema names, target user, and privilege specification. The result grants appropriate rights on the selected views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT {SELECT | INSERT | DELETE | UPDATE | ALL [PRIVILEGES]}\nON {VIEW view_name [, ...]\n    | ALL VIEWS IN SCHEMA schema_name [, ...] }\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Ensuring Read-After-Write Consistency with FLUSH in RisingWave SQL\nDESCRIPTION: This SQL example demonstrates the use of `FLUSH` to ensure data consistency. It first creates a table and inserts a row. `FLUSH` is called to persist this change. Then, a materialized view is created based on the table. Another `FLUSH` ensures the view creation and population process completes before the final `SELECT` query, guaranteeing the query results reflect the inserted data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-flush.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE users (id INT, name VARCHAR(50));\n\nINSERT INTO users VALUES (1, 'Alice');\n\nFLUSH;\n\nCREATE MATERIALIZED VIEW user_count AS\n  SELECT COUNT(*) AS total_users FROM users;\n\nFLUSH;\n\nSELECT * FROM user_count;\n```\n```\n\n----------------------------------------\n\nTITLE: Using array_length Function in SQL (Single Parameter)\nDESCRIPTION: Returns the length of the array (number of elements). This variant takes just the array as a parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\narray_length ( array ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_length(array[1,2,3,4,1]) → 5\n```\n\n----------------------------------------\n\nTITLE: Creating Sink using Kafka Connection in SQL\nDESCRIPTION: Example SQL command demonstrating the creation of a Kafka sink `sink_kafka` from a source table `data_table`. It uses the previously defined `conn_kafka` connection, specifies the target Kafka topic, and sets the data format to JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_kafka from data_table WITH (\n  connector = 'kafka',\n  connection = conn_kafka,\n  topic = 'connection_ddl_1'\n) FORMAT PLAIN ENCODE JSON (\n  force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Azblob Source Syntax in RisingWave SQL\nDESCRIPTION: Provides the general SQL syntax for creating a data source (`CREATE SOURCE`) in RisingWave using the `azblob` connector to ingest data from Azure Blob Storage. It outlines the required clauses like schema definition, `WITH` options for connector parameters, and `FORMAT`/`ENCODE` for data handling, including optional inclusion of metadata columns like file, offset, or payload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name\nschema_definition\n[INCLUDE { file | offset | payload } [AS <column_name>]]\nWITH (\n   connector = 'azblob',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   without_header = 'true' | 'false',\n   delimiter = 'delimiter'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table for IoT Sensor Data Ingestion with MQTT in RisingWave (SQL)\nDESCRIPTION: This SQL snippet creates a table named 'iot_sensor_data' in RisingWave, defining columns for device identifier, timestamp, temperature, humidity, and device status. The table is set to ingest data from an MQTT broker using the specified connector settings, including local TCP URL, topic name 'iot_data', and quality of service set to 'at_least_once'. The incoming data is expected to be in JSON encoding. Dependencies: an operational MQTT server with topic 'iot_data', proper permissions, and a running RisingWave environment. On successful setup, new MQTT messages are stored as rows in the table, ready for querying or transformation. Additional columns or connection configurations can be added as needed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mqtt.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE iot_sensor_data(\\n  device_id VARCHAR,\\n  ts TIMESTAMP,\\n  temperature DECIMAL,\\n  humidity DECIMAL,\\n  device_status VARCHAR\\n\\n)\\nWITH (\\n   connector='mqtt',\\n   url='tcp://localhost',\\n   topic= 'iot_data',\\n   qos = 'at_least_once',\\n  ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Table in RisingWave SQL - SQL\nDESCRIPTION: This SQL snippet demonstrates the creation of a 'sales_data' table with 'product_id' and 'sales_amount' integer columns and inserts sample records. The snippet is compatible with PostgreSQL syntax and intended for execution in RisingWave or similar systems. Inputs are explicit row values, and output is a populated table ready for further querying; ensure RisingWave or a PostgreSQL-compatible database is running to use this.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE sales_data (\\n    product_id INT,\\n    sales_amount INT\\n);\\n\\nINSERT INTO sales_data (product_id, sales_amount)\\nVALUES\\n    (1, 100),\\n    (1, 75),\\n    (2, 150),\\n    (2, 125),\\n    (3, 200);\n```\n\n----------------------------------------\n\nTITLE: Creating a MongoDB CDC Table with Commit Timestamp in RisingWave SQL\nDESCRIPTION: Defines a SQL table in RisingWave with 'mongodb-cdc' as source connector, including the commit timestamp metadata using the 'INCLUDE' clause. Demonstrates specifying MongoDB connection parameters for local ingestion, collection wildcards, and querying the streamed data. Dependencies: RisingWave running with JDK 11+, accessible MongoDB replica set. Input parameters cover connector details, output is a streaming table with commit times from upstream CDC events; historical records use the default epoch.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mongodb-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test (_id JSONB PRIMARY KEY, payload JSONB)\nINCLUDE timestamp AS commit_ts\nWITH (\n  connector = 'mongodb-cdc',\n  mongodb.url = 'mongodb://localhost:27017/?replicaSet=rs0',\n  collection.name = 'test.*'\n);\n\nSELECT * FROM test;\n\n----RESULT\n                 _id                  |                                      payload                                      |         commit_ts\n--------------------------------------+-----------------------------------------------------------------------------------+---------------------------\n {\"$oid\": \"664c48e87d2c84adfabfc03f\"} | {\"_id\": {\"$oid\": \"664c48e87d2c84adfabfc03f\"}, \"data\": \"mydata\", \"name\": \"Ada\"} | 2024-05-21 08:18:25+00:00\n {\"$oid\": \"660125a80f048c7c7eff4a6a\"} | {\"_id\": {\"$oid\": \"660125a80f048c7c7eff4a6a\"}, \"name\": \"Tom\"}                       | 1970-01-01 00:00:00+00:00\n\n```\n\n----------------------------------------\n\nTITLE: Filtering Average Salary with WHERE Clause\nDESCRIPTION: Shows a practical example of using the WHERE clause to filter employee salary data before performing GROUP BY aggregation. Filters for salaries >= $50,000 and computes averages by department and job title.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/where-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- compute the average salary per department per job_title\n-- filtering the result set only to include the departments and job titles with an average salary of at least $50,000\nSELECT department, job_title, AVG(salary)\nFROM employees\nWHERE salary >= 50000\nGROUP BY department, job_title;\n```\n\n----------------------------------------\n\nTITLE: Creating Price Spike Materialized View in SQL\nDESCRIPTION: Creates a materialized view to detect price spikes by analyzing price fluctuations within a 5-minute window, flagging changes exceeding 5%.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-trade-surveillance.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW price_spike AS\nSELECT\n    asset_id,\n    ROUND((MAX(price) - MIN(price)) / MIN(price) * 100, 2) AS price_change_pct,\n    CASE \n        WHEN ROUND((MAX(price) - MIN(price)) / MIN(price) * 100, 2) > 5 THEN TRUE\n        ELSE FALSE\n    END AS price_spike,\n    window_start AS timestamp\nFROM\n    TUMBLE(market_data, timestamp, INTERVAL '5 MINUTES')\nGROUP BY\n    asset_id,\n    window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Spoofing Detection Materialized View in SQL\nDESCRIPTION: Creates a materialized view to detect potential spoofing activity by analyzing bid-ask price differences and trading volume over a 10-minute window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-trade-surveillance.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW spoofing_detection AS\nSELECT\n    asset_id,\n    window_start AS timestamp,\n    CASE\n    WHEN ABS(AVG(bid_price) - AVG(ask_price)) < 0.2 AND \n        SUM(rolling_volume) < AVG(SUM(rolling_volume)) OVER (PARTITION BY asset_id) * 0.8\n        THEN TRUE\n        ELSE FALSE\n    END AS potential_spoofing\nFROM TUMBLE(market_data, timestamp, INTERVAL '10 MINUTES')\nGROUP BY\n    asset_id,\n    window_start;\n```\n\n----------------------------------------\n\nTITLE: Defining CREATE SOURCE Syntax in SQL for RisingWave\nDESCRIPTION: This snippet outlines the syntax for the CREATE SOURCE command in RisingWave. It includes options for specifying column definitions, primary keys, connector properties, and data format settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/connect-with-create-source.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE [IF NOT EXISTS] source_name (\n    column_name data_type [AS source_column_name] [NOT NULL],\n    ...\n    [, PRIMARY KEY (column_name, ...)]\n)\nWITH (\n    connector='connector_name',\n    connector_property='value',\n    ...\n)\nFORMAT format_type ENCODE encode_type (\n    ... -- Format-specific options\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Syntax for CREATE AGGREGATE in RisingWave SQL\nDESCRIPTION: Explains the SQL syntax used to define a new user-defined aggregate function (UDAF) in RisingWave. It outlines the required clauses like function name, argument types, return type, implementation language (Python/JS), and the function body containing the UDAF logic. The optional `IF NOT EXISTS` clause prevents errors if the function already exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-aggregate.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE AGGREGATE [IF NOT EXISTS] function_name ( argument_type [, ...] )\n    RETURNS return_type\n    LANGUAGE language_name\n    AS $$ function_body $$;\n```\n\n----------------------------------------\n\nTITLE: Sample Output of SHOW CREATE VIEW Command in SQL\nDESCRIPTION: Shows the expected output format when using the SHOW CREATE VIEW command. The output includes the fully qualified name of the view (with schema) and the complete CREATE VIEW statement used to define it.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-view.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n   Name    |                 Create Sql\n-----------+---------------------------------------------\n public.v1 | CREATE VIEW v1 AS SELECT id FROM taxi_trips\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating a Schema with IF NOT EXISTS in SQL\nDESCRIPTION: Provides an example command for creating a schema only if it does not already exist, using the IF NOT EXISTS clause to prevent errors on name conflicts. This example does not specify a database or owner and will create 'schema_1' in the default database (dev) unless it exists. No parameters are required beyond the schema name. The output will be a new schema with the provided name, or a no-op if it already exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-schema.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SCHEMA IF NOT EXISTS schema_1;\n```\n\n----------------------------------------\n\nTITLE: Creating Basic RisingWave MySQL CDC Source (SQL)\nDESCRIPTION: This SQL command creates a shared MySQL CDC source named `mysql_mydb` in RisingWave. It uses the `mysql-cdc` connector and specifies the essential connection parameters required to connect to the upstream MySQL database: `hostname`, `port`, `username`, `password`, `database.name`, and a unique `server.id`. This source can then be reused to create multiple tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mysql_mydb WITH (\n  connector = 'mysql-cdc',\n  hostname = '127.0.0.1',\n  port = '8306',\n  username = 'root',\n  password = '123456',\n  database.name = 'mydb',\n  server.id = 5888\n);\n```\n\n----------------------------------------\n\nTITLE: Defining a New User - RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a new user in RisingWave. Options include system permissions such as SUPERUSER, CREATEDB, CREATEUSER, and password settings. No external dependencies are required beyond access to RisingWave with appropriate privileges. Input parameters are the username, permission flags, and an optional password. The output is the creation of a new user account; omitting PASSWORD disables password authentication. Some options have default values as noted in the documentation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER user_name [ [ WITH ] system_permission [ ... ][\\'PASSWORD\\' { password | NULL }] ];\n```\n\n----------------------------------------\n\nTITLE: Tumble Window Aggregation Query in RisingWave SQL\nDESCRIPTION: Performs aggregation over tumbling windows on taxi_trips, grouping by the window intervals and calculating both the count of trips and the sum of distances. The result returns one row per window with summary statistics, and demonstrates pattern for windowed aggregation queries. Relies on window_start and window_end columns added by the TUMBLE function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT window_start, window_end, count(trip_id) AS no_of_trips, sum(distance) AS total_distance\\nFROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES')\\nGROUP BY window_start, window_end\\nORDER BY window_start;\n```\n\n----------------------------------------\n\nTITLE: Defining a Kinesis Source or Table in RisingWave SQL\nDESCRIPTION: This SQL syntax defines how to create either a SOURCE or a TABLE in RisingWave that connects to an AWS Kinesis stream. It includes placeholders for the source/table name, optional schema definition, metadata inclusion (`INCLUDE`), connector-specific parameters within the `WITH` clause (like 'kinesis', stream name, AWS credentials), and data format/encoding specifications (`FORMAT`, `ENCODE`). Use `CREATE TABLE` to persist data and enforce primary keys, or `CREATE SOURCE` for non-persistent streams.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [ IF NOT EXISTS ] source_name\n[ schema_definition ]\n[INCLUDE { header | key | offset | partition | timestamp | payload } [AS <column_name>]]\nWITH (\n   connector='kinesis',\n   connector_parameter='value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   message = 'message',\n   schema.location = 'location'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Source with Watermark (Direct Timestamp Column) - RisingWave SQL\nDESCRIPTION: This complete SQL snippet creates a source in RisingWave with a watermark defined as the 'order_time' column minus 5 seconds. It assumes Kafka as the data source and JSON encoding. The source schema, connector configuration, and watermark definition are included; relevant dependencies include Kafka connectivity and correct type assignments for all columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/watermarks.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1 (\n    product VARCHAR,\n    user VARCHAR,\n    price DOUBLE PRECISION\n    order_time TIMESTAMP,\n    WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND\n) WITH (\n    connector = 'kafka',\n    topic = 'test_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Modifying JSONB Values\nDESCRIPTION: Modifies JSONB data by replacing or inserting values at specified paths. Optional parameter controls whether missing paths should be created.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\njsonb_set('[{\"f1\":1,\"f2\":null},2]', '{0,f3}', '[2,3,4]')\n```\n\n----------------------------------------\n\nTITLE: Querying Taxi Trip Data with Joins and Multiple Clauses in SQL\nDESCRIPTION: This SQL query joins the taxi_trips, taxi, and company tables to calculate total distance and duration of trips for specific taxi companies. It uses LEFT JOIN, subquery in WHERE clause, GROUP BY, and ORDER BY.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    taxi.taxi_id,\n    sum(trips.distance) AS total_distance,\n    sum(trips.duration) AS total_duration\nFROM taxi_trips AS trips\nLEFT JOIN taxi ON trips.id = taxi.trip_id\nWHERE taxi_id IN (\n          SELECT taxi_id\n          FROM company\n          WHERE company_id IN ('Yellow Taxi', 'FabCab')\n      )\n      AND trips.fare > 2.50\nGROUP BY taxi_id\nORDER BY total_distance, total_duration;\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Pulsar Table with JSON Format Including Raw Payload (SQL)\nDESCRIPTION: This SQL statement creates a RisingWave table 'table_include_payload' to ingest JSON data from a Pulsar topic 'pulsar_1_partition_topic'. It defines some specific columns ('v1', 'v2') but also includes the entire raw JSON message using the `INCLUDE payload` clause, which is useful when the exact schema is unknown beforehand. It specifies the Pulsar connector, topic, bootstrap server, and scan startup mode, using the PLAIN ENCODE JSON format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'pulsar',\n    topic = 'pulsar_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with SQL Window Functions using Emit-on-Window-Close in SQL\nDESCRIPTION: This SQL snippet creates a materialized view `mv2` that utilizes SQL window functions (`LEAD`) partitioned by `bar` and ordered by `tm` on table `t`. Applying `EMIT ON WINDOW CLOSE` suggests that the window function calculations will be performed and results emitted based on the watermark progression, ensuring final results are emitted when the relevant time window (implicitly defined by the watermark) closes. This can offer performance benefits for complex window function computations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv2 AS\nSELECT\n    tm, foo, bar,\n    LEAD(foo, 1) OVER (PARTITION BY bar ORDER BY tm) AS l1,\n    LEAD(foo, 3) OVER (PARTITION BY bar ORDER BY tm) AS l2\nFROM t\nEMIT ON WINDOW CLOSE;\n```\n\n----------------------------------------\n\nTITLE: String Replacement with regexp_replace in SQL\nDESCRIPTION: Replaces matched substrings using POSIX regex patterns with support for back references and various matching flags.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nregexp_replace( input_string, pattern, replacement_string [, start_integer [, N_integer ] ] [, flags ] ) → output_string\n```\n\nLANGUAGE: sql\nCODE:\n```\nregexp_replace('foobarbaz', 'b(..)', 'X\\1Y', 'g') → fooXarYXazY\n\nregexp_replace('HELLO world', '[aeiou]', 'X', 'ig') → HXLLX wXrld\n\nregexp_replace('RisingWave', '[aeiou]', 'X', 1, 3, 'i') → RisingWXve\n```\n\n----------------------------------------\n\nTITLE: Defining Python UDFs and Server Setup\nDESCRIPTION: Example Python code demonstrating how to define scalar and table functions using arrow-udf decorators and set up a UDF server. Includes functions for GCD calculation, blocking operations, key-value parsing, number series generation, and text embedding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom arrow_udf import udf, udtf, UdfServer\n\n# Define a scalar function that returns a single value\n@udf(input_types=[\"INT\", \"INT\"], result_type=\"INT\")\ndef gcd(x: int, y: int) -> int:\n    while y != 0:\n        (x, y) = (y, x % y)\n    return x\n\n# Define a scalar function to perform some blocking operation, setting the `io_threads` parameter to run multiple function calls concurrently in a thread pool\n@udf(input_types=[\"INT\"], result_type=\"INT\", io_threads=32)\ndef blocking(x):\n    time.sleep(0.01)\n    return x\n\n# Define a scalar function that returns multiple values within a struct\n@udf(input_types=['VARCHAR'], result_type='STRUCT<key: VARCHAR, value: VARCHAR>')\ndef key_value(pair: str):\n    key, value = pair.split('=')\n    return {'key': key, 'value': value}\n\n# Define a table function over a Python generator function\n@udtf(input_types='INT', result_types='INT')\ndef series(n):\n    for i in range(n):\n        yield i\n\n# Define a function that accepts batch input and returns a batch output\n@udf(input_types=[\"VARCHAR\"], result_type=\"REAL[]\", batch=True)\ndef text_embedding(texts: List[str]) -> List[List[float]]:\n    from openai import OpenAI\n    client = OpenAI(\"<your-api-key>\")\n\n    embeddings = [\n        e.embedding\n        for e in client.embeddings.create(\n            model=\"text-embedding-ada-002\",\n            input=texts,\n            encoding_format=\"float\",\n        ).data\n    ]\n    return embeddings\n\nif __name__ == '__main__':\n    # Create a UDF server and register the functions\n    server = UdfServer(location=\"0.0.0.0:8815\") # You can use any available port in your system. Here we use port 8815.\n    server.add_function(gcd)\n    server.add_function(blocking)\n    server.add_function(key_value)\n    server.add_function(series)\n    server.add_function(text_embedding)\n    # Start the UDF server\n    server.serve()\n```\n\n----------------------------------------\n\nTITLE: Creating CDC Table and Materialized View in RisingWave - SQL\nDESCRIPTION: This snippet, to be executed in RisingWave, first creates a 'pg_person' table configured to synchronize data from the 'person' table in PostgreSQL using the 'postgres-cdc' connector. It details CDC connection options such as hostname, port, credentials, slot, and target table. A materialized view 'city_population' is then created to compute the population per city by grouping over the replicated data. Prerequisites: RisingWave instance with CDC capabilities and network access to PostgreSQL source. Inputs: CDC connection properties; Outputs: a replicated table and an analytical view. Key constraint: Assumes CDC setup (slot, permissions) are correctly provisioned.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/risingwave-as-postgres-fdw.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n---Run in RisingWave\\n---Create a table in RisingWave to replicate the Person table of PostgreSQL into RisingWave\\nCREATE TABLE pg_person (\\n    \"id\" int,\\n    \"name\" varchar,\\n    \"credit_card\" varchar,\\n    \"city\" varchar,\\n    PRIMARY KEY (\"id\")\\n) with (\\n    connector = 'postgres-cdc',\\n    hostname = 'localhost',\\n    port = '5432',\\n    username = 'postgresuser',\\n    password = 'postgrespw',\\n    database.name = 'mydb',\\n    schema.name = 'public',\\n    table.name = 'person',\\n    slot.name = 'person'\\n);\\n\\n---Create a materialized view to analyze the population of each city\\nCREATE MATERIALIZED VIEW city_population AS\\nSELECT\\n    city,\\n    COUNT(*) as population\\nFROM\\n    pg_person\\nGROUP BY\\n    city;\n```\n\n----------------------------------------\n\nTITLE: Setting Up Cross-Database Streaming with Subscription and Materialized View - SQL\nDESCRIPTION: Outlines the required steps to enable streaming between databases in RisingWave using subscriptions and Materialized Views (MVs). The process requires first ensuring the source table has a primary key, creating a subscription for changelog availability, then creating MVs in another database that reference the subscribed table (including via joins). Prerequisites are access to both source and target databases and appropriate privileges. Inputs include table and subscription definitions; output is the creation of cross-database streaming MVs. Constraints include the need for existing primary keys and enforced dependency safeguards.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- Connect to d1\\n\\c d1;\\nCREATE TABLE t1 (v1 INT PRIMARY KEY); -- Ensure PK exists\\n\\n-- Create the subscription to enable cross-database access to t1's changelog\\nCREATE subscription sub_t1 FROM t1 WITH (retention = '1D');\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Connect to d2\\n\\c d2;\\nCREATE TABLE t2 (v2 INT);\\n\\n-- Create an MV reading only from the remote table\\nCREATE MATERIALIZED VIEW mv1 AS SELECT * FROM d1.public.t1; -- Reads via sub_t1\\n\\n-- Create an MV joining the remote table t1 with local table t2\\nCREATE MATERIALIZED VIEW mv2 AS\\nSELECT t1.v1, t2.v2\\nFROM d1.public.t1 -- Reads via sub_t1\\nJOIN t2 ON t1.v1 = t2.v2;\n```\n\n----------------------------------------\n\nTITLE: Using @> Containment Operator in SQL\nDESCRIPTION: Checks if the left array contains all elements of the right array. Returns true if all elements in the right array appear in the left array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\narray[1,2,3] @> array[2,3] → t\n```\n\n----------------------------------------\n\nTITLE: Commenting Objects in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for attaching comments as metadata to a specified object type (TABLE or COLUMN) in RisingWave. Users substitute the placeholders <object_type>, <relation_name>, <object_name>, and <comment> with actual values to target the correct database object and add the intended annotation. The statement is essential for documenting schemas and helps improve maintainability. The code takes descriptive text as input and stores it in the system catalog for later retrieval.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCOMMENT ON <object_type> <relation_name>.<object_name> IS <comment>\n```\n\n----------------------------------------\n\nTITLE: Example of Creating a Pulsar Sink in RisingWave\nDESCRIPTION: A complete example showing how to create a sink that sends data from RisingWave to Apache Pulsar, including OAuth authentication and AWS credentials for OAuth file access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-pulsar.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK IF NOT EXISTS pulsar_sink\nFROM mv_name\nWITH (\n  connector = 'pulsar',\n  topic = 'test-topic',\n  service.url = 'pulsar://broker:6650',\n\n  -- OAuth\n  oauth.issuer.url = 'https://issuer.com',\n  oauth.credentials.url = 'https://provider.com',\n  oauth.audience = 'test-aud',\n  oauth.scope = 'consume',\n\n  -- S3 credential for oauth file\n  aws.credentials.access_key_id = 'xxx',\n  aws.credentials.secret_access_key = 'xxx'\n)\nFORMAT DEBEZIUM ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Adding RisingWave Helm Chart Repository\nDESCRIPTION: Command to add the RisingWave Helm chart repository to your local Helm configuration. The --force-update flag ensures that the repository is updated even if it already exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add risingwavelabs https://risingwavelabs.github.io/helm-charts/ --force-update\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with SSL Encryption\nDESCRIPTION: SQL command to create a table with SSL encryption enabled without SASL authentication. Includes configuration for SSL certificates and keys.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS table_1 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.security.protocol='SSL',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining a Sink with Kafka Connector in dbt Using SQL\nDESCRIPTION: This snippet defines a sink in RisingWave via dbt, outputting average distance and duration metrics from the 'taxi_trips' table to a Kafka topic. It uses dbt's config for sink materialization and specifies Kafka connection parameters, as well as JSON encoding. Prerequisites include a running Kafka server on localhost:9092 and an existing 'taxi_trips' source. The snippet assumes aggregation columns (distance, duration) and outputs to the specified topic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n```sql Define a sink in dbt\n{{ config(materialized='sink') }}\nCREATE SINK {{ this }} AS\nSELECT\n   avg(distance) as avg_distance,\n   avg(duration) as avg_duration\nFROM taxi_trips\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating a Table from a SQL Server CDC Source in RisingWave (SQL)\nDESCRIPTION: This SQL syntax defines how to create a table in RisingWave that consumes CDC data from a previously defined `sqlserver-cdc` source. It requires defining the table schema, including a primary key that must match the upstream SQL Server table. The `FROM source TABLE sqlserver_table_name` clause links the RisingWave table to a specific SQL Server table (format: `database_name.schema_name.table_name`). Optional parameters like `snapshot`, `snapshot.interval`, and `snapshot.batch_size` control the initial data loading behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n   column_name data_type PRIMARY KEY , ...\n   PRIMARY KEY ( column_name, ... )\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n    snapshot='true'\n)\nFROM source TABLE sqlserver_table_name;\n```\n\n----------------------------------------\n\nTITLE: Listing Database Objects with Psql Commands in RisingWave\nDESCRIPTION: Core psql commands for interacting with RisingWave database. These commands allow users to list various database objects like relations, indexes, materialized views, tables, and users. Note that source listing is not yet supported.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/psql-commands.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\\d     # List all relations\n\\di    # List all indexes\n\\dm    # List all materialized views\n\\dt    # List all tables\n\\du    # List all users and privileges\n\\q     # Quit psql\n```\n\n----------------------------------------\n\nTITLE: Regular Expression Matching with regexp_match in SQL\nDESCRIPTION: Function that returns an array of captured substrings from the first match of a POSIX regex pattern. Supports case-sensitive and case-insensitive matching with flags 'i' and 'c'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nregexp_match( input_string, pattern [, optional_flag ] ) → matched_string[]\n```\n\nLANGUAGE: sql\nCODE:\n```\nregexp_match('foobarbequebaz', '(bar)(beque)') → {bar,beque}\nregexp_match('abc', 'd') → NULL\nregexp_match('abc', 'Bc', 'ici') → {bc}\n```\n\n----------------------------------------\n\nTITLE: Defining TTL on an Append-Only Table in RisingWave SQL\nDESCRIPTION: Shows how to configure Time-To-Live (TTL) for an append-only table (`t`) in RisingWave. The `APPEND ONLY` clause is required, and the `WITH` clause includes the `retention_seconds` parameter (set to 86400 seconds, or 1 day in this example) to specify the duration after which data automatically expires and is cleaned up from the table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n    ...\n) APPEND ONLY WITH (retention_seconds = 86400);\n```\n\n----------------------------------------\n\nTITLE: Creating Table from S3 Source in RisingWave with CSV Encoding (SQL)\nDESCRIPTION: Shows an example SQL statement creating a table in RisingWave backed by an S3 source containing CSV files. All required connection parameters are set, and format/encode options customize header handling and delimiters. Assumes provided AWS credentials and S3 bucket. Produces a table whose data is materialized from the S3 bucket contents.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s(\\n    id int,\\n    name varchar,\\n    age int\\n)\\nWITH (\\n    connector = 's3',\\n    s3.region_name = 'ap-southeast-2',\\n    s3.bucket_name = 'example-s3-source',\\n    s3.credentials.access = 'xxxxx',\\n    s3.credentials.secret = 'xxxxx'\\n) FORMAT PLAIN ENCODE CSV (\\n    without_header = 'true',\\n    delimiter = ',' -- set delimiter = E'\\t' for tab-separated files\\n);\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Source from MSK Topic\nDESCRIPTION: This SQL query creates a table in RisingWave that consumes data from an MSK topic connected to Kafka. It specifies the Kafka connector, topic, broker URL, and authentication details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s (v1 int, v2 varchar)\nWITH (\n  connector = 'kafka', topic = '<topic-name>',\n  properties.bootstrap.server = '<broker-url>',\n  scan.startup.mode = 'earliest',\n  properties.sasl.mechanism = 'AWS_MSK_IAM',\n  properties.security.protocol = 'sasl_ssl',\n  properties.sasl.username = '<your-username>',\n  properties.sasl.password = '<your-password>'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Retrieving and Updating Subscription Progress in Python\nDESCRIPTION: These Python functions interact with the 'subscription_progress' table to retrieve the last progress for a given subscription and update the progress. They use SQL queries to fetch and insert data into the table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef get_last_progress(conn, sub_name):\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT progress FROM subscription_progress WHERE sub_name = %s\", (sub_name,))\n        result = cur.fetchone()\n        return result[0] if result else None\n\ndef update_progress(conn, sub_name, progress):\n    with conn.cursor() as cur:\n        cur.execute(\"INSERT INTO subscription_progress (sub_name, progress)\", (sub_name, progress, progress))\n        cur.execute(\"FLUSH\")\n        conn.commit()\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Source Table from a Solace MQTT Topic in SQL\nDESCRIPTION: This SQL statement creates a source table named `combined_passenger_flight_data` in RisingWave. It defines the schema for passenger and flight data and configures the connection to a Solace MQTT broker using the 'mqtt' connector. It specifies the topic 'passenger_full_details', connection URL, credentials, QoS level ('at_least_once'), and expects the data format to be plain JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/solace.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE combined_passenger_flight_data (\n    flight_id VARCHAR,\n    flight_number VARCHAR,\n    carrier_code VARCHAR,\n    flight_date DATE,\n    origin VARCHAR,\n    passenger_ref_number VARCHAR,\n    departure_time TIMESTAMPTZ,\n    opted_in BOOLEAN,\n    contact_info VARCHAR\n)\nWITH (\n    connector = 'mqtt',\n    topic = 'passenger_full_details',\n    url = 'ssl://xxxxxxxxxx:8883',\n    username='solace-cloud-client',\n    password='xxxxxxxxxxxx', \n    qos = 'at_least_once'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Recent Sales Materialized View in SQL\nDESCRIPTION: Creates a materialized view to aggregate recent sales data within the past week, calculating total quantity sold for each product in each warehouse.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW recent_sales AS\nSELECT\n    warehouse_id,\n    product_id,\n    SUM(quantity_sold) AS total_quantity_sold,\n    MAX(timestamp) AS last_sale\nFROM\n    sales\nWHERE\n    timestamp > NOW() - INTERVAL '7 days'\nGROUP BY\n    warehouse_id, product_id;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Per-Room Viewer Count\nDESCRIPTION: SQL statement to create a materialized view that tracks unique viewers for each streaming room per minute.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW room_user_visit_1min AS\nSELECT\n    window_start AS report_ts,\n    COUNT(DISTINCT user_id) AS uv,\n    room_id\nFROM\n    TUMBLE(\n        live_stream_metrics,\n        report_timestamp,\n        INTERVAL '1' MINUTE\n    )\nGROUP BY\n    window_start,\n    room_id;\n```\n\n----------------------------------------\n\nTITLE: Displaying SHOW DATABASES Syntax in RisingWave\nDESCRIPTION: The syntax for the SHOW DATABASES command, which can optionally include a LIKE expression to filter the results based on database names using pattern matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-databases.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW DATABASES [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Inserting Test Data into Kafka Topic\nDESCRIPTION: This bash command starts a Kafka console producer to insert test data into a specified Kafka topic using SASL authentication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nbin/kafka-console-producer.sh --bootstrap-server <broker-url> --topic <topic-name> --producer.config ~/client_sasl.properties\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter for SQL SELECT Documentation\nDESCRIPTION: This YAML snippet defines the metadata for a documentation page. It sets the page title to 'Query with SELECT statements' and specifies its URL path as '/sql/commands/sql-select'. This metadata is typically used by static site generators or documentation systems to build the navigation and structure of the documentation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/query-with-select.mdx#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"Query with SELECT statements\"\nurl: \"/sql/commands/sql-select\"\n---\n```\n\n----------------------------------------\n\nTITLE: General Syntax for Top-N Queries in RisingWave (SQL)\nDESCRIPTION: Provides the basic SQL structure for a Top-N query in RisingWave. It utilizes a subquery to calculate ranks using a ranking function and an outer query to filter the results based on the calculated rank range.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/top-n-by-group.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT [column_list]\n  FROM (\n    SELECT [column_list],\n      ranking_function_clause AS rank\n    FROM table_name)\nWHERE rank_range;\n```\n\n----------------------------------------\n\nTITLE: Creating and Using an Index on 'c_phone' in SQL\nDESCRIPTION: Shows how to create an index named `idx_c_phone` on the `c_phone` column of the previously created `customers` table using the `CREATE INDEX` command. This index is intended to speed up queries that filter customer records based on their phone number. Example `SELECT` statements demonstrate queries that would benefit from this index, filtering by a specific phone number or a list of phone numbers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX idx_c_phone on customers(c_phone);\n\nSELECT * FROM customers where c_phone = '123456789';\n\nSELECT * FROM customers where c_phone in ('123456789', '987654321');\n```\n\n----------------------------------------\n\nTITLE: Dropping Tables Using SQL DROP TABLE Command - SQL\nDESCRIPTION: Demonstrates the use of the SQL DROP TABLE statement to remove tables from a database. The examples show both basic table deletion and conditional deletion with IF EXISTS and schema qualification. The CASCADE option can be used to delete dependent objects, such as materialized views and indexes. Inputs include the table and optionally the schema name, and outputs are the removal of the specified table and, if applicable, its dependencies. Requires database access with sufficient privileges and impacts data irreversibly.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE [ IF EXISTS ] [schema_name.]table_name [ CASCADE ];\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE taxi_trips;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE IF EXISTS rw_schema.taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Creating Sources and Tables with Kafka in RisingWave using SQL\nDESCRIPTION: This SQL snippet provides the syntax for creating either a TABLE or SOURCE in RisingWave with a Kafka connector. It demonstrates how to specify connector options, data format, and schema location (supporting Avro/Protobuf). Required parameters include Kafka topic, broker addresses, and key configuration options like scan mode and group ID. Inputs are table/source names, column definitions, and connector-specific settings; output is a registered source or table ready to ingest data. Limitations involve format-specific constraints (e.g., no schema_definition for Avro/Protobuf sources) and one-source-per-topic mapping.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [ IF NOT EXISTS ] source_name\n[ schema_definition ]\n[INCLUDE { header | key | offset | partition | timestamp | payload } [AS <column_name>]]\nWITH (\n   connector='kafka',\n   connector_parameter='value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   message = 'message',\n   schema.location = 'location' | schema.registry = 'schema_registry_url'\n);\n```\n\n----------------------------------------\n\nTITLE: Basic GROUP BY Syntax in SQL\nDESCRIPTION: Demonstrates the basic syntax of the GROUP BY clause in a SELECT statement. It shows how to group data by one or more columns and apply aggregate functions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column_list\nFROM table_name\nWHERE [ conditions ]\nGROUP BY column1, column2....columnN\nORDER BY column1, column2....columnN\n```\n\n----------------------------------------\n\nTITLE: Querying a Table with Hopping Windows in RisingWave SQL\nDESCRIPTION: Selects rows from the taxi_trips table using the HOP function, assigning each entry to one or more overlapping windows. This example demonstrates usage with a 1-minute hop size and 2-minute window size, and outputs the windowed results via augmented columns. Requires that taxi_trips contains a timestamp in completed_at, and that INTERVAL '1 MINUTE' and INTERVAL '2 MINUTES' are valid.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT trip_id, taxi_id, completed_at, window_start, window_end\\nFROM HOP (taxi_trips, completed_at, INTERVAL '1 MINUTE', INTERVAL '2 MINUTES');\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Metadata Extraction in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka source in RisingWave while extracting metadata fields. It includes the key, partition, offset, and timestamp as separate columns in addition to the main message payload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE kafka_source_with_metadata (\n    user_id INT,\n    product_id VARCHAR\n)\nINCLUDE key AS kafka_key\nINCLUDE partition AS kafka_partition\nINCLUDE offset AS kafka_offset\nINCLUDE timestamp AS kafka_timestamp\nWITH (\n    connector='kafka',\n    topic='user_activity',\n    properties.bootstrap.server='broker1:9092,broker2:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Dynamic HAVING Filter - RisingWave SQL\nDESCRIPTION: This SQL snippet defines a materialized view that selects parts where the aggregated supply cost exceeds 0.01% of the overall sum from the 'partsupp' table. The dynamic HAVING clause uses a scalar subquery to calculate the threshold, enabling continuous evaluation as new data arrives. Requires the 'partsupp' table with columns 'ps_partkey', 'ps_supplycost', and 'ps_availqty'. Output is a live-updated view of part keys and their value, filtered according to the moving threshold.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/dynamic-filters.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv1 AS\nSELECT\n  ps_partkey,\n  sum(ps_supplycost * ps_availqty) AS value\nFROM\n  partsupp\nGROUP BY\n  ps_partkey\nHAVING\n  sum(ps_supplycost * ps_availqty) > (\n    SELECT\n      sum(ps_supplycost * ps_availqty) * 0.0001\n    FROM\n      partsupp\n  )\n```\n\n----------------------------------------\n\nTITLE: Using a Secret in CREATE SOURCE Statement in RisingWave SQL\nDESCRIPTION: This SQL example demonstrates how to first create a secret (`mysql_pwd`) and then reference it within the `WITH` clause of a `CREATE SOURCE` statement. The `password` option is set to `secret mysql_pwd`, securely referencing the stored credential instead of using plain text.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET mysql_pwd WITH (\n  backend = 'meta'\n) AS '123';\n\nCREATE SOURCE mysql_source WITH (\nconnector = 'mysql-cdc',\nhostname = 'localhost',\nport = '8306',\nusername = 'rwcdc',\npassword = secret mysql_pwd,\ndatabase.name = 'test',\nserver.id = '5601'\n);\n\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Table, Subscription, and Cursors in RisingWave via SQL\nDESCRIPTION: This multi-part SQL example shows the process of creating a table, inserting data, creating a subscription, and declaring a subscription cursor to fetch both initial and change data. It includes commands for mutating the table and fetching resulting change records, covering the complete workflow for testing subscriptions and cursors.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table and insert some data.\ncreate table t1(v1 int, v2 int, v3 int);\ninsert into t1 values(1,1,1);\n\n-- Create a subscription.\ncreate subscription sub from t1 with (retention = '1D');\n\n-- Create a subscription cursor.\ndeclare cur subscription cursor for sub full;\n```\n\n----------------------------------------\n\nTITLE: Using a Secret in CREATE SOURCE Command in SQL\nDESCRIPTION: Demonstrates referencing the previously created secret `mysql_pwd` within the `WITH` clause of a `CREATE SOURCE` command in RisingWave. The `password` parameter is assigned using the `secret mysql_pwd` syntax, ensuring the actual password value ('123' in the previous example) is not exposed in the source definition. This requires the `mysql_pwd` secret to exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-secret.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mysql_source WITH (\n connector = 'mysql-cdc',\n hostname = 'localhost',\n port = '8306',\n username = 'rwcdc',\n password = secret mysql_pwd,\n database.name = 'test',\n server.id = '5601'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Foreign Data Wrapper and Querying in PostgreSQL - SQL\nDESCRIPTION: This snippet is executed in PostgreSQL to install and configure the postgres_fdw extension, define a foreign server for RisingWave, set up user mapping, import schema, and query data. It walks through enabling the extension, creating a foreign server, mapping users, importing foreign schema (which brings in the replicated table and materialized view), and verifying their presence. Finally, it demonstrates querying both the replicated table and the analytical view via FDW. Prerequisites: postgres_fdw extension available, RisingWave reachable from PostgreSQL, correct user credentials. Limitations: All write operations are read-only when accessed through FDW.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/risingwave-as-postgres-fdw.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n---Run in PostgreSQL\\n---Enable the postgres_fdw extension\\nCREATE EXTENSION postgres_fdw;\\n\\n---Create a foreign table to connect to RisingWave\\nCREATE SERVER risingwave\\n        FOREIGN DATA WRAPPER postgres_fdw\\n        OPTIONS (host 'localhost', port '4566', dbname 'dev');\\n\\n---Create a user mapping for the foreign server, mapping the RisingWave's user `root` to the PostgreSQL's user `postgresuser`\\nCREATE USER MAPPING FOR postgresuser\\n        SERVER risingwave\\n        OPTIONS (user 'root', password '');\\n\\n---Import the definition of table and materialized view from RisingWave.\\nIMPORT FOREIGN SCHEMA public\\n    FROM SERVER risingwave INTO public;\\n\\n---List the foreign table and materialized view in PostgreSQL.\\nSELECT * FROM pg_foreign_table;\\n---------+----------+-------------------------------------------------\\n ftrelid | ftserver |                    ftoptions\\n---------+----------+-------------------------------------------------\\n   16413 |    16411 | {schema_name=public,table_name=city_population}\\n   16416 |    16411 | {schema_name=public,table_name=pg_person}\\n\\n---Check whether the data is synchronized from PostgreSQL to RisingWave.\\nSELECT * FROM pg_person;\\n------|----------------+---------------------+-------------\\n  id  |      name      |     credit_card     |    city\\n------+----------------+---------------------+-------------\\n 1005 | sarah smith    | 4591 5419 7260 8350 | los angeles\\n 1012 | walter jones   | 8793 6517 3085 0542 | boise\\n 1002 | sarah spencer  | 3453 4987 9481 6270 | los angeles\\n 1007 | walter spencer | 5136 7504 2879 7886 | los angeles\\n 1011 | vicky noris    | 9959 4034 5717 6729 | boise\\n 1016 | john walton    | 0426 2682 6145 8371 | seattle\\n 1010 | kate smith     | 9474 6887 6463 6972 | bend\\n 1015 | vicky jones    | 3148 5012 3225 2870 | los angeles\\n 1017 | luke jones     | 9641 9352 0248 2749 | redmond\\n 1001 | peter white    | 1781 2313 8157 6974 | boise\\n 1004 | julie white    | 0052 8113 1582 4430 | seattle\\n 1008 | john abrams    | 6064 8548 6057 2021 | redmond\\n 1013 | sarah walton   | 2280 4209 8743 0735 | kent\\n\\n---Query the materialized view in RisingWave with PostgreSQL's foreign table.\\nSELECT * FROM city_population;\\n-------------+------------\\n    city     | population\\n-------------+------------\\n boise       |          3\\n los angeles |          4\\n bend        |          1\\n kent        |          1\\n redmond     |          2\\n seattle     |          2\n```\n\n----------------------------------------\n\nTITLE: Creating Aggregated Kafka Sink from Table in SQL\nDESCRIPTION: Example of creating a Kafka sink by selecting and aggregating specific columns from a table, demonstrating how to create a sink from a custom query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink2 AS\nSELECT\n   avg(distance) as avg_distance,\n   avg(duration) as avg_duration\nFROM taxi_trips\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying Inventory Status in SQL\nDESCRIPTION: Retrieves the first 5 rows from the inventory_status materialized view to display current inventory status.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM inventory_status LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW COLUMNS Command in RisingWave SQL\nDESCRIPTION: A practical example showing how to use the SHOW COLUMNS command to list all columns from a table named taxi_trips.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-columns.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Granting RDS Replication Privileges (Bash)\nDESCRIPTION: This bash command executes the `GRANT rds_replication TO <username>;` SQL statement within an AWS RDS or Aurora PostgreSQL instance (implied via `psql`). This grants the necessary AWS-specific replication role (`rds_replication`) to the specified user for CDC operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nGRANT rds_replication TO <username>;\n```\n\n----------------------------------------\n\nTITLE: Creating Unusual Volume Materialized View in SQL\nDESCRIPTION: Creates a materialized view to identify trades with higher than average volume within a 10-minute window, using TUMBLE and PARTITION BY for time-based analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-trade-surveillance.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW unusual_volume AS\nSELECT\n    trade_id,\n    asset_id,\n    volume,\n    CASE WHEN volume > avg_volume * 1.5 THEN TRUE ELSE FALSE END AS unusual_volume,\n    window_start AS timestamp\nFROM (\n    SELECT\n        trade_id,\n        asset_id,\n        volume,\n        AVG(volume) OVER (PARTITION BY asset_id) as avg_volume,\n        window_start\n    FROM TUMBLE(trade_data, timestamp, INTERVAL '10 MINUTES')\n    GROUP BY\n        trade_id,\n        asset_id,\n        volume,\n        window_start\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table using Kafka and Schema Registry Connections in SQL\nDESCRIPTION: Example SQL command showing how to create a table `t` that utilizes previously defined connections. It uses the `conn_kafka` connection for the Kafka connector and the `sr_conn` connection for Avro format encoding, demonstrating the reusability of connections.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t WITH (\n    connector = 'kafka', \n    topic = 'demo-topic', \n    connection = conn_kafka\n) FORMAT PLAIN ENCODE AVRO (connection = sr_conn);\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Table from MySQL CDC Source\nDESCRIPTION: RisingWave SQL syntax for creating a table that consumes data from a previously defined MySQL CDC source. A primary key matching the upstream MySQL table is required. The `FROM source TABLE table_name` clause links this RisingWave table to a specific table within the CDC source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n   column_name data_type PRIMARY KEY , ...\n   PRIMARY KEY ( column_name, ... )\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n   snapshot='true'\n)\nFROM source TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Including Timestamp Metadata from Kafka\nDESCRIPTION: Example of creating a table that includes the Kafka message timestamp as an additional column named 'event_timestamp'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_timestamp(v1 int, v2 varchar)\nINCLUDE timestamp AS event_timestamp\nWITH (\n connector='kafka',\n topic='kafka_1_partition_topic',\n properties.bootstrap.server='localhost:9092',\n scan.startup.mode='earliest'\n) format plain encode json;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for Segment Webhook Data\nDESCRIPTION: Creates a table configured to accept webhook data from Segment, including signature validation using a secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/segment-webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'x-signature',\n  encode(hmac(test_secret, data, 'sha1'), 'hex')\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Up Kafka Source for Fraud Detection in SQL\nDESCRIPTION: This snippet creates a source to ingest credit card transaction data from Kafka into RisingWave. It defines fields for card number, purchase amount, and timestamp for monitoring potentially fraudulent activities.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE transactions (\n  card_number varchar,\n  purchase_amount double precision,\n  purchase_time timestamptz\n) WITH (\n  connector='kafka',\n  topic='credit_card_transactions',\n  properties.bootstrap.server='localhost:9092',\n  scan.startup.mode='earliest',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Basic Generate Series Function Usage\nDESCRIPTION: Demonstrates the basic syntax of generate_series() function to generate sequential numbers or timestamps. The function takes start, stop and optional step parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM generate_series(start, stop, step);\n```\n\n----------------------------------------\n\nTITLE: Creating Publication for Partitioned Table in PostgreSQL\nDESCRIPTION: This SQL command shows how to create a publication in PostgreSQL for a partitioned table, ensuring that events are replicated for the root table rather than individual partitions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE PUBLICATION publication_name FOR table_name WITH (publish_via_partition_root = true);\n```\n\n----------------------------------------\n\nTITLE: Syntax for Moving a Table to a Different Schema using ALTER TABLE in SQL\nDESCRIPTION: Outlines the syntax for relocating a table (`table_name`) to a different schema (`schema_name`) using the `SET SCHEMA` clause. Associated indexes, constraints, and sequences owned by the table's columns are also moved along with the table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE table_name\n    SET SCHEMA schema_name;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Google Pub/Sub Table in SQL\nDESCRIPTION: This SQL example shows how to create a table named 's1' with two columns (v1 as integer and v2 as varchar) that connects to a Google Pub/Sub subscription named 'test-subscription-1'. The data format is set to PLAIN and encoded as JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-pub-sub.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1 (v1 int, v2 varchar) WITH (\n    connector = 'google_pubsub',\n    pubsub.subscription = 'test-subscription-1',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Syntax for ALTER SYSTEM SET Command in RisingWave SQL\nDESCRIPTION: Defines the general syntax structure for the `ALTER SYSTEM SET` command. This command allows modification of a `configuration_parameter` by assigning a specific `value` (or multiple values separated by commas) or resetting it to its `DEFAULT` value. The keywords `TO` and `=` are interchangeable.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-system.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET configuration_parameter { TO | = } { value [, ...] | DEFAULT }\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN PROTOBUF Format in RisingWave\nDESCRIPTION: SQL syntax for data in Protobuf format. Requires specifying a fully qualified message name and either a schema location or schema registry URL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE PROTOBUF (\n   message = 'com.example.MyMessage',\n   schema.location = 'location' | schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\n----------------------------------------\n\nTITLE: Defining the mysql_query Table-Valued Function - SQL\nDESCRIPTION: This SQL snippet defines the syntax for using the mysql_query table-valued function (TVF) in RisingWave, outlining the required parameters to connect to a MySQL database and execute a remote query. The function requires the hostname, port, username, password, target database name, and the SQL query to run, all passed as varchar arguments. It returns a table corresponding to the query result, and relies on MySQL client connectivity inside RisingWave. The function is typically used where occasional reads from external MySQL sources are needed, not for continuous change capture.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql_query(\n    hostname varchar,      -- Database hostname\n    port varchar,          -- Database port\n    username varchar,      -- Authentication username\n    password varchar,      -- Authentication password\n    database_name varchar, -- Target database name\n    query varchar          -- SQL query to execute\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Array of Varchar with RisingWave Data Generator\nDESCRIPTION: SQL statement to create a load generator source with an array of varchar elements. It configures an array of 3 varchar elements, each with length 1, using random generation with seed 3.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1 (c1 varchar [])\nWITH (\n     connector = 'datagen',\n     fields.c1.length = '3',\n     fields.c1._.kind = 'random',\n     fields.c1._.length = '1',\n     fields.c1._.seed = '3',\n     datagen.rows.per.second = '10'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Modifying Materialized View to Add Column in RisingWave - SQL\nDESCRIPTION: This snippet demonstrates replacing a materialized view (m1) with a new one (m2) that adds a new aggregation (max(v1)). This is part of a stepwise evolution to change logic, showing limitations before switching to SINK INTO TABLE. The output is the new materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW m2 as select count(*), max(v1) from t;\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Kafka Sink with AWS MSK IAM Authentication in SQL\nDESCRIPTION: This SQL statement creates an append-only Kafka sink named 'sink1' in RisingWave. It reads data from materialized view 'mv1', connects to an AWS MSK cluster specified by 'msk-broker-addr:9093', and authenticates using the AWS_MSK_IAM SASL mechanism. The connection requires specifying the AWS region, access key ID, and secret access key. Data is sent to the 'quickstart-events' topic in JSON format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   type = 'append-only',\n   topic='quickstart-events',\n   properties.bootstrap.server='msk-broker-addr:9093',\n   properties.sasl.mechanism='AWS_MSK_IAM',\n   aws.region = 'us-east-1',\n   aws.credentials.access_key_id = 'your_access_key',\n   aws.credentials.secret_access_key = 'your_secret_key'\n) FORMAT PLAIN ENCODE JSON;\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave to Process RudderStack Event Data (SQL)\nDESCRIPTION: This SQL command creates a materialized view named `rudderstack_events` based on the `wbhtable`. It extracts specific fields (`id`, `sender.login`, `created_at`) from the JSONB data stored in the `data` column using JSON operators (`->>`, `->`). This allows for easier querying and analysis of the ingested RudderStack event data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/rudderstack-webhook.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW rudderstack_events AS\nSELECT\n  data->>'id' AS id,\n  data->'sender'->>'login' AS sender_login,\n  data->>'created_at' AS event_time\nFROM wbhtable;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for Stream Metrics\nDESCRIPTION: SQL statement to create a source connection to Kafka stream containing live stream metrics data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE live_stream_metrics (\n    client_ip VARCHAR,\n    user_agent VARCHAR,\n    user_id VARCHAR,\n    room_id VARCHAR,\n    video_bps BIGINT,\n    video_fps BIGINT,\n    video_rtt BIGINT,\n    video_lost_pps BIGINT,\n    video_total_freeze_duration BIGINT,\n    report_timestamp TIMESTAMP WITH TIME ZONE,\n    country VARCHAR\n) WITH (\n    connector = 'kafka',\n    topic = 'live_stream_metrics',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating PostgreSQL CDC Source in dbt\nDESCRIPTION: This SQL snippet demonstrates how to create a source model in dbt for ingesting data from PostgreSQL CDC. It configures the source with connection details and CDC-specific parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_15\n\nLANGUAGE: SQL\nCODE:\n```\n{{ config(materialized='source') }}\nCREATE SOURCE {{ this }} WITH (\n    connector = 'postgres-cdc',\n    hostname = '127.0.0.1',\n    port = '8306',\n    username = 'root',\n    password = '123456',\n    database.name = 'mydb',\n    slot.name = 'mydb_slot'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for 5-Minute Windowed CTR in RisingWave SQL\nDESCRIPTION: This SQL snippet creates a materialized view called 'ad_ctr_5min' that calculates the click-through rate (CTR) for ads in 5-minute intervals. It joins ad impressions and clicks using tumbling windows and groups the results by ad ID and time window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW ad_ctr_5min AS\nSELECT\n    ac.ad_id AS ad_id,\n    ac.clicks_count :: NUMERIC / ai.impressions_count AS ctr,\n    ai.window_end AS window_end\nFROM\n    (\n        SELECT\n            ad_id,\n            COUNT(*) AS impressions_count,\n            window_end\n        FROM\n            TUMBLE(\n                ad_impression,\n                impression_timestamp,\n                INTERVAL '5' MINUTE\n            )\n        GROUP BY\n            ad_id,\n            window_end\n    ) AS ai\n    JOIN (\n        SELECT\n            ai.ad_id,\n            COUNT(*) AS clicks_count,\n            ai.window_end AS window_end\n        FROM\n            TUMBLE(ad_click, click_timestamp, INTERVAL '5' MINUTE) AS ac\n            INNER JOIN TUMBLE(\n                ad_impression,\n                impression_timestamp,\n                INTERVAL '5' MINUTE\n            ) AS ai ON ai.bid_id = ac.bid_id\n            AND ai.window_end = ac.window_end\n        GROUP BY\n            ai.ad_id,\n            ai.window_end\n    ) AS ac ON ai.ad_id = ac.ad_id\n    AND ai.window_end = ac.window_end;\n```\n\n----------------------------------------\n\nTITLE: Creating a Python User-Defined Aggregate Function (UDAF) in SQL\nDESCRIPTION: Demonstrates how to create a Python UDAF named 'weighted_avg' that calculates the weighted average of input values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\ncreate aggregate weighted_avg(value int, weight int) returns float language python as $$\ndef create_state():\n    return (0, 0)\n\ndef accumulate(state, value, weight):\n    if value is None or weight is None:\n        return state\n    (s, w) = state\n    s += value * weight\n    w += weight\n    return (s, w)\n\ndef retract(state, value, weight):\n    if value is None or weight is None:\n        return state\n    (s, w) = state\n    s -= value * weight\n    w -= weight\n    return (s, w)\n\ndef finish(state):\n    (sum, weight) = state\n    if weight == 0:\n        return None\n    else:\n        return sum / weight\n$$;\n```\n\n----------------------------------------\n\nTITLE: Syntax for Renaming an Index using ALTER INDEX RENAME TO in SQL\nDESCRIPTION: Details the syntax for renaming an existing index using the `ALTER INDEX` command combined with the `RENAME TO` clause. It requires the current index name (`index_name`) and the desired new name (`new_name`). Renaming the index also renames any associated table constraints (UNIQUE, PRIMARY KEY, or EXCLUDE).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER INDEX index_name\n    RENAME TO new_name;\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL Data Using mysql_query in RisingWave - SQL\nDESCRIPTION: This SQL snippet demonstrates how to use the mysql_query TVF inside RisingWave to retrieve all rows from the previously created 'test' table in MySQL. The function parameters (here shown as shell variables for host, port, username, etc.) specify the external connection and desired query. The result is a tabular dataset that RisingWave consumes as if it were a local table, subject to data type mappings and access privileges. This pattern is useful for static snapshots or infrequent synchronization use cases.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-table.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * \nFROM mysql_query('$MYSQL_HOST', '$MYSQL_TCP_PORT', '$RISEDEV_MYSQL_USER', '$MYSQL_PWD', 'tvf', 'select * from test;');\n----RESULT\n1 t 1 2 3 4 5 6 7 1.08 1.09 1.10 1.11 char varchar \\x000a \\x16 \\x17 \\x18 \\x19 2021-01-01 12:34:56 2021-01-01 12:34:56+00:00 {\"key1\": 1, \"key2\": \"abc\"}\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source in RisingWave (SQL)\nDESCRIPTION: This SQL snippet demonstrates how to create a source in RisingWave that connects to an Apache Iceberg table stored on S3. It specifies the connector type, warehouse path, database and table names, S3 endpoint, access credentials, and region.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE iceberg_source\nWITH (\n    connector = 'iceberg',\n    type='append-only',\n    warehouse.path = 's3://your-bucket/path/to/iceberg/warehouse',\n    database.name = 'your_iceberg_db',\n    table.name = 'your_iceberg_table',\n    s3.endpoint = 'http://your-s3-endpoint:port', -- e.g., 'http://minio:9000'\n    s3.access.key = 'YOUR_ACCESS_KEY',\n    s3.secret.key = 'YOUR_SECRET_KEY',\n    s3.region = 'your-s3-region'  -- Optional if endpoint is specified\n) ;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Sink in RisingWave SQL\nDESCRIPTION: Basic SQL syntax for creating a sink that streams data from RisingWave to Apache Iceberg tables. The command allows specifying the sink name, data source, and various connector parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='iceberg',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Sinks from Kafka Sources into a RisingWave Table (SQL)\nDESCRIPTION: Provides an example of creating a table (`orders`) and two Kafka sources (`orders_s0`, `orders_s1`) in RisingWave. It then demonstrates creating two sinks (`orders_sink0`, `orders_sink1`) using `CREATE SINK INTO` to channel data from each Kafka source into the `orders` table, effectively merging data streams from two Kafka topics into a single table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-sink-into.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE orders (\n    id int primary key,\n    price int,\n    item_id int,\n    customer_id int\n);\n\nCREATE source orders_s0 (\n    id int primary key,\n    price int,\n    item_id int,\n    customer_id int\n) WITH (\n    connector = 'kafka',\n    topic = 'topic_0',\n    ...\n) FORMAT PLAIN ENCODE JSON;\n\nCREATE source orders_s1 (\n    id int primary key,\n    price int,\n    item_id int,\n    customer_id int\n) WITH (\n    connector = 'kafka',\n    topic = 'topic_1',\n    ...\n) FORMAT PLAIN ENCODE JSON;\n\nCREATE SINK orders_sink0 INTO orders FROM orders_s0;\nCREATE SINK orders_sink1 INTO orders FROM orders_s1;\n```\n\n----------------------------------------\n\nTITLE: Merging Multiple Sinks with Shared Primary Key in SQL\nDESCRIPTION: This SQL snippet demonstrates creating multiple source tables (d1, d2, d3) and a target wide table (wide_d), all sharing a primary key 'k'. It then defines three separate sinks (sink1, sink2, sink3), each responsible for selecting data from one source table and inserting/updating specific columns (v1, v2, v3 respectively) into the wide_d table. The `ON CONFLICT DO UPDATE IF NOT NULL` clause on wide_d ensures that incoming rows with the same primary key update existing rows only for the non-null columns provided by the specific sink, effectively merging data from different sources. Sinks are configured as 'append-only' to avoid unintended row deletions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/maintain-wide-table-with-table-sinks.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE d1(v1 int, k int primary key);\nCREATE TABLE d2(v2 int, k int primary key);\nCREATE TABLE d3(v3 int, k int primary key);\nCREATE TABLE wide_d(v1 int, v2 int, v3 int, k int primary key)\nON CONFLICT DO UPDATE IF NOT NULL;\n\nCREATE SINK sink1 INTO wide_d (v1, k) AS\n  SELECT v1, k FROM d1\n  with (\n      type = 'append-only',\n      force_append_only = 'true',\n  );\nCREATE SINK sink2 INTO wide_d (v2, k) AS\n  SELECT v2, k FROM d2\n  with (\n      type = 'append-only',\n      force_append_only = 'true',\n  );\nCREATE SINK sink3 INTO wide_d (v3,k) AS\n  SELECT v3, k FROM d3\n  with (\n      type = 'append-only',\n      force_append_only = 'true',\n  );\n```\n\n----------------------------------------\n\nTITLE: Output of Backfill Executor State Query\nDESCRIPTION: Shows the current state of the backfill process, including the split ID, row count, backfill completion status, and the CDC offset indicating the position in the transaction log of the source database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nsplit_id | id | backfill_finished | row_count | cdc_offset\n----------+----+-------------------+-----------+-------------------------------------------------------------------------------------------------\n3        |  5 | t                 |         4 | {\"SqlServer\": {\"change_lsn\": \"00000029:000005b0:0006\", \"commit_lsn\": \"ffffffff:ffffffff:ffff\"}}\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Using last_value() Window Function in SQL\nDESCRIPTION: The last_value() function returns the value of the last row in the current window frame. If IGNORE NULLS is present, it returns the last non-null value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nlast_value ( value anyelement [ IGNORE NULLS ] ) → anyelement\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    col1, col2,\n    last_value(col2) OVER (\n        PARTITION BY col1\n        ORDER BY col2\n        -- ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) as last\nFROM t ORDER BY col1, col2;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    col1, col2,\n    last_value(col2) OVER (\n        PARTITION BY col1\n        ORDER BY col2\n        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n    ) as last\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Configuring Background DDL in RisingWave\nDESCRIPTION: This SQL command configures the behavior of backfilling historical data when creating a materialized view. It allows setting the DDL operation to run in the background.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET BACKGROUND_DDL\n```\n\n----------------------------------------\n\nTITLE: Defining Streaming Sources with Watermarks - SQL\nDESCRIPTION: These statements define two streaming data sources with watermarked timestamps in RisingWave, simulating event streams for subsequent windowed operations. Both sources use the 'datagen' connector and specify watermark expressions to control event time progression. These are prerequisites for performing windowed or time-bounded joins in further queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1 (\n id int,\n value int,\n ts TIMESTAMP,\n WATERMARK FOR ts AS ts - INTERVAL '20' SECOND\n) WITH (connector = 'datagen');\n\nCREATE SOURCE s2 (\n id int,\n value int,\n ts TIMESTAMP,\n WATERMARK FOR ts AS ts - INTERVAL '20' SECOND\n) WITH (connector = 'datagen');\n```\n\n----------------------------------------\n\nTITLE: Defining Tumbling Windows in RisingWave SQL\nDESCRIPTION: Demonstrates the basic syntax for the tumble() time window function in RisingWave SQL. This snippet illustrates how to apply the TUMBLE construct within the FROM clause, assigning each row to a non-overlapping window and augmenting the result with window_start and window_end columns. Dependencies include a suitable table or source, a timestamp column, and proper INTERVAL parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT [ ALL | DISTINCT ] [ * | expression [ AS output_name ] [, expression [ AS output_name ]...] ]\\nFROM TUMBLE ( table_or_source, time_col, window_size [, offset ] );\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source in RisingWave\nDESCRIPTION: This SQL statement demonstrates how to create a source that connects to a Kafka topic. It defines a schema with three fields and specifies connection properties including the Kafka topic and bootstrap server.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE kafka_source (\n  k int,\n  v1 text,\n  v2 text\n)\nWITH (\n  connector = 'kafka',\n  topic = 'topic_name',\n  properties.bootstrap.server = 'message_queue:29092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Aggregation in SQL - SQL\nDESCRIPTION: This SQL snippet creates a materialized view 'mv_sales_summary' that aggregates 'sales_data' by 'product_id', computing total sales via SUM. Intended for use in RisingWave, this continuously-updated view provides pre-computed, performant access to total sales per product. Prerequisites are an existing 'sales_data' table; inputs are all current and incoming records, and output is the aggregated view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/overview.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv_sales_summary AS\\nSELECT product_id, SUM(sales_amount) AS total_sales\\nFROM sales_data\\nGROUP BY product_id;\n```\n\n----------------------------------------\n\nTITLE: Using DECODE Function in SQL\nDESCRIPTION: The decode() function decodes the text data in the input string into binary data. Supported formats for the encoded input string include base64, hex, and escape.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\ndecode ( input_string, format_type ) → bytea\n```\n\nLANGUAGE: SQL\nCODE:\n```\ndecode('MTIz', 'base64') → '123'\n```\n\n----------------------------------------\n\nTITLE: Using DISTINCT clause in SQL SELECT statements\nDESCRIPTION: This example demonstrates the use of the DISTINCT clause to return only unique combinations of first_name and last_name from an employees table, eliminating any duplicate rows from the result set.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Retrieve the names of employees.\nSELECT DISTINCT first_name, last_name\nFROM employees;\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN with a SELECT Statement in RisingWave SQL\nDESCRIPTION: Demonstrates how to use the `EXPLAIN` command to generate the execution plan for a complex `SELECT` query. This example query involves joins between `orders` and `lineitem` tables, filtering based on dates and existence checks, grouping by priority, and ordering the results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-explain.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT\n    o_orderpriority,\n    count(*) AS order_count\nFROM\n    orders\nWHERE\n    o_orderdate >= date '1997-07-01'\n    and o_orderdate < date '1997-07-01' + interval '3' month\n    and exists (\n        SELECT\n            *\n        FROM\n            lineitem\n        WHERE\n            l_orderkey = o_orderkey\n            and l_commitdate < l_receiptdate\n    )\nGROUP BY\n    o_orderpriority\nORDER BY\n    o_orderpriority;\n```\n\n----------------------------------------\n\nTITLE: Creating an Index on 'o_custkey' and Using it in a JOIN Query in SQL\nDESCRIPTION: Illustrates creating an index named `idx_o_custkey` on the `o_custkey` column of the `orders` table using the `CREATE INDEX` command. This index aims to optimize queries involving joins between the `customers` and `orders` tables on the customer key. An example `SELECT` statement demonstrates a join query filtering by `c_phone`, which benefits from the newly created index on `o_custkey` for faster join processing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-index.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX idx_o_custkey ON orders(o_custkey);\n\nSELECT * FROM customers JOIN orders ON c_custkey = o_custkey\nWHERE c_phone = '123456789';\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Pulsar Source/Table with Protobuf Format (SQL)\nDESCRIPTION: This SQL statement creates a RisingWave source or table named 'source_abc' with predefined columns ('column1', 'column2') to read Protobuf-encoded data from a Pulsar topic 'demo_topic'. It configures the 'pulsar' connector, service URL, OAuth authentication, AWS credentials, and scan startup mode. The data format is specified as PLAIN ENCODE PROTOBUF, requiring the Protobuf message definition ('package.message_name') and the location of the Protobuf schema file (.proto).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='pulsar',\n   topic='demo_topic',\n   service.url='pulsar://localhost:6650/',\n   oauth.issuer.url='https://auth.streamnative.cloud/',\n   oauth.credentials.url='s3://bucket_name/your_key_file.file',\n   oauth.audience='urn:sn:pulsar:o-d6fgh:instance-0',\n   aws.credentials.access_key_id='aws.credentials.access_key_id',\n   aws.credentials.secret_access_key='aws.credentials.secret_access_key',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE PROTOBUF (\n   message = 'package.message_name',\n   schema.location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/demo.proto'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Webhook Table with Secret Validation in SQL\nDESCRIPTION: Demonstrates how to create a webhook-enabled table in RisingWave with secret-based authentication. The table uses JSONB format for data storage and includes signature validation for request authentication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'secret_value';\n\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'${header of signature}',\n  ${signature generation expressions}\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table for Historical Data Backfill\nDESCRIPTION: Creates a table to backfill historical data from PostgreSQL source with timestamp and integer columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3 (id INTEGER, v1 TIMESTAMP WITH TIME ZONE, PRIMARY KEY(id)) FROM pg_source TABLE 'public.t3';\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Bid-Ask Spread in SQL\nDESCRIPTION: Creates a materialized view to calculate average price and bid-ask spread for each asset in 5-minute time windows using TUMBLE() function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW avg_price_bid_ask_spread AS\nSELECT\n    asset_id,\n    ROUND(AVG(price), 2) AS average_price,\n    ROUND(AVG(ask_price - bid_price), 2) AS bid_ask_spread,\n    window_end\nFROM\n    TUMBLE(raw_market_data, timestamp, '5 minutes')\nGROUP BY asset_id, window_end;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for Ad Impressions in RisingWave\nDESCRIPTION: SQL statement to create a source in RisingWave that connects to the Kafka topic containing ad impression events. This defines the schema and connection properties for consuming impression data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE ad_impression (\n    bid_id BIGINT,\n    ad_id BIGINT,\n    impression_timestamp TIMESTAMP WITH TIME ZONE\n) WITH (\n    connector = 'kafka',\n    topic = 'ad_impression',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example: Moving a Table to a Different Schema using ALTER TABLE in SQL\nDESCRIPTION: Provides a practical example of the `ALTER TABLE SET SCHEMA` command. This command moves the table named `test_table` into the schema named `test_schema`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Move a table named \"test_table\" into a schema named \"test_schema\"\nALTER TABLE test_table SET SCHEMA test_schema;\n```\n```\n\n----------------------------------------\n\nTITLE: UNION Example Query\nDESCRIPTION: Shows how to use UNION to combine and deduplicate results from two tables containing points scored data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM points_scored_current_week\nUNION\nSELECT *\nFROM points_scored_last_week;\n```\n\n----------------------------------------\n\nTITLE: Creating Positions Table in SQL\nDESCRIPTION: Creates a table for real-time betting positions tracking current stakes, odds, and profit/loss information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE positions (\n    position_id INT,\n    position_name VARCHAR,\n    user_id INT,\n    league VARCHAR,\n    stake_amount FLOAT,\n    expected_return FLOAT,\n    current_odds FLOAT,\n    profit_loss FLOAT,\n    timestamp TIMESTAMPTZ\n);\n```\n\n----------------------------------------\n\nTITLE: Example: Changing View Owner using ALTER VIEW OWNER TO in SQL\nDESCRIPTION: Example SQL command demonstrating how to change the owner of a view named `view1` to `user1` using the `ALTER VIEW ... OWNER TO` clause. This operation transfers ownership of the specified view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Change the owner of the view named \"view1\" to user \"user1\"\nALTER VIEW view1 OWNER TO user1;\n```\n```\n\n----------------------------------------\n\nTITLE: Syntax for the INSERT Command in RisingWave SQL\nDESCRIPTION: Defines the general syntax for the `INSERT` command in RisingWave SQL. It allows adding new rows into a specified table (`table_name`) either by providing explicit values (`VALUES`) or by using the results of a `SELECT` query (`select_query`). Optionally, specific columns (`col_name`) can be targeted, though currently all columns must be provided in order or the list omitted. The `RETURNING` clause can optionally return specified columns from the inserted rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO table_name [ ( col_name [ , ... ] ) ]\n      { VALUES ( value [ , ... ] ) [ , ( ... ) ] | select_query }\n      [ RETURNING col_name ];\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with Snowflake Catalog\nDESCRIPTION: Example of creating an Iceberg source using the Snowflake catalog type, which requires Snowflake-specific connection details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE iceberg_t1_source\nWITH (\n    connector = 'iceberg',\n    s3.region = 'ap-northeast-2',\n    s3.access.key = 'xxx',\n    s3.secret.key = 'xxx',\n    catalog.name = 'demo1',\n    catalog.type = 'snowflake',\n    catalog.uri = 'jdbc:snowflake://<account_identifier>.snowflakecomputing.com/',\n    catalog.jdbc.user = 'xxx',\n    catalog.jdbc.password = 'xxx',\n    warehouse.path = 's3://xxx',\n    database.name = 'xxx',\n    table.name = 'xxx'\n    );\n```\n\n----------------------------------------\n\nTITLE: Querying a Single Parquet File from S3 with file_scan in SQL\nDESCRIPTION: Queries a single Parquet file stored in S3 by calling file_scan and selecting specified columns, demonstrating integration with RisingWave SQL. Dependencies include an existing, accessible Parquet file with known schema and valid S3 credentials. Parameters specify the file format, S3 bucket region, access credentials, and the Parquet file path. The query returns the rows from the Parquet file; if schema mismatches or credential errors occur, the query may fail.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  product_id,\n  sales_date,\n  quantity,\n  revenue\nFROM file_scan(\n  'parquet',\n  's3',\n  'ap-southeast-2',\n  'xxxxxxxxxx',\n  'yyyyyyyy',\n  's3://your-bucket/path/to/sales_data.parquet'\n);\n\n----RESULT\nproduct_id |  sales_date  | quantity | revenue\n------------+-------------+----------+----------\n         12 | 2023-04-01   |       50 |   1000.00\n         12 | 2023-04-02   |       30 |    600.00\n         15 | 2023-04-01   |       20 |    400.00\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Tumbling Window Aggregation with SQL - SQL\nDESCRIPTION: Uses the TUMBLE function in SQL to count trips per 2-minute window, grouping by window start and end. Requires a 'taxi_trips' table with corresponding columns. Designed to show basic usage of tumbling windows for time-based aggregation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT window_start, window_end, COUNT(*) AS trip_count\\nFROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES')\\nGROUP BY window_start, window_end;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Click-Through Rate (CTR) Analysis\nDESCRIPTION: SQL statement that creates a materialized view to calculate the click-through rate for each ad. It joins impression and click data on bid_id, counts impressions and clicks by ad_id, and calculates the CTR as clicks divided by impressions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW ad_ctr AS\nSELECT\n    ad_clicks.ad_id AS ad_id,\n    ad_clicks.clicks_count :: NUMERIC / ad_impressions.impressions_count AS ctr\nFROM\n    (\n        SELECT\n            ad_impression.ad_id AS ad_id,\n            COUNT(*) AS impressions_count\n        FROM\n            ad_impression\n        GROUP BY\n            ad_id\n    ) AS ad_impressions\n    JOIN (\n        SELECT\n            ai.ad_id,\n            COUNT(*) AS clicks_count\n        FROM\n            ad_click AS ac\n            LEFT JOIN ad_impression AS ai ON ac.bid_id = ai.bid_id\n        GROUP BY\n            ai.ad_id\n    ) AS ad_clicks ON ad_impressions.ad_id = ad_clicks.ad_id;\n```\n\n----------------------------------------\n\nTITLE: Verifying data in MySQL\nDESCRIPTION: SQL query to select all data from the 'personnel' table in MySQL to verify the sink connection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM personnel;\n```\n\n----------------------------------------\n\nTITLE: Array Type Definition and Insertion in RisingWave SQL\nDESCRIPTION: Demonstrates how to define columns with array types when creating a table, and how to insert array values using the ARRAY constructor. Array types are specified using square brackets after the base type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE (f1 INT[], f2 INT[]);\n\nINSERT INTO arr VALUES (ARRAY[1,2], ARRAY[3,4]);\n```\n\n----------------------------------------\n\nTITLE: Converting JSON to Structured Records with jsonb_populate_record\nDESCRIPTION: Function that converts a JSON object into a structured record type, mapping JSON fields to corresponding column names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_populate_record(\n    null::struct<a int, b text[], c struct<d int, e text>>,\n    '{\"a\": 1, \"b\": [\"2\", \"a b\"], \"c\": {\"d\": 4, \"e\": \"a b c\"}, \"x\": \"foo\"}'\n);\n```\n\n----------------------------------------\n\nTITLE: Using INITCAP Function in SQL\nDESCRIPTION: The initcap() function capitalizes the first letter of each word in the input string and converts the remaining characters to lowercase.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\ninitcap ( input_string ) → string\n```\n\nLANGUAGE: SQL\nCODE:\n```\ninitcap('POWERFUL and flexible') → 'Powerful And Flexible'\n```\n\n----------------------------------------\n\nTITLE: Creating Date/Time Values in SQL\nDESCRIPTION: Functions to create date, time, and timestamp values from individual components.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nmake_date(2024, 1, 31) → 2024-01-31\n\nmake_time(1, 45, 30.2) → 01:45:30.200\n\nmake_timestamp(2024, 1, 31, 1, 45, 30.2) → 2024-01-31 01:45:30.200\n```\n\n----------------------------------------\n\nTITLE: Generating SHA-512 Hash of Binary String in SQL\nDESCRIPTION: The sha512 function returns the SHA-512 hash of a binary string. It takes a bytea input and returns a bytea.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nsha512 ( bytea ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sha512('risingwave'::bytea);\n------RESULT\n\\x3d6d6078c75ad459cdc689216d5de35bd6d9a9a50b9bed96417aaf7ad25057b37460564f0ad23a589c655eda45026096a6bab08b3c863f0425cbfea64b5f84a8\n```\n\n----------------------------------------\n\nTITLE: Example of using percentile_cont for median in SQL\nDESCRIPTION: Calculates the median (50th percentile) of values in column1 from table1 using the WITHIN GROUP clause and ORDER BY for percentile calculation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSELECT percentile_cont(0.5) WITHIN GROUP (ORDER BY column1) FROM table1;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with Hive Catalog\nDESCRIPTION: Example of creating an Iceberg source using the Hive catalog type, which requires setting catalog.type to 'hive'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_demo_hive\nWITH (\n    connector = 'iceberg',\n    catalog.type = 'hive',\n    catalog.uri = 'thrift://metastore:9083',\n    warehouse.path = 's3://icebergdata/demo',\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    catalog.name = 'demo',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with Upsert Avro Encoding in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka table in RisingWave using Upsert Avro encoding. It includes the key as a separate column and specifies it as the primary key, along with Avro encoding details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_abc (\n  primary key (rw_key)\n)\nINCLUDE key AS rw_key\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test_topic'\n)\nFORMAT UPSERT ENCODE AVRO (\n   message = 'message_name',\n   schema.registry = 'http://127.0.0.1:8081',\n   schema.registry.username='your_schema_registry_username',\n   schema.registry.password='your_schema_registry_password'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Unnamed Parameters - Double Dollar Definition\nDESCRIPTION: Creates a basic SQL UDF that adds two integer parameters using double dollar definition syntax.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add(INT, INT) returns int language sql as 'select $1 + $2';\n```\n\n----------------------------------------\n\nTITLE: Specifying Schema Definition for RisingWave Kinesis Source/Table SQL\nDESCRIPTION: This SQL snippet shows the syntax for the optional `schema_definition` part within a `CREATE SOURCE` or `CREATE TABLE` statement for a Kinesis connection in RisingWave. It allows users to explicitly define the column names, their corresponding data types, and optionally specify single or composite primary keys. Note that this block is omitted when using Avro or Protobuf formats, as the schema is provided via `schema.location` instead.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Standard Batch Table in RisingWave SQL\nDESCRIPTION: Creates a standard batch table in RisingWave that must be manually populated with data using INSERT statements. This table has an integer primary key and a VARCHAR column for names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE my_batch_table (\n    id INT PRIMARY KEY,\n    name VARCHAR\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Azblob Source for JSON Data in RisingWave SQL\nDESCRIPTION: Shows an example of creating a RisingWave source `s1` to ingest JSON data (specifically newline-delimited JSON, `.ndjson`) from Azure Blob Storage. It defines the schema, configures the `azblob` connector with connection details and a `match_pattern` ('%Ring%*.ndjson') to filter files, and sets the format to `PLAIN` and encoding to `JSON`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1(\n    id int,\n    name TEXT,\n    age int,\n    mark int,\n)\nWITH (\n    connector = 'azblob',\n    azblob.container_name = 'xxx',\n    azblob.credentials.account_name = 'xxx',\n    azblob.credentials.account_key = 'xxx',\n    azblob.endpoint_url = 'xxx',\n    match_pattern = '%Ring%*.ndjson',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining a GCS Source in RisingWave SQL\nDESCRIPTION: This SQL syntax defines the structure for creating a data source in RisingWave that connects to Google Cloud Storage (GCS). It includes specifying the source name, schema, optional metadata columns (`file`, `offset`, `payload`), connector type ('gcs'), GCS-specific parameters, data format, and encoding options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name\nschema_definition\n[INCLUDE { file | offset | payload } [AS <column_name>]]\nWITH (\n   connector = 'gcs',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   without_header = 'true' | 'false',\n   delimiter = 'delimiter'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Processing Time Generated Column in RisingWave SQL\nDESCRIPTION: This snippet shows how to create a table with a generated column that captures the processing time of a message using the proctime() function. The proc_time column is automatically populated with a timestamp when data is inserted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/generated-columns.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (v1 int, proc_time timestamptz as proctime());\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Total Viewer Count\nDESCRIPTION: SQL statement to create a materialized view that tracks unique viewers across the entire platform per minute.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW total_user_visit_1min AS\nSELECT\n    window_start AS report_ts,\n    COUNT(DISTINCT user_id) AS uv\nFROM\n    TUMBLE(\n        live_stream_metrics,\n        report_timestamp,\n        INTERVAL '1' MINUTE\n    )\nGROUP BY\n    window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating and Showing a Table Example\nDESCRIPTION: An example showing how to create a table with specific options and then use SHOW CREATE TABLE to view its definition. Note that IF NOT EXISTS is omitted in the output while WITH options are preserved.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS taxi_trips(\n    id VARCHAR,\n    distance DOUBLE PRECISION,\n    city VARCHAR\n) WITH (appendonly = 'true');\n\nSHOW CREATE TABLE taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Showing All Subscription Cursors in RisingWave Session\nDESCRIPTION: This SQL command lists all active subscription cursors in the current session. The output displays each cursor's name along with the linked subscription, which is useful for monitoring and management of active data consumers within a session.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW SUBSCRIPTION CURSORS;\n\n------RESULT\n Name | SubscriptionName\n------+------------------\n cur2 | sub\n cur  | sub\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink for Fraud Alerts in SQL\nDESCRIPTION: This snippet creates a sink that sends suspicious transaction data to a Kafka topic for alerting purposes. It exports data from the suspicious_transactions materialized view in JSON format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK suspicious_activity FROM suspicious_transactions\nWITH (\n  connector='kafka',\n  properties.bootstrap.server='localhost:9092',\n  topic='suspicious_activity'\n  ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source Table with PrivateLink Connection in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a table in RisingWave that sources data from Kafka using an AWS PrivateLink connection. It includes the table structure definition and the connection parameters in the WITH clause, specifying the PrivateLink endpoint and targets.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE IF NOT EXISTS crypto_source (\n  product_id VARCHAR,\n  price NUMERIC,\n  open_24h NUMERIC,\n  volume_24h NUMERIC,\n  low_24h NUMERIC,\n  high_24h NUMERIC,\n  volume_30d NUMERIC,\n  best_bid  NUMERIC,\n  best_ask  NUMERIC,\n  side VARCHAR,\n  time timestamp,\n  trade_id bigint,\n)\nWITH (\n  connector='kafka',\n  topic='crypto',\n  privatelink.endpoint='10.148.0.4',\n  privatelink.targets='[{\"port\": 9094}, {\"port\": 9095}, {\"port\": 9096}]',\n  properties.bootstrap.server='broker1-endpoint,broker2-endpoint,broker3-endpoint',\n  scan.startup.mode='latest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: SHOW FUNCTIONS Syntax in RisingWave\nDESCRIPTION: The syntax for the SHOW FUNCTIONS command which displays information about user-defined functions. It can optionally include a LIKE expression to filter the results based on function names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-functions.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW FUNCTIONS [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Creating a Google Cloud Storage Sink in SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a sink in RisingWave to store data in Google Cloud Storage. It includes placeholders for sink name, source, and various GCS-specific parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/google-cloud-storage.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='gcs',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave PostgreSQL CDC Source with Debezium Parameters (SQL)\nDESCRIPTION: This SQL example demonstrates creating a shared PostgreSQL CDC source (`pg_mydb`) in RisingWave. It specifies standard connection parameters like hostname, port, credentials, database name, and replication slot name. Crucially, it shows how to include Debezium connector properties within the `WITH` clause by adding the `debezium.` prefix, specifically setting `debezium.schema.history.internal.skip.unparseable.ddl` to `'true'`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE pg_mydb WITH (\n    connector = 'postgres-cdc',\n    hostname = '127.0.0.1',\n    port = '8306',\n    username = 'root',\n    password = '123456',\n    database.name = 'mydb',\n    slot.name = 'mydb_slot',\n    debezium.schema.history.internal.skip.unparseable.ddl = 'true'\n);\n```\n\n----------------------------------------\n\nTITLE: Including Metadata Columns in RisingWave CDC Table (SQL)\nDESCRIPTION: This SQL example creates a RisingWave table named `person` that ingests data from the `public.person` table via a pre-defined MySQL CDC source (`mysql_source`). It utilizes the `INCLUDE` clause multiple times: `INCLUDE TIMESTAMP AS commit_ts` adds the commit timestamp, `INCLUDE DATABASE_NAME as database_name` adds the source database name, and `INCLUDE TABLE_NAME as table_name` adds the source table name as columns in the RisingWave table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id int,\n    name varchar,\n    email_address varchar,\n    credit_card varchar,\n    city varchar,\n    PRIMARY KEY (id)\n) INCLUDE TIMESTAMP AS commit_ts\nINCLUDE DATABASE_NAME as database_name\nINCLUDE TABLE_NAME as table_name\nFROM mysql_source TABLE 'public.person';\n```\n\n----------------------------------------\n\nTITLE: Querying Top 5 Rows with ORDER BY in SQL\nDESCRIPTION: This SQL query selects the department, job title, and average salary from the employees table, orders the results by average salary in descending order, and limits the output to the top 5 rows. It demonstrates the use of LIMIT with ORDER BY for deterministic results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/limit-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT department, job_title, AVG(salary)\nFROM employees\nORDER BY AVG(salary) DESC\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Revoking Table Privileges in SQL\nDESCRIPTION: Syntax for revoking SELECT, UPDATE, INSERT, DELETE, or ALL privileges on specific tables or all tables in a schema from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {{SELECT | UPDATE | INSERT | DELETE} [, ...]| ALL [PRIVILEGES]}\nON {  TABLE table_name [, ...]\n    | ALL TABLES IN SCHEMA schema_name [, ...] }\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Creating Embedded Python User-Defined Functions - SQL/Python\nDESCRIPTION: Shows how to define an embedded Python UDF in RisingWave using the CREATE FUNCTION SQL command with inlined Python code. Prerequisites include a RisingWave environment supporting Python as an embedded language. This snippet creates a function 'gcd' that computes the greatest common divisor of two integers, using named parameters (a and b). Input parameters are the integers, output is the computed integer value. Code is enclosed in $$ markers and indented as a Python function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-function.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Embedded Python UDF\nCREATE FUNCTION gcd(a int, b int) RETURNS int LANGUAGE python AS $$\ndef gcd(a, b):\n    while b != 0:\n        a, b = b, a % b\n    return a\n$$;\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source with Protobuf in RisingWave\nDESCRIPTION: Example of creating a Kafka source with Protobuf encoding that uses a schema registry. This establishes the initial schema configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE src_user WITH (\n    connector = 'kafka',\n    topic = 'sr_pb_test',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n)\nFORMAT PLAIN ENCODE PROTOBUF(\n    schema.registry = 'http://message_queue:8081',\n    message = 'test.User');\n```\n\n----------------------------------------\n\nTITLE: Querying with Dynamic Filters in WHERE Clause - RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates a dynamic filter in the WHERE clause, where product rows are selected if their profit margin exceeds the dynamically computed maximum profit margin from the sales table. It uses a CTE (WITH clause) to calculate the aggregate, and requires tables named 'products' and 'sales'. The filter updates automatically as the sales data changes. The input requires valid 'products' and 'sales' table schemas, and outputs product names meeting the condition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/dynamic-filters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nWITH max_profit AS (SELECT max(profit_margin) max FROM sales)\nSELECT product_name FROM products, max_profit\nWHERE product_profit > max;\n```\n\n----------------------------------------\n\nTITLE: SQL UPDATE Statement Syntax\nDESCRIPTION: Basic syntax structure for the UPDATE command showing how to modify table rows with optional WHERE and RETURNING clauses.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-update.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE table_name\n    SET { col_name = value, ... | ( col_name, ... ) = ( value, ... ) }\n    [ WHERE condition ]\n    [ RETURNING col_name ];\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Avro Format in SQL\nDESCRIPTION: Defines a RisingWave source named `source_abc` that connects to a Kafka topic `demo_topic` using the specified bootstrap servers. It reads data in Avro format, starting from the latest offset or a specific timestamp. The Avro message name and Confluent Schema Registry details (URL, credentials) are required for schema resolution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE AVRO (\n   message = 'message_name',\n   schema.registry = 'http://127.0.0.1:8081',\n   schema.registry.username='your_schema_registry_username',\n   schema.registry.password='your_schema_registry_password'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a JavaScript User-Defined Aggregate Function in RisingWave SQL\nDESCRIPTION: This example demonstrates how to create a user-defined aggregate function 'weighted_avg' in JavaScript. It includes the implementation of required functions like create_state, accumulate, retract, and finish to calculate a weighted average.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-javascript.mdx#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\ncreate aggregate weighted_avg(value int, weight int) returns float language javascript as $$\n    export function create_state() {\n        return { sum: 0, weight: 0 };\n    }\n    export function accumulate(state, value, weight) {\n        if (value == null || weight == null) {\n            return state;\n        }\n        state.sum += value * weight;\n        state.weight += weight;\n        return state;\n    }\n    export function retract(state, value, weight) {\n        if (value == null || weight == null) {\n            return state;\n        }\n        state.sum -= value * weight;\n        state.weight -= weight;\n        return state;\n    }\n    export function finish(state) {\n        if (state.weight == 0) {\n            return null;\n        }\n        return state.sum / state.weight;\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Querying a Table with Tumbling Windows in RisingWave SQL\nDESCRIPTION: Queries the taxi_trips table using the TUMBLE time window function with a 2-minute window. This select statement returns columns from the original table along with window_start and window_end, showing how each trip is assigned to a specific window interval. Assumes taxi_trips contains appropriately typed columns and completed_at is a time value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT trip_id, taxi_id, completed_at, window_start, window_end\\nFROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES');\n```\n\n----------------------------------------\n\nTITLE: CREATE TABLE Syntax for Data Source Connection in SQL\nDESCRIPTION: The SQL syntax for creating a table that connects to an external data source in RisingWave. This command defines the table schema, primary key, connector details, and data format specifications.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/connect-with-create-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [IF NOT EXISTS] table_name (\n    column_name data_type [AS source_column_name] [NOT NULL],\n    ...\n    [, PRIMARY KEY (column_name, ...)]\n)\nWITH (\n    connector='connector_name',\n    connector_property='value',\n    ...\n)\nFORMAT format_type ENCODE encode_type (\n    ... -- Format-specific options\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/OAUTHBEARER Authentication in RisingWave SQL\nDESCRIPTION: This example demonstrates creating a Kafka source table with SASL/OAUTHBEARER authentication without SSL encryption. It specifies the OAUTHBEARER mechanism and a simple OAuth configuration in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_6 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='OAUTHBEARER',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.oauthbearer.config='principal=bob'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Indexing JSONB Expression Fields in SQL for RisingWave\nDESCRIPTION: Demonstrates creating a table with a JSONB column, and an index on an integer-casted field from within the JSONB structure, then querying with an execution plan via EXPLAIN. Dependencies: RisingWave support for JSONB, table creation with 'v' as JSONB, and casting for indexing. Parameters include the JSONB field path. Output: execution plan showing use of the index for optimized retrieval. Limitation: only works where casting to integer from JSONB is valid.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ndev=> create table t(v jsonb);\nCREATE_TABLE\ndev=> create index i on t((v -> 'field')::int);\nCREATE_INDEX\ndev=> explain select * from t where (v->'field')::int = 123;\n                                QUERY PLAN\n--------------------------------------------------------------------------\n BatchExchange { order: [], dist: Single }\n └─BatchScan { table: i, columns: [v], scan_ranges: [CAST = Int32(123)] }\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating CDC Table with Schema Auto-Mapping from SQL Server - SQL\nDESCRIPTION: This snippet shows how to automatically map the upstream SQL Server table schema when creating a CDC table in RisingWave by using an asterisk (*) in the columns definition. This causes all columns from the source table to be mapped and ingested by RisingWave. 'supplier' is created without column details; dependencies include the existence of 'mssql_source' and upstream table 'dbo.supplier'. Limitation: no additional columns or metadata can be specified when using '*'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE supplier (*) FROM mssql_source TABLE 'dbo.supplier';\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Data by Unix Timestamp in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to access historical table data as of a specific Unix timestamp using the FOR SYSTEM_TIME AS OF clause. Requires RisingWave Premium Edition with a SQL-compatible meta store and sufficient retention setting. The query returns data as it appeared at the provided epoch time in seconds; fails if the timestamp falls outside the configured retention window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/time-travel-queries.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t_foo FOR SYSTEM_TIME AS OF 1721024455;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with JDBC Catalog\nDESCRIPTION: Example of creating an Iceberg source using the JDBC catalog type, which requires specifying the JDBC connection details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_demo_jdbc\nWITH (\n    connector = 'iceberg',\n    warehouse.path = 's3://icebergdata/demo',\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    catalog.name = 'demo',\n    catalog.type = 'jdbc',\n    catalog.uri = 'jdbc:postgresql://postgres:5432/iceberg',\n    catalog.jdbc.user = 'admin',\n    catalog.jdbc.password = '123456',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Dependent Materialized Views With New Columns in RisingWave - SQL\nDESCRIPTION: These SQL commands add new aggregate columns to two dependent materialized views: 'orders_new' (adding item_count) and 'cust_sales_new' (adding sales_count via SUM over item_count). Each new view references the prior or upstream entity. Prerequisites are the presence of the source tables and existing views. They illustrate dependency migration when evolving complex streaming topologies.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW orders_new AS\n    SELECT\n        order_id,\n        customer_id,\n        SUM(price * quantity) AS total_price,\n        COUNT(*) AS item_count -- The new column\n    FROM order_items, price\n    WHERE order_items.product_id = price.product_id\n    GROUP BY order_id, customer_id;\n\nCREATE MATERIALIZED VIEW cust_sales_new AS\n    SELECT\n        customer_id,\n        SUM(total_price) AS sales_amount,\n        SUM(item_count) AS sales_count -- The new column\n    FROM orders_new -- the new one\n    GROUP BY customer_id;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Data from Struct Columns\nDESCRIPTION: Examples of querying data from struct columns using dot notation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT (a).b, d\nFROM x;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ((a).b).c, e\nFROM y;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, (fare).initial_charge\nFROM trip;\n```\n\n----------------------------------------\n\nTITLE: Using array_sum Function in SQL\nDESCRIPTION: Returns the sum of all values in the array. Null elements are skipped in the calculation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\narray_sum ( array ) → type of the elements\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_sum(array[3, 2, NULL]) → 5\n\narray_sum(array[-10, 20, -30]) → -20\n\narray_sum(array[interval'4 hour', interval'3 day']) → '3 days 04:00:00'\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Kinesis Table with JSON Payload Ingestion using SQL\nDESCRIPTION: This SQL example demonstrates creating a RisingWave table to ingest raw JSON data from a Kinesis topic using the `INCLUDE payload` clause. While specific columns (`v1`, `v2`) are defined, the `payload` column captures the entire JSON object, enabling flexible schema handling during runtime. It configures the Kinesis connector, topic, message queue server, and scan startup behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'kinesis',\n    topic = 'kinesis_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Granting Table Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet grants table-level privileges (SELECT, UPDATE, INSERT, DELETE, or ALL) to a user for specific tables or all tables in one or more schemas. Parameters: valid table names, schemas, user names; supports WITH GRANT OPTION and GRANTED BY. Outputs: privileges assigned to the user for the designated tables. Limitations: object must be a table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT {{SELECT | UPDATE | INSERT | DELETE} [, ...]| ALL [PRIVILEGES]}\nON { TABLE table_name [, ...]\n    | ALL TABLES IN SCHEMA schema_name [, ...] }\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: Command to connect to the RisingWave database using psql.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Defining a Nested Message in Protobuf\nDESCRIPTION: This snippet demonstrates how to define a nested message structure in Protobuf, which will be converted to a struct type in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/supported-protobuf-types.mdx#2025-04-23_snippet_0\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage NestedMessage {\n  int32 id = 1;\n  string name = 2;\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Trade Data Table in SQL\nDESCRIPTION: Creates a table to store trade data including trade ID, asset ID, timestamp, price, volume, buyer ID, and seller ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-trade-surveillance.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE trade_data (\n    trade_id INT,\n    asset_id INT,\n    timestamp TIMESTAMPTZ,\n    price NUMERIC,\n    volume INT,\n    buyer_id INT,\n    seller_id INT\n);\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Example Table in PostgreSQL - SQL\nDESCRIPTION: Shows how to create a sample table 'test' with two columns (id, x) and populate it with incremental data using a generate_series in PostgreSQL. These setup commands should be run on the PostgreSQL source instance prior to data retrieval with RisingWave. The test data provides a suitable basis for illustrating downstream integration and query functionality.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test (id bigint primary key, x int);\nINSERT INTO test SELECT id, id::int FROM generate_series(1, 100) AS t(id);\n```\n\n----------------------------------------\n\nTITLE: Defining postgres_query TVF Syntax - SQL\nDESCRIPTION: Specifies the complete signature and required parameters for the postgres_query table-valued function in SQL. Each parameter must be provided to establish the connection and query the target PostgreSQL database. This snippet should be consulted when configuring your RisingWave queries for one-off or ad hoc fetches from remote PostgreSQL instances.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\npostgres_query(\n    hostname varchar,      -- Database hostname\n    port varchar,          -- Database port\n    username varchar,      -- Authentication username\n    password varchar,      -- Authentication password\n    database_name varchar, -- Target database name\n    query varchar          -- SQL query to execute\n)\n```\n\n----------------------------------------\n\nTITLE: Checking User Table Privileges\nDESCRIPTION: SQL query to verify table privileges granted to a specific user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\npostgres=# SELECT table_name, grantee, privilege_type\nFROM information_schema.role_table_grants\nWHERE  grantee='<username>';\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave via Docker\nDESCRIPTION: Command to start RisingWave in a Docker container. It maps ports 4566 and 5691 from the container to the host system and runs RisingWave in single_node mode.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:latest single_node\n```\n\n----------------------------------------\n\nTITLE: Dropping a Function by Full Signature in SQL\nDESCRIPTION: Illustrates how to drop a specific user-defined function by providing its full signature, including the function name and the data types of its arguments. This method is necessary when multiple functions share the same name (overloading).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION function_name ( argument_type [, ...] );\n```\n\n----------------------------------------\n\nTITLE: Append-only Process-Time Temporal Join Syntax in SQL\nDESCRIPTION: Demonstrates the syntax for creating an append-only process-time temporal join in RisingWave. This type of join is used for widening fact tables without maintaining join state, suitable when dimension tables are not updated or when updates don't affect previous join results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ... FROM <table_expression> [AS <alias>]\n[ LEFT | INNER ] JOIN <table_expression> FOR SYSTEM_TIME AS OF PROCTIME() [AS <alias>]\nON <join_conditions>;\n```\n\n----------------------------------------\n\nTITLE: Creating a Scalar Python UDF in SQL\nDESCRIPTION: Demonstrates how to create a scalar Python UDF named 'gcd' that calculates the greatest common divisor of two integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE FUNCTION gcd(a int, b int) RETURNS int LANGUAGE python AS $$\ndef gcd(a, b):\n    while b != 0:\n        a, b = b, a % b\n    return a\n$$;\n```\n\n----------------------------------------\n\nTITLE: Creating a CDC Table for All Collections in a MongoDB Database in RisingWave SQL\nDESCRIPTION: Provides an example for setting up a RisingWave streaming table that captures changes from every collection within a specified MongoDB database using a wildcard pattern. Specifies required connector and connection parameters, such as replica set URI and collection pattern. Suitable for centralized ingestion of an entire MongoDB database's CDC streams into RisingWave. Results in a streaming table with each change event.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mongodb-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE source_name (\n   _id varchar PRIMARY KEY,\n   payload jsonb\n) WITH (\n   connector='mongodb-cdc',\n   mongodb.url='mongodb://localhost:27017/?replicaSet=rs0',\n   collection.name='dev.*'\n);\n\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Glue Schema Registry in SQL ENCODE AVRO Clause\nDESCRIPTION: Provides an example snippet showing configuration parameters within the `ENCODE AVRO (...)` clause of a `CREATE SOURCE` or `CREATE TABLE` statement in RisingWave SQL. These parameters are used to connect to and authenticate with AWS Glue Schema Registry to retrieve Avro schemas, specifying the schema ARN, AWS region, and credential details (access key/secret key or IAM role ARN).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nENCODE AVRO (\n  aws.glue.schema_arn = 'arn:aws:glue:ap-southeast-1:123456123456:schema/default-registry/MyEvent',\n  aws.region = 'US-WEST-2',\n  aws.credentials.access_key_id = 'your_access_key_id',\n  aws.credentials.secret_access_key = 'your_secret_access_key',\n  aws.credentials.role.arn = 'arn:aws:iam::123456123456:role/MyGlueRole'\n  ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Pulsar Source/Table with JSON Format and Defined Schema (SQL)\nDESCRIPTION: This SQL statement creates a RisingWave source or table named 'source_abc' with predefined columns ('column1', 'column2') to read JSON data from a Pulsar topic 'demo_topic'. It configures the 'pulsar' connector, service URL, OAuth authentication, AWS credentials, and scan startup mode. The data format is specified as PLAIN ENCODE JSON, expecting incoming messages to conform to the defined table schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='pulsar',\n   topic='demo_topic',\n   service.url='pulsar://localhost:6650/',\n   oauth.issuer.url='https://auth.streamnative.cloud/',\n   oauth.credentials.url='s3://bucket_name/your_key_file.file',\n   oauth.audience='urn:sn:pulsar:o-d6fgh:instance-0',\n   aws.credentials.access_key_id='aws.credentials.access_key_id',\n   aws.credentials.secret_access_key='aws.credentials.secret_access_key',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with NATS JetStream Source in RisingWave (SQL)\nDESCRIPTION: This SQL snippet creates a table 'live_stream_metrics' in RisingWave that ingests data from a NATS JetStream source. It specifies details such as the NATS server, subject, stream, connection mode, and data encoding format (PROTOBUF), along with the Protobuf message and schema location. Requires the NATS JetStream service, RisingWave with enabled source connector, and appropriate schema definitions. The main parameters configure the connection and data decoding; outputs are inserted into the newly created table for downstream queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/nats-jetstream.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE live_stream_metrics\nWITH\n  (\n    connector = 'nats',\n    server_url = 'nats-server:4222',\n    subject = 'live_stream_metrics',\n    stream = 'risingwave',\n    connect_mode = 'plain'\n  ) FORMAT PLAIN ENCODE PROTOBUF (\n    message = 'livestream.schema.LiveStreamMetrics',\n    schema.location = 'http://file_server:8080/schema'\n  );\n```\n\n----------------------------------------\n\nTITLE: Deleting a Specific Row with RETURNING (SQL)\nDESCRIPTION: Demonstrates deleting a specific row from the `taxi_trips` table where the `id` column equals 3. It utilizes the `WHERE` clause for conditional deletion and the `RETURNING id` clause to output the `id` of the row that was removed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM taxi_trips\nWHERE id = 3\nRETURNING id;\n```\n\n----------------------------------------\n\nTITLE: Example: Changing Table Owner using ALTER TABLE in SQL\nDESCRIPTION: Illustrates how to use the `ALTER TABLE OWNER TO` command. This specific example changes the owner of the table named `t` to the user named `user1`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Change the owner of the table named \"t\" to the user \"user1\"\nALTER TABLE t OWNER TO user1;\n```\n```\n\n----------------------------------------\n\nTITLE: Verifying Secret Masking with SHOW CREATE SOURCE in SQL\nDESCRIPTION: Executes the `SHOW CREATE SOURCE` command for the source `mysql_source`, which was created using a secret for the password. The accompanying result comment shows that the password field displays `secret mysql_pwd` instead of the actual secret value, confirming that RisingWave successfully masks the sensitive credential when displaying the source definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-secret.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SOURCE mysql_source;\n\n---RESULT\n--- public.mysql_mydb | CREATE SOURCE mysql_mydb WITH (connector = 'mysql-cdc', hostname = 'mysql', port = '3306', username = 'root', password = secret mysql_pwd, database.name = 'mydb', server.id = '2') FORMAT PLAIN ENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Example: Creating and Querying a Table from SQL Server CDC Source in RisingWave (SQL)\nDESCRIPTION: This example demonstrates creating a RisingWave table named `mytable` with columns `v1` (primary key) and `v2`. It sources data from a previously defined `mssql_source` linked to the `dbo.mytable` table in SQL Server. It then shows a sample query `SELECT * FROM t2 ORDER BY v1;` (assuming `t2` is the table name used in practice, potentially a typo for `mytable`) and example results including ingested data and commit timestamps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE mytable (v1 int PRIMARY KEY, v2 varchar)\nFROM mssql_source TABLE 'dbo.mytable';\n\nSELECT * FROM t2 ORDER BY v1;\n\n----RESULT\n v1 | v2 |         commit_ts\n----+----+---------------------------\n  1 | aa | 1970-01-01 00:00:00+00:00\n  2 | bb | 1970-01-01 00:00:00+00:00\n  3 | cc | 2024-05-20 09:01:08+00:00\n  4 | dd | 2024-05-20 09:01:08+00:00\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with Upsert JSON Format in SQL\nDESCRIPTION: Defines a RisingWave table `source_abc` connected to Kafka topic `t1` using specified bootstrap servers. It handles upsert operations based on the primary key `rw_key`, which is derived from the Kafka message key. The message payload is expected in JSON format and parsed into `column1` and `column2`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n   primary key (rw_key)\n)\ninclude key as rw_key\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='t1'\n) FORMAT UPSERT ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Hopping Window Aggregation with SQL - SQL\nDESCRIPTION: Uses the HOP function in SQL to aggregate the number of trips and total distance within 2-minute windows, sliding forward every minute. Requires a table 'taxi_trips' with at least 'completed_at', 'trip_id', and 'distance' columns. Returns window start/end timestamps, trip counts, and total distances per window, ordered by window_start. Assumes RisingWave or compatible SQL that supports hopping windows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT window_start, window_end, count(trip_id) AS no_of_trips, sum(distance) AS total_distance\\nFROM HOP (taxi_trips, completed_at, INTERVAL '1 MINUTES', INTERVAL '2 MINUTES')\\nGROUP BY window_start, window_end\\nORDER BY window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Glue Catalog Iceberg Sink in SQL\nDESCRIPTION: This example shows how to create an Iceberg sink using AWS Glue catalog. It includes configurations for S3 storage, AWS credentials, and table details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink_test FROM t\nWITH (\n      type='upsert',\n      primary_key='col',\n      connector = 'iceberg',\n      catalog.type = 'glue',\n      catalog.name = 'test',\n      warehouse.path = 's3://my-iceberg-bucket/test',\n      s3.access.key = 'xxxxxxxxxx',\n      s3.secret.key = 'xxxxxxxxxx',\n      s3.region = 'ap-southeast-2',\n      database.name='test_db',\n      table.name='test_table'\n  );\n```\n\n----------------------------------------\n\nTITLE: Using BACKGROUND_DDL for Materialized View Creation in SQL\nDESCRIPTION: Complete example demonstrating how to create a table, populate it with data, enable background DDL, and create a materialized view that processes in the background without blocking.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-background-ddl.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (v1 int);\n\nINSERT INTO t SELECT * FROM generate_series(1, 1000000);\n\nSET BACKGROUND_DDL=true;\n\nCREATE MATERIALIZED VIEW m AS SELECT * FROM t;\n-- The \"CREATE_MATERIALIZED_VIEW\" response will be returned immediately.\n```\n\n----------------------------------------\n\nTITLE: Creating a Channel Attribution Materialized View in SQL\nDESCRIPTION: Creates a materialized view that analyzes marketing channel performance over 1-hour time windows. It groups data by time window and channel attributes to calculate metrics like unique users, conversions, revenue, and average order value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW channel_attribution AS\nSELECT\n    window_start,\n    window_end,\n    channel_type,\n    utm_source,\n    utm_medium,\n    COUNT(DISTINCT user_id) as unique_users,\n    COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN event_id END) as conversions,\n    SUM(CASE WHEN event_type = 'conversion' THEN amount ELSE 0 END) as revenue,\n    SUM(CASE WHEN event_type = 'conversion' THEN amount ELSE 0 END) /\n        NULLIF(COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN event_id END), 0) as avg_order_value\nFROM TUMBLE(marketing_events, timestamp, INTERVAL '1 HOUR')\nGROUP BY\n    window_start,\n    window_end,\n    channel_type,\n    utm_source,\n    utm_medium;\n```\n\n----------------------------------------\n\nTITLE: Example of using percentile_disc in SQL\nDESCRIPTION: Calculates the 75th percentile of values in column1 from table1 using the WITHIN GROUP clause and ORDER BY for the percentile calculation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT percentile_disc(0.75) WITHIN GROUP (ORDER BY column1) FROM table1;\n```\n\n----------------------------------------\n\nTITLE: Dropping a Source in the Default Schema in SQL\nDESCRIPTION: Shows how to remove a source named 'rw_source' from the default ('public') schema in the database. This command is used when no dependent objects exist or have already been dropped, and does not specify conditional or cascade behavior. No additional dependencies are needed, but ensure the source exists before execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-source.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SOURCE rw_source;\n\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave with Docker - Shell Command\nDESCRIPTION: This shell command runs a specific version of RisingWave inside a Docker container. It pulls the 'risingwavelabs/risingwave:v1.4.0' image, binds ports 4566 and 5691 from the container to the host, and starts the server in 'playground' mode. Dependencies: Docker must be installed and the specified image reachable from the registry. Parameters: '-it' for interactive mode, '--pull=always' to ensure latest image, '-p' for port mapping. Input: Run command in terminal; Output: Running RisingWave instance. Ensure ports 4566 and 5691 are available on host.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.4.0 playground\n```\n\n----------------------------------------\n\nTITLE: Defining a Table with Kafka Connector in dbt Using SQL\nDESCRIPTION: This snippet defines a dbt table model in SQL that connects to Kafka for data ingestion in RisingWave. It uses dbt's config macro for custom materialization, sets up the stream connector and encoding, and specifies the schema for the table. Dependencies include a running Kafka instance and proper dbt integration with RisingWave. The config macro is essential for deployment and the table is ready to receive and process JSON-encoded data from the specified Kafka topic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n```sql Define a table with connector settings in dbt\n\n{{ config(materialized='table_with_connector') }}\nCREATE TABLE {{ this }} (v1 int, v2 varchar) WITH (\n  connector = 'kafka',\n  topic = 'kafka_1_partition_topic',\n  properties.bootstrap.server = 'message_queue:29092',\n  scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON\n\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for TCP Metrics in RisingWave\nDESCRIPTION: SQL statement to create a source for TCP performance metrics from a Kafka topic. The source defines the schema for ingesting metrics data including device ID, metric name, and performance values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE tcp_metrics (\n    device_id VARCHAR,\n    metric_name VARCHAR,\n    report_time TIMESTAMP WITH TIME ZONE,\n    metric_value DOUBLE PRECISION\n) WITH (\n    connector = 'kafka',\n    topic = 'tcp_metrics',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Granting MySQL Replication Privileges\nDESCRIPTION: SQL command to grant necessary permissions (SELECT, REPLICATION SLAVE, REPLICATION CLIENT) across all databases (*.*) to the designated MySQL user ('user'@'%') for CDC operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'user'@'%';\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL CDC Source with Auto Schema Change in RisingWave\nDESCRIPTION: SQL command to create a MySQL CDC source in RisingWave with auto schema change enabled. This configuration allows RisingWave to automatically adapt to schema changes in the source MySQL database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE mysql_source WITH (\n connector = 'mysql-cdc',\n hostname = 'localhost',\n port = '3306',\n username = 'root',\n password = 'your_password',\n database.name = 'mytest',\n server.id = '5701',\n auto.schema.change = 'true'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with Upsert JSON Encoding in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka table in RisingWave using Upsert JSON encoding. It includes the key as a separate column and specifies it as the primary key, along with JSON encoding details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n   primary key (rw_key)\n)\nINCLUDE key AS rw_key\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='t1'\n) FORMAT UPSERT ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Source Rate Limit in SQL\nDESCRIPTION: SQL command to create a materialized view with a specified source rate limit to prevent OOM issues during creation with large amounts of existing data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/troubleshoot/troubleshoot-oom.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv WITH ( source_rate_limit = 200 ) AS ...\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave PostgreSQL CDC Source (SQL)\nDESCRIPTION: This SQL syntax example shows how to create a CDC source in RisingWave. It uses the built-in `postgres-cdc` connector and requires connection parameters (like host, port, username, password, database name, schema name, table name) specific to the source PostgreSQL database. This source definition allows RisingWave to connect and listen for changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name WITH (\n   connector='postgres-cdc',\n   <field>=<value>, ...\n);\n```\n\n----------------------------------------\n\nTITLE: Using array_to_string and array_join Functions in SQL\nDESCRIPTION: Converts an array to a string with elements separated by a delimiter. The null_string parameter specifies how NULL elements are represented.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\narray_to_string ( array, delimiter_string, null_string ) → string\n\narray_join(array, delimiter_string, null_string) → string\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_to_string (array[1, 2, 3, NULL, 5], ',', '*') → 1,2,3,*,5\n\narray_join(array[1, 2, 3, NULL, 5], ',', '*') → 1,2,3,*,5\n```\n\n----------------------------------------\n\nTITLE: Declaring External User-Defined Functions - SQL\nDESCRIPTION: Demonstrates how to declare an external user-defined function (UDF) in RisingWave using the CREATE FUNCTION SQL command. Dependencies include a running UDF server (address specified in the USING LINK clause) that exposes the required function. This snippet defines a scalar function 'gcd' accepting two integers and returning an integer by referencing its implementation in the external UDF server. Parameters are input types and server address; output is a scalar integer. The function is available in SQL queries after declaration, and address changes may be necessary for Docker environments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-function.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION gcd(int, int) RETURNS int\nAS gcd\nUSING LINK 'http://localhost:8815'; -- If you are running RisingWave using Docker, replace the address with 'http://host.docker.internal:8815'.\n```\n\n----------------------------------------\n\nTITLE: Creating MQTT Source Table in RisingWave SQL\nDESCRIPTION: This SQL query creates a source table in RisingWave to ingest data from the EMQX MQTT broker. It defines the table schema and specifies the connection details for the MQTT broker.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/emqx.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE shop_floor_machine_data (\n    machine_id VARCHAR,\n    winding_temperature INT,\n    ambient_temperature INT,\n    vibration_level FLOAT,\n    current_draw FLOAT,\n    voltage_level FLOAT,\n    nominal_speed FLOAT, \n    power_consumption FLOAT,\n    efficiency FLOAT,\n    ts TIMESTAMP\n)\nWITH (\n    connector='mqtt',\n    url='ssl://xxxxxxxxx.us-east-1.emqxsl.com:8883',\n    topic= 'factory/machine_data',\n    username='xxxxxx',\n    password='xxxxxx',\n    qos = 'at_least_once'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a PostgreSQL CDC Source in RisingWave SQL\nDESCRIPTION: This SQL example creates a CDC source in RisingWave to ingest real-time changes from a PostgreSQL database ('mydb'). The statement specifies connector type ('postgres-cdc'), database connection parameters (hostname, port, username, password), and CDC slot configuration. The data format is always Debezium JSON and does not require explicit specification. The resulting source can be referenced in subsequent CDC table definitions for streaming ingestion.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE pg_mydb WITH (\n    connector = 'postgres-cdc',\n    hostname = '127.0.0.1',\n    port = '8306',\n    username = 'root',\n    password = '123456',\n    database.name = 'mydb',\n    slot.name = 'mydb_slot'\n);\n```\n\n----------------------------------------\n\nTITLE: Defining a Database Schema - SQL\nDESCRIPTION: This snippet provides the general syntax for the CREATE DATABASE command in SQL, as used in RisingWave. It outlines optional clauses such as IF NOT EXISTS to prevent errors on duplicates, owner assignment, and resource group specification for advanced management. No actual inputs are required for the syntax itself; instead, placeholders like database_name should be replaced with user-supplied values. Requires RisingWave SQL compatibility and, for resource_group, Premium Edition access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-database.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE [ IF NOT EXISTS ] database_name\n    [ WITH ] [ owner [=] user_name ]\n    [ resource_group [=] resource_group_name ];\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Protobuf Format using S3 Schema Location in SQL\nDESCRIPTION: Creates a RisingWave source `source_abc` connected to Kafka topic `demo_topic`. It reads Protobuf encoded messages, specifying the message structure (`package.message_name`). The Protobuf schema (`.pb` file compiled using `protoc`) is fetched from an S3 location, requiring AWS credentials (access key, secret key) for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE PROTOBUF (\n   message = 'package.message_name',\n   access_key = 'your_access_key',\n   secret_key = 'your secret_key',\n   -- compiled from protoc\n   location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/schema_descriptor.pb'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source in RisingWave (SQL)\nDESCRIPTION: This SQL statement creates a source named 'website_visits_stream' in RisingWave. It defines the schema (timestamp, user_id, page_id, action) and configures the connection to a Kafka topic ('demo-stream') running on 'localhost:9092' (presumably provided by WarpStream playground). It specifies the 'kafka' connector, reads data from the 'earliest' offset, and expects messages in JSON format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS website_visits_stream (\n timestamp timestamp,\n user_id varchar,\n page_id varchar,\n action varchar\n )\nWITH (\n connector='kafka',\n topic='demo-stream',\n properties.bootstrap.server='localhost:9092',\n scan.startup.mode='earliest'\n ) ROW FORMAT JSON;\n```\n\n----------------------------------------\n\nTITLE: Example Workflow: Verifying Secret Usage with SHOW CREATE SOURCE in RisingWave SQL\nDESCRIPTION: This is the final part of the example workflow. It uses the `SHOW CREATE SOURCE` command to display the definition of `mysql_source`. The output demonstrates that the password field references the secret (`secret mysql_pwd`) instead of exposing the actual password, confirming the secure handling of the credential.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SOURCE mysql_source;\n\n---RESULT\n--- public.mysql_mydb | CREATE SOURCE mysql_mydb WITH (connector = 'mysql-cdc', hostname = 'mysql', port = '3306', username = 'root', password = secret mysql_pwd, database.name = 'mydb', server.id = '2') FORMAT PLAIN ENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Using SHOW INDEXES Command in RisingWave SQL\nDESCRIPTION: Example showing how to use the SHOW INDEXES command to view all indexes on the table 't3', which will display the index name, table name, key columns, included columns, and distribution information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-indexes.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INDEXES FROM t3;\n```\n\n----------------------------------------\n\nTITLE: Using array_replace Function in SQL\nDESCRIPTION: Returns an array with all occurrences of the current element replaced with the new element. Supports multidimensional arrays with some limitations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\narray_replace ( array, current_element, new_element ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_replace(array[7, null, 8, null], null, 0.5) → {7,0.5,8,0.5}\n```\n\n----------------------------------------\n\nTITLE: Using unnest Function in SQL\nDESCRIPTION: Expands an array or combination of arrays into a set of rows. Elements are output in the order they are stored in the array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nunnest ( array ) → set_of_any_element\n```\n\nLANGUAGE: sql\nCODE:\n```\nunnest(Array[Array[1,3,4,5],Array[2,3]]) →\n1\n3\n4\n5\n2\n3\n```\n\n----------------------------------------\n\nTITLE: Setting Sink Parallelism using ALTER SINK in SQL\nDESCRIPTION: Illustrates how to control the degree of parallelism for the streaming job associated with the sink using the `SET PARALLELISM` clause. The `parallelism_number` can be 'ADAPTIVE' (or 0) to use all available units, or a fixed positive integer to lock the parallelism.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\nSET PARALLELISM { TO | = } parallelism_number;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the parallelism of the sink \"s\" to 4.\nALTER SINK s SET PARALLELISM = 4;\n```\n\n----------------------------------------\n\nTITLE: Defining a Materialized View with Aggregations in dbt Using SQL\nDESCRIPTION: This snippet demonstrates how to create a materialized view in RisingWave using dbt and SQL, aggregating and grouping bid data per day and per auction. It uses dbt's materialized_view config and aggregates with filters on price ranges, providing analytics like total bids, bid rankings, min, max, avg, and sum of prices. Requires a pre-existing 'bid' table/model, appropriate syntax for SQL grouping and filters, and proper dbt-ref usage.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n```sql Define a materialized view in dbt\n{{ config(materialized='materialized_view') }}\nSELECT\n    auction,\n    to_char(date_time, 'YYYY-MM-DD') AS day,\n    count(*) AS total_bids,\n    count(*) filter (where price < 10000) AS rank1_bids,\n    count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,\n    count(*) filter (where price >= 1000000) AS rank3_bids,\n    min(price) AS min_price,\n    max(price) AS max_price,\n    avg(price) AS avg_price,\n    sum(price) AS sum_price\nFROM {{ ref('bid') }}\nGROUP BY auction, to_char(date_time, 'YYYY-MM-DD')\n\n```\n```\n\n----------------------------------------\n\nTITLE: Checking Current Binlog Offset in MySQL\nDESCRIPTION: SQL command to check the current binlog offset in MySQL. This is used to compare with the source offset stored in RisingWave to determine CDC progress.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW MASTER STATUS;\n```\n\n----------------------------------------\n\nTITLE: Querying the Table After Insertion in RisingWave SQL\nDESCRIPTION: Example SQL query using `SELECT *` to retrieve all columns and rows from the `taxi_trips` table. This is typically used after an `INSERT` operation to verify that the data was added correctly. The `ORDER BY id` clause sorts the results based on the `id` column for predictable output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM taxi_trips ORDER BY id;\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Named Parameters\nDESCRIPTION: Demonstrates creating a SQL UDF using named parameters for better readability.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_named(a INT, b INT) returns int language sql as 'select a + b';\n```\n\n----------------------------------------\n\nTITLE: Creating Recursive SQL UDF\nDESCRIPTION: This snippet demonstrates creating a SQL UDF with a recursive corner case, where the function returns a string representation of its signature.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\ncreate function foo(INT) returns varchar language sql as $$select 'foo(INT)'$$;\n```\n\n----------------------------------------\n\nTITLE: Creating a ClickHouse Table with ReplacingMergeTree Engine\nDESCRIPTION: SQL command to create a ClickHouse table with a primary key and ReplacingMergeTree engine. This setup helps prevent duplicate writes during RisingWave recovery.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE demo_test(\n    seq_id Int32,\n    user_id Int32,\n    user_name String\n) ENGINE = ReplacingMergeTree\nPRIMARY KEY (seq_id);\n```\n\n----------------------------------------\n\nTITLE: Setting Materialized View Parallelism Syntax in SQL\nDESCRIPTION: Provides the syntax for controlling the degree of parallelism for the streaming job associated with the materialized view using the `SET PARALLELISM` clause. `parallelism_number` can be `ADAPTIVE` or a fixed integer (0 is equivalent to `ADAPTIVE`).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW materialized_view_name\nSET PARALLELISM { TO | = } parallelism_number;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from GCS JSON Data in RisingWave SQL\nDESCRIPTION: This SQL example shows how to create a RisingWave table sourcing data from JSON files in Google Cloud Storage. It defines the table schema, configures the GCS connector with bucket name and credentials, and uses `match_pattern` to specify which files (e.g., ending in `.ndjson` and containing 'Ring') should be ingested. It uses `FORMAT PLAIN ENCODE JSON`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(\n    id int,\n    name TEXT,\n    age int,\n    mark int,\n)\nWITH (\n    connector = 'gcs',\n    gcs.bucket_name = 'example-bucket',\n    gcs.credential = 'xxxxx'\n    match_pattern = '%Ring%*.ndjson',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining taxi_trips Table Schema in YAML\nDESCRIPTION: This YAML snippet defines the schema for the taxi_trips table, including columns for id, distance, duration, and fare.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n{\n  \"id\": VARCHAR,\n  \"distance\": DOUBLE PRECISION,\n  \"duration\": DOUBLE PRECISION,\n  \"fare\": DOUBLE PRECISION\n}\n```\n\n----------------------------------------\n\nTITLE: Using last_value function in SQL\nDESCRIPTION: Returns the last value in an ordered set of values, including nulls. Requires ORDER BY clause to make results deterministic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nlast_value ( expression ORDER BY order_key ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Specifying PrivateLink Targets for Kafka Brokers in JSON\nDESCRIPTION: This JSON snippet demonstrates how to specify PrivateLink targets (port mappings) for Kafka brokers. The order of the targets must match the order of brokers in the 'properties.bootstrap.server' configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka-config.mdx#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n'[{\"port\": 9094}, {\"port\": 9095}]'\n```\n\n----------------------------------------\n\nTITLE: Kafka Connection Example Using CREATE TABLE in SQL\nDESCRIPTION: An example of connecting to a Kafka topic using the CREATE TABLE command in RisingWave. This example creates a table that ingests data from a Kafka topic named 'user_activity' with JSON encoding and defines a primary key on the user_id column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/connect-with-create-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE my_kafka_table (\n    user_id INT,\n    product_id VARCHAR,\n    timestamp TIMESTAMP,\n    PRIMARY KEY (user_id)\n) WITH (\n    connector='kafka',\n    topic='user_activity',\n    properties.bootstrap.server='broker1:9092,broker2:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave Docker Container\nDESCRIPTION: Docker command to run the RisingWave playground container with exposed ports\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_41\n\nLANGUAGE: bash\nCODE:\n```\nrun -it --pull=always -p 4566:4566 -p 5691:5691 ghcr.io/risingwavelabs/risingwave:v0.1.11 playground\n```\n\n----------------------------------------\n\nTITLE: Creating Embedded Rust User-Defined Functions - SQL/Rust\nDESCRIPTION: Shows how to define an embedded Rust UDF in RisingWave using the CREATE FUNCTION SQL command with Rust source code inlined. Requires RisingWave compiled with Rust embedded function support. The example implements the classic 'gcd' function for two integers and returns their greatest common divisor. Input values are two integers, and the logic is defined in a Rust function within the $$ block.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-function.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Embedded Rust UDF\nCREATE FUNCTION gcd(int, int) RETURNS int LANGUAGE rust AS $$\n    fn gcd(mut a: i32, mut b: i32) -> i32 {\n        while b != 0 {\n            let t = b;\n            b = a % b;\n            a = t;\n        }\n        a\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Creating Real-Time Bid Predictions View with UDF in SQL\nDESCRIPTION: This snippet creates a materialized view that uses a custom prediction function (PREDICT_BID) to generate real-time bid predictions based on the feature vectors calculated from streaming bidding data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW live_predictions AS\n  SELECT\n    ad_id,\n    PREDICT_BID(avg_bid, max_bid, bid_count, win_rate, avg_response_time) AS predicted_bid\n  FROM bidding_feature_vectors;\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only Sink to Snowflake in RisingWave\nDESCRIPTION: Example of creating an append-only sink in RisingWave that sends data to Snowflake. This sink configuration includes S3 parameters for staging data before loading into Snowflake.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK snowflake_sink FROM ss_mv WITH (\n    connector = 'snowflake',\n    type = 'append-only',\n    s3.bucket_name = 'EXAMPLE_S3_BUCKET',\n    s3.credentials.access = 'EXAMPLE_AWS_ACCESS',\n    s3.credentials.secret = 'EXAMPLE_AWS_SECRET',\n    s3.region_name = 'EXAMPLE_REGION',\n    s3.path = 'EXAMPLE_S3_PATH',\n    force_append_only = 'true'\n);\n```\n\n----------------------------------------\n\nTITLE: Using percentile_cont function in SQL\nDESCRIPTION: Computes continuous percentile value, which can interpolate between adjacent input items if needed. Not supported for streaming queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\npercentile_cont ( fraction double precision ) WITHIN GROUP ( ORDER BY sort_expression double precision ) -> double precision\n```\n\n----------------------------------------\n\nTITLE: Converting JSON Path Values to Text with jsonb_extract_path_text\nDESCRIPTION: Function that extracts and converts JSON sub-objects to text at specified paths.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_extract_path_text('{\"f2\":{\"f3\":1},\"f4\":{\"f5\":99,\"f6\":\"string\"}}', 'f4', 'f6');\nSELECT jsonb_extract_path_text('{\"a\": {\"b\": [\"foo\",\"bar\"]}}', variadic array['a', 'b', '1']);\n```\n\n----------------------------------------\n\nTITLE: Canceling Multiple Jobs by ID\nDESCRIPTION: Demonstrates how to cancel multiple running jobs using the CANCEL JOBS command with specific job IDs. Returns the IDs of successfully canceled jobs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-statement-progress.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL JOBS 1010, 1012;\n------RESULT\nId\n------\n 1012\n 1010\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave-Operator Repository (Bash)\nDESCRIPTION: Clones the RisingWave-Operator GitHub repository, which contains the monitoring stack and deployment scripts, to your local environment. Requires bash and Git to be installed. The main input is the public repository URL, and the command outputs a local folder containing all files. No configuration needed; supports further monitoring deployment steps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave-operator.git\n```\n\n----------------------------------------\n\nTITLE: Date and Time Type Examples in RisingWave SQL\nDESCRIPTION: Examples of date and timestamp literal syntax in RisingWave SQL, showing proper formatting for different temporal types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ndate '2022-04-08'\ntime '18:20:49'\n'2022-03-13 01:00:00'::timestamp\n'2022-03-13 01:00:00Z'::timestamptz\n```\n\n----------------------------------------\n\nTITLE: Swapping Two Source Names in RisingWave SQL\nDESCRIPTION: This command is used to exchange the names of two sources using the SWAP WITH clause. Both the current and target source names must exist. Swapping source names affects only metadata, not the underlying source data or configuration. Useful for zero-downtime source replacement scenarios.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE name\nSWAP WITH target_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Swap the names of the api_data source and the file_data source.\nALTER SOURCE api_data\nSWAP WITH file_data;\n```\n\n----------------------------------------\n\nTITLE: Including Kafka Headers in SQL\nDESCRIPTION: Shows two approaches to include Kafka header information. The first generates headers as a list of structs, while the second extracts a specific header value by key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE header [AS kafka_header]\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View with Temporal Filter for Data Expiration (Sales)\nDESCRIPTION: Demonstrates creating a RisingWave source and a materialized view (`sales`) that uses a temporal filter (`sale_date > NOW() - INTERVAL '7 days'`). This filter ensures that the materialized view only retains sales records from the last 7 days, automatically deleting older records to manage storage space.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE sales_source(...) with (connector = 'kafka', ...) FORMAT PLAIN ENCODE JSON;\n\nCREATE MATERIALIZED VIEW sales AS\nSELECT *\nFROM sales_source\nWHERE sale_date > NOW() - INTERVAL '7 days';\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave MySQL CDC Source\nDESCRIPTION: RisingWave SQL syntax for defining a data source that connects to MySQL using the native 'mysql-cdc' connector. This command requires specifying connection details and other relevant parameters within the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name WITH (\n   connector='mysql-cdc',\n   <field>=<value>, ...\n);\n```\n\n----------------------------------------\n\nTITLE: Altering Table Schema and Updating SINK Job in RisingWave - SQL\nDESCRIPTION: This sequence alters the m1_store table to add a new column (max), stops the current sink (DROP SINK) and creates an updated sink that writes both count and max aggregate results. The updated streaming logic demonstrates dynamic schema evolution with SINK INTO TABLE. Inputs: altered table; outputs: updated streamed data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE m1_store ADD COLUMN max int DEFAULT 0;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP SINK m1_stream;\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK m1_stream INTO m1_store AS SELECT 1 as key, count(*) as cnt, max(v1) as max from t;\n```\n\n----------------------------------------\n\nTITLE: Creating Comprehensive Enriched Market Data View in SQL\nDESCRIPTION: Creates a materialized view that combines transformed market data with enrichment data, providing a holistic view of each asset for informed decision-making.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW enriched_market_data AS\nSELECT\n    bas.asset_id,\n    ed.sector,\n    bas.average_price,\n    bas.bid_ask_spread,\n    rv.rolling_volatility,\n    ed.avg_historical_volatility,\n    ed.avg_sector_performance,\n    ed.avg_sentiment_score,\n    rv.window_end\nFROM\n    avg_price_bid_ask_spread AS bas\nJOIN\n    rolling_volatility AS rv\nON\n    bas.asset_id = rv.asset_id AND\n    bas.window_end = rv.window_end\nJOIN (\n    SELECT asset_id,\n        sector,\n        window_end, \n        AVG(historical_volatility) AS avg_historical_volatility,\n        AVG(sector_performance) AS avg_sector_performance,\n        AVG(sentiment_score) AS avg_sentiment_score\n    FROM TUMBLE(enrichment_data, timestamp, '5 minutes')\n    GROUP BY asset_id, sector, window_end\n) AS ed\nON bas.asset_id = ed.asset_id AND\n   bas.window_end = ed.window_end;\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Binary Log Settings\nDESCRIPTION: Configuration settings to be added to the MySQL server configuration file (e.g., my.cnf or my.ini) to enable and configure binary logging for CDC. Requires setting a unique server-id, enabling the log (`log_bin`), setting the format to `ROW`, the row image format to `FULL`, and configuring log retention.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\nserver-id         = 223344\nlog_bin           = mysql-bin\nbinlog_format     = ROW\nbinlog_row_image  = FULL\nexpire_logs_days  = 10\n```\n\n----------------------------------------\n\nTITLE: Conditionally Dropping a Schema-Specific Sink - SQL\nDESCRIPTION: Demonstrates the use of DROP SINK IF EXISTS in SQL to remove the 'rw_sink' from the 'rw_schema' schema only if it exists, preventing errors if the sink does not exist. It uses schema qualification and the IF EXISTS clause for safer execution in database migrations or scripts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-sink.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP SINK IF EXISTS rw_schema.rw_sink;\n```\n\n----------------------------------------\n\nTITLE: Interval Type Examples in RisingWave SQL\nDESCRIPTION: Examples of interval literal syntax showing different time unit specifications and formats.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ninterval '4 hour'\ninterval '3 day'\ninterval '04:00:00.1234'\n```\n\n----------------------------------------\n\nTITLE: Querying Channel Attribution Results in SQL\nDESCRIPTION: A simple query to retrieve the first 5 records from the channel_attribution materialized view, showing marketing performance metrics for different channels.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM channel_attribution LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating an Async JavaScript UDF in RisingWave SQL\nDESCRIPTION: This snippet illustrates how to create an asynchronous JavaScript UDF named 'fetch_weather' that makes an API call. It demonstrates the use of async/await and the 'WITH' clause to enable asynchronous execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-javascript.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION fetch_weather(city varchar) \nRETURNS varchar \nLANGUAGE javascript \nAS $$\nexport async function fetch_weather(city) {\n    const response = await fetch('https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=' + city);\n    const data = await response.json();\n    return data.current.temp_c;  // returns current temperature in Celsius\n}\n$$ \nWITH (async = true);\n```\n\n----------------------------------------\n\nTITLE: Dropping a Materialized View from a Specified Schema with IF EXISTS - SQL\nDESCRIPTION: Removes the ad_ctr_5min materialized view from the rw_schema schema using the IF EXISTS clause to avoid an error if it does not exist. This example requires rw_schema to exist and the user to have necessary privileges. Takes schema-qualified view name as input and does not output anything except for executing the drop if the view exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-mv.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP MATERIALIZED VIEW IF EXISTS rw_schema.ad_ctr_5min;\n```\n\n----------------------------------------\n\nTITLE: Defining Schema in CREATE SOURCE/Table for S3 (SQL)\nDESCRIPTION: Specifies the SQL schema definition block used within CREATE SOURCE or CREATE TABLE statements. Outlines individual columns, their types, and optional primary key settings. Used to precisely describe ingested data structure from S3 files. Requires column type knowledge and intended constraints; applies to CSV, JSON, or Parquet structures. Output governs table/source schema in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\\n   column_name data_type [ PRIMARY KEY ], ...\\n   [ PRIMARY KEY ( column_name, ... ) ]\\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting JSON Path Values with jsonb_extract_path\nDESCRIPTION: Function that extracts JSON sub-objects at specified paths. Accepts variable path elements as text array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT json_extract_path('{\"f2\":{\"f3\":1},\"f4\":{\"f5\":99,\"f6\":\"foo\"}}', 'f4', 'f6');\nSELECT jsonb_extract_path('{\"a\": {\"b\": [\"foo\",\"bar\"]}}', variadic array['a', 'b', '1']);\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Complex Types\nDESCRIPTION: Shows creation of a UDF with various numeric types including INT, BIGINT, FLOAT, DECIMAL, and REAL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_sub_types(INT, BIGINT, FLOAT, DECIMAL, REAL) returns double language sql as 'select $1 + $2 - $3 + $4 + $5';\n```\n\n----------------------------------------\n\nTITLE: Creating Sink using Iceberg Connection in SQL\nDESCRIPTION: Example SQL command illustrating how to create a sink `sink1` from a source table `s1` using a previously defined Iceberg connection `conn`. It specifies the connector as `iceberg`, the sink type as `upsert`, target database and table names, references the `conn` connection, and defines the primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 from s1 WITH (\n    connector = 'iceberg',\n    type = 'upsert',\n    database.name = 'demo_db',\n    table.name = 'test_connection_table',\n    connection = conn,\n    create_table_if_not_exists = 'true',\n    commit_checkpoint_interval = 1,\n    primary_key = 'i1,i2',\n);\n```\n\n----------------------------------------\n\nTITLE: Checking Table Access Privilege in SQL\nDESCRIPTION: Illustrates the usage of has_table_privilege() function to check if a user has specific access to a table. The function can accept user name, OID, or 'public' as user identifier, and various privilege types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nhas_table_privilege([user,] table, privilege) -> boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT has_table_privilege('test_user', 'foo', 'SELECT');\n----RESULT\nt\n```\n\n----------------------------------------\n\nTITLE: Creating Sink from Kafka to Table\nDESCRIPTION: SQL statement to create a sink that loads data from a Kafka source into a RisingWave table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s INTO TABLE t AS SELECT * FROM kafka_source;\n```\n\n----------------------------------------\n\nTITLE: Joining Two Tumbling Windows in SQL - SQL\nDESCRIPTION: Performs a SQL join between tumbling window aggregations of trip data ('taxi_trips') and fare data ('taxi_fare'), matching by trip ID and window start. Returns window start/end, trip distance, total fare, and payment status. Ensures both windows are defined with the same interval and time attribute. Suited for event stream enrichment scenarios.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT trip.window_start, trip.window_end, trip.distance, fare.total_fare, fare.payment_status\\nFROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES') AS trip\\nJOIN TUMBLE (taxi_fare, completed_at, INTERVAL '2 MINUTES') AS fare\\nON trip.trip_id = fare.trip_id AND trip.window_start = fare.window_start\\nORDER BY trip.window_start;\n```\n\n----------------------------------------\n\nTITLE: Defining a Kafka Source Table in RisingWave using Python\nDESCRIPTION: Shows how to use the `risingwave-py` SDK to execute a SQL command that defines a source table in RisingWave connected to an external Kafka topic. The `rw.execute()` method runs a `CREATE TABLE IF NOT EXISTS` statement specifying the Kafka connector, bootstrap server, topic, and Avro format with schema registry details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create a table and load data from upstream kafka\nrw.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS source_abc\n    WITH (\n        connector='kafka',\n        properties.bootstrap.server='localhost:9092',\n        topic='test_topic'\n    ) \n    FORMAT UPSERT ENCODE AVRO (\n        schema.registry = 'http://127.0.0.1:8081',\n        schema.registry.username='your_schema_registry_username',\n        schema.registry.password='your_schema_registry_password'\n)\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Defining the Syntax for CREATE INDEX in SQL\nDESCRIPTION: Provides the general syntax structure for the `CREATE INDEX` command in RisingWave SQL. It outlines the required elements like index name, target object (table or materialized view), and index columns, along with optional clauses such as `IF NOT EXISTS` for conditional creation, column sorting (`ASC`/`DESC`), `INCLUDE` for non-key columns, and `DISTRIBUTED BY` for specifying data distribution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX [ IF NOT EXISTS ] index_name ON object_name ( index_column [ ASC | DESC ], [, ...] )\n[ INCLUDE ( include_column [, ...] ) ]\n[ DISTRIBUTED BY ( distributed_column [, ...] ) ];\n```\n\n----------------------------------------\n\nTITLE: Defining Primary Key using Table Constraint in SQL\nDESCRIPTION: Shows the standard SQL syntax for defining a primary key (`id`) on a table (`table1`) using a table constraint within the `CREATE TABLE` statement. This is used when the primary key isn't implicitly defined by other clauses like `INCLUDE KEY`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table1 (PRIMARY KEY(id))\n```\n\n----------------------------------------\n\nTITLE: Creating CDC Table with Metadata Fields in RisingWave - SQL\nDESCRIPTION: This snippet demonstrates how to create a CDC-enabled table named 'person' in RisingWave, including standard columns for personal data along with metadata fields for the database, schema, and table name. Required dependencies include an existing SQL Server CDC source ('mssql_source'). The statement uses 'INCLUDE' clauses to add commit timestamp and metadata, and sources data from a specific SQL Server table. Key parameters include the table schema, metadata fields, and the upstream table source; outputs are a structured RisingWave table mirroring an upstream SQL Server table with enhanced metadata tracking.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id int,\n    name varchar,\n    email_address varchar,\n    credit_card varchar,\n    city varchar,\n    PRIMARY KEY (id)\n) INCLUDE TIMESTAMP AS commit_ts\nINCLUDE DATABASE_NAME as database_name\nINCLUDE SCHEMA_NAME as schema_name\nINCLUDE TABLE_NAME as table_name\nFROM mssql_source TABLE 'mydb.dbo.person';\n```\n\n----------------------------------------\n\nTITLE: Generating SHA-256 Hash of Binary String in SQL\nDESCRIPTION: The sha256 function returns the SHA-256 hash of a binary string. It takes a bytea input and returns a bytea.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nsha256 ( bytea ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sha256('risingwave'::bytea);\n------RESULT\n\\x73ab8557da7bd59f798600fb1d18d18967bc763638fc456f477799437f229e06\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Simple Indexes in SQL\nDESCRIPTION: Demonstrates creating an index on the 'c_phone' column in the 'customers' table for faster queries by phone number, including typical SELECT queries that take advantage of the index. No external dependencies other than table existence. Input is the 'customers' table; outputs are optimized query plans for specific phone number lookups. Constraints: index must be created before executing the SELECT statements for full benefits.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX idx_c_phone on customers(c_phone);\n\nSELECT * FROM customers where c_phone = '123456789';\n\nSELECT * FROM customers where c_phone in ('123456789', '987654321');\n```\n\n----------------------------------------\n\nTITLE: Windowed Join on Streaming Sources - SQL\nDESCRIPTION: This code defines a materialized view in RisingWave that computes a windowed join across two streaming sources, segmenting both streams by identical tumbling window logic and joining on both key equality and matching window boundaries. Dependencies include pre-created sources (s1, s2), compatibility of their event times, and proper watermarking. The output consists of pairs of records from each source with identical IDs and window intervals.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW window_join AS\nSELECT s1.id AS id1,\n       s1.value AS value1,\n       s2.id AS id2,\n       s2.value AS value2\nFROM TUMBLE(s1, ts, interval '1' MINUTE)\nJOIN TUMBLE(s2, ts, interval '1' MINUTE)\nON s1.id = s2.id and s1.window_start = s2.window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Kafka Connector\nDESCRIPTION: This SQL creates a table directly connected to a Kafka topic with a primary key. This approach enables continuous data ingestion with better query performance, primary key constraints, and update/delete handling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_on_kafka (\n  k int primary key,\n  v1 text,\n  v2 text)\nWITH (\n  connector = 'kafka',\n  topic = 'topic_name',\n  properties.bootstrap.server = 'message_queue:29092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View in RisingWave\nDESCRIPTION: SQL query to create a materialized view in RisingWave that counts the number of targets for each target_id from the user_behaviors source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW target_count AS\nSELECT\n    target_id,\n    COUNT(*) AS target_count\nFROM\n    user_behaviors\nGROUP BY\n    target_id;\n```\n\n----------------------------------------\n\nTITLE: Creating a PostgreSQL CDC Source in RisingWave\nDESCRIPTION: SQL syntax for creating a CDC source from PostgreSQL. This establishes the connection to the PostgreSQL database for change data capture operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc-config.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name WITH (\n   connector='postgres-cdc',\n   <field>=<value>, ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating JDBC Catalog Iceberg Sink in SQL\nDESCRIPTION: This snippet demonstrates how to create an Iceberg sink using a JDBC catalog. It includes configurations for S3 storage, PostgreSQL database connection, and table details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink_demo_jdbc FROM t\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = true,\n    warehouse.path = 's3://icebergdata/demo',\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    catalog.name = 'demo',\n    catalog.type = 'jdbc',\n    catalog.uri = 'jdbc:postgresql://postgres:5432/iceberg',\n    catalog.jdbc.user = 'admin',\n    catalog.jdbc.password = '123456',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Append-Only Iceberg Sink from Upsert Source in SQL\nDESCRIPTION: This snippet demonstrates how to create an append-only Iceberg sink from an upsert source. It includes configurations for forcing append-only behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1_sink FROM s1_table\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = 'true',\n    warehouse.path = 's3a://my-iceberg-bucket/path/to/warehouse,\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY},\n    database.name='dev',\n    table.name='table'\n);\n```\n\n----------------------------------------\n\nTITLE: Ingesting Pandas DataFrame into RisingWave using Python\nDESCRIPTION: Illustrates how to insert data from a Pandas DataFrame into a RisingWave table using the `risingwave-py` SDK. It creates a sample DataFrame with product, price, and timestamp columns, then uses the `rw.insert()` method to load this data into a table named 'test'. The table will be automatically created if it doesn't exist. The snippet also comments on the optional `force_flush` parameter for immediate data visibility.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import datetime\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"product\": [\"foo\", \"bar\"],\n        \"price\": [123.4, 456.7],\n        \"ts\": [datetime.strptime(\"2023-10-05 14:30:00\", \"%Y-%m-%d %H:%M:%S\"), \n               datetime.strptime(\"2023-10-05 14:31:20\", \"%Y-%m-%d %H:%M:%S\")],\n    }\n)\n\n# A test table will be created if not exist in risingwave with the correct schema\nrw.insert(table_name=\"test\", data=df)\n\n# You can provide an optional force_flush parameter and set it to True\n# if you would the inserted data to be visible in fetch query immediately.\n# Otherwise, data will be inserted in batches asynchronously for better performance.\n# rw.insert(table_name=\"test\", data=df, force_flush = True)\n```\n\n----------------------------------------\n\nTITLE: Creating NATS Sink in RisingWave SQL\nDESCRIPTION: SQL syntax for creating a sink to stream data from RisingWave to a NATS subject. It includes required and optional parameters for configuring the connection and authentication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/nats-and-nats-jetstream.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='nats',\n   server_url='<your nats server>:<port>', [ <another_server_url_if_available>, ...]\n   subject='<your subject>',\n\n -- optional parameters\n   connect_mode=<connect_mode>\n   username='<your user name>',\n   password='<your password>'\n   jwt='<your jwt>',\n   nkey='<your nkey>',\n   type='<sink data type>'\n);\n```\n\n----------------------------------------\n\nTITLE: Streaming Ingestion into Iceberg Table in SQL\nDESCRIPTION: This SQL snippet creates an Iceberg table that directly ingests data from a Kafka topic. It demonstrates how to set up streaming ingestion with the Iceberg engine.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE page_views_iceberg (\n    view_id BIGINT,\n    url VARCHAR,\n    user_id INT,\n    view_ts TIMESTAMP\n) WITH (\n    connector = 'kafka',\n    topic = 'page_views_topic',\n    properties.bootstrap.server = 'kafka:9092',\n    scan.startup.mode = 'earliest',\n    commit_checkpoint_interval = 120\n)\nFORMAT PLAIN ENCODE JSON\nENGINE = iceberg;\n```\n\n----------------------------------------\n\nTITLE: Querying Recent Historical Data with Interval in RisingWave SQL\nDESCRIPTION: This snippet illustrates how to query a table’s data as of a point in the recent past using the FOR SYSTEM_TIME AS OF clause with a NOW() - Interval expression. This depends on RisingWave’s time travel retention configuration, and the system returns the table state from the specified interval ago. This is particularly useful for regular point-in-time analysis within the configured history window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/time-travel-queries.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t_foo FOR SYSTEM_TIME AS OF NOW() - '10' SECOND;\n```\n\n----------------------------------------\n\nTITLE: Using jsonb_agg function in SQL\nDESCRIPTION: Collects all input values, including nulls, into a JSON array with optional ordering based on an ORDER BY clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\njsonb_agg ( any_element [ ORDER BY sort_expression ] ) -> jsonb\n```\n\n----------------------------------------\n\nTITLE: Using bit_or function in SQL\nDESCRIPTION: Returns the bitwise OR of all non-null input values or null if no non-null values are provided. Works with integer data types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nbit_or ( smallint | int | bigint ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Dropping a Sink Statement - SQL\nDESCRIPTION: Defines the syntax for the DROP SINK command in SQL, allowing removal of a sink by its name, optionally specifying a schema and using IF EXISTS and CASCADE options for conditional and cascading deletes. Users must have privileges to drop the sink; specifying CASCADE may remove additional dependent objects. The command accepts parameters for the schema and sink name, and options control whether errors are thrown if the sink is missing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-sink.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP SINK [ IF EXISTS ] [schema_name.]sink_name [ CASCADE ];\n```\n\n----------------------------------------\n\nTITLE: Granting Materialized View Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet grants SELECT or ALL privileges on materialized views to a user, either on specific materialized views or all in a schema. Only SELECT can be assigned and revoked for materialized views. Parameters: mv_name(s), schema(s), and user(s).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT {SELECT | ALL [PRIVILEGES]}\nON {MATERIALIZED VIEW mv_name [, ...]\n    | ALL MATERIALIZED VIEWS IN SCHEMA schema_name [, ...] }\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Creating Real-time User Exposure View in SQL\nDESCRIPTION: Creates a materialized view to track users' current total exposure and active positions in real-time.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW real_time_user_exposure AS\nSELECT\n    user_id,\n    SUM(stake_amount) AS total_exposure,\n    COUNT(*) AS active_positions\nFROM\n    positions\nGROUP BY\n    user_id;\n```\n\n----------------------------------------\n\nTITLE: Querying Meta Snapshots\nDESCRIPTION: SQL command to list existing meta snapshots from the catalog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT meta_snapshot_id FROM rw_catalog.rw_meta_snapshot;\n```\n\n----------------------------------------\n\nTITLE: Outer ASOF Join Query - SQL\nDESCRIPTION: This code demonstrates an outer ASOF join using SQL in RisingWave, joining all records from a left table with the closest matches in a right table based on combined equality and inequality conditions. Unmatched right-side fields are set to NULL. The snippet needs two tables with comparable columns and processes potentially non-matching rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT A.field1 AS A_field1 \nFROM TableA ASOF LEFT JOIN TableB \nON A.field1 = B.field1 AND A.field2 <= B.field2;\n```\n\n----------------------------------------\n\nTITLE: Querying Ingested IoT Sensor Data from RisingWave Table (SQL)\nDESCRIPTION: This SQL command retrieves up to five records from the 'iot_sensor_data' table, which collects data from an MQTT topic. There are no required dependencies beyond the existence of the referenced table and previously ingested data. The command returns all columns as output, making it useful for previewing recent or incoming IoT records for validation or exploratory purposes. Result structure depends on the table schema and content streamed from MQTT.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mqtt.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM iot_sensor_data LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.19.0 with Docker\nDESCRIPTION: Command to run RisingWave v0.19.0 in playground mode using Docker. This exposes the necessary ports (4566 and 5691) for accessing the RisingWave instance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_30\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.19.0 playground\n```\n\n----------------------------------------\n\nTITLE: Granting Schema Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet shows how to assign USAGE, CREATE, or ALL PRIVILEGES on one or more schemas to a user. The syntax is similar to granting database privileges and uses optional clauses to control privilege delegation. Dependencies: valid schema and user names. Returns: specified privileges are granted to the user on the specified schema(s).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT {{USAGE | CREATE}[, ...]| ALL [PRIVILEGES]}\nON SCHEMA schema_name [, ...]\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Kinesis Source/Table with Protobuf Format using SQL\nDESCRIPTION: This SQL snippet illustrates creating a RisingWave source or table that consumes data from an AWS Kinesis stream formatted as Protocol Buffers (Protobuf). It configures the Kinesis connector, stream, AWS region, endpoint, and authentication credentials. Crucially, it specifies the Protobuf message name and the location of the schema definition file (`.proto`) required for decoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [IF NOT EXISTS] source_name\nWITH (\n   connector='kinesis',\n   stream='kafka',\n   aws.region='user_test_topic',\n   endpoint='172.10.1.1:9090,172.10.1.2:9090',\n   aws.credentials.session_token='AQoEXAMPLEH4aoAH0gNCAPyJxz4BlCFFxWNE1OPTgk5TthT+FvwqnKwRcOIfrRh3c/L To6UDdyJwOOvEVPvLXCrrrUtdnniCEXAMPLE/IvU1dYUg2RVAJBanLiHb4IgRmpRV3z rkuWJOgQs8IZZaIv2BXIa2R4OlgkBN9bkUDNCJiBeb/AXlzBBko7b15fjrBs2+cTQtp Z3CYWFXG8C5zqx37wnOE49mRl/+OtkIKGO7fAE',\n   aws.credentials.role.arn='arn:aws-cn:iam::602389639824:role/demo_role',\n   aws.credentials.role.external_id='demo_external_id',\n   aws.credentials.access_key_id = 'your_access_key',\n   aws.credentials.secret_access_key = 'your_secret_key'\n) FORMAT PLAIN ENCODE PROTOBUF (\n    message = 'package.message_name',\n    schema.location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/demo.proto'\n);\n```\n\n----------------------------------------\n\nTITLE: Using Secrets as Files in CREATE TABLE Statement in RisingWave SQL\nDESCRIPTION: This SQL snippet illustrates how to reference secrets as file paths within a `CREATE TABLE` statement, specifically for Kafka connector SSL options (`ssl.ca.location`, `ssl.certificate.location`, `ssl.key.location`). The `SECRET secret_name AS FILE` syntax tells RisingWave to materialize the secret content into a temporary file and use its path. A regular secret reference is used for `ssl.key.password`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE district (\n    d_id INTEGER,\n    PRIMARY KEY (d_id)\n) with (\n    connector = 'kafka',\n    topic = 'your-topic',\n    properties.bootstrap.server = 'your-broker-address:29092',\n    ssl.ca.location = SECRET kafka_ca AS FILE,\n    ssl.certificate.location = SECRET kafka_cert AS FILE,\n    ssl.key.location = SECRET kafka_key AS FILE,\n    ssl.key.password = SECRET kafka_password,\n) FORMAT DEBEZIUM ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for a RisingWave Source in SQL\nDESCRIPTION: Specifies the syntax for defining the schema within a `CREATE SOURCE` or `CREATE TABLE` statement in RisingWave. This includes defining column names, their corresponding data types, and optionally specifying single or composite primary keys.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: NULLIF Function in SQL\nDESCRIPTION: Shows the NULLIF function, which returns null if value1 equals value2, otherwise returns value1.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nNULLIF ( value1, value2 )\n```\n\n----------------------------------------\n\nTITLE: Dropping Subscription in RisingWave Using SQL\nDESCRIPTION: This snippet provides the SQL syntax for dropping an existing subscription in RisingWave. It removes all associated metadata and disables further data change retrieval through the named subscription. The user must have rights to remove the subscription; no further parameters are required.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SUBSCRIPTION <subscription_name>;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Sink in RisingWave\nDESCRIPTION: This SQL example shows how to create a sink that streams data from RisingWave to an externally managed Iceberg table. It configures the connection using a REST catalog type with S3 storage and includes authentication details needed for the external Iceberg catalog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_demo_rest FROM t\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = true,\n    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',\n    s3.region = 'ap-southeast-2',\n    s3.access.key = 'xxxx',\n    s3.secret.key = 'xxxx',\n    s3.path.style.access = 'true',\n    catalog.type = 'rest',\n    catalog.uri = 'http://localhost:8181/api/catalog',\n    warehouse.path = 'quickstart_catalog',\n    database.name = 'ns',\n    table.name = 't1',\n    catalog.credential='123456:123456',\n    catalog.scope='PRINCIPAL_ROLE:ALL',\n    catalog.oauth2_server_uri='xxx'\n    catalog.scope='xxx',\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Upsert Sink to Snowflake in RisingWave\nDESCRIPTION: Example of creating an upsert sink in RisingWave that sends data to Snowflake. This sink configuration is similar to the append-only sink but doesn't include the force_append_only parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK snowflake_sink FROM ss_mv WITH (\n   connector = 'snowflake',\n   type = 'append-only',\n   s3.bucket_name = 'EXAMPLE_S3_BUCKET',\n   s3.credentials.access = 'EXAMPLE_AWS_ACCESS',\n   s3.credentials.secret = 'EXAMPLE_AWS_SECRET',\n   s3.region_name = 'EXAMPLE_REGION',\n   s3.path = 'EXAMPLE_S3_PATH',\n);\n```\n\n----------------------------------------\n\nTITLE: Syntax for Dropping a View in SQL\nDESCRIPTION: Defines the structure of the `DROP VIEW` command in SQL. It includes an optional `IF EXISTS` clause to prevent errors if the view doesn't exist, and an optional `CASCADE` option to recursively drop objects that depend on the view. The `view_name` parameter specifies the target view to be dropped.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-view.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP VIEW [ IF EXISTS ] view_name [ CASCADE ];\n```\n\n----------------------------------------\n\nTITLE: Updating Table and Fetching Subscription Changes via SQL in RisingWave\nDESCRIPTION: This snippet demonstrates updating the table and then fetching the before and after changes using the subscription cursor. The two FETCH commands return log entries for 'UpdateDelete' and 'UpdateInsert'. It's useful for understanding how updates are recorded as change events in subscriptions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nupdate t1 set v3 = 10 where v1 = 1;\nfetch next from cur;\n\n----RESULT\n t1.v1 | t1.v2 | t1.v3 |     t1.op     |  rw_timestamp\n-------+-------+-------+---------------+---------------\n     1 |     1 |     1 | UpdateDelete  | 1715669376304\n(1 row)\n\nfetch next from cur;\n----RESULT\n t1.v1 | t1.v2 | t1.v3 |     t1.op     |  rw_timestamp\n-------+-------+-------+---------------+---------------\n     1 |     1 |    10 | UpdateInsert  | 1715669376304\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating Azblob Source for CSV Data in RisingWave SQL\nDESCRIPTION: Demonstrates how to create a RisingWave source named `s` to ingest CSV data from Azure Blob Storage. It specifies the schema (id, name, age), uses the `azblob` connector, provides necessary connection parameters (`container_name`, `credentials`, `endpoint_url`), and sets the format to `PLAIN` and encoding to `CSV` with `without_header = 'true'` and a comma delimiter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s(\n    id int,\n    name varchar,\n    age int\n)\nWITH (\n    connector = 'azblob',\n    azblob.container_name = 'xxx',\n    azblob.credentials.account_name = 'xxx',\n    azblob.credentials.account_key = 'xxx',\n    azblob.endpoint_url = 'xxx',\n) FORMAT PLAIN ENCODE CSV (\n    without_header = 'true',\n    delimiter = ',' -- set delimiter = E'\\t' for tab-separated files\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Raw String Verification for Webhook Data\nDESCRIPTION: Creates a table configured to accept webhook data from Amazon EventBridge, using a raw string for request verification instead of a secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/eventbridge-webhook.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE AS secure_compare(\n  headers->>'authorization',\n  'TEST_WEBHOOK'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for GitHub Event Processing\nDESCRIPTION: Creates a materialized view to extract specific fields from the JSON payload stored in the webhook table for easier querying and analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/github-webhook.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW github_events AS\nSELECT\n  data->>'action' AS action,\n  data->'repository'->>'full_name' AS repository_name,\n  data->'sender'->>'login' AS sender_login,\n  data->>'created_at' AS event_time\nFROM wbhtable;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source in RisingWave\nDESCRIPTION: This SQL snippet demonstrates how to create a source in RisingWave that reads from an Iceberg table stored on AWS S3. It configures connection details for the Iceberg catalog and underlying S3 storage, including endpoint, credentials, and table information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE iceberg_source\nWITH (\n    connector = 'iceberg',\n    type='append-only',\n    warehouse.path = 's3://your-bucket/path/to/iceberg/warehouse',\n    database.name = 'YOUR_ICEBERG_DB',\n    table.name = 'YOUR_ICEBERG_TABLE',\n    s3.endpoint = 'http://YOUR_S3_ENDPOINT:PORT', -- e.g., 'http://minio:9000'\n    s3.access.key = 'YOUR_ACCESS_KEY',\n    s3.secret.key = 'YOUR_SECRET_KEY',\n    s3.region = 'YOUR_S3_REGION'  -- Optional if endpoint is specified\n) ;\n```\n\n----------------------------------------\n\nTITLE: Altering Subscription Metadata in RisingWave Using SQL\nDESCRIPTION: This snippet provides SQL for altering the metadata of an existing subscription, such as renaming it, changing its owner, or updating its schema. Individual clauses are optional, and any or all may be provided in a single ALTER statement. This command is for subscription maintenance and organization and requires relevant permissions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION <subscription_name>\n    [ RENAME TO <new_subscription_name> ]\n    [ OWNER TO <new_owner> ]\n    [ SET SCHEMA <new_schema_name> ]\n    ;\n```\n\n----------------------------------------\n\nTITLE: Creating Inventory Status Materialized View in SQL\nDESCRIPTION: Creates a materialized view to monitor inventory status, indicating whether a product needs to be restocked based on current stock levels and reorder points.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW inventory_status AS\nSELECT\n    warehouse_id,\n    product_id,\n    stock_level,\n    reorder_point,\n    location,\n    CASE\n        WHEN stock_level <= reorder_point THEN 'Reorder Needed'\n        ELSE 'Stock Sufficient'\n    END AS reorder_status,\n    timestamp AS last_update\nFROM\n    inventory;\n```\n\n----------------------------------------\n\nTITLE: Creating an Exam Scores Table in RisingWave\nDESCRIPTION: SQL command to create a table for storing examination scores. The table includes columns for score_id, exam_id, student_id, score, and exam_date.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE exam_scores (\n  score_id int,\n  exam_id int,\n  student_id int,\n  score real,\n  exam_date date\n);\n```\n\n----------------------------------------\n\nTITLE: Using row_number() Window Function in SQL\nDESCRIPTION: The row_number() function assigns a unique sequential integer to each row within a partition of a result set. It starts at 1 for the first row in each partition and increments by 1 for each subsequent row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nrow_number() → integer\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    row_number() OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as r,\n    col1, col2\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Using grouping function in SQL\nDESCRIPTION: Returns a bit mask indicating which GROUP BY expressions are not included in the current grouping set. Used with GROUPING SETS to distinguish result rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\ngrouping ( group_by_expression(s) ) → integer\n```\n\n----------------------------------------\n\nTITLE: Example: Renaming a Database in SQL\nDESCRIPTION: Demonstrates how to use the `ALTER DATABASE ... RENAME TO` command to change the name of the database `database` to `database1`. This provides a concrete example of the `RENAME TO` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-database.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of the database named \"database\" to \"database1\"\nALTER DATABASE database RENAME TO database1;\n```\n\n----------------------------------------\n\nTITLE: Creating Indexes with DISTRIBUTED BY for Data Distribution in SQL\nDESCRIPTION: Demonstrates specifying the DISTRIBUTED BY clause when creating an index for precise data distribution across cluster nodes. In this example, the index is on (c_name, c_nationkey) and distributed by c_name, optimizing query routing and parallelism in distributed environments. Requires the 'customers' table. Input: table columns; output: an index distributed as specified, improving scalability.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- Create an index with specified distributed columns\nCREATE INDEX idx_c_phone2 ON customers(c_name, c_nationkey) DISTRIBUTED BY (c_name);\n\nSELECT * FROM customers WHERE c_name = 'Alice';\n```\n\n----------------------------------------\n\nTITLE: Specifying Confluent Schema Registry in SQL ENCODE Clause\nDESCRIPTION: Illustrates the syntax within the `ENCODE` clause (typically for Avro or Protobuf) of a `CREATE SOURCE` statement to configure RisingWave to fetch schemas from a Confluent Schema Registry. The `schema.registry` parameter should be set to the URL of the registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nENCODE data_encode (\n   schema.registry = 'schema_registry_url'\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink for Personalized Recommendations in SQL\nDESCRIPTION: This snippet creates a sink that sends personalized product recommendations to a Kafka topic for real-time use by the recommendation engine in an e-commerce platform.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK recommendations FROM personalized_recommendations\n  WITH (\n    connector='kafka',\n    properties.bootstrap.server='localhost:9092',\n    topic='recommendations'\n  ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink to write data to an Apache Iceberg table. This requires specifying the Iceberg table and connection parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/write-to-iceberg.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\nFROM source_name\nINTO iceberg (\n    table_name = 'catalog.database.table' \n) \nWITH (\n  properties\n);\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE SET PARALLELISM Syntax in RisingWave SQL\nDESCRIPTION: This command controls the degree of parallelism for a streaming job. It can be set to ADAPTIVE (or 0) to expand the job's parallelism to all available units, or a fixed number to lock it at that value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\nSET PARALLELISM { TO | = } parallelism_number;\n```\n\n----------------------------------------\n\nTITLE: Changing Function Schema with ALTER FUNCTION SET SCHEMA in SQL\nDESCRIPTION: This snippet details the specific syntax for using the `SET SCHEMA` clause within the `ALTER FUNCTION` command to move a function to a different schema. It requires the function signature (name and argument types) and the name of the target schema (`schema_name`). The user executing this command must own the function and have CREATE privilege on the new schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-function.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER FUNCTION function( argument_type [, ...] )\n    SET SCHEMA schema_name;\n```\n\n----------------------------------------\n\nTITLE: Dropping a Sink by Name - SQL\nDESCRIPTION: An example of using the DROP SINK command in SQL to remove a sink named 'rw_sink' from the default 'public' schema. This command does not use IF EXISTS or CASCADE, so it will fail if the sink does not exist. No parameters are required except the sink name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-sink.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SINK rw_sink;\n```\n\n----------------------------------------\n\nTITLE: Syntax for Creating a Sink into a RisingWave Table (SQL)\nDESCRIPTION: Defines the SQL syntax for the `CREATE SINK INTO` command in RisingWave. This command allows creating a sink that directs data into an existing table within RisingWave, optionally specifying columns. Data can originate from another sink/source (`FROM sink_from`) or a `SELECT` query (`AS select_query`). The `IF NOT EXISTS` clause prevents an error if the sink already exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-sink-into.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name INTO table_name [ ( col_name [ , ... ] ) ]\n[FROM sink_from | AS select_query]\n```\n\n----------------------------------------\n\nTITLE: Creating an Intermediate Ordered Materialized View in SQL\nDESCRIPTION: Creates an intermediate materialized view `tmp` that explicitly orders the data from table `t` by the `v1` column. This can be used as a base for subsequent materialized views to ensure better data locality and improve backfilling performance when the original table lacks inherent ordering on `v1`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate materialized view tmp as select * from t order by v1;\n```\n\n----------------------------------------\n\nTITLE: Creating CDC Table from SQL Server Schema/Table Reference in RisingWave - SQL\nDESCRIPTION: This SQL creates a CDC table 'tt3' in RisingWave that ingests change data from table 'tt3' in schema 'dbo' of the previously-defined source 'mssql_mydb'. Primary key and timestamp columns are specified to mirror the upstream SQL Server schema. Prerequisite is the existence of 'mssql_mydb' as a SQL Server CDC source. The key parameter is the FROM clause with the 'TABLE' option specifying the schema-qualified source table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tt3 (\n    v1 integer primary key,\n    v2 timestamp with time zone\n) FROM mssql_mydb TABLE 'dbo.tt3';\n```\n\n----------------------------------------\n\nTITLE: Switching Databases Using SET DATABASE TO and USE Commands in SQL\nDESCRIPTION: Examples of how to switch the current database during an active session using either SET DATABASE TO or USE commands, without disconnecting and reconnecting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Switch database using SET DATABASE TO \nSET DATABASE TO sales_db;\n\n-- Switch database using USE\nUSE marketing_db;\n```\n\n----------------------------------------\n\nTITLE: CASE Statement Example (Syntax 2) for Trip Distance Digit Classification in SQL\nDESCRIPTION: Shows how to use CASE statement (Syntax 2) to classify trip distances based on the number of digits in the distance value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, distance,\n  CASE LENGTH (distance::VARCHAR)\n    WHEN  1 THEN 'One-digit'\n    WHEN  2 THEN 'Double-digit'\n    WHEN  3 THEN 'Three-digit'\n  END AS Digit\n  FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Creating a SQL Server CDC Source with Debezium Parameters in RisingWave (SQL)\nDESCRIPTION: This SQL example shows how to create a RisingWave source for SQL Server CDC while passing specific configuration parameters to the underlying Debezium connector. Parameters are specified within the `WITH` clause using the `debezium.` prefix. In this case, it sets `debezium.schema.history.internal.skip.unparseable.ddl = 'true'` to instruct Debezium to skip DDL statements it cannot parse.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mssql_mydb WITH (\n    connector = 'sqlserver-cdc',\n    hostname = '127.0.0.1',\n    port = '1433',\n    username = 'sa',\n    password = '123456',\n    database.name = 'mydb',\n    debezium.schema.history.internal.skip.unparseable.ddl = 'true'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave\nDESCRIPTION: Creates a materialized view 'counter' that computes running totals of distance and duration from the walk table\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/go.mdx#2025-04-23_snippet_3\n\nLANGUAGE: go\nCODE:\n```\nsql := `CREATE MATERIALIZED VIEW counter AS \n        SELECT\n            SUM(distance) as total_distance,\n            SUM(duration) as total_duration\n        FROM walk`\n\n_, err := conn.Exec(context.Background(), sql)\nreturn err\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/OAUTHBEARER Authentication\nDESCRIPTION: Example of creating a materialized source table in RisingWave that connects to Kafka using SASL/OAUTHBEARER authentication without SSL encryption. The source table defines two columns and specifies necessary Kafka connection properties including authentication parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_6 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='OAUTHBEARER',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.oauthbearer.config='principal=bob'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Sink creation example with S3 catalog for Iceberg\nDESCRIPTION: Example of creating an Iceberg sink that writes to an S3 catalog with specific AWS credentials and region settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/write-to-iceberg.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK IF NOT EXISTS s3_sink\nFROM source1\nINTO iceberg (\n    table_name = 'catalog.database.table'\n)\nWITH (\n    s3.endpoint = 's3.amazonaws.com',\n    s3.region = 'us-east-1',\n    s3.access.key = '<access_key>',\n    s3.secret.key = '<secret_key>'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Upsert MongoDB Sink with Compound Key in RisingWave\nDESCRIPTION: Example of creating a table with a compound primary key and a corresponding upsert sink to MongoDB. Demonstrates how to specify multiple fields as the primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mongodb.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3(\n    a int,\n    b int,\n    value text,\n    primary key (a, b)\n);\n\ninsert into t3 values(1, 2, 'abc');\n\nCREATE sink t3_sink FROM t3\nWITH (\n    connector='mongodb',\n    type = 'upsert',\n    mongodb.url = 'mongodb://mongodb:27017/?replicaSet=rs0',\n    collection.name = 'demo.t3',\n    primary_key='a,b'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source Table in RisingWave\nDESCRIPTION: This SQL query creates a table in RisingWave that connects to a Kafka topic in Confluent Cloud. It defines the schema of the incoming data and specifies the connection parameters for the Kafka source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/confluent-cloud.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s (\n    ordertime timestamp,\n orderid int,\n itemid varchar,\n    orderunits double,\n address STRUCT < city varchar,\n    state varchar,\n zipcode int >\n) WITH (\n    connector = 'kafka',\n    topic = 'topic_0',\n properties.bootstrap.server = 'xyz-x00xx.us-east-1.aws.confluent.cloud:9092',\n    scan.startup.mode = 'earliest',\n    properties.security.protocol = 'SASL_SSL',\n    properties.sasl.mechanism = 'PLAIN',\n    properties.sasl.username = 'username',\n    properties.sasl.password = 'password'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating an AWS Kinesis Sink Example in RisingWave\nDESCRIPTION: Example SQL statement showing how to create a sink named 's1' that sends data from table 't' to a Kinesis stream with AWS authentication details and Debezium JSON formatting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/aws-kinesis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s1 FROM t WITH (\n connector = 'kinesis',\n stream = 'kinesis-sink-demo',\n aws.region = 'us-east-1',\n aws.credentials.access_key_id = 'your_access_key',\n aws.credentials.secret_access_key = 'your_secret_key'\n)\nFORMAT DEBEZIUM ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Indexes for Join Optimization in SQL\nDESCRIPTION: Shows how to create an index on the 'o_custkey' column in the 'orders' table to accelerate join operations between 'customers' and 'orders', especially when filtering by phone number. Depends on prior existence of both tables and their respective indexes. Keys include the join columns ('c_custkey', 'o_custkey') and indexed/filter fields. Output is improved join execution performance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX idx_o_custkey ON orders(o_custkey);\n\nSELECT * FROM customers JOIN orders ON c_custkey = o_custkey\nWHERE c_phone = '123456789';\n```\n\n----------------------------------------\n\nTITLE: Creating Table, Inserting Data, and Creating Materialized View in RisingWave (SQL)\nDESCRIPTION: This snippet illustrates the initial setup: creating a table 't', inserting three rows into it, and defining a materialized view 'mv' that computes the sum of 'v1' and 'v2'. It requires a connected RisingWave SQL environment and privileges to create tables and views. The inserted values populate 't', and the view 'mv' aggregates over the current state of 't'. There are no special parameters or options; table and view names are explicit.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (v1 int, v2 int);\ninsert into t values (1,10), (2,20), (3,30);\nCREATE MATERIALIZED VIEW mv as select sum(v1) as v1_sum, sum(v2) as v2_sum from t;\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Table Using Spark SQL\nDESCRIPTION: This snippet demonstrates how to create an Iceberg table using Spark SQL. It includes configurations for S3 storage, AWS credentials, and table properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nspark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.4_2.12:1.3.1,org.apache.hadoop:hadoop-aws:3.3.2\\\n    --conf spark.sql.catalog.demo=org.apache.iceberg.spark.SparkCatalog \\\n    --conf spark.sql.catalog.demo.type=hadoop \\\n    --conf spark.sql.catalog.demo.warehouse=s3a://my-iceberg-bucket/path/to/warehouse \\\n    --conf spark.sql.catalog.demo.hadoop.fs.s3a.endpoint=https://s3.ap-southeast-1.amazonaws.com \\\n    --conf spark.sql.catalog.demo.hadoop.fs.s3a.path.style.access=true \\\n    --conf spark.sql.catalog.demo.hadoop.fs.s3a.access.key=${ACCESS_KEY} \\\n    --conf spark.sql.catalog.demo.hadoop.fs.s3a.secret.key=${SECRET_KEY} \\\n    --conf spark.sql.defaultCatalog=demo \\\n    --e \"drop table if exists demo.dev.`table`;\n\nCREATE TABLE demo.dev.`table`\n(\n  seq_id bigint,\n  user_id bigint,\n  user_name string\n) TBLPROPERTIES ('format-version'='2')\";\n```\n\n----------------------------------------\n\nTITLE: Enriching Star Schema Fact Table using Table Sinks in SQL\nDESCRIPTION: This SQL snippet illustrates enriching a central fact table (fact) with data from dimension tables (d1, d2, d3) using table sinks, simulating a star schema join pattern. A target wide table (wide_fact) is created with `ON CONFLICT DO UPDATE IF NOT NULL`. A primary sink (fact_sink) inserts only the primary key from the fact table, controlling record existence. Subsequent sinks (sink1, sink2, sink3) join the fact table with respective dimension tables on foreign keys (k1, k2, k3) to retrieve dimension values (v) and update the corresponding columns (v1, v2, v3) in the wide_fact table based on the fact table's primary key (pk). These enrichment sinks are forced to be append-only.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/maintain-wide-table-with-table-sinks.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE fact(pk int primary key, k1 int, k2 int, k3 int);\nCREATE TABLE d1(pk int primary key, v int);\nCREATE TABLE d2(pk int primary key, v int);\nCREATE TABLE d3(pk int primary key, v int);\n\nCREATE TABLE wide_fact(pk int primary key, v1 int, v2 int, v3 int)\n  ON CONFLICT DO UPDATE IF NOT NULL;\n\n/* the main sink is not force-append-only to control if the record exists*/\nCREATE SINK fact_sink INTO wide_fact (pk) AS\n  SELECT pk FROM fact;\n\nCREATE SINK sink1 INTO wide_fact (pk, v1) AS\n  SELECT fact.pk, d1.v\n  FROM fact JOIN d1 ON fact.k1 = d1.pk\nwith (\n  type = 'append-only',\n  force_append_only = 'true',\n);\n\nCREATE SINK sink2 INTO wide_fact (pk, v2) AS\n  SELECT fact.pk, d2.v\n  FROM fact JOIN d2 ON fact.k2 = d2.pk\nwith (\n  type = 'append-only',\n  force_append_only = 'true',\n);\n\nCREATE SINK sink3 INTO wide_fact (pk, v3) AS\n  SELECT fact.pk, d3.v\n  FROM fact JOIN d3 ON fact.k3 = d3.pk\nwith (\n  type = 'append-only',\n  force_append_only = 'true',\n);\n```\n\n----------------------------------------\n\nTITLE: Dropping an Index Using SQL Syntax - SQL\nDESCRIPTION: Demonstrates the generic syntax for the DROP INDEX command in SQL. The code highlights optional clauses such as IF EXISTS for error-tolerant index deletion, schema_name to reference the schema, and CASCADE for removal of dependent objects. This snippet expects valid index and schema names and is used for removing indexes from tables or materialized views in RisingWave SQL. No result is returned unless an error occurs (unless IF EXISTS is supplied).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP INDEX [ IF EXISTS ] [ schema_name.]index_name [ CASCADE ];\n```\n\n----------------------------------------\n\nTITLE: Creating Append-Only Iceberg Sink from Append-Only Source in SQL\nDESCRIPTION: This example shows how to create an append-only Iceberg sink from an append-only source. It includes configurations for S3 storage and table details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1_sink FROM t1_table\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    warehouse.path = 's3a://my-iceberg-bucket/path/to/warehouse,\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY},\n    database.name='dev',\n    table.name='table'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Aggregation - SQL\nDESCRIPTION: Shows how to create a materialized view to aggregate data by a specific field (`v1`) and compute the sum of `v2`. This is used to illustrate performance trade-offs when building MVs and reading unordered source tables in RisingWave. Requires a previously created base table `t` with appropriate integer and varchar columns. Takes no external parameters; the result is a new materialized view with group-by semantics and potentially inefficient backfill due to unordered reads.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate materialized view m as select v1, sum(v2) from t group by v1;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with JSON Format and Payload Inclusion in SQL\nDESCRIPTION: Creates a RisingWave table `table_include_payload` connected to a Kafka topic `kafka_1_partition_topic`. It defines specific columns `v1` and `v2` but also includes the entire raw JSON message in a special `payload` column using `INCLUDE payload`. This is useful when the exact JSON schema is unknown or variable.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'kafka',\n    topic = 'kafka_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example: Moving a View using ALTER VIEW SET SCHEMA in SQL\nDESCRIPTION: Example SQL command showing how to move a view named `test_view` to the schema `test_schema` using the `ALTER VIEW ... SET SCHEMA` clause. This changes the namespace associated with the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Move the view named \"test_view\" to the schema named \"test_schema\"\nALTER VIEW test_view SET SCHEMA test_schema;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Connector in RisingWave\nDESCRIPTION: This SQL command creates a table with a connector in RisingWave. Tables with connectors provide similar benefits to shared sources but also persist all consumed data, offering stronger consistency guarantees.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE\n```\n\n----------------------------------------\n\nTITLE: Defining a Temporary Array in SQL\nDESCRIPTION: Demonstrates how to define a temporary array in an SQL statement using the ARRAY keyword.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ARRAY['foo', 'bar', null];\n```\n\n----------------------------------------\n\nTITLE: Starting a Read-Only Transaction in RisingWave SQL\nDESCRIPTION: Initiates a read-only transaction in RisingWave using either `START TRANSACTION READ ONLY` or `BEGIN READ ONLY`. This ensures subsequent reads are executed against a consistent Hummock snapshot. Note that DDL, most DML, USER, and privilege-related statements are disallowed within the transaction block until committed or rolled back.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/transactions.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION READ ONLY\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN READ ONLY\n```\n\n----------------------------------------\n\nTITLE: SQL UPDATE with Subquery\nDESCRIPTION: Example of updating distance values using arithmetic operation and a subquery in the WHERE clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-update.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE taxi_trips\nSET distance = distance * 0.6214\nWHERE city NOT IN (SELECT city FROM restricted_zones);\n```\n\n----------------------------------------\n\nTITLE: Truncating Date/Time Values in SQL\nDESCRIPTION: Truncates a date/time value to a specified precision. Supports various date/time types and precision strings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ndate_trunc('hour', timestamp '2202-02-16 20:38:40.123456') → 2202-02-16 20:00:00\n\ndate_trunc('day', timestamp with time zone '2202-02-16 20:38:40.123456Z', 'Australia/Sydney') → 2202-02-16 13:00:00+00:00\n\ndate_trunc('month', interval '2333 year 4 months 5 days 02:47:33.123') → 2333 years 4 mons\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Buy Signals in SQL\nDESCRIPTION: This snippet creates a materialized view that filters stock trades to identify potential buy signals based on price and volume thresholds. It's part of a real-time stock trading analytics solution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW buy_signals AS\nSELECT symbol, price, volume\nFROM stock_trades\nWHERE price > 100 AND volume > 1000;\n```\n\n----------------------------------------\n\nTITLE: Basic WITH ORDINALITY Usage with Unnest\nDESCRIPTION: Demonstrates the basic usage of WITH ORDINALITY clause with the unnest function on a simple array. The result includes the unnested values and their corresponding row numbers starting from 1.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-ordinality-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM unnest(array[0,1,2]) WITH ORDINALITY;\n```\n\n----------------------------------------\n\nTITLE: Creating a ClickHouse Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink to ClickHouse in RisingWave. Specifies the sink name, data source, and connection parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='clickhouse',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Statement Progress in RisingWave\nDESCRIPTION: Shows how to query the progress of running DDL statements using the rw_catalog.rw_ddl_progress view. Returns the DDL ID, statement text, and estimated progress percentage.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-statement-progress.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_catalog.rw_ddl_progress;\n\n ddl_id |         ddl_statement         | progress\n--------+-------------------------------+----------\n   1026 | CREATE INDEX idx ON sbtest1(c) | 69.02%\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Defining FULL OUTER JOIN Syntax - SQL\nDESCRIPTION: These snippets define the FULL OUTER JOIN syntax forms in SQL, as supported by RisingWave, enabling extraction of rows that have matches in either the left or right table expressions. NULLs are returned where no match exists for a given table. Inputs are two table expressions, and result is a complete outer join result set including all unmatched rows from both sides.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n<table_expression> FULL [ OUTER ] JOIN <table_expression> ON <join_conditions>;\n<table_expression> FULL [ OUTER ] JOIN <table_expression> USING (<col_name>, <col_name>, ...);\n<table_expression> NATURAL FULL [ OUTER ] JOIN <table_expression>;\n```\n\n----------------------------------------\n\nTITLE: Dropping a Source with Optional Clauses in SQL\nDESCRIPTION: Demonstrates the general syntax for removing a source from the database using the DROP SOURCE command in SQL on RisingWave. Includes options for conditional dropping (IF EXISTS), schema qualification, and specifying CASCADE to remove dependent objects. No actual source names are included; this template requires the user to provide the correct schema and source identifiers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-source.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP SOURCE [ IF EXISTS ] [schema_name.]source_name [ CASCADE ];\n\n```\n\n----------------------------------------\n\nTITLE: Creating Table from S3 Source in RisingWave with JSON Encoding and Metadata Includes (SQL)\nDESCRIPTION: Demonstrates a SQL command for creating a RisingWave table using an S3 JSON/ndjson file source, explicitly including metadata columns (file name and offset). The match_pattern parameter filters files, and endpoint_url points to a specific S3-compatible endpoint. Depends on access to correct S3 bucket, credentials, and optionally includes extra columns for tracking file source/offset. The output is a table mapping incoming JSON data and metadata fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s3(\\n    id int,\\n    name TEXT,\\n    age int,\\n    mark int,\\n)\\nINCLUDE file as file_name\\nINCLUDE offset -- default column name is `_rw_s3_offset`\\nWITH (\\n    connector = 's3',\\n    match_pattern = '%Ring%*.ndjson',\\n    s3.region_name = 'ap-southeast-2',\\n    s3.bucket_name = 'example-s3-source',\\n    s3.credentials.access = 'xxxxx',\\n    s3.credentials.secret = 'xxxxx',\\n    s3.endpoint_url = 'https://s3.us-east-1.amazonaws.com'\\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with CSV Format in SQL\nDESCRIPTION: Defines a RisingWave table `s0` connected to Kafka topic `kafka_csv_topic`. It reads CSV formatted messages, parsing them into columns `v1` (int) and `v2` (varchar). It specifies that the CSV data does not contain a header row (`without_header = 'true'`) and uses a comma (`,`) as the delimiter. Note that CSV headers are not supported for Kafka tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s0 (v1 int, v2 varchar)\nWITH (\n   connector = 'kafka',\n   topic = 'kafka_csv_topic',\n   properties.bootstrap.server = '127.0.0.1:29092',\n   scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE CSV (\n   without_header = 'true',\n   delimiter = ','\n);\n```\n\n----------------------------------------\n\nTITLE: Granting SELECT Permissions on Materialized View\nDESCRIPTION: SQL command to grant SELECT permissions to the Grafana read-only user for accessing a specific materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/grafana.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT ON MATERIALIZED VIEW mv_name TO grafanareader;\n```\n\n----------------------------------------\n\nTITLE: Using var_samp function in SQL\nDESCRIPTION: Calculates the sample variance of input values. Returns NULL if there are fewer than two non-null values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nvar_samp ( expression ) -> output_value\n```\n\n----------------------------------------\n\nTITLE: Basic UNION ALL Syntax\nDESCRIPTION: Demonstrates the basic syntax for UNION ALL operator to combine results from multiple SELECT statements. Includes placeholder expressions and optional WHERE conditions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions]\nUNION ALL\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions];\n```\n\n----------------------------------------\n\nTITLE: INTERSECT Syntax Example\nDESCRIPTION: Shows the basic syntax for INTERSECT operator to find common rows between multiple SELECT statements.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions]\nINTERSECT\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions];\n```\n\n----------------------------------------\n\nTITLE: Creating Google Pub/Sub Source in SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a table or source that connects to Google Pub/Sub in RisingWave. It includes placeholders for various parameters such as source name, schema definition, and connector parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-pub-sub.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [ IF NOT EXISTS ] source_name\n[ schema_definition ]\nWITH (\n   connector='google_pubsub',\n   connector_parameter='value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   message = 'message',\n   schema.location = 'location' | schema.registry = 'schema_registry_url'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Parquet Format in RisingWave SQL\nDESCRIPTION: Specifies the format and encoding for reading Parquet files from various object storage systems like Amazon S3, Google Cloud Storage, and Azure Blob Storage.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT PLAIN\nENCODE PARQUET\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/PLAIN Authentication\nDESCRIPTION: SQL command to create a source with SASL/PLAIN authentication without SSL encryption. Includes username and password configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_2 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Position Overview Materialized View in SQL\nDESCRIPTION: Creates a materialized view that provides key information on each betting position by joining positions with the most recent market price, calculating profit/loss and risk level.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW position_overview AS\nSELECT\n    p.position_id,\n    p.position_name,\n    p.league,\n    p.stake_amount,\n    p.max_risk,\n    p.fair_value,\n    m.market_price,\n    (m.market_price - p.fair_value) * p.stake_amount AS profit_loss,\n    CASE\n        WHEN (m.market_price - p.fair_value) * p.stake_amount > p.max_risk THEN 'High'\n        WHEN (m.market_price - p.fair_value) * p.stake_amount BETWEEN p.max_risk * 0.5 AND p.max_risk THEN 'Medium'\n        ELSE 'Low'\n    END AS risk_level,\n    m.timestamp AS last_update\nFROM\n    positions AS p\nJOIN\n    (SELECT position_id, market_price, timestamp,\n            ROW_NUMBER() OVER (PARTITION BY position_id ORDER BY timestamp DESC) AS row_num\n     FROM market_data) AS m\nON p.position_id = m.position_id\nWHERE m.row_num = 1;\n```\n\n----------------------------------------\n\nTITLE: Creating an A/B Test Results Materialized View in SQL\nDESCRIPTION: Creates a materialized view that analyzes A/B test results over 1-hour time windows. Uses joins to combine marketing events with campaign and variant information, calculating metrics like impressions, clicks, conversions, revenue, and conversion rate.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW ab_test_results AS\nSELECT\n    window_start,\n    window_end,\n    c.campaign_id,\n    c.campaign_name,\n    av.variant_name,\n    av.variant_type,\n    COUNT(DISTINCT CASE WHEN event_type = 'impression' THEN me.event_id END) as impressions,\n    COUNT(DISTINCT CASE WHEN event_type = 'click' THEN me.event_id END) as clicks,\n    COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN me.event_id END) as conversions,\n    SUM(CASE WHEN event_type = 'conversion' THEN amount ELSE 0 END) as revenue,\n    COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN me.event_id END)::float /\n        NULLIF(COUNT(DISTINCT CASE WHEN event_type = 'click' THEN me.event_id END), 0) as conversion_rate\nFROM TUMBLE(marketing_events, timestamp, INTERVAL '1 HOUR') as me\nJOIN campaigns c ON me.campaign_id = c.campaign_id\nJOIN ab_test_variants av ON c.campaign_id = av.campaign_id\nWHERE c.campaign_type = 'ab_test'\nGROUP BY\n    window_start,\n    window_end,\n    c.campaign_id,\n    c.campaign_name,\n    av.variant_name,\n    av.variant_type;\n```\n\n----------------------------------------\n\nTITLE: Using array_prepend Function in SQL\nDESCRIPTION: Prepends a compatible element to the beginning of the input array, resulting in a new array with the element at the first position.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\narray_prepend ( any_compatible, array ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_prepend(123, array[66]) → {123, 66}\n```\n\n----------------------------------------\n\nTITLE: Setting Time Zone Using SQL Syntax\nDESCRIPTION: The basic syntax for the SET TIME ZONE command, which allows specifying a time zone, setting to local system time, or resetting to default.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-time-zone.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET TIME ZONE { time_zone | LOCAL | DEFAULT };\n```\n\n----------------------------------------\n\nTITLE: Creating an Upsert MongoDB Sink with Single Key in RisingWave\nDESCRIPTION: Example of creating a sink with the upsert type for a table with a single primary key to MongoDB. Specifies the MongoDB URL, collection name, and primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mongodb.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE sink t2_sink FROM t2\nWITH (\n    connector='mongodb',\n    type = 'upsert',\n    mongodb.url = 'mongodb://mongodb:27017/?replicaSet=rs0',\n    collection.name = 'demo.t2',\n    primary_key='id'\n);\n```\n\n----------------------------------------\n\nTITLE: SQL Table Data Display\nDESCRIPTION: Result set showing the contents of the taxi_trips table with id, distance, and city columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-update.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n id | distance |    city\n----+----------+-------------\n  1 |       16 | Yerba Buena\n  2 |       23 | New York\n  3 |        6 | Chicago\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only MongoDB Sink in RisingWave\nDESCRIPTION: Example of creating a sink with the append-only type to MongoDB. Specifies the MongoDB URL and collection name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mongodb.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE sink t1_sink FROM t1\nWITH (\n    connector='mongodb',\n    type = 'append-only',\n    mongodb.url = 'mongodb://mongodb:27017/?replicaSet=rs0',\n    collection.name = 'demo.t1'\n);\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW FUNCTIONS Command in RisingWave SQL\nDESCRIPTION: An example of the SHOW FUNCTIONS command output in RisingWave. The result displays function names, argument types, return types, the language they're implemented in (Python in this example), and their server endpoint links.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-functions.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n       Name       |         Arguments         |                                Return Type                                | Language |         Link\n------------------+---------------------------+---------------------------------------------------------------------------+----------+-----------------------\n jsonb_concat     | jsonb[]                   | jsonb                                                                     | python   | http://localhost:8815\n array_access     | varchar[], integer        | varchar                                                                   | python   | http://localhost:8815\n hex_to_dec       | varchar                   | numeric                                                                   | python   | http://localhost:8815\n gcd              | integer, integer, integer | integer                                                                   | python   | http://localhost:8815\n gcd              | integer, integer          | integer                                                                   | python   | http://localhost:8815\n extract_tcp_info | bytea                     | struct<src_ip varchar,dst_ip varchar,src_port smallint,dst_port smallint> | python   | http://localhost:8815\n int_42           |                           | integer                                                                   | python   | http://localhost:8815\n series2          | integer                   | struct<x integer,y varchar>                                               | python   | http://localhost:8815\n series           | integer                   | integer                                                                   | python   | http://localhost:8815\n jsonb_access     | jsonb, integer            | jsonb                                                                     | python   | http://localhost:8815\n(10 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating a User Account with Password - RisingWave SQL\nDESCRIPTION: This SQL snippet provides an example of creating a new user named 'user1' with the password 'pAssword12345' in RisingWave. No particular system permissions are specified beyond the default; the password is set using the WITH PASSWORD clause. The input parameters are the username and password. A new user will be created and enabled for password authentication if the statement executes successfully.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER user1\n    WITH PASSWORD 'pAssword12345';\n```\n\n----------------------------------------\n\nTITLE: Granting RDS Replication Privilege for AWS PostgreSQL\nDESCRIPTION: SQL command to grant the rds_replication privilege to a user in AWS RDS/Aurora PostgreSQL environments, which is required for CDC operations in managed PostgreSQL instances.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nGRANT rds_replication TO <username>;\n```\n\n----------------------------------------\n\nTITLE: Registering Socket Address Parser in RisingWave\nDESCRIPTION: SQL command to create a function in RisingWave that maps to the Java socket address parser implementation. The function takes a VARCHAR input and returns a structured type with host and port fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION ip_port(varchar) RETURNS struct<host varchar, port smallint>\nAS ip_port USING link 'http://localhost:8815';\n```\n\n----------------------------------------\n\nTITLE: Creating Table from GCS Parquet Data in RisingWave SQL\nDESCRIPTION: This SQL example illustrates creating a RisingWave table that reads data from Parquet files stored in Google Cloud Storage. It defines the table schema (`id`, `name`, `age`), configures the GCS connector including bucket name and credentials, and uses `match_pattern` to select files ending with `.parquet`. The data format is specified using `FORMAT PLAIN ENCODE PARQUET`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(\n    id int,\n    name varchar,\n    age int\n)\nWITH (\n    connector = 'gcs',\n    gcs.bucket_name = 'example-bucket',\n    gcs.credential = 'xxxxx'\n    match_pattern = '*.parquet',\n) FORMAT PLAIN ENCODE PARQUET;\n```\n\n----------------------------------------\n\nTITLE: Syntax for Dropping a Column with ALTER TABLE in SQL\nDESCRIPTION: Explains the syntax for removing an existing column (`column_name`) from a table (`table_name`). The `DROP [COLUMN]` clause specifies the action. Using `IF EXISTS` prevents an error if the specified column does not exist in the table, issuing a notice instead. The `COLUMN` keyword is optional.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE table_name\n    DROP [ COLUMN ] [ IF EXISTS ] column_name;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Partial Indexes with INCLUDE Clause in SQL\nDESCRIPTION: Illustrates creation of an index with the INCLUDE clause on 'customers(c_phone)', including only 'c_name' and 'c_address' columns. Useful for covering queries that only access a subset of columns, reducing storage requirements. Requires 'customers' table to exist. The included SELECT shows how RisingWave leverages this index to speed up relevant queries. Limitation: only included columns are available in index-only access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Create an index that only includes necessary columns\nCREATE INDEX idx_c_phone1 ON customers(c_phone) INCLUDE (c_name, c_address);\n\n-- RisingWave will automatically use index idx_c_phone1 for the following query since it only access the indexed columns.\nSELECT c_name, c_address FROM customers WHERE c_phone = '123456789';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table Connected to Iceberg in RisingWave\nDESCRIPTION: Syntax for creating a table in RisingWave that reads data from an Apache Iceberg table. The syntax includes required parameters like table name and catalog settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/read-from-iceberg.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [IF NOT EXISTS] table_name WITH (\n  connector='iceberg',\n  connector_parameter='value',\n  ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with JSON Format in SQL\nDESCRIPTION: Defines a RisingWave source `source_abc` connected to a Kafka topic `demo_topic` with specified bootstrap servers. It expects messages in JSON format and parses them into `column1` (varchar) and `column2` (integer). The source starts reading from the latest offset or a specific timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with GROUPING SETS in SQL\nDESCRIPTION: Demonstrates the use of GROUPING SETS to perform multiple groupings in a single query, showing how to group by customer_id and product_category together and separately.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT customer_id, product_category, SUM(order_amount) AS total_amount\nFROM orders\nGROUP BY GROUPING SETS ((customer_id, product_category), ());\n```\n\n----------------------------------------\n\nTITLE: Ingesting JSON Payloads with Flexible Schema from S3 Using SQL\nDESCRIPTION: Illustrates a RisingWave SQL CREATE TABLE statement using INCLUDE payload, which allows ingestion of arbitrary JSON objects from S3 when the schema is not fully known upfront. Useful for semi-structured data ingestion where later pruning/filtering is desired. Requires S3 connectivity and optionally uses Kafka-like options if mixing with streaming sources. Result is a table that stores and exposes all payload data for later processing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\\nINCLUDE payload\\nWITH (\\n    connector = 's3',\\n    topic = 's3_1_partition_topic',\\n    properties.bootstrap.server = 'message_queue:29092',\\n    scan.startup.mode = 'earliest'\\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Including Multiple Metadata Fields in Kafka Table\nDESCRIPTION: Example of creating a table that ingests data from Kafka while including all supported metadata fields (key, partition, offset, timestamp, header, and payload) as additional columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE additional_columns (\n  a int,\n  primary key (key_col)\n)\nINCLUDE key AS key_col\nINCLUDE partition AS partition_col\nINCLUDE offset AS offset_col\nINCLUDE timestamp AS timestamp_col\nINCLUDE header AS header_col\nINCLUDE payload AS payload_col\nWITH (\n\tconnector = 'kafka',\n  properties.bootstrap.server = 'message_queue:29092',\n\ttopic = 'kafka_additional_columns')\nFORMAT UPSERT ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Batch Reading Examples from AWS S3 File Sources\nDESCRIPTION: This snippet demonstrates different ways to read data from AWS S3 in RisingWave, including creating a source, deriving a materialized view, creating a table with S3 connector, and directly querying the source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a source that connects to S3\nCREATE SOURCE s3_source WITH ( connector = 's3', ... );\n\n-- Create a materialized view from the source for batch processing\nCREATE MATERIALIZED VIEW mv AS SELECT * FROM s3_source;\n\n-- Create a table using the S3 connector\nCREATE TABLE s3_table ( ... ) WITH ( connector = 's3', ... );\n\n-- Select from the source directly\nSELECT count(*) from s3_source;\n```\n\n----------------------------------------\n\nTITLE: Complete PostgreSQL CDC Connection Example in RisingWave\nDESCRIPTION: A complete example showing how to create a PostgreSQL CDC source and a table from that source in RisingWave. It includes setting up the connection parameters and mapping to a specific table in the upstream database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a shared CDC source\nCREATE SOURCE pg_source WITH (\n    connector='postgres-cdc',\n    hostname='localhost',\n    port='5432',\n    username='your_user',\n    password='your_password',\n    database.name='your_database',\n    schema.name='public' -- Optional, defaults to 'public'\n);\n\n-- Create a table from the source, representing a specific PostgreSQL table\nCREATE TABLE my_table (\n    id INT PRIMARY KEY,\n    name VARCHAR\n)\nFROM pg_source TABLE 'public.my_upstream_table';\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source without Data Storage in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka source in RisingWave without storing the data. It defines a source with user_id, product_id, and timestamp columns, connecting to a Kafka topic named 'user_activity'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE my_kafka_source (\n    user_id INT,\n    product_id VARCHAR,\n    timestamp TIMESTAMP\n) WITH (\n    connector='kafka',\n    topic='user_activity',\n    properties.bootstrap.server='broker1:9092,broker2:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example: Adding an Integer Column using ALTER TABLE in SQL\nDESCRIPTION: Provides a practical example of the `ALTER TABLE ADD COLUMN` command. This specific command adds a column named `age` with the data type `int` to the table named `employees`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Add a column named \"age\" to a table named \"employees\" with a data type of integer\nALTER TABLE employees ADD age int;\n```\n```\n\n----------------------------------------\n\nTITLE: Implementing a Process-Time Temporal Join with a Versioned Table\nDESCRIPTION: This SQL query demonstrates how to join a sales table with a versioned products table using process-time temporal join. It fetches the latest product information based on the timestamp conditions between the process time and valid time ranges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT transaction_id, product_id, quantity, sale_date, product_name, price\nFROM sales\nJOIN products FOR SYSTEM_TIME AS OF PROCTIME()\nON product_id = id WHERE process_time BETWEEN valid_from AND valid_to;\n```\n\n----------------------------------------\n\nTITLE: Creating PostgreSQL CDC Source Connection for Supabase in RisingWave\nDESCRIPTION: This SQL command establishes a connection to a Supabase PostgreSQL database for CDC ingestion. It specifies the connection details including hostname, port, credentials, and replication settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/supabase-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE supabase_pgdb WITH (\n    connector = 'postgres-cdc',\n    hostname = 'db.xxxxxx.supabase.co',\n    port = '8306',\n    username = 'root',\n    password = '123456',\n    database.name = 'mydb',\n    slot.name = 'mydb_slot',\n    publication.name = 'rw_publication'\n);\n```\n\n----------------------------------------\n\nTITLE: Monitoring MySQL Real-time CDC Replication\nDESCRIPTION: This SQL query checks the real-time replication progress for a MySQL CDC source by querying the internal source table. It shows the current binlog file and position being consumed from MySQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_my_mysql_source_1_source_2;\n```\n\n----------------------------------------\n\nTITLE: Defining AWS Kinesis Sink SQL Syntax in RisingWave\nDESCRIPTION: SQL syntax for creating a sink from RisingWave to AWS Kinesis Data Streams, including connection parameters, data format options, and encoding configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/aws-kinesis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector = 'kinesis',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    key = 'value'\n) ]\n[KEY ENCODE key_encode [(...)]]\n;\n```\n\n----------------------------------------\n\nTITLE: Example of Creating a Google Cloud Storage Sink in SQL\nDESCRIPTION: This SQL example shows how to create a specific GCS sink named 'gcs_sink'. It selects data from a table 't1', specifies the GCS path, bucket name, credentials, and service account. The sink is configured as append-only and uses Parquet encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/google-cloud-storage.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK gcs_sink AS SELECT v1\nFROM t1\nWITH (\n    connector='gcs',\n    gcs.path = '<test_path>',\n    gcs.bucket_name = '<bucket_name>',\n    gcs.credential = '<account_name>',\n    gcs.service_account = '<service_account>'\n    type = 'append-only',\n)FORMAT PLAIN ENCODE PARQUET(force_append_only=true);\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source with a Generated Column in RisingWave SQL\nDESCRIPTION: Demonstrates creating a specific Kafka source named `from_kafka` using RisingWave SQL. It uses `*` to include all columns from the upstream Kafka topic, adds a generated column `gen_i32_field`, includes the Kafka message key using `INCLUDE KEY`, specifies Kafka connection details and topic name, and configures the format as `UPSERT` and encoding as `AVRO` with a schema registry location.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE from_kafka (\n  *,\n  gen_i32_field INT AS int32_field + 2\n)\nINCLUDE KEY AS some_key\nWITH (\n  connector = 'kafka',\n  topic = 'test-rw-sink-upsert-avro',\n  properties.bootstrap.server = 'message_queue:29092'\n)\nFORMAT upsert ENCODE AVRO (\n  schema.registry = 'http://message_queue:8081'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table from MySQL CDC Source with dbt\nDESCRIPTION: Creates a RisingWave table that ingests data from a MySQL CDC source using dbt's 'table_with_connector' materialization model. The table maps to the 't1' table in the 'mydb' database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n{{ config(materialized='table_with_connector') }}\nCREATE TABLE {{ this }}  (\n    v1 int,\n    v2 int,\n    PRIMARY KEY(v1)\n) FROM {{ ref('mysql_mydb') }} TABLE 'mydb.t1';\n\n```\n\n----------------------------------------\n\nTITLE: Scaling Compute Nodes\nDESCRIPTION: Bash commands for scaling compute nodes using kubectl, with options for both risingwave-operator and standard deployment.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# If you are using risingwave-operator\nkubectl apply -f <file-with-more-replicas>.yaml # or kubectl edit RisingWave/<name>\n# If you are not using risingwave-operator\nkubectl scale statefulset/risingwave-compute --replicas=<number-of-replicas>\n```\n\n----------------------------------------\n\nTITLE: Creating a Google Pub/Sub Sink with Local Emulator\nDESCRIPTION: Demonstrates how to create a table and sink data to Google Pub/Sub using a local emulator. The example creates a personnel table and configures a sink to stream data in PLAIN format with JSON encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/google-pub-sub.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS personnel (id integer, name varchar);\n\nCREATE SINK pubusb_sink\nFROM\n  personnel\nWITH\n(\n    connector = 'google_pubsub',\n    pubsub.endpoint = 'localhost:8900',\n    pubsub.emulator_host = 'localhost:8900', -- local emulator\n    pubsub.project_id = 'demo',\n    pubsub.topic = 'test',\n) FORMAT PLAIN ENCODE JSON (\n    force_append_only='true',\n);\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW TABLES command with LIKE pattern\nDESCRIPTION: Example showing how to use the SHOW TABLES command with a schema specification and a LIKE pattern to filter table names that start with 't_'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-tables.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES FROM public LIKE 't_';\n```\n\n----------------------------------------\n\nTITLE: Creating a Warehouse in Snowflake\nDESCRIPTION: SQL command to create a warehouse in Snowflake. This warehouse will be used for processing the dynamic table that reads upsert results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE WAREHOUSE test_warehouse;\n```\n\n----------------------------------------\n\nTITLE: Cloning and Starting RisingWave Demo Cluster\nDESCRIPTION: Commands to clone the RisingWave repository and start a Docker-based demo cluster for ad performance analysis. The cluster includes RisingWave components and a workload generator that feeds random data into Kafka topics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\n```\n\nLANGUAGE: bash\nCODE:\n```\ncd risingwave/integration_tests/ad-ctr\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Creating Source with Struct for JSON Parsing\nDESCRIPTION: Example of creating a source table using struct to parse JSON data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE z (nested STRUCT <v1 INTEGER, v2 VARCHAR>) FORMAT JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining SINK INTO TABLE Job in RisingWave - SQL\nDESCRIPTION: This command starts a new streaming job (sink) that writes aggregates from table t into the m1_store table, assigning constant key and output alias cnt. It uses the previously defined schema with primary key. Ensures synchronous record flow and conflict overwriting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK m1_stream INTO m1_store AS SELECT 1 as key, count(*) as cnt from t;\n```\n\n----------------------------------------\n\nTITLE: Example of Using ALTER FUNCTION SET SCHEMA in SQL\nDESCRIPTION: This SQL example demonstrates a practical application of the `ALTER FUNCTION ... SET SCHEMA` command. It changes the schema of a specific function named `test_func`, which accepts a single integer (INT) argument, moving it to a schema named `test_schema`. This assumes both the function and the target schema exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-function.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the schema of the function named \"test_func\" to a schema named \"test_schema\"\nALTER FUNCTION test_func(INT) SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Syntax for the EXPLAIN Command in RisingWave SQL\nDESCRIPTION: Defines the basic syntax structure for the `EXPLAIN` command in RisingWave. It allows specifying optional parameters (`option`) to modify the output of the execution plan for a given SQL `statement`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-explain.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN [ ( option [ , ... ] ) ] statement;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from S3 Source in RisingWave with Parquet Encoding (SQL)\nDESCRIPTION: Shows a practical example of defining a RisingWave table whose data is read from S3-held Parquet files. Uses s3_v2 as the connector, match_pattern to filter for relevant files, and passes all necessary S3 credential parameters. Intended for ingestion of columnar Parquet-encoded data with schema mapping onto the table definition. Produces a live table reflecting S3 object contents.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s(\\n    id int,\\n    name varchar,\\n    age int\\n)\\nWITH (\\n    connector = 's3_v2',\\n    match_pattern = '*.parquet',\\n    s3.region_name = 'ap-southeast-2',\\n    s3.bucket_name = 'example-s3-source',\\n    s3.credentials.access = 'xxxxx',\\n    s3.credentials.secret = 'xxxxx'\\n) FORMAT PLAIN ENCODE PARQUET;\n```\n\n----------------------------------------\n\nTITLE: Using SHOW CREATE INDEX Command in SQL\nDESCRIPTION: Example of using the SHOW CREATE INDEX command on the previously created 'idx1' index to see the query used to create it.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE INDEX idx1;\n```\n\n----------------------------------------\n\nTITLE: Defining a RisingWave Table Schema for DynamoDB Sink\nDESCRIPTION: This SQL statement creates a table in RisingWave with a schema that matches the partition key and sort key structure of a DynamoDB table. It ensures proper data mapping when sinking to DynamoDB.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/amazon-dynamodb.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS movies (\n    year integer,\n    title varchar,\n    description varchar,\n    primary key (year, title)\n);\n```\n\n----------------------------------------\n\nTITLE: Type String Format for Encryption Methods\nDESCRIPTION: Specifies the format for the type string parameter used in encryption functions. It defines how to specify algorithm, mode, and padding options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nalgorithm [-mode][/pad:padding]\n```\n\n----------------------------------------\n\nTITLE: Basic Arithmetic Operators in SQL\nDESCRIPTION: Fundamental mathematical operators for addition, subtraction, multiplication, division, and modulo operations. Also includes bitwise operations and basic mathematical functions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/mathematical.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n1 + 2 → 3\n1 - 2 → -1\n- (-1) → 1\n2 * 3 → 6\n3 / 2 → 1\n3.0 / 2 → 1.5\n3 / 1.8 → 1.666\n3 % 2 → 1\n2.0 ^ -2 → 0.25\n|/ 27 → 3\n@ -10 → 10\n91 & 15 → 11\n32 | 3 → 35\n17 # 5 → 20\n~1 → -2\n1 << 4 → 16\n8 >> 2 → 2\n```\n\n----------------------------------------\n\nTITLE: Changing Database Owner using ALTER DATABASE OWNER TO in SQL\nDESCRIPTION: Shows the syntax for changing the owner of a specific database using the `OWNER TO` clause. The `new_user` parameter specifies the user to become the new owner. Executing this requires the ability to `SET ROLE` to the new owning role and the `CREATEDB` privilege, unless the user is a superuser.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-database.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE database_name\n    OWNER TO new_user;\n```\n\n----------------------------------------\n\nTITLE: Including Raw Payload for Unknown Schemas in SQL\nDESCRIPTION: Creates a table that includes the entire payload when the upstream schema is unknown. This allows ingesting all JSON data first and then processing it during runtime without defining the exact schema upfront.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'kafka',\n    topic = 'kafka_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Implementing Predicate Pushdown in RisingWave (SQL)\nDESCRIPTION: These examples demonstrate how RisingWave utilizes predicate pushdown to optimize queries. The EXPLAIN outputs illustrate when a WHERE clause filter can be pushed down into the BatchScan for efficient execution or when it results in an additional BatchFilter layer. These snippets highlight how the choice of filter column impacts query plan efficiency.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(k1 INT, k2 INT, v1 INT, v2 INT, PRIMARY KEY(k1,k2));\n\n--- The predicate k1=1 is pushed down to the BatchScan.\nEXPLAIN SELECT * FROM t WHERE k1=1;\n BatchExchange { order: [], dist: Single }\n └─BatchScan { table: t, columns: [k1, k2, v1, v2], scan_ranges: [k1 = Int32(1)] }\n\n--- The predicate k2=1 cannot be pushed down to the BatchScan.\nEXPLAIN SELECT * FROM t WHERE k2=1;\n BatchExchange { order: [], dist: Single }\n └─BatchFilter { predicate: (t.k2 = 1:Int32) }\n   └─BatchScan { table: t, columns: [k1, k2, v1, v2] }\n```\n\n----------------------------------------\n\nTITLE: Querying Prometheus ServiceMonitors for RisingWave (Bash)\nDESCRIPTION: Lists all Prometheus ServiceMonitor resources with the risingwave/name label across all namespaces. Shows if Prometheus is correctly configured to collect data from the RisingWave deployment. Prerequisite: kubectl CLI configured for the Kubernetes cluster. Outputs a table of matching ServiceMonitors; should show risingwave-service-monitor in the monitoring namespace if successful.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get servicemonitors -A -l risingwave/name\n```\n\n----------------------------------------\n\nTITLE: Implementing JSONB Array Access Function in Java\nDESCRIPTION: A Java implementation of a scalar function that accesses elements from a JSON array using GSON parser. The function takes a JSON string and index as input and returns the element at that index as JSONB.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nimport com.google.gson.Gson;\n\n// Returns the i-th element of a JSON array.\npublic class JsonbAccess implements ScalarFunction {\n    static Gson gson = new Gson();\n\n    public @DataTypeHint(\"JSONB\") String eval(@DataTypeHint(\"JSONB\") String json, int index) {\n        if (json == null)\n            return null;\n        var array = gson.fromJson(json, Object[].class);\n        if (index >= array.length || index < 0)\n            return null;\n        var obj = array[index];\n        return gson.toJson(obj);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating JSON-encoded Kafka Sink from Materialized View in SQL\nDESCRIPTION: Example of creating a Kafka sink by selecting an entire materialized view, using JSON encoding and specifying Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Table Creation and Row Insertion Example in RisingWave SQL\nDESCRIPTION: Demonstrates creating a simple table with two integer columns and inserting three rows of data. This example sets up the data for demonstrating row constructors in the next example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (v1 int, v2 int);\nINSERT INTO t VALUES (1,12), (2,13), (3,30);\n```\n\n----------------------------------------\n\nTITLE: Querying the Materialized View in RisingWave\nDESCRIPTION: SQL query to retrieve the latest data from the aviation_mv materialized view, limiting the result to 5 rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/instaclustr-kafka.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM aviation_mv LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Setting Adaptive Parallelism for a Table in RisingWave\nDESCRIPTION: This example shows setting a table's parallelism to ADAPTIVE mode, which automatically adjusts to use all available resources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\n-- Set to ADAPTIVE\nALTER TABLE t SET PARALLELISM = adaptive;\nSELECT fragment_id, parallelism FROM rw_fragments;\n\n------RESULTS\n fragment_id | parallelism\n-------------+-------------\n           1 |          12\n           2 |          12\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: General Syntax for ALTER INDEX in SQL\nDESCRIPTION: Provides the basic syntax structure for the `ALTER INDEX` command in SQL. It shows that the command requires the index name followed by an alteration option (`alter_option`), which varies depending on the desired modification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER INDEX index_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Querying a Directory of Parquet Files from S3 with file_scan in SQL\nDESCRIPTION: Illustrates loading multiple Parquet files from a directory on S3 by referencing the directory path in file_scan. Requires all files in the directory to share the same schema, as schema inference is based on the first file detected. The function merges the contents of all matching Parquet files, returning results as if from a single virtual table. Limitations include requiring homogeneous file schemas and valid S3 access credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  product_id,\n  sales_date,\n  quantity,\n  revenue\nFROM file_scan(\n  'parquet',\n  's3',\n  'ap-southeast-2',\n  'xxxxxxxxxx',\n  'yyyyyyyy',\n  's3://your-bucket/path/to/sales_data_file_directory/'\n);\n\n----RESULT\nproduct_id |  sales_date  | quantity | revenue\n------------+-------------+----------+----------\n         12 | 2023-04-01   |       50 |   1000.00\n         12 | 2023-04-02   |       30 |    600.00\n         15 | 2023-04-01   |       20 |    400.00\n         15 | 2023-04-03   |       40 |    800.00\n         18 | 2023-04-02   |       25 |    500.00\n         18 | 2023-04-04   |       35 |    700.00\n(6 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Metric Averaging\nDESCRIPTION: SQL statement to create a materialized view that calculates the average metric values every 30 seconds using a tumble window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW metric_avg_30s AS\nSELECT\n    name AS metric_name,\n    window_start AS metric_time,\n    avg(value :: decimal) AS metric_value\nFROM\n    tumble(\n        prometheus,\n        timestamp,\n        interval '30 s'\n    )\nGROUP BY\n    name,\n    window_start\nORDER BY\n    window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from GCS CSV Data in RisingWave SQL\nDESCRIPTION: This SQL example demonstrates creating a RisingWave table that ingests data from CSV files stored in Google Cloud Storage. It defines the table schema, includes optional metadata columns `file` (renamed to `file_name`) and `offset` (defaulting to `_rw_gcs_offset`), specifies the GCS connector, bucket name, and Base64-encoded credentials. Although seemingly intended for CSV based on the tab title and delimiter setting, the example explicitly uses `FORMAT PLAIN ENCODE JSON`. The `delimiter` parameter is typically associated with CSV encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(\n    id int,\n    name varchar,\n    age int,\n    primary key(id)\n)\nINCLUDE file as file_name\nINCLUDE offset -- default column name is `_rw_gcs_offset`\nWITH (\n    connector = 'gcs',\n    gcs.bucket_name = 'example-bucket',\n    gcs.credential = 'xxxxx'\n) FORMAT PLAIN ENCODE JSON (\n    without_header = 'true',\n    delimiter = ',' -- set delimiter = E'\\t' for tab-separated files\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Append-Only Sink from Append-Only Source in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create an append-only sink in RisingWave, targeting a ClickHouse database. It specifies the connector type, sink type, and necessary ClickHouse connection details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s1_sink FROM t1_table\nWITH (\n    connector = 'clickhouse',\n    type = 'append-only',\n    clickhouse.url = '${CLICKHOUSE_URL}',\n    clickhouse.user = '${CLICKHOUSE_USER}',\n    clickhouse.password = '${CLICKHOUSE_PASSWORD}',\n    clickhouse.database = 'default',\n    clickhouse.table='demo_test'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with Upsert Avro Format in SQL\nDESCRIPTION: Defines a RisingWave table named `source_abc` that connects to a Kafka topic `test_topic` and handles upsert operations based on the primary key. It reads data in Avro format using Confluent Schema Registry for schema information and includes the Kafka message key as the `rw_key` column, which is also designated as the primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS source_abc (\n  primary key (rw_key)\n)\ninclude key as rw_key\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test_topic'\n)\nFORMAT UPSERT ENCODE AVRO (\n   message = 'message_name',\n   schema.registry = 'http://127.0.0.1:8081',\n   schema.registry.username='your_schema_registry_username',\n   schema.registry.password='your_schema_registry_password'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Campaign Performance Materialized View in SQL\nDESCRIPTION: Creates a materialized view to summarize performance metrics of marketing campaigns over 1-hour time windows, including impressions, clicks, conversions, and revenue.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW campaign_performance AS\nSELECT\n    window_start,\n    window_end,\n    c.campaign_id,\n    c.campaign_name,\n    c.campaign_type,\n    COUNT(DISTINCT CASE WHEN event_type = 'impression' THEN me.event_id END) as impressions,\n    COUNT(DISTINCT CASE WHEN event_type = 'click' THEN me.event_id END) as clicks,\n    COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN me.event_id END) as conversions,\n    SUM(CASE WHEN event_type = 'conversion' THEN amount ELSE 0 END) as revenue,\n    COUNT(DISTINCT CASE WHEN event_type = 'click' THEN me.event_id END)::float /\n        NULLIF(COUNT(DISTINCT CASE WHEN event_type = 'impression' THEN me.event_id END), 0) as ctr,\n    COUNT(DISTINCT CASE WHEN event_type = 'conversion' THEN me.event_id END)::float /\n        NULLIF(COUNT(DISTINCT CASE WHEN event_type = 'click' THEN me.event_id END), 0) as conversion_rate\nFROM TUMBLE(marketing_events, timestamp, INTERVAL '1 HOUR') as me\nJOIN campaigns c ON me.campaign_id = c.campaign_id\nGROUP BY\n    window_start,\n    window_end,\n    c.campaign_id,\n    c.campaign_name,\n    c.campaign_type;\n```\n\n----------------------------------------\n\nTITLE: Creating Demand Forecast Materialized View in SQL\nDESCRIPTION: Creates a materialized view to forecast demand by calculating how long the current stock will last based on recent sales trends, joining inventory_status and recent_sales views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW demand_forecast AS\nSELECT\n    i.warehouse_id,\n    i.product_id,\n    i.stock_level,\n    r.total_quantity_sold AS weekly_sales,\n    CASE\n        WHEN r.total_quantity_sold = 0 THEN 0\n        ELSE ROUND(i.stock_level / r.total_quantity_sold, 2)\n    END AS stock_days_remaining\nFROM\n    inventory_status AS i\nLEFT JOIN\n    recent_sales AS r\nON\n    i.warehouse_id = r.warehouse_id AND i.product_id = r.product_id;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Bytes Encoding in SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka source in RisingWave using Bytes encoding. It defines a single column of type bytea and specifies Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE t1 (id bytea)\nWITH (\n   connector='kafka',\n   topic='topic1',\n   properties.bootstrap.server='localhost:9093',\n) FORMAT PLAIN ENCODE BYTES;\n```\n\n----------------------------------------\n\nTITLE: Concatenating Two Arrays in SQL\nDESCRIPTION: Demonstrates how to concatenate two arrays of the same data type using the || operator. This operation is equivalent to using the array_cat function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\narray[66] || array[123] → {66, 123}\n```\n\n----------------------------------------\n\nTITLE: Card Layout Structure in Markdown\nDESCRIPTION: Defines a card-based navigation layout using markdown and HTML elements to display different types of system catalogs with icons and links.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<CardGroup> \n <Card title=\"Information schema\" icon=\"database\" iconType=\"solid\" href=\"/sql/system-catalogs/information-schema\" > A set of views containing information about objects defined in the current database. </Card> \n <Card title=\"PostgreSQL catalogs\" icon=\"table\" iconType=\"solid\" href=\"/sql/system-catalogs/pg-catalog\" > System catalogs and views of PostgreSQL supported by RisingWave. </Card> \n <Card title=\"RisingWave catalogs\" icon=\"wave-square\" iconType=\"solid\" href=\"/sql/system-catalogs/rw-catalog\" > System tables and views providing metadata about relations and cluster job status in RisingWave. </Card> \n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View in RisingWave - SQL\nDESCRIPTION: This SQL snippet creates a new materialized view (cust_sales) that summarizes sales by customer using aggregation (SUM of total_price) from an existing orders source. It requires the orders table or materialized view to exist. Parameters include target view name and selected columns; the output is a new materialized view with the computed sales_amount per customer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW cust_sales AS\n    SELECT\n        customer_id,\n        SUM(total_price) AS sales_amount\n    FROM orders\n    GROUP BY customer_id;\n\n```\n\n----------------------------------------\n\nTITLE: Dropping a Database with Syntax Example - RisingWave SQL\nDESCRIPTION: This snippet shows the syntax for deleting a database from RisingWave, with an optional IF EXISTS clause to avoid errors if the database does not exist. There are no external dependencies, but all dependent schemas must be removed beforehand. Input is the database name, and the output is permanent deletion of the specified database. This operation cannot be undone.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-database.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE [ IF EXISTS ] database_name;\n```\n\n----------------------------------------\n\nTITLE: LATERAL Subqueries Example in FROM Clause\nDESCRIPTION: Example of using LATERAL subqueries to reference columns from preceding FROM items. This query calculates the maximum sale amount and finds the customer name based on that amount.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/from-clause.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale_customer.customer_name\nFROM\n  salesperson,\n  -- Calculate the maximum sale and cache it in a derived table\n  LATERAL\n  (SELECT MAX(amount) AS amount\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id)\n  AS max_sale,\n  -- find customer, reusing cached maximum sale amount\n  LATERAL\n  (SELECT customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    AND all_sales.amount =\n        -- the cached maximum sale amount\n        max_sale.amount)\n  AS max_sale_customer;\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for Azblob Source in RisingWave SQL\nDESCRIPTION: Shows the syntax for defining the schema within the `CREATE SOURCE` statement when connecting to Azure Blob Storage. It details how to specify column names, data types, and optional primary keys (either per-column or composite).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a CDC Source Table in RisingWave via SQL\nDESCRIPTION: Demonstrates the general SQL DDL syntax for creating a CDC-enabled table in RisingWave using the 'mongodb-cdc' connector. This template allows users to define a source table, specifying the primary key and including a JSON payload, as well as optional metadata like timestamps. Required parameters include the connector type and MongoDB connection details. Inputs include the table schema and connector options; output is a CDC-enabled streaming source in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mongodb-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] source_name (\n    _id data_type PRIMARY KEY ,\n    payload jsonb\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n    connector='mongodb-cdc',\n    connector_parameter='value', ...\n);\n\n```\n\n----------------------------------------\n\nTITLE: Dropping the Last Remaining Overloaded Function by Name in SQL\nDESCRIPTION: Shows dropping the final remaining function named `f1` (specifically `f1(int, int)`) by using only its name. This is now possible because the other `f1` functions with different signatures have been dropped, making the name `f1` unique.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION f1;\n-- Or DROP FUNCTION f1(int,int);\n```\n\n----------------------------------------\n\nTITLE: Example: Swapping Subscription Names in SQL\nDESCRIPTION: Demonstrates how to swap the names of the subscriptions \"user_updates\" and \"admin_updates\" using the `ALTER SUBSCRIPTION ... SWAP WITH` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n-- Swap the names of the user_updates subscription and the admin_updates subscription.\nALTER SUBSCRIPTION user_updates\nSWAP WITH admin_updates;\n```\n\n----------------------------------------\n\nTITLE: Creating a MongoDB CDC Table with Metadata Fields in RisingWave SQL\nDESCRIPTION: Shows how to create a RisingWave SQL table ingesting MongoDB CDC streams and capturing additional metadata: commit timestamp, database name, and collection name, using multiple INCLUDE clauses. Demonstrates specifying MongoDB connector parameters suitable for containerized setups. Requires MongoDB with replica set and RisingWave with the mongodb-cdc connector enabled. Output includes extra metadata columns for each ingested change event.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mongodb-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE users (_id JSONB PRIMARY KEY, payload JSONB)\nINCLUDE TIMESTAMP as commit_ts\nINCLUDE DATABASE_NAME as database_name\nINCLUDE COLLECTION_NAME as collection_name\nWITH (\n  connector = 'mongodb-cdc',\n  mongodb.url = 'mongodb://mongodb:27017/?replicaSet=rs0',\n  collection.name = 'random_data.*'\n);\n\n```\n\n----------------------------------------\n\nTITLE: Creating a CDC Table for Multiple MongoDB Databases in RisingWave SQL\nDESCRIPTION: Demonstrates how to define a CDC source table in RisingWave that ingests data from all collections across multiple MongoDB databases using comma-separated wildcard patterns. Establishes the necessary collection pattern format and connector settings for broad ingestion from several sources. Inputs: multiple database patterns; Output: unified streaming table containing CDC events from all specified collections.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mongodb-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE source_name (\n   _id varchar PRIMARY KEY,\n   payload jsonb\n) WITH (\n   connector='mongodb-cdc',\n   mongodb.url='mongodb://localhost:27017/?replicaSet=rs0',\n   collection.name='db1.*, db2.*'\n);\n\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Kinesis Source/Table with Defined JSON Schema using SQL\nDESCRIPTION: This SQL snippet shows how to create a RisingWave source or table reading from an AWS Kinesis stream with JSON formatted data. It defines the expected columns (`column1`, `column2`) and their types. The connection details include the Kinesis connector, stream name, AWS region, endpoint, and authentication credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kinesis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [IF NOT EXISTS] source_name (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kinesis',\n   stream='kafka',\n   aws.region='user_test_topic',\n   endpoint='172.10.1.1:9090,172.10.1.2:9090',\n   aws.credentials.session_token='AQoEXAMPLEH4aoAH0gNCAPyJxz4BlCFFxWNE1OPTgk5TthT+FvwqnKwRcOIfrRh3c/L To6UDdyJwOOvEVPvLXCrrrUtdnniCEXAMPLE/IvU1dYUg2RVAJBanLiHb4IgRmpRV3z rkuWJOgQs8IZZaIv2BXIa2R4OlgkBN9bkUDNCJiBeb/AXlzBBko7b15fjrBs2+cTQtp Z3CYWFXG8C5zqx37wnOE49mRl/+OtkIKGO7fAE',\n   aws.credentials.role.arn='arn:aws-cn:iam::602389639824:role/demo_role',\n   aws.credentials.role.external_id='demo_external_id',\n   aws.credentials.access_key_id = 'your_access_key',\n   aws.credentials.secret_access_key = 'your_secret_key'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Adding a Column to a Table in RisingWave\nDESCRIPTION: SQL command for adding a new column to an existing table in RisingWave, specifying the column name and data type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE <table_name> ADD COLUMN <column_name> <column_type>;\n```\n\n----------------------------------------\n\nTITLE: Including Kafka Headers as Metadata\nDESCRIPTION: Examples of two different ways to include Kafka header information: either as a List of Structs containing all headers, or as individual columns for specific header values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE header [AS kafka_header]\n```\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE header 'header_col' [AS kafka_header]\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/PLAIN Authentication without SSL in RisingWave SQL\nDESCRIPTION: This example shows how to create a Kafka source with SASL/PLAIN authentication without SSL encryption. It includes the SASL username and password in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_2 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a table and sink in RisingWave\nDESCRIPTION: SQL queries to create a 'personnel' table in RisingWave and set up a sink to MySQL using the JDBC connector.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE personnel (\n id integer,\n name varchar,\n);\n\nCREATE SINK s_mysql FROM personnel WITH (\n connector='jdbc',\n jdbc.url='jdbc:mysql://<aws_rds_endpoint>:<port>/test_db',\n user='<username>',\n password='<password>',\n table.name='personnel',\n type = 'upsert',\n primary_key = 'id'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Interval Join in SQL with Time-Based Condition\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating an interval join between two sources with a time-based condition. The join requires equality on the id field and specifies that s1.ts must fall within a one-minute window after s2.ts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW interval_join AS\nSELECT s1.id AS id1,\n       s1.value AS value1,\n       s2.id AS id2,\n       s2.value AS value2\nFROM s1 JOIN s2\nON s1.id = s2.id and s1.ts between s2.ts and s2.ts + INTERVAL '1' MINUTE;\n```\n\n----------------------------------------\n\nTITLE: Example of Creating Table with Citus CDC Connector in RisingWave\nDESCRIPTION: A complete example of creating a table named 'github_events_rw' in RisingWave, using the Citus CDC connector. It includes all necessary connector parameters and table structure.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/citus-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE github_events_rw (\n    event_id bigint,\n    event_type text,\n    event_public boolean,\n    repo_id bigint,\n    payload jsonb,\n    repo jsonb,\n    user_id bigint,\n    org jsonb,\n    created_at timestamp,\n    PRIMARY KEY (event_id, user_id)\n) WITH (\n    connector = 'citus-cdc',\n    hostname = '127.0.0.1',\n    port = '5432',\n    username = 'dbz',\n    password = '123456',\n    database.servers = '172.31.29.245:5432,172.31.31.177:5432',\n    database.name = 'postgres',\n    schema.name = 'public',\n    table.name = 'github_events',\n    slot.name = 'github_events_dbz_slot1',\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with REST Catalog\nDESCRIPTION: Example of creating an Iceberg source using the REST catalog type, which acts as a proxy to other catalogs like Hive, JDBC, and Nessie catalog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_demo_rest\nWITH (\n    connector = 'iceberg',\n    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',\n    s3.region = 'ap-southeast-2',\n    s3.access.key = 'xxxx',\n    s3.secret.key = 'xxxx',\n    s3.path.style.access = 'true',\n    catalog.type = 'rest',\n    catalog.uri = 'http://localhost:8181/api/catalog',\n    warehouse.path = 'quickstart_catalog',\n    database.name = 'ns',\n    table.name = 't1',\n    catalog.credential='123456:123456',\n    catalog.scope='PRINCIPAL_ROLE:ALL',\n    catalog.oauth2_server_uri='xxx'\n    catalog.scope='xxx',\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave (SQL)\nDESCRIPTION: This SQL statement creates a materialized view named 'visits_stream_mv' in RisingWave. It aggregates data from the 'website_visits_stream' source, grouping by 'page_id' to calculate the total visits, count of unique visitors, and the timestamp of the last visit for each page.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW visits_stream_mv AS\nSELECT page_id,\ncount(*) AS total_visits,\ncount(DISTINCT user_id) AS unique_visitors,\nmax(timestamp) AS last_visit_time\nFROM website_visits_stream\nGROUP BY page_id;\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink from RisingWave to Supabase using JDBC Connector in SQL\nDESCRIPTION: This SQL command creates a sink named 'promotion_update' that transfers data from a materialized view 'product_calc_mv' in RisingWave to a 'promotions' table in Supabase. It uses the JDBC connector with PostgreSQL compatibility and specifies connection parameters including URL, credentials, and upsert operation type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/supabase.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK promotion_update FROM product_calc_mv WITH (\n  connector='jdbc',\n  jdbc.url='jdbc:postgresql://xxxx.supabase.co:5432/postgres',\n  user = 'postgres',\n  password = 'xxx',\n  table.name = 'promotions',\n  type = 'upsert'\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Kafka ACLs for RisingWave Consumer Groups using Bash\nDESCRIPTION: This Bash snippet shows the Kafka CLI command to add ACL permissions for a RiseWave consumer group prefix. It configures read access for a specific user/service account to all consumer groups matching the 'rw-consumer-.*' pattern on the target Kafka broker. Dependencies include a working Kafka installation and appropriate user permissions. Inputs are the broker address and principal; output is an updated Kafka ACL allowing RisingWave read access. Users must adapt the placeholders (broker-addr, user) before use.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./kafka-acls.sh --bootstrap-server <broker-addr> \\\n  --add --allow-principal User:<user or service account> \\\n  --consumer-group rw-consumer-.* \\\n  --operation READ\n```\n\n----------------------------------------\n\nTITLE: Creating IoT Sensor Data Table with MQTT Connector in RisingWave SQL\nDESCRIPTION: SQL query to create a table 'iot_sensor_data' in RisingWave that connects to a HiveMQ MQTT broker. This table stores IoT sensor data including device ID, timestamp, temperature, humidity, and device status.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hivemq.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE iot_sensor_data (\n  device_id VARCHAR,\n  ts TIMESTAMP,\n  temperature INTEGER,\n  humidity VARCHAR,\n  device_status INTEGER\n)\nWITH (\n  connector = 'mqtt', \n  url = 'ssl://xxxxxxxxx.s1.eu.hivemq.cloud:8883',\n  topic = 'iot_topic',\n  username = 'xxxxxx',\n  password = 'xxxxxx',\n  qos = 'at_least_once',\n  scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Debugging dbt connection to RisingWave\nDESCRIPTION: This command checks the connection between dbt and RisingWave. It's used to verify that the connection configurations in the profiles.yml file are correct.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndbt debug\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SASL/GSSAPI Authentication in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka sink with SASL/GSSAPI (Kerberos) authentication without SSL encryption. It includes Kerberos-specific parameters in the WITH clause of the CREATE SINK statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   type = 'append-only',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.sasl.mechanism='GSSAPI',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.kerberos.service.name='kafka',\n   properties.sasl.kerberos.keytab='/etc/krb5kdc/kafka.client.keytab',\n   properties.sasl.kerberos.principal='kafkaclient4@AP-SOUTHEAST-1.COMPUTE.INTERNAL',\n   properties.sasl.kerberos.kinit.cmd='sudo kinit -R -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal} || sudo kinit -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal}',\n   properties.sasl.kerberos.min.time.before.relogin='10000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Casting to rw_int256 in SQL\nDESCRIPTION: Shows how to cast other data types, such as hexadecimal strings, to rw_int256 using different syntax options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncast ('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe' AS rw_int256);\n```\n\nLANGUAGE: sql\nCODE:\n```\n'10000000000000000' :: rw_int256;\n```\n\n----------------------------------------\n\nTITLE: Syntax for SHOW JOBS Command in SQL\nDESCRIPTION: The syntax for the SHOW JOBS command in RisingWave. It allows for an optional LIKE expression to filter the output based on pattern matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-jobs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW JOBS [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Concatenating Maps in SQL\nDESCRIPTION: The map_cat function combines two maps. If the same key exists in both maps, the value from the second map takes precedence.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmap_cat ( map, map ) → map\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_cat (MAP{1:100,2:200}, MAP{2:201,3:300}) -> {1:100,2:201,3:300}\n```\n\n----------------------------------------\n\nTITLE: Initializing Immutable Parameter via Meta Node CLI - Bash\nDESCRIPTION: This Bash snippet shows the command-line syntax for initializing an immutable parameter (such as state_store or data_directory) before starting a RisingWave cluster. Run it in the directory where RisingWave is installed; replace <parameter_name> and <value> as required. Use this command only when bootstrapping a new cluster or changing immutable configurations before launch. Requires CLI access and should not be used once the system is running.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-system-parameters.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmeta-node --<parameter_name> <value>\n```\n\n----------------------------------------\n\nTITLE: Setting CSV Format in RisingWave SQL\nDESCRIPTION: Configures the format and encoding for consuming CSV data. Allows customization of delimiter and header options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT PLAIN\nENCODE CSV (\n    delimiter = 'delimiter',\n    without_header = 'false' | 'true'\n)\n```\n\n----------------------------------------\n\nTITLE: Creating an OpenSearch Sink in RisingWave SQL\nDESCRIPTION: SQL syntax for creating an OpenSearch sink in RisingWave. This code demonstrates how to configure the sink with parameters such as the connector type, primary key, index, URL, and authentication credentials. The sink will stream any inserted or updated data to the specified OpenSearch endpoint.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/opensearch.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_name\n[ FROM sink_from | AS select_query ]\nWITH (\n  connector = 'opensearch',\n  primary_key = '<primary key of the sink_from object>',\n  { index = '<your opensearch index>' | index_column = '<your index column>' },\n  url = 'http://<opensearch hostname>:<opensearch port>',\n  username = '<your opensearch username>',\n  password = '<your password>',\n  delimiter='<delimiter>'\n);\n```\n\n----------------------------------------\n\nTITLE: Generating Complete Time Windows with generate_series() in SQL - SQL\nDESCRIPTION: Demonstrates use of generate_series() in a CTE to build a complete series of window start timestamps, then LEFT JOINs this with existing aggregated data to fill missing time windows with zero counts. Requires access to the 'taxi_trips' table, and support for generate_series() and CTEs. Ensures full time coverage for reporting or visualization in time-based aggregations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nWITH time_series AS (\\n    SELECT \\n        generate_series(\\n            TIMESTAMP '2022-07-01 22:00:00',  -- Start time\\n            NOW(),  -- End time\\n            INTERVAL '2 MINUTES'              -- Step size\\n        ) AS window_start\\n)\\nSELECT \\n    ts.window_start,\\n    ts.window_start + INTERVAL '2 MINUTES' AS window_end,\\n    COALESCE(t.trip_count, 0) AS trip_count\\nFROM time_series ts\\nLEFT JOIN (\\n    SELECT \\n        window_start, \\n        COUNT(*) AS trip_count\\n    FROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES')\\n    GROUP BY window_start\\n) t\\nON ts.window_start = t.window_start\\nORDER BY ts.window_start;\n```\n\n----------------------------------------\n\nTITLE: Subquery Syntax in FROM Clause\nDESCRIPTION: Syntax for using a subquery in the FROM clause. Subqueries must be enclosed in parentheses and assigned a table alias name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/from-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nFROM (SELECT * FROM table1) AS alias_name\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SSL Encryption without SASL in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to create a Kafka source table with SSL encryption but without SASL authentication. It specifies the SSL certificate locations and key password in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS table_1 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.security.protocol='SSL',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Round Trip Time Anomalies\nDESCRIPTION: SQL statement to create a materialized view that detects anomalies in TCP round trip times (SRTT). This view filters for devices where the SRTT exceeds 500.0 milliseconds, indicating network latency issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW srtt_incidents AS\nSELECT\n    device_id,\n    window_end AS trigger_time,\n    metric_value AS trigger_value\nFROM\n    high_util_tcp_metrics\nWHERE\n    metric_name = 'srtt'\n    AND metric_value > 500.0;\n```\n\n----------------------------------------\n\nTITLE: Creating and Displaying a Materialized View in SQL\nDESCRIPTION: Example of creating a materialized view from a table and then using SHOW CREATE MATERIALIZED VIEW to display its creation query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-mv.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW v1 AS SELECT id FROM taxi_trips;\nSHOW CREATE MATERIALIZED VIEW v1;\n```\n\n----------------------------------------\n\nTITLE: Constructing Maps from Arrays in RisingWave SQL\nDESCRIPTION: Demonstrates two alternative methods to create maps: using map_from_key_values to combine separate key and value arrays, or using map_from_entries with an array of row pairs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/map-type.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT map_from_key_values(array['key1', 'key2', 'key3'], array[1,2,3]);\n-- OR\nSELECT map_from_entries(array[row('key1',1), row('key2',2), row('key3',3)]);\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Retransmission Rate Anomalies\nDESCRIPTION: SQL statement to create a materialized view that detects anomalies in TCP retransmission rates. This view filters for devices where the retransmission rate exceeds 0.15, indicating potential network issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW retrans_incidents AS\nSELECT\n    device_id,\n    window_end AS trigger_time,\n    metric_value AS trigger_value\nFROM\n    high_util_tcp_metrics\nWHERE\n    metric_name = 'retrans_rate'\n    AND metric_value > 0.15;\n```\n\n----------------------------------------\n\nTITLE: Indexing Concatenated Name Expressions in SQL\nDESCRIPTION: Provides an example of indexing a concatenated expression (first_name || ' ' || last_name) to optimize searches for full name strings. Dependencies: 'people' table with 'first_name' and 'last_name' columns. Input: composite queries for full names; output: accelerated exact match lookups using the created index.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM people WHERE (first_name || ' ' || last_name) = 'John Smith';\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX people_names ON people ((first_name || ' ' || last_name));\n```\n\n----------------------------------------\n\nTITLE: greatest Function in SQL\nDESCRIPTION: Illustrates the greatest function, which returns the largest value from a list of expressions, ignoring NULL values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ngreatest(value1, value2, ...) → ANY\n```\n\nLANGUAGE: sql\nCODE:\n```\ngreatest(1, 2, 3) → 3\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id INT, v1 INT2, v2 INT4, v3 INT8);\n\ninsert into t values (1, 1, 2, 3), (2, 2, NULL, 5), (3, NULL, NULL, 8), (4, NULL, NULL, NULL);\n\nselect greatest(v1, v2, v3) from t order by id;\n------ results\n3, 5, 8, NULL\n```\n\n----------------------------------------\n\nTITLE: Creating a Struct-Returning Python UDF in SQL (Class Method)\nDESCRIPTION: Demonstrates an alternative way to create a Python UDF that returns a structured type using a custom class.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE FUNCTION key_value(varchar) RETURNS STRUCT<key varchar, value varchar> LANGUAGE python AS $$\nclass KeyValue:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n\ndef key_value(s: str):\n    key, value = s.split('=')\n    return KeyValue(key, value)\n$$;\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink with Emit-on-Window-Close for Ordered Output in SQL\nDESCRIPTION: This SQL snippet demonstrates creating a sink `s` that selects columns `time` and `foo` from table `t`. The `EMIT ON WINDOW CLOSE` clause is used here to ensure that rows are emitted to the sink ordered by the watermark column (`time` in this context, based on the surrounding text suggesting watermark-based ordering). This is useful for scenarios requiring ordered output based on event time progression.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s AS\nselect time, foo from t emit on window close;\n```\n\n----------------------------------------\n\nTITLE: Array Constructor Syntax in RisingWave SQL\nDESCRIPTION: Shows the syntax for creating arrays from a list of expressions. The ARRAY keyword is followed by square brackets containing comma-separated expressions that will form the elements of the array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nARRAY [expression1, expression2, ...]\n```\n\n----------------------------------------\n\nTITLE: Querying Data from Kafka Source Table in RisingWave\nDESCRIPTION: This SQL query selects and displays the first 10 rows of data from the Kafka source table created in RisingWave. It demonstrates how to verify the ingested data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/confluent-cloud.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM s LIMIT 10 ;\n```\n\n----------------------------------------\n\nTITLE: Creating a Secret in RisingWave for Segment Webhook Validation\nDESCRIPTION: Creates a secret in RisingWave to securely store a secret string for validating incoming webhook requests from Segment.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/segment-webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'TEST_WEBHOOK';\n```\n\n----------------------------------------\n\nTITLE: Performing Time Travel Queries on Iceberg Table in SQL\nDESCRIPTION: These SQL queries demonstrate how to perform time travel queries on Iceberg tables. They show querying based on a specific timestamp and a specific Iceberg snapshot ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM users_iceberg FOR SYSTEM_TIME AS OF '2023-10-27 10:00:00';\n\nSELECT * FROM users_iceberg FOR SYSTEM_VERSION AS OF 876543219876543210;\n```\n\n----------------------------------------\n\nTITLE: Defining Syntax for CREATE SECRET in SQL\nDESCRIPTION: Provides the basic syntax template for creating a secret in RisingWave using SQL. It outlines the required keywords and placeholders for the secret name, backend specification (currently only 'meta'), and the secret value itself. This command is used to securely store sensitive credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-secret.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET secret_name WITH ( backend = 'meta') AS 'your_secret';\n```\n\n----------------------------------------\n\nTITLE: Basic GROUP BY Example in SQL\nDESCRIPTION: Illustrates a simple GROUP BY query that computes the average salary per department and job title combination from an employees table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT department, job_title, AVG(salary)\nFROM employees\nGROUP BY department, job_title;\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN JSON Format in RisingWave\nDESCRIPTION: SQL syntax for configuring standard JSON ingestion in RisingWave. This format directly decodes JSON data and requires schema definition in the CREATE SOURCE/CREATE TABLE statement or through a schema registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE JSON [ (\n   schema.registry = 'schema_registry_url [, ...]',\n   [schema.registry.username = 'username'],\n   [schema.registry.password = 'password']\n) ]\n```\n\n----------------------------------------\n\nTITLE: Building JSON Arrays with jsonb_build_array\nDESCRIPTION: Function that constructs a JSON array from variable arguments, converting each argument using to_jsonb.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_build_array(1, 2, 'foo', 4, 5);\nSELECT jsonb_build_array(variadic array[1, 2, 4, 5]);\n```\n\n----------------------------------------\n\nTITLE: Row Constructor Query Example in RisingWave SQL\nDESCRIPTION: Shows how to use a row constructor to create row values from table columns, including applying transformations to column values. The result is a set of row values with the specified structure.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT row (v1, v2*2) AS demo FROM t;\n```\n\n----------------------------------------\n\nTITLE: Setting up CA certificate for SSL connections in RisingWave Cloud\nDESCRIPTION: This snippet indicates the need to set up a CA certificate for enabling SSL connections to RisingWave Cloud. The specific command would be displayed in the portal for users to copy and run in their terminal window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connect-to-a-project.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Copy the command and run it in a terminal window.\n```\n\n----------------------------------------\n\nTITLE: Basic INCLUDE Clause Syntax in SQL\nDESCRIPTION: Syntax for the INCLUDE clause used to extract metadata fields from external sources. This defines how to specify which fields to include and optionally rename them.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE { header | key | offset | partition | timestamp | payload | subject | file | database_name | collection_name } [AS column_name]\n```\n\n----------------------------------------\n\nTITLE: Defining a Map Using Literal Notation in RisingWave SQL\nDESCRIPTION: Creates a map with string keys and integer values using literal notation. The result shows the map with key-value pairs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/map-type.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAP {'key1': 1, 'key2': 2, 'key3': 3};\n----RESULT\n{key1:1,key2:2,key3:3}\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for Webhook Data\nDESCRIPTION: Creates a table configured to accept webhook data from Amazon EventBridge, including signature validation using a secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/eventbridge-webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook',\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'authorization',\n  test_secret\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an S3 Sink in SQL for RisingWave\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a sink in RisingWave that sends data to Amazon S3. It includes placeholders for various required and optional parameters such as region name, bucket name, and credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/aws-s3.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='s3',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source in RisingWave\nDESCRIPTION: SQL syntax for creating a data source that connects to Apache Iceberg tables. This command establishes a connection to an Iceberg table using specified configuration parameters in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg-config.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [IF NOT EXISTS] source_name\nWITH (\n   connector='iceberg',\n   connector_parameter='value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with SASL/SCRAM Authentication\nDESCRIPTION: SQL command to create a table with SASL/SCRAM authentication using SHA-256 encryption without SSL. Includes username and password configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS table_4 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='SCRAM-SHA-256',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW SOURCES Command in RisingWave SQL\nDESCRIPTION: A practical example of using the SHOW SOURCES command to list all sources in the database, showing the result set with three sources listed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-sources.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SOURCES;\n\n----RESULT\n Name\n------\nnics_metrics\ntcp_metrics\ntwitter_events\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave\nDESCRIPTION: SQL command to create a materialized view based on the aviation_source. It transforms and casts certain columns from the source data, modifying their data types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/instaclustr-kafka.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW aviation_mv AS\nSELECT\n    flight_date,\n    departure_airport,\n    CAST(departure_scheduled AS TIMESTAMP) AS departure_scheduled,\n    CAST(departure_estimated AS TIMESTAMP)AS departure_estimated,\n    arrival_airport,\n    CAST(arrival_scheduled AS TIMESTAMP) AS arrival_scheduled,\n    airline_name,\n    flight_number,\nFROM aviation_source;\n```\n\n----------------------------------------\n\nTITLE: Syntax for Adding a Column with ALTER TABLE in SQL\nDESCRIPTION: Details the syntax for adding a new column (`column_name`) with a specified `data_type` to an existing table (`table_name`). Optionally, a `DEFAULT` value (`default_expr`) can be assigned for new rows where the column value is not explicitly provided. The `COLUMN` keyword is optional.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE table_name\n    ADD [ COLUMN ] column_name data_type [ DEFAULT default_expr ];\n```\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for ALTER TABLE in SQL\nDESCRIPTION: Outlines the fundamental syntax for the `ALTER TABLE` command. `table_name` specifies the target table, and `alter_option` represents the specific modification clause to be applied (e.g., ADD COLUMN, DROP COLUMN).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE table_name\n    alter_option;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Processing EventBridge Data\nDESCRIPTION: Creates a materialized view to extract specific fields from the JSON payload stored in the webhook table, enabling easier querying and analysis of the event data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/eventbridge-webhook.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW eventbridge_events AS\nSELECT\n  data->>'id' AS id,\n  data->'sender'->>'login' AS sender_login,\n  data->>'created_at' AS event_time\nFROM wbhtable;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from GCS JSON with Payload Column in RisingWave SQL\nDESCRIPTION: This SQL example demonstrates creating a RisingWave table to ingest JSON data from GCS when the exact schema is unknown or flexible. It defines minimal known columns (`v1`, `v2`) and uses `INCLUDE payload` to store the entire raw JSON object in a special column. It specifies the GCS connector (`connector = 'gcs'`). Note: The example includes parameters `topic` and `properties.bootstrap.server` which are typically used for Kafka connectors and might be extraneous or incorrect in a GCS context.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'gcs',\n    topic = 'gcs_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying RisingWave Internal Table for CDC Backfill Progress (SQL)\nDESCRIPTION: This SQL query shows how to check the progress of historical data backfilling for a RisingWave CDC table. It queries an internal table (e.g., `__internal_orders_rw_4002_streamcdcscan_5002`, where the name depends on the actual table and internal IDs) associated with the CDC table (`orders_rw` in this example context). The result shows details like the current split being processed, backfill status (`backfill_finished`), row count, and the current CDC offset.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_orders_rw_4002_streamcdcscan_5002;\n\n-[ RECORD 1 ]-----+---------------------------------------------------------------\nsplit_id          | 5001\no_orderkey        | 4024320\nbackfill_finished | f\nrow_count         | 1006080\ncdc_offset        | {\"MySql\": {\"filename\": \"binlog.000005\", \"position\": 60946679}}\n```\n\n----------------------------------------\n\nTITLE: Using min function in SQL\nDESCRIPTION: Returns the minimum value of non-null inputs, or null if no non-null values are provided. Works with numeric, string, date/time, interval types, or arrays.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nmin ( expression ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Table to Receive RudderStack Webhooks with Secret Validation (SQL)\nDESCRIPTION: This SQL statement creates a table named `wbhtable` designed to receive RudderStack webhook data. It defines a single column `data` of type `JSONB` to store the incoming payload. The `WITH (connector = 'webhook')` clause configures it as a webhook source. The `VALIDATE SECRET test_secret AS secure_compare(...)` clause specifies that incoming requests must be validated using the previously created `test_secret` by comparing it securely against the value found in the lowercase `authorization` HTTP header.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/rudderstack-webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook',\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'authorization',\n  test_secret\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink in RisingWave to Apache Doris - SQL Syntax\nDESCRIPTION: Defines the SQL syntax for creating a sink from RisingWave to Apache Doris. The syntax includes optional parameters and connection details required for establishing the data pipeline.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-doris.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='doris',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a MongoDB Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink to MongoDB from RisingWave. Includes placeholders for sink name, source, and configuration parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mongodb.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='mongodb',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a CDC Table with Metadata Columns in RisingWave SQL\nDESCRIPTION: This SQL statement creates a 'person' table in RisingWave, including typical columns for personal information as well as additional metadata fields (database_name, schema_name, table_name). These metadata fields provide context about the table's source in PostgreSQL when ingesting CDC data. The table configuration specifies CDC-related clauses: 'INCLUDE TIMESTAMP AS commit_ts' attaches a commit timestamp, and additional INCLUDE clauses map PostgreSQL metadata fields. The table pulls its data from the 'public.person' table in the upstream database using the CDC source 'pg_source'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id int,\n    name varchar,\n    email_address varchar,\n    credit_card varchar,\n    city varchar,\n    PRIMARY KEY (id)\n) INCLUDE TIMESTAMP AS commit_ts\nINCLUDE DATABASE_NAME as database_name\nINCLUDE SCHEMA_NAME as schema_name\nINCLUDE TABLE_NAME as table_name\nFROM pg_source TABLE 'public.person';\n\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Table with Commit Timestamp from PostgreSQL CDC (SQL)\nDESCRIPTION: This SQL snippet shows how to define a RisingWave table (`mytable`) to ingest data from a PostgreSQL source (`pg_source`). It utilizes the `INCLUDE timestamp AS commit_ts` clause to add a column containing the commit timestamp of the upstream change. The example `SELECT` query and its result illustrate that historical data receives a default timestamp (`1970-01-01 00:00:00+00:00`), while recent changes show their actual commit timestamp. Requires a pre-configured `pg_source`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE mytable (v1 int PRIMARY KEY, v2 varchar)\nINCLUDE timestamp AS commit_ts\nFROM pg_source TABLE 'public.mytable';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t2 ORDER BY v1;\n\n----RESULT\n v1 | v2 |         commit_ts\n----+----+---------------------------\n  1 | aa | 1970-01-01 00:00:00+00:00\n  2 | bb | 1970-01-01 00:00:00+00:00\n  3 | cc | 2024-05-20 09:01:08+00:00\n  4 | dd | 2024-05-20 09:01:08+00:00\n```\n\n----------------------------------------\n\nTITLE: Implementing Socket Address Parser in Java\nDESCRIPTION: A Java implementation of a scalar function that splits a socket address string into host and port components. Returns a structured type containing the parsed values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_10\n\nLANGUAGE: java\nCODE:\n```\n// Split a socket address into host and port.\npublic static class IpPort implements ScalarFunction {\n    public static class SocketAddr {\n        public String host;\n        public short port;\n    }\n\n    public SocketAddr eval(String addr) {\n        var socketAddr = new SocketAddr();\n        var parts = addr.split(\":\");\n        socketAddr.host = parts[0];\n        socketAddr.port = Short.parseShort(parts[1]);\n        return socketAddr;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Series Table Function\nDESCRIPTION: Example implementation of a table function that generates a series of integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport com.risingwave.functions.TableFunction;\n\npublic class Series implements TableFunction {\n    public Iterator<Integer> eval(int n) {\n        return java.util.stream.IntStream.range(0, n).iterator();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Aggregate Materialized View with Filter in RisingWave - SQL\nDESCRIPTION: This snippet creates a filtered materialized view (adult_users) that counts all users whose age is 18 or above. Demonstrates usage of a WHERE filter with aggregations. The source table 'users' is required. Outputs a single-row stream summarizing qualifying user count, and illustrates limitations of in-place updates for such filtered views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW adult_users AS\n  SELECT\n    COUNT(*) as user_count\n  FROM users\n  WHERE age >= 18;\n```\n\n----------------------------------------\n\nTITLE: Defining a Source with Kafka Connector in dbt Using SQL\nDESCRIPTION: This snippet shows how to define a dbt source model in SQL for RisingWave, using a Kafka connector for ingestion. It specifies a plain and JSON-encoded source with two columns (v1 and v2), leveraging dbt's config macro for materialization. Dependencies include dbt and RisingWave, with Kafka configured as the data source; you must ensure Kafka is running and accessible at the provided server address. Usage requires specifying the stream topic and Kafka bootstrap server, and input format is JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n```sql Define a source in dbt\n{{ config(materialized='source') }}\nCREATE SOURCE {{ this }} (v1 int, v2 varchar) WITH (\n  connector = 'kafka',\n  topic = 'kafka_1_partition_topic',\n  properties.bootstrap.server = 'message_queue:29092',\n  scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON\n```\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF Wrapper Function\nDESCRIPTION: Demonstrates creating a wrapper function that combines multiple UDFs into a single function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_sub_wrapper(INT, INT) returns int language sql as 'select add_wp($1, $2) + sub_wp($1, $2) + 114512';\n```\n\n----------------------------------------\n\nTITLE: Creating Subscription Progress Table in SQL\nDESCRIPTION: This SQL snippet creates a table named 'subscription_progress' to store the consumption progress of subscriptions. It uses a VARCHAR primary key for the subscription name and a BIGINT for the progress timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS subscription_progress (\n    sub_name VARCHAR PRIMARY KEY,\n    progress BIGINT\n) ON CONFLICT OVERWRITE;\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: Command to connect to RisingWave database using psql client.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SASL/OAUTHBEARER Authentication\nDESCRIPTION: Example of creating a Kafka sink using SASL/OAUTHBEARER authentication without SSL encryption. The sink connects to a Kafka topic with specific authentication parameters and formats the output as JSON.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   type = 'append-only',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.sasl.mechanism='OAUTHBEARER',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.oauthbearer.config='principal=bob'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Checking BYOC Environment Status After Update\nDESCRIPTION: This Bash command retrieves the status of a BYOC environment after an update using the RisingWave CLI (rwc).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ rwc byoc describe --name $BYOC_NAME\n```\n\n----------------------------------------\n\nTITLE: Creating Indexes on Expressions in SQL\nDESCRIPTION: Explains how to create an index not merely on columns but on expressions, to optimize queries involving computed values. Syntax is provided for generic expression indexing, enabling improved performance for queries on generated fields or expressions. Prerequisite: table and field presence. Key parameter is the SQL expression on one or more columns. Outputs: faster response for expression-based queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX index_name ON object_name (expression(column_name));\n```\n\n----------------------------------------\n\nTITLE: Using approx_percentile function in SQL\nDESCRIPTION: Returns an approximate value of the specified percentile from a numeric column with an optional relative error parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\napprox_percentile(DOUBLE percentile [, DOUBLE relative_error]) WITHIN GROUP (ORDER BY percentile_column) -> output_value\n```\n\n----------------------------------------\n\nTITLE: Setting License Key via SQL in RisingWave\nDESCRIPTION: SQL command to set a license key for an existing RisingWave cluster. This allows access to Premium Edition features.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-premium-edition-intro.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET license_key TO '...';\n```\n\n----------------------------------------\n\nTITLE: SHOW INTERNAL TABLES Syntax in RisingWave SQL\nDESCRIPTION: The SQL syntax for the SHOW INTERNAL TABLES command, which can optionally filter tables by schema name and pattern matching using a LIKE expression.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-internal-tables.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INTERNAL TABLES [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Complex Query with VALUES Clause and JOIN in RisingWave\nDESCRIPTION: Illustrates a more complex use of the VALUES clause in a subquery with JOIN to create a materialized view in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/values-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW join_mv AS\nWITH info(number, job) AS (VALUES (1, 'Writer'), (2, 'Software Engineer'), (3, 'Accountant')) \nSELECT * FROM mv JOIN info ON mv.id = info.number;\n```\n\n----------------------------------------\n\nTITLE: Configuring Bytes Format in RisingWave\nDESCRIPTION: SQL syntax for reading raw data streams without decoding using the BYTES row format. This format requires exactly one field of BYTEA data type in the table or source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE BYTES\n```\n\n----------------------------------------\n\nTITLE: Creating Ordered Materialized View for Performance - SQL\nDESCRIPTION: Showcases the creation of an intermediate materialized view that orders data by `v1` to enhance storage and read performance, particularly during downstream MV backfill. Requires an existing table `t` and sufficient storage in RisingWave. Takes no runtime parameters; the result is a view with ordered rows, improving cache locality and reducing remote I/O during batch queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate materialized view tmp as select * from t order by v1;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Highly Utilized TCP Metrics\nDESCRIPTION: SQL statement to create a materialized view that joins TCP and NIC metrics, filters for high utilization, and computes averages in 1-minute tumbling windows. This view serves as the foundation for anomaly detection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW high_util_tcp_metrics AS\nSELECT\n    tcp.device_id AS device_id,\n    tcp.window_end AS window_end,\n    tcp.metric_name AS metric_name,\n    tcp.metric_value AS metric_value,\n    nic.avg_util AS tcp_avg_bandwidth_util\nFROM\n    (\n        SELECT\n            device_id,\n            window_end,\n            metric_name,\n            AVG(metric_value) AS metric_value\n        FROM\n            TUMBLE(\n                tcp_metrics,\n                report_time,\n                INTERVAL '1' MINUTE\n            )\n        GROUP BY\n            device_id,\n            window_end,\n            metric_name\n    ) AS tcp\n    JOIN (\n        SELECT\n            device_id,\n            window_end,\n            AVG((metric_value) / bandwidth) * 100 AS avg_util\n        FROM\n            TUMBLE(\n                nics_metrics,\n                report_time,\n                INTERVAL '1' MINUTE\n            )\n        WHERE\n            metric_name = 'tx_bytes'\n            AND aggregation = 'avg'\n        GROUP BY\n            device_id,\n            window_end\n    ) AS nic ON tcp.device_id = nic.device_id\n    AND tcp.window_end = nic.window_end\nWHERE\n    avg_util >= 50;\n```\n\n----------------------------------------\n\nTITLE: Syntax for ALTER VIEW Command in SQL\nDESCRIPTION: General syntax structure for the `ALTER VIEW` command in SQL. It requires the view name and an `alter_option` clause specifying the modification to be performed. Specific clauses like `OWNER TO`, `SET SCHEMA`, `RENAME TO`, or `SWAP WITH` are used for `alter_option`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER VIEW view_name\n    alter_option;\n```\n```\n\n----------------------------------------\n\nTITLE: Swapping Sink Names using ALTER SINK in SQL\nDESCRIPTION: Demonstrates how to swap the names of two existing sinks using the `SWAP WITH` clause. This atomically exchanges the names specified by `name` and `target_name`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK name\nSWAP WITH target_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Swap the names of the log_sink sink and the error_sink sink.\nALTER SINK log_sink\nSWAP WITH error_sink;\n```\n\n----------------------------------------\n\nTITLE: Memory Usage Breakdown in RisingWave Compute Node\nDESCRIPTION: Example showing the memory allocation breakdown in a RisingWave compute node with 8GB total memory, including storage, compute, and reserved memory components.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/faq/faq-using-risingwave.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntotal_memory: 8.00 GiB\n    storage_memory: 2.13 GiB\n        block_cache_capacity: 688.00 MiB\n        meta_cache_capacity: 802.00 MiB\n        shared_buffer_capacity: 688.00 MiB\n    compute_memory: 3.47 GiB\n    reserved_memory: 2.40 GiB\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink from RisingWave to StarRocks in SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a sink in RisingWave to transfer data to StarRocks. It includes all necessary parameters such as connector type, host information, authentication details, and configuration options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/starrocks.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='starrocks',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Syntax for Changing Table Owner with ALTER TABLE in SQL\nDESCRIPTION: Describes the syntax used to change the ownership of a table (`table_name`) to a different user (`new_user`) using the `OWNER TO` clause. This change cascades to related internal objects and associated indexes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE table_name\n    OWNER TO new_user;\n```\n```\n\n----------------------------------------\n\nTITLE: Using array_position Function in SQL\nDESCRIPTION: Returns the subscript (position) of the first occurrence of a compatible element in the array. Positions are 1-based.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\narray_position ( array, any_compatible ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_position(array[1,2,3,4,5,6,1,2,3,4,5,6], 4) → 4\n```\n\n----------------------------------------\n\nTITLE: Swapping Subscription Names using SWAP WITH in SQL\nDESCRIPTION: Shows the syntax for swapping the names of two existing subscriptions using the `SWAP WITH` clause. The subscription identified by `name` will exchange its name with the subscription identified by `target_name`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION name\nSWAP WITH target_name;\n```\n\n----------------------------------------\n\nTITLE: Dropping a Schema in a Specific Database using SQL\nDESCRIPTION: This example demonstrates how to remove a specific schema named `rw_schema` located within the `rw_db` database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-schema.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA rw_db.rw_schema;\n```\n\n----------------------------------------\n\nTITLE: Querying Actor Distribution Across Compute Nodes in RisingWave (SQL)\nDESCRIPTION: This SQL query examines the distribution of actors (processing instances) across compute nodes by joining the `rw_actors` and `rw_parallel_units` tables. It groups the result by each worker node's ID, providing a count of actors per node for workload balancing assessment. The query output is a list of worker IDs and their corresponding actor counts, helping administrators detect imbalance and optimize resource utilization.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-a-large-number-of-streaming-jobs.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect worker_id, count(*) from rw_actors a, rw_parallel_units p where a.parallel_unit_id = p.id group by p.worker_id;\n```\n\n----------------------------------------\n\nTITLE: Modifying User Password and Privileges Example - SQL\nDESCRIPTION: This example shows altering the privileges and password for an existing user 'user001'. It uses the ALTER USER command to adjust role attributes such as 'NOSUPERUSER' and 'CREATEDB', and to set a new password. The snippet demonstrates changing multiple user properties in a single statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-user.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER user001 NOSUPERUSER CREATEDB PASSWORD '4d2Df1ee5';\n```\n\n----------------------------------------\n\nTITLE: Dropping an Index from a Materialized View in a Custom Schema - SQL\nDESCRIPTION: Removes the ad_id_index index from the ad_ctr_5min materialized view found in the rw_schema schema. The code demonstrates schema-qualified DROP INDEX usage in RisingWave SQL. Dependent objects can be dropped if CASCADE is used. Requires that the specified index exists in rw_schema. No result is returned unless dropping fails and IF EXISTS is not present.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP INDEX rw_schema.id_index;\n```\n\n----------------------------------------\n\nTITLE: Defining Watermark with Delay Using Interval - RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to define a watermark in RisingWave SQL as the observed event timestamp minus a delay interval. This method is useful for handling out-of-order data and can be configured with different time units such as seconds, minutes, etc. The 'INTERVAL' expression specifies the delay, and the watermark updates only when new, greater values are observed; dependencies are standard interval support in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/watermarks.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nWATERMARK FOR time_col as time_col - INTERVAL 'string' time_unit\n```\n\n----------------------------------------\n\nTITLE: Creating Another RisingWave CDC Table from Shared Source (SQL)\nDESCRIPTION: Similar to the previous example, this SQL snippet creates another RisingWave CDC table, `t3_rw`, using the same shared source `mysql_mydb`. It specifies a different upstream table, `'mydb.t3'`, demonstrating how a single shared source can be used to ingest data from multiple tables within the same upstream database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3_rw (\n  v1 INTEGER,\n  v2 timestamptz,\n  PRIMARY KEY (v1)\n) FROM mysql_mydb TABLE 'mydb.t3';\n```\n\n----------------------------------------\n\nTITLE: Deleting Rows from Table in RisingWave (SQL)\nDESCRIPTION: This SQL snippet deletes all rows from table 't' where the value of 'v1' is less than or equal to 3. It requires the existence of table 't' with those rows. The deletion modifies the underlying dataset, which will be reflected automatically in aggregates in materialized views like 'mv'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\ndelete from t where v1 <= 3;\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source with Protobuf Encoding in RisingWave\nDESCRIPTION: This example demonstrates how to create a source in RisingWave that reads data from a Kafka topic with Protobuf encoding. The command specifies the Kafka connector, topic name, bootstrap server, and schema registry details needed for Protobuf deserialization.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/format-and-encode-parameters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: js\nCODE:\n```\nCREATE SOURCE src_user WITH (\n    connector = 'kafka',\n    topic = 'sr_pb_test',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n)\nFORMAT PLAIN ENCODE PROTOBUF(\n    schema.registry = 'http://message_queue:8081',\n    message = 'test.User');\n\n```\n\n----------------------------------------\n\nTITLE: Table Definition Example\nDESCRIPTION: Shows the structure of a sample table containing array data that will be used with WITH ORDINALITY.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-ordinality-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n   arr\n---------\n {a,b,c}\n {d,e}\n```\n\n----------------------------------------\n\nTITLE: Configuring NodePort Service Type for RisingWave in Kubernetes\nDESCRIPTION: This YAML snippet shows how to configure the RisingWave service to use NodePort type in the risingwave.yaml file. This allows connecting to RisingWave from Nodes in Kubernetes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\n# ...\nkind: RisingWave\n...\nspec:\n  frontendServiceType: NodePort\n# ...\n```\n\n----------------------------------------\n\nTITLE: Creating Schema Registry Connection in SQL\nDESCRIPTION: Example SQL command to create a reusable connection named `sr_conn` for a Schema Registry. It specifies the connection type as `schema_registry` and provides the registry URL, username, and password.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION sr_conn WITH (\n  type = 'schema_registry',\n  schema.registry = 'http://...',\n  schema.registry.username = 'admin_user',\n  schema.registry.password = 'schema_registry_password'\n);\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW DATABASES Command in RisingWave\nDESCRIPTION: A simple example showing how to list all available databases in RisingWave using the SHOW DATABASES command without any filtering.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-databases.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW DATABASES;\n```\n\n----------------------------------------\n\nTITLE: Defining Raw Encryption and Decryption Functions in SQL\nDESCRIPTION: Defines the syntax for encrypt and decrypt functions which use a cipher to encrypt or decrypt data using a specified cryptographic algorithm. These functions take data, key, and type parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nencrypt(data bytea, key bytea, type text) -> bytea\ndecrypt(data bytea, key bytea, type text) -> bytea\n```\n\n----------------------------------------\n\nTITLE: Querying and Materializing Data from S3 Source in RisingWave Using SQL\nDESCRIPTION: Provides sample SQL statements to show typical workflows for querying directly from an S3-connected source, creating materialized views, or creating tables using the S3 connector. Covers SELECT, CREATE MATERIALIZED VIEW, and CREATE TABLE patterns. No external dependencies except RisingWave DDL/DML access and a set up S3 source. Outputs include live views and results from the ingested data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a materialized view from the source\\nCREATE SOURCE s3_source WITH ( connector = 's3', ... );\\nCREATE MATERIALIZED VIEW mv AS SELECT * FROM s3_source;\\n\\n-- Create a table with the S3 connector\\nCREATE TABLE s3_table ( ... ) WITH ( connector = 's3', ... );\\n\\n-- Select from the source directly\\nSELECT count(*) from s3_source;\n```\n\n----------------------------------------\n\nTITLE: Generating Array of Structs with RisingWave Data Generator\nDESCRIPTION: SQL statement to create a load generator source with an array of struct elements. It configures an array of 2 struct elements, each containing a random integer field 'v2' with values between 1 and 2.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1 (v1 struct<v2 int> [])\nWITH (\n    connector = 'datagen',\n    fields.v1.length = '2',\n    fields.v1._.v2.kind = 'random',\n    fields.v1._.v2.min = '1',\n    fields.v1._.v2.max = '2',\n    fields.v1._.v2.seed = '1',\n    datagen.rows.per.second = '10'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Raw Market Data Table in SQL\nDESCRIPTION: Creates a table to store raw market data including asset ID, timestamp, price, volume, and bid-ask prices.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE raw_market_data (\n    asset_id INT,\n    timestamp TIMESTAMPTZ,\n    price NUMERIC,\n    volume INT,\n    bid_price NUMERIC,\n    ask_price NUMERIC\n);\n```\n\n----------------------------------------\n\nTITLE: Session Window Aggregation with SQL - SQL\nDESCRIPTION: Aggregates unique products viewed per user in session windows, using FIRST_VALUE with SESSION WITH GAP clause to mark session boundaries (gap of 5 minutes). Operates on a 'user_views' table that includes 'user_id', 'product_id', 'viewed_at'. Returns user ID, session window start, and count of distinct products. Designed for RisingWave or similar systems supporting session windowing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\\n    user_id, window_start,\\n    count(DISTINCT product_id) AS n_viewed_product\\nFROM (\\n    SELECT\\n        *,\\n        first_value(viewed_at) OVER (\\n            PARTITION BY user_id ORDER BY viewed_at\\n            SESSION WITH GAP INTERVAL '5 MINUTES'\\n        ) AS window_start\\n    FROM user_views\\n)\\nGROUP BY user_id, window_start\\nORDER BY user_id, window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Avro-encoded Kafka Sink in SQL\nDESCRIPTION: SQL syntax for creating a Kafka sink with Avro encoding. Demonstrates the use of various schema registry options and parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT [ UPSERT | PLAIN ]\nENCODE AVRO (\n   schema.registry = 'schema_registry_url',\n   [schema.registry.username = 'username'],\n   [schema.registry.password = 'password'],\n   [schema.registry.name.strategy = 'topic_name_strategy'],\n   [key.message = 'test_key'],\n   [message = 'main_message',]\n)\n```\n\n----------------------------------------\n\nTITLE: Dropping an Index from a Table - SQL\nDESCRIPTION: Removes the id_index index from the taxi_trips table within the default schema (public) in RisingWave. This example illustrates the basic usage of DROP INDEX without referencing a specific schema or using optional clauses. Requires that id_index exists in the default schema. No output is produced unless an error is thrown and IF EXISTS is not specified.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP INDEX id_index;\n```\n\n----------------------------------------\n\nTITLE: Configuring UPSERT AVRO Format in RisingWave\nDESCRIPTION: SQL syntax for handling Avro updates/deletes (key-value pairs) from Kafka. A schema registry is required for Avro format in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT UPSERT\nENCODE AVRO (\n   schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Pulsar Source or Table in RisingWave (SQL)\nDESCRIPTION: This snippet demonstrates the SQL syntax used in RisingWave to create a new Pulsar source or table by specifying connection parameters and data formatting options. It supports both sources and persisted tables, where connector settings, authentication, and schema encoding can be defined. Key parameters include Pulsar topic, service URL, data format, and schema location or registry; outputs are new sources or tables which can ingest data according to these settings. Requires RisingWave with Pulsar connector enabled; Avro/Protobuf users must use web-based schemas.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} [ IF NOT EXISTS ] source_name\n[ schema_definition ]\n[INCLUDE { header | key | offset | partition | timestamp | payload } [AS <column_name>]]\nWITH (\n   connector='pulsar',\n   connector_parameter='value', ...\n)\nFORMAT data_format ENCODE data_encode (\n   message = 'message',\n   schema.location = 'location' | schema.registry = 'schema_registry_url'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Latest Timestamp - SQL\nDESCRIPTION: Creates a materialized view that tracks the maximum timestamp from the `transactions` table, ideal for append-only or source tables where transaction data is never updated or deleted. Requires a table named `transactions` with a `timestamp` field. The output is a single up-to-date timestamp value; the MV only needs to store the current maximum.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW time_latest_transaction AS SELECT max(timestamp) FROM transactions\n```\n\n----------------------------------------\n\nTITLE: Creating Thread View Count Materialized View\nDESCRIPTION: SQL statement to create a materialized view that calculates thread view counts using time window functions tumble() and hop() over 24-hour periods.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW thread_view_count AS WITH t AS (\n    SELECT\n        target_id,\n        COUNT() AS view_count,\n        window_start AS window_time\n    FROM\n        TUMBLE(\n            user_behaviors,\n            event_timestamp,\n            INTERVAL '10 minutes'\n        )\n    WHERE\n        target_type = 'thread'\n        AND behavior_type = 'show'\n    GROUP BY\n        target_id,\n        window_start\n)\nSELECT\n    target_id,\n    SUM(t.view_count) AS view_count,\n    window_start,\n    window_end\nFROM\n    HOP(\n        t,\n        t.window_time,\n        INTERVAL '10 minutes',\n        INTERVAL '1440 minutes'\n    )\nGROUP BY\n    target_id,\n    window_start,\n    window_end;\n```\n\n----------------------------------------\n\nTITLE: Using stddev_pop function in SQL\nDESCRIPTION: Calculates the population standard deviation of input values. Returns NULL if there are no non-null values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nstddev_pop ( expression ) -> output_value\n```\n\n----------------------------------------\n\nTITLE: Window Function Call Syntax in RisingWave SQL\nDESCRIPTION: Demonstrates the syntax for window function calls in RisingWave SQL. The window is defined by the OVER clause with optional PARTITION BY, ORDER BY, and frame clauses that control how rows are grouped and processed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nwindow_function_name ( [expression [, expression ... ]] ) OVER\n( PARTITION BY partition_expression\n[ ORDER BY sort_expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] ]\n[frame_clause])\n```\n\n----------------------------------------\n\nTITLE: ASOF Join for Correlating Stock Prices and Sentiments - SQL\nDESCRIPTION: This SQL statement performs an ASOF JOIN between stock price data and market sentiment information, matching each stock price with the latest sentiment record at or before the stock timestamp. It requires defined tables with appropriate timestamp fields and executes a join with both an equality condition (stock_name) and an inequality (market_time <= stock_time). Output contains stock details and their merged corresponding sentiment.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sp.stock_name, sp.stock_time, sp.price, md.sentiment\nFROM stock_prices sp\nASOF JOIN market_data md \nON sp.stock_name = md.stock_name \nAND md.market_time <= sp.stock_time;\n```\n\n----------------------------------------\n\nTITLE: Creating a CDC Table from a Specific PostgreSQL Schema/Table in RisingWave SQL\nDESCRIPTION: This SQL statement creates a CDC table 'tt3' in RisingWave that streams from the 'public.tt3' table in PostgreSQL. It defines column types and primary key, and links the table to the upstream CDC source ('pg_mydb'), requiring the schema-qualified source table name after the TABLE keyword. This enables flexible mapping from CDC sources to target tables while preserving type and schema consistency.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tt3 (\n    v1 integer primary key,\n    v2 timestamp with time zone\n) FROM pg_mydb TABLE 'public.tt3';\n```\n\n----------------------------------------\n\nTITLE: Creating a DynamoDB Sink in RisingWave SQL\nDESCRIPTION: This SQL statement creates a sink in RisingWave to transfer data to Amazon DynamoDB. It specifies the sink name, data source, connector type, and various configuration parameters for connecting to and writing data to DynamoDB.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/amazon-dynamodb.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector = 'dynamodb',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    format_parameter = 'value'\n) ];\n```\n\n----------------------------------------\n\nTITLE: Creating Protobuf-encoded Kafka Sink with UPSERT Format in SQL\nDESCRIPTION: SQL syntax for creating a Kafka sink with Protobuf encoding using UPSERT format. Demonstrates the use of message and schema location parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT UPSERT\nENCODE PROTOBUF (\n   message = 'com.example.MyMessage',\n   schema.location = 'location'\n) KEY ENCODE TEXT\n```\n\n----------------------------------------\n\nTITLE: Populating Records from JSONB Array\nDESCRIPTION: Expands a top-level JSON array of objects into rows with specified struct type. Converts JSON elements into structured data rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nselect * from jsonb_populate_recordset(\n    null::struct<a int, b int>,\n    '[{\"a\":1,\"b\":2}, {\"a\":3,\"b\":4}]'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Extracting First Path Match with jsonb_path_query_first\nDESCRIPTION: Function that returns only the first item matching a JSON path query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_path_query_first('{\n  \"employees\": [\n    {\n      \"name\": \"John\",\n      \"age\": 30\n    },\n    {\n      \"name\": \"Jane\",\n      \"age\": 25\n    },\n    {\n      \"name\": \"David\",\n      \"age\": 35\n    }\n  ]\n}', '$.employees[0]');\n```\n\n----------------------------------------\n\nTITLE: Checking RisingWave Cluster Status\nDESCRIPTION: Commands to check the current status of the RisingWave cluster and its output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get risingwave <risingwave-cluster>\n```\n\nLANGUAGE: sql\nCODE:\n```\nNAME         META STORE   STATE STORE   VERSION   RUNNING   AGE\nrisingwave   Etcd         S3            v1.3.0    True      2m20s\n```\n\n----------------------------------------\n\nTITLE: Using || Concatenation Operator in SQL\nDESCRIPTION: Appends a compatible element to the end of an array, achieving the same result as using the array_append function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\narray[66] || 123 → {66, 123}\n```\n\n----------------------------------------\n\nTITLE: Configuring Huawei Cloud OBS in Docker Compose File\nDESCRIPTION: Command line parameter for specifying the bucket name when using Huawei Cloud OBS as the state store. This should be added to the docker-compose-with-obs.yml file.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n--state-store hummock+obs://<bucket-name>\n```\n\n----------------------------------------\n\nTITLE: Configuring Iceberg Engine for S3 Tables in SQL\nDESCRIPTION: These SQL commands set the Iceberg engine connection to use the S3 Tables connection. They show both session-level and system-level configurations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSET iceberg_engine_connection = 'public.my_s3_tables_conn';\n\nALTER SYSTEM SET iceberg_engine_connection = 'public.my_s3_tables_conn';\n```\n\n----------------------------------------\n\nTITLE: Syntax for SQL DELETE Statement\nDESCRIPTION: Defines the basic syntax structure for the SQL `DELETE` command. It includes the target table name, an optional `WHERE` clause to specify conditions for row deletion, and an optional `RETURNING` clause to output specified columns from the deleted rows. The `WHERE` clause uses a boolean expression to filter rows, and omitting it deletes all rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM table_name\nWHERE condition\n[ RETURNING col_name ];\n```\n\n----------------------------------------\n\nTITLE: Querying Table Names in PostgreSQL\nDESCRIPTION: This SQL query retrieves the names of tables in the 'public' schema using the pg_tables system view. It demonstrates how to use system catalogs to obtain database metadata.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/pg-catalog.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT tablename FROM pg_tables WHERE schemaname = 'public';\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES SQL syntax\nDESCRIPTION: The syntax for the SHOW TABLES command, which allows viewing tables in a particular schema with optional pattern matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-tables.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Modifying Maps with map_insert Function in RisingWave SQL\nDESCRIPTION: Shows how to use the map_insert function to add new key-value pairs or update existing ones in a map. The first example adds a new entry, while the second example overwrites an existing key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/map-type.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT map_insert(MAP {'key1': 1, 'key2': 2, 'key3': 3}, 'key4', 4);\n----RESULT\n{key1:1,key2:2,key3:3,key4:4}\n\nSELECT map_insert(MAP {'key1': 1, 'key2': 2, 'key3': 3}, 'key2', 4);\n----RESULT\n{key1:1,key3:3,key2:4}\n```\n\n----------------------------------------\n\nTITLE: Granting SELECT Privilege for a Source Example (SQL)\nDESCRIPTION: This snippet grants SELECT privileges for the source s1 to user1. Demonstrates the most basic usage of the GRANT command for sources in RisingWave. Input: source name and user. Output: user1 gains SELECT privilege on source s1.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT SELECT\nON SOURCE s1\nTO user1;\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Connection with Glue Catalog in SQL\nDESCRIPTION: This SQL snippet shows how to create an Iceberg connection using a Glue catalog. It includes properties for warehouse path, S3 endpoint, region, and credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION public.conn WITH (\n    type = 'iceberg',\n    catalog.type = 'glue',\n    warehouse.path = 's3://my-iceberg-bucket/test',\n    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',\n    s3.region = 'ap-southeast-2',\n    s3.access.key = <access_key_id>,\n    s3.secret.key = <secret_key>,\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Enrichment Data Table in SQL\nDESCRIPTION: Creates a table to store external data that adds context to the raw market data, including sector, volatility, performance, and sentiment scores.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE enrichment_data (\n    asset_id INT,\n    sector VARCHAR,\n    historical_volatility NUMERIC,\n    sector_performance NUMERIC,\n    sentiment_score NUMERIC,\n    timestamp TIMESTAMPTZ\n);\n```\n\n----------------------------------------\n\nTITLE: Conditionally Dropping a Source in a Specific Schema in SQL\nDESCRIPTION: Illustrates the use of DROP SOURCE IF EXISTS to conditionally remove the 'rw_source' from the 'rw_schema' schema, preventing errors if the source does not exist. The snippet demonstrates qualified source naming and is useful for idempotent database operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-source.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP SOURCE IF EXISTS rw_schema.rw_source;\n\n```\n\n----------------------------------------\n\nTITLE: Using SHOW CREATE SINK in SQL\nDESCRIPTION: Command syntax for viewing the SQL statement used to create a specified sink in RisingWave. This command helps users verify sink settings and troubleshoot issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-sink.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SINK sink_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Vectors for Ad Bidding in SQL\nDESCRIPTION: This snippet creates a materialized view that generates feature vectors from bidding data for machine learning models. It calculates metrics like average bid, max bid, and win rate based on the last day's data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW bidding_feature_vectors AS\n  SELECT\n    ad_id,\n    AVG(bid_amount) AS avg_bid,\n    MAX(bid_amount) AS max_bid,\n    COUNT(*) AS bid_count,\n    SUM(CASE WHEN bid_won THEN 1 ELSE 0 END) AS win_count,\n    AVG(response_time) AS avg_response_time\n  FROM bidding_data\n  WHERE event_time >= NOW() - INTERVAL '1 day'\n  GROUP BY ad_id;\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with Storage Catalog\nDESCRIPTION: Example of creating an Iceberg source using the Storage catalog type, which stores metadata in the underlying file system (S3 in this case).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_demo_storage\nWITH (\n    connector = 'iceberg',\n    catalog.type = 'storage',\n    warehouse.path = 's3://icebergdata/demo',\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: SHOW INDEXES Command Output in RisingWave SQL\nDESCRIPTION: Sample output of the SHOW INDEXES command, displaying the index 'idx1' on table 't3' with its key columns, included columns, and distribution information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-indexes.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n Name | On |      Key       | Include | Distributed By\n------+----+----------------+---------+----------------\n idx1 | t3 | v1 ASC, v2 ASC | v3      | v1, v2\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating a Snowflake Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink to Snowflake in RisingWave. This snippet shows the general structure and required parameters for setting up the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='snowflake',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave Playground with Docker - Shell\nDESCRIPTION: This shell command runs the RisingWave playground environment in an interactive Docker container. It pulls the specified version of the RisingWave image, maps ports 4566 and 5691 from the container to the host for service access, and provides an ephemeral playground instance suitable for evaluation or demo purposes. Dependencies include having Docker installed and network permissions to pull images. The main parameter is the RisingWave image tag (e.g., v1.6.0, v1.5.0); expected output is a running instance of RisingWave on the local machine at the configured ports.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.6.0 playground\n```\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.5.0 playground\n```\n\n----------------------------------------\n\nTITLE: Granting Source Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This snippet demonstrates how to grant SELECT or ALL PRIVILEGES on sources to a user, either for specific sources/tables or all sources in specified schemas. Only SELECT privilege can be assigned and revoked for sources. Input: source or table names, schema names, and user. Output: user receives permissions for the designated sources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT { SELECT | ALL [PRIVILEGES]}\nON {  source_or_table_name [, ...]\n    | ALL SOURCES IN SCHEMA schema_name [, ...] }\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: General Syntax for ALTER SUBSCRIPTION in SQL\nDESCRIPTION: Provides the basic syntax structure for the `ALTER SUBSCRIPTION` command in RisingWave. It requires a subscription name and an alteration option clause to specify the modification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION subscription_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Dropping a Schema and Its Contents using CASCADE in SQL\nDESCRIPTION: This example demonstrates the use of the `CASCADE` option with `DROP SCHEMA`. It removes the `rw_schema` schema and automatically drops all objects contained within it (like tables, materialized views) and any objects that depend on those objects.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-schema.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA rw_schema CASCADE;\n```\n\n----------------------------------------\n\nTITLE: Performing Basic Operations on Iceberg Table in SQL\nDESCRIPTION: These SQL commands demonstrate inserting data into and selecting data from an Iceberg table. They show how to interact with Iceberg tables using standard SQL operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users_iceberg VALUES (1, 'Alice', NOW());\nINSERT INTO users_iceberg VALUES (2, 'Bob', NOW());\n\nSELECT * FROM users_iceberg WHERE user_id = 1;\n```\n\n----------------------------------------\n\nTITLE: Cancelling Streaming Jobs with SQL Command (SQL)\nDESCRIPTION: This snippet demonstrates the syntax required to cancel one or more currently running streaming jobs in the RisingWave database. Users must supply one or more job IDs, which can be obtained using the SHOW JOBS command. The SQL statement can cancel jobs for tables, views, sinks, or connectors that are in-progress; the result lists IDs of jobs successfully cancelled.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-cancel-jobs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL [ JOBS | JOB ] job_id [,...];\n```\n\n----------------------------------------\n\nTITLE: LEFT JOIN with LATERAL Subquery in SQL\nDESCRIPTION: Example of using a LEFT JOIN with a LATERAL subquery to ensure source rows appear in the result even if the subquery yields no rows. This is a rewrite of the previous query using LEFT JOIN.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/from-clause.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale.customer_name\nFROM\n  salesperson left join\n  -- find maximum size and customer at same time\n  LATERAL\n  (SELECT amount, customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    ORDER BY amount DESC LIMIT 1)\n  AS max_sale on true;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for NIC Metrics in RisingWave\nDESCRIPTION: SQL statement to create a source for network interface card (NIC) metrics from a Kafka topic. The source defines the schema for ingesting metrics data including device ID, metric name, and bandwidth information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE nics_metrics (\n    device_id VARCHAR,\n    metric_name VARCHAR,\n    aggregation VARCHAR,\n    nic_name VARCHAR,\n    report_time TIMESTAMP WITH TIME ZONE,\n    bandwidth DOUBLE PRECISION,\n    metric_value DOUBLE PRECISION\n) WITH (\n    connector = 'kafka',\n    topic = 'nics_metrics',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying Materialized View in psql Syntax (SQL)\nDESCRIPTION: This snippet demonstrates querying the materialized view 'mv' using the psql prompt (as indicated by 'dev=>'). It is functionally identical to previous select statements, and shows that the aggregates returned correspond to the current state of table 't'. The prefix illustrates command usage in the psql CLI.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\ndev=> select * from mv;\n v1_sum | v2_sum\n--------+--------\n      9 |     90\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Registering JSONB Access Function in RisingWave\nDESCRIPTION: SQL command to create a function in RisingWave that maps to the Java JSONB access implementation. The function takes JSONB and integer parameters and returns JSONB.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION jsonb_access(jsonb, int) RETURNS jsonb\nAS jsonb_access USING link 'http://localhost:8815';\n```\n\n----------------------------------------\n\nTITLE: Altering User Permissions and Password in SQL\nDESCRIPTION: This SQL command modifies the system permissions and password of an existing user in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER user001 WITH NOSUPERUSER CREATEDB PASSWORD '4d2Df1ee5';\n```\n\n----------------------------------------\n\nTITLE: Showing Table Columns Descriptions in RisingWave SQL\nDESCRIPTION: This SQL command reveals each column and its associated metadata, such as comments, in the specified table ('t1'). The statement is beneficial for schema inspection, providing a quick overview of column structure and descriptive annotations. The table must exist, and relevant metadata will be displayed accordingly.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with an Array Column\nDESCRIPTION: Illustrates the creation of a 'taxi' table with multiple columns, including an array column 'trip_id' of VARCHAR type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE taxi (\n        taxi_id VARCHAR,\n        trip_id VARCHAR[],\n        plate VARCHAR,\n        company VARCHAR,\n        license_expiration_date DATE,\n        licensed_to VARCHAR\n    );\n```\n\n----------------------------------------\n\nTITLE: Creating Secrets Syntax in RisingWave SQL\nDESCRIPTION: This SQL snippet shows the basic syntax for creating a secret in RisingWave. It uses the `CREATE SECRET` command, specifying a secret name and the backend (currently only 'meta' is supported), and provides the secret value as a string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET secret_name WITH ( backend = 'meta') AS 'your_secret';\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cluster Recovery Status in SQL\nDESCRIPTION: Shows how to use rw_recovery_status() function to retrieve the current recovery status of the cluster. The function returns one of 'STARTING', 'RECOVERING', or 'RUNNING'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nrw_recovery_status() -> varchar\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT rw_recovery_status();\n-- RESULT\n'RUNNING'\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View with AS CHANGELOG in SQL\nDESCRIPTION: Shows how to create a materialized view using a subquery with the AS CHANGELOG clause to incorporate changelog metadata into the materialized view's columns. Designed for a database supporting AS CHANGELOG (such as RisingWave), this snippet creates a view that aggregates event data and changelog operation details from a source stream. Inputs include the source table and columns to expose; the result is a materialized view that persists changelog context.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-as-changelog.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW ss_mv AS\nWITH sub AS CHANGELOG FROM user_behaviors\nSELECT\n    user_id,\n    target_id,\n    event_timestamp AT TIME ZONE 'America/Indiana/Indianapolis' AS event_timestamp,\n    changelog_op AS __op,\n    _changelog_row_id::bigint AS __row_id\nFROM\n    sub;\n```\n\n----------------------------------------\n\nTITLE: Creating a BigQuery Sink with S3 JSON Key File\nDESCRIPTION: Example of creating a BigQuery sink using an S3 JSON key file for authentication. This snippet shows how to configure the sink with S3-specific parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/bigquery.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK big_query_sink_s3\nFROM mv1\nWITH (\n    connector = 'bigquery',\n    type = 'append-only',\n    bigquery.s3.path= '${s3_service_account_json_path}',\n    bigquery.project= '${project_id}',\n    bigquery.dataset= '${dataset_id}',\n    bigquery.table= '${table_id}',\n    aws.credentials.access_key_id = '${aws_access_key}',\n    aws.credentials.secret_access_key = '${aws_secret_access}',\n    region = '${aws_region}',\n    force_append_only='true',\n);\n```\n\n----------------------------------------\n\nTITLE: Enabling Database-Level CDC in SQL Server (SQL)\nDESCRIPTION: This SQL command enables Change Data Capture (CDC) for the entire database context in which it is executed. It uses the `sys.sp_cdc_enable_db` system stored procedure. This is a prerequisite for enabling CDC on individual tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXEC sys.sp_cdc_enable_db;\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Table from PostgreSQL CDC Source (SQL)\nDESCRIPTION: This SQL syntax example demonstrates how to create a table in RisingWave that ingests data from a previously defined PostgreSQL CDC source. It requires defining the table schema, including column names and data types, and specifying the primary key(s) which must match the upstream PostgreSQL table. The `FROM source TABLE pg_table_name` clause links it to the source and specifies the upstream table, while `WITH (snapshot='true')` indicates an initial snapshot should be taken.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n   column_name data_type PRIMARY KEY , ...\n   PRIMARY KEY ( column_name, ... )\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n    snapshot='true'\n)\nFROM source TABLE pg_table_name;\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View in RisingWave with Java\nDESCRIPTION: Queries the 'counter' materialized view to retrieve the current aggregated data. The code fetches the total distance and duration values and displays them to the console.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/java.mdx#2025-04-23_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport java.sql.*;\nimport java.util.Properties;\n\npublic class retrieve {\n\n    public static void main (String arg[]) throws SQLException {\n\n        //If necessary, add the code for connecting to RisingWave here.\n\n        PreparedStatement showMV = conn.prepareStatement(\"SELECT * FROM counter;\");\n        ResultSet rs = showMV.executeQuery();\n        while (rs.next()) {\n            System.out.println(\"Total distance: \" + rs.getString(\"total_distance\"));\n            System.out.println(\"Total duration: \" + rs.getString(\"total_duration\"));\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Kafka Source Filtered by Timestamp in SQL\nDESCRIPTION: Demonstrates how to query a Kafka source `source_name` directly and filter messages based on their Kafka timestamp using the `_rw_kafka_timestamp` virtual column. This example selects messages received within the last 10 minutes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM source_name\nWHERE _rw_kafka_timestamp > now() - interval '10 minute';\n```\n\n----------------------------------------\n\nTITLE: Configuring S3 Tables with Iceberg Sink\nDESCRIPTION: Example SQL command that demonstrates how to configure RisingWave's Iceberg sink connector to use Amazon S3 Tables as its catalog. The command includes necessary SigV4 authentication parameters for the S3 Tables REST API.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK my_s3_tables_sink FROM source_table\nWITH (\n    connector = 'iceberg',\n    type = 'upsert', -- Or 'append-only'\n    primary_key = 'id', -- Required for 'upsert' type\n\n    -- Specify the S3 Tables warehouse ARN\n    warehouse.path = 'arn:aws:s3tables:<your-region>:<your-account-id>:bucket/<your-bucket-name>',\n    -- AWS Credentials\n    s3.access.key = '<your-aws-access-key-id>',\n    s3.secret.key = '<your-aws-secret-access-key>',\n    s3.region = '<your-region>', -- e.g., 'us-east-1'\n\n    -- S3 Tables REST catalog endpoint\n    catalog.uri = 'https://s3tables.<your-region>.amazonaws.com/iceberg',\n    -- REST catalog signing configurations\n    catalog.rest.signing_region = '<your-region>', -- e.g., 'us-east-1'\n    catalog.rest.sigv4_enabled = true,\n    catalog.rest.signing_name = 's3tables',\n    -- Specify REST catalog type\n    catalog.type = 'rest',\n\n    -- Target Iceberg table details within S3 Tables catalog\n    database.name = '<your-database-name>', -- Database in S3 Tables\n    table.name = '<your-table-name>',       -- Table name in S3 Tables\n    create_table_if_not_exists = true      -- Optional: Create table if it doesn't exist\n);\n```\n\n----------------------------------------\n\nTITLE: Updating a Source Schema with Protobuf in RisingWave\nDESCRIPTION: Example of refreshing a source's schema registry by modifying the Protobuf message type to accommodate new fields in the schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE src_user FORMAT PLAIN ENCODE PROTOBUF(\n    schema.registry = 'http://message_queue:8081',\n    message = 'test.UserWithMoreFields'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating JDBC Sink from RisingWave to PostgreSQL\nDESCRIPTION: SQL query to create a sink in RisingWave that will output data from the target_count materialized view to a PostgreSQL table using the JDBC connector.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK target_count_postgres_sink FROM target_count WITH (\n    connector = 'jdbc',\n    jdbc.url = 'jdbc:postgresql://postgres:5432/mydb',\n    user = 'myuser',\n    password = '123456',\n    table.name = 'target_count',\n    type = 'upsert',\n    primary_key = 'target_id'\n);\n```\n\n----------------------------------------\n\nTITLE: Window Frame Clause Syntax in RisingWave SQL\nDESCRIPTION: Shows the syntax options for window frame clauses, including ROWS, RANGE, and SESSION frames. Each option specifies which rows are included in window function calculations relative to the current row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n{ ROWS | RANGE } frame_start [ frame_exclusion ]\n{ ROWS | RANGE } BETWEEN frame_start AND frame_end [ frame_exclusion ]\nSESSION WITH GAP gap [ frame_exclusion ]\n```\n\n----------------------------------------\n\nTITLE: Syntax for Ranking Function Clause in RisingWave Top-N (SQL/JS)\nDESCRIPTION: Defines the syntax for the ranking function clause within a RisingWave Top-N query. It includes the function name (`row_number` or `rank`), an optional `PARTITION BY` clause for grouping, and a required `ORDER BY` clause for ordering within partitions or the entire set. Note: The original markdown uses 'js' identifier, but the content describes SQL syntax.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/top-n-by-group.mdx#2025-04-23_snippet_1\n\nLANGUAGE: js\nCODE:\n```\nfunction_name() OVER ([PARTITION BY col1[, col2...]]\n        ORDER BY col1 [ ASC | DESC ][, col2 [ ASC | DESC ]...])\n```\n\n----------------------------------------\n\nTITLE: Session Window Aggregation Using WINDOW Function Frames in RisingWave SQL\nDESCRIPTION: Uses window function frames with SESSION gaps to assign each row a session window based on activity in user_views. Outputs window_start and window_end calculated by first_value and last_value functions, grouping by user_id and ordered by viewed_at, with a 5-minute inactivity interval. Session windows are currently supported only in batch and emit-on-window-close streaming modes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\\n    user_id, product_id, viewed_at,\\n    first_value(viewed_at) OVER (\\n        PARTITION BY user_id ORDER BY viewed_at\\n        SESSION WITH GAP INTERVAL '5 MINUTES'\\n    ) AS window_start,\\n    last_value(viewed_at) OVER (\\n        PARTITION BY user_id ORDER BY viewed_at\\n        SESSION WITH GAP INTERVAL '5 MINUTES'\\n    ) AS window_end\\nFROM user_views\n```\n\n----------------------------------------\n\nTITLE: Creating Betting History Table in SQL\nDESCRIPTION: Creates a table to store historical betting records with details like user ID, position ID, bet amount, result, profit/loss, and timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE betting_history (\n    user_id INT,\n    position_id INT,\n    bet_amount FLOAT,\n    result VARCHAR,\n    profit_loss FLOAT, \n    timestamp TIMESTAMPTZ\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Watermark as Maximum Observed Timestamp - RisingWave SQL\nDESCRIPTION: This snippet shows how to declare the watermark as exactly the observed value of a timestamp column (e.g., 'time_col') in a RisingWave source. It requires that the column is present and of timestamp type, and is suitable for real-time processing where no delay is desired. No dependencies aside from the RisingWave SQL dialect are necessary.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/watermarks.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nWATERMARK FOR time_col as time_col\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection in Python\nDESCRIPTION: Sets up the database connection parameters for connecting to RisingWave using psycopg2 library in Python.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndefault_params = {\n    \"dbname\": \"dev\",\n    \"user\": \"root\",\n    \"password\": \"\",\n    \"host\": \"localhost\",\n    \"port\": \"4566\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Customer CDC Table in RisingWave\nDESCRIPTION: SQL command for creating a table in RisingWave that ingests CDC data from Neon's customer table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE customer (\n    customer_id INTEGER,\n    customer_name VARCHAR,\n    email VARCHAR,\n    phone_number VARCHAR\n    PRIMARY KEY (customer_id)\n) WITH (\n    connector = 'postgres-cdc',\n    hostname = '127.0.0.1',\n    port = '5432',\n    username = 'postgres',\n    password = 'postgres',\n    database.name = 'dev',\n    schema.name = 'public',\n    table.name = 'customer'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SASL/PLAIN Authentication and SSL Encryption in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka sink with both SASL/PLAIN authentication and SSL encryption. It combines SASL parameters with SSL parameters in the WITH clause of the CREATE SINK statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_SSL',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating an Upsert Table in RisingWave\nDESCRIPTION: This SQL command creates an upsert table in RisingWave, which supports in-place updates. It uses the data generator connector to populate the table with mock data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE s1_table (id int, name varchar)\nWITH (\n    connector = 'datagen',\n    fields.id.kind = 'sequence',\n    fields.id.start = '1',\n    fields.id.end = '10000',\n    fields.name.kind = 'random',\n    fields.name.length = '10',\n    datagen.rows.per.second = '200'\n) FORMAT UPSERT ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/PLAIN and SSL\nDESCRIPTION: SQL command to create a source with both SASL/PLAIN authentication and SSL encryption. Includes configuration for both authentication methods.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_3 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='PLAIN',\n   properties.security.protocol='SASL_SSL',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example: Moving a Subscription Between Schemas in SQL\nDESCRIPTION: Provides an example of moving the subscription named \"test_subscription\" into the schema named \"test_schema\" using the `ALTER SUBSCRIPTION ... SET SCHEMA` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Move the subscription named \"test_subscription\" to the schema named \"test_schema\"\nALTER SUBSCRIPTION test_subscription SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Altering Streaming Rate Limit Using risectl in Bash\nDESCRIPTION: Bash command using risectl to alter the streaming rate limit of an existing materialized view, where <id> can be found from the RisingWave Dashboard or rw_catalog schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/troubleshoot/troubleshoot-oom.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave ctl throttle source/mv <id> <source_rate_limit>\n```\n\n----------------------------------------\n\nTITLE: Including Timestamp from Kafka in SQL\nDESCRIPTION: Creates a table that ingests data from Kafka with an additional timestamp column. This example shows a simpler case with just a single included field.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_timestamp(v1 int, v2 varchar)\nINCLUDE timestamp AS event_timestamp\nWITH (\n connector='kafka',\n topic='kafka_1_partition_topic',\n properties.bootstrap.server='localhost:9092',\n scan.startup.mode='earliest'\n) format plain encode json;\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Table in RisingWave SQL\nDESCRIPTION: This example demonstrates how to create a basic table in RisingWave with three columns: id, distance, and city. Each column has a specified data type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-table.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE taxi_trips(\n    id VARCHAR,\n    distance DOUBLE PRECISION,\n    city VARCHAR\n);\n```\n\n----------------------------------------\n\nTITLE: LIKE and SIMILAR TO Pattern Matching in SQL\nDESCRIPTION: Pattern matching expressions using LIKE and SIMILAR TO operators with support for wildcards and metacharacters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nstring [ NOT ] { LIKE | ILIKE } pattern\n\nstring [!]~~[*] pattern\n```\n\nLANGUAGE: sql\nCODE:\n```\n'abc' LIKE 'abc'           true\n'abc' LIKE 'a%'            true\n'abc' LIKE '_b_'           true\n'abc' LIKE 'c'             false\n```\n\n----------------------------------------\n\nTITLE: Creating a materialized view in RisingWave using Ruby\nDESCRIPTION: This snippet creates a materialized view named 'counter' in RisingWave. The view calculates the sum of distance and duration from the 'walk' table, providing real-time aggregated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/ruby.mdx#2025-04-23_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'pg'\n\nconn = PG.connect(host: '127.0.0.1', port: 4566, dbname: 'dev', user: 'root')\n\nsql = <<-EOF\nCREATE MATERIALIZED VIEW counter\n    AS SELECT\n    SUM(distance) as total_distance,\n    SUM(duration) as total_duration\n    FROM walk;\nEOF\nconn.exec(sql)\n```\n\n----------------------------------------\n\nTITLE: HMAC Function Syntax in SQL\nDESCRIPTION: Defines the syntax for the HMAC function which calculates a hash-based message authentication code using a secret key, payload, and specified hash algorithm (SHA1 or SHA256).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nhmac (secret varchar, payload bytea, hash_algo varchar) -> signature bytea\n```\n\n----------------------------------------\n\nTITLE: Adding Column Comment with RisingWave SQL\nDESCRIPTION: This SQL command adds a descriptive annotation to the 'v1' column of table 't1' in RisingWave. The user must specify both the table and column name. The command stores the provided comment for documentation and metadata lookup purposes. It requires the column to exist before execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCOMMENT ON COLUMN t1.v1 IS 'column for the duration of the trip';\n```\n\n----------------------------------------\n\nTITLE: Describing Table Structure with RisingWave SQL\nDESCRIPTION: This SQL statement provides a summary view of the table 't1', including its columns, types, and any comments. It is an alternative to SHOW COLUMNS, offering schema details and embedded annotations. The command is useful for database users seeking to understand table structure and documentation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE t1;\n```\n\n----------------------------------------\n\nTITLE: Creating Marketing Events Table in SQL\nDESCRIPTION: Creates a table to track user interactions with marketing campaigns, including details such as clicks, impressions, and conversions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE marketing_events (\n    event_id varchar PRIMARY KEY,\n    user_id integer,\n    campaign_id varchar,\n    channel_type varchar,  -- email, social, search, display\n    event_type varchar,    -- impression, click, conversion\n    amount numeric,        -- conversion amount if applicable\n    utm_source varchar,\n    utm_medium varchar,\n    utm_campaign varchar,\n    timestamp timestamptz DEFAULT CURRENT_TIMESTAMP\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Table with S3 Tables in SQL\nDESCRIPTION: This SQL snippet creates an Iceberg table using the S3 Tables connection. It demonstrates how to specify the Iceberg engine and set the commit checkpoint interval.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE my_iceberg_table (\n    id INT PRIMARY KEY,\n    name VARCHAR\n)\nWITH (\n    commit_checkpoint_interval = 5\n)\nENGINE = iceberg;\n```\n\n----------------------------------------\n\nTITLE: Output of SHOW TABLES command\nDESCRIPTION: Example output from the SHOW TABLES command showing matching table name 't1' that starts with the requested pattern.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-tables.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nt1\n```\n\n----------------------------------------\n\nTITLE: Querying Data from RisingWave and Fetching Results in Python\nDESCRIPTION: Demonstrates querying data from a RisingWave table ('test') using the `risingwave-py` SDK. It executes a SQL query involving a time window (`tumble`) and aggregation (`avg`). The `rw.fetch()` method retrieves the results, defaulting to a Pandas DataFrame (`OutputFormat.DATAFRAME`). The snippet also shows how to retrieve results as a list of raw tuples using `OutputFormat.RAW`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom risingwave import OutputFormat\n\nresult: pd.DataFrame = rw.fetch(\"\"\"\n        SELECT window_start, window_end, product, ROUND(avg(price)) as avg_price\n        FROM tumble(test, ts, interval '10 seconds') \n        GROUP BY window_start, window_end, product\"\"\", \n        format=OutputFormat.DATAFRAME)\n\nprint(result)\n# Output:\n#          window_start          window_end product  avg_price\n# 0 2023-10-05 14:31:20 2023-10-05 14:31:30     bar      457.0\n# 1 2023-10-05 14:30:00 2023-10-05 14:30:10     foo      123.0\n\n# You can also use OutputFormat.RAW to get back list of tuples as the query results\n# rw.fetch(\"...\",  format=OutputFormat.RAW)\n# [(datetime.datetime(2023, 10, 5, 14, 31, 20), datetime.datetime(2023, 10, 5, 14, 31, 30), 'bar', 457.0), \n#  (datetime.datetime(2023, 10, 5, 14, 30), datetime.datetime(2023, 10, 5, 14, 30, 10), 'foo', 123.0)]\n```\n\n----------------------------------------\n\nTITLE: Calculating HMAC with SHA256 in SQL\nDESCRIPTION: Demonstrates how to use the HMAC function to calculate a message authentication code using SHA256 as the hash algorithm with a specified secret and payload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT hmac('secret', 'payload'::bytea, 'sha256');\n----RESULT\n\\xb82fcb791acec57859b989b430a826488ce2e479fdf92326bd0a2e8375a42ba4\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Processing Segment Webhook Data\nDESCRIPTION: Creates a materialized view to extract specific fields from the JSON payload of Segment webhook data for further processing and analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/segment-webhook.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW segmentb_events AS\nSELECT\n  data->>'action' AS action,\n  data->'repository'->>'full_name' AS repository_name,\n  data->'sender'->>'login' AS sender_login,\n  data->>'created_at' AS event_time\nFROM wbhtable;\n```\n\n----------------------------------------\n\nTITLE: Creating a Webhook Table in RisingWave for GitHub Events\nDESCRIPTION: Sets up a table in RisingWave configured to accept and validate webhook data from GitHub using HMAC SHA-256 signature verification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/github-webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'x-hub-signature-256',\n  'sha256=' || encode(hmac(test_secret, data, 'sha256'), 'hex')\n);\n```\n\n----------------------------------------\n\nTITLE: Joining Tumbling Windows with Reference Table - SQL\nDESCRIPTION: Performs a SQL join between a tumbling window aggregation (over 'taxi_trips') and a reference table ('taxi_simple') to enrich each windowed record with its associated company name. Requires both source tables; assumes both tables have a taxi_id field. Outputs windowed distance and company per trip window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT trip.window_start, trip.window_end, trip.distance, taxi_simple.company\\nFROM TUMBLE (taxi_trips, completed_at, INTERVAL '2 MINUTES') AS trip\\nJOIN taxi_simple\\nON trip.taxi_id = taxi_simple.taxi_id\\nORDER BY trip.window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Webhook Table with Raw String Validation in SQL\nDESCRIPTION: Shows how to create a webhook table using raw string validation instead of secrets management. Uses SHA-1 HMAC signature validation with a hardcoded secret value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook',\n) VALIDATE AS secure_compare(\n  headers->>'x-hub-signature',\n  'sha1=' || encode(hmac('secret_value', data, 'sha1'), 'hex')\n);\n```\n\n----------------------------------------\n\nTITLE: Checking JSON Path Existence with jsonb_path_exists\nDESCRIPTION: Function that checks if a JSON path returns any items from a JSON value. Supports optional variables and silent error handling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_path_exists('{\"a\":1, \"b\":2, \"c\":3}', '$.b');\n```\n\n----------------------------------------\n\nTITLE: Creating a Source Table with Datagen Connector in RisingWave SQL\nDESCRIPTION: This SQL statement creates a source table 's1' with five columns using the 'datagen' connector. It specifies various data generation parameters for each column, including array, struct, timestamp, and varchar types. The generator is set to produce 10 rows per second.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1 (i1 int [], v1 struct<v2 int, v3 double>, t1 timestamp, z1 timestamptz, c1 varchar)\nWITH (\n     connector = 'datagen',\n\n     fields.i1.length = '3',\n     fields.i1._.kind = 'sequence',\n     fields.i1._.start = '1',\n\n     fields.v1.v2.kind = 'random',\n     fields.v1.v2.min = '-10',\n     fields.v1.v2.max = '10',\n     fields.v1.v2.seed = '1',\n\n     fields.v1.v3.kind = 'random',\n     fields.v1.v3.min = '15',\n     fields.v1.v3.max = '55',\n     fields.v1.v3.seed = '1',\n\n     fields.t1.kind = 'random',\n     fields.t1.max_past = '2h 37min',\n     fields.t1.max_past_mode = 'relative',\n     fields.t1.seed = '3',\n\n     fields.z1.kind = 'random',\n     fields.z1.max_past = '2h 37min',\n     fields.z1.max_past_mode = 'relative',\n     fields.z1.seed = '3',\n\n     fields.c1.kind = 'random',\n     fields.c1.length = '16',\n     fields.c1.seed = '3',\n\n     datagen.rows.per.second = '10'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with Custom Message Size in SQL\nDESCRIPTION: Example of creating a Kafka sink with a custom message.max.bytes setting, demonstrating how to configure Kafka-specific properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='localhost:9092',\n   topic='test',\n   properties.message.max.bytes = 2000\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Example Workflow: Creating a Secret in RisingWave SQL\nDESCRIPTION: This is the first part of an example workflow, demonstrating the creation of a secret named `mysql_pwd` with the value '123' using the `CREATE SECRET` command in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET mysql_pwd WITH ( backend = 'meta' ) AS '123';\n```\n\n----------------------------------------\n\nTITLE: Scaling UDF Server with Multiple Processes\nDESCRIPTION: Python code for scaling the UDF server by launching multiple instances on different ports using multiprocessing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom multiprocessing import Pool\n\ndef start_server(port: int):\n    \"\"\"Start a UDF server listening on the specified port.\"\"\"\n    server = UdfServer(location=f\"localhost:{port}\")\n    # add functions ...\n    server.serve()\n\nif __name__ == \"__main__\":\n    \"\"\"Start multiple servers listening on different ports.\"\"\"\n    n = 4\n    with Pool(n) as p:\n        p.map(start_server, range(8816, 8816 + n))\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Redis Sink\nDESCRIPTION: SQL for creating a materialized view named 'bhv_mv' from a source, which will be used as the input for Redis sinks. The view selects user_id, target_id, and event_timestamp columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/redis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW bhv_mv AS\nSELECT\n    user_id,\n    target_id,\n    event_timestamp\nFROM\n    source_1;\n```\n\n----------------------------------------\n\nTITLE: Using SHOW CURSORS Command in SQL\nDESCRIPTION: The SHOW CURSORS command lists all cursors that are currently open in the active database session. This can be useful for tracking active cursors during troubleshooting or development.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-cursors.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CURSORS;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Permissions and Password - SQL\nDESCRIPTION: This snippet demonstrates creating a new user with optional system permissions and an authentication password using the CREATE USER command in SQL. Dependencies include valid user names, supported system permissions, and password format compliance. The required parameters are the user name; optional parameters include permissions and password (accepts NULL), and output is the creation of a new user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-user.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER user_name [ [ WITH ] system_permission [ ... ][PASSWORD { password | NULL }] ];\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Generated Columns in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to create a table with generated columns using the CREATE TABLE statement. The generated columns v1 and v3 are computed from v2 using simple arithmetic expressions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/generated-columns.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (v1 int AS v2-1, v2 int, v3 int AS v2+1);\n```\n\n----------------------------------------\n\nTITLE: Example: Creating a MySQL Password Secret in RisingWave SQL\nDESCRIPTION: This SQL code provides a specific example of creating a secret named `mysql_pwd` intended to store a MySQL password ('123'). It utilizes the `CREATE SECRET` command with the required `backend = 'meta'` option.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET mysql_pwd WITH (\n  backend = 'meta'\n) AS '123';\n```\n\n----------------------------------------\n\nTITLE: Cloning the RisingWave Repository and Starting the Demo Cluster\nDESCRIPTION: Commands to clone the RisingWave repository and start a demo cluster using Docker Compose. The cluster includes RisingWave components and a workload generator that feeds random data into Kafka topics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\n```\n\nLANGUAGE: bash\nCODE:\n```\ncd risingwave/integration_tests/cdn-metrics\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Creating Azblob Source for Parquet Data in RisingWave SQL\nDESCRIPTION: Provides an example of creating a RisingWave source `s2` to ingest Parquet data from Azure Blob Storage. It defines the schema (id, name, age), configures the `azblob` connector with connection details and a `match_pattern` ('*.parquet') to select Parquet files, and sets the format to `PLAIN` and encoding to `PARQUET`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s2(\n    id int,\n    name varchar,\n    age int\n)\nWITH (\n    connector = 'azblob',\n    azblob.container_name = 'xxx',\n    azblob.credentials.account_name = 'xxx',\n    azblob.credentials.account_key = 'xxx',\n    azblob.endpoint_url = 'xxx',\n    match_pattern = '*.parquet',\n) FORMAT PLAIN ENCODE PARQUET;\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Sink in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates how to create an Elasticsearch sink in RisingWave. It specifies the sink name, data source, and various configuration parameters including the Elasticsearch connection details, index name, and authentication credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/elasticsearch.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_name\n[ FROM sink_from | AS select_query ]\nWITH (\n  connector = 'elasticsearch',\n  primary_key = '<primary key of the sink_from object>',\n  { index = '<your Elasticsearch index>' | index_column = '<your index column>' },\n  url = 'http://<ES hostname>:<ES port>',\n  username = '<your ES username>',\n  password = '<your password>',\n  delimiter='<delimiter>'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Source with Generated Column and Watermark - RisingWave SQL\nDESCRIPTION: This example creates a RisingWave source where the timestamp of interest is nested within a STRUCT, extracted using a generated column, and then a watermark is defined on this generated column with a 5-second delay. This allows more complex schemas, such as those with nested data, to be used for event time processing. Dependencies include support for STRUCT types and generated columns in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/watermarks.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s2 (\n    order_id BITINT,\n    detail STRUCT<\n        product VARCHAR,\n        user VARCHAR,\n        price DOUBLE PRECISION\n        order_time TIMESTAMP\n    >,\n    order_time AS (detail).order_time,\n    WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND\n) WITH ( ... );\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Connection in SQL\nDESCRIPTION: Example SQL command to create an Iceberg connection named `CONN`. It specifies the connection type as `iceberg`, sets the catalog type to `storage`, and configures S3-related parameters like warehouse path, endpoint, region, access key, and secret key for accessing the Iceberg data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION CONN WITH (\n    type = 'iceberg',\n    catalog.name = 'demo',\n    catalog.type = 'storage',\n    warehouse.path = 's3a://hummock001/iceberg-data',\n    s3.endpoint = 'http://127.0.0.1:9301',\n    s3.region = 'us-east-1',\n    s3.access.key = 'hummockadmin',\n    s3.secret.key = 'hummockadmin'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Citus CDC Connector in RisingWave\nDESCRIPTION: SQL syntax for creating a table in RisingWave using the native Citus CDC connector. It includes the table structure and connector parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/citus-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] source_name (\n    column_name data_type PRIMARY KEY , ...\n    [PRIMARY KEY ( column_name, ... )]\n)\nWITH (\n    connector='citus-cdc',\n    connector_parameter='value', ...\n)\n[ FORMAT DEBEZIUM ENCODE JSON ];\n```\n\n----------------------------------------\n\nTITLE: Copying Data from a Source to a Table in RisingWave SQL\nDESCRIPTION: Demonstrates a pattern for creating a connection to a data source and then manually copying data into a standard batch table. This example shows the three-step process of creating a source, creating a table, and inserting data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/overview.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a connection (data not stored)\nCREATE SOURCE my_source ...;\n\n-- Create a standard table\nCREATE TABLE my_batch_table (...);\n\n-- Copy data from the source to the table\nINSERT INTO my_batch_table SELECT * FROM my_source;\n```\n\n----------------------------------------\n\nTITLE: Defining Hopping Windows in RisingWave SQL\nDESCRIPTION: Shows the syntax for the hop() time window function in RisingWave SQL, which allows rows to be included in overlapping (hopping) windows. Each window is defined by a hop_size and window_size, with optional offset. Requires a compatible table/source and suitable time column, both hop_size and window_size as INTERVAL types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT [ ALL | DISTINCT] [ * | expression [ AS output_name ] [, expression [ AS output_name ]...] ]\\nFROM HOP ( table_or_source, time_col, hop_size, window_size [, offset ]);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for AMQ Streams Data\nDESCRIPTION: SQL command to create a table in RisingWave that connects to the AMQ Streams topic. It defines the schema and specifies the Kafka connector settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/redhat-amq-streams.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE financial_transactions (\n    tx_id VARCHAR PRIMARY KEY,\n    sender_account VARCHAR,\n    receiver_account VARCHAR,\n    amount NUMERIC,\n    currency VARCHAR,\n    tx_timestamp TIMESTAMP\n)\nWITH(\n  connector='kafka',\n  topic = 'financial-transactions',\n  properties.bootstrap.server = 'localhost:9092',\n  scan.startup.mode = 'earliest'\n  )\n  FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Applying a Temporal Filter to Delay Input for Temporal Join\nDESCRIPTION: Demonstrates how to use a temporal filter within a subquery to delay the processing of records from the `fact` source before performing a temporal join. The filter `fact.p_time + INTERVAL '5' SECOND < NOW()` holds back records for 5 seconds, allowing corresponding records in the `dimension` table more time to arrive, thus mitigating potential issues caused by data arrival latency. The temporal filter should be applied in a subquery in the FROM clause due to potential optimizer limitations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n  CREATE MATERIALIZED VIEW mv AS\n  SELECT\n    id1, a1, a2\n  FROM (\n    -- Delay the source for 5 seconds\n    SELECT * FROM fact WHERE fact.p_time + INTERVAL '5' SECOND < NOW()\n  ) fact\n  LEFT JOIN dimension FOR SYSTEM_TIME AS OF PROCTIME() ON id1 = id2;\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Table from MySQL Source\nDESCRIPTION: SQL command to create a RisingWave table that mirrors a table from the MySQL source. This table will automatically update its schema when changes occur in the source table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_19\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE rw_customers (\n    id BIGINT,\n    modified TIMESTAMP,\n    custinfo JSONB,\n    PRIMARY KEY (id)\n) FROM mysql_source TABLE 'mytest.customers';\n```\n\n----------------------------------------\n\nTITLE: Creating Example Functions for DROP Demonstration in SQL\nDESCRIPTION: Creates several Python user-defined functions (`f1` with zero, one, and two integer arguments, and `f2` with two integer arguments) in RisingWave using `CREATE FUNCTION`. These functions serve as examples for demonstrating the `DROP FUNCTION` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION f1() RETURNS real LANGUAGE python AS func1 USING LINK 'http://localhost:8815';\nCREATE FUNCTION f1(int) RETURNS int LANGUAGE python AS func2 USING LINK 'http://localhost:8815';\nCREATE FUNCTION f1(int,int) RETURNS int LANGUAGE python AS func3 USING LINK 'http://localhost:8815';\nCREATE FUNCTION f2(int,int) RETURNS int LANGUAGE python AS func4 USING LINK 'http://localhost:8815';\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave Repository and Starting Demo Cluster\nDESCRIPTION: Clone the RisingWave repository and start the demo cluster using Docker Compose. This sets up RisingWave, Prometheus, and Grafana for the tutorial.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\ncd risingwave/integration_tests/prometheus\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Constructing Maps from Key-Value Pairs in SQL\nDESCRIPTION: The map_from_entries function constructs a map from an array of key-value pairs. It takes an array of rows as input and returns a map.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmap_from_entries ( array ) → map\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_from_entries(array[row('key1',1), row('key2',2), row('key3',3)]) -> {key1:1,key2:2,key3:3}\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE MATERIALIZED VIEW Command Syntax in Bash\nDESCRIPTION: The syntax for the SHOW CREATE MATERIALIZED VIEW command that displays the query used to create a specified materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-mv.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW CREATE MATERIALIZED VIEW mv_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from Iceberg Source\nDESCRIPTION: CTAS statement to create a new table from Iceberg source data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t AS SELECT * FROM iceberg_source;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Default Permissions in SQL\nDESCRIPTION: This SQL command creates a new user with default system permissions in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER user_name;\n```\n\n----------------------------------------\n\nTITLE: Using cardinality Function in SQL\nDESCRIPTION: Returns the total number of elements in an array, or 0 if the array is empty. For multi-dimensional arrays, it counts all elements at all levels.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\ncardinality ( array ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\ncardinality(array[array[array[3,4,5],array[2,2,2]],array[array[6,7,8],array[0,0,0]]]) → 12\n```\n\n----------------------------------------\n\nTITLE: Setting BACKGROUND_DDL Syntax in SQL\nDESCRIPTION: The syntax for enabling or disabling background DDL operations. When set to true, subsequent DDL operations will execute in the background.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-background-ddl.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET BACKGROUND_DDL = { true | false };\n```\n\n----------------------------------------\n\nTITLE: Example Output of SHOW ALL Command\nDESCRIPTION: Illustrates the typical tabular output format generated by the `SHOW ALL` command in RisingWave. The table lists parameter names (e.g., `implicit_flush`, `query_mode`), their current settings, and brief descriptions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-runtime-parameters.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bsh\nCODE:\n```\n Runtime Parameters\n          Name                  |     Setting     |        Description\n--------------------------------+-----------------+--------------------------------------\n implicit_flush                 | false           | If set to `true`, every INSERT/UPDATE/DELETE statement will block until the entire dataflow is refreshed.\n create_compaction_group_for_mv | false           | If set to `true`, RisingWave will create dedicated compaction groups when creating these materialized views.\n query_mode                     | auto            | A temporary config variable to force query running in either local or distributed mode. If the value is auto, the system will decide for you automatically.\n ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving View Definition in SQL\nDESCRIPTION: The pg_get_viewdef() function returns the definition of a specified view or materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\npg_get_viewdef(view_name) → text\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table\nCREATE TABLE table1 (\n    id int PRIMARY KEY,\n    name VARCHAR\n);\n\n-- Create a materialized view\nCREATE MATERIALIZED VIEW materialized_view1 AS\nSELECT id, name\nFROM table1;\n\n-- Retrieve the definition of the materialized view using pg_get_viewdef\nSELECT pg_get_viewdef('materialized_view1'::regclass);\n----RESULT\n SELECT id, name FROM table1\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Prepending Element to Array in SQL\nDESCRIPTION: Shows how to prepend a single compatible element to the beginning of an array using the || operator. This operation is equivalent to using the array_prepend function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\n123 || array[66] → {123, 66}\n```\n\n----------------------------------------\n\nTITLE: Restoring Meta Snapshot with SQL Backend\nDESCRIPTION: Command to restore a meta snapshot when using SQL database as the meta store backend.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nrisectl \\\nmeta \\\nrestore-meta \\\n--meta-store-type sql \\\n--meta-snapshot-id [snapshot_id] \\\n--sql-endpoint [sql_endpoint] \\\n--backup-storage-url [backup_storage_url, e.g. s3://bucket_read_from] \\\n--backup-storage-directory [backup_storage_directory, e.g. dir_read_from] \\\n--hummock-storage-url [hummock_storage_url, e.g. s3://bucket_write_to] \\\n--hummock-storage-directory [hummock_storage_directory, e.g. dir_write_to]\n```\n\n----------------------------------------\n\nTITLE: Taxi Reference Table for Join Example - Bash\nDESCRIPTION: Sample lookup table mapping taxi IDs to companies. Used to illustrate joining reference data to windowed aggregation results in SQL queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n taxi_id | company\\n---------+------------\\n 1001    | SAFE TAXI\\n 1002    | SUPER TAXI\\n 1003    | FAST TAXI\\n 1004    | BEST TAXI\\n 1005    | WEST TAXI\\n 1006    | EAST TAXI\n```\n\n----------------------------------------\n\nTITLE: Syntax for Dropping SQL Connections\nDESCRIPTION: This SQL snippet defines the syntax for the `DROP CONNECTION` command. It includes an optional `IF EXISTS` clause to prevent errors if the connection does not exist and requires the `connection_name` parameter to specify the connection to remove. Note that all dependent sources and sinks must be removed prior to dropping the connection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-connection.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP CONNECTION [ IF EXISTS ] connection_name;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with rw_int256 Column in SQL\nDESCRIPTION: Demonstrates how to create a table with a column of type rw_int256 and insert various values, including large positive and negative integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_name (column_name rw_int256);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (v rw_int256);\nINSERT INTO t VALUES (1), (100), (10000), (100000000), (10000000000000000), ('100000000000000000000000000000000'), (0), (-1), (-100), (-10000), (-100000000), (-10000000000000000), ('-100000000000000000000000000000000');\n```\n\n----------------------------------------\n\nTITLE: Declaring Subscription Cursor with Specific Starting Point in RisingWave SQL\nDESCRIPTION: This example shows declaring a new subscription cursor using a 'since unix_ms' clause to only receive rows after a certain timestamp, followed by FETCH statements returning change events. This technique enables targeted incremental change consumption for clients interested only in recent events.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\ndeclare cur2 subscription cursor for sub since 1715669376304;\nfetch next from cur2;\n\n----RESULT\n t1.v1 | t1.v2 | t1.v3 |     t1.op     |  rw_timestamp\n-------+-------+-------+---------------+---------------\n     1 |     1 |     1 | UpdateDelete  | 1715669376304\n(1 row)\n\nfetch next from cur2;\n----RESULT\n t1.v1 | t1.v2 | t1.v3 |     t1.op     |  rw_timestamp\n-------+-------+-------+---------------+---------------\n     1 |     1 |    10 | UpdateInsert  | 1715669376304\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Using CONVERT_FROM Function in SQL\nDESCRIPTION: The convert_from() function converts a string to the database encoding. The original encoding is specified by src_encoding name. The string must be valid in this encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nconvert_from(string bytea, src_encoding name)  →  text\n```\n\nLANGUAGE: SQL\nCODE:\n```\nconvert_from('\\x4346464558'::bytea, 'utf8')  →  'CFFEX'\n```\n\n----------------------------------------\n\nTITLE: Accessing Map Values by Key in RisingWave SQL\nDESCRIPTION: Demonstrates how to access a specific value in a map using bracket notation with the key. The example retrieves the value for 'key1'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/map-type.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAP {'key1': 1, 'key2': 2, 'key3': 3}['key1'];\n----RESULT\n1\n```\n\n----------------------------------------\n\nTITLE: Configuring MinIO as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up MinIO as the state store backend for RisingWave. It specifies the MinIO endpoint, bucket, and credentials for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the MinIO state store backend.\n    minio:\n      # Endpoint of the MinIO service.\n      endpoint: risingwave-minio:9301\n\n      # Name of the MinIO bucket.\n      bucket: hummock001\n\n      # Credentials to access the MinIO bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: minio-credentials\n\n        # Key of the username ID in the secret.\n        usernameKeyRef: username\n\n        # Key of the password key in the secret.\n        passwordKeyRef: password\n```\n\n----------------------------------------\n\nTITLE: Creating Another CDC Table from a Different Schema in RisingWave SQL\nDESCRIPTION: Here, a second CDC-enabled table 'tt4' is created in RisingWave to ingest from 'ods.tt4' in PostgreSQL. The DDL defines its schema and specifies the primary key, with the source identified as 'pg_mydb'. This demonstrates the capability to create multiple CDC-driven tables across various PostgreSQL schemas using a single source definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tt4 (\n  v1 integer primary key,\n  v2 varchar,\n  PRIMARY KEY (v1)\n) FROM pg_mydb TABLE 'ods.tt4';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for HubSpot Webhook Data\nDESCRIPTION: Creates a table configured to accept webhook data from HubSpot. It includes a validation clause that uses the previously created secret to verify the signature of incoming requests.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hubspot-webhook.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'x-hubspot-signature',\n  encode(\n    sha256(\n      convert_to(\n        (test_secret || 'POST' || 'http://127.0.0.1:4560/webhook/dev/public/' || convert_from(data, 'utf8'))\n      , 'UTF8'\n      )\n    ) \n  , 'hex'\n  )\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Fixed Parallelism\nDESCRIPTION: SQL command to set fixed parallelism for a table, manually specifying the number of parallel processes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t SET PARALLELISM = 16;\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Source for Coreflux MQTT Data Ingestion (SQL)\nDESCRIPTION: This SQL statement creates a source table named `machine_metrics` in RisingWave to ingest data from a Coreflux MQTT broker. It specifies the connection details (URL, topic, credentials, QoS) and the expected JSON data format and schema. Requires a running RisingWave cluster and access to the specified Coreflux broker endpoint, topic, and credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/coreflux-broker.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE machine_metrics (\n    machine_id VARCHAR,\n    ts TIMESTAMP,\n    operating_status VARCHAR,\n    temperature DECIMAL,\n    vibration DECIMAL,\n    pressure DECIMAL,\n    energy_consumption DECIMAL,\n    fault_code VARCHAR\n)\nWITH (\n    connector='mqtt',\n    url='ssl://xxxxxxxxxxxxxxx.coreflux.cloud:8883',\n    topic='factory/machine_data',\n    username='admin',\n    password='xxxxxxxxxxx',\n    qos='at_least_once'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a JavaScript UDAF for Weighted Average in RisingWave\nDESCRIPTION: Provides an example of the `CREATE AGGREGATE` command using JavaScript. It defines a `weighted_avg` function equivalent to the Python example, calculating the weighted average of two integer columns. The embedded JavaScript code exports the necessary functions: `create_state`, `accumulate`, `retract`, and `finish` to manage the aggregation state and compute the final result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-aggregate.mdx#2025-04-23_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n-- Javascript UDAF\nCREATE AGGREGATE weighted_avg(value int, weight int) RETURNS float LANGUAGE javascript AS $$\n    export function create_state() {\n        return { sum: 0, weight: 0 };\n    }\n    export function accumulate(state, value, weight) {\n        if (value == null || weight == null) {\n            return state;\n        }\n        state.sum += value * weight;\n        state.weight += weight;\n        return state;\n    }\n    export function retract(state, value, weight) {\n        if (value == null || weight == null) {\n            return state;\n        }\n        state.sum -= value * weight;\n        state.weight -= weight;\n        return state;\n    }\n    export function finish(state) {\n        if (state.weight == 0) {\n            return null;\n        }\n        return state.sum / state.weight;\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Configuring Elastic Disk Cache in TOML\nDESCRIPTION: TOML configuration example for setting up elastic disk cache in RisingWave compute nodes. Includes settings for metadata cache, data block cache, and cache refill parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/disk-cache.mdx#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[storage.meta_file_cache]\ndir = \"/path/to/your/meta_cache_dir\"\ncapacity_mb = 10240\ninsert_rate_limit_mb = 50\n\n[storage.data_file_cache]\ndir = \"/path/to/your/data_cache_dir\"\ncapacity_mb = 92160\ninsert_rate_limit_mb = 450\n\n[storage.cache_refill]\ndata_refill_levels = [0, 1, 2, 3, 4, 5, 6]\n```\n\n----------------------------------------\n\nTITLE: Querying a Source in RisingWave using SQL\nDESCRIPTION: These SQL snippets show how to query a created source directly. The first example demonstrates a simple SELECT statement, while the second shows how to filter Kafka messages based on their timestamp using the special '_rw_kafka_timestamp' column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/connect-with-create-source.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM my_kafka_source;\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM my_kafka_source WHERE _rw_kafka_timestamp > NOW() - INTERVAL '1 day';\n```\n\n----------------------------------------\n\nTITLE: Executing an Ad-hoc Aggregate Subquery Over a Materialized View in SQL - SQL\nDESCRIPTION: This SQL snippet counts how many products have a 'total_sales' value exceeding that of the product with 'product_id = 1'. Using a scalar subquery within a WHERE clause, it demonstrates advanced SQL usage for flexible, real-time analysis. Prerequisites are a populated 'mv_sales_summary' view; inputs are the existing aggregate values, and output is the count of qualifying products (result set).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/overview.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(*) FROM mv_sales_summary where mv_sales_summary.total_sales >\\n    (SELECT total_sales FROM mv_sales_summary where product_id = 1);\\n\\n----RESULT\\n count\\n-------\\n     2\\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Calling SQL UDF with Built-in Function\nDESCRIPTION: This snippet shows how to call the previously created call_regexp_replace function, which uses the regexp_replace built-in function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nselect call_regexp_replace();\n----RESULT\nDog is the cutest animal.\n```\n\n----------------------------------------\n\nTITLE: Creating a Table-Returning Python UDF in SQL\nDESCRIPTION: Demonstrates how to create a table-returning Python UDF named 'series' that generates a sequence of integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE FUNCTION series(n int) RETURNS TABLE (x int) LANGUAGE python AS $$\ndef series(n):\n    for i in range(n):\n        yield i\n$$;\n```\n\n----------------------------------------\n\nTITLE: Expanding JSON Arrays with jsonb_array_elements\nDESCRIPTION: Function that expands a top-level JSON array into individual JSON values. Takes a jsonb input and returns a set of jsonb values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_array_elements('[1,true, [2,false]]'::jsonb);\n```\n\n----------------------------------------\n\nTITLE: DROP SCHEMA Syntax in SQL\nDESCRIPTION: Defines the syntax for the `DROP SCHEMA` command. It allows specifying `IF EXISTS` to avoid errors for non-existent schemas, an optional `database_name` to target a specific database, the mandatory `schema_name`, and an optional `CASCADE` clause to drop dependent objects.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-schema.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA [ IF EXISTS ] [database_name.]schema_name [ CASCADE ];\n```\n\n----------------------------------------\n\nTITLE: Monitoring Backfill Progress in RisingWave\nDESCRIPTION: This SQL command is used to monitor the progress of backfilling historical data when creating a materialized view. It shows the status of ongoing jobs in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW JOBS\n```\n\n----------------------------------------\n\nTITLE: Expected Query Result from Materialized View (SQL Output)\nDESCRIPTION: This block shows the expected output format and sample data when querying the 'visits_stream_mv' materialized view. It displays aggregated metrics like total visits, unique visitors, and last visit time per page ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\n page_id | total_visits | unique_visitors |   last_visit_time\n---------+--------------+-----------------+---------------------\n page_0  |            2 |               2 | 2023-07-26 19:03:08\n page_4  |            9 |               9 | 2023-07-26 19:03:00\n page_8  |            9 |               9 | 2023-07-26 19:02:57\n page_3  |           14 |              14 | 2023-07-26 19:03:09\n page_7  |            4 |               4 | 2023-07-26 19:02:52\n page_1  |            7 |               6 | 2023-07-26 19:02:55\n page_5  |            9 |               9 | 2023-07-26 19:03:01\n page_9  |           12 |              12 | 2023-07-26 19:02:48\n page_2  |            4 |               4 | 2023-07-26 19:02:58\n page_6  |            7 |               6 | 2023-07-26 19:03:03\n\n```\n\n----------------------------------------\n\nTITLE: Dropping a Specific User with DROP USER Command in SQL\nDESCRIPTION: This SQL example demonstrates how to remove a user named 'user1' from the system. The operation requires that the executing user have the necessary privileges (CREATEUSER or SUPERUSER), and the user being dropped must not be the current session's user. On success, the user is removed; errors may be raised if conditions are not met.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-user.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP USER user1;\n```\n\n----------------------------------------\n\nTITLE: Defining taxi Table Schema in YAML\nDESCRIPTION: This YAML snippet defines the schema for the taxi table, including columns for taxi_id and trip_id.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n{\n  \"taxi_id\": VARCHAR,\n  \"trip_id\": VARCHAR\n}\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave CDC Table from Shared Source (SQL)\nDESCRIPTION: This SQL snippet demonstrates creating a RisingWave CDC table named `t1_rw` that ingests data from a specific table in an upstream MySQL database. It references the pre-defined shared source `mysql_mydb` using the `FROM` clause and specifies the target upstream table as `'mydb.t1'`. This avoids repeating connection details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1_rw (\n    v1 int,\n    v2 int,\n    PRIMARY KEY(v1)\n) FROM mysql_mydb TABLE 'mydb.t1';\n```\n\n----------------------------------------\n\nTITLE: Example Top-N Query using row_number() in RisingWave (SQL)\nDESCRIPTION: Demonstrates a practical Top-N query in RisingWave SQL. It uses the `row_number()` window function, partitioned by column 'x' and ordered by column 'y', to assign ranks within each group. The outer query then filters these results to select only rows with a rank less than 10.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/top-n-by-group.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT r\n  FROM (\n    SELECT\n      *,\n      row_number() OVER (PARTITION BY x ORDER BY y) r\n    FROM t\n  ) Q\nWHERE Q.r < 10;\n```\n\n----------------------------------------\n\nTITLE: Using Rust UDFs in RisingWave SQL Queries\nDESCRIPTION: This example shows how to use the previously defined Rust UDFs in SQL queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gcd(25, 15);\nSELECT * FROM series(5);\n```\n\n----------------------------------------\n\nTITLE: Converting Materialized View to SINK INTO TABLE in RisingWave - SQL\nDESCRIPTION: This sequence of SQL statements shows how to migrate from a materialized view to a 'SINK INTO TABLE' approach for more flexible, in-place logic changes. It creates a base table for persistence and a sink streaming job producing rows into that table, using ON CONFLICT OVERWRITE to resolve duplicate primary keys. Assumes prior existence of table 't'; results in a decoupled, modifiable streaming to storage pipeline.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW m1 AS SELECT id, v1 FROM t;\n\n-- Converted to SINK INTO TABLE\nCREATE TABLE m1_store (id INT PRIMARY KEY, v1 INT) ON CONFLICT OVERWRITE;\nCREATE SINK m1_stream INTO m1_store AS SELECT id, v1 FROM t;\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave MySQL CDC Source with Debezium Parameter (SQL)\nDESCRIPTION: This SQL snippet shows how to create a shared MySQL CDC source named `mysql_mydb` in RisingWave. It specifies connection parameters like hostname, port, username, password, database name, and a unique server ID. Additionally, it demonstrates passing a Debezium-specific configuration property (`schema.history.internal.skip.unparseable.ddl`) by prefixing it with `debezium.` within the `WITH` clause to customize the underlying Debezium connector's behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mysql_mydb WITH (\n  connector = 'mysql-cdc',\n  hostname = '127.0.0.1',\n  port = '8306',\n  username = 'root',\n  password = '123456',\n  database.name = 'mydb',\n  server.id = 5888,\n  debezium.schema.history.internal.skip.unparseable.ddl = 'true'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Connection with JDBC Catalog in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create an Iceberg connection using a JDBC catalog. It specifies various connection properties including warehouse path, S3 credentials, and catalog details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION public.conn WITH (\n    type = 'iceberg',\n    warehouse.path = 's3://hummock001/iceberg-data',\n    s3.access.key = <access_key_id>,\n    s3.secret.key = <secret_key>,\n    s3.endpoint = 'http://127.0.0.1:9301',\n    s3.region = 'ap-southeast-2',\n    catalog.type = 'jdbc',\n    catalog.uri = 'jdbc:postgresql://127.0.0.1:8432/metadata',\n    catalog.jdbc.user = 'postgres',\n    catalog.jdbc.password = '123',\n    catalog.name = 'dev',\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Table with Primary Key Constraint in RisingWave (SQL)\nDESCRIPTION: This SQL snippet shows how to define a table in RisingWave with a primary key constraint by specifying it in the schema. The table created ensures uniqueness for the specified primary key column(s), and subsequent data with duplicate primary keys will overwrite existing records. Input is the table schema and primary key expression; output is a table with enforced primary key semantics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table1 (PRIMARY KEY(id))\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into JSONB Columns in SQL\nDESCRIPTION: These SQL INSERT statements show how to add JSON data to JSONB columns. The examples include inserting simple key-value pairs and more complex nested JSON structures.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/jsonb.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO x VALUES ('{\"a\": 3, \"b\": 4}', 5);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO y VALUES ('ABCD1234', '{\"color\": \"blue\", \"size\": \"M\"}');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO product (name, price, attributes)\nVALUES\n        (\n            'T-Shirt',\n            19.99,\n            '{\"color\": \"red\", \"size\": \"L\"}'\n        );\n```\n\n----------------------------------------\n\nTITLE: Aggregate Function Call Syntax in RisingWave SQL\nDESCRIPTION: Shows the four different syntax variations for aggregate function calls in RisingWave SQL, including standard aggregation, distinct aggregation, star aggregation, and within group aggregation. Each syntax may optionally include a filter clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\naggregate_name ( expression [ , ... ] [ order_by_clause ] ) [ FILTER ( WHERE filter_clause ) ]\naggregate_name ( DISTINCT expression [ , ... ] [ order_by_clause ] ) [ FILTER ( WHERE filter_clause ) ]\naggregate_name ( * ) [ FILTER ( WHERE filter_clause ) ]\naggregate_name ( [ expression [ , ... ] ] ) WITHIN GROUP ( order_by_clause ) [ FILTER ( WHERE filter_clause ) ]\n```\n\n----------------------------------------\n\nTITLE: Creating S3 File Sink in RisingWave SQL\nDESCRIPTION: This SQL command creates a sink to stream data to Amazon S3 in Parquet format. It specifies various S3 configuration parameters and sets the sink type to 'append-only'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/delivery/overview.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK test_file_sink FROM test\nWITH (\n    connector = 's3',\n    s3.region_name = '{config['S3_REGION']}',\n    s3.bucket_name = '{config['S3_BUCKET']}',\n    s3.credentials.access = '{config['S3_ACCESS_KEY']}',\n    s3.credentials.secret = '{config['S3_SECRET_KEY']}',\n    s3.endpoint_url = 'https://{config['S3_ENDPOINT']}'\n    s3.path = '',\n    type = 'append-only',\n    force_append_only='true'\n) FORMAT PLAIN ENCODE PARQUET(force_append_only='true');\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink to Apache Pulsar SQL Syntax\nDESCRIPTION: The SQL syntax for creating a sink from RisingWave to Apache Pulsar, including all required and optional parameters, format specifications and encoding options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-pulsar.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='pulsar',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    key = 'value' ) ]\n[KEY ENCODE key_encode [(...)]];\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink from RisingWave to Google BigQuery\nDESCRIPTION: SQL syntax for creating a sink to BigQuery. Includes all possible parameters and their descriptions. This snippet defines the structure and options for configuring the BigQuery sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/bigquery.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='bigquery',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with Glue Catalog\nDESCRIPTION: Example of creating an Iceberg source using the Glue catalog type, which is designed to work with AWS S3.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_test\nWITH (\n    connector = 'iceberg',\n    catalog.type = 'glue',\n    warehouse.path = 's3://my-iceberg-bucket/test',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-2',\n    database.name='test_db',\n    table.name='test_table'\n);\n```\n\n----------------------------------------\n\nTITLE: Example of Creating an S3 Sink in SQL for RisingWave\nDESCRIPTION: This SQL example shows how to create a sink named 's3_sink' that selects data from a table 't' and sends it to an S3 bucket. It includes specific parameters for S3 configuration, credentials, and data formatting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/aws-s3.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s3_sink AS SELECT v1\nFROM t \nWITH (\n    connector='s3',\n    s3.path = '<test_path>',\n    s3.region_name = '<region_name>',\n    s3.bucket_name = '<bucket_name>',\n    s3.credentials.account_name = '<account_name>',\n    s3.credentials.account_key = '<account_key>',\n    s3.endpoint_url = '<endpoint_url>',\n    type = 'append-only',\n)FORMAT PLAIN ENCODE PARQUET(force_append_only=true);\n```\n\n----------------------------------------\n\nTITLE: Non-Append-Only Process-Time Temporal Join Syntax in SQL\nDESCRIPTION: Shows the syntax for creating a non-append-only process-time temporal join, which can handle non-append-only input for the left table by maintaining an internal state to materialize lookup results. This allows for retracting join results when updates occur.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\n<table_expression> [ LEFT | INNER ] JOIN <table_expression> FOR SYSTEM_TIME AS OF PROCTIME() ON <join_conditions>;\n```\n\n----------------------------------------\n\nTITLE: Example Workflow: Creating a Source Using a Secret in RisingWave SQL\nDESCRIPTION: This is the second part of an example workflow. It shows how to create a MySQL CDC source (`mysql_source`) that references the previously created `mysql_pwd` secret for the `password` option using the `secret mysql_pwd` syntax.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mysql_source WITH (\n connector = 'mysql-cdc',\n hostname = 'localhost',\n port = '8306',\n username = 'rwcdc',\n password = secret mysql_pwd,\n database.name = 'test',\n server.id = '5601'\n);\n```\n\n----------------------------------------\n\nTITLE: CASE Statement Example (Syntax 1) for Trip Distance Classification in SQL\nDESCRIPTION: Demonstrates the use of CASE statement (Syntax 1) to classify trip distances into categories based on their length.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, distance,\n  CASE\n    WHEN (distance < 3) THEN 'short'\n    WHEN (distance >= 3 AND distance < 10) THEN 'mid'\n    WHEN (distance >= 10 AND distance < 20) THEN 'long'\n    WHEN (distance >= 20) THEN 'extra'\n  END AS \"Category\"\n  FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Watermark on a Column - RisingWave SQL\nDESCRIPTION: This snippet demonstrates the syntax for defining a watermark directly on a source column in RisingWave SQL, establishing the maximum observed event time as the watermark. This approach requires a timestamp-type column, and the watermark will be updated automatically as new maximum values are ingested. It is useful for basic event time tracking, and expects 'column_name' to be a valid column within the source schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/watermarks.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nWATERMARK FOR column_name as expr\n```\n\n----------------------------------------\n\nTITLE: Configuring Avro Format in RisingWave\nDESCRIPTION: SQL syntax for configuring Avro format in RisingWave. Requires specifying a schema registry URL for schema resolution. Avro maps can be ingested as either map type or jsonb.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE AVRO (\n    schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT [ DEBEZIUM | UPSERT | PLAIN ] ENCODE AVRO (\n    map.handling.mode = 'map' | 'jsonb'\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View with Temporal Filter for Active Sessions\nDESCRIPTION: Illustrates creating a RisingWave source and a materialized view (`user_sessions`) with a temporal filter (`last_active + session_timeout * 2 > NOW()`). This filter identifies and retains records representing currently active user sessions, effectively cleaning up expired session data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE user_sessions_source(...) with (connector = 'kafka', ...) FORMAT PLAIN ENCODE JSON;\n\nCREATE MATERIALIZED VIEW user_sessions AS\nSELECT *\nFROM user_sessions_source\nWHERE last_active + session_timeout * 2 > NOW();\n```\n\n----------------------------------------\n\nTITLE: Inspecting and Generating Parallelism Adjustment Statements (bash, SQL)\nDESCRIPTION: This comprehensive example walks through: 1) retrieving parallelism settings per streaming job fragment; 2) dynamically generating SQL statements to adjust parallelism for jobs that exceed a threshold; and 3) executing those ALTER statements to reduce parallelism. The interaction is displayed as terminal (bash) output, but the commands executed are SQL. This technique depends on access to system tables like `rw_fragment_parallelism` and the appropriate database privileges to alter job configuration. The inputs are the cluster’s state and fragment metadata, outputs are the reduced parallelism settings and confirmation messages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-a-large-number-of-streaming-jobs.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n/* get the current parallelism of the running streaming jobs*/\ndev=> select * from rw_fragment_parallelism;\n  id  |    name     |   relation_type   | fragment_id | distribution_type | state_table_ids | upstream_fragment_ids |        flags        | parallelism\n------+-------------+-------------------+-------------+-------------------+-----------------+-----------------------+---------------------+-------------\n 1003 | table_xxx_1 | table             |           6 | HASH              | {}              | {}                    | {SOURCE,DML}        |           4\n 1003 | table_xxx_1 | table             |           5 | HASH              | {1003}          | {6}                   | {MVIEW}             |           4\n 1006 | table_xxx_4 | table             |          12 | HASH              | {}              | {}                    | {SOURCE,DML}        |           16\n 1006 | table_xxx_4 | table             |          11 | HASH              | {1006}          | {12}                  | {MVIEW}             |           16\n 1005 | table_xxx_3 | table             |          10 | HASH              | {}              | {}                    | {SOURCE,DML}        |           32\n 1005 | table_xxx_3 | table             |           9 | HASH              | {1005}          | {10}                  | {MVIEW}             |           32\n 1004 | table_xxx_2 | table             |           8 | HASH              | {}              | {}                    | {SOURCE,DML}        |           32\n 1004 | table_xxx_2 | table             |           7 | HASH              | {1004}          | {8}                   | {MVIEW}             |           32\n 1013 | other_mv    | materialized view |          16 | HASH              | {1014,1013}     | {5}                   | {MVIEW,STREAM_SCAN} |           32\n 1009 | mv_xxx_2    | materialized view |          14 | HASH              | {1010,1009}     | {7}                   | {MVIEW,STREAM_SCAN} |           32\n 1011 | mv_xxx_3    | materialized view |          15 | HASH              | {1012,1011}     | {9}                   | {MVIEW,STREAM_SCAN} |           32\n 1007 | mv_xxx_1    | materialized view |          13 | HASH              | {1008,1007}     | {5}                   | {MVIEW,STREAM_SCAN} |           4\n(12 rows)\n\n/* generate the alter statement sql to decrease parallelism for some jobs with some condition*/\ndev=> select distinct 'alter ' || fp.relation_type || ' ' || fp.name || ' set parallelism = 4;' as sql\nfrom rw_fragment_parallelism fp\nwhere fp.parallelism > 4 and fp.name like '%_xxx_%';\n                       sql\n-------------------------------------------------------\n alter table table_xxx_4 set parallelism = 4;\n alter materialized view mv_xxx_2 set parallelism = 4;\n alter materialized view mv_xxx_3 set parallelism = 4;\n alter table table_xxx_2 set parallelism = 4;\n alter table table_xxx_3 set parallelism = 4;\n(5 rows)\n\n/* alter them one by one*/\ndev=>  alter table table_xxx_4 set parallelism = 4;\nALTER_TABLE\ndev=>  alter materialized view mv_xxx_2 set parallelism = 4;\nALTER_MATERIALIZED_VIEW\ndev=>  alter materialized view mv_xxx_3 set parallelism = 4;\nALTER_MATERIALIZED_VIEW\ndev=>  alter table table_xxx_2 set parallelism = 4;\nALTER_TABLE\ndev=>  alter table table_xxx_3 set parallelism = 4;\nALTER_TABLE\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave\nDESCRIPTION: Creates a materialized view 'counter' that calculates total distance and duration from the walk source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/nodejs.mdx#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Pool } = require('pg')\n\nconst credentials = {\n    user: 'root',\n    host: '127.0.0.1',\n    database: 'dev',\n    password: 'secret',\n    port: 4566,\n}\n\nconst createmv = `CREATE MATERIALIZED VIEW counter\n    AS SELECT\n    SUM(distance) as total_distance,\n    SUM(duration) as total_duration\n    FROM walk`;\n\nconst start = async () => {\n    const pool = new Pool(credentials);\n    const res = await pool.query(createmv);\n    console.log(res);\n    await pool.end();\n}\nstart().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Converting to JSONB\nDESCRIPTION: Converts any SQL value to JSONB data type, handling arrays and composites recursively.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nto_jsonb(array['apple', 'banana', 'cherry'])\n```\n\n----------------------------------------\n\nTITLE: Using UDFs in RisingWave Queries\nDESCRIPTION: Example SQL queries demonstrating how to use the declared UDFs in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gcd(25, 15);\n---\n5\n\nSELECT blocking(2);\n---\n2\n\nSELECT key_value('a=b');\n---\n(a,b)\n\nSELECT * FROM series(5);\n---\n0\n1\n2\n3\n4\n\nSELECT text_embedding('Hello, RisingWave UDF!');\n---\n {-0.009116887,-0.03780581,-0.014567504,0.001315606,...}\n```\n\n----------------------------------------\n\nTITLE: Window Frame Boundaries Syntax in RisingWave SQL\nDESCRIPTION: Defines the syntax for specifying window frame boundaries (frame_start and frame_end) in ROWS or RANGE frames, which determine the starting and ending positions of the window relative to the current row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nUNBOUNDED PRECEDING\noffset PRECEDING\nCURRENT ROW\noffset FOLLOWING\nUNBOUNDED FOLLOWING\n```\n\n----------------------------------------\n\nTITLE: CORRESPONDING Syntax Example\nDESCRIPTION: Shows the syntax for using CORRESPONDING keyword with set operations to match columns by name instead of position.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions]\n<operation> CORRESPONDING [BY (column_name1, column_name2, ...)]\nSELECT expression1, expression2, ... expression_n\nFROM tables\n[WHERE conditions];\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View Exceeding Hard Limit in SQL\nDESCRIPTION: This SQL snippet demonstrates attempting to create a materialized view named `test_cluster_limit_exceed_hard`. The result block shows that if this operation exceeds the hard actor limit per parallelism, the command will fail and return an `ERROR` message, preventing the creation of the view due to potential critical cluster overload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/cluster-limit.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW test_cluster_limit_exceed_hard AS SELECT * FROM test;\n\n----RESULT\nERROR:  Failed to run the query\n\nCaused by:\n  Protocol error:\n- Actor count per parallelism exceeds the critical limit.\n- Depending on your workload, this may overload the cluster and cause performance/stability issues. Please scale the cluster before proceeding!\n- Contact us via Slack or https://risingwave.com/contact-us/ for further enquiry.\n- You can bypass this check via SQL `SET bypass_cluster_limits TO true`.\n- You can check actor count distribution via SQL `SELECT * FROM rw_worker_actor_count`.\nActorCountPerParallelism { critical limit: 7, recommended limit: 6. worker_id_to_actor_count: [\"1 -> WorkerActorCount { actor_count: 32, parallelism: 4 }\"] }\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Avro Encoding in SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka source in RisingWave using Avro encoding. It specifies the Avro message name and schema registry details, along with Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE AVRO (\n   message = 'message_name',\n   schema.registry = 'http://127.0.0.1:8081',\n   schema.registry.username='your_schema_registry_username',\n   schema.registry.password='your_schema_registry_password'\n);\n```\n\n----------------------------------------\n\nTITLE: Fetching Data Non-Blocking from Subscription Cursor - Example Result\nDESCRIPTION: This snippet shows an example result of fetching a row from a RisingWave subscription cursor after an update operation. The 'op' column indicates the change type, and 'rw_timestamp' provides the change's timestamp. This output is generated by previous FETCH statements for consumer reference.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nFETCH NEXT FROM cur;\n\n----RESULT\nt1.v1 | t1.v2 | t1.v3 |    t1.op     |  rw_timestamp  \n-------+-------+-------+--------------+---------------\n    1 |     1 |     1 | UpdateDelete | 1715669376304\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Generator Source in RisingWave SQL\nDESCRIPTION: SQL syntax for connecting RisingWave to the built-in load generator. This statement creates a table with the specified columns and configures the data generation parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE source_name ( column_name data_type, ... )\nWITH (\n   connector = ' datagen ',\n   fields.column_name.column_parameter = ' value ', ...  -- Configure the generator for each column. See detailed information below.\n   datagen.rows.per.second = ' rows_integer '  -- Specify how many rows of records to generate every second. For example, '20'.\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Using count function in SQL\nDESCRIPTION: Returns the number of non-null input values. Can take any supported data type as input and returns a bigint.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncount ( expression ) -> bigint\n```\n\n----------------------------------------\n\nTITLE: Defining a Watermark on a Source Table in SQL\nDESCRIPTION: This SQL snippet shows how to define a source table `t` with a watermark. The `WATERMARK FOR event_time AS event_time - INTERVAL '5 minutes'` clause specifies that the watermark for the `event_time` column is generated based on the latest `event_time` observed, minus a 5-minute delay. Defining a watermark is essential for using the `EMIT ON WINDOW CLOSE` feature, as it determines when windows can be considered closed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE t (\n    event_time TIMESTAMP,\n    <... other fields ...>\n    WATERMARK FOR event_time AS event_time - INTERVAL '5 minutes'\n) WITH ( ... );\n```\n\n----------------------------------------\n\nTITLE: Cloning the Stream Processing Repository with Git\nDESCRIPTION: Clones the awesome-stream-processing repository containing demo code for sports betting analysis and other stream processing examples.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/awesome-stream-processing.git\n```\n\n----------------------------------------\n\nTITLE: Querying Employees Table with ORDER BY in SQL\nDESCRIPTION: SQL query to retrieve employee details sorted by salary in descending order. This example demonstrates the practical use of the ORDER BY clause for data sorting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/order-by-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT employee_id, employee_name, salary\nFROM employees\nORDER BY salary DESC;\n\n----RESULT\nemployee_id | employee_name | salary\n-------------+---------------+--------\n           5 | Eve           |  75000\n           3 | Charlie       |  70000\n           2 | Bob           |  60000\n           4 | David         |  55000\n           1 | Alice         |  50000\n(5 rows)\n```\n\n----------------------------------------\n\nTITLE: Swapping Materialized View Names Syntax in SQL\nDESCRIPTION: Shows the syntax for swapping the names of two materialized views using the `SWAP WITH` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW name\nSWAP WITH target_name;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for HubSpot Webhook Data with Raw String Verification\nDESCRIPTION: Creates a table configured to accept webhook data from HubSpot using a raw string for verification instead of a secret. This method is an alternative to using a secret for signature validation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hubspot-webhook.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE AS secure_compare(\n  headers->>'x-hubspot-signature',\n  encode(\n    sha256(\n      convert_to(\n        ('TEST_WEBHOOK' || 'POST' || 'http://127.0.0.1:4560/webhook/dev/public/' || convert_from(data, 'utf8'))\n      , 'UTF8'\n      )\n    ) \n  , 'hex'\n  )\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Materialized View Data in RisingWave (SQL)\nDESCRIPTION: This SQL snippet shows how to retrieve the current aggregated results from the materialized view 'mv'. It expects 'mv' to exist and return the sum of values inserted so far. The output will display columns 'v1_sum' and 'v2_sum', representing the current aggregates based on the underlying table's state.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from mv;\n```\n\n----------------------------------------\n\nTITLE: Removing Null Values with jsonb_strip_nulls\nDESCRIPTION: Function that recursively removes all object fields with null values from a JSONB value while preserving empty objects.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_strip_nulls('{\"a\": 1, \"b\": null, \"c\": {\"d\": null, \"e\": 2}}');\nSELECT jsonb_strip_nulls('{\"a\": {\"b\": null, \"c\": null}, \"d\": {} }');\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v1.1.0 Playground with Docker\nDESCRIPTION: Provides the Docker command to download and run the RisingWave v1.1.0 playground environment. It pulls the specified image, runs it interactively (`-it`), maps the PostgreSQL port (4566) and the dashboard port (5691) to the host machine.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\n    `docker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.1.0 playground`\n```\n\n----------------------------------------\n\nTITLE: Generating SHA-224 Hash of Binary String in SQL\nDESCRIPTION: The sha224 function returns the SHA-224 hash of a binary string. It takes a bytea input and returns a bytea.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nsha224 ( bytea ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sha224('risingwave'::bytea);\n------RESULT\n\\xb898defab7c2e2f41c9a494a22e3567274b48123625f96008439e0bb\n```\n\n----------------------------------------\n\nTITLE: Creating a table for grouping function example in SQL\nDESCRIPTION: Creates a sample table with brand, size, and sales columns to demonstrate grouping operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE items_sold (brand varchar, size varchar, sales int);\n```\n\n----------------------------------------\n\nTITLE: Creating an Azure Blob Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink that exports data from RisingWave to Azure Blob Storage. This defines the basic structure with connector parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/azure-blob.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='azblob',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Using array_append Function in SQL\nDESCRIPTION: Appends a compatible element to the end of an input array. The function takes an array and an element of compatible type as arguments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\narray_append ( array, any_compatible ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_append(array[66], 123) → {66, 123}\n```\n\n----------------------------------------\n\nTITLE: Downloading RisingWave Resource File\nDESCRIPTION: Command to download a RisingWave resource configuration file for customization\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://raw.githubusercontent.com/risingwavelabs/risingwave-operator/main/docs/manifests/<sub-directory> -o risingwave.yaml\n```\n\n----------------------------------------\n\nTITLE: Cleanup Commands\nDESCRIPTION: Commands to disconnect from RisingWave and optionally remove containers and generated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\\q\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Using array_distinct Function in SQL\nDESCRIPTION: Returns an array of the same type as the input array with all duplicate values removed, keeping only distinct elements.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\narray_distinct ( array ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_distinct(array[1,2,1,1]) → {1,2}\n```\n\n----------------------------------------\n\nTITLE: Schema Definition Syntax for RisingWave Tables (SQL)\nDESCRIPTION: This SQL snippet provides the syntax for specifying column names, types, and primary keys in table or source definitions within RisingWave. It allows configuration of single or composite primary keys and associates column-level key constraints. Key parameters are column names, data types, and key designations; designed for use when data format is not Avro or Protobuf. Output is a structured schema definition section within a CREATE statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating AWS PrivateLink Connection in SQL\nDESCRIPTION: Example SQL command for creating an AWS PrivateLink connection in RisingWave. This is used to establish secure connectivity to cloud-hosted services like AWS MSK located in different VPCs. It requires specifying the type as `privatelink`, the provider as `aws`, and the VPC endpoint service name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION connection_name WITH (\n    type = 'privatelink',\n    provider = 'aws',\n    service.name = 'com.amazonaws.xyz.us-east-1.abc-xyz-0000'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for User Behaviors\nDESCRIPTION: SQL statement to create a source that connects to Kafka stream containing user behavior data with timestamps and interaction details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE user_behaviors (\n    user_id VARCHAR,\n    target_id VARCHAR,\n    target_type VARCHAR,\n    event_timestamp TIMESTAMP WITH TIME ZONE,\n    behavior_type VARCHAR,\n    parent_target_type VARCHAR,\n    parent_target_id VARCHAR\n) WITH (\n    connector = 'kafka',\n    topic = 'user_behaviors',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Describing RisingWave Catalog Table Schema in SQL\nDESCRIPTION: These SQL commands demonstrate how to view the schema of specific catalog tables, showing the column names and their data types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE rw_catalog.rw_ddl_progress;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE rw_catalog.rw_meta_snapshot;\n```\n\n----------------------------------------\n\nTITLE: Configuring Debezium Mongo JSON Format in RisingWave SQL\nDESCRIPTION: Specifies the format and encoding for consuming Debezium Mongo JSON data. This format requires '_id' and 'payload' columns in the table schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT DEBEZIUM_MONGO\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Using BTRIM Function in SQL\nDESCRIPTION: The btrim() function is equal to trim (BOTH). It removes the specified characters from both the beginning and end of the input string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nbtrim ( input_string [, characters ] ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nbtrim(' cake ') → 'cake'\nbtrim('abcxyzabc', 'cba') → 'xyz'\n```\n\n----------------------------------------\n\nTITLE: Dropping a Materialized View from Default Schema - SQL\nDESCRIPTION: Removes a materialized view named ad_ctr_5min from the public schema using the DROP MATERIALIZED VIEW command in SQL. No schema is specified, so the view is expected to exist in the default (usually public) schema; there are no optional clauses or CASCADE. No dependencies or outputs except for the removal of the specific materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-mv.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP MATERIALIZED VIEW ad_ctr_5min;\n```\n\n----------------------------------------\n\nTITLE: Declaring External Functions in RisingWave SQL\nDESCRIPTION: SQL commands to declare the external Python functions in RisingWave database, mapping them to the corresponding Python implementations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION gcd(int, int) RETURNS int\nAS gcd USING LINK 'http://localhost:8815';\n\nCREATE FUNCTION blocking(int) RETURNS int\nAS blocking USING LINK 'http://localhost:8815';\n\nCREATE FUNCTION key_value(varchar) RETURNS struct<key varchar, value varchar>\nAS key_value USING LINK 'http://localhost:8815';\n\nCREATE FUNCTION series(int) RETURNS TABLE (x int)\nAS series USING LINK 'http://localhost:8815';\n\nCREATE FUNCTION text_embedding(varchar) RETURNS real[]\nAS text_embedding USING LINK 'http://localhost:8815';\n```\n\n----------------------------------------\n\nTITLE: Setting Specific Source Rate Limit in RisingWave\nDESCRIPTION: This example demonstrates setting the source rate limit of a Kafka source table to 1000 units per second.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\n-- Alter the rate limit of this table\nALTER TABLE kafka_source SET source_rate_limit TO 1000;\n```\n\n----------------------------------------\n\nTITLE: Using CONVERT_TO Function in SQL\nDESCRIPTION: The convert_to() function converts a string to the encoding specified by dest_encoding name and returns a byte array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nconvert_to(string text, dest_encoding name) → bytea\n```\n\nLANGUAGE: SQL\nCODE:\n```\nconvert_to('Hello World', 'UTF8') → '\\\\x48656c6c6f20576f726c64'\n```\n\n----------------------------------------\n\nTITLE: Deleting Persistent Volume Claims\nDESCRIPTION: Command to remove all persistent volume claims related to the RisingWave installation. Note that underlying persistent volumes will be reclaimed based on their configured policies.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/uninstall-risingwave-k8s.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl delete persistentvolumeclaims -l app.kubernetes.io/instance=my-risingwave\n```\n\n----------------------------------------\n\nTITLE: Granting Multiple Privileges on Table in SQL\nDESCRIPTION: This SQL command grants both SELECT and UPDATE privileges on a table to a user in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT SELECT, UPDATE\nON TABLE t1\nTO user1;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SASL/SCRAM Authentication in RisingWave SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka sink with SASL/SCRAM authentication without SSL encryption. It specifies the SCRAM-SHA-256 mechanism and related SASL parameters in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.sasl.mechanism='SCRAM-SHA-256',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying and Casting JSONB Data in SQL\nDESCRIPTION: This SQL query demonstrates how to retrieve data from JSONB columns, use JSON operators (-> and ->>), and cast JSONB values to other data types. It showcases various operations on JSONB data, including numeric calculations, boolean operations, and string manipulations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/jsonb.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO product VALUES ('USB cable', 4.99, '{\"lengthInFeet\": 3, \"backorder\": true, \"brand\": \"sin90\", \"compatible\": [\"pc\", \"mac\", \"phone\"]}');\n\nSELECT\n  (attributes -> 'lengthInFeet')::INT * 30.48 AS cm,\n  NOT (attributes -> 'backorder')::BOOL AS available,\n  UPPER(attributes ->> 'brand') AS brand_good,\n  UPPER((attributes -> 'brand')::VARCHAR) AS brand_bad,\n  attributes -> 'compatible'\nFROM product;\n```\n\n----------------------------------------\n\nTITLE: Creating S3 Sink with Batching Strategy in RisingWave SQL\nDESCRIPTION: This SQL command creates an S3 sink with a batching strategy. It specifies maximum row count, rollover interval, and path partition prefix for optimizing file management in the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/delivery/overview.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1 \nFROM t\nWITH (\n    connector = 's3',\n    max_row_count = '100',\n    rollover_seconds = '10',\n    type = 'append-only',\n    path_partition_prefix = 'day'\n) FORMAT PLAIN ENCODE PARQUET (force_append_only=true);\n```\n\n----------------------------------------\n\nTITLE: Creating a Cassandra/ScyllaDB Sink in RisingWave\nDESCRIPTION: SQL syntax for creating a sink from RisingWave to Cassandra or ScyllaDB. The sink can be configured as upsert or append-only and requires connection details such as the Cassandra URL, keyspace, table, and datacenter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/cassandra-or-scylladb.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n    connector='cassandra',\n    type='<type>',\n    cassandra.url = '<node1>,<node2>,<node3>',\n    cassandra.keyspace = '<keyspace>',\n    cassandra.table = '<cassandra_table>',\n    cassandra.datacenter = '<data_center>'\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Cache Eviction Policy Variables (Rust/TOML Configuration Structure)\nDESCRIPTION: Shows the Rust struct field definitions corresponding to configurable variables in the RisingWave TOML configuration file for tuning the cache eviction policy. These variables control the memory usage thresholds (`memory_controller_threshold_stable`, `memory_controller_threshold_graceful`, `memory_controller_threshold_aggressive`) and eviction factors (`memory_controller_eviction_factor_stable`, `memory_controller_eviction_factor_graceful`, `memory_controller_eviction_factor_aggressive`) that determine when and how aggressively RisingWave evicts data from cache.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/tune-reserved-memory.mdx#2025-04-23_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n#[serde(default = \"default::developer::memory_controller_threshold_aggressive\")]\npub memory_controller_threshold_aggressive: f64,\n\n#[serde(default = \"default::developer::memory_controller_threshold_graceful\")]\npub memory_controller_threshold_graceful: f64,\n\n#[serde(default = \"default::developer::memory_controller_threshold_stable\")]\npub memory_controller_threshold_stable: f64,\n\n#[serde(default = \"default::developer::memory_controller_eviction_factor_aggressive\")]\npub memory_controller_eviction_factor_aggressive: f64,\n\n#[serde(default = \"default::developer::memory_controller_eviction_factor_graceful\")]\npub memory_controller_eviction_factor_graceful: f64,\n\n#[serde(default = \"default::developer::memory_controller_eviction_factor_stable\")]\npub memory_controller_eviction_factor_stable: f64,\n```\n\n----------------------------------------\n\nTITLE: Creating a Specific Secret 'mysql_pwd' in SQL\nDESCRIPTION: This example demonstrates how to create a specific secret named `mysql_pwd` with the value '123' using the `meta` backend in RisingWave. This secret can subsequently be referenced in other SQL commands, such as `CREATE SOURCE`, to avoid exposing sensitive credentials directly in configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-secret.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET mysql_pwd WITH ( backend = 'meta' ) AS '123';\n```\n\n----------------------------------------\n\nTITLE: Using avg function in SQL\nDESCRIPTION: Returns the arithmetic mean of all non-null input values or null if no non-null values are provided. Works with numeric data types and returns numeric or double precision results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\navg ( expression ) -> see description\n```\n\n----------------------------------------\n\nTITLE: Setting Maxwell JSON Format in RisingWave SQL\nDESCRIPTION: Defines the format and encoding for consuming Maxwell JSON data. Allows direct referencing of JSON payload fields as column names in the schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT MAXWELL\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Using count(*) function in SQL\nDESCRIPTION: Returns the total number of rows in the input, including rows with null values. Returns a bigint.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\ncount(*) -> bigint\n```\n\n----------------------------------------\n\nTITLE: Dropping Overloaded Functions by Full Signature in SQL\nDESCRIPTION: Demonstrates dropping specific versions of the overloaded function `f1` by providing their full signatures: one with no arguments (`f1()`) and one with a single integer argument (`f1(int)`).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION f1();\nDROP FUNCTION f1(int);\n```\n\n----------------------------------------\n\nTITLE: Using first_value() Window Function in SQL\nDESCRIPTION: The first_value() function returns the value of the first row in the current window frame. If IGNORE NULLS is present, it returns the first non-null value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nfirst_value ( value anyelement [ IGNORE NULLS ] ) → anyelement\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    col1, col2,\n    first_value(col2) OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as first\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source - New Syntax\nDESCRIPTION: Example of the new syntax for creating a Kafka source connection in RisingWave, where parameter names are no longer wrapped in single quotes\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_40\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s WITH ( connector = 'kafka', kafka.topic = 'kafka_1_partition_topic', kafka.brokers = '127.0.0.1:29092' ) ROW FORMAT json;\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN PARQUET Format in RisingWave\nDESCRIPTION: SQL syntax for reading Parquet files from object storage systems including Amazon S3, Google Cloud Storage, and Azure Blob Storage. Parquet uses columnar storage for efficient data handling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE PARQUET\n```\n\n----------------------------------------\n\nTITLE: Calling SQL UDF with Mixed Parameters\nDESCRIPTION: This snippet shows how to call the previously created add_sub_mix_wrapper function with specific integer arguments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect add_sub_mix_wrapper(1, 2, 3);\n----RESULT\n4\n```\n\n----------------------------------------\n\nTITLE: Valid SQL Temporal Filter Syntax Examples\nDESCRIPTION: Illustrates valid syntax examples for temporal filters in SQL using the NOW() function combined with INTERVAL arithmetic and comparison operators (<, >, <=). These filters compare a time-based column against a dynamic time calculated relative to the current time.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Valid\nt > NOW() - INTERVAL '1 hour'\nt <= NOW() - INTERVAL '1 hour' -- To delay event handling by 1 hour\nt < DATE_TRUNC('hour', NOW()) - INTERVAL '1 hour'\n```\n\n----------------------------------------\n\nTITLE: Verifying Schema Access Privilege in SQL\nDESCRIPTION: Shows how to use has_schema_privilege() function to check if a user has specific access to a schema. The function accepts similar arguments as has_table_privilege() and checks for 'CREATE' and/or 'USAGE' privileges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nhas_schema_privilege([user,] schema, privilege) -> boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT has_schema_privilege('test_user', 'test_schema', 'CREATE');\n----RESULT\nt\n```\n\n----------------------------------------\n\nTITLE: Creating Meta Snapshot using RisingWave binary\nDESCRIPTION: Alternative command to create a meta snapshot using the pre-built RisingWave binary.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./risingwave ctl meta backup-meta\n```\n\n----------------------------------------\n\nTITLE: Using bool_and function in SQL\nDESCRIPTION: Returns true if all non-null input values are true, otherwise false. Takes boolean input values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nbool_and ( boolean ) -> boolean\n```\n\n----------------------------------------\n\nTITLE: Demonstrating grouping operations in SQL\nDESCRIPTION: Shows how the grouping function works with GROUPING SETS to identify which columns are included in each grouping level, indicated by bit values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nSELECT brand, size, sum(sales), grouping(brand), grouping(size), grouping(brand,size), count(DISTINCT sales)\nFROM items_sold\nGROUP BY GROUPING SETS ((brand), (size), ());\n------RESULTS\nBar NULL 20 0 1 1 2\nFoo NULL 30 0 1 1 2\nNULL L 15 1 0 2 2\nNULL M 35 1 0 2 2\nNULL NULL 50 1 1 3 4\n```\n\n----------------------------------------\n\nTITLE: Updating Records in a Non-Append-Only Temporal Join\nDESCRIPTION: Shows a SQL update statement that modifies the quantity column in the sales table, demonstrating how non-append-only temporal joins handle updates to the left-hand side table by looking up the latest data from the right-hand side.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE sales SET quantity = quantity + 1;\n```\n\n----------------------------------------\n\nTITLE: Sample Passenger and Flight Data Structure in JSON\nDESCRIPTION: This JSON object represents a sample record for passenger and flight details that would be published to the Solace topic 'passenger_full_details'. It includes key information like passenger reference number, flight details, departure time, contact info, and opt-in status for notifications.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/solace.mdx#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n        \"passenger_ref_number\": \"PRN026\",\n        \"flight_id\": \"LH6456\",\n        \"flight_number\": \"6456\",\n        \"carrier_code\": \"LH\",\n        \"flight_date\": \"2024-10-17\",\n        \"origin\": \"LHR\",\n        \"departure_time\": \"2024-10-17T04:40:00Z\",\n        \"contact_info\": \"john.garcia@gmail.com\",\n        \"opted_in\": true\n    }\n```\n\n----------------------------------------\n\nTITLE: Creating Protobuf-encoded Kafka Sink with PLAIN Format in SQL\nDESCRIPTION: SQL syntax for creating a Kafka sink with Protobuf encoding using PLAIN format. Shows the required and optional parameters for schema definition and registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT PLAIN\nENCODE PROTOBUF (\n   message = 'com.example.MyMessage',\n   schema.location = 'location'\n)\n```\n\n----------------------------------------\n\nTITLE: Inserting Multiple Rows with VALUES in RisingWave SQL\nDESCRIPTION: Example SQL statement demonstrating how to insert four new rows into the `taxi_trips` table using the `VALUES` clause. Each tuple in the `VALUES` list corresponds to a new row, providing values for the `id`, `distance`, and `city` columns in the order defined by the table schema (or implicitly). A `NULL` value is inserted for the `city` in the last row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO taxi_trips\n    VALUES\n      (1,16,'Dallas'),\n      (2,23,'New York'),\n      (3,6,'Chicago'),\n      (4,9,NULL);\n```\n\n----------------------------------------\n\nTITLE: Inserting Initial Data into Exam Scores Table\nDESCRIPTION: SQL command to insert five rows of sample data into the exam_scores table, including score_id, exam_id, student_id, score, and exam_date values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO exam_scores (score_id, exam_id, student_id, score, exam_date)\nVALUES\n  (1, 101, 1001, 85.5, '2022-01-10'),\n  (2, 101, 1002, 92.0, '2022-01-10'),\n  (3, 101, 1003, 78.5, '2022-01-10'),\n  (4, 102, 1001, 91.2, '2022-02-15'),\n  (5, 102, 1003, 88.9, '2022-02-15');\n```\n\n----------------------------------------\n\nTITLE: Querying A/B Test Results in SQL\nDESCRIPTION: A simple query to retrieve the first 5 records from the ab_test_results materialized view, showing performance metrics for different A/B test variants.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ab_test_results LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Accessing Map Values by Key in SQL\nDESCRIPTION: The map_access function retrieves the value associated with a given key in a map. It returns null if the key is not found.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmap_access ( map, key ) → value\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_access(MAP{1:100,2:200}, 1) -> 100\nmap_access(MAP{1:100,2:200}, 3) -> null\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Table with Data Storage in SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka table in RisingWave, which stores the ingested data. It defines a table with user_id as the primary key, along with product_id and timestamp columns, connecting to a Kafka topic named 'user_activity'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE my_kafka_table (\n    user_id INT,\n    product_id VARCHAR,\n    timestamp TIMESTAMP,\n    PRIMARY KEY (user_id)\n) WITH (\n    connector='kafka',\n    topic='user_activity',\n    properties.bootstrap.server='broker1:9092,broker2:9092'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Rolling Volatility in SQL\nDESCRIPTION: Creates a materialized view to calculate rolling price volatility within 5-minute time windows using TUMBLE() function and stddev_samp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW rolling_volatility AS\nSELECT\n    asset_id,\n    ROUND(stddev_samp(price), 2) AS rolling_volatility,\n    window_end\nFROM\n    TUMBLE(raw_market_data, timestamp, '5 minutes')\n    GROUP BY asset_id, window_end;\n```\n\n----------------------------------------\n\nTITLE: Creating Sink from Source to Iceberg Table in SQL\nDESCRIPTION: This SQL command creates a sink that transfers data from a source stream to an Iceberg table. It shows how to set up data flow into an Iceberg table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK user_sink INTO users_iceberg FROM raw_users_stream;\n```\n\n----------------------------------------\n\nTITLE: Querying a View in RisingWave with SQL via Shell\nDESCRIPTION: Illustrates executing a SELECT query against a previously created view (v3) and displays the results in a shell environment. This enables users to retrieve view results for inspection or downstream processing. Assumes the view has been properly defined in the database. Output columns include view-derived data; output appears in tabular shell format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-view.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nSELECT * FROM v3;\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE SWAP WITH Syntax in RisingWave SQL\nDESCRIPTION: This command swaps the names of two tables. It provides a convenient way to replace one table with another without changing references to the table names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE name\nSWAP WITH target_name;\n```\n\n----------------------------------------\n\nTITLE: Defining RIGHT OUTER JOIN Syntax - SQL\nDESCRIPTION: This set of snippets documents the SQL syntax for RIGHT OUTER JOINs in RisingWave, allowing retrieval of all rows from the right table and matched values (or NULLs) from the left table based on provided join conditions. The code relies on two table expressions as input and produces a union of right table rows with left-side matches or NULLs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n<table_expression> RIGHT [ OUTER ] JOIN <table_expression> ON <join_conditions>;\n<table_expression> RIGHT [ OUTER ] JOIN <table_expression> USING (<col_name>, <col_name>, ...);\n<table_expression> NATURAL RIGHT [ OUTER ] JOIN <table_expression>;\n```\n\n----------------------------------------\n\nTITLE: Creating Customer and Order Tables in SQL\nDESCRIPTION: Provides the SQL statements required to create 'customers' and 'orders' tables, complete with data types and primary keys. These tables are prerequisites for subsequent index creation and query examples, demonstrating indexing use cases in RisingWave. Key parameters include field names and data types. The output is a set of initialized tables ready to store and index transactional and customer data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/indexes.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE customers (\n    c_custkey INTEGER,\n    c_name VARCHAR,\n    c_address VARCHAR,\n    c_nationkey INTEGER,\n    c_phone VARCHAR,\n    c_acctbal NUMERIC,\n    c_mktsegment VARCHAR,\n    c_comment VARCHAR,\n    PRIMARY KEY (c_custkey)\n);\n\nCREATE TABLE orders (\n    o_orderkey BIGINT,\n    o_custkey INTEGER,\n    o_orderstatus VARCHAR,\n    o_totalprice NUMERIC,\n    o_orderdate DATE,\n    o_orderpriority VARCHAR,\n    o_clerk VARCHAR,\n    o_shippriority INTEGER,\n    o_comment VARCHAR,\n    PRIMARY KEY (o_orderkey)\n);\n```\n\n----------------------------------------\n\nTITLE: Secure String Comparison in SQL\nDESCRIPTION: The secure_compare function compares two strings in a fixed amount of time, regardless of equality, ensuring resistance to timing attacks. It takes two varchar inputs and returns a boolean result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/comparison.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nsecure_compare (varchar, varchar) -> boolean\n```\n\n----------------------------------------\n\nTITLE: Cancelling Specific Jobs by ID (SQL)\nDESCRIPTION: This example cancels two specific streaming jobs, identified by their IDs, using the CANCEL JOBS command in SQL. The command requires knowledge of job IDs, which may be acquired with SHOW JOBS. Upon execution, the output lists the IDs of the jobs that were successfully cancelled, in no guaranteed order.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-cancel-jobs.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL JOBS 1010, 1012;\n------RESULT\nId\n------\n 1012\n 1010\n\n```\n\n----------------------------------------\n\nTITLE: Setting up a Temporal Join in RisingWave\nDESCRIPTION: Shows the basic setup for a temporal join in RisingWave without an explicit delay filter. It creates a source (`fact`), a dimension table (`dimension`), and a materialized view (`mv`) that joins them using `FOR SYSTEM_TIME AS OF PROCTIME()`. This demonstrates the context where delaying one side of the join might be necessary.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n  CREATE SOURCE fact(id1 INT, a1 INT, p_time TIMESTAMPTZ AS proctime()) WITH (connector = 'kafka', ...);\n  CREATE TABLE dimension(id2 INT, a2 INT, PRIMARY KEY (id2)) WITH (connector = 'jdbc', ...);\n  CREATE MATERIALIZED VIEW mv AS SELECT id1, a1, a2 FROM fact LEFT JOIN dimension FOR SYSTEM_TIME AS OF PROCTIME() ON id1 = id2;\n```\n\n----------------------------------------\n\nTITLE: Defining AS CHANGELOG CTE in SQL\nDESCRIPTION: Demonstrates the syntax for using the AS CHANGELOG clause within a Common Table Expression (CTE) to capture table changelog events from a source table. This approach requires a SQL environment supporting AS CHANGELOG semantics (such as RisingWave) and enables downstream queries to treat changelog operations as row-level columns. The only required parameter is the source table name. The expected output is a CTE that exposes changelog metadata as columns for further use.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-as-changelog.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nWITH table_name AS CHANGELOG FROM source_table;\n```\n\n----------------------------------------\n\nTITLE: Converting String to Timestamp in SQL\nDESCRIPTION: The to_timestamp function converts a string to a timestamptz according to the given format. It takes a string and a timestamp format as input and returns a timestamptz.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nto_timestamp ( string, timestamp_format ) → timestamptz\n```\n\nLANGUAGE: sql\nCODE:\n```\nto_timestamp('2022 12 25', 'YYYY MM DD') → '2022-12-25 00:00:00+00:00'\n\nto_timestamp('2022-12-25 00:00:00.900006', 'YYYY-MM-DD HH24:MI:SS.US') → '2022-12-25 00:00:00.900006+00:00'\n\nto_timestamp('2022-12-25 00:00:00.906', 'YYYY-MM-DD HH24:MI:SS.MS') → '2022-12-25 00:00:00.906+00:00'\n\nto_timestamp('2023-07-11 20:01:00-07:00', 'YYYY-MM-DD HH24:MI:SSTZH:TZM') → '2023-07-12 03:01:00+00:00'\n```\n\n----------------------------------------\n\nTITLE: Defining SQL User-Defined Functions - SQL\nDESCRIPTION: Provides the general syntax to define a SQL-based UDF in RisingWave using the CREATE FUNCTION statement with RETURN or AS clauses. Dependencies include RisingWave with SQL UDF support. The syntax supports optional IF NOT EXISTS, return type declaration, and variants for SQL expression definitions. Functions accept arguments defined in the function header and the output type routed through RETURNS. These UDFs expand directly in SQL and have performance similar to manual expression use.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-function.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION [ IF NOT EXISTS ] function_name ( argument_type [, ...] )\n    RETURNS return_type\n    LANGUAGE sql\n    { AS as_definition | RETURN return_definition };\n```\n\n----------------------------------------\n\nTITLE: Updating Helm Chart Repositories\nDESCRIPTION: Command to update all Helm chart repositories to ensure you have the latest versions of charts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Creating User Betting Patterns View in SQL\nDESCRIPTION: Creates a materialized view to analyze betting patterns by calculating total bets, wins, losses, and average profit/loss per user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW user_betting_patterns AS\nSELECT\n    user_id,\n    COUNT(*) AS total_bets,\n    SUM(CASE WHEN result = 'Win' THEN 1 ELSE 0 END) AS wins,\n    SUM(CASE WHEN result = 'Loss' THEN 1 ELSE 0 END) AS losses,\n    AVG(profit_loss) AS avg_profit_loss,\n    SUM(profit_loss) AS total_profit_loss\nFROM\n    betting_history\nGROUP BY\n    user_id;\n```\n\n----------------------------------------\n\nTITLE: Defining Window Join Syntax - SQL\nDESCRIPTION: This snippet provides the generic syntax for a window join in RisingWave SQL, showing how two time-windowed expressions may be joined on custom conditions, such as watermarks. Inputs must be identical windowing logic for both sources. This template does not execute any operation itself but guides users on structuring windowed joins.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n<time_window_expression> JOIN <time_window_expression> ON <join_conditions>;\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDFs with Input Value Adjustment\nDESCRIPTION: This snippet demonstrates creating SQL UDFs that adjust the input value before passing it to another function (print in this case).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\ncreate function print_add_one(INT) returns int language sql as 'select print($1 + 1)';\n\ncreate function print_add_two(INT) returns int language sql as 'select print($1 + $1)';\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Changes and Handling Events in Python\nDESCRIPTION: Demonstrates event-driven processing by subscribing to changes from a RisingWave materialized view (`test_mv`) and a table (`test`) using the `risingwave-py` SDK. It defines a custom handler function (`simple_event_handler`) to process change events (received as Pandas DataFrames). The `mv.on_change()` and `rw.on_change()` methods are used to subscribe, running in separate threads to avoid blocking. Key parameters like `handler`, `output_format`, `persist_progress`, and `max_batch_size` are shown. The handler example triggers an action based on data changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Write your own handler\n# the event will contains all fields of the subscribed MV/Table plus two additional columns:\n# - op: varchar. The change operations. Valid values: [Insert, UpdateInsert, Delete, UpdateDelete]. \n#                The reason why we have UpdateInsert and UpdateDelete is because RisingWave treats an UPDATE \n#                as a delete of the old value followed by an insert of the new value.\n# - rw_timestamp: bigint. The Unix timestamp in milliseconds when the data was written.\ndef simple_event_handler(event: pd.DataFrame):\n    for _, row in event.iterrows():\n        # Trigger an action (e.g. place an order via REST API) when the avg_price exceeds 300\n        if (row[\"op\"] == \"UpdateInsert\" or row[\"op\"] == \"Insert\") and row[\"avg_price\"] >= 300:\n                print(\n                    f\"{row['window_start']} - {row['window_end']}: {row['product']} avg price {row['avg_price']} exceeds 300\")\n                # ...\n\n\nimport threading\n\n# Subscribe changes of a materialized view and feed it to your own handler.\n# Run on_change in a separate thread without blocking the main thread.\nthreading.Thread(\n    target=lambda: mv.on_change(\n        # Pass your handler here\n        handler = simple_event_handler,\n        # Support DATAFRAME and RAW tuples here\n        output_format=OutputFormat.DATAFRAME,\n        # If set to True, progress of the subscription will be saved and can be recovered on python application crashed\n        persist_progress=True, \n        # Maximal number of rows returned each time\n        max_batch_size = 10)\n    ).start()\n\n# Subscribe changes of a table and print them to console.\n# Run on_change in a separate thread without blocking the main thread.\nthreading.Thread(\n    target=lambda: rw.on_change(\n        subscribe_from=\"test\",\n        handler = lambda data: print(data),\n        output_format=OutputFormat.RAW,\n        persist_progress=False, \n        max_batch_size = 5)\n    ).start()\n\n\n# Future inserted data into the base table will be reflected in the subscriptions\n# df = pd.DataFrame(\n#     {\n#         \"product\": [\"foo\", \"bar\"],\n#         \"price\": [1000.2, 5000.4],\n#         \"ts\": [datetime.strptime(\"2023-10-05 17:30:00\", \"%Y-%m-%d %H:%M:%S\"), \n#                datetime.strptime(\"2023-10-05 17:31:20\", \"%Y-%m-%d %H:%M:%S\")],\n#     }\n# )\n# rw.insert(table_name=\"test\", data=df)\n```\n\n----------------------------------------\n\nTITLE: Basic SQL WITH Clause Syntax\nDESCRIPTION: Demonstrates the basic syntax of a SELECT statement with an optional WITH clause. The WITH clause defines a named CTE that can be referenced in the main query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nWITH name_for_summary_data AS (SELECT statement)\nSELECT columns\nFROM name_for_summary_data\n```\n\n----------------------------------------\n\nTITLE: Using DISTINCT ON clause with ORDER BY in SQL SELECT statements\nDESCRIPTION: This example shows how to use DISTINCT ON to retrieve the latest order for each customer. The query uses ORDER BY to ensure that the row with the latest order_date appears first for each customer_id.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Retrieve the latest order for each unique customer.\nSELECT DISTINCT ON (customer_id) order_id, customer_id, order_date, total_amount\nFROM orders\nORDER BY customer_id, order_date DESC;\n```\n\n----------------------------------------\n\nTITLE: Altering Table or Source Schema in RisingWave - SQL\nDESCRIPTION: These SQL statements demonstrate how to add a new column (birth_date) to a RisingWave table and source using ALTER TABLE and ALTER SOURCE commands. Existing records will have NULL in the new column. No dependencies besides an existing table or source are necessary. The main input is the table or source name and the target column definition; the output is a schema-modified streaming object.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE customers ADD COLUMN birth_date date;\n\nALTER SOURCE customers ADD COLUMN birth_date date;\n\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Return Expression\nDESCRIPTION: Shows how to create a SQL UDF using the RETURN clause instead of AS definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_return(INT, INT) returns int language sql return $1 + $2;\n```\n\n----------------------------------------\n\nTITLE: Creating a JDBC Sink to CockroachDB in RisingWave\nDESCRIPTION: This SQL query creates a sink named 'sink1' in RisingWave to transfer data from a materialized view 'mv1' to a CockroachDB table 'target_count'. It uses the JDBC connector with specific connection parameters and defines the sink type as 'upsert' with a primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/cockroachdb.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1\nFROM mv1\nWITH (\n  connector = 'jdbc',\n  jdbc.url = 'jdbc:postgresql://cockroachdb:26257/defaultdb',\n  user = 'root',\n  password = '...',\n  table.name = 'target_count',\n  type = 'upsert',\n  primary_key = 'target_id'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source Connection\nDESCRIPTION: SQL statement to create a source connection to Kafka stream with Twitter data structure.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE twitter (\n    data STRUCT < created_at TIMESTAMP WITH TIME ZONE,\n    id VARCHAR,\n    text VARCHAR,\n    lang VARCHAR >,\n    author STRUCT < created_at TIMESTAMP WITH TIME ZONE,\n    id VARCHAR,\n    name VARCHAR,\n    username VARCHAR,\n    followers INT >\n) WITH (\n    connector = 'kafka',\n    topic = 'twitter',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying a RisingWave Materialized View in SQL\nDESCRIPTION: This simple SQL SELECT statement demonstrates how to query the `checkin_open_notification` materialized view in RisingWave. It retrieves the first 5 rows from the view, showing the latest filtered data for passengers who should receive check-in notifications.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/solace.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM checkin_open_notification LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Joining Orders and Product Descriptions in SQL\nDESCRIPTION: This SQL query demonstrates joining the `orders` table with the `product_description` table based on the `product_id`. This example is used in the context of discussing join amplification, where certain join key values (like a popular `product_id`) might cause performance issues. The surrounding text explains a workaround involving splitting the materialized view based on conditions applied to another column (e.g., `orders.user_id % 7` or `hash_value(orders.user_id) % 7`) to distribute the workload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/troubleshoot-high-latency.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT * FROM orders\nINNER JOIN product_description\nON orders.product_id = product_description.product_id\n```\n```\n\n----------------------------------------\n\nTITLE: Defining INNER JOIN Syntax - SQL\nDESCRIPTION: These code snippets provide the different syntactic forms of INNER JOIN in SQL as supported by RisingWave, including the use of ON, USING, and NATURAL clauses. They define how to join two table expressions based on user-specified join conditions or using common columns. The expected input is two table expressions, and output is a combined set of rows matching the join condition. No execution occurs here; these are purely templates for query statements.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n<table_expression> INNER JOIN <table_expression> ON <join_conditions>;\n<table_expression> INNER JOIN <table_expression> USING (<col_name>, <col_name>, ...);\n<table_expression> NATURAL [ INNER ] JOIN <table_expression>;\n```\n\n----------------------------------------\n\nTITLE: Joined Tables Syntax in SQL\nDESCRIPTION: Syntax for creating joined tables in a FROM clause. A joined table is derived from two other tables according to the rules of the specified join type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/from-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nt1 join_type t2 [ join_condition ]\n```\n\n----------------------------------------\n\nTITLE: Using Standard Deviation and Variance Functions with rw_int256 in SQL\nDESCRIPTION: Shows how to use population and sample standard deviation and variance functions with rw_int256 values, returning double results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT stddev_pop(v), stddev_samp(v), var_pop(v), var_samp(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from an Internal Table in RisingWave\nDESCRIPTION: Example of querying data from a specific internal table using a SELECT statement with a LIMIT clause to view the first 5 rows of data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-internal-tables.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_v_19_hashjoinleft_1013 LIMIT 5;\n\n orders.o_orderkey | orders.o_orderdate | orders.o_shippriority | customer.c_custkey | orders.o_custkey\n-------------------+--------------------+-----------------------+--------------------+------------------\n                69 | 1994-06-04         |                     0 |                 85 |               85\n               256 | 1993-10-19         |                     0 |                125 |              125\n              1154 | 1992-02-15         |                     0 |                 37 |               37\n              1792 | 1993-11-09         |                     0 |                 49 |               49\n              1894 | 1992-03-30         |                     0 |                 76 |               76\n(5 rows)\n```\n\n----------------------------------------\n\nTITLE: Using UDFs in SQL Queries\nDESCRIPTION: Example SQL queries demonstrating how to use the declared UDFs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gcd(25, 15);\nSELECT * FROM series(10);\n```\n\n----------------------------------------\n\nTITLE: Using var_pop function in SQL\nDESCRIPTION: Calculates the population variance of input values. Returns NULL if there are no non-null values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nvar_pop ( expression ) -> output_value\n```\n\n----------------------------------------\n\nTITLE: Example Output for Consuming Subscription with Python\nDESCRIPTION: This snippet provides example output from the Python client after fetching rows from a RisingWave subscription. Each output line includes tuple-style values representing columns and their change metadata. Shown output illustrates incremental data changes as fetched by the Python consumption loop.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nRow fetched: (1, 'Alice', 30, 1, 1716434906890)\nRow fetched: (2, 'Bob', 25, 1, 1716434909889)\nRow fetched: (3, 'Charlie', 35, 1, 1716434912889)\nRow fetched: (4, 'Diana', 28, 1, 1716434920889)\n```\n\n----------------------------------------\n\nTITLE: Creating Upsert Sink from Upsert Source in SQL\nDESCRIPTION: This SQL snippet illustrates the creation of an upsert sink from an upsert source in RisingWave. It specifies the 'upsert' type and includes a 'primary_key' field to identify the primary key in the target ClickHouse table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK s1_sink FROM s1_table\nWITH (\n    connector = 'clickhouse',\n    type = 'upsert',\n    primary_key = 'seq_id',\n    clickhouse.url = '${CLICKHOUSE_URL}',\n    clickhouse.user = '${CLICKHOUSE_USER}',\n    clickhouse.password = '${CLICKHOUSE_PASSWORD}',\n    clickhouse.database = 'default',\n    clickhouse.table='demo_test'\n);\n```\n\n----------------------------------------\n\nTITLE: Example: Revoking Source Privilege in SQL\nDESCRIPTION: Example showing how to revoke the SELECT privilege for a specific source from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE SELECT\nON SOURCE s1\nFROM user1;\n```\n\n----------------------------------------\n\nTITLE: Example: Renaming a View using ALTER VIEW RENAME TO in SQL\nDESCRIPTION: Example SQL command illustrating how to rename a view named `view1` to `view2` using the `ALTER VIEW ... RENAME TO` clause. This updates the identifier used to reference the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Change the name of the view named \"view1\" to \"view2\"\nALTER VIEW view1 RENAME TO view2;\n```\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View in RisingWave\nDESCRIPTION: Executes a query on the materialized view 'counter' to retrieve and display real-time aggregated data\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/go.mdx#2025-04-23_snippet_4\n\nLANGUAGE: go\nCODE:\n```\nsql := `SELECT * FROM counter`\nrows, err := conn.Query(context.Background(), sql)\nif err != nil {\n return err\n}\ndefer rows.Close()\n\nfor rows.Next() {\n var total_distance, total_duration float64\n err = rows.Scan(&total_distance, &total_duration)\n if err != nil {\n  return err\n }\n fmt.Printf(\"Total Distance: %.2f, Total Duration: %.2f\\n\", total_distance, total_duration)\n}\nreturn rows.Err()\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Emit-on-Window-Close Behavior in SQL\nDESCRIPTION: This SQL snippet modifies the previous example to use the 'emit on window close' policy by adding the `EMIT ON WINDOW CLOSE` clause. The materialized view `window_count` will now only emit the final, immutable count aggregation result for each 1-minute window when the watermark for `event_time` surpasses the window's end time. This requires a watermark to be defined on the source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW window_count AS\nSELECT window_start, window_end, COUNT(*)\nFROM TUMBLE(events, event_time, INTERVAL '1' MINUTE)\nGROUP BY window_start, window_end\nEMIT ON WINDOW CLOSE;\n```\n\n----------------------------------------\n\nTITLE: Committing a Transaction in RisingWave SQL\nDESCRIPTION: Finalizes a transaction initiated with `START TRANSACTION` or `BEGIN`. In the context of read-only transactions, this command submits the sequence of read queries performed within the transaction block as a single, atomic unit.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/transactions.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCOMMIT\n```\n\n----------------------------------------\n\nTITLE: Refreshing Source Schema from Registry in RisingWave SQL\nDESCRIPTION: This section demonstrates how to use the REFRESH SCHEMA clause to fetch and update a source's schema from a schema registry. It requires the source to have been created with a schema registry and appropriate network access. The operation does not allow dropping columns or changing field types and will update the source to match the latest registry schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name REFRESH SCHEMA;\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE src_user WITH (\n    connector = 'kafka',\n    topic = 'sr_pb_test',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n)\nFORMAT PLAIN ENCODE PROTOBUF(\n    schema.registry = 'http://message_queue:8081',\n    message = 'test.User'\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE src_user REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Example of Dropping a View if it Exists in SQL\nDESCRIPTION: Provides a practical example demonstrating how to use the `DROP VIEW` command with the `IF EXISTS` clause. This specific statement attempts to remove the view named `sales_report`, but will not raise an error if the view is not found.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-view.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP VIEW IF EXISTS sales_report;\n```\n\n----------------------------------------\n\nTITLE: Updating an Existing BYOC Environment with Custom Settings\nDESCRIPTION: This Bash command updates an existing BYOC environment with new custom settings using the RisingWave CLI (rwc), specifying the environment name, version, and path to custom settings file.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ rwc byoc update \\\n  --name $BYOC_NAME \\\n  --version $VERSION \\\n  --custom-settings-path $BYOC_CONFIG\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in RisingWave for Segment Webhook Data with Raw String Verification\nDESCRIPTION: Creates a table configured to accept webhook data from Segment, including signature validation using a raw string instead of a secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/segment-webhook.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE AS secure_compare(\n  headers->>'x-signature',\n  encode(hmac('TEST_WEBHOOK', data, 'sha1'), 'hex')\n);\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Client on Red Hat/CentOS\nDESCRIPTION: Installs only the PostgreSQL client package on Red Hat/CentOS systems using YUM, which includes psql and other client utilities without the server components.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsudo yum install postgresql\n```\n\n----------------------------------------\n\nTITLE: Creating Equivalent Wide Table using Materialized View and Joins in SQL\nDESCRIPTION: This SQL snippet shows the equivalent operation to the previous star schema enrichment example, but implemented using a `CREATE MATERIALIZED VIEW` statement. It joins the `fact` table with dimension tables `d1`, `d2`, and `d3` using `LEFT JOIN` operations based on the foreign key relationships (k1=d1.pk, k2=d2.pk, k3=d3.pk). This approach achieves the same result as the multiple sink method but potentially incurs higher resource usage compared to the sink-based approach for maintaining wide tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/maintain-wide-table-with-table-sinks.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW wide_fact AS\nSELECT fact.pk, d1.v v1, d2.v v2, d3.v v3\nFROM fact\nLEFT JOIN d1 ON fact.k1 = d1.pk\nLEFT JOIN d2 ON fact.k2 = d2.pk\nLEFT JOIN d3 ON fact.k3 = d3.pk\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Source in RisingWave\nDESCRIPTION: Creates a source table 'walk' using the datagen connector to generate mock data for distance and duration metrics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/nodejs.mdx#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Pool } = require('pg')\n\nconst credentials = {\n    user: 'root',\n    host: '127.0.0.1',\n    database: 'dev',\n    password: 'secret',\n    port: 4566,\n}\n\nconst createsource = `CREATE TABLE walk(distance INT, duration INT)\nWITH ( connector = 'datagen',\n    fields.distance.kind = 'sequence',\n    fields.distance.start = '1',\n    fields.distance.end  = '60',\n    fields.duration.kind = 'sequence',\n    fields.duration.start = '1',\n    fields.duration.end = '30',\n    datagen.rows.per.second='15',\n    datagen.split.num = '1'\n) FORMAT PLAIN ENCODE JSON`;\n\nconst start = async () => {\n    const pool = new Pool(credentials);\n    const res = await pool.query(createsource);\n    console.log(res);\n    await pool.end();\n}\nstart().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Adding a Column to a Source in RisingWave SQL\nDESCRIPTION: This snippet shows how to add a new column to an existing source using the ADD COLUMN clause. The command specifies the source name, the column name, and its data type. Adding nested columns is supported using the struct type. Modifying primary keys or removing columns is not supported—such operations require recreating the source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name\n    ADD COLUMN col_name data_type;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Add a column named \"v3\" to a source named \"src1\"\nALTER SOURCE src1\n    ADD COLUMN v3 int;\n```\n\n----------------------------------------\n\nTITLE: Creating Orders CDC Table in RisingWave\nDESCRIPTION: SQL command for creating a table in RisingWave that ingests CDC data from Neon's orders table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE orders (\n    order_id INTEGER PRIMARY KEY,\n    customer_id INTEGER,\n    order_timestamp TIMESTAMP,\n    total_amount NUMERIC,\n    status VARCHAR\n) WITH (\n    connector = 'postgres-cdc',\n    hostname = '127.0.0.1',\n    port = '5432',\n    username = 'postgres',\n    password = 'postgres',\n    database.name = 'dev',\n    schema.name = 'public',\n    table.name = 'order'\n);\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL CDC Backfill Progress\nDESCRIPTION: This SQL query retrieves information about the initial backfill progress for a MySQL CDC source. It shows whether the backfill is complete, how many rows have been processed, and the current position in the MySQL binlog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_my_mysql_source_1_streamcdcscan_4;\n```\n\n----------------------------------------\n\nTITLE: Using percentile_disc function in SQL\nDESCRIPTION: Computes discrete percentile, returning the first value whose position equals or exceeds the specified fraction. Not supported for streaming queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\npercentile_disc ( fraction double precision ) WITHIN GROUP ( ORDER BY sort_expression anyelement ) -> same as sort_expression\n```\n\n----------------------------------------\n\nTITLE: Basic SQL Query Structure with HAVING Clause\nDESCRIPTION: This snippet demonstrates the structure of a SELECT query that includes a HAVING clause. It shows the proper position of the HAVING clause in relation to other SQL clauses like SELECT, FROM, WHERE, GROUP BY, and ORDER BY.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/having-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column1, column2\nFROM table1, table2\nWHERE [ conditions ]\nGROUP BY column1, column2\nHAVING [ conditions ]\nORDER BY column1, column2\n```\n\n----------------------------------------\n\nTITLE: Example Session Window Query Result - Bash\nDESCRIPTION: Output example of a session window aggregation, showing user IDs, session window start time, and the count of unique products viewed per session. For illustration of expected analytical result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n user_id | window_start        | n_viewed_product\\n---------+---------------------+-----------------\\n 1       | 2022-07-01 22:00:00 | 2\\n 1       | 2022-07-01 22:10:00 | 1\\n 2       | 2022-07-01 22:05:00 | 2\n```\n\n----------------------------------------\n\nTITLE: Old Syntax for Defining Table with Primary Key in Column Definition\nDESCRIPTION: The old syntax for creating a table with a connector where the primary key is defined within the column definition. This approach is being deprecated in favor of using table constraint syntax.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE debezium_non_compact (order_id int PRIMARY KEY) WITH (\nconnector = 'kafka',\nkafka.topic = 'debezium_non_compact_avro_json',\nkafka.brokers = 'message_queue:29092',\nkafka.scan.startup.mode = 'earliest'\n) ROW FORMAT DEBEZIUM_AVRO ROW SCHEMA LOCATION CONFLUENT SCHEMA REGISTRY 'http://message_queue:8081';\n```\n\n----------------------------------------\n\nTITLE: Retrieving Index Size for a Table in SQL\nDESCRIPTION: Shows how to use pg_indexes_size() function to get the total size of all indexes associated with a particular table in bytes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_indexes_size('t1');\n---------RESULT\n pg_indexes_size\n-----------------\n               0\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Changing Connection Schema Example with SQL\nDESCRIPTION: This SQL example shows exactly how to issue an ALTER CONNECTION command to change the schema associated with a specific connection. The connection 'test_conn' is reassigned to 'test_schema'. This command is useful when reorganizing or migrating database objects between schemas; ensure you have the necessary privileges before execution. The output is a modified association for the named connection; if the schema or connection does not exist, an error occurs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-connection.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the schema of the connection named \"test_conn\" to a schema named \"test_schema\"\nALTER CONNECTION test_conn SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with SQLAlchemy\nDESCRIPTION: Establishes a connection to RisingWave using SQLAlchemy with the risingwave+psycopg2 driver.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nDB_URI = 'risingwave+psycopg2://root@risingwave-standalone:4566/dev'\n\nengine = create_engine(DB_URI)\n```\n\n----------------------------------------\n\nTITLE: Creating an Upsert Sink to Apache Doris\nDESCRIPTION: Example of creating an upsert sink from RisingWave to Apache Doris. This configuration enables updating existing records based on a primary key (user_id). The target Doris table must have a UNIQUE KEY constraint.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-doris.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK doris_sink FROM mv1\nWITH (\n    connector = 'doris',\n    type = 'upsert',\n    doris.url = 'http://fe:8030',\n    doris.user = 'xxxx',\n    doris.password = 'xxxx',\n    doris.database = 'demo',\n    doris.table='demo_bhv_table',\n    primary_key = 'user_id'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Sink with Without Backfill in RisingWave - SQL\nDESCRIPTION: This example demonstrates how to create a new sink from a source with the 'without_backfill = true' option, ensuring that only new data is streamed out. The sink is created using the CREATE SINK ... FROM ... WITH syntax, which assumes the referenced materialized view exists. The output excludes existing (historical) records.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK ... FROM ... WITH (without_backfill = true).\n```\n\n----------------------------------------\n\nTITLE: Example Tumbling Window Query Result with Missing Windows - Bash\nDESCRIPTION: Output example of trip count aggregation in 2-minute tumbling windows, demonstrating a missing time window row where no data exists. Useful for illustrating the 'gap' problem in aggregations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n window_start        | window_end           | trip_count \\n---------------------+----------------------+------------\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00  | 2          \\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00  | 2          \\n 2022-07-01 22:06:00 | 2022-07-01 22:08:00  | 1          \\n 2022-07-01 22:08:00 | 2022-07-01 22:10:00  | 1          \n```\n\n----------------------------------------\n\nTITLE: Querying Materialized View After Deletion in RisingWave (SQL)\nDESCRIPTION: This code snippet queries the materialized view 'mv' once more, after several rows have been deleted from the base table. The results display updated aggregate sums reflecting only the remaining data in table 't'. 'mv' must exist prior to running this query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from mv;\n```\n\n----------------------------------------\n\nTITLE: Creating a Sink in RisingWave for Delta Lake\nDESCRIPTION: This SQL snippet shows the syntax for creating a sink in RisingWave to transfer data to Delta Lake. It includes various parameters for configuring the sink, such as connector type, location, and S3 credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='deltalake',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Defining LEFT OUTER JOIN Syntax - SQL\nDESCRIPTION: These code snippets show syntactic variations for LEFT OUTER JOIN (or LEFT JOIN) in SQL as handled by RisingWave. They specify joining two tables where all rows from the left table are kept, and matching or NULL-filled data appears from the right table depending on the join condition. The input should be two valid table expressions; output will include unmatched left-side row values with NULLs for missing right-side data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n<table_expression> LEFT [ OUTER ] JOIN <table_expression> ON <join_conditions>;\n<table_expression> LEFT [ OUTER ] JOIN <table_expression> USING (<col_name>, <col_name>, ...);\n<table_expression> NATURAL LEFT [ OUTER ] JOIN <table_expression>;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View with VALUES Clause in RisingWave\nDESCRIPTION: Shows how to use the VALUES clause to create a materialized view with predefined data in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/values-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv (id, name) AS VALUES (1, 'John'), (2, 'Jane'), (3, 'Bob');\n```\n\n----------------------------------------\n\nTITLE: Updating Homebrew Package Definitions on macOS\nDESCRIPTION: Updates the Homebrew package definitions (formulae) on macOS to ensure the latest package information is available before installing packages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbrew update\n```\n\n----------------------------------------\n\nTITLE: Syntax for SHOW SINKS Command in RisingWave SQL\nDESCRIPTION: Defines the syntax for the SHOW SINKS command, which can list all sinks optionally filtered by schema and name pattern.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-sinks.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SINKS [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Data in Iceberg Tables with Time Travel\nDESCRIPTION: SQL syntax for time travel queries in Iceberg tables, allowing users to query data as of a specific timestamp (in string format or Unix timestamp) or snapshot ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg-config.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Query as of a timestamp (STRING format)\nSELECT * FROM source_name FOR SYSTEM_TIME AS OF 'YYYY-MM-DD HH:MM:SS[+-HH:MM]';\n\n-- Query as of a timestamp (UNIX timestamp in seconds)\nSELECT * FROM source_name FOR SYSTEM_TIME AS OF <unix_timestamp_seconds>;\n\n-- Query as of a snapshot ID\nSELECT * FROM source_name FOR SYSTEM_VERSION AS OF <snapshot_id>;\n```\n\n----------------------------------------\n\nTITLE: Basic INCLUDE Clause Syntax for Source or Table Creation in SQL\nDESCRIPTION: Shows the general syntax for using the INCLUDE clause when creating a source or table in RisingWave. The clause extracts fields not included in the main payload as separate columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE { header | key | offset | partition | timestamp | payload | subject | file | database_name | collection_name } [AS column_name]\n```\n\n----------------------------------------\n\nTITLE: Setting System-Wide Runtime Parameters Using ALTER SYSTEM SET in SQL\nDESCRIPTION: This snippet illustrates the ALTER SYSTEM SET command to modify the default value of a runtime parameter for all new sessions in the system. The 'session_param_name' specifies the parameter, while 'session_param_value' provides the new default value. This operation only applies to sessions started after the command is run; currently active sessions are unaffected. The command requires database-level ALTER SYSTEM privileges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-runtime-parameters.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET session_param_name TO session_param_value;\n```\n\n----------------------------------------\n\nTITLE: Installing pgx Driver with Go\nDESCRIPTION: Command to install the pgx PostgreSQL driver package for Go applications\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/go.mdx#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngo get github.com/jackc/pgx/v4\n```\n\n----------------------------------------\n\nTITLE: Configuring S3 Bucket in Docker Compose File\nDESCRIPTION: Example of specifying an S3 bucket name in the docker-compose-with-s3.yml configuration file. This parameter is required when using S3 or S3-compatible storage as the state store.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n- \"hummock+s3://<bucket-name>\"\n```\n\n----------------------------------------\n\nTITLE: Using SHOW CREATE VIEW with Example in SQL\nDESCRIPTION: A complete example demonstrating how to create a view and then use SHOW CREATE VIEW to display its definition. The example creates a view named v1 that selects the id column from the taxi_trips table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-view.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE VIEW v1 AS SELECT id FROM taxi_trips;\nSHOW CREATE VIEW v1;\n```\n\n----------------------------------------\n\nTITLE: Example Execution Plan Output for CREATE MATERIALIZED VIEW (Stream)\nDESCRIPTION: Provides an example execution plan for a `CREATE MATERIALIZED VIEW` statement (likely the preceding example). This stream plan outlines the operators (like StreamTableScan, StreamFilter, StreamHashJoin, StreamProject, StreamExchange, StreamMaterialize) involved in building and maintaining the materialized view state as data flows through the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-explain.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n                      QUERY PLAN\n-----------------------------------------------------------\n StreamMaterialize { columns: [name, city, state, id, _row_id(hidden), _row_id#1(hidden)], pk_columns: [_row_id, _row_id#1] }\n   StreamExchange { dist: HashShard([4, 5]) }\n     StreamProject { exprs: [$4, $5, $6, $0, $2, $7] }\n       StreamHashJoin { type: Inner, predicate: $1 = $3 }\n         StreamProject { exprs: [$0, $1, $3] }\n           StreamExchange { dist: HashShard([1]) }\n             StreamFilter { predicate: ($2 = 10:Int32) }\n               StreamTableScan { table: auction, columns: [id, seller, category, _row_id], pk_indices: [3] }\n         StreamExchange { dist: HashShard([0]) }\n           StreamFilter { predicate: ((($3 = 'OR':Varchar) OR ($3 = 'ID':Varchar)) OR ($3 = 'CA':Varchar)) }\n             StreamTableScan { table: person, columns: [id, name, city, state, _row_id], pk_indices: [4] }\n```\n\n----------------------------------------\n\nTITLE: Creating a Table-Returning JavaScript UDF in RisingWave SQL\nDESCRIPTION: This example shows how to create a JavaScript UDF named 'series' that returns a table. It demonstrates the use of the 'yield' statement to return multiple rows of data from the function.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-javascript.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION series(n int) RETURNS TABLE (x int) LANGUAGE javascript AS $$\n    for(let i = 0; i < n; i++) {\n        yield i;\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Resetting Time Zone to Server Default\nDESCRIPTION: Example of resetting the time zone to the server's default configuration value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-time-zone.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET TIME ZONE DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Basic Range Function Usage\nDESCRIPTION: Shows the basic syntax of the range() function which generates sequences similar to generate_series() but excludes the end value\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM range(start, stop, step);\n```\n\n----------------------------------------\n\nTITLE: Checking Pod Status\nDESCRIPTION: Commands to verify the status of RisingWave pods after upgrade.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods -l risingwave/name=<risingwave-cluster>\n```\n\nLANGUAGE: bash\nCODE:\n```\nNAME                                    READY   STATUS    RESTARTS      AGE\nrisingwave-compactor-5cfcb469c5-gnkrp   1/1     Running   2 (1m ago)    2m35s\nrisingwave-compute-0                    1/1     Running   2 (1m ago)    2m35s\nrisingwave-frontend-86c948f4bb-69cld    1/1     Running   2 (1m ago)    2m35s\nrisingwave-meta-0                       1/1     Running   1 (1m ago)    2m35s\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using ruby-pg in Ruby\nDESCRIPTION: This snippet demonstrates how to establish a connection to RisingWave using the ruby-pg driver. It specifies the host, port, database name, and user for the connection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/ruby.mdx#2025-04-23_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'pg'\n\nconn = PG.connect(host: '127.0.0.1', port: 4566, dbname: 'dev', user: 'root')\n```\n\n----------------------------------------\n\nTITLE: Fetching Data Non-Blocking from Subscription Cursor in RisingWave\nDESCRIPTION: This snippet demonstrates performing a non-blocking fetch for the next N rows from a subscription cursor in RisingWave. The query immediately returns available rows from the cursor up to N; if fewer than N rows are available, it returns the partial result set. It's used for incremental, polling-style data consumption.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nFETCH NEXT/n FROM cursor_name;\n```\n\n----------------------------------------\n\nTITLE: Generate Series with Step Increment\nDESCRIPTION: Example demonstrating generate_series() with a custom step value of 2 to generate even numbers from 2 to 10\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM generate_series(2, 10, 2);\n```\n\n----------------------------------------\n\nTITLE: Invalid Table Creation with Generated Column\nDESCRIPTION: Example of an invalid table creation where a source column appears after a generated column, which will result in an error.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n  id integer PRIMARY KEY,\n  next_id int AS id + 1,\n  name varchar,\n  PRIMARY KEY (id)\n) FROM pg_mydb TABLE 'public.person';\n```\n\n----------------------------------------\n\nTITLE: Creating a Streaming Materialized View - SQL\nDESCRIPTION: This SQL statement creates a materialized view 'm1' that continuously maintains the count of all rows in table 't' in real-time as changes arrive. Used to illustrate the difference between batch and streaming workloads in RisingWave, this command requires streaming-enabled infrastructure and that 't' exists. The output is a continuously updated view which can be queried via 'SELECT * FROM m1', returning up-to-date aggregation results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/reference/architecture.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW m1 AS SELECT COUNT(*) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Creating a Protobuf Source in RisingWave\nDESCRIPTION: Example of creating a Kafka source with Protobuf encoding that uses a schema registry, preparing it for later schema refresh operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE src_user WITH (\n    connector = 'kafka',\n    topic = 'sr_pb_test',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n)\nFORMAT PLAIN ENCODE PROTOBUF(\n    schema.registry = 'http://message_queue:8081',\n    message = 'test.User'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a SQL Server Sink in RisingWave\nDESCRIPTION: This SQL statement creates a sink from RisingWave to Microsoft SQL Server. It specifies the source data and connection parameters required to establish the sink connection. The sink enables data to flow from a RisingWave materialized view or table to a specified SQL Server table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/sql-server.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='sqlserver',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Updated Results from the Materialized View\nDESCRIPTION: SQL query to retrieve the latest data from the average_exam_scores materialized view, showing how the view automatically updates with the newly inserted data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM average_exam_scores;\n------\n exam_id |   average_score   | total_scores\n---------+-------------------+--------------\n     101 |             87.74 |            5\n     102 | 88.64000000000001 |            5\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Listing Kafka Topics\nDESCRIPTION: This optional bash command lists all Kafka topics using the Kafka topics script with SASL authentication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nbin/kafka-topics.sh --bootstrap-server <broker-url> --list --command-config ~/client_sasl.properties\n```\n\n----------------------------------------\n\nTITLE: Counting JSON Array Elements with jsonb_array_length\nDESCRIPTION: Function that returns the number of elements in a top-level JSON array as an integer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_array_length('[1,2,3,{\"f1\":1,\"f2\":[5,6]},4]');\n```\n\n----------------------------------------\n\nTITLE: Creating a MySQL CDC Source with dbt\nDESCRIPTION: Creates a MySQL CDC source using dbt's 'source' materialization model. The source connects to a MySQL database with specified connection parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\n{{ config(materialized='source') }}\nCREATE SOURCE {{ this }} WITH (\n  connector = 'mysql-cdc',\n  hostname = '127.0.0.1',\n  port = '8306',\n  username = 'root',\n  password = '123456',\n  database.name = 'mydb',\n  server.id = 5888\n);\n```\n\n----------------------------------------\n\nTITLE: Setting up database and table in self-hosted MySQL\nDESCRIPTION: SQL queries to create a database 'test_db', use it, and create a 'personnel' table within it.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE test_db;\n\nUSE test_db;\n\nCREATE TABLE personnel (\n id integer,\n name varchar(200),\n PRIMARY KEY (id)\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Materialized View Results\nDESCRIPTION: SQL query to retrieve and display the first 5 rows from the metric_avg_30s materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM metric_avg_30s LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Example Usage of SHOW JOBS Command in SQL\nDESCRIPTION: An example of using the SHOW JOBS command in RisingWave. It demonstrates the output format, showing job IDs, statements, and progress percentages for ongoing materialized view creations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-jobs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW JOBS;\n------RESULT\n  Id  |                     Statement                     | Progress\n------+---------------------------------------------------+----------\n 1010 | CREATE MATERIALIZED VIEW mv3 AS SELECT *FROM mv1  | 2.21%\n 1012 | CREATE MATERIALIZED VIEW mv2 AS SELECT* FROM mv1  | 0.86%\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source for Ad Clicks in RisingWave\nDESCRIPTION: SQL statement to create a source in RisingWave that connects to the Kafka topic containing ad click events. This defines the schema and connection properties for consuming click data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE ad_click (\n    bid_id BIGINT,\n    click_timestamp TIMESTAMP WITH TIME ZONE\n) WITH (\n    connector = 'kafka',\n    topic = 'ad_click',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Simple Array Constructor Example in RisingWave SQL\nDESCRIPTION: Demonstrates creating a simple one-dimensional array with three elements, where the third element is the result of a calculation. The result is an array containing the values 1, 2, and 12.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ARRAY[1, 2, 3*4];\n----------\n {1,2,12}\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Storing Authentication Secret in JSON Format\nDESCRIPTION: This JSON snippet defines the username and password for SASL authentication in Amazon MSK. It is used when storing a new secret in AWS Secrets Manager.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"username\": \"<your-username>\",\n  \"password\": \"<your-password>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Configurable NATS JetStream Source in RisingWave (SQL)\nDESCRIPTION: This SQL snippet creates a source 'test_source' in RisingWave, ingesting from a NATS JetStream stream. It demonstrates usage of a wide range of configurable NATS consumer parameters, such as authentication, delivery, acknowledgment, subject filtering, batching, and more—mapping closely to options available in the async_nats crate. Environment variable interpolation is supported for sensitive parameters. Requires RisingWave with NATS source connector support, as well as a reachable NATS JetStream server. The created source makes data available for real-time processing downstream, with configuration parameters affecting ingestion behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/nats-jetstream.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE test_source\nWITH (\n    connector='nats',\n    server_url='{{ env_var(\"SERVER\") }}',\n    subject='risingwave.test.source',\n    stream='risingwave-test-source',\n    scan.startup.mode='earliest',\n    connect_mode='user_and_password',\n    username='{{ env_var(\"USER\") }}',\n    password='{{ env_var(\"PASSWORD\") }}',\n    consumer.durable_name='risingwave-test-source',\n    consumer.description='desc-test-source',\n    consumer.ack_policy='all',\n    consumer.ack_wait=10,\n    consumer.max_deliver=10,\n    consumer.filter_subjects='demo.subject.filter.*',\n    consumer.filter_subjects='demo.subject.filter.1,demo.subject.filter.2',\n    consumer.replay_policy='instant',\n    consumer.rate_limit=100000000000,\n    consumer.sample_frequency=100,\n    consumer.max_waiting=10,\n    consumer.max_ack_pending=10,\n    -- consumer.idle_heartbeat=60, not available in async_nats crate\n    consumer.max_batch=1000,\n    consumer.max_bytes=1000000000,\n    consumer.max_expires=3600,\n    consumer.inactive_threshold=10000000,\n    consumer.memory_storage='false',\n    consumer.backoff='10,30,60',\n    consumer.num_replicas=1\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Processing HubSpot Event Data\nDESCRIPTION: Creates a materialized view to extract specific fields from the JSON payload stored in the webhook table. This allows for easier querying and analysis of the HubSpot event data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hubspot-webhook.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE MATERIALIZED VIEW hubspot_events AS\nSELECT\n  data->>'vid' AS id,\n  data->'properties'->>'lastname' AS last_name,\n  data->'properties'->>'hs_object_id' AS hs_object_id\nFROM wbhtable;\n```\n\n----------------------------------------\n\nTITLE: SQL UPDATE with RETURNING Clause\nDESCRIPTION: Example of updating a city name with a WHERE condition and returning the id of updated rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-update.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE taxi_trips\nSET city = 'San Francisco'\nWHERE city = 'Yerba Buena'\nRETURNING id;\n```\n\n----------------------------------------\n\nTITLE: Inserting Values into Struct Columns\nDESCRIPTION: Examples of inserting values into tables with struct columns using ROW constructor.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO x VALUES (ROW(3, 4), 5);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO y VALUES (ROW(ROW(6), 7), 8);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO trip VALUES\n        (\n            '1234ABCD',\n            '2022-07-28 11:04:05',\n            '2022-07-28 11:15:22',\n            6.1,\n            ROW(1.0, 4.0, 1.5, 2.0)\n        );\n```\n\n----------------------------------------\n\nTITLE: Creating Hashtag Analysis Materialized View\nDESCRIPTION: SQL query to create a materialized view that tracks daily hashtag usage frequencies using regular expressions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW hot_hashtags AS WITH tags AS (\n    SELECT\n        unnest(regexp_matches((data).text, '#\\w+', 'g')) AS hashtag,\n        (data).created_at AS created_at\n    FROM\n        twitter\n)\nSELECT\n    hashtag,\n    COUNT(*) AS hashtag_occurrences,\n    window_start\nFROM\n    TUMBLE(tags, created_at, INTERVAL '1 day')\nGROUP BY\n    hashtag,\n    window_start;\n```\n\n----------------------------------------\n\nTITLE: Creating Azblob Source with Dynamic Schema using INCLUDE payload in RisingWave SQL\nDESCRIPTION: Illustrates creating a RisingWave table (`table_include_payload`) that ingests JSON data from an external source, potentially Azure Blob Storage, using the `INCLUDE payload` clause. This approach loads the entire JSON object into a special `payload` column without requiring a fully predefined schema upfront, allowing for flexible schema handling. Note: The `WITH` clause parameters shown (`topic`, `properties.bootstrap.server`, `scan.startup.mode`) are typical for Kafka/message queues, not Azblob, and might be incorrect for an Azblob source; however, the example demonstrates the `INCLUDE payload` concept with `FORMAT PLAIN ENCODE JSON`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'azblob',\n    topic = 'azblob_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Inventory Table in SQL\nDESCRIPTION: Creates a table to track current stock levels of each product at each warehouse, including warehouse ID, product ID, timestamp, stock level, reorder point, and location.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE inventory (\n    warehouse_id INT,\n    product_id INT,\n    timestamp TIMESTAMPTZ,\n    stock_level INT,\n    reorder_point INT,\n    location VARCHAR\n);\n```\n\n----------------------------------------\n\nTITLE: Simple SQL CTE Example\nDESCRIPTION: Creates a CTE named 'cte' that defines a single column 'x' with a value of 35, then selects all columns from this CTE in the main query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- create a CTE called \"cte\" and use it in the main query\nWITH cte AS (SELECT 35 AS x)\nSELECT * FROM cte;\n┌────┐\n│ x  │\n├────┤\n│ 35 │\n└────┘\n```\n\n----------------------------------------\n\nTITLE: Modifying Source Rate Limit in RisingWave SQL\nDESCRIPTION: This set of examples shows how to control the rate limit for ingesting data from a source using the SET SOURCE_RATE_LIMIT clause. The rate can be set to 'default' or a custom number. This affects only live streaming, not the backfill phase for views, and the operation requires referencing runtime parameter documentation for exact semantics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name\n    SET SOURCE_RATE_LIMIT { TO | = } { default | rate_limit_number };\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Alter the rate limit of a source to default\nALTER SOURCE kafka_source SET source_rate_limit TO default;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Alter the rate limit of a source to 1000\nALTER SOURCE kafka_source SET source_rate_limit TO 1000;\n```\n\n----------------------------------------\n\nTITLE: Configuring MAXWELL JSON Format in RisingWave\nDESCRIPTION: SQL syntax for Maxwell CDC data in JSON format. The schema must be defined directly in the CREATE SOURCE or CREATE TABLE statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT MAXWELL\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS S3 as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up AWS S3 as the state store backend for RisingWave. It specifies the S3 bucket, region, and credentials for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the S3 state store backend.\n    s3:\n      # Region of the S3 bucket.\n      region: us-east-1\n\n      # Name of the S3 bucket.\n      bucket: risingwave\n\n      # Credentials to access the S3 bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: s3-credentials\n\n        # Key of the access key ID in the secret.\n        accessKeyRef: AWS_ACCESS_KEY_ID\n\n        # Key of the secret access key in the secret.\n        secretAccessKeyRef: AWS_SECRET_ACCESS_KEY\n\n        # Optional, set it to true when the credentials can be retrieved\n        # with the service account token, e.g., running inside the EKS.\n        #\n        # useServiceAccount: true\n```\n\n----------------------------------------\n\nTITLE: Calling a Scalar Python UDF in SQL\nDESCRIPTION: Shows how to call the previously created 'gcd' function with example parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT gcd(15, 25);\n\n-----RESULT\n   5\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/GSSAPI (Kerberos) Authentication in RisingWave SQL\nDESCRIPTION: This snippet shows how to create a Kafka source with SASL/GSSAPI (Kerberos) authentication without SSL encryption. It includes Kerberos-specific configurations such as keytab location and principal in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_5 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='GSSAPI',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.kerberos.service.name='kafka',\n   properties.sasl.kerberos.keytab='/etc/krb5kdc/kafka.client.keytab',\n   properties.sasl.kerberos.principal='kafkaclient4@AP-SOUTHEAST-1.COMPUTE.INTERNAL',\n   properties.sasl.kerberos.kinit.cmd='sudo kinit -R -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal} || sudo kinit -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal}',\n   properties.sasl.kerberos.min.time.before.relogin='10000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: UNION ALL Example Query\nDESCRIPTION: Demonstrates UNION ALL usage to combine results from two tables while preserving duplicate rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM points_scored_current_week\nUNION ALL\nSELECT *\nFROM points_scored_last_week;\n```\n\n----------------------------------------\n\nTITLE: Creating a Struct-Returning Python UDF in SQL (Dictionary Method)\nDESCRIPTION: Shows how to create a Python UDF that returns a structured type using a dictionary.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE FUNCTION key_value(varchar) RETURNS STRUCT<key varchar, value varchar> LANGUAGE python AS $$\ndef key_value(s: str):\n    key, value = s.split('=')\n    return {'key': key, 'value': value}\n$$;\n```\n\n----------------------------------------\n\nTITLE: Updating RisingWave meta configuration for SQL backend\nDESCRIPTION: Configuration parameters required to set up RisingWave with SQL backend after migration. These parameters specify the SQL endpoint address and set the backend type to SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/migrate-to-sql-backend.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n--sql-endpoint [endpoint address]\n--backend sql\n```\n\n----------------------------------------\n\nTITLE: Removing a Column from a Table in RisingWave\nDESCRIPTION: SQL command for removing a column from a table. Note that this cannot be done if the column is referenced in a materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name DROP COLUMN column_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Sales Table in SQL\nDESCRIPTION: Creates a table to store sales transaction details, including sale ID, warehouse ID, product ID, quantity sold, and timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE sales (\n    sale_id INT,\n    warehouse_id INT,\n    product_id INT,\n    quantity_sold INT,\n    timestamp TIMESTAMPTZ\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Max Value Aggregation - SQL\nDESCRIPTION: Defines a materialized view that continuously tracks the maximal value of a column (`balance`) from an account table. Useful in scenarios where frequent updates occur and append-only semantics are not permitted. Requires the presence of an `account_table` with a `balance` field. The output is a real-time maintained maximum value, with storage requirements for all potential candidate rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW max_account_balance AS SELECT max(balance) FROM account_table\n```\n\n----------------------------------------\n\nTITLE: SQL Syntax for Dropping a Secret\nDESCRIPTION: Defines the SQL syntax for the `DROP SECRET` command. It requires the name of the secret to be dropped (`secret_name`) as a parameter. This command permanently removes the specified secret from the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-secret.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP SECRET secret_name;\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN with CREATE MATERIALIZED VIEW in RisingWave SQL\nDESCRIPTION: Illustrates using the `EXPLAIN` command to view the execution plan for creating a materialized view (`CREATE MATERIALIZED VIEW`) named `nexmark_q3`. This helps understand the underlying streaming plan before actually creating the view, which joins `auction` and `person` tables based on specific criteria.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-explain.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN CREATE MATERIALIZED VIEW nexmark_q3 AS\n     SELECT P.name, P.city, P.state, A.id\n     FROM auction AS A INNER JOIN person AS P on A.seller = P.id\n     WHERE A.category = 10 and (P.state = 'OR' OR P.state = 'ID' OR P.state = 'CA');\n```\n\n----------------------------------------\n\nTITLE: Using jsonb_object_agg function in SQL\nDESCRIPTION: Aggregates name/value pairs as a JSON object. Values can be null, but keys must be non-null text values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\njsonb_object_agg ( key \"text\" , value \"any\" ) -> jsonb\n```\n\n----------------------------------------\n\nTITLE: Defining Syntax for ALTER SWAP Command in SQL\nDESCRIPTION: This snippet outlines the general syntax structure for the `ALTER ... SWAP` command in RisingWave SQL. It shows how to specify the object type (TABLE, MATERIALIZED VIEW, VIEW, SOURCE, SINK, SUBSCRIPTION), the current object name (`name`), and the target object name (`target_name`) to perform the swap. Both objects must be of the same type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-swap.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER [ TABLE | MATERIALIZED VIEW | VIEW | SOURCE | SINK | SUBSCRIPTION ] name\nSWAP WITH target_name;\n```\n\n----------------------------------------\n\nTITLE: Creating and Commenting on a Table with an Index in SQL\nDESCRIPTION: Demonstrates creating a `customers` table with columns (`customer_id`, `name`, `email`), defining a primary key, adding descriptive comments to the table and its columns using `COMMENT ON`, and creating an index (`idx_customers_email`) on the `email` column. This setup is used as a prerequisite for the `DESCRIBE` example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-describe.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE customers (\n  customer_id BIGINT PRIMARY KEY,\n  name VARCHAR,\n  email VARCHAR\n);\nCOMMENT ON COLUMN customers.customer_id IS 'Unique identifier for each customer';\nCOMMENT ON COLUMN customers.name IS 'Name of the customer';\nCOMMENT ON COLUMN customers.email IS 'Email address of the customer';\nCOMMENT ON TABLE customers IS 'All customer records';\nCREATE INDEX idx_customers_email ON customers(email);\n```\n\n----------------------------------------\n\nTITLE: Creating Campaigns Table in SQL\nDESCRIPTION: Creates a table to store information about each marketing campaign, including campaign type and target audience.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE campaigns (\n    campaign_id varchar PRIMARY KEY,\n    campaign_name varchar,\n    campaign_type varchar,  -- regular, ab_test\n    start_date timestamptz,\n    end_date timestamptz,\n    budget numeric,\n    target_audience varchar\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Sink to Publish Data to a Solace MQTT Topic in SQL\nDESCRIPTION: This SQL statement creates a sink named `checkin_notifications_sink` in RisingWave. It takes the data processed by the `checkin_open_notification` materialized view and sends it to the Solace topic `checkin_open_notification` using the 'mqtt' connector. Connection details, credentials, QoS ('at_least_once'), and plain JSON format are specified for the outgoing data stream.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/solace.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK checkin_notifications_sink\nFROM checkin_open_notification\nWITH (\n    connector = 'mqtt',\n    topic = 'checkin_open_notification',\n    url = 'ssl://xxxxxxxxxx:8883',\n    username='solace-cloud-client',\n    password='xxxxxxxxxxxx', \n    qos = 'at_least_once'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Extracting Date Parts in SQL\nDESCRIPTION: Extracts specific parts of a date or timestamp value. The function can handle various date/time types and precisions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ndate_part('day', date '2022-04-07') → 7\n\ndate_part('hour', timestamp '2022-04-07 22:00:30') → 22\n\ndate_part('second', time '22:00:30.123') → 30.123\n\ndate_part('day', interval '2 days') → 2\n\ndate_part('day', '2023-06-01 00:00:00Z'::timestamptz, 'Australia/Sydney') → 1\n```\n\n----------------------------------------\n\nTITLE: Extracting Key-Value Pairs with jsonb_each\nDESCRIPTION: Function that expands a JSON object into a set of key-value pairs, where keys are varchar and values are jsonb.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_each('{\"a\":\"foo\", \"b\":\"bar\"}'::jsonb);\n```\n\n----------------------------------------\n\nTITLE: Redis Sink Syntax Definition\nDESCRIPTION: SQL syntax definition for creating a Redis sink in RisingWave. It outlines the complete structure including optional clauses, connector parameters, and formatting options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/redis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='redis',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    key = 'value' ) ]\n[KEY ENCODE key_encode [(...)]]\n;\n```\n\n----------------------------------------\n\nTITLE: Running dbt models in RisingWave\nDESCRIPTION: This command executes the defined dbt models in RisingWave. It applies the transformations and materializations specified in the model files.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndbt run\n```\n\n----------------------------------------\n\nTITLE: Querying Resource Group Configuration and Usage in RisingWave (SQL)\nDESCRIPTION: Queries the rw_resource_groups system catalog table to list defined resource groups and summarize each group’s assigned workers, parallelism, and the number of databases and streaming jobs. The query is a simple SELECT statement with no parameters. Output includes one row per resource group, supporting monitoring and troubleshooting of workload allocation and cluster capacity.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_resource_groups;\n-- Example Output:\n  name              | num_workers | total_parallelism_units | num_databases | num_streaming_jobs\n--------------------+-------------+-------------------------+---------------+--------------------\n rg_default         |           4 |                      16 |             2 |                  5\n rg_high_cpu        |           2 |                       8 |             1 |                  1\n rg_general_purpose |           2 |                       8 |             1 |                  3\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Configuring User-Defined Functions in RisingWave\nDESCRIPTION: This snippet demonstrates how to configure user-defined function (UDF) settings in the RisingWave configuration file. It shows how to enable or disable embedded Python, JavaScript, and WebAssembly UDFs using the appropriate boolean flags in the [udf] section.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[udf]\nenable_embedded_python_udf = false\nenable_embedded_javascript_udf = true\nenable_embedded_wasm_udf = true\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source in RisingWave\nDESCRIPTION: SQL statement to register the Kafka topic as a source in RisingWave, defining the structure of the incoming data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE prometheus (\n    labels STRUCT <\n        __name__ VARCHAR,\n        instance VARCHAR,\n        job VARCHAR\n    >,\n    name VARCHAR,\n    timestamp TIMESTAMP WITH TIME ZONE,\n    value VARCHAR\n) WITH (\n    connector = 'kafka',\n    topic = 'prometheus',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Configuring Cloud Storage in Docker Compose File\nDESCRIPTION: Example of specifying a bucket name for cloud storage services like Google Cloud Storage, Alibaba Cloud OSS, or Azure Blob Storage in the respective Docker Compose configuration files.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n - \"hummock+<service_name>://<bucket-name>\"\n```\n\n----------------------------------------\n\nTITLE: Refreshing a Table Schema in RisingWave\nDESCRIPTION: SQL command for refreshing the schema of a table with connectors, which updates the table's structure based on the updated schema registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE src_user REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Including Commit Timestamp in RisingWave CDC Table (SQL)\nDESCRIPTION: This SQL snippet demonstrates how to create a RisingWave table (`mytable`) that ingests data from a PostgreSQL source (`pg_source`) table (`public.mytable`). It uses the `INCLUDE timestamp AS commit_ts` clause to add a column named `commit_ts` which stores the upstream commit timestamp. For historical data ingested during backfill, this timestamp defaults to '1970-01-01 00:00:00+00:00'. The example also includes a query and its result showing the populated `commit_ts` column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE mytable (v1 int PRIMARY KEY, v2 varchar)\nINCLUDE timestamp AS commit_ts\nFROM pg_source TABLE 'public.mytable';\n\nSELECT * FROM t2 ORDER BY v1;\n\n----RESULT\n v1 | v2 |         commit_ts\n----+----+---------------------------\n  1 | aa | 1970-01-01 00:00:00+00:00\n  2 | bb | 1970-01-01 00:00:00+00:00\n  3 | cc | 2024-05-20 09:01:08+00:00\n  4 | dd | 2024-05-20 09:01:08+00:00\n```\n\n----------------------------------------\n\nTITLE: WITH ORDINALITY Output Example\nDESCRIPTION: Shows the output format of using WITH ORDINALITY, displaying the unnested values in the first column and their ordinal positions in the second column named 'ordinality'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-ordinality-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n unnest | ordinality\n--------+------------\n      0 |          1\n      1 |          2\n      2 |          3\n```\n\n----------------------------------------\n\nTITLE: Altering Connection Schema with SQL\nDESCRIPTION: This SQL code demonstrates how to change the schema of a connection using the ALTER CONNECTION command and the SET SCHEMA clause. It requires ownership of the connection and CREATE privileges on the target schema. The main parameter is the connection_name (the connection to be altered) and the schema_name (the new schema). The statement updates the metadata to associate the connection with a different schema; no data is moved or lost. Attempting this without sufficient privileges will result in an error.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-connection.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER CONNECTION connection_name\n    SET SCHEMA schema_name;\n```\n\n----------------------------------------\n\nTITLE: Example of RisingWave Pods Status Output\nDESCRIPTION: Example output showing the status of all RisingWave-related pods when the cluster has started successfully, including component pods like compactor, compute, frontend, and meta.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nNAME                                   READY   STATUS    RESTARTS        AGE\nrisingwave-compactor-8dd799db6-hdjjz   1/1     Running   1 (8m33s ago)   11m\nrisingwave-compute-0                   2/2     Running   0               11m\nrisingwave-postgresql-0                1/1     Running   0               11m\nrisingwave-frontend-7bd7b8c856-czdgd   1/1     Running   1 (8m33s ago)   11m\nrisingwave-meta-0                      1/1     Running   0               11m\nrisingwave-minio-5cfd8f5f64-6msqm      1/1     Running   0               11m\n```\n\n----------------------------------------\n\nTITLE: Defining a Table with Indexes in dbt Using SQL\nDESCRIPTION: This snippet illustrates how to define a dbt-managed table in SQL with explicit index declarations for columns c1 and c2 using RisingWave syntax. It uses a config block to set materialization to 'table' and specifies indexes as a list of dictionaries. The snippet demonstrates table creation via UNION SELECT, and index creation requires proper dbt/RisingWave support for index-related configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n```sql Define a table with indexes in dbt\n{{ config(\n    materialized = 'table',\n    indexes=[\n      {'columns': ['c1']},\n      {'columns': ['c2', 'c1']},\n    ]\n)}}\nselect 1 as c1, 1 c2 union select 2 as c1, 2 as c2\n```\n```\n\n----------------------------------------\n\nTITLE: Filtering Grouped Data with HAVING Clause\nDESCRIPTION: This example computes the average salary per department per job title and filters the results to only include groups with an average salary of at least $50,000. It demonstrates practical usage of the HAVING clause to filter aggregated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/having-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- compute the average salary per department per job_title\n-- filtering the result set only to include the departments and job titles with an average salary of at least $50,000\nSELECT department, job_title, AVG(salary)\nFROM employees\nGROUP BY department, job_title\nHAVING AVG(salary) >= 50000;\n```\n\n----------------------------------------\n\nTITLE: Running Mintlify Development Server\nDESCRIPTION: Command to start the Mintlify development server at the root of the documentation where mint.json is located, allowing local preview of documentation changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmintlify dev\n```\n\n----------------------------------------\n\nTITLE: Inspecting Unbalanced Actor Distribution Output (bash)\nDESCRIPTION: This snippet is an example output from the previous SQL query revealing actor distribution imbalance across worker nodes. It lists worker node IDs and the respective counts of actors, highlighting scenarios where one node is underutilized. No computation occurs in this snippet—it's for interpretive context only and informs subsequent remedial actions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-a-large-number-of-streaming-jobs.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nworker_id|count|\n---------+-----+\n    12001|  720|\n    12002|23455|\n    12003|23300|\n```\n\n----------------------------------------\n\nTITLE: Querying Backfill Executor State\nDESCRIPTION: Checks the internal state of the backfill executor by querying the specific internal table identified in the previous step. This provides information about the backfill progress and CDC offset.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_t3_3_streamcdcscan_4;\n```\n\n----------------------------------------\n\nTITLE: Scale-in Commands\nDESCRIPTION: Bash commands for reducing the number of compute nodes in the cluster.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# If you are using risingwave-operator\nkubectl apply -f <file-with-less-replicas>.yaml # or kubectl edit RisingWave/<name>\n\n# If you are not using risingwave-operator\nkubectl scale statefulset/risingwave-compute --replicas=<number-of-replicas>\n```\n\n----------------------------------------\n\nTITLE: Binary String Example in RisingWave SQL\nDESCRIPTION: Example of bytea type using hex format for binary string representation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/overview.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n'\\xDe00BeEf'\n```\n\n----------------------------------------\n\nTITLE: Creating High-risk Users View in SQL\nDESCRIPTION: Creates a materialized view to identify high-risk users based on exposure levels, profit patterns, and risk tolerance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW high_risk_users AS\nSELECT\n    u.user_id,\n    u.username,\n    u.risk_tolerance,\n    p.total_exposure,\n    b.total_bets,\n    b.avg_profit_loss,\n    b.total_profit_loss\nFROM\n    user_profiles AS u\nJOIN\n    real_time_user_exposure AS p\nON\n    u.user_id = p.user_id\nJOIN\n    user_betting_patterns AS b\nON\n    u.user_id = b.user_id\nWHERE\n    p.total_exposure > u.avg_bet_size * 5\n    AND b.avg_profit_loss < 0;\n```\n\n----------------------------------------\n\nTITLE: Querying Iceberg Files from System Table\nDESCRIPTION: Query to retrieve all Iceberg files from the rw_iceberg_files system table, showing file paths, formats, and metadata.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_iceberg_files;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Join and Aggregation in RisingWave - SQL\nDESCRIPTION: These statements create two related materialized views: 'orders', which aggregates order items and prices using a join, and 'cust_sales', which computes sales per customer from orders. Dependencies include 'order_items' and 'price' tables. Joins and aggregations compute outputs such as 'total_price' and 'sales_amount'. This demonstrates building layered views with dependencies.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW orders AS\n    SELECT\n        order_id,\n        customer_id,\n        SUM(price * quantity) AS total_price\n    FROM order_items, price\n    WHERE order_items.product_id = price.product_id\n    GROUP BY order_id, customer_id;\n\nCREATE MATERIALIZED VIEW cust_sales AS\n    SELECT\n        customer_id,\n        SUM(total_price) AS sales_amount\n    FROM orders\n    GROUP BY customer_id;\n```\n\n----------------------------------------\n\nTITLE: Example of Modifying a Runtime Parameter using ALTER SYSTEM in RisingWave SQL\nDESCRIPTION: Provides a concrete example of using the `ALTER SYSTEM SET` command to modify a specific runtime parameter. This snippet demonstrates setting the `rw_streaming_enable_delta_join` parameter to `true`, thereby enabling the delta join feature in RisingWave's streaming engine.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-system.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET rw_streaming_enable_delta_join TO true;\n```\n\n----------------------------------------\n\nTITLE: Granting SELECT on a Materialized View with Delegation Example (SQL)\nDESCRIPTION: This example grants SELECT privilege on materialized view mv1 (located in schema1 of database db1) to user1, and allows user1 to grant the privilege to others using WITH GRANT OPTION and GRANTED BY. Demonstrates privilege delegation for a specific materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT SELECT\nON MATERIALIZED VIEW mv1 IN SCHEMA db1.schema1\nTO user1 WITH GRANT OPTION GRANTED BY user;\n```\n\n----------------------------------------\n\nTITLE: Creating User Profiles Table in SQL\nDESCRIPTION: Creates a table to store static user information including user ID, username, preferred league, average bet size, and risk tolerance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE user_profiles (\n    user_id INT,\n    username VARCHAR,\n    preferred_league VARCHAR,\n    avg_bet_size FLOAT,\n    risk_tolerance VARCHAR\n);\n```\n\n----------------------------------------\n\nTITLE: Creating A/B Test Variants Table in SQL\nDESCRIPTION: Creates a table to store details about A/B test variations for campaigns, including variant type and name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE ab_test_variants (\n    variant_id varchar PRIMARY KEY,\n    campaign_id varchar,\n    variant_name varchar,  -- A, B, Control\n    variant_type varchar,  -- subject_line, creative, landing_page\n    content_details varchar\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Secret in RisingWave for Webhook Authentication\nDESCRIPTION: Creates a secret in RisingWave to securely store a string used for validating incoming webhook requests from Amazon EventBridge.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/eventbridge-webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'TEST_WEBHOOK';\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Source in RisingWave with Java\nDESCRIPTION: Creates a source table named 'walk' using the 'datagen' connector to generate mock data. The source consists of two columns: 'distance' and 'duration', simulating data that might be tracked by smart watches.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/java.mdx#2025-04-23_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nimport java.sql.*;\nimport java.util.Properties;\n\npublic class source {\n\n    public static void main (String arg[]) throws SQLException {\n\n        //If necessary, add the code for connecting to RisingWave here.\n\n        String sqlQuery = \"CREATE TABLE walk (distance INT, duration INT) WITH \" +\n        \"(connector = 'datagen',\" +\n        \"fields.distance.kind = 'sequence',\" +\n        \"fields.distance.start = '1',\" +\n        \"fields.distance.end  = '60',\" +\n        \"fields.duration.kind = 'sequence',\" +\n        \"fields.duration.start = '1',\" +\n        \"fields.duration.end = '30',\" +\n        \"datagen.rows.per.second='15',\" +\n        \"datagen.split.num = '1') \" +\n        \"FORMAT PLAIN ENCODE JSON\";\n        PreparedStatement st = conn.prepareStatement(sqlQuery); //Define a query and pass it to a PreparedStatement object.\n        st.executeQuery(); //Execute the query.\n        conn.close();  //Close the connection.\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating JSON Path Predicates with jsonb_path_match\nDESCRIPTION: Function that evaluates JSON path predicates and returns a boolean result based on the first matching item.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_path_match('{\"employee\":{\"name\":\"John\",\"age\":30}}', 'exists($.employee.age ? (@ > 25))');\n```\n\n----------------------------------------\n\nTITLE: Changing Schema Owner With ALTER SCHEMA OWNER TO - SQL\nDESCRIPTION: Illustrates altering the ownership of a schema via the OWNER TO clause in an ALTER SCHEMA statement. The example changes the owner of a specified schema (here, \"schema1\") to a new user (\"user1\"). Required privileges include the ability to SET ROLE and CREATEDB, or superuser permissions. Input parameters are the schema name and the new user. On success, the schema will be owned by the specified user; misuse or lack of privileges will raise an error.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-schema.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SCHEMA current_schema_name\n    OWNER TO new_user;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the schema named \"schema1\" to user \"user1\"\nALTER SCHEMA schema1 OWNER TO user1;\n```\n\n----------------------------------------\n\nTITLE: Creating a Secret in RisingWave for GitHub Webhook Verification\nDESCRIPTION: Creates a secret in RisingWave to securely store a secret string used for validating incoming GitHub webhook requests.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/github-webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'TEST_WEBHOOK';\n```\n\n----------------------------------------\n\nTITLE: Querying Table Names and Types in SQL\nDESCRIPTION: SQL query to retrieve the names and types of all tables, views, and materialized views in the current database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/information-schema.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT table_name, table_type\nFROM information_schema.tables;\n```\n\n----------------------------------------\n\nTITLE: ASOF LEFT JOIN for Stock Prices and Sentiments - SQL\nDESCRIPTION: This snippet demonstrates an ASOF LEFT JOIN between stock prices and market sentiment data, ensuring that every stock price record is included in the output, with matching sentiment or NULLs where unavailable. It depends on the regular presence and structure of stock_prices and market_data tables and supports missing-data scenarios.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/joins.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sp.stock_name, sp.stock_time, sp.price, md.sentiment\nFROM stock_prices sp\nASOF LEFT JOIN market_data md \nON sp.stock_name = md.stock_name \nAND md.market_time <= sp.stock_time;\n```\n\n----------------------------------------\n\nTITLE: Creating a Delta Lake Table in Spark SQL\nDESCRIPTION: This command creates a Delta Lake table in AWS S3 using Spark SQL. It sets up necessary configurations for Spark and Delta Lake, including S3 access credentials and the table schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nspark-sql --packages io.delta:delta-core_2.12:2.2.0,org.apache.hadoop:hadoop-aws:3.3.2\\\n    --conf 'spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension' \\\n    --conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog' \\\n    --conf 'spark.hadoop.fs.s3a.access.key=${ACCESS_KEY}' \\\n    --conf 'spark.hadoop.fs.s3a.secret.key=${SECRET_KEY}' \\\n    --conf 'spark.hadoop.fs.s3a.endpoint=https://s3.ap-southeast-1.amazonaws.com' \\\n    --conf 'spark.hadoop.fs.s3a.path.style.access=true' \\\n    --e \"create table delta.\\`s3a://my-delta-lake-bucket/path/to/table\\`(id int, name string) using delta\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Database with Owner and Resource Group - SQL\nDESCRIPTION: This example demonstrates how to create a new database named 'travel' only if it does not exist. The statement assigns 'travel_admin' as the owner and allocates the database to the 'high_priority' resource group, leveraging Premium Edition features of RisingWave. This SQL statement requires the user to have the necessary privileges and, for resource group assignment, access to Premium Edition features. Outputs successful database creation or an error if the database exists (if IF NOT EXISTS is not supplied).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-database.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS travel\n    WITH OWNER = travel_admin\n    RESOURCE_GROUP = high_priority;\n```\n\n----------------------------------------\n\nTITLE: Creating a BigQuery Sink with Local JSON Key File\nDESCRIPTION: Example of creating a BigQuery sink using a local JSON key file for authentication. This snippet demonstrates how to configure the sink with specific parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/bigquery.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK big_query_sink_local\nFROM mv1\nWITH (\n    connector = 'bigquery',\n    type = 'append-only',\n    bigquery.local.path= '${bigquery_service_account_json_path}',\n    bigquery.project= '${project_id}',\n    bigquery.dataset= '${dataset_id}',\n    bigquery.table= '${table_id}',\n    force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE SET SOURCE_RATE_LIMIT Syntax in RisingWave SQL\nDESCRIPTION: This command controls the rate limit of the source associated with a table that has a connector. It can be set to 'default' or a specific numeric value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\n    SET SOURCE_RATE_LIMIT { TO | = } { default | rate_limit_number };\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only Sink from Upsert Table in RisingWave\nDESCRIPTION: This SQL command creates an append-only sink in RisingWave to transfer data from an upsert table to Delta Lake. It uses the 'force_append_only' parameter to ensure append-only behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1_sink FROM s1_table\nWITH (\n    connector = 'deltalake',\n    type = 'append-only',\n    force_append_only = 'true',\n    location = 's3a://my-delta-lake-bucket/path/to/table',\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY}'\n);\n```\n\n----------------------------------------\n\nTITLE: Refreshing Source Schema with REFRESH SCHEMA Clause\nDESCRIPTION: SQL command for refreshing a source's schema using the REFRESH SCHEMA clause, which can be used when the FORMAT and ENCODE options remain unchanged.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Defining Connection Syntax in SQL\nDESCRIPTION: General syntax for the `CREATE CONNECTION` command in RisingWave SQL. It allows creating a named, reusable connection configuration with specified parameters. The `IF NOT EXISTS` clause prevents errors if the connection already exists. Sensitive parameters can be managed using the `SECRET` keyword.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-connection.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION [ IF NOT EXISTS ] connection_name\nWITH (\n    type = '<connector_type>',\n    connection_parameter = SECRET `<secret_name>`,\n    ...\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Up Bidding Data Source for Ad Tech in SQL\nDESCRIPTION: This snippet creates a source to ingest real-time bidding data from Kafka for ad tech feature engineering. It includes fields for bid details, success metrics, and timestamps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE bidding_data (\n  ad_id varchar,\n  bid_amount double precision,\n  bid_count integer,\n  bid_won boolean,\n  response_time interval,\n  event_time timestamptz\n) WITH (\n  connector='kafka',\n  topic='bidding_data',\n  properties.bootstrap.server='localhost:9092',\n  scan.startup.mode='earliest',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Automatically Mapping MySQL Table Schema to RisingWave\nDESCRIPTION: Creates a RisingWave table that automatically maps the entire schema from an upstream MySQL table. This feature uses the '*' wildcard to ingest all columns without specifying them individually.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE supplier (*) FROM mysql_source TABLE 'public.supplier';\n```\n\n----------------------------------------\n\nTITLE: Configuring Storage Catalog for Iceberg Sink\nDESCRIPTION: Example SQL command for creating an Iceberg sink using the Storage catalog which stores metadata in the underlying file system. This example demonstrates configuration with S3 as the file system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_demo_storage FROM t\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = true,\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    catalog.type = 'storage',\n    catalog.name = 'demo',\n    warehouse.path = 's3://icebergdata/demo',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Adaptive Parallelism for Materialized View\nDESCRIPTION: SQL command to modify a materialized view's scaling policy to adaptive parallelism.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW mv SET PARALLELISM = adaptive;\n```\n\n----------------------------------------\n\nTITLE: Unnesting an Array into Separate Rows\nDESCRIPTION: Demonstrates the use of the unnest() function to spread array values into separate rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT unnest(array[1,2,3,4]);\n```\n\n----------------------------------------\n\nTITLE: Creating Database Users with SQL Commands in RisingWave\nDESCRIPTION: Use the CREATE USER SQL command to create a new database user after connecting to a RisingWave project. This requires having the CREATEUSER privilege or being a super user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/create-a-database-user.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL RDS Instance\nDESCRIPTION: Command to connect to a PostgreSQL RDS instance using psql. It requires the endpoint, port, and login credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npsql --host = pg-to-rw.xxxxxx.us-east-1.rds.amazonaws.com --port=5432 --username=awsuser --password\n```\n\n----------------------------------------\n\nTITLE: Checking SQL Server Agent Status in SQL Server (SQL)\nDESCRIPTION: This SQL query checks the status of the SQL Server Agent service, which is required by the RisingWave SQL Server CDC connector. It queries the `sys.dm_server_services` dynamic management view. The expected output for a running agent is `RUNNING` in the `status_desc` column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT status_desc FROM sys.dm_server_services WHERE servicename LIKE 'SQL Server Agent%';\n```\n\n----------------------------------------\n\nTITLE: Analyzing Hummock SSTable Distribution by Compaction Level in SQL\nDESCRIPTION: This SQL query aggregates information about SSTables within the Hummock storage system, grouping them by compaction group, level type, level ID, and sub-level ID. It calculates the total count of files and the total file size (in KB) for each group, ordered to provide a clear view of data distribution across different compaction levels. This analysis helps diagnose compaction performance issues, such as write stalls, by revealing potential imbalances or excessive data in specific levels.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/specific-bottlenecks.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT compaction_group_id,\n       level_id,\n       level_type,\n       sub_level_id,\n       count(*)                       AS total_file_count,\n       round(Sum(file_size) / 1024.0) AS total_file_size_kb\nFROM   rw_catalog.rw_hummock_sstables\nGROUP  BY compaction_group_id,\n          level_type,\n          level_id,\n          sub_level_id\nORDER  BY compaction_group_id,\n          level_id,\n          sub_level_id DESC;\n```\n\n----------------------------------------\n\nTITLE: Creating Table for SINK INTO TABLE with Primary Key and Conflict Resolution in RisingWave - SQL\nDESCRIPTION: This snippet creates the storage table (m1_store) with a primary key for use with SINK INTO TABLE and enables ON CONFLICT OVERWRITE logic, necessary for in-place modifications. Assumes downstream SINK jobs will stream into this table. The schema includes a dummy key column, as required by SINK INTO TABLE.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE m1_store(key int primary key, cnt int) ON CONFLICT OVERWRITE; \n-- SINK INTO TABLE requires a primary key, so we add a dummy column.\n-- The ON CONFLICT clause will handle conflicts between old and updated records from new streaming job.\n```\n\n----------------------------------------\n\nTITLE: Example Output of SHOW PROCESSLIST in RisingWave\nDESCRIPTION: Example showing the output of the SHOW PROCESSLIST command, which displays all active processes in the RisingWave system including connection details and currently executing SQL statements.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-processlist.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW PROCESSLIST;\n------RESULT\nId   | User |      Host       | Database | Time |                 Info\n-------+------+-----------------+----------+------+---------------------------------------\n 56 | root | 127.0.0.1:57542 | dev      | 6ms  | SELECT c FROM sbtest1 WHERE id=197719\n 57 | root | 127.0.0.1:57545 | dev      |      |\n 64 | root | 127.0.0.1:57552 | dev      |      |\n 67 | root | 127.0.0.1:57554 | dev      |      |\n 52 | root | 127.0.0.1:57540 | dev      | 0ms  | SELECT c FROM sbtest1 WHERE id=961513\n 16 | root | 127.0.0.1:57054 | dev      | 0ms  | show processlist;\n 58 | root | 127.0.0.1:57546 | dev      |      |\n 54 | root | 127.0.0.1:57543 | dev      | 3ms  | SELECT c FROM sbtest1 WHERE id=99465\n 55 | root | 127.0.0.1:57544 | dev      | 1ms  | SELECT c FROM sbtest1 WHERE id=601879\n 53 | root | 127.0.0.1:57541 | dev      |      |\n 65 | root | 127.0.0.1:57553 | dev      | 0ms  | SELECT c FROM sbtest1 WHERE id=547609\n 61 | root | 127.0.0.1:57549 | dev      | 2ms  | SELECT c FROM sbtest1 WHERE id=394922\n 60 | root | 127.0.0.1:57548 | dev      | 4ms  | SELECT c FROM sbtest1 WHERE id=453909\n 63 | root | 127.0.0.1:57551 | dev      | 0ms  | SELECT c FROM sbtest1 WHERE id=190594\n 62 | root | 127.0.0.1:57550 | dev      | 0ms  | SELECT c FROM sbtest1 WHERE id=128925\n 66 | root | 127.0.0.1:57555 | dev      |      |\n 59 | root | 127.0.0.1:57547 | dev      | 0ms  | SELECT c FROM sbtest1 WHERE id=772039\n(17 rows)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Schema Name in SQL\nDESCRIPTION: The current_schema function returns the current schema. This is the schema that will be used for creating tables or other named objects without specifying a target schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncurrent_schema → *current_schema_name*\ncurrent_schema() → *current_schema_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT current_schema(); → 'public'\n```\n\n----------------------------------------\n\nTITLE: Querying Demand Forecast in SQL\nDESCRIPTION: Retrieves the first 5 rows from the demand_forecast materialized view to display predicted stock duration based on current inventory and recent sales.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM demand_forecast LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with JSONB Columns in SQL\nDESCRIPTION: These SQL statements demonstrate how to create tables with JSONB columns. The examples include creating a simple table with a JSONB column, as well as a more complex table structure for a product catalog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/jsonb.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE x (j_data JSONB, d INTEGER);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE y (id VARCHAR, metadata JSONB);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE product (\n        name VARCHAR,\n        price NUMERIC,\n        attributes JSONB\n        );\n```\n\n----------------------------------------\n\nTITLE: Creating Subscription in RisingWave Using SQL\nDESCRIPTION: This snippet demonstrates the SQL syntax for creating a subscription tied to a specific table or materialized view in RisingWave. It uses a mandatory FROM clause to specify the data source and a retention parameter for specifying the duration incremental data should be kept. The statement is a prerequisite for using subscriptions and their associated cursors; it requires connection to a RisingWave SQL endpoint and permissions for subscription management.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SUBSCRIPTION <subscription_name> FROM <table_or_mv_name> WITH (\nretention = '<duration>'\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Windowed CTR Data in RisingWave\nDESCRIPTION: A simple SQL query to retrieve all records from the 'ad_ctr_5min' materialized view, showing the ad ID, CTR value, and the end timestamp of each 5-minute window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ad_ctr_5min;\n```\n\n----------------------------------------\n\nTITLE: Querying Column Names for a Specific Table in SQL\nDESCRIPTION: SQL query to retrieve all column names from a specific table, sink, view, or materialized view named 'taxi_trip'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/information-schema.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column_name\nFROM information_schema.columns\nWHERE table_name='taxi_trip';\n```\n\n----------------------------------------\n\nTITLE: Querying Feature Vectors for Ad Bidding Prediction in SQL\nDESCRIPTION: This snippet demonstrates how to query the bidding_feature_vectors materialized view to retrieve feature data for a specific ad, which can be used as input for bid price prediction models.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM bidding_feature_vectors WHERE ad_id = 'specific_ad_id';\n```\n\n----------------------------------------\n\nTITLE: Sample Output of SELECT from taxi_trips (SQL)\nDESCRIPTION: Displays the sample output after executing `SELECT * FROM taxi_trips;`, showing the initial state of the table containing three rows with columns `id`, `distance`, and `city`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n id | distance |    city\n----+----------+-------------\n  1 |       16 | Yerba Buena\n  2 |       23 | New York\n  3 |        6 | Chicago\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Connecting and Logging In as a User - psql Bash Command\nDESCRIPTION: This bash command shows how to connect to a RisingWave instance as a specific user using the psql client. The example connects to localhost on port 4566, database 'dev', as user 'user1'. Input parameters specify the host, port, database, and username. The command prompts for a password or authentication token as appropriate.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U user1\n\n```\n\n----------------------------------------\n\nTITLE: Decrypting Data Using AES in SQL\nDESCRIPTION: Shows how to decrypt previously encrypted data using the decrypt function with the same parameters used for encryption (AES algorithm, CBC mode, PKCS padding).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT decrypt('\\x9cf6a49f90b3ac816aeeeed286606fdb','my_secret_key111', 'aes-cbc/pad:pkcs');)\n----RESULT\n\\x48656c6c6f2c20576f726c6421\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Dropping a Function by Name Only in SQL\nDESCRIPTION: Shows how to drop a user-defined function using only its name. This approach works only if the function name is unique within its schema; otherwise, an error occurs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION function_name;\n```\n\n----------------------------------------\n\nTITLE: Building Rust UDFs into WebAssembly Module\nDESCRIPTION: These Bash commands demonstrate how to build Rust UDFs into a WebAssembly module and optionally strip the binary to reduce its size.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncargo build --release --target wasm32-wasip1\n\n# Optional: Strip the binary\ncargo install wasm-tools\nwasm-tools strip ./target/wasm32-wasip1/release/udf.wasm > udf.wasm\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave via Docker (Shell Bash)\nDESCRIPTION: This shell command runs the RisingWave v1.2.0 playground in an interactive Docker container, automatically pulling the latest image, mapping required ports for service access. It assumes Docker is installed and your network allows pulling from DockerHub. The main parameters are the ports and image version, with the resulting output being an interactive RisingWave instance available on ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.2.0 playground\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View with Changelog Results in SQL\nDESCRIPTION: Illustrates how to query the materialized view 'ss_mv' to observe the impact of various changelog DML operations, including the resulting changelog_op values. This step is typically performed after changes have been made to the source table, revealing how operations are materialized as rows in the view. The input is a standard SELECT statement without parameters; the output is a tabular result reflecting the historical changelog (example result provided as a comment).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-as-changelog.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ss_mv;\n\n-------RESULT\nv1  v2  changelog_op\n1   1   1\n2   2   1\n2   2   2\n1   1   4\n1   100 3\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source in RisingWave\nDESCRIPTION: SQL query to create a source in RisingWave that reads data from a Kafka broker. It defines the schema and connection properties for the source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE user_behaviors (\n    user_id VARCHAR,\n    target_id VARCHAR,\n    target_type VARCHAR,\n    event_timestamp TIMESTAMPTZ,\n    behavior_type VARCHAR,\n    parent_target_type VARCHAR,\n    parent_target_id VARCHAR\n) WITH (\n    connector = 'kafka',\n    topic = 'user_behaviors',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Redis Sink with Template Encoding\nDESCRIPTION: Example of creating a Redis sink named 'redis_sink_2' using template-based encoding. It defines custom formats for both keys and values using column values from the materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/redis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK redis_sink_2\nFROM bhv_mv WITH (\n    primary_key = 'user_id',\n    connector = 'redis',\n    redis.url= 'redis://127.0.0.1:6379/',\n) FORMAT PLAIN ENCODE TEMPLATE (\n    force_append_only='true',\n    key_format = 'UserID:{user_id}',\n    value_format = 'TargetID:{target_id},EventTimestamp{event_timestamp}'\n);\n```\n\n----------------------------------------\n\nTITLE: Upgrading RisingWave with Helm\nDESCRIPTION: Commands to upgrade RisingWave to either the latest version or a specific version.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhelm upgrade --reuse-values my-risingwave risingwavelabs/risingwave\n```\n\nLANGUAGE: bash\nCODE:\n```\nhelm upgrade --set image.tag={risingwave-version} \\\n  -f values.yaml \\\n  --reuse-values \\\n  --version {chart-version} \\\n  my-risingwave risingwavelabs/risingwave\n```\n\n----------------------------------------\n\nTITLE: Configuring Source Parallelism in RisingWave SQL\nDESCRIPTION: These statements are used to set or adjust the parallelism degree for a shared source, specifying either 'ADAPTIVE' or a fixed number. Available since version 2.3, setting parallelism increases or limits the number of workers for streaming jobs on the source. Requires the source to be a shared source, and setting to 0 is equivalent to ADAPTIVE.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name\nSET PARALLELISM { TO | = } parallelism_number;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE s_kafka SET PARALLELISM = 2;\n```\n\n----------------------------------------\n\nTITLE: Declaring WebAssembly UDFs in RisingWave SQL\nDESCRIPTION: These SQL commands show how to declare UDFs in RisingWave using a WebAssembly module, either by embedding the binary or loading from the file system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\\set wasm_binary `base64 -i path/to/udf.wasm`\nCREATE FUNCTION gcd(int, int) RETURNS int LANGUAGE wasm USING BASE64 :'wasm_binary';\n\n-- Alternatively, load from file system\nCREATE FUNCTION gcd(int, int) RETURNS int LANGUAGE wasm USING LINK 'fs:///path/to/udf.wasm';\n```\n\n----------------------------------------\n\nTITLE: Setting Sink Rate Limit using ALTER SINK in SQL\nDESCRIPTION: Explains how to modify the rate limit for a sink using the `SET SINK_RATE_LIMIT` clause. The limit can be set to `default` or a specific `rate_limit_number` (rows per second).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\n    SET SINK_RATE_LIMIT { TO | = } { default | rate_limit_number };\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Alter the rate limit of a sink to default\nALTER SINK s1 SET SINK_RATE_LIMIT = default;\n\n-- Alter the rate limit of a sink to 1000\nALTER SINK s1 SET SINK_RATE_LIMIT = 1000;\n```\n\n----------------------------------------\n\nTITLE: Sample CTR Query Results in RisingWave\nDESCRIPTION: Example output from querying the ad_ctr_5min materialized view, showing CTR values for different ads across multiple 5-minute time windows. The results display ad IDs, calculated CTR values, and window end timestamps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n ad_id |              ctr               |        window_end\n-------+--------------------------------+---------------------------\n     1 | 0.8823529411764705882352941176 | 2022-05-24 06:25:00+00:00\n     1 | 0.8793103448275862068965517241 | 2022-05-24 06:30:00+00:00\n     1 | 0.880597014925373134328358209  | 2022-05-24 06:35:00+00:00\n     1 | 0.8285714285714285714285714286 | 2022-05-24 06:40:00+00:00\n     2 | 0.3636363636363636363636363636 | 2022-05-24 06:25:00+00:00\n     2 | 0.4464285714285714285714285714 | 2022-05-24 06:30:00+00:00\n     2 | 0.5918367346938775510204081633 | 2022-05-24 06:35:00+00:00\n     2 | 0.5806451612903225806451612903 | 2022-05-24 06:40:00+00:00\n     3 | 0.0975609756097560975609756098 | 2022-05-24 06:30:00+00:00\n     3 | 0.0983606557377049180327868852 | 2022-05-24 06:35:00+00:00\n     3 | 0.0789473684210526315789473684 | 2022-05-24 06:40:00+00:00\n     3 | 0.1129032258064516129032258065 | 2022-05-24 06:45:00+00:00\n     4 | 0.4166666666666666666666666667 | 2022-05-24 06:25:00+00:00\n     4 | 0.2881355932203389830508474576 | 2022-05-24 06:30:00+00:00\n     4 | 0.3181818181818181818181818182 | 2022-05-24 06:35:00+00:00\n     4 | 0.3076923076923076923076923077 | 2022-05-24 06:40:00+00:00\n```\n\n----------------------------------------\n\nTITLE: Calling SQL UDFs with Input Value Adjustment\nDESCRIPTION: This snippet shows how to call the previously created print_add_one and print_add_two functions with specific integer arguments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nselect print_add_one(1), print_add_one(114513), print_add_two(2);\n----RESULT\n2 114514 4\n```\n\n----------------------------------------\n\nTITLE: Altering a Secret Example in SQL\nDESCRIPTION: Provides a concrete example of altering a secret named 'mysql_pwd' and updating its value to 'new_password' using the ALTER SECRET command in RisingWave. Assumes the existing 'mysql_pwd' secret exists and user has appropriate privileges. The only supported backend is 'meta'. Input values are the secret name and new secret data. The updated secret is stored securely in the backend, but active jobs will only see the change after a restart.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-secret.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SECRET mysql_pwd WITH (\n    backend = 'meta' \n) AS 'new_password';\n```\n\n----------------------------------------\n\nTITLE: VALUES Clause Syntax in RisingWave SQL\nDESCRIPTION: Demonstrates the basic syntax of the VALUES clause for generating one or more rows of data as a table expression in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/values-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nVALUES (expression1, expression2, ...),\n       (expression1, expression2, ...),\n       ...\n```\n\n----------------------------------------\n\nTITLE: Example Execution Plan Output for a SELECT Statement (Batch)\nDESCRIPTION: Shows a sample execution plan generated by `EXPLAIN` for a batch query (likely the preceding `SELECT` example). This output details the sequence of operations (like BatchScan, BatchFilter, BatchHashJoin, BatchSort, BatchExchange) RisingWave performs, showing data flow and processing steps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-explain.mdx#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n BatchExchange { order: [orders.o_orderpriority ASC], dist: Single }\n   BatchSort { order: [orders.o_orderpriority ASC] }\n     BatchHashAgg { group_key: [orders.o_orderpriority], aggs: [count] }\n       BatchExchange { order: [], dist: HashShard(orders.o_orderpriority) }\n         BatchHashJoin { type: LeftSemi, predicate: orders.o_orderkey = lineitem.l_orderkey }\n           BatchExchange { order: [], dist: HashShard(orders.o_orderkey) }\n             BatchProject { exprs: [orders.o_orderkey, orders.o_orderpriority] }\n               BatchFilter { predicate: (orders.o_orderdate >= '1997-07-01':Varchar::Date) AND (orders.o_orderdate < ('1997-07-01':Varchar::Date + '3 mons 00:00:00':Interval)) }\n                 BatchScan { table: orders, columns: [o_orderkey, o_orderpriority, o_orderdate] }\n           BatchExchange { order: [], dist: HashShard(lineitem.l_orderkey) }\n             BatchProject { exprs: [lineitem.l_orderkey] }\n               BatchFilter { predicate: (lineitem.l_commitdate < lineitem.l_receiptdate) }\n                 BatchScan { table: lineitem, columns: [l_orderkey, l_commitdate, l_receiptdate] }\n(13 rows)\n```\n\n----------------------------------------\n\nTITLE: Starting UDF Server\nDESCRIPTION: Implementation of the UDF server initialization and function registration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nimport com.risingwave.functions.UdfServer;\n\npublic class App {\n    public static void main(String[] args) {\n        try (var server = new UdfServer(\"0.0.0.0\", 8815)) {\n            // Register functions\n            server.addFunction(\"gcd\", new Gcd());\n            server.addFunction(\"series\", new Series());\n            // Start the server\n            server.start();\n            server.awaitTermination();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example: Swapping Materialized View Names in SQL\nDESCRIPTION: Demonstrates how to swap the names of the materialized views `sales_summary` and `sales_archive`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n-- Swap the names of the sales_summary materialized view and the sales_archive materialized view.\nALTER MATERIALIZED VIEW sales_summary\nSWAP WITH sales_archive;\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Connection with Rest Catalog in SQL\nDESCRIPTION: This SQL snippet demonstrates creating an Iceberg connection using a Rest catalog. It specifies the catalog URI, warehouse path, S3 endpoint, region, and credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION public.conn WITH (\n    type = 'iceberg',\n    catalog.type='rest',\n    catalog.uri= 'http://localhost:8181/catalog',\n    warehouse.path = 'test',\n    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',\n    s3.region = 'ap-southeast-2'\n    s3.access.key = <access_key_id>,\n    s3.secret.key = <secret_key>,\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Index Example in SQL\nDESCRIPTION: Example showing how to create a table 't3' with three integer columns and an index 'idx1' on columns v1 and v2.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS t3 (\n    v1 int,\n    v2 int,\n    v3 int);\n\nCREATE INDEX idx1 ON t3 (v1,v2);\n```\n\n----------------------------------------\n\nTITLE: CORRESPONDING Example Queries\nDESCRIPTION: Demonstrates two examples of using CORRESPONDING with UNION - one without specifying columns and one with explicit column matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, name, age, gender\nFROM employees\nUNION CORRESPONDING\nSELECT id, name, salary, gender\nFROM managers;\n\nSELECT id, name, age, gender\nFROM employees\nUNION CORRESPONDING BY (id, name)\nSELECT id, name, salary, gender\nFROM managers;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave\nDESCRIPTION: SQL command for creating a materialized view that selects all columns from a Kafka source. Note that the view won't automatically pick up new columns added to the source later.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv1 AS SELECT * FROM my_kafka_source;\n```\n\n----------------------------------------\n\nTITLE: Example of Creating a WebHDFS Sink in SQL\nDESCRIPTION: This example shows how to create a WebHDFS sink named 'webhdfs_sink'. It selects data from a table 't1', specifies the WebHDFS path and endpoint, and uses Parquet encoding with forced append-only mode.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/webhdfs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK webhdfs_sink AS SELECT v1\nFROM t1\nWITH (\n    connector='webhdfs',\n    webhdfs.path = '<test_path>',\n    webhdfs.endpoint = '<test_endpoint>',\n    type = 'append-only',\n)FORMAT PLAIN ENCODE PARQUET(force_append_only=true);\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Client on Fedora\nDESCRIPTION: Installs only the PostgreSQL client package on Fedora systems using DNF, which includes psql without the server components.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsudo dnf install postgresql.x86_64\n```\n\n----------------------------------------\n\nTITLE: Using START TRANSACTION Command Syntax in RisingWave\nDESCRIPTION: The basic syntax for the START TRANSACTION command. Note that in RisingWave, this command starts a transaction in read-only mode with the READ ONLY option.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-start-transaction.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION;\n```\n\n----------------------------------------\n\nTITLE: Setting Reserved Memory via Environment Variable or Command Line (Bash)\nDESCRIPTION: Demonstrates how to override the default calculated reserved memory for a RisingWave compute node by setting an environment variable (`RW_RESERVED_MEMORY_BYTES`) or using a command-line argument (`--reserved-memory-bytes`). This example sets the reserved memory to 8GB (8589934592 bytes). The minimum allowed value is 512MB.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/tune-reserved-memory.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nRW_RESERVED_MEMORY_BYTES=8589934592\n```\n\nLANGUAGE: bash\nCODE:\n```\n--reserved-memory-bytes=8589934592\n```\n\n----------------------------------------\n\nTITLE: Using QUOTE_LITERAL Function with Text Input in SQL\nDESCRIPTION: The quote_literal() function returns the given string properly quoted, so that it can be safely used as a string literal in an SQL statement. This involves doubling any embedded single-quotes and backslashes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nquote_literal(string text) → text\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT quote_literal(E'O\\'Reilly');\n----RESULT\n'O''Reilly'\n\nSELECT quote_literal(E'C:\\\\Windows\\\\');\n----RESULT\nE'C:\\\\Windows\\\\'\n```\n\n----------------------------------------\n\nTITLE: Querying Iceberg System Tables in RisingWave\nDESCRIPTION: SQL queries for accessing Iceberg metadata through system tables in RisingWave. These tables provide information about data files and snapshots in Iceberg tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg-config.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Query Iceberg data files\nSELECT * FROM rw_iceberg_files;\n\n-- Query Iceberg snapshots\nSELECT * FROM rw_iceberg_snapshots;\n```\n\n----------------------------------------\n\nTITLE: Setting Protobuf Format in RisingWave SQL\nDESCRIPTION: Configures the format and encoding for consuming Protobuf data. Requires specifying a message and schema location or Confluent Schema Registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT PLAIN\nENCODE PROTOBUF (\n   message = 'com.example.MyMessage',\n   schema.location = 'location' | schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Redis Sink with JSON Encoding\nDESCRIPTION: Example of creating a Redis sink named 'redis_sink' from the materialized view 'bhv_mv' with JSON encoding. It uses 'user_id' as the primary key and connects to a local Redis instance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/redis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK redis_sink\nFROM bhv_mv WITH (\n    connector = 'redis',\n    primary_key = 'user_id',\n    redis.url= 'redis://127.0.0.1:6379/'\n) FORMAT PLAIN ENCODE JSON (\n    force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: Using lead() Window Function in SQL\nDESCRIPTION: The lead() function is similar to lag(), but it allows you to access the value of a subsequent row in the result set.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nlead ( value anycompatible [, offset const integer] ) → anycompatible\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    col1, col2,\n    lead(col2) OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as lead\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using LoadBalancer in Kubernetes\nDESCRIPTION: These commands set up environment variables and connect to RisingWave using psql when the service type is LoadBalancer. It retrieves the necessary host and port information from the load balancer created by the cloud provider.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nexport RISINGWAVE_NAME=risingwave-postgresql-hdfs\nexport RISINGWAVE_NAMESPACE=default\nexport RISINGWAVE_HOST=`kubectl -n ${RISINGWAVE_NAMESPACE} get svc -l risingwave/name=${RISINGWAVE_NAME},risingwave/component=frontend -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}'`\nexport RISINGWAVE_PORT=`kubectl -n ${RISINGWAVE_NAMESPACE} get svc -l risingwave/name=${RISINGWAVE_NAME},risingwave/component=frontend -o jsonpath='{.items[0].spec.ports[0].port}'`\npsql -h ${RISINGWAVE_HOST} -p ${RISINGWAVE_PORT} -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Reading GCS Parquet Files with file_scan Function in SQL\nDESCRIPTION: This signature outlines the `file_scan` table function in RisingWave SQL, specifically for reading Parquet files directly from Google Cloud Storage. It requires specifying the format (`parquet`), connector type (`gcs`), GCS credentials, service account information, and the file location (either a single file path or a directory path within the GCS bucket). Note that when reading a directory, the schema is inferred from the first file listed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nfile_scan (parquet, gcs, credential, service_account, file_location)\n```\n\n----------------------------------------\n\nTITLE: Solution to avoid naming conflicts with SQL built-ins\nDESCRIPTION: Example demonstrating how to qualify column names with table names to avoid conflicts with built-in functions in RisingWave SQL queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/identifiers.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT t.user, avatar FROM t; -- Qualify it with `t.` to select the column rather than the builtin.\n```\n\n----------------------------------------\n\nTITLE: Continuous Timestamp Generation in Materialized View\nDESCRIPTION: Advanced usage showing how to create a materialized view that continuously generates timestamps using now() as the stop parameter\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv AS\nSELECT * FROM generate_series(\n  '2020-01-01 00:00:00'::timestamptz,\n  now(),\n  interval '1 hour'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Debezium JSON Format in RisingWave\nDESCRIPTION: SQL syntax for configuring Debezium JSON format in RisingWave. Allows direct referencing of JSON payload fields in the schema definition, with options to ignore key parts of messages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT DEBEZIUM\nENCODE JSON [ (\n   [ ignore_key = 'true | false ' ]\n) ]\n```\n\n----------------------------------------\n\nTITLE: Creating a Non-Materialized View with RisingWave SQL\nDESCRIPTION: Demonstrates the SQL syntax for defining a non-materialized view using CREATE VIEW. This command allows you to specify a view's name, optional column list, and a SELECT query for data retrieval. It requires an existing table or source as input, and the resultant view is recreated each time it is queried. This snippet is useful for setting up reusable query definitions and does not store actual data; instead, it computes on demand.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-view.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE VIEW [IF NOT EXISTS] view_name [ ( column_name [, ...] ) ] AS select_query;\n```\n\n----------------------------------------\n\nTITLE: Declaring Functions in RisingWave\nDESCRIPTION: SQL commands to declare the UDFs in RisingWave system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION gcd(int, int) RETURNS int\nAS gcd\nUSING LINK 'http://localhost:8815';\n\nCREATE FUNCTION series(int) RETURNS TABLE (x int)\nAS series\nUSING LINK 'http://localhost:8815';\n```\n\n----------------------------------------\n\nTITLE: Valid SQL Temporal Filter with AND Operator\nDESCRIPTION: Shows a valid SQL example where multiple temporal filters and other conditions are combined using the AND operator within a WHERE clause. This allows defining a specific time window.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Valid\nt > NOW() - INTERVAL '1 hour' AND t < NOW() + INTERVAL '1 hour' AND a < 1\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Connection with Amazon S3 Tables in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create an Iceberg connection using Amazon S3 Tables as the catalog. It includes AWS credentials and S3 Tables specific configurations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE CONNECTION my_s3_tables_conn\nWITH (\n    type = 'iceberg',\n    warehouse.path = 'arn:aws:s3tables:<your-region>:<your-account-id>:bucket/<your-bucket-name>',\n    s3.access.key = '<your-aws-access-key-id>',\n    s3.secret.key = '<your-aws-secret-access-key>',\n    s3.region = '<your-region>',\n    catalog.uri = 'https://s3tables.<your-region>.amazonaws.com/iceberg',\n    catalog.rest.signing_region = '<your-region>',\n    catalog.rest.sigv4_enabled = true,\n    catalog.rest.signing_name = 's3tables',\n    catalog.type = 'rest'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Databases with Resource Groups in RisingWave (SQL)\nDESCRIPTION: Creates a new database in RisingWave and assigns it to a specific resource group using the WITH RESOURCE_GROUP clause. Requires that the named resource group already exists in the cluster. Key parameters include the new database name and the target resource group name. The input is a SQL statement; the database is created in RisingWave and constrained to use the compute nodes of the specified resource group. Omitting the resource group assigns the database to a default group.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE database_name\nWITH resource_group = 'resource_group_name';\n```\n\n----------------------------------------\n\nTITLE: Creating Additional CDC Table from Different Source Schema in RisingWave - SQL\nDESCRIPTION: This SQL statement defines a CDC table 'tt4' in RisingWave, sourcing change data from the upstream SQL Server table 'tt4' in schema 'ods'. It illustrates multi-schema ingestion from a single CDC source connection. Requires that the source 'mssql_mydb' has been created and that 'ods.tt4' exists upstream. Defines primary key and value columns, allowing independent ingestion without redefining connection parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tt4 (\n  v1 integer primary key,\n  v2 varchar,\n  PRIMARY KEY (v1)\n) FROM mssql_mydb TABLE 'ods.tt4';\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using Node.js pg Pool\nDESCRIPTION: Establishes a connection to RisingWave using a connection pool and executes a basic test query.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/nodejs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Pool } = require('pg')\n\nconst credentials = {\n  user: 'root',\n  host: '127.0.0.1',\n  database: 'dev',\n  password: 'secret',\n  port: 4566,\n}\n \nconst start = async () => {\n    const pool = new Pool(credentials);\n    const res = await pool.query(\"SELECT 1+2\"); /*A basic query to ensure the connection is successful. \n    Replace it with your own query. */\n    console.log(res); //Print out the results.\n    await pool.end();\n}\n\nstart().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Checking Internal State of Backfill Executor\nDESCRIPTION: Query to check the internal state of the backfill executor including progress and CDC offset information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_t3_3_streamcdcscan_4;\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only Sink to Apache Doris\nDESCRIPTION: Example of creating an append-only sink from RisingWave to Apache Doris. This configuration specifies the connection details and sets the sink type to append-only, which adds new records without updating existing ones.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-doris.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK doris_sink FROM mv1\nWITH (\n    connector = 'doris',\n    type = 'append-only',\n    doris.url = 'http://fe:8030',\n    doris.user = 'xxxx',\n    doris.password = 'xxxx',\n    doris.database = 'demo',\n    doris.table='demo_bhv_table',\n    force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: Resuming Cluster with RiseCTL Command\nDESCRIPTION: This command uses the 'risectl' tool to resume the cluster after addressing issues during recovery failure.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/troubleshoot/troubleshoot-recovery-failure.mdx#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nrisectl meta resume\n```\n\n----------------------------------------\n\nTITLE: Viewing Kafka Topic Data using Command-line Tools\nDESCRIPTION: Command to view the recently written data in the Kafka topic 'example_topic'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsh kafka-console-consumer.sh --bootstrap-server 10.0.96.4:9092 --topic example_topic --from-beginning\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: Command to connect to the RisingWave database using the PostgreSQL CLI tool (psql). This connection is used to manage data streams and perform data analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Creating SQL Server CDC Source in RisingWave - SQL\nDESCRIPTION: This snippet sets up an upstream SQL Server CDC source connector in RisingWave by specifying the connector type, connection credentials, and the target database name. Required dependencies are network access to the SQL Server instance and enabled CDC on the source. Mandatory parameters include 'connector', 'hostname', 'port', 'username', 'password', and 'database.name'. The source may be used by multiple CDC tables, and the internal format is fixed as JSON, so format specification is omitted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE mssql_mydb WITH (\n    connector = 'sqlserver-cdc',\n    hostname = '127.0.0.1',\n    port = '1433',\n    username = 'sa',\n    password = '123456',\n    database.name = 'mydb'\n);\n```\n\n----------------------------------------\n\nTITLE: Specifying Protobuf Schema Location in SQL ENCODE Clause\nDESCRIPTION: Illustrates the syntax within the `ENCODE` clause of a `CREATE SOURCE` statement for specifying the location of a pre-compiled Protobuf schema (`FileDescriptorSet`). This example shows using a local file path (`file://...`).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nENCODE data_encode (\n   schema.location = 'file://...' -- path to schema_descriptor.pb\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave with Java\nDESCRIPTION: Creates a materialized view named 'counter' that calculates aggregate statistics from the 'walk' source. The view captures the sum of distance and duration values to maintain real-time totals.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/java.mdx#2025-04-23_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport java.sql.*;\nimport java.util.Properties;\n\npublic class create_mv {\n\n    public static void main (String arg[]) throws SQLException {\n\n        //If necessary, add the code for connecting to RisingWave here.\n\n        String sqlQuery = \"CREATE MATERIALIZED VIEW counter AS \" +\n        \"SELECT sum(distance) AS total_distance, sum(duration) AS total_duration \" +\n        \"FROM walk; \";\n        PreparedStatement st = conn.prepareStatement(sqlQuery); \n        st.executeQuery();\n        conn.close();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying User Authentication with OAuth - SQL\nDESCRIPTION: This snippet shows how to configure OAuth-based authentication for a user using ALTER USER with a WITH oauth clause. It requires specifying mandatory parameters 'jwks_url' and 'issuer', with optional parameters validated against JWT claims. All option keys must be lowercase; failure to match claim values will result in login denial.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-user.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER user_name WITH oauth (\n  jwks_url = 'xxx.com',\n  issuer = 'risingwave',\n  other_params_should_match = 'xxx',\n);\n\n```\n\n----------------------------------------\n\nTITLE: Listing Internal CDC Tables in RisingWave\nDESCRIPTION: This SQL command shows all internal tables in RisingWave, which is the first step in monitoring CDC progress. It helps identify the specific internal tables associated with your CDC sources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INTERNAL TABLES;\n```\n\n----------------------------------------\n\nTITLE: Adding a Column to a Source in RisingWave\nDESCRIPTION: SQL command for adding a new column to an existing source in RisingWave, specifying the column name and data type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE <source_name> ADD COLUMN <column_name> <column_type>;\n```\n\n----------------------------------------\n\nTITLE: Querying MQTT Source Table in RisingWave SQL\nDESCRIPTION: This SQL query retrieves data from the shop_floor_machine_data source table, which contains the ingested MQTT data from the EMQX broker.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/emqx.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM shop_floor_machine_data LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating Table from PostgreSQL CDC Source in dbt\nDESCRIPTION: This SQL snippet shows how to create a table model in dbt that ingests data from a PostgreSQL CDC source. It defines the table structure and links it to the previously defined source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\n{{ config(materialized='table_with_connector') }}\nCREATE TABLE {{ this }} (\n    v1 integer primary key,\n    v2 timestamp with time zone\n) FROM {{ ref('pg_mydb') }} TABLE 'public.tt3';\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source with Amazon S3 Tables\nDESCRIPTION: Example SQL statement for creating a RisingWave source that connects to an Iceberg table managed by Amazon S3 Tables. This configuration uses REST catalog and SigV4 authentication to access the S3 Tables catalog API.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg-config.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE my_s3_tables_source\nWITH (\n    connector = 'iceberg',\n\n    -- Specify the S3 Tables warehouse ARN\n    warehouse.path = 'arn:aws:s3tables:<your-region>:<your-account-id>:bucket/<your-bucket-name>',\n    -- AWS Credentials\n    s3.access.key = '<your-aws-access-key-id>',\n    s.secret.key = '<your-aws-secret-access-key>',\n    s3.region = '<your-region>', -- e.g., 'us-east-1'\n\n    -- S3 Tables REST catalog endpoint\n    catalog.uri = 'https://s3tables.<your-region>.amazonaws.com/iceberg',\n    -- REST catalog signing configurations (Required for S3 Tables)\n    catalog.rest.signing_region = '<your-region>', -- e.g., 'us-east-1'\n    catalog.rest.sigv4_enabled = true,\n    catalog.rest.signing_name = 's3tables',\n    -- Specify REST catalog type\n    catalog.type = 'rest',\n\n    -- Target Iceberg table details within S3 Tables catalog\n    database.name = '<your-database-name>', -- Database in S3 Tables\n    table.name = '<your-table-name>'       -- Table name in S3 Tables\n;\n```\n\n----------------------------------------\n\nTITLE: Generate Series with Timestamps\nDESCRIPTION: Example showing how to generate a series of timestamps with 12-hour intervals using generate_series()\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT generate_series\nFROM generate_series(\n    '2008-03-01 00:00:00'::TIMESTAMP,\n    '2008-03-04 12:00:00'::TIMESTAMP,\n    interval '12' hour\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Upsert Table in SQL\nDESCRIPTION: This snippet demonstrates how to create an upsert table using the datagen connector. It includes configurations for generating sequence and random data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE s1_table (\n     seq_id bigint,\n     user_id bigint,\n     user_name varchar)\nWITH (\n     connector = 'datagen',\n     fields.seq_id.kind = 'sequence',\n     fields.seq_id.start = '1',\n     fields.seq_id.end = '10000000',\n     fields.user_id.kind = 'random',\n     fields.user_id.min = '1',\n     fields.user_id.max = '10000000',\n     fields.user_name.kind = 'random',\n     fields.user_name.length = '10',\n     datagen.rows.per.second = '20000'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Dropping Users with DROP USER Command in SQL\nDESCRIPTION: This SQL snippet shows the full syntax for dropping one or more users from RisingWave using the DROP USER command, with optional IF EXISTS clauses. It requires sufficient privileges (CREATEUSER or SUPERUSER depending on the target account) and the user must not be the currently logged-in user. Parameters include the user names to be dropped and an option to avoid errors if users do not exist. No output is returned if successful; errors are returned for permission or state issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-user.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP USER [ IF EXISTS ] user_name [ , ... ];\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE REFRESH SCHEMA Syntax in RisingWave SQL\nDESCRIPTION: This command refreshes the schema registry of a table created with connectors. It helps in updating the schema when the source schema has changed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\n    REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: New Syntax for Specifying CSV Format\nDESCRIPTION: The new syntax for specifying CSV format options using the FORMAT PLAIN ENCODE CSV structure with parameters defined in a key-value format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\nFORMAT PLAIN ENCODE CSV (\nwithout_header = 'true',\ndelimiter = ','\n);\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using risingwave-py\nDESCRIPTION: Demonstrates how to establish a connection to a RisingWave instance using the `risingwave-py` SDK. It shows two methods: using named parameters with `RisingWaveConnOptions.from_connection_info` and using a PostgreSQL-style connection string with `RisingWaveConnOptions`. It also illustrates the recommended usage of a context manager (`with rw.getconn() as conn:`) for operations versus using the main `RisingWave` object directly.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/python-sdk/intro.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom risingwave import RisingWave, RisingWaveConnOptions\n\n# Connect to RisingWave instance on localhost with named parameters\nrw = RisingWave(\n    RisingWaveConnOptions.from_connection_info(\n        host=\"localhost\", port=4566, user=\"root\", password=\"root\", database=\"dev\"\n    )\n)\n\n# Connect to RisingWave instance on localhost with connection string\nrw = RisingWave(RisingWaveConnOptions(\"postgresql://root:root@localhost:4566/dev\"))\n\n# You can create a new SQL connection and execute operations under the with statement. \n# This is the recommended way for python sdk usage.\nwith rw.getconn() as conn:\n    conn.insert(...)\n    conn.fetch(...)\n    conn.execute(...)\n    conn.mv(...)\n    conn.on_change(...)\n\n\n# You can also use the existing connection created by RisingWave object to execute operations.\n# This will be used in the later sections for simplicity.\nrw.insert(...)\nrw.fetch(...)\nrw.execute(...)\nrw.mv(...)\nrw.on_change(...)\n```\n\n----------------------------------------\n\nTITLE: Exiting RisingWave Connection\nDESCRIPTION: Command to disconnect from the RisingWave database session using the PostgreSQL-compatible quit command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n\\q\n```\n\n----------------------------------------\n\nTITLE: Enabling Table-Level CDC in SQL Server (SQL)\nDESCRIPTION: This SQL command enables Change Data Capture (CDC) for a specific table (`t1` in schema `dbo`) within a SQL Server database where CDC is already enabled. It executes the `sys.sp_cdc_enable_table` stored procedure, creating necessary CDC system objects. The `@role_name = NULL` parameter makes the gating role optional. Replace `dbo` and `t1` with the actual schema and table names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 't1', @role_name = NULL;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table for Historical Data Backfill from MSSQL Source\nDESCRIPTION: Creates a table in RisingWave that will be populated with historical data from an MSSQL source table. The table has an integer ID as the primary key and a timestamp column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3 (id INTEGER, v1 TIMESTAMP WITH TIME ZONE, PRIMARY KEY(id)) FROM mssql_source TABLE 'dbo.t3';\n```\n\n----------------------------------------\n\nTITLE: Querying Top Viewed Threads\nDESCRIPTION: SQL query to retrieve the most viewed threads ordered by view count.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM thread_view_count\nORDER BY view_count DESC, window_start\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: RENAME TO Example in RisingWave SQL\nDESCRIPTION: This example demonstrates renaming a table called 'table0' to 'table1'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of the table named \"table0\" to \"table1\"\nALTER TABLE table0 RENAME TO table1;\n```\n\n----------------------------------------\n\nTITLE: GROUP BY CUBE Syntax in SQL\nDESCRIPTION: Shows the syntax for using CUBE in a GROUP BY clause, which generates all possible combinations of the specified columns for subtotals.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nGROUP BY CUBE(c1,c2,c3)\n```\n\n----------------------------------------\n\nTITLE: Refreshing a Source Schema in RisingWave\nDESCRIPTION: Simple SQL command for refreshing the schema of an existing source using the REFRESH SCHEMA clause, which updates the schema from the registry.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE src_user REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Configuring CANAL JSON Format in RisingWave\nDESCRIPTION: SQL syntax for Canal CDC data (TiCDC dialect) in JSON format. The schema must be defined directly in the CREATE SOURCE or CREATE TABLE statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT CANAL\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Creating Maven Project\nDESCRIPTION: Command to generate a new Maven project for Java UDF development.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmvn archetype:generate -DgroupId=com.example -DartifactId=udf-example -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false\n```\n\n----------------------------------------\n\nTITLE: Applying RisingWave Resource File\nDESCRIPTION: Commands to apply a RisingWave resource configuration file using relative or absolute paths\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f a.yaml      # relative path\nkubectl apply -f /tmp/a.yaml # absolute path\n```\n\n----------------------------------------\n\nTITLE: SQL CREATE Statement with INCLUDE Clause Pattern\nDESCRIPTION: Demonstrates the pattern for adding the INCLUDE clause to CREATE SOURCE or CREATE TABLE statements. This shows where to place the clause in relation to schema definition and connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE { SOURCE | TABLE } name (\n    column_name data_type, ...  -- Your regular schema definition\n)\n[INCLUDE ... [AS ...]]\nWITH (\n    connector='...',\n    ...\n)\nFORMAT ... ENCODE ...;\n```\n\n----------------------------------------\n\nTITLE: Calling SQL UDF Wrapper for Built-in Function\nDESCRIPTION: This snippet shows how to call the previously created regexp_replace_wrapper function with a specific string argument.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nselect regexp_replace_wrapper('Cat is the cutest animal.');\n----RESULT\nDog is the cutest animal.\n```\n\n----------------------------------------\n\nTITLE: Querying Updated Materialized View Data in RisingWave (SQL)\nDESCRIPTION: This code performs another fetch from the materialized view 'mv' after more data has been inserted into table 't'. It fetches the recalculated aggregates, reflecting the current sums including the new rows. No parameters or special constraints are present.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from mv;\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum Concurrent Creating Streaming Jobs in SQL\nDESCRIPTION: Example of how to adjust the maximum number of concurrent creating streaming jobs using the ALTER SYSTEM SET command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-background-ddl.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET max_concurrent_creating_streaming_jobs TO 4;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Protobuf Encoding in SQL\nDESCRIPTION: This SQL snippet shows how to create a Kafka source in RisingWave using Protobuf encoding. It specifies the Protobuf message name, access credentials, and schema descriptor location, along with Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_abc\nWITH (\n   connector='kafka',\n   topic='demo_topic',\n   properties.bootstrap.server='172.10.1.1:9090,172.10.1.2:9090',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE PROTOBUF (\n   message = 'package.message_name',\n   access_key = 'your_access_key',\n   secret_key = 'your secret_key',\n   -- compiled from protoc\n   location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/schema_descriptor.pb'\n); \n```\n\n----------------------------------------\n\nTITLE: Creating Table for Ingesting Supabase CDC Data in RisingWave\nDESCRIPTION: This SQL command creates a table in RisingWave to ingest data from a specific Supabase table. It defines the schema and specifies the source table from the previously created Supabase connection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/supabase-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE tt3 (\n    v1 integer primary key,\n    v2 timestamp with time zone\n) FROM supabase_pgdb TABLE 'public.tt3';\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Download Speed Anomalies\nDESCRIPTION: SQL statement to create a materialized view that detects anomalies in download speeds. This view filters for devices where the download speed falls below 200.0, indicating potential performance issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW download_incidents AS\nSELECT\n    device_id,\n    window_end AS trigger_time,\n    metric_value AS trigger_value\nFROM\n    high_util_tcp_metrics\nWHERE\n    metric_name = 'download_speed'\n    AND metric_value < 200.0;\n```\n\n----------------------------------------\n\nTITLE: CASE Statement (Syntax 1) in SQL\nDESCRIPTION: Demonstrates the first syntax of the CASE statement, which evaluates conditions sequentially and returns the result associated with the first matching condition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCASE\n    WHEN condition THEN result\n    [ ... ]\n    [ ELSE result ]\nEND\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Numeric Literals in RisingWave SQL\nDESCRIPTION: This snippet showcases how to express numeric literals in different number systems within RisingWave, including decimal, hexadecimal, octal, and binary representations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/literals.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n2147       -- Decimal\n0x42e3     -- Hexadecimal\n0o664      -- Octal\n0b1101     -- Binary\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with ROLLUP in SQL\nDESCRIPTION: Illustrates the use of ROLLUP to generate subtotals and grand totals for multiple levels of grouping based on product category, subcategory, and region.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT product_category, product_subcategory, region, SUM(sales_amount) AS total_sales\nFROM sales\nGROUP BY ROLLUP (product_category, product_subcategory, region);\n```\n\n----------------------------------------\n\nTITLE: Using Custom Aggregate Functions (UDAFs) in RisingWave SQL\nDESCRIPTION: Demonstrates how to invoke a user-defined aggregate function (UDAF), such as the previously defined `weighted_avg`, within RisingWave SQL queries. It shows examples of using the UDAF in a simple batch query with `VALUES` and incorporating it into a `CREATE MATERIALIZED VIEW` statement for continuous computation. Includes commands for inserting data and flushing the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-aggregate.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Use UDAF\n-- call UDAF in a batch query\nSELECT weighted_avg(value, weight) FROM (VALUES (1, 1), (NULL, 2), (3, 3)) AS t(value, weight);\n-----RESULT\n2.5\n\n-- call UDAF in a materialized view\nCREATE TABLE t(value int, weight int);\nCREATE MATERIALIZED VIEW mv AS SELECT weighted_avg(value, weight) FROM t;\n\nINSERT INTO t VALUES (1, 1), (NULL, 2), (3, 3);\nFLUSH;\n\nSELECT * FROM mv;\n-----RESULT\n2.5\n```\n\n----------------------------------------\n\nTITLE: Configuring Hive Catalog for Iceberg Sink\nDESCRIPTION: Example SQL command for creating an Iceberg sink using the Hive catalog. This configuration requires setting the catalog.type parameter to 'hive' and specifying the Thrift URI for the Hive metastore.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_demo_hive FROM t\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = true,\n    catalog.type = 'hive',\n    catalog.uri = 'thrift://metastore:9083',\n    warehouse.path = 's3://icebergdata/demo',\n    s3.endpoint = 'http://minio-0:9301',\n    s3.access.key = 'xxxxxxxxxx',\n    s3.secret.key = 'xxxxxxxxxx',\n    s3.region = 'ap-southeast-1',\n    catalog.name = 'demo',\n    database.name = 's1',\n    table.name = 't1'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Source Table and Initial Materialized Views in RisingWave - SQL\nDESCRIPTION: These commands create a simple source table 't' and an initial materialized view aggregating a count over that table. Useful as an initial setup before evolving logic using SINK INTO TABLE. Inputs are table and view definitions; outputs are persistent streaming state representing table and count.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(v1 int);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW m1 as select count(*) from t;\n```\n\n----------------------------------------\n\nTITLE: Configuring JSON Format in RisingWave\nDESCRIPTION: SQL syntax for configuring JSON format in RisingWave. Allows direct decoding of JSON from external sources with optional schema registry integration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE JSON [ (\n   schema.registry = 'schema_registry_url [, ...]',\n   [schema.registry.username = 'username'],\n   [schema.registry.password = 'password']\n   ) ]\n```\n\n----------------------------------------\n\nTITLE: Nested SQL CTE Example\nDESCRIPTION: Demonstrates the use of multiple CTEs where the second CTE references the first. The first CTE 'cte' defines a column 'i', and the second CTE 'cte2' uses this to calculate a new column 'x'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- create two CTEs, where the second CTE references the first CTE\nWITH cte AS (SELECT 35 AS i),\n     cte2 AS (SELECT i*100 AS x FROM cte)\nSELECT * FROM cte2;\n┌──────┐\n│  x   │\n├──────┤\n│ 3500 │\n└──────┘\n```\n\n----------------------------------------\n\nTITLE: Creating Append-Only Sink from Upsert Source in SQL\nDESCRIPTION: This SQL snippet shows how to create an append-only sink from an upsert source in RisingWave. It uses the 'append-only' type and 'force_append_only' option to ignore delete messages and convert updates to inserts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINKs1_sink FROM t1_table\nWITH (\n    connector = 'clickhouse',\n    type = 'append-only',\n    clickhouse.url = '${CLICKHOUSE_URL}',\n    clickhouse.user = '${CLICKHOUSE_USER}',\n    clickhouse.password = '${CLICKHOUSE_PASSWORD}',\n    clickhouse.database = 'default',\n    clickhouse.table='demo_test'\n);\n```\n\n----------------------------------------\n\nTITLE: Extracting Date/Time Fields in SQL\nDESCRIPTION: Extracts specific fields from date/time values. Supports various date/time types and fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nextract(day from date '2022-04-07') → 7\n\nextract(hour from timestamp '2022-04-07 22:00:30') → 22\n\nextract(second from time '22:00:30.123') → 30.123000\n\nextract(day from interval '2 days') → 2\n\nextract(day from '2023-06-01 00:00:00Z'::timestamptz at time zone 'us/pacific') → 31\n```\n\n----------------------------------------\n\nTITLE: Configuring HDFS as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up HDFS as the state store backend for RisingWave. It includes the necessary volume mounts and environment variables for Hadoop configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: risingwave.risingwavelabs.com/v1alpha1\nkind: RisingWave\nmetadata:\n  name: risingwave\nspec:\n  image: <the image you packaged>\n  metaStore:\n    memory: true\n  stateStore:\n    hdfs:\n      nameNode: <your_cluster_name/namenode>\n      root: <data_directory>\n  components:\n    meta:\n      nodeGroups:\n      - name: ''\n        replicas: 1\n        template:\n          spec:\n            resources:\n              limits:\n                cpu: 1\n                memory: 2Gi\n            env:\n            - name: HADOOP_CONF_DIR\n              value: /var/etc/hadoop/conf\n            volumes:\n            - name: hadoop-conf\n              configMap:\n                name: hadoop-conf\n            volumeMounts:\n            - name: hadoop-conf\n              mountPath: /var/etc/hadoop/conf\n              readOnly: true\n    compute:\n      nodeGroups:\n      - name: ''\n        replicas: 1\n        template:\n          spec:\n            resources:\n              limits:\n                cpu: 4\n                memory: 16Gi\n            env:\n            - name: HADOOP_CONF_DIR\n              value: /var/etc/hadoop/conf\n            volumes:\n            - name: hadoop-conf\n              configMap:\n                name: hadoop-conf\n            volumeMounts:\n            - name: hadoop-conf\n              mountPath: /var/etc/hadoop/conf\n              readOnly: true\n    compactor:\n      nodeGroups:\n      - name: ''\n        replicas: 1\n        template:\n          spec:\n            resources:\n              limits:\n                cpu: 2\n                memory: 4Gi\n            env:\n            - name: HADOOP_CONF_DIR\n              value: /var/etc/hadoop/conf\n            volumes:\n            - name: hadoop-conf\n              configMap:\n                name: hadoop-conf\n            volumeMounts:\n            - name: hadoop-conf\n              mountPath: /var/etc/hadoop/conf\n              readOnly: true\n    frontend:\n      nodeGroups:\n      - name: ''\n        replicas: 1\n        template:\n          spec:\n            resources:\n              limits:\n                cpu: 2\n                memory: 4Gi\n```\n\n----------------------------------------\n\nTITLE: Executing the DISCARD ALL Command in RisingWave\nDESCRIPTION: This command attempts to reset the state of the current session. However, as RisingWave currently does not support temporary objects, executing `DISCARD ALL` will effectively have no impact on the session state. The `ALL` parameter is required.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-discard.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nDISCARD ALL;\n```\n\n----------------------------------------\n\nTITLE: Example: Setting Backfill Rate Limit in SQL\nDESCRIPTION: Provides examples of how to use `SET BACKFILL_RATE_LIMIT` to pause backfill (set to 0), set a specific rate limit (set to 1), or disable the limit (set to DEFAULT) for a materialized view named `mv1`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n-- Pause the backfill\nALTER MATERIALIZED VIEW mv1 SET BACKFILL_RATE_LIMIT=0;\n\n-- Set backfill rate limit to 1\nALTER MATERIALIZED VIEW mv1 SET BACKFILL_RATE_LIMIT=1;\n\n-- Disable the backfill rate limit\nALTER MATERIALIZED VIEW mv1 SET BACKFILL_RATE_LIMIT=DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table from PostgreSQL CDC Source in RisingWave\nDESCRIPTION: SQL syntax for creating a table in RisingWave based on a PostgreSQL CDC source. This maps to a specific upstream PostgreSQL table and requires defining a primary key consistent with the source table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n    column_name data_type PRIMARY KEY , ...\n    PRIMARY KEY ( column_name, ... )\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n    snapshot='true'\n)\nFROM source TABLE pg_table_name;\n```\n\n----------------------------------------\n\nTITLE: Including Full JSON Payload for Unknown Schemas\nDESCRIPTION: Example of including the entire JSON payload as a separate column when the exact schema is unknown in advance, allowing for runtime data processing and filtering.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_include_payload (v1 int, v2 varchar)\nINCLUDE payload\nWITH (\n    connector = 'kafka',\n    topic = 'kafka_1_partition_topic',\n    properties.bootstrap.server = 'message_queue:29092',\n    scan.startup.mode = 'earliest'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Calling SQL UDF with Corner Case\nDESCRIPTION: This snippet shows how to call the previously created corner_case function, which returns a string representation of its parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nselect corner_case(1, 2, 3);\n----RESULT\n$1 + a + $3\n```\n\n----------------------------------------\n\nTITLE: Using OVERLAY Function in SQL\nDESCRIPTION: The overlay() function replaces a substring in the input string with a substring, starting at a specified position and with an optional length. If the length is omitted, its value is the length of the substring.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\noverlay ( input_string PLACING substring FROM start_int [ FOR length_int ] ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\noverlay('yabadoo' PLACING 'daba' FROM 5 FOR 0) → 'yabadabadoo'\noverlay('abcdef' PLACING '45' FROM 4) → 'abc45f'\noverlay('RisingWave' PLACING '🌊' FROM 7) → 'Rising🌊ave'\n```\n\n----------------------------------------\n\nTITLE: SET PARALLELISM Example in RisingWave SQL\nDESCRIPTION: A simple example showing how to set a table's parallelism to a fixed value of 8.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE test_table SET PARALLELISM = 8;\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Generated Data from RisingWave Source Table\nDESCRIPTION: This code block shows the sample output of the query executed on the 's1' table. It displays 20 rows of generated data, including array integers, struct values, timestamps, and random strings, demonstrating the variety of data types and ranges specified in the table creation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n     i1     |            v1            |             t1             |                z1                |        c1\n------------+--------------------------+----------------------------+----------------------------------+------------------\n {1,2,3}    | (7,53.96978949033611)    | 2023-11-28 13:35:04.967040 | 2023-11-28 21:35:04.967330+00:00 | pGWJLsbmPJZZWpBe\n {4,5,6}    | (5,44.24453663454818)    | 2023-11-28 14:13:15.264457 | 2023-11-28 22:13:15.264481+00:00 | FT7BRdifYMrRgIyI\n {7,8,9}    | (3,18.808367835800485)   | 2023-11-28 15:12:41.918935 | 2023-11-28 23:12:41.919590+00:00 | 0zsMbNLxQh9yYtHh\n {10,11,12} | (-4,26.893033246334525)  | 2023-11-28 14:55:43.193883 | 2023-11-28 22:55:43.193917+00:00 | zujxzBql3QHxENyy\n {13,14,15} | (-3,28.68505963291612)   | 2023-11-28 13:35:05.967253 | 2023-11-28 21:35:05.967520+00:00 | aBJTDJpinRv8mLvQ\n {16,17,18} | (4,36.32012760913261)    | 2023-11-28 14:13:16.264624 | 2023-11-28 22:13:16.264646+00:00 | HVur4zU3hQFgVh74\n {19,20,21} | (-10,16.212694434604053) | 2023-11-28 15:12:42.919339 | 2023-11-28 23:12:42.919465+00:00 | LVLAhd1pQvhXVL8p\n {22,23,24} | (-8,28.388082274426225)  | 2023-11-28 14:55:44.193726 | 2023-11-28 22:55:44.193787+00:00 | siFqrkdlCnNZqAUT\n {25,26,27} | (2,40.86763449564268)    | 2023-11-28 15:19:51.600898 | 2023-11-28 23:19:51.600977+00:00 | ORjwy3oMNbl1Yi6X\n {28,29,30} | (3,29.179236922708526)   | 2023-11-28 15:27:49.755084 | 2023-11-28 23:27:49.755105+00:00 | YIVLnWxHyfsiPHQo\n {31,32,33} | (6,26.03842827701958)    | 2023-11-28 16:07:02.012019 | 2023-11-29 00:07:02.012133+00:00 | lpzCxwpoJp9njIAa\n {34,35,36} | (-2,20.2351457847852)    | 2023-11-28 14:23:37.167393 | 2023-11-28 22:23:37.167453+00:00 | oW8xmndvmXMRp1Rc\n {37,38,39} | (2,36.51138960926262)    | 2023-11-28 15:19:52.600699 | 2023-11-28 23:19:52.600741+00:00 | 0m1Qxn96Xeq42H3Z\n {40,41,42} | (0,34.2997487580596)     | 2023-11-28 15:27:50.754878 | 2023-11-28 23:27:50.754899+00:00 | 1jT3TnEEj56YNa7w\n {43,44,45} | (7,39.13577932700749)    | 2023-11-28 16:07:03.011837 | 2023-11-29 00:07:03.011905+00:00 | linRToOjph0WlJrd\n {46,47,48} | (7,37.43674199879566)    | 2023-11-28 14:23:38.167161 | 2023-11-28 22:23:38.167271+00:00 | beql98l3IIkjomTl\n {49,50,51} | (1,41.62099792202798)    | 2023-11-28 15:24:46.803776 | 2023-11-28 23:24:46.803844+00:00 | xHbIYlJismRlIKFw\n {52,53,54} | (9,49.240259695092895)   | 2023-11-28 15:39:22.752067 | 2023-11-28 23:39:22.752115+00:00 | TDYNZsSNYMpOpZgC\n {55,56,57} | (6,54.64984398127376)    | 2023-11-28 13:32:15.049957 | 2023-11-28 21:32:15.050089+00:00 | jqPQM3oyA2lOXLcn\n {58,59,60} | (-4,54.197350082045176)  | 2023-11-28 14:07:53.278392 | 2023-11-28 22:07:53.278457+00:00 | 72cIOHPb7DE8FTme\n(20 rows)\n```\n\n----------------------------------------\n\nTITLE: Ad Impression Event Schema in JSON\nDESCRIPTION: JSON schema for ad impression events, including bid_id (identifier for a bid request), ad_id (identifier for the ad), and impression_timestamp (when the ad was presented to a viewer).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bid_id\": 2439384144522347,\n  \"ad_id\": 5,\n  \"impression_timestamp\": \"2022-05-23T14:11:04Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying All Rows from a Materialized View in SQL - SQL\nDESCRIPTION: This SQL snippet selects all columns from the 'mv_sales_summary' materialized view to retrieve the total sales per product. It outputs an aggregated list reflecting current totals, relying on the previously created view. Inputs are none beyond the view itself, and the query demonstrates standard result retrieval from materialized aggregates.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/overview.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mv_sales_summary;\\n\\n----RESULT\\n product_id | total_sales\\n------------+-------------\\n          1 |         175\\n          2 |         275\\n          3 |         200\\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Querying PostgreSQL CDC Backfill Progress\nDESCRIPTION: This SQL query retrieves information about the initial backfill progress for a PostgreSQL CDC source. It shows whether the backfill is complete, how many rows have been processed, and the current position in the PostgreSQL WAL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_my_pg_source_1_streamcdcscan_4;\n```\n\n----------------------------------------\n\nTITLE: Setting Source Schema in RisingWave SQL\nDESCRIPTION: These snippets demonstrate moving a source to a different schema using the SET SCHEMA clause. The command requires the source's current name and the target schema name. The operation updates metadata for the source without altering its contents or definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE current_source_name\n    SET SCHEMA schema_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Move the source named \"test_source\" to the schema named \"test_schema\"\nALTER SOURCE test_source SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Renaming Database using ALTER DATABASE RENAME TO in SQL\nDESCRIPTION: Shows the syntax for renaming a specific database using the `RENAME TO` clause. The `new_name` parameter specifies the desired new name for the database. Only the database owner (with `CREATEDB` privilege) or a superuser can rename a database. Renaming the currently connected database is not permitted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-database.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE database_name\n    RENAME TO new_name;\n```\n\n----------------------------------------\n\nTITLE: Using BIT_LENGTH Function in SQL\nDESCRIPTION: The bit_length() function returns the number of bits in the input string, which is 8 times the octet_length.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nbit_length ( input_string ) → integer\n```\n\nLANGUAGE: SQL\nCODE:\n```\nbit_length('wave') → 32\n```\n\n----------------------------------------\n\nTITLE: Creating a source table with datagen connector in RisingWave using Ruby\nDESCRIPTION: This code creates a source table named 'walk' using the datagen connector in RisingWave. It defines the table structure and sets up mock data generation parameters for distance and duration columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/ruby.mdx#2025-04-23_snippet_1\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'pg'\n\nconn = PG.connect(host: '127.0.0.1', port: 4566, dbname: 'dev', user: 'root')\n\nsql = <<-EOF\nCREATE TABLE walk(distance INT, duration INT)\nWITH (\n    connector = 'datagen',\n    fields.distance.kind = 'sequence',\n    fields.distance.start = '1',\n    fields.distance.end  = '60',\n    fields.duration.kind = 'sequence',\n    fields.duration.start = '1',\n    fields.duration.end = '30',\n    datagen.rows.per.second='15',\n    datagen.split.num = '1'\n) FORMAT PLAIN ENCODE JSON\nEOF\nconn.exec(sql) # Execute the query.\n```\n\n----------------------------------------\n\nTITLE: Querying JSON Paths with jsonb_path_query\nDESCRIPTION: Function that extracts all items matching a JSON path query and returns them as a set of jsonb values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_path_query('{\n  \"employees\": [\n    {\n      \"name\": \"John\",\n      \"age\": 30\n    },\n    {\n      \"name\": \"Jane\",\n      \"age\": 25\n    },\n    {\n      \"name\": \"David\",\n      \"age\": 35\n    },\n    {\n      \"name\": \"Michael\",\n      \"age\": 32\n    }\n  ]\n}', '$.employees[*] ? (@.age >= 25 && @.age <= 30)');\n```\n\n----------------------------------------\n\nTITLE: Querying Detected Anomalies\nDESCRIPTION: SQL query to retrieve detected anomalies from the srtt_incidents materialized view, which contains devices experiencing slow round trip times.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM srtt_incidents;\n```\n\n----------------------------------------\n\nTITLE: CASE Statement (Syntax 2) in SQL\nDESCRIPTION: Illustrates the second syntax of the CASE statement, which compares an expression to multiple values and returns the result associated with the first matching value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCASE expression\n    WHEN value THEN result\n    [ ... ]\n    [ ELSE result ]\nEND\n```\n\n----------------------------------------\n\nTITLE: Formatting Date/Time Values in SQL\nDESCRIPTION: Converts date/time values to strings according to specified formats.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nto_char(timestamp '2002-04-20 17:31:12.66', 'HH12:MI:SS') → '05:31:12'\n\nto_char('2023-07-11 20:01:00-07:00'::timestamptz, 'HH12:MI:SS TZH:TZM') → 03:01:00 +00:00\n\nto_char('1year 2 month 3day 4hour 5minute 6second'::interval, 'YYYY MM DD PM HH12 HH24 MI SS MS US') → 0001 02 03 AM 04 04 05 06 000 000000\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Complex Struct for Trip Data\nDESCRIPTION: Example of creating a table using struct for organizing fare-related fields in a trip tracking system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE trip (\n        id VARCHAR,\n        started_at TIMESTAMP,\n        completed_at TIMESTAMP,\n        distance DOUBLE PRECISION,\n        fare STRUCT <\n            initial_charge DOUBLE PRECISION,\n            subsequent_charge DOUBLE PRECISION,\n            surcharge DOUBLE PRECISION,\n            tolls DOUBLE PRECISION\n            >\n        );\n```\n\n----------------------------------------\n\nTITLE: Creating a User Named test with OAuth Authentication - RisingWave SQL\nDESCRIPTION: This SQL snippet illustrates creating the 'test' user in RisingWave with OAuth authentication parameters (including required jwks_url and issuer, plus optional matching parameters). The command ensures that JWT claims will be validated against supplied parameters. It must be executed as a privileged user in the SQL shell, with prerequisites including a compatible OAuth provider and RisingWave configured for OAuth authentication. The user is created on success.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER test WITH oauth (\n  jwks_url = 'xxx.com',  // required\n  issuer = 'risingwave',  // required\n  other_params_should_match = 'xxx',  // optional, will be checked against jwt.claims\n);\n```\n\n----------------------------------------\n\nTITLE: Example: Setting Fixed Subscription Parallelism in SQL\nDESCRIPTION: Illustrates how to set the parallelism for the subscription named \"s\" to a fixed value of 4 using the `ALTER SUBSCRIPTION ... SET PARALLELISM` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the parallelism of the SUBSCRIPTION \"s\" to 4.\nALTER SUBSCRIPTION s SET PARALLELISM = 4;\n```\n\n----------------------------------------\n\nTITLE: Viewing All Running Jobs in RisingWave\nDESCRIPTION: Shows how to display all running streaming jobs using the SHOW JOBS command, including job IDs, statements, and progress information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-statement-progress.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW JOBS;\n------RESULT\n  Id  |                     Statement                     | Progress\n------+---------------------------------------------------+----------\n 1010 | CREATE MATERIALIZED VIEW mv3 AS SELECT *FROM mv1  | 2.21%\n 1012 | CREATE MATERIALIZED VIEW mv2 AS SELECT* FROM mv1  | 0.86%\n```\n\n----------------------------------------\n\nTITLE: Creating Table for Backfilling Optimization - SQL\nDESCRIPTION: Demonstrates creating a base table with integer, varchar, and timestamp fields in SQL. This table serves as historical data storage, relevant for discussing query performance during backfilling in RisingWave. Requires an operational RisingWave SQL environment and sufficient storage. Inputs are the column definitions and primary key declaration; output is a new table where backfilling performance may vary depending on schema design.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(v1 int, v2 varchar, v3 timestamp);\n```\n\n----------------------------------------\n\nTITLE: Initiating a new dbt project\nDESCRIPTION: This command starts the process of creating a new dbt project. It will prompt for project details and database configurations specific to RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndbt init\n```\n\n----------------------------------------\n\nTITLE: Adding a Column to a Kafka Source in RisingWave\nDESCRIPTION: Example of adding an integer column named 'new_col' to an existing Kafka source. This new column won't be included in existing materialized views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE my_kafka_source ADD COLUMN new_col INTEGER;\n```\n\n----------------------------------------\n\nTITLE: Reading Parquet Files from Azblob using file_scan Function in RisingWave SQL\nDESCRIPTION: Presents the function signature for `file_scan` used to read Parquet files directly from Azure Blob Storage in RisingWave (added in version 2.3). It lists the required parameters: format (`parquet`), connector (`azblob`), Azure credentials (`account_name`, `account_key`, `endpoint`), and the file or directory location. When reading a directory, all files must share the schema of the first file listed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/azure-blob.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nfile_scan (parquet, azblob, account_name, account_key, endpoint, file_location)\n```\n\n----------------------------------------\n\nTITLE: Deleting All Rows from a Table (SQL)\nDESCRIPTION: Shows the SQL command to delete all rows from the `taxi_trips` table. Omitting the `WHERE` clause, as done here, results in the removal of all records, while the table structure itself remains intact.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM taxi_trips\n```\n\n----------------------------------------\n\nTITLE: Using ENCODE Function in SQL\nDESCRIPTION: The encode() function encodes the binary data in bytea into its textual representation. Supported encoding formats include base64, hex, and escape.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nencode ( bytea, format_type ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nencode(E'123'::bytea, 'base64') → 'MTIz'\n```\n\n----------------------------------------\n\nTITLE: Altering System Parameter via SQL - Bash\nDESCRIPTION: This Bash snippet demonstrates how to update a mutable system parameter in RisingWave using the ALTER SYSTEM SET SQL command from a psql session. The syntax allows you to specify the parameter name and assign a new value or reset it to DEFAULT. No special dependencies are required except database access. Use this for runtime configuration tuning where permitted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-system-parameters.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nALTER SYSTEM SET parameter_name { TO | = } { value | 'value' | DEFAULT };\n```\n\n----------------------------------------\n\nTITLE: Bulk Ingestion Using INSERT SELECT with Apache Iceberg Source\nDESCRIPTION: This example shows how to import data from an Apache Iceberg source into a RisingWave table using INSERT SELECT. This approach converts ad-hoc query results into streaming data for downstream processing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE source_iceberg_t1\nWITH (\n    connector = 'iceberg',\n    catalog.type = 'storage',\n    ...\n    database.name = 's1',\n    table.name = 't1'\n);\n\nCREATE TABLE t1(\n  timestamp timestamp with time zone,\n  user_id varchar,\n  page_id varchar,\n  action varchar\n);\n\nINSERT INTO t1 SELECT * FROM source_iceberg_t1;\n```\n\n----------------------------------------\n\nTITLE: Conditionally Dropping a Schema using IF EXISTS in SQL\nDESCRIPTION: This example illustrates using the `IF EXISTS` clause with `DROP SCHEMA`. This prevents the command from returning an error if the specified schema (`rw_schema`) does not exist in the database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-schema.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA IF EXISTS rw_schema;\n```\n\n----------------------------------------\n\nTITLE: Installing arrow-udf Package with pip\nDESCRIPTION: Command to install the arrow-udf framework which provides Python SDK for defining and running UDFs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install arrow-udf\n```\n\n----------------------------------------\n\nTITLE: Starting a Read-Only Transaction in RisingWave SQL\nDESCRIPTION: This SQL command initiates a read-only transaction in RisingWave. Although RisingWave accepts `BEGIN` without `READ ONLY` for compatibility, it does not actually start a transaction. Only `BEGIN READ ONLY` effectively starts a transaction block, restricting subsequent operations within the transaction to read-only commands until a `COMMIT` is issued. The command returns 'BEGIN' upon successful execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-begin.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN READ ONLY;\n-------RESULT\nBEGIN\n\n```\n\n----------------------------------------\n\nTITLE: COALESCE Function in SQL\nDESCRIPTION: Demonstrates the COALESCE function, which returns the first non-null value from a list of expressions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCOALESCE ( value [ , ... ] )\n```\n\n----------------------------------------\n\nTITLE: Finding Tables with Specific Column Name in SQL\nDESCRIPTION: SQL query to find all tables, sinks, views, and materialized views that contain a specific column named 'trip_id'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/information-schema.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT table_name\nFROM information_schema.columns\nWHERE column_name='trip_id';\n```\n\n----------------------------------------\n\nTITLE: Creating JSON Arrays from Path Queries with jsonb_path_query_array\nDESCRIPTION: Function that extracts matching items and returns them as a single JSON array with support for variables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_path_query_array('{\n  \"employees\": [\n    {\n      \"name\": \"John\",\n      \"age\": 30\n    },\n    {\n      \"name\": \"Alice\",\n      \"age\": 35\n    },\n    {\n      \"name\": \"Bob\",\n      \"age\": 25\n    }\n  ]\n}', '$.employees[*] ? (@.age >= $min && @.age <= $max)', '{\"min\": 24, \"max\": 32}');\n```\n\n----------------------------------------\n\nTITLE: JSON Type Validation Example Query\nDESCRIPTION: Demonstrates testing various values against different JSON types using the IS JSON predicate, including scalar, object, and array validation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT js,\n  js IS JSON \"json?\",\n  js IS JSON SCALAR \"scalar?\",\n  js IS JSON OBJECT \"object?\",\n  js IS JSON ARRAY \"array?\"\nFROM (VALUES\n      ('123'), ('\"abc\"'), ('{\"a\": \"b\"}'), ('[1,2]'),('abc')) foo(js);\n```\n\n----------------------------------------\n\nTITLE: Example of Creating a StarRocks Sink in RisingWave\nDESCRIPTION: This SQL example shows how to create a sink named 'bhv_starrocks_sink' from a materialized view 'bhv_mv' to a StarRocks table. It includes specific connection details, authentication, and configuration settings for the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/starrocks.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK bhv_starrocks_sink\nFROM bhv_mv WITH (\n    connector = 'starrocks',\n    type = 'append-only',\n    starrocks.host = 'starrocks-fe',\n    starrocks.mysqlport = '9030',\n    starrocks.httpport = '8030',\n    starrocks.user = 'users',\n    starrocks.password = '123456',\n    starrocks.database = 'demo',\n    starrocks.table = 'demo_bhv_table',\n    force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Upsert JSON Format in RisingWave SQL\nDESCRIPTION: Specifies the format and encoding for consuming Upsert JSON data from Kafka topics. Supports schema registry configuration for automatic schema retrieval.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nFORMAT UPSERT\nENCODE JSON [ (\n   schema.registry = 'schema_registry_url [, ...]',\n   [schema.registry.username = 'username'],\n   [schema.registry.password = 'password']\n   ) ]\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Data by Datetime in RisingWave SQL\nDESCRIPTION: This snippet shows how to access historical data as of a specific datetime using the FOR SYSTEM_TIME AS OF clause. Requires a properly configured meta store and sufficient time travel retention. The datetime must be in ISO 8601 format and within the allowable time travel window; otherwise, an error is returned.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/time-travel-queries.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t_foo FOR SYSTEM_TIME AS OF '2000-02-29T12:13:14-08:30';\n```\n\n----------------------------------------\n\nTITLE: Configuring DEBEZIUM JSON Format in RisingWave\nDESCRIPTION: SQL syntax for Debezium CDC data in JSON format. The ignore_key option (default: false) allows consuming only the payload without the key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT DEBEZIUM\nENCODE JSON [ (\n   [ ignore_key = 'true | false ' ]\n) ]\n```\n\n----------------------------------------\n\nTITLE: Using rank() Window Function in SQL\nDESCRIPTION: The rank() function returns the rank of the current row, with gaps. It returns the row_number of the first row in its peer group.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nrank() → integer\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    rank() OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as r,\n    col1, col2\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with an Array of Arrays\nDESCRIPTION: Shows how to create a table 'x' that contains an array of arrays using the INT[][] data type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE x (a INT[][]);\n```\n\n----------------------------------------\n\nTITLE: Configuring DEBEZIUM_MONGO JSON Format in RisingWave\nDESCRIPTION: SQL syntax for loading data from MongoDB via Kafka topics in Debezium Mongo JSON format. The table schema must have _id and payload columns, where _id is the primary key and payload is type jsonb.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT DEBEZIUM_MONGO\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic JavaScript UDF in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to create a basic JavaScript UDF named 'gcd' that calculates the greatest common divisor of two integers. It shows the syntax for defining a function with arguments, return type, and function body in JavaScript.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-javascript.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION gcd(a int, b int) RETURNS int LANGUAGE javascript AS $$\n    if(a == null || b == null) {\n        return null;\n    }\n    while (b != 0) {\n        let t = b;\n        b = a % b;\n        a = t;\n    }\n    return a;\n$$;\n```\n\n----------------------------------------\n\nTITLE: Expected Materialized View Output (bash/console)\nDESCRIPTION: This console output snippet illustrates the expected result after querying the materialized view 'mv'. There are no parameters; it's sample output reflecting the sum of the current rows in table 't'. This output is for visualization only, not executable code.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n v1_sum | v2_sum\n--------+--------\n      6 |     60\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Updating Helm Repository\nDESCRIPTION: Command to update the local cache of available Helm charts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Creating a Secret in RisingWave for HubSpot Webhook Validation\nDESCRIPTION: Creates a secret in RisingWave to securely store a string used for validating incoming webhook requests from HubSpot. This is the recommended method for signature verification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hubspot-webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'TEST_WEBHOOK';\n```\n\n----------------------------------------\n\nTITLE: Example: Changing Database Owner in SQL\nDESCRIPTION: Demonstrates how to use the `ALTER DATABASE ... OWNER TO` command to change the owner of the database named `database1` to the user `user1`. This is a practical application of the `OWNER TO` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-database.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the database named \"database1\" to user \"user1\"\nALTER DATABASE database1 OWNER TO user1;\n```\n\n----------------------------------------\n\nTITLE: Renaming a Subscription using RENAME TO in SQL\nDESCRIPTION: Shows the syntax for renaming an existing subscription (`subscription_name`) to a new name (`new_name`) using the `RENAME TO` clause within the `ALTER SUBSCRIPTION` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION subscription_name\n    RENAME TO new_name;\n```\n\n----------------------------------------\n\nTITLE: Querying Current Streaming Jobs (SQL)\nDESCRIPTION: This snippet shows a SQL command to list all ongoing streaming jobs in the system. It outputs a table displaying job IDs, statements representing the job's SQL origin, and the current completion progress as a percentage. Required dependencies include an active connection to a RisingWave SQL endpoint, and it returns job metadata for any jobs still in progress.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-cancel-jobs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW JOBS;\n------RESULT\n  Id  |                     Statement                     | Progress\n------+---------------------------------------------------+----------\n 1010 | CREATE MATERIALIZED VIEW mv3 AS SELECT *FROM mv1  | 2.21%\n 1012 | CREATE MATERIALIZED VIEW mv2 AS SELECT* FROM mv1  | 0.86%\n```\n\n----------------------------------------\n\nTITLE: Defining Schemas with CREATE SCHEMA in SQL\nDESCRIPTION: Demonstrates the syntax for creating schemas in RisingWave using the CREATE SCHEMA statement. The snippet covers optional clauses like IF NOT EXISTS, specifying the database, and defining the schema owner via AUTHORIZATION. It serves as a template for constructing CREATE SCHEMA queries with following parameters: schema_name (target schema name), [database_name] (optional target database), and user_name (owner/authorized user). Inputs are schema and user names; outputs are newly created schemas or error messages in case of conflicts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-schema.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SCHEMA [IF NOT EXISTS] [database_name.]schema_name [AUTHORIZATION user_name];\n\nCREATE SCHEMA [ IF NOT EXISTS ] AUTHORIZATION user_name;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View for Upsert Sink in RisingWave\nDESCRIPTION: Example of creating a materialized view in RisingWave that transforms streaming data into incremental logs for upsert operations in Snowflake. This view includes changelog information for tracking modifications.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW ss_mv AS\nWITH sub AS changelog FROM user_behaviors\nSELECT\n    user_id,\n    target_id,\n    event_timestamp AT TIME ZONE 'America/Indiana/Indianapolis' as event_timestamp,\n    changelog_op AS __op,\n    _changelog_row_id::bigint AS __row_id\nFROM\n    sub;\n```\n\n----------------------------------------\n\nTITLE: Verifying MySQL Binary Log Status (Enabled)\nDESCRIPTION: SQL command to verify the status of the binary log (`log_bin`) variable in MySQL after applying configuration changes and restarting the server. The example output shows the variable is now `ON`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'log_bin';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| log_bin       | ON    |\n+---------------+-------+\n```\n\n----------------------------------------\n\nTITLE: Table Creation and Data Insertion\nDESCRIPTION: Creates example employee and manager tables with sample data to demonstrate CORRESPONDING usage.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT PRIMARY KEY,\n    name VARCHAR,\n    age INT,\n    gender VARCHAR\n);\n\nCREATE TABLE managers (\n    id INT PRIMARY KEY,\n    name VARCHAR,\n    salary DECIMAL,\n    gender VARCHAR\n);\n\nINSERT INTO employees (id, name, age, gender) VALUES\n(1, 'Alice', 30, 'Female'),\n(2, 'Bob', 25, 'Male'),\n(3, 'Charlie', 28, 'Male');\n\nINSERT INTO managers (id, name, salary, gender) VALUES\n(1, 'David', 80000, 'Male'),\n(2, 'Eve', 90000, 'Female'),\n(3, 'Frank', 75000, 'Male');\n```\n\n----------------------------------------\n\nTITLE: Sample Output After Deleting All Rows (SQL)\nDESCRIPTION: Displays the sample output after executing `SELECT * FROM taxi_trips;` following the deletion of all rows, confirming that the table is now empty and returns '(0 rows)'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n id | distance | city\n----+----------+------\n(0 rows)\n```\n\n----------------------------------------\n\nTITLE: Using QUOTE_NULLABLE Function in SQL\nDESCRIPTION: The quote_nullable() function returns the given string properly quoted, so that it can be safely used as a string literal in an SQL statement. It returns NULL if the input string is null.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nquote_nullable(string text) → text\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT quote_nullable(NULL);\n----RESULT\nNULL\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with a Map Column in RisingWave SQL\nDESCRIPTION: Creates a table named 'x' with a column 'a' of type MAP(VARCHAR, INTEGER), which stores string keys and integer values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/map-type.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE x (a MAP(VARCHAR, INTEGER));\n```\n\n----------------------------------------\n\nTITLE: Modifying Schemas Using ALTER SCHEMA - SQL\nDESCRIPTION: Demonstrates the general syntax for altering an existing schema using the ALTER SCHEMA command. This template defines the basic structure which can be extended with various alter options, such as changing the owner or renaming the schema. No additional dependencies are required beyond access to an SQL environment with appropriate privileges. The required parameter is the existing schema name, and alter_option depends on the intended operation; outputs and effects vary according to the clause used.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-schema.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SCHEMA current_schema_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry in Config File - Bash\nDESCRIPTION: This snippet demonstrates how to define the \\\"telemetry_enabled\\\" system parameter within a RisingWave config file to disable telemetry reporting. Save this configuration in the appropriate \\\"risingwave/src/config/<your-config>.yaml\\\" file before starting the RisingWave cluster. No external dependencies are required. The key parameter is \\\"telemetry_enabled\\\", which controls anonymous usage statistics being collected; set it to \\\"false\\\" to opt out. This approach is persistent and applies cluster-wide.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/telemetry.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[server]\ntelemetry_enabled = false\n\n```\n\n----------------------------------------\n\nTITLE: Refreshing Schema Registry for a Source in RisingWave\nDESCRIPTION: SQL syntax for refreshing the schema registry of a source by modifying its FORMAT and ENCODE options. This is useful when the schema of upstream data changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/modify-source-or-table-schemas.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name FORMAT data_format ENCODE data_encode [ (\n    message='message',\n    schema.location='location', ...) ];\n```\n\n----------------------------------------\n\nTITLE: Querying Ingested Data in RisingWave Cloud\nDESCRIPTION: SQL query to select and limit the ingested data from the created source in RisingWave Cloud.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nSELECT * from your_source_name limit 1;\n```\n\n----------------------------------------\n\nTITLE: Querying IoT Sensor Data in RisingWave SQL\nDESCRIPTION: SQL query to retrieve the latest 5 records from the 'iot_sensor_data' table in RisingWave. This provides a snapshot of the most recent IoT data ingested from the HiveMQ MQTT broker.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/hivemq.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM iot_sensor_data LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Default Emit-on-Update Behavior in SQL\nDESCRIPTION: This SQL snippet demonstrates creating a materialized view `window_count` that calculates a count aggregation over a tumbling window of 1 minute based on the `event_time` column in the `events` table. By default, RisingWave uses the 'emit on update' policy, meaning partial results are emitted frequently as data arrives.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/emit-on-window-close.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW window_count AS\nSELECT window_start, window_end, COUNT(*)\nFROM TUMBLE(events, event_time, INTERVAL '1' MINUTE)\nGROUP BY window_start, window_end;\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW MATERIALIZED VIEWS Command\nDESCRIPTION: Demonstrates how to use the SHOW MATERIALIZED VIEWS command to list all materialized views in a specific schema named 'schema_1'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-mv.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW MATERIALIZED VIEWS FROM schema_1;\n```\n\n----------------------------------------\n\nTITLE: Cloning the RisingWave Repository for Multi-Cluster Dashboard Generation (Bash)\nDESCRIPTION: Clones the risingwave repository, which contains the tools and templates for generating Grafana dashboards to monitor multiple clusters. Needs git and network access. This is preparatory for generating customized dashboard JSON files.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\n```\n\n----------------------------------------\n\nTITLE: SHOW SCHEMAS SQL Command Syntax in RisingWave\nDESCRIPTION: Defines the syntax for the SHOW SCHEMAS command with an optional LIKE expression to filter results by name pattern.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-schemas.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW SCHEMAS [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Moving a Subscription to a Different Schema using SET SCHEMA in SQL\nDESCRIPTION: Shows the syntax for moving an existing subscription (`current_subscription_name`) to a different schema (`schema_name`) using the `SET SCHEMA` clause in the `ALTER SUBSCRIPTION` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION current_subscription_name\n    SET SCHEMA schema_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Append-Only Source in SQL\nDESCRIPTION: This example shows how to create an append-only source using the datagen connector. It includes configurations for generating sequence and random data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE s1_source (\n     seq_id bigint,\n     user_id bigint,\n     user_name varchar)\nWITH (\n     connector = 'datagen',\n     fields.seq_id.kind = 'sequence',\n     fields.seq_id.start = '1',\n     fields.seq_id.end = '10000000',\n     fields.user_id.kind = 'random',\n     fields.user_id.min = '1',\n     fields.user_id.max = '10000000',\n     fields.user_name.kind = 'random',\n     fields.user_name.length = '10',\n     datagen.rows.per.second = '20000'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Altering a Source Structure in RisingWave SQL\nDESCRIPTION: This snippet demonstrates the primary SQL syntax for altering a source in RisingWave. It serves as a template, where 'alter_option' is replaced with specific alterations like adding columns, renaming, changing owner, etc. Prerequisites include an existing source and appropriate user permissions. The snippet does not perform any operation by itself, but provides the basic structure for further alteration commands.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE current_source_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Querying Campaign Performance Materialized View in SQL\nDESCRIPTION: Retrieves the results from the campaign_performance materialized view, showing performance metrics for each campaign.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/marketing-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM campaign_performance LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with SSL Encryption in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Kafka sink with SSL encryption without SASL authentication. It specifies the necessary SSL parameters in the WITH clause of the CREATE SINK statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink1 FROM mv1\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   properties.security.protocol='SSL',\n   properties.ssl.ca.location='/home/ubuntu/kafka/secrets/ca-cert',\n   properties.ssl.certificate.location='/home/ubuntu/kafka/secrets/client_risingwave_client.pem',\n   properties.ssl.key.location='/home/ubuntu/kafka/secrets/client_risingwave_client.key',\n   properties.ssl.key.password='abcdefgh'\n)\nFORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Configuring a Serving Compute Node in TOML\nDESCRIPTION: This TOML configuration example sets up a serving compute node with 16GB of memory. It allocates memory for block and meta caches while minimizing shared buffer and compactor memory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/dedicated-compute-node.mdx#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[storage]\n# Shared buffer is not needed for a serving-only compute node.\nshared_buffer_capacity_mb = 1\n\n# Compactor is irrelevant to a serving-only compute node.\ncompactor_memory_limit_mb = 1\n\n# Allocate 30% of total memory to block cache: 16GB * 0.3 = 4.8GB\nblock_cache_capacity_mb = 4800\n\n# Allocate 10% of total memory to meta cache: 16GB * 0.1 = 1.6GB\nmeta_cache_capacity_mb = 1600\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with EMIT ON WINDOW CLOSE (RisingWave SQL, v1.1 Syntax)\nDESCRIPTION: Demonstrates the legacy syntax for creating a materialized view in RisingWave v1.1 where the EMIT ON WINDOW CLOSE clause precedes the SELECT statement. This code requires a RisingWave database with v1.1 compatibility, and should be updated for newer versions. The main parameter here is the SQL definition for the materialized view, and the output is the successful creation of the view upon execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv\nEMIT ON WINDOW CLOSE\nAS SELECT\n...;\n```\n\n----------------------------------------\n\nTITLE: Using array_max Function in SQL\nDESCRIPTION: Returns the maximum value in an array. Null elements are skipped, but if the array contains only null elements, NULL is returned.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\narray_max ( array ) → type of the elements\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_max(array[3.14, 1.14, 1.14514]) → 3.14\n\narray_max(array[date'2002-10-30', date'2023-09-06', date'2017-06-18']) → 2023-09-06\n\narray_max(array['','']) → empty\n\narray_max(array['a', 'b', NULL, 'c']) → c\n\narray_max(array[NULL]) → NULL\n```\n\n----------------------------------------\n\nTITLE: Viewing Internal Tables for Backfill Executors\nDESCRIPTION: Shows all internal tables in RisingWave, which helps identify the tables related to backfill executors. This step is necessary to find the specific internal table that tracks the backfill process state.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INTERNAL TABLES;\n```\n\n----------------------------------------\n\nTITLE: Configuring UPSERT JSON Format in RisingWave\nDESCRIPTION: SQL syntax for Kafka topics with updates/deletes as key-value pairs in JSON format. RisingWave inserts, updates, or deletes rows based on the key and value pairs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT UPSERT\nENCODE JSON [ (\n   schema.registry = 'schema_registry_url [, ...]',\n   [schema.registry.username = 'username'],\n   [schema.registry.password = 'password']\n) ]\n```\n\n----------------------------------------\n\nTITLE: Including All Supported Fields from Kafka in SQL\nDESCRIPTION: Creates a table that ingests data from Kafka while including all supported additional fields (key, partition, offset, timestamp, header, payload) with custom column names. Uses UPSERT format for handling updates and deletes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE additional_columns (\n  a int,\n  primary key (key_col)\n)\nINCLUDE key AS key_col\nINCLUDE partition AS partition_col\nINCLUDE offset AS offset_col\nINCLUDE timestamp AS timestamp_col\nINCLUDE header AS header_col\nINCLUDE payload AS payload_col\nWITH (\n\tconnector = 'kafka',\n  properties.bootstrap.server = 'message_queue:29092',\n\ttopic = 'kafka_additional_columns')\nFORMAT UPSERT ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Streaming Configuration Example\nDESCRIPTION: Configuration example for streaming settings, including consistency control parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[streaming]\nunsafe_enable_strict_consistency = true\n```\n\n----------------------------------------\n\nTITLE: INCLUDE Clause in CREATE TABLE/SOURCE Statement\nDESCRIPTION: How to use the INCLUDE clause within a CREATE TABLE or CREATE SOURCE statement after the schema definition. This demonstrates the proper placement of the clause in the full SQL statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/extract-metadata-from-sources.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE { SOURCE | TABLE } name (\n    column_name data_type, ...  -- Your regular schema definition\n)\n[INCLUDE ... [AS ...]]\nWITH (\n    connector='...',\n    ...\n)\nFORMAT ... ENCODE ...;\n```\n\n----------------------------------------\n\nTITLE: Querying Hummock Compaction Groups for Write Stalls in SQL\nDESCRIPTION: This SQL query retrieves information about Hummock compaction groups to identify potential write stalls. It selects the group ID, the write stop threshold (`level0StopWriteThresholdSubLevelNumber`), and the `active_write_limit` reason from the `rw_hummock_compaction_group_configs` table, filtering for rows where an `active_write_limit` is currently imposed. An active limit indicates a write stall, typically because the number of Level 0 sub-levels exceeded the configured threshold.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/specific-bottlenecks.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n=> SELECT id,\n          compaction_config->>'level0StopWriteThresholdSubLevelNumber' as write_stop_threshold,\n\t\t\t\t\tactive_write_limit\n   FROM rw_hummock_compaction_group_configs\n   WHERE active_write_limit is not null;\n id | write_stop_threshold |                         active_write_limit\n----+----------------------+---------------------------------------------------------------------\n  3 | 300                  | {\"reason\": \"too many L0 sub levels: 301 > 300\", \"tableIds\": [1001]}\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Getting JSONB Value Type\nDESCRIPTION: Returns the type of the top-level JSON value as a text string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_typeof ('-123.4');\n```\n\n----------------------------------------\n\nTITLE: Creating a Webhook Table with SHA-1 and Raw String Verification\nDESCRIPTION: Demonstrates an alternative way to create a webhook table using SHA-1 and a raw string for signature verification instead of a secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/github-webhook.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook'\n) VALIDATE SECRET test_secret AS secure_compare(\n  headers->>'x-hub-signature',\n  'sha1=' || encode(hmac('TEST_WEBHOOK', data, 'sha1'), 'hex')\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a MongoDB Sink with Dynamic Collection Name in RisingWave\nDESCRIPTION: Example of creating a sink with a dynamic collection name to MongoDB. Demonstrates how to use a field value as the collection name and optionally drop that field from the result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mongodb.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE sink t2_sink FROM t2\nWITH (\n    connector='mongodb',\n    type = 'upsert',\n    mongodb.url = 'mongodb://mongodb:27017/?replicaSet=rs0',\n    collection.name = 'demo.t2',\n    collection.name.field = 'collection_name',\n    collection.name.field.drop = 'true',\n    primary_key='_id'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Multiple Parameter Types\nDESCRIPTION: Demonstrates creating a UDF that handles multiple parameter types including INT, FLOAT, and returns a float value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_sub(INT, FLOAT, INT) returns float language sql as $$select -$1 + $2 - $3$$;\n```\n\n----------------------------------------\n\nTITLE: Creating Read-Only User for Grafana\nDESCRIPTION: SQL statements to create a dedicated read-only user for Grafana to query the database securely.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER grafanareader WITH PASSWORD 'password';\nGRANT SELECT ON MATERIALIZED VIEW metric_avg_30s TO grafanareader;\n```\n\n----------------------------------------\n\nTITLE: Using ASCII Function in SQL\nDESCRIPTION: The ascii() function returns the Unicode code point of the first character of the input string. If the string is empty, it returns NULL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nascii ( input_string ) → int\n```\n\nLANGUAGE: SQL\nCODE:\n```\nascii('RisingWave') → 82\nascii('🌊') → 127754\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with Java JDBC\nDESCRIPTION: Establishes a connection to RisingWave using the PostgreSQL JDBC driver. The code specifies connection parameters including the database URL, user credentials, and SSL settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/java.mdx#2025-04-23_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nimport java.sql.*;\nimport java.util.Properties;\n\npublic class RisingWaveConnect {\n\n    public static void main (String arg[]) throws SQLException{\n        String url = \"jdbc:postgresql://localhost:4566/dev\";\n        Properties props = new Properties();\n        props.setProperty(\"user\", \"root\");\n        props.setProperty(\"password\", \"secret\");\n        props.setProperty(\"ssl\", \"false\");\n        Connection conn = DriverManager.getConnection(url, props);\n\n        //If needed, add the code for issuing queries here.\n        conn.close();\n    }   \n}\n```\n\n----------------------------------------\n\nTITLE: Example: Swapping View Names using ALTER VIEW SWAP WITH in SQL\nDESCRIPTION: Example SQL command demonstrating how to swap the names of two views, `user_profiles` and `guest_profiles`, using the `ALTER VIEW ... SWAP WITH` clause. After execution, `user_profiles` will refer to the original `guest_profiles` view, and vice versa.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Swap the names of the user_profiles view and the guest_profiles view.\nALTER VIEW user_profiles\nSWAP WITH guest_profiles;\n```\n```\n\n----------------------------------------\n\nTITLE: Fetching Data from Subscription Cursor - Insert Result Example\nDESCRIPTION: This SQL snippet shows an example output from fetching data from a RisingWave subscription cursor after an initial insert operation. The result indicates column values, operation type, and change timestamp for consumer verification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nfetch next from cur;\n\n----RESULT\n v1 | v2 | v3 |   op   | rw_timestamp\n----+----+----+--------+--------------\n  1 |  1 |  1 | Insert |\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: SQL FROM Clause Syntax\nDESCRIPTION: The syntax for the FROM clause within a SELECT statement, defining the various forms that from_item can take. This includes tables with aliases, window functions, subqueries, and join operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n    table_name  [ [ AS ] alias [ ( column_alias_list ) ] ]\n    window_type ( table_name, col_name, interval_expression ) [ [ AS ] alias [ ( column_alias_list ) ] ]\n    ( SELECT ) [ [ AS ] alias [ ( column_alias_list ) ] ]\n    from_item join_type from_item [ ON join_condition ]\n```\n\n----------------------------------------\n\nTITLE: KILL Command Syntax for Terminating Processes in RisingWave\nDESCRIPTION: Syntax for the KILL command which allows you to terminate a specific process by its ID after identifying it using SHOW PROCESSLIST.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-processlist.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nKILL process_id;\n```\n\n----------------------------------------\n\nTITLE: Creating Upsert Iceberg Sink from Upsert Source in SQL\nDESCRIPTION: This example shows how to create an upsert Iceberg sink from an upsert source. It includes configurations for specifying the primary key for upserts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK s1_sink FROM s1_table\nWITH (\n    connector = 'iceberg',\n    type = 'upsert',\n    warehouse.path = 's3a://my-iceberg-bucket/path/to/warehouse,\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY},\n    database.name='dev',\n    table.name='table',\n    primary_key='seq_id'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source in RisingWave\nDESCRIPTION: SQL command to create a source in RisingWave for ingesting data from Instaclustr Kafka. It defines the schema for aviation data and specifies Kafka connection properties.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/instaclustr-kafka.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE aviation_source (\n    flight_date VARCHAR,\n    flight_status VARCHAR,\n\n    departure_airport VARCHAR,\n    departure_timezone VARCHAR,\n    departure_iata VARCHAR,\n    departure_icao VARCHAR,\n    departure_terminal VARCHAR,\n    departure_gate VARCHAR,\n    departure_delay VARCHAR,\n    departure_scheduled TIMESTAMP WITH TIME ZONE,\n    departure_estimated TIMESTAMP WITH TIME ZONE,\n    departure_actual TIMESTAMP WITH TIME ZONE,\n    departure_estimated_runway TIMESTAMP WITH TIME ZONE,\n    departure_actual_runway TIMESTAMP WITH TIME ZONE,\n\n    arrival_airport VARCHAR,\n    arrival_timezone VARCHAR,\n    arrival_iata VARCHAR,\n    arrival_icao VARCHAR,\n    arrival_terminal VARCHAR,\n    arrival_gate VARCHAR,\n    arrival_baggage VARCHAR,\n    arrival_delay VARCHAR,\n    arrival_scheduled TIMESTAMP WITH TIME ZONE,\n    arrival_estimated TIMESTAMP WITH TIME ZONE,\n    arrival_actual TIMESTAMP WITH TIME ZONE,\n    arrival_estimated_runway TIMESTAMP WITH TIME ZONE,\n    arrival_actual_runway TIMESTAMP WITH TIME ZONE,\n\n    airline_name VARCHAR,\n    airline_iata VARCHAR,\n    airline_icao VARCHAR,\n\n    flight_number VARCHAR,\n    flight_iata VARCHAR,\n    flight_icao VARCHAR,\n\n    codeshared_airline_name VARCHAR,\n    codeshared_airline_iata VARCHAR,\n    codeshared_airline_icao VARCHAR,\n    codeshared_flight_number VARCHAR,\n    codeshared_flight_iata VARCHAR\n\n) WITH (\n  connector = 'kafka',\n  topic='Insta-topic',\n  properties.bootstrap.server = 'x.x.x.x:9092',\n  scan.startup.mode = 'earliest',\n  properties.sasl.mechanism = 'SCRAM-SHA-256',\n  properties.security.protocol = 'SASL_PLAINTEXT',\n  properties.sasl.username = 'ickafka',\n  properties.sasl.password = 'xxxxxx'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with EMIT ON WINDOW CLOSE (RisingWave SQL, v1.2+ Syntax)\nDESCRIPTION: Shows the current syntax for creating a materialized view in RisingWave from v1.2 onwards, placing EMIT ON WINDOW CLOSE after the SELECT clause. Requires RisingWave v1.2 or later. The essential parameter is the SELECT statement, and the expected output is the creation of a materialized view that emits on window close as per the new specification.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv\nAS SELECT\n...\nEMIT ON WINDOW CLOSE;\n```\n\n----------------------------------------\n\nTITLE: Using hex_to_int256 Function in SQL\nDESCRIPTION: Demonstrates the hex_to_int256 function for converting hexadecimal strings to rw_int256 values, including positive and negative examples.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT hex_to_int256('0xdeadbeef');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT hex_to_int256('0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff01');\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Slice of an Array\nDESCRIPTION: Demonstrates how to retrieve a slice of an array using the array slicing syntax.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT array[1,NULL,2][:3];\n```\n\n----------------------------------------\n\nTITLE: Example of Azure Blob Sink Implementation in RisingWave\nDESCRIPTION: A complete example showing how to create a sink that exports data from table 't' to Azure Blob Storage. The sink is configured as append-only and uses Parquet encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/azure-blob.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK azblob_sink AS SELECT v1\nFROM t\nWITH (\n    connector='azblob',\n    azblob.path = 'test_sink/',\n    azblob.container_name = '<container_name>',\n    azblob.credentials.account_name = '<account_name>',\n    azblob.credentials.account_key = '<account_key>',\n    azblob.endpoint_url = '<endpoint_url>',\n    type = 'append-only',\n)FORMAT PLAIN ENCODE PARQUET(force_append_only=true);\n```\n\n----------------------------------------\n\nTITLE: Extracting Object Keys with jsonb_object_keys\nDESCRIPTION: Function that returns all top-level keys from a JSON object as a set of varchar values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_object_keys('{\"f1\":\"abc\",\"f2\":{\"f3\":\"a\", \"f4\":\"b\"}}'::jsonb);\n```\n\n----------------------------------------\n\nTITLE: Setting Fixed Parallelism for a Table in RisingWave\nDESCRIPTION: This example demonstrates changing a table's parallelism to 8 and viewing the results in the rw_fragments system table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n-- Set to a fixed number.\nALTER TABLE t SET PARALLELISM = 8;\nSELECT fragment_id, parallelism FROM rw_fragments;\n\n------RESULTS\n fragment_id | parallelism\n-------------+-------------\n           1 |           8\n           2 |           8\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: RisingWave Configuration for Nexmark Benchmark\nDESCRIPTION: YAML configuration used for RisingWave during the Nexmark benchmark testing. It specifies memory allocation for various components including block cache, meta cache, compactor, and shared buffer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-benchmarks-stream-processing.mdx#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n[storage]\nblock_cache_capacity_mb = 2048\nmeta_cache_capacity_mb = 512\ncompactor_memory_limit_mb = 2560\nshared_buffer_capacity_mb = 2048\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with psycopg2\nDESCRIPTION: Establishes a basic connection to RisingWave database using psycopg2 driver with default configuration settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg2\n\nconn = psycopg2.connect(host=\"127.0.0.1\", port=4566, user=\"root\", dbname=\"dev\")\n```\n\n----------------------------------------\n\nTITLE: Example: Moving Materialized View Schema in SQL\nDESCRIPTION: Demonstrates how to move the materialized view named `test_materialized_view` into the schema named `test_schema`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Move the materialized view named \"test_materialized_view\" to the schema named \"test_schema\"\nALTER MATERIALIZED VIEW test_materialized_view SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Changing Source Ownership in RisingWave SQL\nDESCRIPTION: This snippet uses the OWNER TO clause to reassign ownership of a source to another user. Both the current source name and the new owner's user identifier are required. Execution requires superuser or owner-level privileges, and only the ownership metadata is affected.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE current_source_name\n    OWNER TO new_user;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the source named \"src\" to user \"user1\"\nALTER SOURCE src OWNER TO user1;\n```\n\n----------------------------------------\n\nTITLE: Setting Subscription Parallelism using SET PARALLELISM in SQL\nDESCRIPTION: Describes the syntax for modifying the degree of parallelism for the streaming job associated with a subscription using `SET PARALLELISM`. The `parallelism_number` parameter can be set to `ADAPTIVE` for dynamic allocation or a fixed integer (where 0 is equivalent to `ADAPTIVE`) to specify a constant number of parallel units.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION subscription_name\nSET PARALLELISM { TO | = } parallelism_number;\n```\n\n----------------------------------------\n\nTITLE: Creating a Secret in RisingWave for RudderStack Webhook Authentication (SQL)\nDESCRIPTION: This SQL command creates a named secret (`test_secret`) within RisingWave's metadata backend. This secret stores a string ('TEST_WEBHOOK') that will be used later to validate incoming webhook requests from RudderStack, ensuring secure communication. Replace 'TEST_WEBHOOK' with a strong, unique secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/rudderstack-webhook.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET test_secret WITH (backend = 'meta') AS 'TEST_WEBHOOK';\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Sink on GCS in SQL\nDESCRIPTION: This snippet demonstrates how to create an Iceberg sink on Google Cloud Storage (GCS) using the 'rest' catalog type. It includes configurations for GCS credentials and catalog details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink_t FROM t WITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = 'true',\n    database.name = 'public',\n    table.name = 't',\n    catalog.name = 'demo',\n    catalog.type = 'rest',\n    catalog.uri = 'http://127.0.0.1:8181',\n    warehouse.path = 'gs://bucket/path',\n    gcs.credential = 'xxxxxxxx'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Cloud Storage as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up Google Cloud Storage as the state store backend for RisingWave. It specifies the GCS bucket, root directory, and credentials for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the Google Cloud Storage state store backend.\n    gcs:\n      # Name of the Google Cloud Storage bucket.\n      bucket: risingwave\n\n      # Root directory of the Google Cloud Storage bucket.\n      root: risingwave\n\n      # Credentials to access the Google Cloud Storage bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: gcs-credentials\n\n        # Key of the service account credentials in the secret.\n        serviceAccountCredentialsKeyRef: ServiceAccountCredentials\n\n        # Optional, set it to true when the credentials can be retrieved.\n        # useWorkloadIdentity: true\n```\n\n----------------------------------------\n\nTITLE: Delaying Execution with pg_sleep_for in SQL\nDESCRIPTION: The pg_sleep_for function is a convenience function that allows specifying sleep time as an interval. It takes an interval as input and delays the execution for the specified duration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\npg_sleep_for ( interval )\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_sleep_for('5 minutes');\n```\n\n----------------------------------------\n\nTITLE: Using array_cat Function in SQL\nDESCRIPTION: Concatenates two arrays with the same data type. For 2-dimensional arrays, the second argument is appended as the last element or the first argument is prepended as the first element.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\narray_cat ( array, array ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_cat(array[66], array[123]) → {66, 123}\n\narray_cat(array[array[66]], array[233]) → {{66}, {233}}\n\narray_cat(array[233], array[array[66]]) → {{233}, {66}}\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF Wrapper for Built-in Function\nDESCRIPTION: This snippet demonstrates creating a SQL UDF that wraps the regexp_replace built-in function with a parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\ncreate function regexp_replace_wrapper(varchar) returns varchar language sql as $$select regexp_replace($1, 'Cat', 'Dog', 'g')$$;\n```\n\n----------------------------------------\n\nTITLE: Revoking View Privileges in SQL\nDESCRIPTION: Syntax for revoking SELECT, INSERT, DELETE, UPDATE, or ALL privileges on specific views or all views in a schema from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {SELECT | INSERT | DELETE | UPDATE | ALL [PRIVILEGES]}\nON {VIEW view_name [, ...]\n    | ALL VIEWS IN SCHEMA schema_name [, ...] }\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Verifying dbt-risingwave plugin installation\nDESCRIPTION: This command checks the installed version of dbt and its plugins. It's used to confirm that the risingwave plugin is successfully installed and recognized by dbt.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndbt --version\n```\n\n----------------------------------------\n\nTITLE: Configuring Debezium Avro Format in RisingWave\nDESCRIPTION: SQL syntax for configuring Debezium Avro format in RisingWave. Schema can be inferred from Schema Registry. The ignore_key parameter can be used to ignore the key part of messages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT DEBEZIUM\nENCODE AVRO (\n    message = 'main_message',\n    schema.registry = 'schema_registry_url [, ...]',\n    [ignore_key = 'true | false']\n)\n```\n\n----------------------------------------\n\nTITLE: SHOW INDEXES Syntax in RisingWave SQL\nDESCRIPTION: The basic syntax for the SHOW INDEXES command, which allows viewing indexes from a particular table with an optional LIKE expression for filtering results by name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-indexes.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INDEXES FROM table_name [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Show CREATE SOURCE Syntax in SQL\nDESCRIPTION: The basic syntax for the SHOW CREATE SOURCE command, which displays the SQL statement that was used to create a specified source. This command is useful for verifying source settings and troubleshooting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-source.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SOURCE source_name;\n```\n\n----------------------------------------\n\nTITLE: Retrieving an Element from an Array of Arrays\nDESCRIPTION: Demonstrates how to select the second element from the array column 'a' in the 'x' table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT a[2] FROM x;\n```\n\n----------------------------------------\n\nTITLE: Configuring Iceberg Engine Connection in SQL\nDESCRIPTION: These SQL commands set the Iceberg engine connection for the current session and system-wide. This configuration is necessary before creating Iceberg tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET iceberg_engine_connection = 'public.conn';\nALTER system SET iceberg_engine_connection = 'public.conn';\n```\n\n----------------------------------------\n\nTITLE: SQL SIMILAR TO Pattern Matching Examples\nDESCRIPTION: Examples demonstrating the usage of SIMILAR TO operator with different patterns and escape characters. Shows basic pattern matching, alternation with grouping, and custom escape character usage.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\n'abc' SIMILAR TO 'a|b|c'                false\n'abc' SIMILAR TO '(a|b|c)+'             true\n'a_b' SIMILAR TO 'a$_b' ESCAPE '$'      true\n```\n\n----------------------------------------\n\nTITLE: Listing Hadoop Configuration Files\nDESCRIPTION: This Bash command lists the Hadoop configuration files in the $HADOOP_HOME/etc/hadoop directory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nls $HADOOP_HOME/etc/hadoop\ncore-site.xml hdfs-site.xml\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with Go\nDESCRIPTION: Establishes a connection to RisingWave database using the pgx driver. Includes error handling and connection cleanup\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/go.mdx#2025-04-23_snippet_1\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n \"context\"\n \"fmt\"\n \"log\"\n\n \"github.com/jackc/pgx/v4\"\n)\n\nfunc main() {\n         // Please replace the placeholders with the actual credentials.\n connStr := \"postgres://USER:PASSWORD@localhost:4566/DATABASE\"\n conn, err := pgx.Connect(context.Background(), connStr)\n if err != nil {\n  log.Fatalf(\"Unable to connect to RisingWave: %v\\n\", err)\n }\n defer conn.Close(context.Background())\n\n fmt.Println(\"Connected to RisingWave\")\n}\n```\n\n----------------------------------------\n\nTITLE: Using AUTHORIZATION in CREATE SCHEMA in SQL\nDESCRIPTION: Shows a group of examples creating schemas with owner assignment via the AUTHORIZATION clause. The first example creates a schema with the name set to the user 'joe' (schema name omitted), assigning ownership to 'joe'. The second creates a schema 'new_schema' owned by 'joe'. Both utilize IF NOT EXISTS to avoid conflicts. The SHOW SCHEMAS command verifies schema creation by listing all schemas. No external dependencies required, but 'joe' should be a valid username. The output is confirmation of creation (CREATE_SCHEMA) and an updated list of existing schemas.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-schema.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a new schema for the user 'joe'. As the schema name is omitted, the schema name is default to the user name 'joe'.\nCREATE SCHEMA IF NOT EXISTS AUTHORIZATION joe;\n\n----RESULT\nCREATE_SCHEMA\n\n-- Create a new schema named 'new_schema', and assign 'joe' as the owner.\nCREATE SCHEMA IF NOT EXISTS new_schema AUTHORIZATION joe;\n\n----RESULT\nCREATE_SCHEMA\n\n-- Display the existing schemas. You will see 'joe' and 'new_schema'.\nSHOW SCHEMAS;\n\n----RESULT\n        Name\n--------------------\n information_schema\n public\n pg_catalog\n joe\n new_schema\n rw_catalog\n(6 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with Bytes Format in SQL\nDESCRIPTION: Creates a RisingWave source `t1` connected to Kafka topic `topic1`. It ingests the raw byte payload of Kafka messages into a single column `id` of type `bytea` without attempting any decoding or parsing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE t1 (id bytea)\nWITH (\n   connector='kafka',\n   topic='topic1',\n   properties.bootstrap.server='localhost:9093',\n) FORMAT PLAIN ENCODE BYTES;\n```\n\n----------------------------------------\n\nTITLE: Querying Ad Performance from Materialized View\nDESCRIPTION: SQL query to retrieve the click-through rate for a specific ad from the materialized view. This demonstrates how to access the real-time CTR metrics calculated by RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ad_ctr WHERE ad_id = 9;\n```\n\n----------------------------------------\n\nTITLE: Fetching Data Blocking with Timeout from Subscription Cursor in RisingWave\nDESCRIPTION: This SQL snippet fetches up to N rows from a subscription cursor with a timeout. The statement waits until either the specified number of rows are available or the timeout duration is reached, returning whatever has been fetched up to that point. Useful for applications that want to block for new data without constant polling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nFETCH NEXT/n FROM cursor_name WITH (timeout = '1s');\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Corner Case\nDESCRIPTION: This snippet demonstrates creating a SQL UDF with a corner case where the function returns a string representation of its parameters instead of performing calculations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ncreate function corner_case(INT, a INT, INT) returns varchar language sql as $$select '$1 + a + $3'$$;\n```\n\n----------------------------------------\n\nTITLE: Configuring Alibaba Cloud OSS as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up Alibaba Cloud OSS as the state store backend for RisingWave. It specifies the OSS region, bucket, and credentials for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the Alibaba Cloud OSS state store backend.\n    aliyunOSS:\n      # Region of the Alibaba Cloud OSS bucket.\n      region: cn-hangzhou\n\n      # Name of the Alibaba Cloud OSS compatible bucket.\n      bucket: risingwave\n\n      # Use internal endpoint or not. Check the following document for details:\n      # https://www.alibabacloud.com/help/en/oss/user-guide/regions-and-endpoints\n      internalEndpoint: false\n\n      # Credentials to access the Alibaba Cloud OSS bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: oss-credentials\n\n        # Key of the access key ID in the secret.\n        accessKeyRef: ACCESS_KEY_ID\n\n        # Key of the secret access key in the secret.\n        secretAccessKeyRef: SECRET_ACCESS_KEY_ID\n```\n\n----------------------------------------\n\nTITLE: Range Function with Numbers Example\nDESCRIPTION: Example demonstrating range() function usage with simple number sequence generation\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM range(1, 4);\n```\n\n----------------------------------------\n\nTITLE: Using array_ndims Function in SQL\nDESCRIPTION: Returns the number of dimensions of the input array, useful for determining if an array is multi-dimensional.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\narray_ndims ( array ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_ndims(array[array[2, 3], array[4, 5]]) → 2\n```\n\n----------------------------------------\n\nTITLE: Updating AWS EKS Kubeconfig\nDESCRIPTION: Command to update the local configuration for kubectl and Helm to access an AWS EKS cluster. This is required only when using AWS EKS.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naws eks update-kubeconfig --name <your_eks_cluster_name>\n```\n\n----------------------------------------\n\nTITLE: Configuring REST Catalog for Iceberg Sink\nDESCRIPTION: Example SQL command for creating an Iceberg sink using the REST catalog, which acts as a proxy to other catalogs like Hive, JDBC, and Nessie. This approach is recommended for using RisingWave with Iceberg tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-iceberg.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK sink_demo_rest FROM t\nWITH (\n    connector = 'iceberg',\n    type = 'append-only',\n    force_append_only = true,\n    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',\n    s3.region = 'ap-southeast-2',\n    s3.access.key = 'xxxx',\n    s3.secret.key = 'xxxx',\n    s3.path.style.access = 'true',\n    catalog.type = 'rest',\n    catalog.uri = 'http://localhost:8181/api/catalog',\n    warehouse.path = 'quickstart_catalog',\n    database.name = 'ns',\n    table.name = 't1',\n    catalog.credential='123456:123456',\n    catalog.scope='PRINCIPAL_ROLE:ALL',\n    catalog.oauth2_server_uri='xxx'\n    catalog.scope='xxx',\n);\n```\n\n----------------------------------------\n\nTITLE: Desired JSON Structure\nDESCRIPTION: Target JSON structure after parsing with struct type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nested\": {\n    \"v1\": 10,\n    \"v2\": \"hello\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a destination table in MySQL\nDESCRIPTION: SQL query to create a 'personnel' table in the 'test_db' database with 'id' and 'name' columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test_db.personnel (\n id integer,\n name varchar(200),\n PRIMARY KEY (id)\n);\n```\n\n----------------------------------------\n\nTITLE: Setting wal_level to logical in Self-hosted PostgreSQL\nDESCRIPTION: Command to configure the PostgreSQL write-ahead logging level to 'logical', which is required for CDC. This enables logical decoding of database changes for replication.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nALTER SYSTEM SET wal_level = logical;\n```\n\n----------------------------------------\n\nTITLE: Retrieving SQL Keywords Information in SQL\nDESCRIPTION: The pg_get_keywords() function returns a collection of records that provide information about the SQL keywords recognized by the server. It includes the keyword, its category code, and a description of the category.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\npg_get_keywords () → setof record ( word text, catcode text, catdesc text)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM pg_get_keywords() LIMIT 1;\n\n----RESULT\n word    | catcode | catdesc\n---------+---------+---------\nABSOLUTE | R       | Reserved\n(1 rows)\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE TABLE Syntax\nDESCRIPTION: The basic syntax for the SHOW CREATE TABLE command in SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-table.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Checking WAL Level in Neon PostgreSQL\nDESCRIPTION: SQL command to verify the Write-Ahead Logging (WAL) level configuration in Neon PostgreSQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW wal_level;\n```\n\n----------------------------------------\n\nTITLE: Checking MySQL Replication Lag\nDESCRIPTION: This SQL command should be run on the MySQL server to check for replication lag. The 'Seconds_Behind_Master' value in the output indicates how far behind RisingWave is in processing changes from MySQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW SLAVE STATUS\\G\n```\n\n----------------------------------------\n\nTITLE: Creating a Dynamic Table in Snowflake for Upsert Results\nDESCRIPTION: SQL command to create a dynamic table in Snowflake that processes the upsert data from RisingWave. This table deduplicates rows and filters based on operation type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE DYNAMIC TABLE user_behaviors\nTARGET_LAG = '1 minute'\nWAREHOUSE = test_warehouse\nAS SELECT *\n   FROM (\n       SELECT *, ROW_NUMBER() OVER (PARTITION BY {primary_key} ORDER BY __row_id DESC) AS dedupe_id\n       FROM t3\n   ) AS subquery\nWHERE dedupe_id = 1 AND (__op = 1 or __op = 3);\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating PostgreSQL Table - SQL\nDESCRIPTION: This snippet creates a 'person' table in PostgreSQL and inserts multiple sample rows for demonstration. The table's schema defines fields for id, name, credit_card, and city, with a primary key on 'id'. This prepares source data to be ingested into RisingWave via CDC. Prerequisites: Accessible PostgreSQL instance with proper credentials and permissions to create tables and insert data. Inputs: explicit SQL statements; Outputs: table and loaded rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/risingwave-as-postgres-fdw.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n---Run in PostgreSQL\\nCREATE TABLE person (\\n  \"id\" int,\\n  \"name\" varchar(64),\\n  \"credit_card\" varchar(200),\\n  \"city\" varchar(200),\\n  PRIMARY KEY (\"id\")\\n);\\n\\nINSERT INTO person VALUES (1001, 'peter white', '1781 2313 8157 6974', 'boise');\\nINSERT INTO person VALUES (1002, 'sarah spencer', '3453 4987 9481 6270', 'los angeles');\\nINSERT INTO person VALUES (1004, 'julie white', '0052 8113 1582 4430', 'seattle');\\nINSERT INTO person VALUES (1005, 'sarah smith', '4591 5419 7260 8350', 'los angeles');\\nINSERT INTO person VALUES (1007, 'walter spencer', '5136 7504 2879 7886', 'los angeles');\\nINSERT INTO person VALUES (1008, 'john abrams', '6064 8548 6057 2021', 'redmond');\\nINSERT INTO person VALUES (1010, 'kate smith', '9474 6887 6463 6972', 'bend');\\nINSERT INTO person VALUES (1011, 'vicky noris', '9959 4034 5717 6729', 'boise');\\nINSERT INTO person VALUES (1012, 'walter jones', '8793 6517 3085 0542', 'boise');\\nINSERT INTO person VALUES (1013, 'sarah walton', '2280 4209 8743 0735', 'kent');\\nINSERT INTO person VALUES (1015, 'vicky jones', '3148 5012 3225 2870', 'los angeles');\\nINSERT INTO person VALUES (1016, 'john walton', '0426 2682 6145 8371', 'seattle');\\nINSERT INTO person VALUES (1017, 'luke jones', '9641 9352 0248 2749', 'redmond');\n```\n\n----------------------------------------\n\nTITLE: Inserting data for grouping function example in SQL\nDESCRIPTION: Inserts sample data into the items_sold table to demonstrate grouping operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO items_sold VALUES ('Foo', 'L', 10),('Foo', 'M', 20),('Bar', 'M', 15),('Bar', 'L', '5');\n```\n\n----------------------------------------\n\nTITLE: Invalid CDC Table Definition with Generated Column Not at End in RisingWave - SQL\nDESCRIPTION: This snippet demonstrates an invalid table definition in RisingWave, where a source column ('name') appears after a generated column ('next_id'). This placement contravenes current RisingWave requirements that all generated columns must come last in the schema. Attempting to execute this statement will trigger an error, serving as a cautionary example for schema design; no output table is created.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n  id integer PRIMARY KEY,\n  next_id int AS id + 1,\n  name varchar,\n  PRIMARY KEY (id)\n) FROM mssql_mydb TABLE 'dbo.person';\n```\n\n----------------------------------------\n\nTITLE: Range Function with Decimal Step\nDESCRIPTION: Example showing range() function usage with decimal numbers and step value\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM range(0.1, 2.1, 0.5);\n```\n\n----------------------------------------\n\nTITLE: Using QUOTE_LITERAL Function with Any Element Input in SQL\nDESCRIPTION: This version of quote_literal() converts the given value to text and then quotes it as a literal to be safely used in an SQL statement, similar to the text input version.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\nquote_literal(value anyelement) → text\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT quote_literal(42.5);\n----RESULT\n'42.5'\n\nSELECT quote_literal('hello'::bytea);\n----RESULT\nE'\\\\x68656c6c6f'\n\nSELECT quote_literal('{\"hello\":\"world\",\"foo\":233}'::jsonb);\n----RESULT\n'{\"foo\": 233, \"hello\": \"world\"}'\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDFs with Mixed Parameters\nDESCRIPTION: This snippet demonstrates creating SQL UDFs with mixed parameters and calling inner SQL UDFs. It includes functions for addition, subtraction, and a wrapper function that combines both operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncreate function add_cs(INT, INT) returns int language sql as $$select $1 + $2$$;\ncreate function sub_cs(INT, INT) returns int language sql as 'select $1 - $2';\n\ncreate function add_sub_mix_wrapper(INT, a INT, INT) returns int language sql as 'select add_cs($1, a) + a + sub_cs(a, $3)';\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW ALL Command in Bash/SQL Client\nDESCRIPTION: This command retrieves and displays all current runtime parameters, their settings, and descriptions within a RisingWave session. It requires access to a running RisingWave instance via a compatible client or shell.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-runtime-parameters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW ALL;\n```\n\n----------------------------------------\n\nTITLE: Updating apt Package List on Debian/Ubuntu\nDESCRIPTION: Updates the apt package list on Debian/Ubuntu systems to ensure the latest package information is available before installing packages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt update\n```\n\n----------------------------------------\n\nTITLE: Creating Embedded JavaScript User-Defined Functions - SQL/JavaScript\nDESCRIPTION: Illustrates the definition of an embedded JavaScript UDF for RisingWave using the CREATE FUNCTION SQL command and inlined JavaScript logic. Requires embedded JavaScript support in the RisingWave installation. The function 'gcd' calculates the greatest common divisor of two integer arguments and returns an integer. Inputs are provided as (a int, b int) and the logic must be valid JavaScript. The code is embedded in double-$ markers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-function.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Embedded JavaScript UDF\nCREATE FUNCTION gcd(a int, b int) RETURNS int LANGUAGE javascript AS $$\n    while (b != 0) {\n        let t = b;\n        b = a % b;\n        a = t;\n    }\n    return a;\n$$;\n```\n\n----------------------------------------\n\nTITLE: Displaying RisingWave Catalogs in SQL\nDESCRIPTION: This SQL command displays the list of relations in RisingWave catalogs, including their schema, name, type, and owner.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\\d\n```\n\n----------------------------------------\n\nTITLE: General Syntax for ALTER FUNCTION in SQL\nDESCRIPTION: This snippet outlines the basic syntax structure for the `ALTER FUNCTION` command in SQL. It requires the function name, its argument types, and an `alter_option` clause (like `SET SCHEMA`) to specify the desired modification. You must own the function to use this command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-function.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER FUNCTION function( argument_type [, ...] )\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Date/Time Values in SQL\nDESCRIPTION: Functions to convert strings to date and timestamp values according to specified formats.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nto_date('05 Dec 2000', 'DD Mon YYYY') → '2000-12-05'\n\nto_timestamp(1262349296.7890123) → '2010-01-01 12:34:56.789012+00:00'\n```\n\n----------------------------------------\n\nTITLE: Including Specific Kafka Header by Key in SQL\nDESCRIPTION: Demonstrates how to include a specific header value from Kafka by providing the header key. This generates a column with a specific naming convention based on the header name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/ingest-additional-fields-with-include-clause.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINCLUDE header 'header_col' [AS kafka_header]\n```\n\n----------------------------------------\n\nTITLE: Creating NATS JetStream Source or Table in RisingWave SQL\nDESCRIPTION: This SQL syntax demonstrates how to create either a SOURCE or a TABLE in RisingWave to ingest data from a NATS JetStream stream. It specifies the connector type as 'nats', provides connection details like 'server_url', 'subject', and 'stream'. Optional parameters cover authentication (username/password, jwt, nkey), connection mode, and delivery options (scan.startup.mode, scan.startup.timestamp.millis). Metadata fields like partition, offset, payload, or subject can be included. The 'FORMAT PLAIN ENCODE data_encode' clause specifies the data format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/nats-jetstream.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE { TABLE | SOURCE} [ IF NOT EXISTS ] source_name\n[ schema_definition ]\n[INCLUDE { partition | offset | payload | subject } [AS <column_name>]]\nWITH (\n   connector='nats',\n   server_url='<your nats server>:<port>', [ <another_server_url_if_available>, ...]\n   subject='<subject>[,<another_subject...]',\n   stream='<stream_name>',\n\n-- optional parameters\n   connect_mode='<connect_mode>',\n   username='<your user name>',\n   password='<your password>',\n   jwt=`<your jwt>`,\n   nkey=`<your nkey>`, ...\n\n-- delivery parameters\n   scan.startup.mode=`<startup_mode>`,\n   scan.startup.timestamp.millis='xxxxx'\n)\nFORMAT PLAIN ENCODE data_encode;\n```\n\n----------------------------------------\n\nTITLE: Pattern Matching with regexp_matches in SQL\nDESCRIPTION: Returns all matches of a POSIX regex pattern as sets of string arrays. Supports back references and lookaround assertions with case sensitivity options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nregexp_matches( input_string, pattern [, optional_flag ] ) → set_of_matched_string[]\n```\n\nLANGUAGE: sql\nCODE:\n```\nregexp_matches('foobarbequebazilbarfbonk', '(b[^b]+)(b[^b]+)') →\n{bar,beque}\n{bazil,barf}\n\nregexp_matches('abcabc', 'Bc', 'i') →\n{bc}\n{bc}\n```\n\n----------------------------------------\n\nTITLE: Defining Primary Key Constraint in CREATE TABLE Statement (SQL)\nDESCRIPTION: Repeated example showing the standard SQL syntax for defining a primary key constraint on the `id` column for `table1` directly within the `CREATE TABLE` statement.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table1 (PRIMARY KEY(id));\n```\n\n----------------------------------------\n\nTITLE: Defining Rust Functions for WebAssembly Module\nDESCRIPTION: This Rust code defines two functions (scalar and table) that can be compiled into a WebAssembly module for use in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nuse arrow_udf::function;\n\n// define a scalar function\n#[function(\"gcd(int, int) -> int\")]\nfn gcd(mut x: i32, mut y: i32) -> i32 {\n    while y != 0 {\n        (x, y) = (y, x % y);\n    }\n    x\n}\n\n// define a table function\n#[function(\"series(int) -> setof int\")]\nfn series(n: i32) -> impl Iterator<Item = i32> {\n    0..n\n}\n```\n\n----------------------------------------\n\nTITLE: Using array_positions Function in SQL\nDESCRIPTION: Returns an array of all subscripts (positions) where the specified element occurs in the array. Positions are 1-based.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\narray_positions ( array, any_compatible ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_positions(array[1,2,3,4,5,6,1,2,3,4,5,6], 4) → {4, 10}\n```\n\n----------------------------------------\n\nTITLE: Creating SQL UDF with Built-in Function\nDESCRIPTION: This snippet demonstrates creating a SQL UDF that calls a built-in function (regexp_replace) without parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\ncreate function call_regexp_replace() returns varchar language sql as $$select regexp_replace('Cat is the cutest animal.', 'Cat', 'Dog', 'g')$$;\n```\n\n----------------------------------------\n\nTITLE: Setting RW_IMPLICIT_FLUSH Configuration Syntax in SQL\nDESCRIPTION: The SQL syntax for enabling or disabling the RW_IMPLICIT_FLUSH configuration option in RisingWave. This setting controls whether data changes are automatically flushed after batch operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-rw-implicit-flush.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET RW_IMPLICIT_FLUSH = { true | false };\n```\n\n----------------------------------------\n\nTITLE: Using first_value function in SQL\nDESCRIPTION: Returns the first value in an ordered set of values, including nulls. Requires ORDER BY clause to make results deterministic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nfirst_value ( expression ORDER BY order_key ) -> same as input type\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with PostgreSQL Client\nDESCRIPTION: Command to connect to the RisingWave cluster using the psql client, specifying the host, port, database, and user credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4567 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Example Usage of SHOW SINKS Command in RisingWave SQL\nDESCRIPTION: Demonstrates a simple usage of the SHOW SINKS command to list all sinks in the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-sinks.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SINKS;\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View with Aggregation in SQL\nDESCRIPTION: Creates a materialized view `m` by selecting `v1` and the sum of `v2` from table `t`, grouped by `v1`. The performance of backfilling this MV can be affected by the data ordering in the source table `t`, especially if `v1` values are randomly ordered, leading to poor cache locality.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate materialized view m as select v1, sum(v2) from t group by v1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Blob Storage as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up Azure Blob Storage as the state store backend for RisingWave. It specifies the Azure Blob endpoint, container, and credentials for access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the Google Cloud Storage state store backend.\n    azureBlob:\n      # Endpoint of the Azure Blob service.\n      endpoint: https://you-blob-service.blob.core.windows.net\n\n      # Working directory root of the Azure Blob service.\n      root: risingwave\n\n      # Container name of the Azure Blob service.\n      container: risingwave\n\n      # Credentials to access the Google Cloud Storage bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: gcs-credentials\n\n        # Key of the account name in the secret.\n        accountNameRef: AccountName\n\n        # Key of the account name in the secret.\n        accountKeyRef: AccountKey\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v2.3.0 in Docker\nDESCRIPTION: Command to run RisingWave version 2.3.0 in standalone mode using Docker. Maps ports 4566 and 5691 to the host.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v2.3.0 standalone\n```\n\n----------------------------------------\n\nTITLE: Advanced WITH ORDINALITY Output Example\nDESCRIPTION: Shows the result of using WITH ORDINALITY with CROSS JOIN, displaying the original array, unnested elements, and their ordinal positions with custom column names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-ordinality-clause.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n   arr   | elts | num\n---------+------+-----\n {a,b,c} | c    |   3\n {a,b,c} | b    |   2\n {a,b,c} | a    |   1\n {d,e}   | e    |   2\n {d,e}   | d    |   1\n```\n\n----------------------------------------\n\nTITLE: Basic FROM Clause Syntax in SQL\nDESCRIPTION: The basic syntax of the FROM clause which can reference one or more tables. When multiple sources are specified, the result is the Cartesian product (cross join) of all sources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/from-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nFROM table_reference [, table_reference [, ...]]\n```\n\n----------------------------------------\n\nTITLE: Querying Runtime Parameters Using SHOW Command in SQL\nDESCRIPTION: This snippet demonstrates the syntax for querying the current value of a specific runtime parameter using the SHOW command in SQL. No external dependencies are required. The key parameter is 'parameter_name', which should be replaced with the desired configuration parameter; the command outputs its current value in the session. The input requires a valid SQL session, and the output is a single-row result containing the parameter value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-runtime-parameters.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW parameter_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Basic Struct Columns\nDESCRIPTION: Examples of creating tables with struct columns containing nested integer values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE x (a STRUCT <b INTEGER, c INTEGER>, d INTEGER);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE y (a STRUCT <b STRUCT<c INTEGER>, d INTEGER>, e VARCHAR);\n```\n\n----------------------------------------\n\nTITLE: Dropping and Renaming Materialized Views in RisingWave - SQL\nDESCRIPTION: This snippet shows the process for migrating an old materialized view to a new schema: it drops the old view (cust_sales) and renames the newly created view (cust_sales_new) to the original name. It assumes the new view already exists and is fully populated. Outputs are changes in object naming and schema update visibility.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDROP MATERIALIZED VIEW cust_sales;\nALTER MATERIALIZED VIEW cust_sales_new RENAME TO cust_sales;\n```\n\n----------------------------------------\n\nTITLE: SHOW COLUMNS Command Syntax in RisingWave SQL\nDESCRIPTION: The syntax for the SHOW COLUMNS command in RisingWave, which allows listing columns from a specified relation with an optional LIKE pattern for filtering results.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-columns.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS FROM relation_name [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Specifying Schema Location When Creating Source (Bash)\nDESCRIPTION: This Bash code snippet demonstrates how to include an external schema location in the source definition via the ROW SCHEMA LOCATION clause. This is required when configuring RisingWave to use external schemas (e.g., Avro or Protobuf) and is typically used within a CREATE SOURCE or TABLE statement. Parameters involve specifying the appropriate URL or S3 path for the schema file.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nROW SCHEMA LOCATION 'location'\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Endpoint in Docker Compose File\nDESCRIPTION: Format for specifying MySQL or MySQL-compatible storage connection details in the Docker Compose configuration file. This includes user credentials, host, port, and database name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n--sql-endpoint mysql://<user>:<password>@<host>:<port>/<db>\n```\n\n----------------------------------------\n\nTITLE: Connecting as OAuth User - psql Bash Command\nDESCRIPTION: This bash snippet demonstrates logging in as the 'test' user (configured for OAuth authentication) using psql. The password parameter will be interpreted as the OAuth token and is sent as plaintext. Requires that the user 'test' exists and is set up for OAuth as per RisingWave documentation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n-- The password here is actually OAuth token, and will be passed with plaintext.\npsql -h localhost -p 4566 -d dev -U test\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with a Primary Key for Optimized Backfilling in SQL\nDESCRIPTION: Defines a table `t` with `v1` as the primary key. This ensures RisingWave stores data ordered by `v1`, improving cache locality and backfilling performance for materialized views that group or order by `v1`, as rows with the same `v1` will be read consecutively.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(v1 int primary key, v2 varchar);\n```\n\n----------------------------------------\n\nTITLE: Installing RisingWave via Script Installation\nDESCRIPTION: Downloads and installs RisingWave using a curl command. This is one of the quickest ways to get RisingWave running on your system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L https://risingwave.com/sh | sh\n```\n\n----------------------------------------\n\nTITLE: Displaying RisingWave Catalog Table in Markdown\nDESCRIPTION: This code snippet represents a markdown table that lists and describes various RisingWave catalogs. It includes relation names and their corresponding descriptions, providing an overview of the system's internal structure and available metadata.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n| Relation Name                         | Description                                                                                                                                                                                                                                                                                                                                                                  |\n| :------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `rw_actors`                           | Contains the available actor IDs, their statuses, and the corresponding fragment IDs, and parallel unit IDs.                                                                                                                                                                                                                                                                 |\n| `rw_actor_id_to_ddl`                  | Contains information about the participants who executed the database schema change operations (DDL) and their corresponding actor IDs. The outputs include actor IDs, fragment IDs, job IDs, schema IDs, DDL types, and names of the affected object.                                                                                                                       |\n| `rw_columns`                          | Contains information about columns of all relations (except sources) in the database, including their names, positions, data types, generation details, and more.                                                                                                                                                                                                            |\n| `rw_connections`                      | Contains details about the connections available in the database, such as their IDs, names, owners, types, and more.                                                                                                                                                                                                                                                         |\n| `rw_databases`                        | Contains information about the databases available in the database, such as the IDs, names, and owners.                                                                                                                                                                                                                                                                      |\n| `rw_depend`                           | Contains the dependency relationships between tables, indexes, views, materialized views, sources, and sinks.                                                                                                                                                                                                                                                                |\n| `rw_ddl_progress`                     | Contains the progress of running DDL statements. You can use this relation to view the progress of running DDL statements. For details, see [Monitor statement progress](/operate/monitor-statement-progress).                                                                                                                                                               |\n| `rw_description`                      | Contains optional descriptions (comments) for each database object. Descriptions can be added with the [COMMENT ON](/sql/commands/sql-comment-on) command and viewed with DESCRIBE or SHOW COLUMNS FROM command.                                                                                                                                                             |\n| `rw_event_logs`                       | Contains information about events, including event IDs, timestamps, event types, and additional information if available.                                                                                                                                                                                                                                                    |\n| `rw_fragment_id_to_ddl`               | Contains information about the database schema change operations (DDL) and their corresponding fragment IDs. The outputs include fragment IDs, job IDs, schema IDs, DDL types, and names of the affected object.                                                                                                                                                             |\n| `rw_fragment_parallelism`             | Contains information about the parallelism configuration at the fragment level, including fragment IDs, parallelism, and more.                                                                                                                                                                                                                                               |\n| `rw_fragments`                        | Contains low-level information about fragments in the database, including fragment IDs, table IDs, and more.                                                                                                                                                                                                                                                                 |\n| `rw_functions`                        | Contains information about functions in the database, including their IDs, names, schema identifiers, types, argument and return data types, programming language, and more.                                                                                                                                                                                                 |\n| `rw_hummock_branched_objects`         | Contains information about branched objects of Hummock (the storage engine in RisingWave), including object IDs, corresponding SST IDs, and compaction group IDs.                                                                                                                                                                                                            |\n| `rw_hummock_checkpoint_version`       | Contains information about the checkpoint version of data in Hummock (the storage engine in RisingWave), including version ID, maximum committed epoch, safe epoch, and compaction group details.                                                                                                                                                                            |\n| `rw_hummock_compact_task_progress`    | Contains information about compaction task status, including compaction group IDs, task IDs, SST-related information, numbers of pending read and write IOs, and more.                                                                                                                                                                                                       |\n| `rw_hummock_compaction_group_configs` | Contains information about the configuration settings for the Hummock compaction groups in the database, including compaction group IDs, parent compaction group IDs, member tables, compaction settings, and active write limits.                                                                                                                                           |\n| `rw_hummock_current_version`          | Contains information about the current version of data in Hummock (the storage engine in RisingWave), including version ID, maximum committed epoch, safe epoch, and compaction group details.                                                                                                                                                                               |\n| `rw_hummock_meta_configs`             | Contains metadata configurations and their values for Hummock (the storage engine in RisingWave).                                                                                                                                                                                                                                                                            |\n| `rw_hummock_pinned_snapshots`         | Contains information about the pinned snapshots in Hummock (the storage engine in RisingWave), including the worker node ID and the minimum pinned snapshot ID.                                                                                                                                                                                                              |\n| `rw_hummock_pinned_versions`          | Contains information about the pinned versions in Hummock (the storage engine in RisingWave), including the worker node ID and the minimum pinned snapshot ID.                                                                                                                                                                                                               |\n| `rw_hummock_sstables`                 | Contains information about the SSTables (Sorted String Tables) used in Hummock (the storage engine in RisingWave).                                                                                                                                                                                                                                                           |\n```\n\n----------------------------------------\n\nTITLE: Example Output: Checking User Roles in PostgreSQL (Bash)\nDESCRIPTION: This snippet shows example output from the `\\du` psql command. It lists database roles and their attributes, demonstrating how to verify if a user (e.g., 'rw') has the required 'Create DB' and 'Replication' attributes for CDC.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndev-# \\du\n                                   List of roles\nRole name |                         Attributes                         | Member of\n-----------+-----------------------------------------------------------+---------\nrw        | Create DB, Replication                                     | {}\npostgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}\n```\n\n----------------------------------------\n\nTITLE: Creating a Rust UDF in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to create a Rust UDF named 'gcd' (greatest common divisor) using the CREATE FUNCTION command in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION gcd(int, int) RETURNS int LANGUAGE rust AS $$\n    fn gcd(mut x: i32, mut y: i32) -> i32 {\n        while y != 0 {\n            (x, y) = (y, x % y);\n        }\n        return x;\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Converting JSON Arrays to Text with jsonb_array_elements_text\nDESCRIPTION: Function that expands a JSON array into text values. Converts array elements to varchar type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_array_elements_text('[\"foo\", \"bar\"]'::jsonb)\n```\n\n----------------------------------------\n\nTITLE: Creating JSON Objects with jsonb_build_object\nDESCRIPTION: Function that builds a JSON object from alternating keys and values. Keys are converted to text and values are converted using to_jsonb.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_build_object('foo', 1, 2, row(3,'bar'));\nSELECT jsonb_build_object(variadic array['foo', '1', '2', 'bar']);\n```\n\n----------------------------------------\n\nTITLE: Setting Adaptive Parallelism for Table\nDESCRIPTION: SQL command to modify a table's scaling policy to adaptive parallelism, which automatically adjusts based on available CPU cores.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t SET PARALLELISM = adaptive;\n```\n\n----------------------------------------\n\nTITLE: Granting All Privileges on All Sources Example (SQL)\nDESCRIPTION: This example grants all privileges to user1 on all sources within the schema1 schema and specifies the grantor with GRANTED BY. Demonstrates how to apply the GRANT command in a practical context. Inputs: schema and user names. Outputs: user1 receives all rights on the specified sources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT ALL PRIVILEGES\nON ALL SOURCES IN SCHEMA schema1\nTO user1 GRANTED BY user;\n```\n\n----------------------------------------\n\nTITLE: Type Cast Syntax in RisingWave SQL\nDESCRIPTION: Shows two equivalent ways to perform type casting in RisingWave SQL: the CAST function and the double-colon shorthand notation. Both convert an expression from one data type to another.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCAST ( expression AS type )\nexpression::type\n```\n\n----------------------------------------\n\nTITLE: Generating Struct Data with RisingWave Data Generator\nDESCRIPTION: Example SQL statement to create a load generator source with a struct column. The struct column 'v1' contains two nested columns 'v2' (integer) and 'v3' (double), both using sequence generation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1 (v1 struct<v2 int, v3 double>)\nWITH (\n     connector = 'datagen',\n     fields.v1.v2.kind = 'sequence',\n     fields.v1.v2.start = '-10',\n     fields.v1.v3.kind = 'sequence',\n     fields.v1.v3.start = '1.5',\n     datagen.rows.per.second = '5'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Sink creation example with Hive catalog for Iceberg\nDESCRIPTION: Example of creating an Iceberg sink that writes to a Hive catalog with HMS endpoint configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/iceberg/write-to-iceberg.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK IF NOT EXISTS hive_sink\nFROM source2\nINTO iceberg (\n    table_name = 'catalog.database.table'\n)\nWITH (\n  hive.metastore = 'thrift://127.0.0.1:9083'\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Avro Map Type Handling in RisingWave\nDESCRIPTION: SQL syntax for ingesting Avro map type into RisingWave map type or jsonb. This applies to DEBEZIUM, UPSERT, or PLAIN formats with AVRO encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT [ DEBEZIUM | UPSERT | PLAIN ] ENCODE AVRO (\n    map.handling.mode = 'map' | 'jsonb'\n)\n```\n\n----------------------------------------\n\nTITLE: Using LOWER Function in SQL\nDESCRIPTION: The lower() function converts the string to all lowercase.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nlower ( input_string ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nlower('TOM') → 'tom'\n```\n\n----------------------------------------\n\nTITLE: Using SHOW VIEWS Command in SQL\nDESCRIPTION: Example of using the SHOW VIEWS command to list all views in the public schema, which in this case returns the view 'v3' created earlier.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-views.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VIEWS FROM public;\n```\n\n----------------------------------------\n\nTITLE: Dropping an Aggregate Function with Full Signature in SQL\nDESCRIPTION: Demonstrates how to drop a specific user-defined aggregate function by providing its name (`function_name`) and the data types of its arguments (`argument_type`). This method is necessary when the function name is not unique within the schema to ensure the correct function is removed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-aggregate.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP AGGREGATE function_name ( argument_type [, ...] );\n```\n\n----------------------------------------\n\nTITLE: Creating Table and View Example in SQL\nDESCRIPTION: Example showing how to create a table 't3' with three integer columns and an appendonly property, followed by creating a view 'v3' that displays the sum of the v2 column from the table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-views.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS t3 (\n    v1 int,\n    v2 int,\n    v3 int)\nWITH (appendonly = 'true');\n\nCREATE VIEW v3 AS SELECT sum(v2) AS sum_v2 FROM t3;\n```\n\n----------------------------------------\n\nTITLE: Configuring S3-compatible Storage as State Backend in RisingWave\nDESCRIPTION: This YAML configuration sets up an S3-compatible storage service as the state store backend for RisingWave. It uses Tencent Cloud Object Store (COS) as an example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  stateStore:\n    # Prefix to objects in the object stores or directory in file system. Default to \"hummock\".\n    dataDirectory: hummock\n\n    # Declaration of the S3 compatible state store backend.\n    s3:\n      # Endpoint of the S3 compatible object storage.\n      #\n      # Here we use Tencent Cloud Object Store (COS) in ap-guangzhou as an example.\n      endpoint: cos.ap-guangzhou.myqcloud.com\n\n      # Region of the S3 compatible bucket.\n      region: ap-guangzhou\n\n      # Name of the S3 compatible bucket.\n      bucket: risingwave\n\n      # Credentials to access the S3 compatible bucket.\n      credentials:\n        # Name of the Kubernetes secret that stores the credentials.\n        secretName: cos-credentials\n\n        # Key of the access key ID in the secret.\n        accessKeyRef: ACCESS_KEY_ID\n\n        # Key of the secret access key in the secret.\n        secretAccessKeyRef: SECRET_ACCESS_KEY\n```\n\n----------------------------------------\n\nTITLE: Viewing System Parameters via SQL - Bash\nDESCRIPTION: This Bash snippet shows how to list all current system parameters in a RisingWave database by executing the SHOW PARAMETERS SQL command, typically from within a psql session. There are no prerequisites beyond having SQL client access, and no parameters need to be provided. The output will display all parameter names, values, and mutability status. Designed for auditing and inspecting the current environment configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-system-parameters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW PARAMETERS;\n```\n\n----------------------------------------\n\nTITLE: Creating RisingWave Pulsar Source/Table with Avro Format (SQL)\nDESCRIPTION: This SQL statement creates a RisingWave source or table named 'source_abc' to read data from a Pulsar topic 'demo_topic'. It uses the 'pulsar' connector, specifies the service URL, OAuth authentication parameters (issuer URL, credentials URL, audience), AWS credentials for accessing resources (like the credentials file), and configures the scan startup mode. The data format is defined as PLAIN ENCODE AVRO, requiring the Avro message definition and the location of the Avro schema file (.avsc).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {TABLE | SOURCE} IF NOT EXISTS source_abc\nWITH (\n   connector='pulsar',\n   topic='demo_topic',\n   service.url='pulsar://localhost:6650/',\n   oauth.issuer.url='https://auth.streamnative.cloud/',\n   oauth.credentials.url='s3://bucket_name/your_key_file.file',\n   oauth.audience='urn:sn:pulsar:o-d6fgh:instance-0',\n   aws.credentials.access_key_id='aws.credentials.access_key_id',\n   aws.credentials.secret_access_key='aws.credentials.secret_access_key',\n   scan.startup.mode='latest',\n   scan.startup.timestamp.millis='140000000'\n) FORMAT PLAIN ENCODE AVRO (\n   message = 'message',\n   schema.location = 'https://demo_bucket_name.s3-us-west-2.amazonaws.com/demo.avsc'\n);\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Hummock Compaction Group Configurations in SQL\nDESCRIPTION: This SQL query retrieves the complete configuration details for all Hummock compaction groups stored in the `rw_hummock_compaction_group_configs` system table. This information is crucial for understanding the current settings applied to compaction processes and is often used in conjunction with other diagnostic queries (like analyzing SSTable distribution) when investigating compaction bottlenecks or performance issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/specific-bottlenecks.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_hummock_compaction_group_configs;\n```\n\n----------------------------------------\n\nTITLE: Using CONCAT Function in SQL\nDESCRIPTION: The concat() function concatenates the arguments. NULL arguments are ignored.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nconcat ( any_input_value_1 [, any_input_value_2 [, ...] ]) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nconcat('Abcde', 2, NULL, 22) → 'Abcde222'\nconcat(variadic array['abcde', '2', NULL, '22']); -> \"abcde222\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Storage Full Error in RisingWave\nDESCRIPTION: This snippet shows an example error message that occurs when the storage backend reaches its minimum free drive threshold. It indicates that the user needs to delete some objects to proceed with operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nError { code: \"XMinioStorageFull\", message: \"Storage backend has reached its minimum free drive threshold. Please delete a few objects to proceed.\" }\n```\n\n----------------------------------------\n\nTITLE: Checking Internal State of Backfill Executor in RisingWave\nDESCRIPTION: SQL command to check the internal state of the backfill executor in RisingWave. This provides information about the progress of historical data ingestion.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM __internal_t3_3_streamcdcscan_4;\n```\n\n----------------------------------------\n\nTITLE: Connecting with tenant identifier in username\nDESCRIPTION: Connect to RisingWave Cloud by prefixing the username with the tenant identifier separated by a semicolon. This solution works with all clients but uses the CleartextPassword authentication method.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connection-errors.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npsql \"postgresql://<tenant identifier>;<username>:@<hostname>:<port>/<database?sslmode=verify-full\"\n```\n\n----------------------------------------\n\nTITLE: Querying Top Hashtags\nDESCRIPTION: SQL query to retrieve the top 10 most frequently used hashtags.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM hot_hashtags\nORDER BY hashtag_occurrences DESC\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Using LTRIM Function in SQL\nDESCRIPTION: The ltrim() function is equal to trim (LEADING). It removes the specified characters from the beginning of the input string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\nltrim ( input_string [, characters ] ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nltrim(' cake ') → 'cake '\nltrim('abcxyzabc', 'cba') → 'xyzabc'\n```\n\n----------------------------------------\n\nTITLE: Using sum function in SQL\nDESCRIPTION: Returns the sum of all non-null input values, or null if no non-null values are provided. Works with numeric types and returns appropriate numeric type based on input.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nsum ( expression )\n```\n\n----------------------------------------\n\nTITLE: Connecting with tenant identifier in hostname\nDESCRIPTION: Connect to RisingWave Cloud by prefixing the hostname with the tenant identifier. This method requires TLS security and client support for SNI routing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connection-errors.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql \"postgresql://<username>:@<tenant identifier>.<hostname>:<port>/<database?sslmode=verify-full\"\n```\n\n----------------------------------------\n\nTITLE: Dropping an Aggregate Function by Name Only in SQL\nDESCRIPTION: Illustrates dropping a user-defined aggregate function using only its name (`function_name`). This simpler method is applicable only if the function name is unique within its schema. It is recommended to use `SHOW FUNCTIONS` to verify uniqueness before using this method.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-aggregate.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP AGGREGATE function_name;\n```\n\n----------------------------------------\n\nTITLE: Setting Configuration Parameters in SQL\nDESCRIPTION: Demonstrates the use of set_config() function to set a configuration parameter. The function allows specifying whether the new value should apply only to the current transaction or the entire session.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nset_config ( setting_name text, new_value text, is_local boolean ) → text\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT set_config('rw_implicit_flush', 'true', false);\n-------\ntrue\n```\n\n----------------------------------------\n\nTITLE: Upgrading RisingWave Image Version\nDESCRIPTION: Commands for upgrading the RisingWave image version and waiting for completion.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkubectl patch risingwave <risingwave-cluster> --type='merge' -p '{\"spec\": {\"image\": \"ghcr.io/risingwavelabs/risingwave:<target-version>\"}}'\n```\n\nLANGUAGE: bash\nCODE:\n```\nkubectl wait --for=condition=Upgrading=false risingwave/<risingwave-cluster>\n```\n\n----------------------------------------\n\nTITLE: SHOW VIEWS Command Result in Bash\nDESCRIPTION: Sample output from the SHOW VIEWS command showing the list of views in the public schema, which includes only the 'v3' view in this example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-views.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nv3\n```\n\n----------------------------------------\n\nTITLE: Creating Table Schema for Sysbench in SQL\nDESCRIPTION: This SQL snippet defines the schema for the 'sbtest' table used in the sysbench benchmark. It includes integer and varchar columns with a primary key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-benchmarks-query.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE sbtest(\n  id INTEGER,\n  k INTEGER,\n  c VARCHAR,\n  pad VARCHAR,\n  PRIMARY KEY (id)\n);\n```\n\n----------------------------------------\n\nTITLE: Example Tumbling Window Join Result with Fares - Bash\nDESCRIPTION: Output display of joined tumbling windows between taxi trip and fare data, showing matching of records on trip ID and window start. Reports window interval, distance, fare amount, and payment status for each joined record.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n window_start        | window_end          | distance | total_fare | payment_status\\n---------------------+---------------------+----------+------------+----------------\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00 | 4        | 8          | COMPLETED\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00 | 6        | 12         | PROCESSING\\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00 | 7        | 15         | COMPLETED\\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00 | 3        | 5          | COMPLETED\\n 2022-07-01 22:04:00 | 2022-07-01 22:06:00 | 2        | 5          | REJECTED\\n 2022-07-01 22:06:00 | 2022-07-01 22:08:00 | 8        | 20         | COMPLETED\n```\n\n----------------------------------------\n\nTITLE: Creating a WebHDFS Sink in SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a sink that writes data to WebHDFS. It includes placeholders for sink name, source, and various connector parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/webhdfs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='webhdfs',\n   connector_parameter = 'value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Exposing Grafana for External Access (Bash)\nDESCRIPTION: Extends local port-forwarding to listen on all network interfaces (0.0.0.0), allowing remote clients to access Grafana. Use this if you need access from hosts other than localhost. Caution: this may expose the service externally, so external firewall or security group restrictions may be needed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkubectl port-forward -n monitoring svc/prometheus-grafana 3000:http-web --address 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Ad Click Event Schema in JSON\nDESCRIPTION: JSON schema for ad click events, including bid_id (matching the impression event) and click_timestamp (when the ad was clicked).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bid_id\": 2439384144522347,\n  \"click_timestamp\": \"2022-05-23T14:12:56Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Example Hopping Window Query Result - Bash\nDESCRIPTION: Sample output for a hopping window aggregation SQL query over taxi trips, displaying each window's start and end, trip counts, and total distance. Used for illustration; not executable.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n window_start        | window_end          | no_of_trips | total_distance\\n---------------------+---------------------+-------------+----------------\\n 2022-07-01 21:59:00 | 2022-07-01 22:01:00 | 1           | 4\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00 | 2           | 10\\n 2022-07-01 22:01:00 | 2022-07-01 22:03:00 | 2           | 9\\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00 | 2           | 10\\n 2022-07-01 22:03:00 | 2022-07-01 22:05:00 | 1           | 7\\n 2022-07-01 22:04:00 | 2022-07-01 22:06:00 | 1           | 2\\n 2022-07-01 22:05:00 | 2022-07-01 22:07:00 | 2           | 10\\n 2022-07-01 22:06:00 | 2022-07-01 22:08:00 | 1           | 8\n```\n\n----------------------------------------\n\nTITLE: Creating a Rust Table Function in RisingWave SQL\nDESCRIPTION: This example shows how to create a table function 'series' in Rust that generates a sequence of numbers from 0 to n-1.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION series(n int) RETURNS TABLE (x int) LANGUAGE rust AS $$\n    fn series(n: i32) -> impl Iterator<Item = i32> {\n        (0..n).into_iter()\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Defining Expression as Column in RisingWave Table\nDESCRIPTION: SQL command to create a RisingWave table with a generated column. The 'next_id' column is dynamically computed based on the 'id' column during data ingestion.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE person (\n  id integer PRIMARY KEY,\n  name varchar,\n  next_id int AS id + 1,\n  PRIMARY KEY (id)\n) FROM mysql_mydb TABLE 'mydb.person';\n```\n\n----------------------------------------\n\nTITLE: Creating JSONB Objects\nDESCRIPTION: Creates JSONB objects from text arrays where adjacent pairs become key-value pairs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\njsonb_object('{a, 1, b, def, c, 3.5}' :: text[])\n```\n\n----------------------------------------\n\nTITLE: Enabling CDC Backfill in MySQL-CDC Connector (RisingWave SQL)\nDESCRIPTION: Sets the cdc_backfill session parameter to 'true' to enable performance optimization for data ingestion in the MySQL-CDC connector. Requires RisingWave with CDC feature enabled, using a supported MySQL source. The input is the command itself, affecting all CDC table backfilling for the duration of the session.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSET cdc_backfill=\"true\";\n```\n\n----------------------------------------\n\nTITLE: Dropping Schemas and Database Sequentially - RisingWave SQL\nDESCRIPTION: This snippet demonstrates the proper sequence for fully deleting a database by first dropping all dependent schemas, followed by the database itself. Required prerequisites include having the correct schema and database names and sufficient privileges. Inputs are schema and database names, and outputs are the removal of schemas and the database without returning errors. This pattern is necessary because RisingWave requires all schemas be dropped before the database itself.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-database.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA rw_db.rw_schema;\nDROP SCHEMA rw_db.public;\nDROP DATABASE rw_db;\n```\n\n----------------------------------------\n\nTITLE: Granting Sink Privileges with SQL GRANT Command (SQL)\nDESCRIPTION: This SQL code grants a user privilege (only SELECT or ALL) on one or more sinks or all sinks in particular schema(s). The only assignable privilege for sinks is SELECT. Required: sink names, schema, and user details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-grant.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT { SELECT | ALL [PRIVILEGES]}\nON {  sink_name [, ...]\n    | ALL SINKS IN SCHEMA schema_name [, ...] }\nTO user_name [WITH GRANT OPTION] [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Equivalent Query without GROUPING SETS in SQL\nDESCRIPTION: Shows an equivalent query to the GROUPING SETS example using UNION ALL, demonstrating how GROUPING SETS simplifies complex grouping operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT customer_id, product_category, SUM(order_amount) AS total_amount\nFROM orders\nGROUP BY customer_id, product_category\nUNION ALL\nSELECT NULL, NULL, SUM(order_amount) AS total_amount\nFROM orders;\n```\n\n----------------------------------------\n\nTITLE: Granting Privileges to PostgreSQL User for CDC\nDESCRIPTION: SQL commands to grant necessary privileges to an existing or new PostgreSQL user for CDC operations. The user needs REPLICATION, LOGIN, and CREATEDB privileges, plus appropriate access to the database and schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- For an existing user:\nALTER USER <username> REPLICATION LOGIN CREATEDB;\n\n-- Or, for a new user:\nCREATE USER <username> REPLICATION LOGIN CREATEDB;\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT CONNECT ON DATABASE <database_name> TO <username>;\nGRANT USAGE ON SCHEMA <schema_name> TO <username>;\nGRANT SELECT ON ALL TABLES IN SCHEMA <schema_name> TO <username>;\nGRANT CREATE ON DATABASE <database_name> TO <username>;\n```\n\n----------------------------------------\n\nTITLE: Creating an Upsert Table in RisingWave\nDESCRIPTION: SQL command to create an upsert table in RisingWave using the datagen connector. This table supports in-place updates and generates test data similar to the append-only source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE s1_table (\n    seq_id integer,\n    user_id integer,\n    user_name varchar)\nWITH (\n    connector ='datagen',\n    fields.seq_id.kind ='sequence',\n    fields.seq_id.start ='1',\n    fields.seq_id.end ='10000000',\n    fields.user_id.kind ='random',\n    fields.user_id.min ='1',\n    fields.user_id.max ='10000000',\n    fields.user_name.kind ='random',\n    fields.user_name.length ='10',\n    datagen.rows.per.second ='20000'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Creating Maps from Separate Key and Value Arrays in SQL\nDESCRIPTION: The map_from_key_values function constructs a map from separate arrays of keys and values. It takes two arrays as input and returns a map.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmap_from_key_values ( array, array ) → map\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_from_key_values(array['key1','key2','key3'], array[1,2,3]) -> {key1:1,key2:2,key3:3}\n```\n\n----------------------------------------\n\nTITLE: Configuring DataDog for RisingWave Metrics Collection\nDESCRIPTION: This YAML configuration shows how to set up DataDog Agent to collect metrics from a RisingWave Cloud project using the OpenMetrics integration. It includes the endpoint configuration and authentication details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/export-metrics.mdx#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ninstances:\n- openmetrics_endpoint: http://{CLOUD_HOST}/api/v1/tenant/{CLUSTER_ID}/metrics\n  namespace: risingwave\n  metrics:\n  - .*\n  auth_type: basic\n  username: {API_KEY}\n  password: {API_SECRET}\n```\n\n----------------------------------------\n\nTITLE: Using CHAR_LENGTH, CHARACTER_LENGTH, LENGTH Functions in SQL\nDESCRIPTION: These functions return the number of characters in the input string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nchar_length ( input_string ) → integer_output\ncharacter_length ( input_string ) → integer_output\nlength ( input_string ) → integer_output\n```\n\nLANGUAGE: SQL\nCODE:\n```\nchar_length('wave') → 4\n```\n\n----------------------------------------\n\nTITLE: Using string_to_array Function in SQL\nDESCRIPTION: Converts a string to an array by splitting on a delimiter. The null_string parameter specifies which substring should be converted to NULL in the resulting array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nstring_to_array ( string, delimiter_string, null_string ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\nstring_to_array('a b c', ' ', 'a') → {NULL,b,c}\n```\n\n----------------------------------------\n\nTITLE: Output of DESCRIBE Command for Auto-Mapped Table in RisingWave - SQL\nDESCRIPTION: This snippet displays the output of the 'DESCRIBE supplier;' command after creating a CDC table using schema auto-mapping. It lists each column name, type, visibility, and constraints such as primary and distribution keys. The output confirms the successful ingestion and mapping of all upstream columns by RisingWave. No input is needed; output serves as a confirmation and data exploration aid.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n       Name        |       Type        | Is Hidden | Description\n-------------------+-------------------+-----------+-------------\n s_suppkey         | bigint            | false     |\n s_name            | character varying | false     |\n s_address         | character varying | false     |\n s_nationkey       | bigint            | false     |\n s_phone           | character varying | false     |\n s_acctbal         | numeric           | false     |\n s_comment         | character varying | false     |\n primary key       | s_suppkey         |           |\n distribution key  | s_suppkey         |           |\n table description | supplier          |           |\n(10 rows)\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE INDEX Command Output in SQL\nDESCRIPTION: Example output from the SHOW CREATE INDEX command, displaying the index name (with schema) and the SQL statement used to create it.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-index.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n    Name     |           Create Sql\n-------------+---------------------------------\n public.idx1 | CREATE INDEX idx1 ON t3(v1, v2)\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Syntax for DROP FUNCTION in SQL\nDESCRIPTION: Defines the syntax for the `DROP FUNCTION` command. It allows removing a user-defined function specified by its name and optionally its argument types. The `IF EXISTS` clause prevents an error if the function doesn't exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION [ IF EXISTS ] function_name [ ( argument_type [, ...] ) ] ;\n```\n\n----------------------------------------\n\nTITLE: Connecting with tenant identifier in options field\nDESCRIPTION: Connect to RisingWave Cloud by specifying the tenant identifier in the options field of the PostgreSQL connection string. Uses URL encoding (%3D) for the equals sign.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connection-errors.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npsql \"postgresql://<username>:@<hostname>:<port>/<database?options=--tenant%3D<tenant identifier>\"\n```\n\n----------------------------------------\n\nTITLE: Executing RECOVER Command and Expected Result in Bash\nDESCRIPTION: This snippet demonstrates the execution of the `RECOVER` command in Bash and indicates the expected output (`RECOVER`) upon successful execution. This forces an immediate ad-hoc recovery within the RisingWave system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-recover.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nRECOVER;\n----RESULT\nRECOVER\n```\n\n----------------------------------------\n\nTITLE: Retrieving RisingWave License Information using SQL\nDESCRIPTION: An SQL query to retrieve detailed license information from RisingWave. This command returns license details including CPU core limits, expiration date, issuer, subscriber, and license tier.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-premium-edition-intro.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT rw_license();\n```\n\n----------------------------------------\n\nTITLE: Using CONCAT_WS Function in SQL\nDESCRIPTION: The concat_ws() function concatenates the arguments with a separator. The first argument is used as the separator and should not be NULL. Other NULL arguments are ignored.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nconcat_ws ( separator_string, any_input-value_1 [, any_input-value_2 [, ...] ]) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nconcat_ws(',', 'Abcde', 2, NULL, 22) → 'Abcde,2,22'\nconcat_ws(',', variadic array['abcde', 2, NULL, 22] :: varchar[]); -> \"abcde,2,22\"\n```\n\n----------------------------------------\n\nTITLE: Checking Persistent Volume Claims\nDESCRIPTION: Command to list persistent volume claims (PVCs) associated with the RisingWave installation. This identifies storage resources that need cleanup.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/uninstall-risingwave-k8s.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get persistentvolumeclaims -l app.kubernetes.io/instance=my-risingwave\n```\n\n----------------------------------------\n\nTITLE: Expected Materialized View Output After Insert (bash/console)\nDESCRIPTION: Shows the expected result from the console after querying 'mv' following the insertion of new rows. No parameters; purely illustrative output. It demonstrates that the aggregates now sum to 15 and 150 respectively.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n v1_sum | v2_sum\n--------+--------\n     15 |    150\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Taxi Trips Example Dataset - Bash\nDESCRIPTION: Example dataset for taxi trips including trip IDs, taxi IDs, completion timestamps, distance, and duration. Provided for context and used as sample input for windowed aggregation queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n trip_id | taxi_id | completed_at         | distance | duration \\n---------+---------+----------------------+----------+----------\\n 1       | 1001    | 2022-07-01 22:00:00  | 4        | 6        \\n 2       | 1002    | 2022-07-01 22:01:00  | 6        | 9        \\n 3       | 1003    | 2022-07-01 22:02:10  | 3        | 5        \\n 4       | 1004    | 2022-07-01 22:03:00  | 7        | 15       \\n 5       | 1005    | 2022-07-01 22:07:00  | 2        | 4        \\n 6       | 1006    | 2022-07-01 22:08:30  | 8        | 17       \n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE INDEX Syntax in SQL\nDESCRIPTION: The basic syntax for the SHOW CREATE INDEX command which requires the index name as a parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE INDEX index_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View with Kafka Timestamp in SQL\nDESCRIPTION: Defines a RisingWave materialized view `v1` based on an existing Kafka source `source_name`. It selects a regular column `col1` along with the virtual column `_rw_kafka_timestamp`, which contains the timestamp associated with the Kafka message.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW v1 AS\nSELECT _rw_kafka_timestamp, col1\nFROM source_name;\n```\n\n----------------------------------------\n\nTITLE: Checking PostgreSQL Recovery Mode in SQL\nDESCRIPTION: Illustrates the use of pg_is_in_recovery() function to check if the PostgreSQL instance is currently in recovery mode.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\npg_is_in_recovery() -> boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_is_in_recovery();\n----RESULT\nt\n```\n\n----------------------------------------\n\nTITLE: Changing Subscription Owner using OWNER TO in SQL\nDESCRIPTION: Shows the syntax for changing the owner of a specified subscription (`current_subscription_name`) to a different user (`new_user`) using the `OWNER TO` clause in the `ALTER SUBSCRIPTION` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SUBSCRIPTION current_subscription_name\n    OWNER TO new_user;\n```\n\n----------------------------------------\n\nTITLE: Example JSON Data Structure for Electric Motor\nDESCRIPTION: This JSON snippet shows the data structure for an electric motor, including various sensor readings and timestamps.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/emqx.mdx#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"machine_id\": \"machine_1\",\n  \"winding_temperature\": 80,\n  \"ambient_temperature\": 40,\n  \"vibration_level\": 1.97,\n  \"current_draw\": 14.43,\n  \"voltage_level\": 50.37,\n  \"nominal_speed\": 4207.69,\n  \"power_consumption\": 646.32,\n  \"efficiency\": 82.88,\n  \"ts\": \"2024-09-09 09:57:51\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave with Docker - Shell Command (Older Version)\nDESCRIPTION: This shell command runs the v1.3.0 version of RisingWave using Docker. It ensures the 'risingwavelabs/risingwave:v1.3.0' image is up to date, enables interactive mode, binds ports 4566 and 5691 between container and host, and initiates the server in 'playground' mode. Docker must be installed and network ports 4566, 5691 must be free. Executing this command sets up RisingWave v1.3.0 for evaluation, development, or testing purposes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.3.0 playground\n```\n\n----------------------------------------\n\nTITLE: Example: Dropping a Column using ALTER TABLE in SQL\nDESCRIPTION: Shows a concrete example of the `ALTER TABLE DROP COLUMN` command. This command removes the column named `fax` from the `employees` table. Note that dropping columns referenced by materialized views, indexes, or generated columns might be restricted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n```sql\n-- Remove a column named \"fax\" from the \"employees\" table\nALTER TABLE employees DROP fax;\n```\n```\n\n----------------------------------------\n\nTITLE: Connecting to Kafka for Stock Trading Analytics in SQL\nDESCRIPTION: This snippet creates a source in RisingWave to ingest real-time stock trade data from a Kafka topic. It defines a schema with symbol, price, and volume fields for stock trades.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE stock_trades (\n  symbol varchar,\n  price double precision,\n  volume double precision\n) WITH (\n  connector='kafka',\n  topic='stock_trades',\n  properties.bootstrap.server='localhost:9092',\n  scan.startup.mode='earliest',\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Calculating Map Length in SQL\nDESCRIPTION: The map_length function returns the number of key-value pairs in a map. It takes a map as input and returns an integer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmap_length ( map ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_length(MAP{1:100,2:200}) -> 2\n```\n\n----------------------------------------\n\nTITLE: Deleting Meta Snapshots\nDESCRIPTION: Command to delete specific meta snapshots using risectl.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nrisectl meta delete-meta-snapshots [snapshot_ids]\n```\n\n----------------------------------------\n\nTITLE: Querying RisingWave Table\nDESCRIPTION: This SQL query selects all records from the RisingWave table 's' that was created to consume data from the MSK topic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM s;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Index in RisingWave SQL\nDESCRIPTION: Example demonstrating how to create a table named 't3' with three integer columns and an index 'idx1' on the first two columns to prepare for the SHOW INDEXES example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-indexes.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS t3 (\n    v1 int,\n    v2 int,\n    v3 int);\n\nCREATE INDEX idx1 ON t3 (v1,v2);\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Sink with PrivateLink Connection in SQL\nDESCRIPTION: Example of creating a Kafka sink using a PrivateLink connection for secure VPC communication, demonstrating how to specify PrivateLink targets and endpoint.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SINK sink2 FROM mv2\nWITH (\n   connector='kafka',\n   properties.bootstrap.server='b-1.xxx.amazonaws.com:9092,b-2.test.xxx.amazonaws.com:9092',\n   topic='msk_topic',\n   privatelink.endpoint='10.148.0.4',\n   privatelink.targets = '[{\"port\": 8001}, {\"port\": 8002}]'\n)\nFORMAT PLAIN ENCODE JSON (\n   force_append_only='true'\n);\n```\n\n----------------------------------------\n\nTITLE: Formatting JSONB Output\nDESCRIPTION: Takes a JSONB value and returns formatted, indented JSON text representation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_pretty('[{\"f1\":1,\"f2\":null}, 2]');\n```\n\n----------------------------------------\n\nTITLE: Taxi Fare Table Example - SQL\nDESCRIPTION: Example table for taxi fare events with trip ID, completion timestamp, total fare, and payment status columns. Used as sample data for demonstrating window join operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\n trip_id | completed_at        | total_fare | payment_status\\n---------+---------------------+------------+----------------\\n 1       | 2022-07-01 22:00:00 | 8          | COMPLETED\\n 2       | 2022-07-01 22:01:00 | 12         | PROCESSING\\n 3       | 2022-07-01 22:02:10 | 5          | COMPLETED\\n 4       | 2022-07-01 22:03:00 | 15         | COMPLETED\\n 5       | 2022-07-01 22:06:00 | 5          | REJECTED\\n 6       | 2022-07-01 22:06:00 | 20         | COMPLETED\n```\n\n----------------------------------------\n\nTITLE: Changing Materialized View Owner Syntax in SQL\nDESCRIPTION: Shows the syntax for changing the owner of a specified materialized view using the `OWNER TO` clause. This change also cascades to related internal objects.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW materialized_view_name\n    OWNER TO new_user;\n```\n\n----------------------------------------\n\nTITLE: Names interpreted as builtins in SQL expressions\nDESCRIPTION: Example showing how certain names like 'user' are interpreted as built-in functions rather than column names in SQL expressions, which can cause unexpected behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/identifiers.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT user; -- This is the builtin `user`.\nSELECT user, avatar FROM t; -- This is also the builtin `user`, rather than a column from the table `t`.\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Source with GCS Configuration\nDESCRIPTION: SQL statement to create an Iceberg source using Google Cloud Storage with REST catalog configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE gcs_iceberg_source\nWITH (\n    connector = 'iceberg',\n    catalog.type = 'rest',\n    catalog.uri = 'http://127.0.0.1:8181',\n    warehouse.path = 'gs://bucket/path',\n    gcs.credential = 'xxxxxxxx',\n    database.name = 'public',\n    table.name = 't',\n);\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Slice from a Multidimensional Array\nDESCRIPTION: Shows how to retrieve the first two elements from a multidimensional array using array slicing.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT array[array[1],array[2],array[3]][-21432315:134124523][1:2];\n```\n\n----------------------------------------\n\nTITLE: Querying Date Truncation (Pre-v1.1.0) in RisingWave SQL\nDESCRIPTION: Demonstrates the behavior of the `date_trunc` function in RisingWave before version 1.1.0 when applied to a `date` type. The function implicitly cast the date to a `timestamp` and returned the truncated timestamp without timezone information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\n            SELECT date_trunc('month', date '2023-03-04');\n\n                    date_trunc\n            ---------------------------\n             2023-03-01 00:00:00\n            (1 row)\n```\n\n----------------------------------------\n\nTITLE: Rendering SQL Command Cards - React JSX\nDESCRIPTION: This snippet renders a CardGroup container with multiple Card components for each SQL command. Each Card specifies properties such as title, icon, iconType, href (documentation link), and a short description, collectively forming a visual index of SQL functionalities. Dependencies include React, a CardGroup and Card UI component library, and access to an icon set. Inputs include props for Card titles, icons, and links; output is a React component tree. This implementation assumes the Card and CardGroup components handle display and layout responsively and requires a React build environment.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n<CardGroup cols={2}>\\n  <Card title=\\\"ALTER CONNECTION\\\" icon=\\\"link\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-connection\\\">\\n    Modify the properties of a connection.\\n  </Card>\\n  <Card title=\\\"ALTER DATABASE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-database\\\">\\n    Modify the properties of a database.\\n  </Card>\\n  <Card title=\\\"ALTER FUNCTION\\\" icon=\\\"function\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-function\\\">\\n    Modify the properties of a function.\\n  </Card>\\n  <Card title=\\\"ALTER INDEX\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-index\\\">\\n    Modify the properties of an index.\\n  </Card>\\n  <Card title=\\\"ALTER MATERIALIZED VIEW\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-materialized-view\\\">\\n    Modify the properties of a materialized view.\\n  </Card>\\n  <Card title=\\\"ALTER SCHEMA\\\" icon=\\\"diagram-project\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-schema\\\">\\n    Modify the properties of a schema.\\n  </Card>\\n  <Card title=\\\"ALTER SINK\\\" icon=\\\"sink\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-sink\\\">\\n    Modify the properties of a sink.\\n  </Card>\\n  <Card title=\\\"ALTER SOURCE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-source\\\">\\n    Modify the properties of a source.\\n  </Card>\\n  <Card title=\\\"ALTER SUBSCRIPTION\\\" icon=\\\"circle-check\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-subscription\\\">\\n    Modify the properties of a subscription.\\n  </Card>\\n  <Card title=\\\"ALTER SWAP\\\" icon=\\\"text-slash\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-swap\\\">\\n    Modify the names between two database objects.\\n  </Card>\\n  <Card title=\\\"ALTER SYSTEM\\\" icon=\\\"gear\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-system\\\">\\n    Modify a server configuration parameter.\\n  </Card>\\n  <Card title=\\\"ALTER TABLE\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-table\\\">\\n    Modify the properties of a table.\\n  </Card>\\n  <Card title=\\\"ALTER USER\\\" icon=\\\"user\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-user\\\">\\n    Modify the properties of a user.\\n  </Card>\\n  <Card title=\\\"ALTER VIEW\\\" icon=\\\"eye\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-alter-view\\\">\\n    Modify the properties of a view.\\n  </Card>\\n  <Card title=\\\"AS CHANGELOG\\\" icon=\\\"clock-rotate-left\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-as-changelog\\\">\\n    Convert stream into an append-only changelog.\\n  </Card>\\n  <Card title=\\\"BEGIN\\\" icon=\\\"play\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-begin\\\">\\n    Start a transaction.\\n  </Card>\\n  <Card title=\\\"CANCEL JOBS\\\" icon=\\\"stop\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-cancel-jobs\\\">\\n    Cancel specific streaming jobs.\\n  </Card>\\n  <Card title=\\\"COMMENT ON\\\" icon=\\\"comment\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-comment-on\\\">\\n    Add comments on tables or columns.\\n  </Card>\\n  <Card title=\\\"COMMIT\\\" icon=\\\"check\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-commit\\\">\\n    Commit the current transaction.\\n  </Card>\\n  <Card title=\\\"CREATE AGGREGATE\\\" icon=\\\"calculator\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-aggregate\\\">\\n    Create a user-defined aggregate function.\\n  </Card>\\n  <Card title=\\\"CREATE CONNECTION\\\" icon=\\\"plug\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-connection\\\">\\n    Create a connection between VPCs.\\n  </Card>\\n  <Card title=\\\"CREATE DATABASE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-database\\\">\\n    Create a new database.\\n  </Card>\\n  <Card title=\\\"CREATE FUNCTION\\\" icon=\\\"code\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-function\\\">\\n    Create a user-defined function.\\n  </Card>\\n  <Card title=\\\"CREATE INDEX\\\" icon=\\\"list-ol\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-index\\\">\\n    Create an index on a column of a table or a materialized view to speed up data retrieval.\\n  </Card>\\n  <Card title=\\\"CREATE MATERIALIZED VIEW\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-mv\\\">\\n    Create a materialized view.\\n  </Card>\\n  <Card title=\\\"CREATE SCHEMA\\\" icon=\\\"folder-tree\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-schema\\\">\\n    Create a new schema.\\n  </Card>\\n  <Card title=\\\"CREATE SECRET\\\" icon=\\\"key\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-secret\\\">\\n    Create a secret to store credentials.\\n  </Card>\\n  <Card title=\\\"CREATE SINK INTO\\\" icon=\\\"arrow-right-to-bracket\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-sink-into\\\">\\n    Create a sink into RisingWave's table.\\n  </Card>\\n  <Card title=\\\"CREATE SINK\\\" icon=\\\"arrow-right-from-bracket\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-sink\\\">\\n    Create a sink.\\n  </Card>\\n  <Card title=\\\"CREATE SOURCE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-source\\\">\\n    Supported data sources and how to connect RisingWave to the sources.\\n  </Card>\\n  <Card title=\\\"CREATE TABLE\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-table\\\">\\n    Create a table.\\n  </Card>\\n  <Card title=\\\"CREATE USER\\\" icon=\\\"user-plus\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-user\\\">\\n    Create a new user account.\\n  </Card>\\n  <Card title=\\\"CREATE VIEW\\\" icon=\\\"eye\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-create-view\\\">\\n    Create a non-materialized view.\\n  </Card>\\n  <Card title=\\\"DELETE\\\" icon=\\\"trash\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-delete\\\">\\n    Remove rows from a table.\\n  </Card>\\n  <Card title=\\\"DESCRIBE\\\" icon=\\\"circle-info\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-describe\\\">\\n    Get information about the columns in a table, source, sink, view, or materialized view.\\n  </Card>\\n  <Card title=\\\"DISCARD\\\" icon=\\\"broom\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-discard\\\">\\n    Discard session state.\\n  </Card>\\n  <Card title=\\\"DROP AGGREGATE\\\" icon=\\\"calculator\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-aggregate\\\">\\n    Drop a user-defined aggregate function.\\n  </Card>\\n  <Card title=\\\"DROP CONNECTION\\\" icon=\\\"link-slash\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-connection\\\">\\n    Remove a connection.\\n  </Card>\\n  <Card title=\\\"DROP DATABASE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-database\\\">\\n    Remove a database.\\n  </Card>\\n  <Card title=\\\"DROP FUNCTION\\\" icon=\\\"code\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-function\\\">\\n    Drop a user-defined function.\\n  </Card>\\n  <Card title=\\\"DROP INDEX\\\" icon=\\\"list-ol\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-index\\\">\\n    Remove an index.\\n  </Card>\\n  <Card title=\\\"DROP MATERIALIZED VIEW\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-mv\\\">\\n    Remove a materialized view.\\n  </Card>\\n  <Card title=\\\"DROP SCHEMA\\\" icon=\\\"folder\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-schema\\\">\\n    Remove a schema.\\n  </Card>\\n  <Card title=\\\"DROP SECRET\\\" icon=\\\"key\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-secret\\\">\\n    Drop a secret.\\n  </Card>\\n  <Card title=\\\"DROP SINK\\\" icon=\\\"arrow-right-from-bracket\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-sink\\\">\\n    Remove a sink.\\n  </Card>\\n  <Card title=\\\"DROP SOURCE\\\" icon=\\\"database\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-source\\\">\\n    Remove a source.\\n  </Card>\\n  <Card title=\\\"DROP TABLE\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-table\\\">\\n    Remove a table.\\n  </Card>\\n  <Card title=\\\"DROP USER\\\" icon=\\\"user-minus\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-user\\\">\\n    Remove a user.\\n  </Card>\\n  <Card title=\\\"DROP VIEW\\\" icon=\\\"eye-slash\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-drop-view\\\">\\n    Drop a view.\\n  </Card>\\n  <Card title=\\\"EXPLAIN\\\" icon=\\\"magnifying-glass-chart\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-explain\\\">\\n    Show the execution plan of a statement.\\n  </Card>\\n  <Card title=\\\"FLUSH\\\" icon=\\\"floppy-disk\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-flush\\\">\\n    Commit pending data changes and persist updated data to storage.\\n  </Card>\\n<Card title=\\\"GRANT\\\" icon=\\\"key\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-grant\\\">\\n    Grant a user privileges.\\n  </Card>\\n  <Card title=\\\"INSERT\\\" icon=\\\"plus\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-insert\\\">\\n    Insert new rows of data into a table.\\n  </Card>\\n  <Card title=\\\"RECOVER\\\" icon=\\\"rotate\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-recover\\\">\\n    Trigger recovery manually.\\n  </Card>\\n  <Card title=\\\"REVOKE\\\" icon=\\\"ban\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-revoke\\\">\\n    Revoke privileges from a user.\\n  </Card>\\n  <Card title=\\\"SELECT\\\" icon=\\\"table-list\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-select\\\">\\n    Retrieve data from a table or a materialized view.\\n  </Card>\\n  <Card title=\\\"SET BACKGROUND_DDL\\\" icon=\\\"gears\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-set-background-ddl\\\">\\n    Run Data Definition Language (DDL) operations in the background.\\n  </Card>\\n  <Card title=\\\"SET RW_IMPLICIT_FLUSH\\\" icon=\\\"floppy-disk\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-set-rw-implicit-flush\\\">\\n    Enable or disable implicit flushes after batch operations.\\n  </Card>\\n  <Card title=\\\"SET TIME ZONE\\\" icon=\\\"clock\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-set-time-zone\\\">\\n    Set time zone.\\n  </Card>\\n  <Card title=\\\"SET\\\" icon=\\\"sliders\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-set\\\">\\n    Change a run-time parameter.\\n  </Card>\\n  <Card title=\\\"SHOW CLUSTER\\\" icon=\\\"server\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-show-cluster\\\">\\n    Show the details of your RisingWave cluster.\\n  </Card>\\n  <Card title=\\\"SHOW COLUMNS\\\" icon=\\\"table-columns\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-show-columns\\\">\\n    Show columns in a table, source, sink, view or materialized view.\\n  </Card>\\n  <Card title=\\\"SHOW CONNECTIONS\\\" icon=\\\"network-wired\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-show-connections\\\">\\n    Show existing connections.\\n  </Card>\\n  <Card title=\\\"SHOW CREATE INDEX\\\" icon=\\\"list-ol\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-show-create-index\\\">\\n    Show the query used to create the specified index.\\n  </Card>\\n  <Card title=\\\"SHOW CREATE MATERIALIZED VIEW\\\" icon=\\\"table\\\" iconType=\\\"solid\\\" href=\\\"/sql/commands/sql-show-create-mv\\\">\\n    Show the query used to create the specified materialized view.\\n  </Card>\\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Restoring Meta Snapshot with etcd Backend\nDESCRIPTION: Command to restore a meta snapshot when using etcd as the meta store backend.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nrisectl \\\nmeta \\\nrestore-meta \\\n--meta-store-type etcd \\\n--meta-snapshot-id [snapshot_id] \\\n--etcd-endpoints [etcd_endpoints, e.g. 127.0.0.1:2388] \\\n--backup-storage-url [backup_storage_url, e.g. s3://bucket_read_from] \\\n--backup-storage-directory [backup_storage_directory, e.g. dir_read_from] \\\n--hummock-storage-url [hummock_storage_url, e.g. s3://bucket_write_to] \\\n--hummock-storage-directory [hummock_storage_directory, e.g. dir_write_to]\n```\n\n----------------------------------------\n\nTITLE: Docker Command to Run RisingWave\nDESCRIPTION: Command to run RisingWave v1.0.0 from Docker in playground mode, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.0.0 playground\n```\n\n----------------------------------------\n\nTITLE: Querying Current Timestamp in SQL\nDESCRIPTION: Returns the current date and time as a timestamptz value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncurrent_timestamp() → `2023-09-06 07:06:46.724+00:00`\n```\n\n----------------------------------------\n\nTITLE: Creating Risk Summary Materialized View in SQL\nDESCRIPTION: Creates a materialized view that summarizes the number of positions in each risk category (High, Medium, Low) to provide an overview of overall risk exposure.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW risk_summary AS\nSELECT\n    risk_level,\n    COUNT(*) AS position_count\nFROM\n    position_overview\nGROUP BY\n    risk_level;\n```\n\n----------------------------------------\n\nTITLE: Example Output from SHOW CREATE MATERIALIZED VIEW Command in SQL\nDESCRIPTION: Example result set returned by the SHOW CREATE MATERIALIZED VIEW command, showing the name and creation SQL for the materialized view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-mv.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n   Name    |                 Create Sql\n-----------+---------------------------------------------\n public.v1 | CREATE MATERIALIZED VIEW v1 AS SELECT id FROM taxi_trips\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Rolling Back RisingWave Version\nDESCRIPTION: Command to roll back RisingWave to a previous version in case of issues during upgrade.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl patch risingwave <risingwave-cluster> --type='merge' -p '{\"spec\": {\"image\": \"ghcr.io/risingwavelabs/risingwave:<version-before>\"}}'\n```\n\n----------------------------------------\n\nTITLE: Increasing Cluster Limits via Meta Developer Configuration in Bash/TOML\nDESCRIPTION: This configuration snippet, typically part of a TOML file accessed or modified via Bash commands, demonstrates how to increase the soft and hard limits for the number of actors allowed per worker parallelism in the RisingWave meta node. Setting these values overrides the default limits.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/cluster-limit.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[meta.developer]\nmeta_actor_cnt_per_worker_parallelism_soft_limit = 100\nmeta_actor_cnt_per_worker_parallelism_hard_limit = 400\n```\n\n----------------------------------------\n\nTITLE: Checking MySQL Binary Log Status (Initial)\nDESCRIPTION: SQL command to check the current status of the binary log (`log_bin`) variable in MySQL before enabling it. The example output shows the variable is `OFF`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'log_bin';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| log_bin       | OFF   |\n+---------------+-------+\n```\n\n----------------------------------------\n\nTITLE: Renaming a Source in RisingWave SQL\nDESCRIPTION: These snippets show how to rename an existing source using the RENAME TO clause in RisingWave SQL. The existing source name and the new desired name must be specified. Renaming is restricted to non-primary key modifications and requires appropriate privileges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-source.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER SOURCE source_name\n    RENAME TO new_source_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of a source named \"src\" to \"src1\"\nALTER SOURCE src\n   RENAME TO src1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection in Python\nDESCRIPTION: Sets up the database connection parameters for connecting to RisingWave using psycopg2 library in Python.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-data-enrichment.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndefault_params = {\n    \"dbname\": \"dev\",\n    \"user\": \"root\",\n    \"password\": \"\",\n    \"host\": \"localhost\",\n    \"port\": \"4566\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying RisingWave Catalog Tables in SQL\nDESCRIPTION: This SQL query retrieves specific columns from the rw_tables catalog, showing how to access metadata about tables in the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name, owner, definition FROM rw_tables;\n```\n\n----------------------------------------\n\nTITLE: Installing the Monitoring Stack for RisingWave (Bash)\nDESCRIPTION: Runs a provided installation script to deploy Prometheus, Grafana, and related monitoring components into a dedicated Kubernetes namespace (monitoring). The script is executed from the monitoring folder inside the previously cloned operator repository. Prerequisites include access to a Kubernetes cluster and execute permissions for the script. It creates the monitoring namespace and required services, outputting deployment progress/errors.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./monitoring/install.sh\n```\n\n----------------------------------------\n\nTITLE: Creating a Kubernetes Namespace for RisingWave\nDESCRIPTION: Command to create a dedicated Kubernetes namespace for RisingWave resources, which helps with organization and resource management.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create namespace risingwave\n```\n\n----------------------------------------\n\nTITLE: Checking Index Column Properties in SQL\nDESCRIPTION: The pg_index_column_has_property() function checks if an index column has a specific property. It takes the index OID, column number, and property name as parameters and returns a boolean result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\npg_index_column_has_property ( index regclass, column integer, property text ) → boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table named 't' with columns 'a' and 'b' of type INT\nCREATE TABLE t (a INT, b INT);\n\n-- Create an index named 'i' on table 't' with column 'a' in ascending order and column 'b' in descending order\nCREATE INDEX i ON t (a ASC, b DESC);\n\n-- Check if the first column of index 'i' has the 'ASC' property\nSELECT pg_index_column_has_property('i'::REGCLASS, 1, 'ASC');\n----RESULT\nt\n\n-- Check if the first column of index 'i' has the 'DESC' property\nSELECT pg_index_column_has_property('i'::REGCLASS, 1, 'DESC');\n----RESULT\nf\n```\n\n----------------------------------------\n\nTITLE: Declaring Subscription Cursor in SQL\nDESCRIPTION: Demonstrates the updated syntax for declaring a subscription cursor, which now defaults to consuming data from the current time. The FULL option is introduced to start consuming from stock data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nDECLARE cursor_name SUBSCRIPTION CURSOR\n```\n\nLANGUAGE: SQL\nCODE:\n```\nDECLARE cursor_name SUBSCRIPTION CURSOR FULL\n```\n\n----------------------------------------\n\nTITLE: Installing Specific RisingWave Version Using Helm\nDESCRIPTION: Command to install a specific version of RisingWave using the image.tag parameter. Replace <version_number> with the desired version, such as v1.7.0.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhelm install -n risingwave --create-namespace --set wait=true --set image.tag=<version_number> <my-risingwave> -f values.yaml risingwavelabs/risingwave\n```\n\n----------------------------------------\n\nTITLE: Querying the Materialized View\nDESCRIPTION: SQL query to retrieve all records from the high_util_tcp_metrics materialized view, which contains the average TCP metrics for devices with high bandwidth utilization.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM high_util_tcp_metrics;\n```\n\n----------------------------------------\n\nTITLE: Helm Deployment Output Example\nDESCRIPTION: Example output from a successful RisingWave Helm deployment, showing the deployment name, namespace, status, and revision.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nNAME: my-risingwave\nLAST DEPLOYED: Wed Aug 16 15:35:19 2023\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave via PostgreSQL Client\nDESCRIPTION: Command to connect to the RisingWave instance using the PostgreSQL client (psql). This establishes a connection to manage data streams and perform data analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Performing Random Point Selects in SQL\nDESCRIPTION: This SQL query is part of the 'select_random_points' workload. It selects multiple columns for 10 random points based on the 'k' values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-benchmarks-query.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, k, c, pad FROM sbtest WHERE k IN (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n```\n\n----------------------------------------\n\nTITLE: SWAP WITH Example in RisingWave SQL\nDESCRIPTION: This example demonstrates swapping the names of the 'products' table and the 'inventory' table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n-- Swap the names of the products table and the inventory table.\nALTER TABLE products\nSWAP WITH inventory;\n```\n\n----------------------------------------\n\nTITLE: Applying MySQL Privilege Changes\nDESCRIPTION: SQL command to reload the grant tables in MySQL, ensuring that the newly granted privileges for the replication user take effect immediately without restarting the server.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nFLUSH PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Example Tumbling Window Join Result - SQL\nDESCRIPTION: Sample output from joining tumbling windowed trip records with company dimension, displaying window times, trip distances, and company name. Used for demonstrating SQL join result format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n window_start        | window_end          | distance | company\\n---------------------+---------------------+----------+------------\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00 | 6        | SAFE TAXI\\n 2022-07-01 22:00:00 | 2022-07-01 22:02:00 | 4        | SUPER TAXI\\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00 | 3        | FAST TAXI\\n 2022-07-01 22:02:00 | 2022-07-01 22:04:00 | 7        | BEST TAXI\\n 2022-07-01 22:04:00 | 2022-07-01 22:06:00 | 2        | WEST TAXI\\n 2022-07-01 22:06:00 | 2022-07-01 22:08:00 | 8        | EAST TAXI\n```\n\n----------------------------------------\n\nTITLE: Example: Renaming a Subscription in SQL\nDESCRIPTION: Provides a concrete example of renaming the subscription \"sub0\" to \"sub1\" using the `ALTER SUBSCRIPTION ... RENAME TO` command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Rename the subscription named \"sub0\" to \"sub1\"\nALTER SUBSCRIPTION sub0 RENAME TO sub1;\n```\n\n----------------------------------------\n\nTITLE: General Syntax for ALTER SINK in SQL\nDESCRIPTION: Provides the basic syntax structure for the `ALTER SINK` command. The `alter_option` specifies the specific modification to be performed on the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Example: Revoking Source Privileges in SQL\nDESCRIPTION: Example showing how to revoke all privileges for all sources in a schema from a user, specifying the user granting the privileges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE ALL PRIVILEGES\nON ALL SOURCES IN SCHEMA schema1\nFROM user1 GRANTED BY user;\n```\n\n----------------------------------------\n\nTITLE: Declaring file_scan Function Signature in SQL\nDESCRIPTION: Defines the signature of the file_scan table function, which is used to read files (such as Parquet) from various storage backends including S3. This signature indicates the required parameters: file format, storage type, S3 region, S3 access and secret keys, and the file or directory location. This function is a core part of reading external Parquet data into RisingWave tables and requires appropriate IAM credentials and S3 access.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/s3.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nfile_scan(file_format, storage_type, s3_region, s3_access_key, s3_secret_key, file_location_or_directory)\n```\n\n----------------------------------------\n\nTITLE: Implementing GCD Scalar Function\nDESCRIPTION: Example implementation of a scalar function that calculates the greatest common divisor of two integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport com.risingwave.functions.ScalarFunction;\n\npublic class Gcd implements ScalarFunction {\n    public int eval(int a, int b) {\n        while (b != 0) {\n            int temp = b;\n            b = a % b;\n            a = temp;\n        }\n        return a;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Valid and Invalid SQL Temporal Filter Syntax with OR Operator\nDESCRIPTION: Provides examples demonstrating the constraints of using the OR operator with temporal filters in SQL. A temporal filter can be disjoined with a non-temporal condition (like IS NULL or a comparison on another column), but not directly with another temporal filter. Also illustrates an invalid case where a complex OR condition mixes temporal and non-temporal filters within parentheses.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Valid\nt > NOW() - INTERVAL '1 hour' OR t IS NULL OR a < 1\n\n-- Invalid\nt > NOW() - INTERVAL '1 hour' OR t < NOW() - INTERVAL '1 hour'\n\n-- Invalid\n(a < 1) OR (t > NOW() - INTERVAL '1 hour' AND t < NOW() - INTERVAL '1')\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Topic with SASL Authentication\nDESCRIPTION: This bash command creates a new Kafka topic using the Kafka topics script. It specifies the broker URL, SASL properties file, and the desired topic name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nbin/kafka-topics.sh --bootstrap-server <broker-url> --command-config ~/client_sasl.properties --create --topic <topic-name>\n```\n\n----------------------------------------\n\nTITLE: Querying Iceberg Data with Time Travel\nDESCRIPTION: Examples of using the time travel feature to query Iceberg data from a specific point in time or version, using either a timestamp or a snapshot ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n-- Querying data using a timestamp\nSELECT * FROM s FOR SYSTEM_TIME AS OF '2100-01-01 00:00:00+00:00';\nSELECT * FROM s FOR SYSTEM_TIME AS OF 4102444800;\n\n-- Querying data using a version identifier\nSELECT * FROM s FOR SYSTEM_VERSION AS OF 3023402865675048688;\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Table with DML Insert Statements\nDESCRIPTION: This example demonstrates creating a table and inserting multiple rows of data using DML statements. It shows how to load batch data directly into RisingWave without using external connectors.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE website_visits (\n  timestamp timestamp with time zone,\n  user_id varchar,\n  page_id varchar,\n  action varchar\n);\n\nINSERT INTO website_visits (timestamp, user_id, page_id, action) VALUES\n  ('2023-06-13T10:00:00Z', 'user1', 'page1', 'view'),\n  ('2023-06-13T10:01:00Z', 'user2', 'page2', 'view'),\n  ('2023-06-13T10:02:00Z', 'user3', 'page3', 'view'),\n  ('2023-06-13T10:03:00Z', 'user4', 'page1', 'view'),\n  ('2023-06-13T10:04:00Z', 'user5', 'page2', 'view');\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN CSV Format in RisingWave\nDESCRIPTION: SQL syntax for consuming data in CSV format. Options include delimiter for specifying the field separator and without_header to indicate if the CSV has a header row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE CSV (\n    delimiter = 'delimiter',\n    without_header = 'false' | 'true'\n)\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v1.10.0 from Docker\nDESCRIPTION: Command to pull and run RisingWave version 1.10.0 in standalone mode with ports 4566 and 5691 exposed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.10.0 single_node\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus for RisingWave Metrics Collection\nDESCRIPTION: This YAML configuration snippet shows how to set up Prometheus to scrape metrics from a RisingWave Cloud project. It includes settings for authentication, target endpoints, and scrape intervals.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/export-metrics.mdx#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nscrape_configs:\n- job_name: risingwave-remote\n  static_configs:\n  - targets:\n    - {CLOUD_HOST}\n  metrics_path: /api/v1/tenant/{CLUSTER_ID}/metrics\n  basic_auth:\n    username: {API_KEY}\n    password: {API_SECRET}\n  scrape_interval: 60s\n  scrape_timeout: 60s\n  scheme: https\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Database User Name in SQL\nDESCRIPTION: The user function returns the name of the current database user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nuser → *user_name*\nuser() → *user_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT user(); → `root`\n```\n\n----------------------------------------\n\nTITLE: Generating Series with Negative Steps in SQL\nDESCRIPTION: Example showing how the generate_series function supports negative step values to generate a descending sequence of numbers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM generate_series(5,1,-2);\n    generate_series\n    -----------------\n                5\n                3\n                1\n    (3 rows)\n```\n\n----------------------------------------\n\nTITLE: Displaying PostgreSQL and RisingWave Versions in SQL\nDESCRIPTION: The version() function displays the PostgreSQL version and the RisingWave version implemented in the current instance of RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT version ();\n---------RESULT\n version\n-----------------\n PostgreSQL 8.3-RisingWave-1.0.0-alpha (76672d87cf5c20aa8fbb6f11996ef15255443b51)\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Generating Self-Signed SSL Certificate\nDESCRIPTION: OpenSSL command to generate a self-signed certificate and private key valid for 365 days, suitable for testing environments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/secure-connections-with-ssl-tls.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -x509 -sha256 -nodes -newkey rsa:2048 -days 365 -keyout localhost.key -out localhost.crt\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with SSL using psql\nDESCRIPTION: Command to establish a secure SSL connection to RisingWave using psql client with verify-full SSL mode.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/secure-connections-with-ssl-tls.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npsql -p 4566 -d dev -h localhost -U root --set=sslmode=verify-full\n```\n\n----------------------------------------\n\nTITLE: Iceberg Time Travel Query Examples\nDESCRIPTION: Examples of time travel queries in Iceberg tables, demonstrating various formats including timestamps with and without timezone, Unix timestamps, and snapshot IDs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg-config.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM s FOR SYSTEM_TIME AS OF '2100-01-01 00:00:00+00:00'; -- Example with timezone offset\nSELECT * FROM s FOR SYSTEM_TIME AS OF '2024-04-10 12:34:56'; -- Example without timezone (local time)\nSELECT * FROM s FOR SYSTEM_TIME AS OF 4102444800; -- Example with Unix timestamp\nSELECT * FROM s FOR SYSTEM_VERSION AS OF 3023402865675048688; -- Example with Snapshot ID\n```\n\n----------------------------------------\n\nTITLE: Setting Backfill Rate Limits in RisingWave\nDESCRIPTION: These examples show how to: pause backfilling by setting the limit to 0, set a specific backfill rate limit of 1000, and disable the backfill rate limit by setting it to DEFAULT.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\n-- Pause the backfill\nALTER TABLE t1 SET BACKFILL_RATE_LIMIT=0;\n\n-- Alter backfill rate limit\nALTER TABLE t1 SET BACKFILL_RATE_LIMIT=1000;\n\n-- Disable the backfill rate limit\nALTER TABLE t1 SET BACKFILL_RATE_LIMIT=DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Renaming a Sink using ALTER SINK in SQL\nDESCRIPTION: Shows how to change the name of an existing sink using the `RENAME TO` clause. The `new_name` parameter specifies the desired new name for the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\n    RENAME TO new_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of the sink named \"sink0\" to \"sink1\"\nALTER SINK sink0 RENAME TO sink1;\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v1.9.1 Docker Container\nDESCRIPTION: Command to run the RisingWave v1.9.1 standalone version using Docker. This sets up a single-node instance and exposes ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.9.1-standalone single_node\n```\n\n----------------------------------------\n\nTITLE: New Syntax for Specifying Data Format Part 1\nDESCRIPTION: The new syntax for specifying data and encoding formats for sources in CREATE SOURCE and CREATE TABLE commands. This shows the first part with the new FORMAT and ENCODE keywords.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT data_format ENCODE data_encode (\nmessage = 'message',\nschema.location = 'location' | schema.registry = 'schema_registry_url'\n);\n```\n\n----------------------------------------\n\nTITLE: REFRESH SCHEMA Example in RisingWave SQL\nDESCRIPTION: This example demonstrates refreshing the schema of a table named 't_user'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\n-- Refresh the schema of the table named \"t_user\".\nALTER TABLE t_user REFRESH SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response from RisingWave License Query\nDESCRIPTION: Sample JSON output showing license details returned by the rw_license() function. The response includes information about CPU core limits, expiration timestamp, issuer domain, subscriber name, and license tier type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-premium-edition-intro.mdx#2025-04-23_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\"cpu_core_limit\": null, \"exp\": 9999999999, \"iss\": \"test.risingwave.com\", \"sub\": \"rw-test\", \"tier\": \"paid\"}\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up RisingWave Docker Environment\nDESCRIPTION: Optional Docker Compose command to remove the containers and volumes created for the RisingWave environment, cleaning up all generated data and resources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/real-time-ad-performance-analysis.mdx#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Validating RisingWave Instance Status in Kubernetes\nDESCRIPTION: This command checks the status of the RisingWave instance in Kubernetes. It displays information about the running state, storage types for metadata and objects, and the age of the instance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get risingwave\n```\n\nLANGUAGE: bash\nCODE:\n```\nNAME        RUNNING   STORAGE(META)   STORAGE(OBJECT)   AGE\nrisingwave  True      postgresql      S3                30s\n```\n\n----------------------------------------\n\nTITLE: Compiling a Protobuf Schema File for RisingWave\nDESCRIPTION: Bash command to compile a .proto file into a FileDescriptorSet for use with RisingWave's Protobuf format. The compiled schema.pb file is then referenced in the schema.location parameter.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nprotoc -I=$include_path --include_imports --descriptor_set_out=schema.pb schema.proto\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: Command to connect to the RisingWave database using psql client.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Creating Positions Table in SQL for Sports Betting Data\nDESCRIPTION: Creates a table to track key details about betting positions including stake amount, expected return, fair value, and market odds to assess risk and performance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE positions (\n    position_id INT,\n    league VARCHAR,\n    position_name VARCHAR,\n    timestamp TIMESTAMPTZ,\n    stake_amount FLOAT,\n    expected_return FLOAT,\n    max_risk FLOAT,\n    fair_value FLOAT,\n    current_odds FLOAT,\n    profit_loss FLOAT,\n    exposure FLOAT\n);\n```\n\n----------------------------------------\n\nTITLE: Example: Swapping Materialized View Names with ALTER SWAP in SQL\nDESCRIPTION: This example demonstrates the practical application of the `ALTER ... SWAP` command in RisingWave SQL. It specifically shows how to swap the names of two materialized views, `historical_sales` and `current_sales`. This assumes both materialized views exist prior to executing the command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-swap.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW historical_sales\nSWAP WITH current_sales;\n```\n\n----------------------------------------\n\nTITLE: Inserting Values with an Array Column\nDESCRIPTION: Shows how to insert a row into the 'taxi' table, including values for the 'trip_id' array column.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO taxi VALUES\n        (\n            'FAST0001',\n            ARRAY['ABCD1234', 'ABCD1235', 'ABCD1236', 'ABCD1237'],\n            'N5432N',\n            'FAST TAXI',\n            '2030-12-31',\n            'DAVID WANG'\n        );\n```\n\n----------------------------------------\n\nTITLE: Using <@ Containment Operator in SQL\nDESCRIPTION: Checks if the left array is contained by the right array. Returns true if all elements in the left array appear in the right array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\narray[2,3] <@ array[1,2,3] → t\n```\n\n----------------------------------------\n\nTITLE: Basic SET Command Syntax in SQL\nDESCRIPTION: The basic syntax for the SET command to change runtime parameters. It allows setting parameters to specific values or resetting them to default.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET parameter_name { TO | = } { value | 'value' | DEFAULT};\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Recursive Protobuf Definitions in SQL\nDESCRIPTION: This SQL statement creates a table that handles recursive Protobuf definitions by specifying certain message types to be encoded as JSONB. It uses Kafka as the source and Protobuf for encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/supported-protobuf-types.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE opentelemetry_test \nWITH ( \n    ${RISEDEV_KAFKA_WITH_OPTIONS_COMMON}, \n    topic = 'opentelemetry_test' \n) \nFORMAT PLAIN \nENCODE PROTOBUF ( \n    schema.registry = '${RISEDEV_SCHEMA_REGISTRY_URL}', \n    message = 'opentelemetry_test.OTLPTestMessage', \n    messages_as_jsonb = 'opentelemetry.proto.common.v1.ArrayValue,opentelemetry.proto.common.v1.KeyValueList,opentelemetry.proto.common.v1.AnyValue'\n);\n```\n\n----------------------------------------\n\nTITLE: Enabling Sink Decoupling in RisingWave SQL\nDESCRIPTION: This SQL command enables sink decoupling for all sinks created in the session. Sink decoupling introduces a buffering queue between a RisingWave sink and the downstream system to maintain stability and performance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/delivery/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET sink_decouple = true;\n```\n\n----------------------------------------\n\nTITLE: Example of Creating and Dropping a Secret in SQL\nDESCRIPTION: Provides a practical example demonstrating the creation of a secret named `mysql_pwd` using `CREATE SECRET` with the `meta` backend and its subsequent removal using `DROP SECRET`. The expected results (`CREATE_SECRET`, `DROP_SECRET`) indicate the successful execution of each command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-secret.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SECRET mysql_pwd WITH ( backend = 'meta' ) AS '123';\n----RESULT\nCREATE_SECRET\n\nDROP SECRET mysql_pwd;\n----RESULT\nDROP_SECRET\n```\n\n----------------------------------------\n\nTITLE: SQL Syntax for Creating Google Pub/Sub Sink in RisingWave\nDESCRIPTION: Defines the complete SQL syntax for creating a Google Pub/Sub sink connector in RisingWave, including all available parameters, format options, and encoding settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/google-pub-sub.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='google_pubsub',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    key = 'value'\n) ]\n[KEY ENCODE key_encode [(...)]];\n\n```\n\n----------------------------------------\n\nTITLE: Encrypting Data Using AES in SQL\nDESCRIPTION: Demonstrates how to encrypt a string using the encrypt function with AES algorithm in CBC mode with PKCS padding, using a specified secret key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT encrypt('Hello, World!', 'my_secret_key111', 'aes-cbc/pad:pkcs');\n----RESULT\n\\x9cf6a49f90b3ac816aeeeed286606fdb\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Homebrew Installation Command for RisingWave\nDESCRIPTION: Command to install RisingWave on a local machine using Homebrew package manager.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\nbrew install risingwave\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Settings for BYOC in YAML\nDESCRIPTION: This YAML configuration file defines custom settings for a BYOC deployment, including container security context, pod security admission labels, extra tags, and AWS-specific settings for EKS node AMI version.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncontainer_security_context:\n  allowPrivilegeEscalation: false\n  capabilities:\n    drop:\n    - ALL\n  readOnlyRootFilesystem: true\n  runAsNonRoot: true\n  runAsUser: 65521\n  seccompProfile:\n    type: RuntimeDefault\npod_security_admission_labels:\n  pod-security.kubernetes.io/enforce: restricted\nextra_tags:\n  foo: bar\naws_settings:\n  eks_node_ami_release_version: 1.32.0-20241225\n```\n\n----------------------------------------\n\nTITLE: Checking Pod Status\nDESCRIPTION: Commands to verify the status of cert-manager and risingwave-operator pods\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl -n cert-manager get pods\nkubectl -n risingwave-operator-system get pods\n```\n\n----------------------------------------\n\nTITLE: Executing Point Select Query in SQL\nDESCRIPTION: This SQL query represents the 'oltp_point_select' workload in the sysbench benchmark. It selects a single column based on a specific ID.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-benchmarks-query.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT c FROM sbtest WHERE id = ?;\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory in Bash\nDESCRIPTION: Changes the current directory to the warehouse_inventory_mgmt folder within the cloned repository.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd awesome-stream-processing/tree/main/02-simple-demos/logistics/warehouse_inventory_mgmt\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.18.0 with Docker\nDESCRIPTION: Command to run RisingWave v0.18.0 in playground mode using Docker. This exposes the necessary ports (4566 and 5691) for accessing the RisingWave instance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.18.0 playground\n```\n\n----------------------------------------\n\nTITLE: Time Travel Queries for Specific Snapshots\nDESCRIPTION: Queries to read specific Iceberg table snapshots using snapshot ID or timestamp.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t FOR SYSTEM_VERSION AS OF 4476030648521181855;\nSELECT * FROM t FOR SYSTEM_TIME AS OF '2024-04-03 08:54:22.488+00:00';\n```\n\n----------------------------------------\n\nTITLE: Connecting to MySQL RDS instance via command line\nDESCRIPTION: Command to connect to a MySQL RDS instance from the command line, using the endpoint, port, username, and password.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmysql -h rw-to-mysql.xxxxxx.us-east-1.rds.amazonaws.com -P 3306 -u <username> -p <password>\n```\n\n----------------------------------------\n\nTITLE: Setting Time Zone to Local System Time\nDESCRIPTION: Example of setting the database time zone to match the system's local time zone.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-time-zone.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET TIME ZONE LOCAL;\n```\n\n----------------------------------------\n\nTITLE: Button Component Implementation\nDESCRIPTION: Renders a button component that links to the RisingWave query console.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/console-overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: mdx\nCODE:\n```\n<Button href=\"https://cloud.risingwave.com/auth/signin/\" target=\"_blank\">\nGo to query console\n</Button>\n```\n\n----------------------------------------\n\nTITLE: Creating a Source in RisingWave Using Data Generator\nDESCRIPTION: This SQL command creates a source in RisingWave using the built-in load generator. It generates mock data with specified fields and data generation parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SOURCE s1_source (id int, name varchar)\nWITH (\n     connector = 'datagen',\n     fields.id.kind = 'sequence',\n     fields.id.start = '1',\n     fields.id.end = '10000',\n     fields.name.kind = 'random',\n     fields.name.length = '10',\n     datagen.rows.per.second = '200'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: SQL SELECT Query Example\nDESCRIPTION: Query showing the initial state of the taxi_trips table before updates.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-update.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Querying Buy Signals Materialized View in SQL\nDESCRIPTION: This snippet demonstrates how to query the buy_signals materialized view to get real-time insights on potential stock trading opportunities that meet the defined criteria.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/use-cases.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM buy_signals;\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW CLUSTER Command Syntax in Bash\nDESCRIPTION: Shows the syntax for the SHOW CLUSTER command which is used to display details about your RisingWave cluster configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-cluster.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW CLUSTER;\n```\n\n----------------------------------------\n\nTITLE: Exporting a Stylized Button Component with React in JavaScript\nDESCRIPTION: This React component exports a functional Button that accepts an 'href' and 'children' as props. The button is visually styled with utility classes for layout, color, and hover effects, supporting both light and dark modes. The component renders a button inside a link, making the entire button navigable to the specified 'href'. Dependencies include React and (optionally) a utility CSS framework such as Tailwind CSS. 'href' specifies the navigation target, while 'children' denotes the button's inner contents, supporting flexible usage. The component is designed for use in React-based projects where styled, theme-responsive buttons are needed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/snippets/button.mdx#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport const Button = ({ href, children }) => {\n  return <div className=\"not-prose group\">\n    <a href={href} >\n      <button className=\"flex items-center space-x-2.5 py-1 px-4 bg-primary-dark dark:bg-white text-white dark:text-gray-950 rounded-xl group-hover:opacity-[0.9] font-medium\">\n        <span>\n          {children}\n        </span>\n      </button>\n    </a>\n  </div>;\n};\n```\n\n----------------------------------------\n\nTITLE: Describing Kafka Topic using Command-line Tools\nDESCRIPTION: Command to describe the created Kafka topic 'example_topic'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./kafka-topics.sh --describe example_topic --bootstrap-server 10.0.96.4:9092\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave Java UDF Template\nDESCRIPTION: Command to clone the template repository for RisingWave Java UDF development.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave-java-udf-template.git\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Source Rate Limit in RisingWave\nDESCRIPTION: This example creates a Kafka source table with an initial source rate limit of 0, which effectively pauses the source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table with source\nCREATE TABLE kafka_source (v1 int) WITH (\n  connector = 'kafka',\n  topic = 'kafka_source',\n  properties.bootstrap.server = 'localhost:29092',\n  scan.startup.mode = 'earliest',\n  source_rate_limit = 0\n) FORMAT PLAIN ENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE SET BACKFILL_RATE_LIMIT Syntax in RisingWave SQL\nDESCRIPTION: This command controls the rate limit of backfilling from a CDC database for a CDC table. It can be set to 'default', a specific numeric value, or 0 to pause backfilling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\n    SET BACKFILL_RATE_LIMIT { TO | = } { default | rate_limit_number };\n```\n\n----------------------------------------\n\nTITLE: Using array_min Function in SQL\nDESCRIPTION: Returns the minimum value in an array. Null elements are skipped, but if the array contains only null elements, NULL is returned.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\narray_min ( array ) → type of the elements\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_min(array['a', 'b', 'c']) → a\n\narray_min(array[date'2002-10-30', date'2023-09-06', date'2017-06-18']) → 2002-10-30\n\narray_min(array['','']) → empty\n\narray_min(array['a', 'b', NULL, 'c']) → a\n\narray_min(array[NULL]) → NULL\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE TABLE Output Example\nDESCRIPTION: The result of executing the SHOW CREATE TABLE command, displaying the table name and its creation SQL. The output preserves important schema details and options while omitting the IF NOT EXISTS clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-table.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n   Name    |                 Create Sql\n-----------+---------------------------------------------\n public.taxi_trips | CREATE TABLE taxi_trips (id CHARACTER VARYING, distance DOUBLE, city CHARACTER VARYING) WITH (appendonly = 'true')\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Inserting or Updating Map Entries in SQL\nDESCRIPTION: The map_insert function adds a new key-value pair to a map or updates an existing one. It returns a new map with the changes applied.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmap_insert ( map, key, value ) → map\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_insert(MAP{1:100,2:200}, 3, 300) -> {1:100,2:200,3:300}\nmap_insert(MAP{1:100,2:200}, 1, 101) -> {2:200,1:101}\n```\n\n----------------------------------------\n\nTITLE: Example: Creating Databases Assigned to Resource Groups (SQL)\nDESCRIPTION: Demonstrates assigning different databases to dedicated resource groups at creation in RisingWave. This setup provides fault and performance isolation for workloads with varying resource needs. The command can be repeated for each database/resource group pair, specifying both as parameters. The resulting databases will be isolated to the compute nodes of their assigned group.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Example:\nCREATE DATABASE analytics_db WITH resource_group = 'rg_general_purpose';\nCREATE DATABASE critical_payments_db WITH resource_group = 'rg_high_cpu';\n```\n\n----------------------------------------\n\nTITLE: Using DROP MATERIALIZED VIEW Syntax - SQL\nDESCRIPTION: Demonstrates the general syntax for the DROP MATERIALIZED VIEW statement in SQL, showing all optional clauses such as IF EXISTS, schema qualification, and CASCADE. Requires a SQL-compatible database that supports materialized views. Inputs include the materialized view name, an optional schema name, and optional CASCADE; output is the removal of the specified materialized view and dependent objects if CASCADE is used.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-mv.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP MATERIALIZED VIEW [ IF EXISTS ] [schema_name.]mv_name [ CASCADE ];\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Iceberg Engine in SQL\nDESCRIPTION: This SQL snippet creates a table using the Iceberg engine. It demonstrates setting the commit checkpoint interval and specifying the Iceberg engine.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/store/iceberg-table-engine.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n    id INT PRIMARY KEY, \n    name VARCHAR\n) WITH (commit_checkpoint_interval = 1) \nENGINE = iceberg;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Creation and Initialization Times from RisingWave Catalogs in SQL\nDESCRIPTION: This SQL query demonstrates how to retrieve the creation and initialization times of sources from the rw_sources catalog, which can be useful for tracking object lifecycles.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name, initialized_at, created_at FROM rw_sources;\n```\n\n----------------------------------------\n\nTITLE: Creating a Rust Structured Type Function in RisingWave SQL\nDESCRIPTION: This snippet demonstrates how to create a function that returns a structured type, parsing a key-value pair from a string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-rust.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE FUNCTION key_value(varchar) RETURNS STRUCT<key varchar, value varchar> LANGUAGE rust AS $$\n    #[derive(StructType)]\n    struct KeyValue<'a> {\n        key: &'a str,\n        value: &'a str,\n    }\n    #[function(\"key_value(varchar) -> struct KeyValue\")]\n    fn key_value(kv: &str) -> Option<KeyValue<'_>> {\n        let (key, value) = kv.split_once('=')?;\n        Some(KeyValue { key, value })\n    }\n$$;\n```\n\n----------------------------------------\n\nTITLE: Retrieving an Element from an Array Column\nDESCRIPTION: Shows how to select the first element from the 'trip_id' array column in the 'taxi' table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT trip_id[1]\nFROM taxi;\n```\n\n----------------------------------------\n\nTITLE: SSH Connection to EC2 Instance\nDESCRIPTION: This bash command demonstrates how to connect to an EC2 instance using SSH. The specific values for the key file and EC2 public DNS need to be replaced with actual values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nssh -i \"xxx.pem\" ubuntu@ec2-xx-xxx-xxx-xxx.compute-1.amazonaws.com\n```\n\n----------------------------------------\n\nTITLE: Installing dbt-risingwave plugin using pip\nDESCRIPTION: This command installs the dbt-risingwave plugin, which is required to use dbt with RisingWave. It uses Python's pip package manager to install the plugin.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/other/dbt.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m pip install dbt-risingwave\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Scan Count in SQL\nDESCRIPTION: Shows how to use pg_stat_get_numscans() function to get the total number of scans performed on a specified table since the server was started. Note that this is a dummy function for compatibility and may be removed in the future.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_stat_get_numscans('my_table');\n pg_stat_get_numscans\n----------------------\n                    0\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Querying Data from Iceberg Source in RisingWave (SQL)\nDESCRIPTION: This SQL query demonstrates how to select all data from the previously created Iceberg source in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/iceberg.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM iceberg_source;\n```\n\n----------------------------------------\n\nTITLE: Starting the Python UDF Server\nDESCRIPTION: Command to start the UDF server by running the Python script.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython3 udf.py\n```\n\n----------------------------------------\n\nTITLE: Checking PostgreSQL WAL Level (Bash)\nDESCRIPTION: This bash command connects to a PostgreSQL instance using `psql` (implied) and executes the `SHOW wal_level;` SQL command to check the current setting of the Write-Ahead Log level. This setting needs to be `logical` for CDC.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW wal_level;\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave via psql\nDESCRIPTION: Command to connect to a running RisingWave instance using the PostgreSQL client (psql). It connects to the dev database as the root user on localhost port 4566.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Using array_transform Function in SQL\nDESCRIPTION: Transforms each element in an array using a lambda expression and returns the results in a new array of the same length. The lambda expression can perform type conversions and conditional logic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\narray_transform ( array_expression, lambda_expression )\n\nlambda_expression:\n| element_alias | transform_expression\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array_transform('{1,2,3}'::int[], |x| (x::double precision+0.5));\n------RESULT\n{1.5,2.5,3.5}\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array_transform(\n    ARRAY['Apple', 'Airbnb', 'Amazon', 'Facebook', 'Google', 'Microsoft', 'Netflix', 'Uber'],\n    |x| case when x ilike 'A%' then 'A' else 'Other' end\n);\n------RESULT\n{A,A,A,Other,Other,Other,Other,Other}\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(v int, arr int[]);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array_transform(arr, |x| x + v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Using trim_array Function in SQL\nDESCRIPTION: Trims an array by removing the specified number of elements from the end. For multidimensional arrays, only the first dimension is trimmed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\ntrim_array ( array, num_of_elements_to_trim ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\ntrim_array(array[1,2,3,4,5,NULL], 4) → {1,2}\n```\n\n----------------------------------------\n\nTITLE: Declaring a Subscription Cursor in RisingWave Using SQL\nDESCRIPTION: This snippet demonstrates declaring a subscription cursor for a RisingWave subscription, specifying where to start reading changes. 'since_clause' allows defining an incremental starting point, or 'FULL' can be used to fetch all historical records from the subscription. This command enables fine-grained data change consumption and requires the specified subscription to exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDECLARE cursor_name SUBSCRIPTION CURSOR FOR subscription_name [since_clause | FULL];\n```\n\n----------------------------------------\n\nTITLE: Using LPAD Function in SQL\nDESCRIPTION: The lpad() function pads the input string on the left with spaces until it reaches the specified input integer length. If the input string is longer than the input integer length, it is truncated to the specified length. Providing the optional padding string replaces the spaces with the padding string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_15\n\nLANGUAGE: SQL\nCODE:\n```\nlpad ( input_string, input_int ) → string\n\nlpad ( input_string, input_int, padding_string ) → string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nlpad('42', 5) → '&nbsp;&nbsp;&nbsp42'\nlpad('42', 5, 'R') → 'RRR42'\n```\n\n----------------------------------------\n\nTITLE: Setting KAFKA_OPTS Environment Variable\nDESCRIPTION: This bash command sets the KAFKA_OPTS environment variable to specify the location of the JAAS configuration file for Kafka security settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport KAFKA_OPTS=-Djava.security.auth.login.config=/home/ubuntu/users_jaas.conf\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using NodePort in Kubernetes\nDESCRIPTION: These commands set up environment variables and connect to RisingWave using psql when the service type is NodePort. It retrieves the necessary host and port information from Kubernetes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nexport RISINGWAVE_NAME=risingwave-postgresql-hdfs\nexport RISINGWAVE_NAMESPACE=default\nexport RISINGWAVE_HOST=`kubectl -n ${RISINGWAVE_NAMESPACE} get node -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}'`\nexport RISINGWAVE_PORT=`kubectl -n ${RISINGWAVE_NAMESPACE} get svc -l risingwave/name=${RISINGWAVE_NAME},risingwave/component=frontend -o jsonpath='{.items[0].spec.ports[0].nodePort}'`\npsql -h ${RISINGWAVE_HOST} -p ${RISINGWAVE_PORT} -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Querying Recent Sales in SQL\nDESCRIPTION: Retrieves all rows from the recent_sales materialized view to display aggregated sales data from the past week.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM recent_sales;\n```\n\n----------------------------------------\n\nTITLE: Configuring Upsert Avro Format in RisingWave\nDESCRIPTION: SQL syntax for configuring Upsert Avro format for Kafka topics in RisingWave. Supports CRUD operations based on message key and value fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT UPSERT\nENCODE AVRO (\n   schema.location = 'location' | schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\n----------------------------------------\n\nTITLE: Querying Data in Delta Lake Using Spark SQL\nDESCRIPTION: This command uses Spark SQL to query the total number of records in the Delta Lake table. It sets up necessary configurations for Spark and Delta Lake, including S3 access credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/delta-lake.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nspark-sql --packages io.delta:delta-core_2.12:2.2.0,org.apache.hadoop:hadoop-aws:3.3.2\\\n    --conf 'spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension' \\\n    --conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog' \\\n    --conf 'spark.hadoop.fs.s3a.access.key=${ACCESS_KEY}' \\\n    --conf 'spark.hadoop.fs.s3a.secret.key=${SECRET_KEY}' \\\n    --conf 'spark.hadoop.fs.s3a.endpoint=https://s3.ap-southeast-1.amazonaws.com' \\\n    --conf 'spark.hadoop.fs.s3a.path.style.access=true' \\\n    --e \"select count(*) from delta.\\`s3a://my-delta-lake-bucket/path/to/table\\`\"\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: Connect to the RisingWave database using psql to manage data streams and perform data analysis.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Migrating Dependent Materialized Views in RisingWave - SQL\nDESCRIPTION: This snippet demonstrates coordinated migration of dependent materialized views in the correct order: dropping old versions and renaming new ones. This ensures dependencies are realigned. Inputs are existing views with identical schema; outputs are updated streaming objects under canonical names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/alter-streaming.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nDROP MATERIALIZED VIEW cust_sales;\nALTER MATERIALIZED VIEW cust_sales_new RENAME TO cust_sales;\n\nDROP MATERIALIZED VIEW orders;\nALTER MATERIALIZED VIEW orders_new RENAME TO orders;\n```\n\n----------------------------------------\n\nTITLE: Renaming a User in SQL\nDESCRIPTION: This SQL command renames an existing user in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER user1 RENAME TO user001;\n```\n\n----------------------------------------\n\nTITLE: Querying Fragment Parallelism\nDESCRIPTION: SQL query to view the parallelism of fragments within a specific streaming job.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndev=> SELECT * FROM rw_fragment_parallelism WHERE name = 't';\n  id  | name |   relation_type   | fragment_id | distribution_type | state_table_ids | upstream_fragment_ids |        flags        | parallelism\n------+------+-------------------+-------------+-------------------+-----------------+-----------------------+---------------------+-------------\n 1001 | t    | table             |           2 | HASH              | {}              | {}                    | {SOURCE,DML}        |           4\n 1001 | t    | table             |           1 | HASH              | {1001}          | {2}                   | {MVIEW}             |           4\n```\n\n----------------------------------------\n\nTITLE: Example Output: User Table Privileges (Bash)\nDESCRIPTION: This snippet displays example output from the SQL query that checks user table privileges. It shows that the user 'rw' has 'SELECT' privileges on several tables (lineitem, customer, etc.), confirming the necessary permissions for CDC.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n table_name | grantee | privilege_type\n -----------+---------+----------------\n lineitem   | rw      | SELECT\n customer   | rw      | SELECT\n nation     | rw      | SELECT\n orders     | rw      | SELECT\n part       | rw      | SELECT\n partsupp   | rw      | SELECT\n supplier   | rw      | SELECT\n region     | rw      | SELECT\n (8 rows)\n```\n\n----------------------------------------\n\nTITLE: Calculating Bit Length of Binary String in SQL\nDESCRIPTION: The bit_length function returns the number of bits in a binary string, which is 8 times the octet_length. It takes a bytea input and returns an integer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nbit_length ( bytea ) -> integer\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT bit_length('😇'::bytea);\n------RESULT\n32\n```\n\n----------------------------------------\n\nTITLE: Using array_agg function in SQL\nDESCRIPTION: Collects all input values, including nulls, into an array with optional ordering of elements based on an ORDER BY clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\narray_agg ( expression [ ORDER BY sort_expression ] ) -> output_array\n```\n\n----------------------------------------\n\nTITLE: Verifying Data in PostgreSQL\nDESCRIPTION: SQL query to verify that data has been successfully sunk to the target_count table in PostgreSQL by selecting the first 10 rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM target_count\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: General Syntax for ALTER MATERIALIZED VIEW in SQL\nDESCRIPTION: Provides the basic syntax structure for the `ALTER MATERIALIZED VIEW` command. The specific modification is defined by the `alter_option` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW materialized_view_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Granting SELECT Privilege on Materialized View in SQL\nDESCRIPTION: This SQL command grants the SELECT privilege on a materialized view to a user, with the option to grant this privilege to others.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nGRANT SELECT\nON MATERIALIZED VIEW mv1 IN SCHEMA db1.schema1\nTO user1 WITH GRANT OPTION GRANTED BY user;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Expression Column in RisingWave\nDESCRIPTION: Demonstrates how to create a table with a generated column 'next_id' that computes values based on the 'id' column. The generated column must appear at the end of the schema definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n  id integer PRIMARY KEY,\n  name varchar,\n  next_id int AS id + 1,\n  PRIMARY KEY (id)\n) FROM pg_mydb TABLE 'public.person';\n```\n\n----------------------------------------\n\nTITLE: Using avg Function with rw_int256 in SQL\nDESCRIPTION: Shows the usage of the avg function to calculate the average of rw_int256 values, returning a double result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT avg(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Managing Subscription Cursor and Progress in Python\nDESCRIPTION: This Python code snippet demonstrates how to manage a subscription cursor, fetch data, and update progress. It retrieves the last progress, declares a cursor for the subscription, and periodically updates the progress while processing data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/serve/subscription.mdx#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Fetch the last progress from subscription_progress table\nlast_progress = get_last_progress(conn, sub_name)\n\nwith conn.cursor() as cur:\n    if last_progress is not None:\n        cur.execute(\n            \"DECLARE cur SUBSCRIPTION CURSOR FOR {} SINCE {}\".format(sub_name, last_progress))\n    else:\n        cur.execute(\n            \"DECLARE cur SUBSCRIPTION CURSOR FOR {};\".format(sub_name))\n\n    while True:\n        cur.execute(\"FETCH NEXT FROM cur\")\n        row = cur.fetchone()\n        last_progress = row[0]  # 'rw_timestamp' is the progress indicator\n\n        ...\n\n        if trigger_update():\n            update_progress(conn, sub_name, last_progress)\n```\n\n----------------------------------------\n\nTITLE: Example: Renaming Materialized View in SQL\nDESCRIPTION: Demonstrates how to rename the materialized view `mv_1` to `mv_2`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of the materialized view named \"mv_1\" to \"mv_2\"\nALTER MATERIALIZED VIEW mv_1 RENAME TO mv_2;\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Source with Specific Consumer Properties in RisingWave SQL\nDESCRIPTION: This SQL statement demonstrates creating a Kafka source named 's1' in RisingWave. It connects to a Kafka cluster specified by 'properties.bootstrap.server', reads from 'topic', starts consuming from the 'earliest' offset, and defines the data structure with columns 'v1' and 'v2'. Crucially, it sets specific Kafka consumer properties 'queued.min.messages' and 'queued.max.messages.kbytes' using the 'properties' clause for fine-tuning consumption behavior. The source expects data in 'PLAIN' format with 'JSON' encoding.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1 (v1 int, v2 varchar) with (\n  connector = 'kafka',\n  topic = 'kafka_1_partition_topic',\n  properties.bootstrap.server = 'message_queue:29092',\n  scan.startup.mode = 'earliest',\n  properties.queued.min.messages = 10000,\n  properties.queued.max.messages.kbytes = 65536\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for RisingWave Kafka Sources and Tables using SQL\nDESCRIPTION: This SQL code describes the schema definition syntax for specifying columns and primary keys when creating a Kafka source or table in RisingWave. Each column is assigned a data type, and tables may have single or composite primary keys. No schema definition is needed for Avro/Protobuf formats. The input consists of column names and data types, optionally defining a primary key; outputs are structured schemas for data ingestion. This must align with the incoming data's structure and is essential for key constraint enforcement in tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: Cleanup Commands\nDESCRIPTION: Commands to disconnect from RisingWave and optionally remove containers and generated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n\\q\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Starting Grafana for RisingWave Monitoring\nDESCRIPTION: Command to start Grafana server with a custom configuration file for visualizing RisingWave metrics.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ngrafana server --config ./standalone/grafana.ini\n```\n\n----------------------------------------\n\nTITLE: Example of Dropping a Specific SQL Connection\nDESCRIPTION: This SQL code provides an example of using the `DROP CONNECTION` command. It demonstrates how to remove a connection specifically named `c1`. This command assumes that the connection `c1` exists and has no dependent sources or sinks.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-connection.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP CONNECTION c1;\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave Repository\nDESCRIPTION: Commands to clone the RisingWave repository and navigate to the clickstream demo directory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\ncd risingwave/integration_tests/clickstream\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source - Old Syntax\nDESCRIPTION: Example of the deprecated syntax for creating a Kafka source connection in RisingWave\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_39\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1 WITH ( 'connector' = 'kafka', 'kafka.topic' = 'kafka_1_partition_topic', 'kafka.brokers' = '127.0.0.1:29092' ) ROW FORMAT json;\n```\n\n----------------------------------------\n\nTITLE: Installing Specific RisingWave Operator Version\nDESCRIPTION: Command to install a specific version of RisingWave Operator, replacing ${VERSION} with desired version\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply --server-side -f https://github.com/risingwavelabs/risingwave-operator/releases/download/${VERSION}/risingwave-operator.yaml\n```\n\n----------------------------------------\n\nTITLE: Using array_upper Function in SQL\nDESCRIPTION: Returns the upper bound of the requested array dimension. The second parameter must be 1, and this will return the same value as array_length.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\narray_upper ( array, int ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_upper(array[array[2, 3, 4], array[3, 4, 5]], 1) → 2\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave Repository\nDESCRIPTION: Commands to clone the RisingWave repository and navigate to the livestream demo directory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\ncd risingwave/integration_tests/livestream\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Data for AMQ Streams Topic\nDESCRIPTION: Example of JSON-formatted financial transaction data to be ingested from AMQ Streams into RisingWave. Each entry represents a unique transaction with various details.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/redhat-amq-streams.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{\"tx_id\": \"TX1004\", \"sender_account\": \"ACC1004\", \"receiver_account\": \"ACC2004\", \"amount\": 2000.00, \"currency\": \"USD\", \"tx_timestamp\": \"2024-03-29T12:36:00Z\"}\n{\"tx_id\": \"TX1005\", \"sender_account\": \"ACC1005\", \"receiver_account\": \"ACC2005\", \"amount\": 450.25, \"currency\": \"EUR\", \"tx_timestamp\": \"2024-03-29T12:36:15Z\"}\n{\"tx_id\": \"TX1006\", \"sender_account\": \"ACC1006\", \"receiver_account\": \"ACC2006\", \"amount\": 1250.00, \"currency\": \"USD\", \"tx_timestamp\": \"2024-03-29T12:36:30Z\"}\n{\"tx_id\": \"TX1007\", \"sender_account\": \"ACC1007\", \"receiver_account\": \"ACC2007\", \"amount\": 830.50, \"currency\": \"GBP\", \"tx_timestamp\": \"2024-03-29T12:36:45Z\"}\n{\"tx_id\": \"TX1008\", \"sender_account\": \"ACC1008\", \"receiver_account\": \"ACC2008\", \"amount\": 540.00, \"currency\": \"EUR\", \"tx_timestamp\": \"2024-03-29T12:37:00Z\"}\n{\"tx_id\": \"TX1009\", \"sender_account\": \"ACC1009\", \"receiver_account\": \"ACC2009\", \"amount\": 975.75, \"currency\": \"GBP\", \"tx_timestamp\": \"2024-03-29T12:37:15Z\"}\n{\"tx_id\": \"TX1010\", \"sender_account\": \"ACC1010\", \"receiver_account\": \"ACC2010\", \"amount\": 1600.00, \"currency\": \"USD\", \"tx_timestamp\": \"2024-03-29T12:37:30Z\"}\n```\n\n----------------------------------------\n\nTITLE: Cloning RisingWave Repository\nDESCRIPTION: Commands to clone the RisingWave repository and navigate to the twitter integration test directory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\ncd risingwave/integration_tests/twitter\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Old Syntax for Specifying Data Format Part 1\nDESCRIPTION: The deprecated syntax for specifying data and encoding formats for sources in CREATE SOURCE and CREATE TABLE commands. This shows the first part of the old row format syntax pattern.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nROW FORMAT data_format\n[ MESSAGE 'message' ]\n[ ROW SCHEMA LOCATION ['location' | CONFLUENT SCHEMA REGISTRY 'schema_registry_url' ] ];\n```\n\n----------------------------------------\n\nTITLE: Using lag() Window Function in SQL\nDESCRIPTION: The lag() function allows you to access the value of a previous row in the result set. You can specify the number of rows to look back.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/window-functions.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nlag ( value anycompatible [, offset const integer] ) → anycompatible\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    col1, col2,\n    lag(col2) OVER (\n        PARTITION BY col1\n        ORDER BY col2\n    ) as lag\nFROM t ORDER BY col1, col2;\n```\n\n----------------------------------------\n\nTITLE: Creating Market Data Table in SQL for Sports Betting\nDESCRIPTION: Creates a table to track market activity related to betting positions, including pricing and volume trends across different bookmakers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE market_data (\n    position_id INT,\n    bookmaker VARCHAR,\n    market_price FLOAT,\n    volume INT,\n    timestamp TIMESTAMPTZ\n);\n```\n\n----------------------------------------\n\nTITLE: Using Map Access Operator in SQL\nDESCRIPTION: The map access operator is an alias for the map_access function. It provides a convenient syntax for retrieving values from a map using square brackets.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nMAP{1:100,2:200}[1] → 100\nMAP{1:100,2:200}[3] → null\n```\n\n----------------------------------------\n\nTITLE: Querying Risk Summary Materialized View in SQL\nDESCRIPTION: Retrieves and displays the risk summary data, showing the count of positions in each risk level category.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM risk_summary;\n```\n\n----------------------------------------\n\nTITLE: Monitoring PostgreSQL Real-time CDC Replication\nDESCRIPTION: This SQL query checks the real-time replication progress for a PostgreSQL CDC source by querying the internal source table. It shows the current LSN (Log Sequence Number) being consumed from PostgreSQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM __internal_my_pg_source_1_source_2;\n```\n\n----------------------------------------\n\nTITLE: Revoking Schema Privileges in SQL\nDESCRIPTION: Syntax for revoking CREATE or ALL privileges on schemas from a user. The GRANTED BY clause specifies the user revoking the privileges, defaulting to root.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {CREATE | ALL [PRIVILEGES]}\nON SCHEMA schema_name [, ...]\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Retrieving Runtime Parameter Value in SQL\nDESCRIPTION: Demonstrates the use of current_setting() function to retrieve the value of a specified runtime parameter. This function is equivalent to the SQL SHOW command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT current_setting ('server_version');\n---------RESULT\n current_setting\n-----------------\n 8.3.0\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Inserting Values into an Array of Arrays\nDESCRIPTION: Demonstrates how to insert values into the 'x' table that contains an array of arrays.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/array-type.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO x VALUES (ARRAY[ARRAY[1], ARRAY[2,3]]);\n```\n\n----------------------------------------\n\nTITLE: Dropping Secrets Syntax in RisingWave SQL\nDESCRIPTION: This SQL snippet shows the basic syntax for removing a previously created secret from RisingWave using the `DROP SECRET` command followed by the name of the secret to be dropped.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-secrets.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDROP SECRET secret_name;\n```\n\n----------------------------------------\n\nTITLE: Disconnecting from RisingWave and Cleaning Up\nDESCRIPTION: Commands to disconnect from the RisingWave database and optionally remove the Docker containers and generated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n\\q\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Removing the Demo Environment\nDESCRIPTION: Optional command to remove all Docker containers and associated volumes created for the demo, cleaning up resources when finished with the tutorial.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Converting JSON Objects to Text with jsonb_each_text\nDESCRIPTION: Function that expands a JSON object into key-value pairs with text values. Both keys and values are returned as varchar.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM jsonb_each_text('{\"a\":\"foo\", \"b\":\"bar\"}'::jsonb);\n```\n\n----------------------------------------\n\nTITLE: Struct Type Casting Examples\nDESCRIPTION: Examples of explicit and implicit type casting with struct types.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT (1, (2, 3))::STRUCT<i BIGINT, j STRUCT<a BIGINT, b VARCHAR>>;\n-----Result\n(1,(2,3))\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ROW(1, ROW('1', 1)) = ROW('1', ROW(1, '1'));\n-----\nt\n```\n\n----------------------------------------\n\nTITLE: Starting Multi-node RisingWave Cluster\nDESCRIPTION: Command to start a multi-node RisingWave cluster where compute node, meta node, and compactor node are separate processes. This uses the distributed Docker Compose configuration file with MinIO as the state store.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose -f docker-compose-distributed.yml up\n```\n\n----------------------------------------\n\nTITLE: Using FORMAT Function in SQL\nDESCRIPTION: The format() function produces output formatted according to a format string, in a style similar to the C function sprintf.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nformat( format_string [, format_arg [, ...] ] ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT format(f, a, b) from (values\n    ('%s %s', 'Hello', 'World'),\n    ('%s%s', 'Hello', null),\n    (null, 'Hello', 'World')\n) as t(f, a, b);\n----\nHello World\nHello\nNULL\n```\n\nLANGUAGE: SQL\nCODE:\n```\nformat('%s %s', variadic array['Hello', 'World']); -> \"Hello World\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Source in RisingWave\nDESCRIPTION: Creates a table 'walk' with a datagen connector to generate mock data for distance and duration metrics\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/go.mdx#2025-04-23_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nsql := `CREATE TABLE walk(distance INT, duration INT)\n        WITH ( \n            connector = 'datagen',\n            fields.distance.kind = 'sequence',\n            fields.distance.start = '1',\n            fields.distance.end  = '60',\n            fields.duration.kind = 'sequence',\n            fields.duration.start = '1',\n            fields.duration.end = '30',\n            datagen.rows.per.second='15',\n            datagen.split.num = '1'\n        ) FORMAT PLAIN ENCODE JSON`\n\n_, err := conn.Exec(context.Background(), sql)\nreturn err\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with SQLAlchemy\nDESCRIPTION: Creates a users table using SQLAlchemy connection engine with basic schema definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith engine.connect() as conn:\n    conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS users (\n    id INTEGER PRIMARY KEY,\n    name VARCHAR,\n    age INTEGER)\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Using RW_IMPLICIT_FLUSH with Batch Operations in SQL\nDESCRIPTION: An example demonstrating how to enable RW_IMPLICIT_FLUSH and perform batch operations in RisingWave. When enabled, INSERT, UPDATE, and DELETE operations are implicitly flushed, making data changes immediately visible without explicit FLUSH commands.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-rw-implicit-flush.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Enable RW_IMPLICIT_FLUSH\nSET RW_IMPLICIT_FLUSH TO true;\n\n-- Perform batch operations\nINSERT INTO users (id, name) VALUES (1, 'Alice'), (2, 'Bob'), (3, 'Charlie');\nUPDATE users SET name = 'David' WHERE id = 2;\nDELETE FROM users WHERE id = 3;\n\n-- Data changes are implicitly flushed and immediately visible\nSELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Example of using approx_percentile in SQL\nDESCRIPTION: Calculates the approximate 50th percentile of a numeric column with the default relative error of 0.01 (1%).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT approx_percentile(0.5) WITHIN GROUP (ORDER BY column1) FROM table1;\n```\n\n----------------------------------------\n\nTITLE: Trigonometric Function Examples in SQL\nDESCRIPTION: Examples of trigonometric functions including sine, cosine, tangent, and their inverse operations in both radians and degrees.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/mathematical.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nsin(1) → 0.8414709848078965\ncos(1) → 0.5403023058681398\ntan(1) → 1.5574077246549021\ncot(1) → 0.6420926159343308\nasin(0.5) → 0.5235987755982989\nacos(0.5) → 1.0471975511965976\natan(1.0) → 0.7853981633974483\natan2(1.0, 1.0) → 0.7853981633974483\nsinh(1.0) → 1.1752011936438014\ncosh(1.0) → 1.5430806348152437\ntanh(1.0) → 0.7615941559557649\ncoth(2) → 1.0373147207275481\nasinh(1.0) → 0.881373587019543\nacosh(2.0) → 1.3169578969248166\natanh(0.5) → 0.5493061443340549\nsind(15) → 0.2588190451025208\ncosd(15) → 0.9659258262890683\ntand(15) → 0.26794919243112275\ncotd(45) → 1\nacosd(0.25) → 75.52248781407008\n```\n\n----------------------------------------\n\nTITLE: Creating CDC Table with Generated Expression Column in RisingWave - SQL\nDESCRIPTION: This statement defines a CDC table 'person' in RisingWave with a generated column 'next_id', calculated as 'id + 1' for each record during ingestion. It demonstrates how to compute new fields dynamically while ingesting CDC streams. Dependencies include table source 'dbo.person' and compliance with the restriction that generated columns must appear at the end of the schema. Key input: reference to generated column; output: a table with both source and computed fields.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n  id integer PRIMARY KEY,\n  name varchar,\n  next_id int AS id + 1,\n  PRIMARY KEY (id)\n) FROM mssql_mydb TABLE 'dbo.person';\n```\n\n----------------------------------------\n\nTITLE: Checking Key Existence in Maps in SQL\nDESCRIPTION: The map_contains function checks if a given key exists in a map. It returns a boolean value indicating the presence of the key.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nmap_contains ( map, key ) → boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_contains(MAP{1:100,2:200}, 1) -> true\nmap_contains(MAP{1:100,2:200}, 3) -> false\n```\n\n----------------------------------------\n\nTITLE: Inserting, Deleting, and Updating Source Table (Changelog Operations) in SQL\nDESCRIPTION: Demonstrates a sequence of DML operations (INSERT, DELETE, UPDATE) on the source table 'user_behaviors' to generate changelog events. These operations provide the data and changelog scenarios for the previously defined materialized view, helping test and illustrate how changes are tracked. Inputs are standard row values; outputs are implicit in the effect on downstream queries representing the changelog.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-as-changelog.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO user_behaviors (v1, v2) VALUES (1, 1);\nINSERT INTO user_behaviors (v1, v2) VALUES (2, 2);\n\nDELETE FROM user_behaviors WHERE v1 = 2;\n\nUPDATE user_behaviors SET v2 = 100 WHERE v1 = 1;\n\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave with psql\nDESCRIPTION: Command to connect to a running RisingWave instance using the PostgreSQL interactive terminal. This connects to the default development database (dev) as the root user without requiring a password.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Extracting Map Components in SQL\nDESCRIPTION: The map_entries, map_keys, and map_values functions extract components from a map. They return arrays of key-value pairs, keys, or values respectively.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmap_entries ( map ) → array\nmap_keys ( map ) → array\nmap_values ( map ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_entries(MAP{1:100,2:200}) -> array[row(1,100),row(2,200)]\nmap_keys(MAP{1:100,2:200}) -> array[1,2]\nmap_values(MAP{1:100,2:200}) -> array[100,200]\n```\n\n----------------------------------------\n\nTITLE: Converting Functions to Aggregate Functions in RisingWave SQL\nDESCRIPTION: Shows the syntax for converting array functions or user-defined functions into aggregate functions using the AGGREGATE: prefix. The function must accept exactly one argument of an array type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nAGGREGATE:function_name\n```\n\n----------------------------------------\n\nTITLE: Configuring Shared Kafka Source Behavior in RisingWave SQL\nDESCRIPTION: Shows SQL commands to control the `streaming_use_shared_source` session variable in RisingWave. This variable enables or disables the shared source feature for Kafka sources. The `SET` command modifies the setting for the current session, while `ALTER SYSTEM SET` changes the default value for future sessions across the cluster.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-source.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n# change the config in the current session\nSET streaming_use_shared_source=[true|false];\n\n# change the default value of the session variable in the cluster\n# (the current session is not affected)\nALTER SYSTEM SET streaming_use_shared_source=[true|false];\n```\n\n----------------------------------------\n\nTITLE: Renaming a User with SQL ALTER USER - SQL\nDESCRIPTION: This snippet demonstrates how to rename an existing user using the ALTER USER command in SQL. The command requires specifying the current user name and the new desired user name as parameters. Output is confirmation of the user rename; constraints include requiring the target user to exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-user.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER user_name\n    RENAME TO new_user_name\n\n```\n\n----------------------------------------\n\nTITLE: Disabling Sink Decoupling in RisingWave SQL\nDESCRIPTION: This SQL command disables sink decoupling for all sinks created in the session, regardless of the default setting.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/delivery/overview.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET sink_decouple = false;\n```\n\n----------------------------------------\n\nTITLE: INTERSECT Example Query\nDESCRIPTION: Demonstrates how to use INTERSECT to find common rows between two points scored tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/set-operations.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM points_scored_current_week\nINTERSECT\nSELECT *\nFROM points_scored_last_week;\n```\n\n----------------------------------------\n\nTITLE: Array Expansion using _pg_expandarray\nDESCRIPTION: Demonstrates how to use _pg_expandarray function to expand an array into rows with values and their corresponding indices\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema._pg_expandarray(Array['a','b','c']);\n```\n\n----------------------------------------\n\nTITLE: Using string_agg function in SQL\nDESCRIPTION: Concatenates non-null input values into a string, with optional delimiter and ordering. Returns null if no non-null values are provided.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nstring_agg ( value text, delimiter text [ ORDER BY sort_expression ] ) -> output_string\n```\n\n----------------------------------------\n\nTITLE: Setting Backfill Rate Limit Syntax in SQL\nDESCRIPTION: Provides the syntax for controlling the backfill rate limit for a materialized view using the `SET BACKFILL_RATE_LIMIT` clause. Accepts `default` or a specific `rate_limit_number`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW mv_name\n    SET BACKFILL_RATE_LIMIT { TO | = } { default | rate_limit_number };\n```\n\n----------------------------------------\n\nTITLE: Example SHOW CLUSTER Query with Results in SQL\nDESCRIPTION: Demonstrates a SHOW CLUSTER command execution with sample output showing cluster nodes, their addresses, types, states, parallel units allocation, and operational status.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-cluster.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CLUSTER;\n\n------RESULT\n Id |      Addr      |           Type           |  State  | Parallel Units | Is Streaming | Is Serving | Is Unschedulable |        Started At\n----+----------------+--------------------------+---------+----------------+--------------+------------+------------------+---------------------------\n  0 | 127.0.0.1:5690 | WORKER_TYPE_META         | RUNNING |                |              |            |                  | 2024-05-07 07:57:18+00:00\n  1 | 127.0.0.1:5688 | WORKER_TYPE_COMPUTE_NODE | RUNNING | 0, 1, 2, 3     | t            | t          | f                | 2024-05-07 07:57:21+00:00\n  2 | 127.0.0.1:4566 | WORKER_TYPE_FRONTEND     | RUNNING |                |              |            |                  | 2024-05-07 07:57:24+00:00\n  3 | 127.0.0.1:6660 | WORKER_TYPE_COMPACTOR    | RUNNING |                |              |            |                  | 2024-05-07 07:57:24+00:00\n(4 rows)\n```\n\n----------------------------------------\n\nTITLE: Revoking Materialized View Privileges in SQL\nDESCRIPTION: Syntax for revoking SELECT or ALL privileges on specific materialized views or all materialized views in a schema from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {SELECT | ALL [PRIVILEGES]}\nON {MATERIALIZED VIEW mv_name [, ...]\n    | ALL MATERIALIZED VIEWS IN SCHEMA schema_name [, ...] }\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Querying Comments Metadata Table in RisingWave SQL\nDESCRIPTION: This SQL query retrieves all entries from the system-level 'rw_description' table in RisingWave, which stores comment metadata for tables and columns. The example output illustrates the structure and content of returned rows, providing the link between object IDs, roles, columns, and corresponding descriptions. This is useful for administrators querying current documentation and auditing comments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_description;\n------\n objoid | classoid | objsubid |             description\n--------+----------+----------+-------------------------------------\n   1001 |       41 |          | table to store traffic data\n   1001 |       41 |        1 | column for the duration of the trip\n   1001 |       41 |        2 |\n   1001 |       41 |        0 |\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for NATS JetStream Source/Table in RisingWave SQL\nDESCRIPTION: This SQL snippet shows the syntax for defining the schema within a `CREATE TABLE` or `CREATE SOURCE` statement when connecting to NATS JetStream. It allows specifying column names and their corresponding data types. An optional PRIMARY KEY constraint can be defined either inline for a single column or separately for multiple columns. Note that primary key constraints are enforced for tables but not for sources.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/nats-jetstream.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n(\n   column_name data_type [ PRIMARY KEY ], ...\n   [ PRIMARY KEY ( column_name, ... ) ]\n)\n```\n\n----------------------------------------\n\nTITLE: Changing Sink Owner using ALTER SINK in SQL\nDESCRIPTION: Demonstrates how to change the owner of a specified sink using the `OWNER TO` clause. This change cascades to all related internal objects. The `new_user` parameter specifies the new owner.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\n    OWNER TO new_user;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the sink named \"sink1\" to user \"user1\"\nALTER SINK sink1 OWNER TO user1;\n```\n\n----------------------------------------\n\nTITLE: Base64 Encoding GCS Credentials in Shell\nDESCRIPTION: This shell command demonstrates how to read a GCS service account key JSON file, encode its content into Base64 format without line breaks (`-b 0`), and copy the result to the clipboard using `pbcopy`. This encoded string is required for the `gcs.credential` parameter when creating a GCS source in RisingWave if not using Application Default Credentials (ADC).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/google-cloud-storage.mdx#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncat ~/Downloads/rwc-byoc-test-464bdd851bce.json | base64 -b 0 | pbcopy\n```\n\n----------------------------------------\n\nTITLE: Querying Across Databases Using SQL SELECT - SQL\nDESCRIPTION: Demonstrates how to reference and join tables across different databases using the standard three-part naming convention (database_name.schema_name.object_name) in SQL. No additional dependencies are required beyond standard SQL permission and RisingWave multi-database support. Inputs are fully-qualified table names; output is standard query result sets. Resource allocation is determined by the database to which the client is connected.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Example: Assuming connected to 'db2', query table 't1' in 'db1'\\nSELECT COUNT(*) FROM d1.public.t1;\\n\\n-- Example: Join local table 't2' with remote table 'd1.public.t1'\\nSELECT t1.v1, t2.v2\\nFROM d1.public.t1\\nJOIN public.t2 ON t1.v1 = t2.v2;\n```\n\n----------------------------------------\n\nTITLE: Example: Changing Subscription Owner in SQL\nDESCRIPTION: Demonstrates how to use the `ALTER SUBSCRIPTION ... OWNER TO` command to change the owner of the subscription named \"sub\" to the user \"admin\".\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-subscription.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the subscription named \"sub\" to user \"admin\"\nALTER SUBSCRIPTION sub OWNER TO admin;\n```\n\n----------------------------------------\n\nTITLE: Configuring Node Resources in values.yml\nDESCRIPTION: Example YAML configuration for resizing a compactor node in RisingWave by specifying resource limits and requests. Similar configurations can be applied to compute and meta nodes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# To resize other types of node, please replace the name with\n# computeComponent, or metaComponent.\ncompactorComponent:\n  resources:\n    # The maximum amount of CPU and memory the Pod can use.\n    limits:\n      cpu: 1\n      memory: 2Gi\n    # The minimum amount of CPU and memory that the Pod is guaranteed to have.\n    requests:\n      # 0.1 cores\n      cpu: 100m\n      memory: 64Mi\n```\n\n----------------------------------------\n\nTITLE: Moving View to a Different Schema with ALTER VIEW SET SCHEMA in SQL\nDESCRIPTION: Syntax for moving an existing SQL view to a different schema using the `ALTER VIEW ... SET SCHEMA` clause. Requires the view name (`view_name`) and the target schema name (`schema_name`). The user executing this command must own the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER VIEW view_name\n    SET SCHEMA schema_name;\n```\n```\n\n----------------------------------------\n\nTITLE: Dropping a Sink in RisingWave (SQL)\nDESCRIPTION: Illustrates how to remove a specific sink (`orders_sink0`) using the `DROP SINK` command in RisingWave. This operation stops the data flow managed by the specified sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-sink-into.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP SINK orders_sink0;\n```\n\n----------------------------------------\n\nTITLE: Creating and Viewing Table Parallelism in RisingWave\nDESCRIPTION: This example creates a new table and then views its parallelism settings by querying the rw_fragments system table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table.\nCREATE TABLE t(v int);\n-- View parrellelism by rw_fragments table.\nSELECT fragment_id, parallelism FROM rw_fragments;\n\n------RESULTS\n fragment_id | parallelism\n-------------+-------------\n           1 |           3\n           2 |           3\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Session User Name in SQL\nDESCRIPTION: The session_user function returns the name of the current session user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nsession_user → *session_user_name*\nsession_user() → *session_user_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT session_user(); → `root`\n```\n\n----------------------------------------\n\nTITLE: Altering Backfill Rate Limit for Materialized Views in SQL\nDESCRIPTION: Shows how to alter the backfill rate limit for materialized views using SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nALTER MATERIALIZED VIEW view_name SET (backfill_rate_limit = ...)\n```\n\n----------------------------------------\n\nTITLE: Using Scalar Functions as Aggregate Functions in SQL\nDESCRIPTION: Demonstrates the new capability to use scalar functions with list inputs as aggregate functions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT scalar_function(column_name) FROM table_name GROUP BY ...\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample Table and Inserting Data in RisingWave (SQL)\nDESCRIPTION: This SQL script first creates a table named 't' in RisingWave with columns for a floating-point value ('v') and a timestamp ('ts'). It then inserts five sample data rows into this table. This table is intended to be used later in the guide as a data source for creating visualizations in Apache Superset.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/superset.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (v float, ts timestamp);\nINSERT INTO t VALUES (1.0, '2022-11-15 15:35:40'),\n(2.1, '2022-11-15 15:36:24'),\n(3.5, '2022-11-15 15:37:32'),\n(4.2, '2022-11-15 15:38:12'),\n(4.2, '2022-11-15 15:38:21');\n```\n\n----------------------------------------\n\nTITLE: Querying Results from a Materialized View in RisingWave\nDESCRIPTION: Shows how to query the results from a previously created materialized view using the VALUES clause in RisingWave SQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/values-clause.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM join_mv;\n-- Results\n id | name | number |        job        \n----+------+--------+-------------------\n  2 | Jane |      2 | Software Engineer\n  3 | Bob  |      3 | Accountant\n  1 | John |      1 | Writer\n```\n\n----------------------------------------\n\nTITLE: Extracting Substring from Binary String in SQL\nDESCRIPTION: The substr function extracts a substring from a binary string (bytea) starting at a specified position for a given number of bytes. If the count is omitted, it extends to the end of the string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nsubstr ( bytea_value, start_int, [, count_int] ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT substr('abcde'::bytea, 2, 7);\n------RESULT\n\\x62636465\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT substr('abcde'::bytea, -2, 5);\n------RESULT\n\\x6162\n```\n\n----------------------------------------\n\nTITLE: Connecting to Self-hosted PostgreSQL\nDESCRIPTION: Command to connect to a self-hosted PostgreSQL instance using psql. It includes the connection string with username, password, host, port, and database name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npsql postgresql://myuser:123456@127.0.0.1:5432/mydb\n```\n\n----------------------------------------\n\nTITLE: Querying Filtered Data from PostgreSQL Table via postgres_query - SQL\nDESCRIPTION: Demonstrates a RisingWave SQL query that retrieves rows (where id > 90) from a PostgreSQL table using the postgres_query TVF. Connection and authentication information is specified via literal arguments, as is the free-form query to execute on the remote database. The output provides a static snapshot (rows 91-100), with no ongoing sync or CDC behavior.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-table.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * \nFROM postgres_query('localhost', '5432', 'postgres', 'postgres', 'mydb', 'SELECT * FROM test WHERE id > 90;');\n----RESULT\n91 91\n92 92\n93 93\n94 94\n95 95\n96 96\n97 97\n98 98\n99 99\n100 100\n```\n\n----------------------------------------\n\nTITLE: Revoking Source Privileges in SQL\nDESCRIPTION: Syntax for revoking SELECT or ALL privileges on specific sources or all sources in a schema from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE {SELECT | ALL [PRIVILEGES]}\nON {  SOURCE source_name [, ...]\n    | ALL SOURCES IN SCHEMA schema_name [, ...] }\nFROM user_name [GRANTED BY user_name];\n```\n\n----------------------------------------\n\nTITLE: Creating a Source in RisingWave for Snowflake Sink\nDESCRIPTION: Example of creating a source in RisingWave that generates data to be sunk to Snowflake. This source uses the datagen connector to generate sequential IDs and random names.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/snowflake.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1_source (id int,name varchar)\nWITH (\n\tconnector ='datagen',\n\tfields.id.kind ='sequence',\n\tfields.id.start ='1',\n\tfields.id.end ='10000',\n\tfields.name.kind ='random',\n\tfields.name.length ='10',\n\tdatagen.rows.per.second ='200'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Selecting Row Count in SQL - SQL\nDESCRIPTION: This SQL statement performs a COUNT aggregate function to determine the total number of rows in table 't'. It is used as an example of a batch query in the RisingWave architecture, suitable for one-off analytic queries or point lookups. The query expects a table 't' to exist and returns a single integer count as its output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/reference/architecture.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v2.0.0 from Docker\nDESCRIPTION: Command to pull and run RisingWave version 2.0.0 in standalone mode with ports 4566 and 5691 exposed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v2.0.0-standalone single_node\n```\n\n----------------------------------------\n\nTITLE: Configuring LoadBalancer Service Type for RisingWave in Kubernetes\nDESCRIPTION: This YAML snippet shows how to configure the RisingWave service to use LoadBalancer type in the risingwave.yaml file. This is useful when using managed Kubernetes services provided by cloud vendors to expose the service to the public network.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\n# ...\nkind: RisingWave\n...\nspec:\n  frontendServiceType: LoadBalancer\n# ...\n```\n\n----------------------------------------\n\nTITLE: Adding Table Comment with RisingWave SQL\nDESCRIPTION: This SQL snippet shows how to annotate the table 't1' in RisingWave with a descriptive comment. The statement helps clarify the table's purpose for developers and analysts. The dependency is an existing table named 't1'; the command attaches the comment as metadata, which can later be retrieved or removed as needed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCOMMENT ON TABLE t1 IS 'table to store traffic data';\n```\n\n----------------------------------------\n\nTITLE: Calling a Table-Returning Python UDF in SQL\nDESCRIPTION: Shows how to call the previously created 'series' function to generate a sequence of 5 integers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/embedded-python-udfs.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM series(5);\n\n-----RESULT\n 0\n 1\n 2\n 3\n 4\n(5 rows)\n```\n\n----------------------------------------\n\nTITLE: Setting Global Streaming Parallelism in RisingWave\nDESCRIPTION: This example sets the streaming_parallelism parameter to 3 using the SET command, which affects the default parallelism for newly created tables.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSET streaming_parallelism = 3;\n```\n\n----------------------------------------\n\nTITLE: Creating a RisingWave Table to Receive RudderStack Webhooks with Raw String Validation (SQL)\nDESCRIPTION: This SQL statement creates a table named `wbhtable` for receiving RudderStack webhook data, similar to the previous example. However, instead of using a pre-defined secret, it uses `VALIDATE AS secure_compare(...)` with a raw string ('TEST_WEBHOOK') directly embedded in the command for validation. Incoming requests' lowercase `authorization` header value must match this raw string for the data to be ingested. This method is less secure than using a named secret.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/rudderstack-webhook.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table wbhtable (\n  data JSONB\n) WITH (\n  connector = 'webhook',\n) VALIDATE AS secure_compare(\n  headers->>'authorization',\n  'TEST_WEBHOOK'\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Materialized View in RisingWave\nDESCRIPTION: Creates a materialized view named 'counter' that calculates total distance and duration from the walk table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg2\n\nconn = psycopg2.connect(host=\"localhost\", port=4566, user=\"root\", dbname=\"dev\")\nconn.autocommit = True\n\nwith conn.cursor() as cur:\n    cur.execute(\"\"\"CREATE MATERIALIZED VIEW counter\n    AS SELECT\n    SUM(distance) as total_distance,\n    SUM(duration) as total_duration\n    FROM walk;\"\"\")\n\nconn.close()\n```\n\n----------------------------------------\n\nTITLE: Querying Date Truncation (Post-v1.1.0) in RisingWave SQL\nDESCRIPTION: Illustrates the behavior of the `date_trunc` function in RisingWave version 1.1.0 and later when applied to a `date` type. Due to a breaking change for PostgreSQL compatibility, the function now casts the date to `timestamptz` and returns the truncated timestamp including the timezone offset (`+00:00`). Old queries saved as views might need type adjustments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\n            SELECT date_trunc('month', date '2023-03-04');\n\n                    date_trunc\n            ---------------------------\n             2023-03-01 00:00:00+00:00\n            (1 row)\n```\n\n----------------------------------------\n\nTITLE: Listing Internal Tables in RisingWave\nDESCRIPTION: SQL command to list internal tables in RisingWave. This is used to find the relevant backfill executor state for monitoring CDC progress.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW INTERNAL TABLES;\n```\n\n----------------------------------------\n\nTITLE: Querying a materialized view in RisingWave using Ruby\nDESCRIPTION: This code demonstrates how to query the 'counter' materialized view in RisingWave using Ruby. It executes a SELECT statement and iterates through the results, printing each row.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/ruby.mdx#2025-04-23_snippet_3\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'pg'\n\nconn = PG.connect(host: '127.0.0.1', port: 4566, dbname: 'dev', user: 'root')\n\nres = conn.exec('SELECT * FROM counter;')\nres.each do |row|\n  puts row\nend\n```\n\n----------------------------------------\n\nTITLE: Installing RisingWave Operator Latest Version\nDESCRIPTION: Command to install the latest version of RisingWave Operator on Kubernetes\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply --server-side -f https://github.com/risingwavelabs/risingwave-operator/releases/latest/download/risingwave-operator.yaml\n```\n\n----------------------------------------\n\nTITLE: Using OCTET_LENGTH Function in SQL\nDESCRIPTION: The octet_length() function returns the number of bytes in the string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_17\n\nLANGUAGE: SQL\nCODE:\n```\noctet_length ( input_string )\n```\n\nLANGUAGE: SQL\nCODE:\n```\noctet_length('wave') → 4\n```\n\n----------------------------------------\n\nTITLE: Creating Market Data Table in SQL\nDESCRIPTION: Creates a table to store market data including asset ID, timestamp, bid price, ask price, price, and rolling volume.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/market-trade-surveillance.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE market_data (\n    asset_id INT,\n    timestamp TIMESTAMPTZ,\n    bid_price NUMERIC,\n    ask_price NUMERIC,\n    price NUMERIC,\n    rolling_volume INT\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Primary Key for Improved Locality - SQL\nDESCRIPTION: Demonstrates creating a table with a primary key which affects storage ordering of rows and thus improves cache locality during backfilling operations in RisingWave. This schema enhances read performance by ensuring that rows with the same key (`v1`) are stored together. Requires RisingWave SQL with table creation privileges; input is column definitions and primary key constraint; output is a table optimized for locality.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/performance-best-practices.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(v1 int primary key, v2 varchar);\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Transactions Table in RisingWave\nDESCRIPTION: SQL script to create a 'transactions' table in RisingWave, insert sample data, and query the inserted data. This script demonstrates table creation, data insertion, and basic querying in RisingWave through Bytebase.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/bytebase.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Step 1: Create the transactions table\nCREATE TABLE transactions (\n    transaction_id INT,\n    customer_id INT,\n    transaction_type VARCHAR,\n    amount DECIMAL,\n    currency VARCHAR,\n    transaction_tp TIMESTAMP,\n    transaction_status VARCHAR\n);\n\n-- Step 2: Insert sample data into the transactions table\nINSERT INTO transactions (transaction_id, customer_id, transaction_type, amount, currency, transaction_tp, transaction_status) VALUES\n(1, 101, 'Deposit', 500.00, 'USD', '2024-03-15 09:30:00', 'Completed'),\n(2, 102, 'Withdrawal', 200.00, 'EUR', '2024-03-15 10:15:00', 'Pending'),\n(3, 103, 'Transfer', 1000.00, 'GBP', '2024-03-15 11:00:00', 'Completed'),\n(4, 104, 'Deposit', 250.50, 'INR', '2024-03-15 12:45:00', 'Failed'),\n(5, 105, 'Withdrawal', 750.75, 'USD', '2024-03-15 14:20:00', 'Completed'),\n(6, 106, 'Transfer', 5000.00, 'EUR', '2024-03-15 15:30:00', 'Pending');\n\n-- Step 3: Show data insertion\nSELECT * FROM transactions;\n```\n\n----------------------------------------\n\nTITLE: Storage Data File Cache Configuration in TOML\nDESCRIPTION: Configures the storage data file cache directory and capacity settings for RisingWave nodes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[storage.data_file_cache]\ndir = \"/risingwave/foyer/meta\"\ncapacity_mb = 20480\n```\n\n----------------------------------------\n\nTITLE: Removing Table Comment with RisingWave SQL\nDESCRIPTION: This SQL statement clears (removes) the existing comment metadata from a RisingWave table, in this example 't1', by setting the comment to NULL. This operation leaves the object without any annotation, which can be useful for cleanup or schema changes. The targeted table must be present in the database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-comment-on.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCOMMENT ON table t1 IS NULL;\n```\n\n----------------------------------------\n\nTITLE: Syntax for ALTER DATABASE in SQL\nDESCRIPTION: Provides the basic syntax structure for the `ALTER DATABASE` command in SQL. The `alter_option` specifies the specific modification to be performed on the database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-database.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE database_name\n    alter_option;\n```\n\n----------------------------------------\n\nTITLE: Altering Secrets Using SQL in RisingWave\nDESCRIPTION: Demonstrates the generic ALTER SECRET SQL command syntax for updating the value of an existing secret in the RisingWave system. Requires an existing secret and permission to execute ALTER SECRET statements. Parameters include the secret name, backend (currently only 'meta'), and the new secret value. The primary output is the update of the stored secret, with no direct result set. The secret's value will not change for running jobs until the jobs are restarted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-secret.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER SECRET secret_name WITH (\n    backend = 'meta'\n) AS 'your_new_secret';\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Employees Table in SQL\nDESCRIPTION: SQL code to create the 'employees' table with columns for employee_id, employee_name, and salary. It also includes INSERT statements to populate the table with sample data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/order-by-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    employee_id INT,\n    employee_name VARCHAR,\n    salary INT\n);\n\nINSERT INTO employees (employee_id, employee_name, salary) VALUES\n(1, 'Alice', 50000),\n(2, 'Bob', 60000),\n(3, 'Charlie', 70000),\n(4, 'David', 55000),\n(5, 'Eve', 75000);\n```\n\n----------------------------------------\n\nTITLE: Dropping a Function with a Unique Name in SQL\nDESCRIPTION: Demonstrates dropping the function `f2` by specifying only its name. This is possible because `f2` is unique within the schema after the creation step.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION f2;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Custom Permissions and Password in SQL\nDESCRIPTION: This SQL command creates a new user with the CREATEDB permission and sets a password in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/access-control.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER user001 WITH CREATEDB PASSWORD '1234abcd';\n```\n\n----------------------------------------\n\nTITLE: Using min Function with rw_int256 in SQL\nDESCRIPTION: Shows how to use the min function to find the minimum value in a set of rw_int256 values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT min(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Advanced WITH ORDINALITY with Column Aliases\nDESCRIPTION: Demonstrates using WITH ORDINALITY with CROSS JOIN and custom column aliases. The query unnests array elements from a table column while maintaining row numbering.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/with-ordinality-clause.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t CROSS JOIN unnest(t.arr) WITH ORDINALITY AS x(elts, num);\n```\n\n----------------------------------------\n\nTITLE: Querying Active Streaming Jobs and Their Resource Groups in RisingWave (SQL)\nDESCRIPTION: Queries the rw_streaming_jobs system catalog table to display currently active streaming jobs, including each job’s ID, name, status, database ID, and resource group assignment. This SELECT statement enables administrators to troubleshoot or audit the placement of streaming workloads across resource groups. It returns a list of jobs with relevant metadata; requires appropriate read permissions on system catalogs.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/workload-isolation-interaction.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT job_id, name, status, database_id, resource_group FROM rw_streaming_jobs;\n-- Example Output:\n job_id | name          | status  | database_id | resource_group\n--------+---------------+---------+-------------+--------------------\n      6 | payment_processor_mv| CREATED |       10001 | rg_high_cpu\n      7 | dashboard_agg_mv | CREATED |       10002 | rg_general_purpose\n      8 | user_activity_mv | CREATED |       10003 | rg_default\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Displaying Subscription Cursors in RisingWave (Bash)\nDESCRIPTION: This command shows all subscription cursors in the current session. It returns a table with two columns: Name (cursor name) and SubscriptionName (associated subscription).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-subscription-cursors.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SUBSCRIPTION CURSORS;\n```\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SUBSCRIPTION CURSORS;\n\n------RESULT\n Name | SubscriptionName\n------+------------------\n cur2 | sub\n cur  | sub\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: Determining Data Type of Value in SQL\nDESCRIPTION: The pg_typeof() function returns the standard name of the data type of the provided value. It returns a regtype, which is an OID alias type, displaying as a type name.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\npg_typeof() → regtype\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_typeof(round(null));  → `double precision`\nSELECT pg_typeof(row(true, 1, 'hello')); → `record`\nSELECT pg_typeof(array[1, 2]); → `integer[]`\n```\n\n----------------------------------------\n\nTITLE: Creating a Base Table without Primary Key in SQL\nDESCRIPTION: Demonstrates the creation of a basic table named `t` with columns `v1`, `v2`, and `v3` without specifying a primary key. This structure can lead to non-sequential data storage, potentially impacting backfilling performance for downstream materialized views that group by `v1`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/best-practices.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(v1 int, v2 varchar, v3 timestamp);\n```\n\n----------------------------------------\n\nTITLE: Configuring Canal JSON Format in RisingWave\nDESCRIPTION: SQL syntax for configuring Canal JSON format in RisingWave. Supports the TiCDC dialect of the Canal CDC format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/supported-sources-and-formats.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT CANAL\nENCODE JSON\n```\n\n----------------------------------------\n\nTITLE: ALTER TABLE RENAME TO Syntax in RisingWave SQL\nDESCRIPTION: This command changes the name of a table to a new name provided by the user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\n    RENAME TO new_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Table for CDC Historical Data Backfill in RisingWave\nDESCRIPTION: SQL command to create a RisingWave table for backfilling historical data from a MySQL CDC source. This is used to demonstrate monitoring of historical data ingestion progress.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t3 (id INTEGER, v1 TIMESTAMP WITH TIME ZONE, PRIMARY KEY(id)) FROM mysql_source TABLE 'mydb.t3';\n```\n\n----------------------------------------\n\nTITLE: Example of using mode function in SQL\nDESCRIPTION: Calculates the mode of values in column1 from table1 using the WITHIN GROUP clause and ORDER BY for the mode calculation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT mode() WITHIN GROUP (ORDER BY column1) FROM table1;\n```\n\n----------------------------------------\n\nTITLE: Renaming a View with ALTER VIEW RENAME TO in SQL\nDESCRIPTION: Syntax for renaming an existing SQL view using the `ALTER VIEW ... RENAME TO` clause. Requires the current view name (`view_name`) and the desired new name (`new_name`). The user executing this command must own the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER VIEW view_name\n    RENAME TO new_name;\n```\n```\n\n----------------------------------------\n\nTITLE: Using DESCRIBE to Inspect a Table in SQL\nDESCRIPTION: Shows an example of using the `DESCRIBE` command to retrieve the structure, column details, comments, primary key, distribution key, and index information for the previously created `customers` table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-describe.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE customers;\n```\n\n----------------------------------------\n\nTITLE: Showing Cursors in SQL\nDESCRIPTION: Illustrates new commands to display query cursors and subscription cursors in the current session.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CURSORS\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW SUBSCRIPTION CURSORS\n```\n\n----------------------------------------\n\nTITLE: Initializing data_directory Parameter via Meta Node CLI - Bash\nDESCRIPTION: This Bash code snippet provides a direct example of initializing the data_directory parameter for the meta node in a RisingWave cluster. The command should be executed prior to starting the cluster and will set the persistent storage directory path. Dependencies include the RisingWave installation and CLI access to the meta node. Only for initial setup or reconfiguration before cluster start.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-system-parameters.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmeta-node --data_directory \"hummock_001\"\n```\n\n----------------------------------------\n\nTITLE: Renaming a User Example - SQL\nDESCRIPTION: This example provides a practical use of the ALTER USER command: renaming user 'user1' to 'user001'. It illustrates how to perform a user rename operation, which outputs confirmation of the action. The target user must pre-exist in the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-user.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER user1 RENAME TO user001;\n```\n\n----------------------------------------\n\nTITLE: Example: Setting Materialized View Parallelism in SQL\nDESCRIPTION: Demonstrates how to set the parallelism level of the materialized view `m_join` to a fixed value of 3.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the parallelism of the materialized view \"m_join\" to 3.\nALTER MATERIALIZED VIEW m_join SET PARALLELISM = 3;\n```\n\n----------------------------------------\n\nTITLE: Creating Target Table in PostgreSQL\nDESCRIPTION: SQL query to create a table named 'target_count' in PostgreSQL, which will be the sink target for data from RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE target_count (\n  target_id VARCHAR(128) PRIMARY KEY,\n  target_count BIGINT\n);\n```\n\n----------------------------------------\n\nTITLE: Querying Iceberg Snapshots from System Table\nDESCRIPTION: Query to retrieve all Iceberg snapshots from the rw_iceberg_snapshots system table, showing snapshot details and manifest information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM rw_iceberg_snapshots;\n```\n\n----------------------------------------\n\nTITLE: Configuring PostgreSQL Connection Parameters for Looker to RisingWave - Markdown\nDESCRIPTION: This snippet provides example parameter values for setting up the Looker PostgreSQL data source connection to a RisingWave database. It specifies the default host, port, database, username, and password fields to be provided in Looker for a successful connection. There are no external dependencies, though both Looker and RisingWave must be running and accessible. The snippet is designed to guide users in completing the configuration screen within Looker, with the expected input being the host (e.g., localhost), port (default 4566), database name (default dev), username (default root), and an empty password for the default user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/looker.mdx#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* Host: The hostname or IP address of the RisingWave database. The default **Host** for RisingWave is `localhost`.\n* Port: The port number of the RisingWave database. The default **Port** for RisingWave is `4566`. If left blank, the default port of PostgreSQL `5432` will be used.\n* Database: The name of the RisingWave database you want to connect to. The default **Database** is `dev`.\n* Username: The username for accessing the database. The default **Username** is `root`.\n* Password: The password associated with the provided username. By default, there is no password for `root`.\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Size in SQL\nDESCRIPTION: Demonstrates the use of pg_table_size() function to get the size of a table in bytes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_table_size('t1');\n---------RESULT\n pg_table_size\n---------------\n           240\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Moving Materialized View Schema Syntax in SQL\nDESCRIPTION: Shows the syntax for moving a materialized view to a different schema using the `SET SCHEMA` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW materialized_view_name\n    SET SCHEMA schema_name;\n```\n\n----------------------------------------\n\nTITLE: Starting a Read-Only Transaction in RisingWave\nDESCRIPTION: An example of starting a read-only transaction in RisingWave using the START TRANSACTION command with the READ ONLY option. The result shows the transaction has started successfully.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-start-transaction.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION READ ONLY;\n-------RESULT\nSTART_TRANSACTION\n\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/GSSAPI Authentication\nDESCRIPTION: SQL command to create a source with SASL/GSSAPI (Kerberos) authentication. Includes Kerberos-specific configuration parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE IF NOT EXISTS source_5 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='GSSAPI',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.kerberos.service.name='kafka',\n   properties.sasl.kerberos.keytab='/etc/krb5kdc/kafka.client.keytab',\n   properties.sasl.kerberos.principal='kafkaclient4@AP-SOUTHEAST-1.COMPUTE.INTERNAL',\n   properties.sasl.kerberos.kinit.cmd='sudo kinit -R -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal} || sudo kinit -kt \"%{sasl.kerberos.keytab}\" %{sasl.kerberos.principal}',\n   properties.sasl.kerberos.min.time.before.relogin='10000'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Querying Streaming Parallelism\nDESCRIPTION: SQL query to view the current scaling policy of tables, materialized views, and sinks.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/k8s-cluster-scaling.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndev=> SELECT * FROM rw_streaming_parallelism;\n  id  | name |   relation_type   | parallelism\n------+------+-------------------+-------------\n 1001 | t    | table             | FIXED(4)\n 1002 | mv1  | materialized view | AUTO\n 1004 | idx  | index             | AUTO\n(3 rows)\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Sample MySQL Table - SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a 'test' table in a MySQL database with a variety of data types for compatibility testing, then populate it with a representative row of sample data. The table includes types such as bigint, bit, bool, float, various blob types, and json to showcase data type mapping to RisingWave. This creates a realistic scenario for verifying how different MySQL data types are ingested and converted through the mysql_query TVF.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-table.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test (\n    id bigint primary key, v0 bit, v1 bool, v2 tinyint(1),\n    v3 tinyint(2), v4 smallint, v5 mediumint, v6 integer,\n    v7 bigint, v8 float, v9 double, v10 numeric(4, 2),\n    v11 decimal(4, 2), v12 char(255), v13 varchar(255),\n    v14 bit(10), v15 tinyblob, v16 blob, v17 mediumblob,\n    v18 longblob, v19 date, v20 time, v21 timestamp,\n    v22 json\n);\n\nINSERT INTO test SELECT\n    1 as id, true as v0, true as v1, 2 as v2, 3 as v3, 4 as v4, 5 as v5,\n    6 as v6, 7 as v7, 1.08 as v8, 1.09 as v9, 1.10 as v10, 1.11 as v11,\n    'char' as v12, 'varchar' as v13, b'1010' as v14, x'16' as v15, x'17' as v16,\n    x'18' as v17, x'19' as v18, '2021-01-01' as v19, '12:34:56' as v20,\n    '2021-01-01 12:34:56' as v21, JSON_OBJECT('key1', 1, 'key2', 'abc');\n```\n\n----------------------------------------\n\nTITLE: Altering Tables with Generated Columns in SQL\nDESCRIPTION: Shows that ALTER TABLE commands are now supported on tables with generated columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name ...\n```\n\n----------------------------------------\n\nTITLE: Using LEFT Function in SQL\nDESCRIPTION: The left() function returns the first input integer characters in the input string. If the input integer is negative, the last input_integer characters are removed from the output string.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\nleft ( input_string, input_integer ) → output_string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nleft('risingwave', 4) → 'risi'\nleft('risingwave', -4) → 'rising'\n```\n\n----------------------------------------\n\nTITLE: Moving Sink to a Different Schema using ALTER SINK in SQL\nDESCRIPTION: Shows how to move an existing sink to a different schema using the `SET SCHEMA` clause. The `schema_name` parameter indicates the target schema for the sink.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-sink.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER SINK sink_name\n    SET SCHEMA schema_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Move the sink named \"test_sink\" to the schema named \"test_schema\"\nALTER SINK test_sink SET SCHEMA test_schema;\n```\n\n----------------------------------------\n\nTITLE: Granting Privileges in PostgreSQL\nDESCRIPTION: SQL query to grant necessary privileges (SELECT, INSERT, UPDATE, DELETE) on a specific table to a user in PostgreSQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/postgresql.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT, INSERT, UPDATE, DELETE ON [table_name] TO [username];\n```\n\n----------------------------------------\n\nTITLE: SHOW CONNECTIONS Basic Syntax in RisingWave\nDESCRIPTION: The basic syntax for the SHOW CONNECTIONS command which can optionally include a LIKE expression for filtering connection names using pattern matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-connections.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW CONNECTIONS [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample Table for Top-N Examples in RisingWave (SQL)\nDESCRIPTION: SQL statement to create a simple table named 't' with three integer columns (x, y, z). This table serves as the basis for demonstrating Top-N query examples in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/top-n-by-group.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (x int, y int, z int);\n```\n\n----------------------------------------\n\nTITLE: Querying 5 Random Rows without ORDER BY in SQL\nDESCRIPTION: This SQL query selects the department, job title, and average salary from the employees table and limits the output to 5 rows without sorting. It demonstrates the use of LIMIT without ORDER BY, which can result in non-deterministic output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/limit-clause.mdx#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT department, job_title, AVG(salary)\nFROM employees\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Renaming a Schema With ALTER SCHEMA RENAME TO - SQL\nDESCRIPTION: Shows how to rename an existing schema using the RENAME TO clause of ALTER SCHEMA. The first snippet displays the generic syntax, and the second gives a concrete example renaming \"schema0\" to \"schema1\". Users must have CREATE privilege for the database containing the schema, or be a superuser. Inputs include the current schema name and the new name; the schema is renamed if privileges are sufficient, else an error is returned.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-schema.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER SCHEMA current_schema_name\n    RENAME TO new_name;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Rename the schema named \"schema0\" to \"schema1\".\nALTER SCHEMA schema0 RENAME TO schema1;\n```\n\n----------------------------------------\n\nTITLE: Uninstalling RisingWave with Helm\nDESCRIPTION: Command to uninstall RisingWave from a Kubernetes cluster using Helm. This gracefully removes the RisingWave deployment named 'my-risingwave'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/uninstall-risingwave-k8s.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm uninstall my-risingwave\n```\n\n----------------------------------------\n\nTITLE: Updating Struct Type Handling\nDESCRIPTION: Example demonstrating the new way of handling STRUCT types with named fields and dictionary return values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n- @udf(input_types=['VARCHAR'], result_type='STRUCT<VARCHAR, VARCHAR>')\n+ @udf(input_types=['VARCHAR'], result_type='STRUCT<key: VARCHAR, value: VARCHAR>')\n  def key_value(pair: str):\n      key, value = pair.split('=')\n-     return (key, value)\n+     return {'key': key, 'value': value}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Role Name in SQL\nDESCRIPTION: The current_role function returns the name of the role that the current user is acting as, if the current user is a member of one or more roles.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncurrent_role → *current_role_name*\ncurrent_role() → *current_role_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT current_role(); → 'root'\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave using ClusterIP in Kubernetes\nDESCRIPTION: These commands create a PostgreSQL Pod, attach to it, and connect to RisingWave using psql. This method is used when the RisingWave frontend service is of type ClusterIP and not directly accessible outside Kubernetes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f https://raw.githubusercontent.com/risingwavelabs/risingwave-operator/main/docs/manifests/psql/psql-console.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\nkubectl exec -it psql-console -- bash\n```\n\nLANGUAGE: bash\nCODE:\n```\npsql -h risingwave-frontend -p 4567 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Using count Function with rw_int256 in SQL\nDESCRIPTION: Demonstrates the usage of the count function to count non-null rows of rw_int256 type, returning a bigint result.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Installing RisingWave Using Helm\nDESCRIPTION: Command to install the RisingWave Helm chart with customized configuration from a values.yaml file. This deploys the latest stable version of RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nhelm install -n risingwave --create-namespace --set wait=true -f values.yaml <my-risingwave> risingwavelabs/risingwave\n```\n\n----------------------------------------\n\nTITLE: Inserting data into RisingWave table\nDESCRIPTION: SQL query to insert sample data into the 'personnel' table in RisingWave and flush the changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/mysql.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO personnel VALUES (1, 'Alice'), (2, 'Bob');\n\nFLUSH;\n```\n\n----------------------------------------\n\nTITLE: Using bool_or function in SQL\nDESCRIPTION: Returns true if any non-null input value is true, otherwise false. Takes boolean input values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nbool_or ( boolean ) -> boolean\n```\n\n----------------------------------------\n\nTITLE: Setting Source Rate Limit to Default in RisingWave\nDESCRIPTION: This example shows how to set the source rate limit of a Kafka source table to the default value.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-table.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\n-- Pause the source\nALTER TABLE kafka_source SET source_rate_limit TO default;\n```\n\n----------------------------------------\n\nTITLE: Range Function with Timestamps\nDESCRIPTION: Example demonstrating how to generate timestamp sequences using the range() function\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT range\nFROM range(\n    '2008-03-01 00:00:00'::TIMESTAMP,\n    '2008-03-04 12:00:00'::TIMESTAMP,\n    interval '12' hour\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Streaming Job Parallelism in RisingWave YAML (bash)\nDESCRIPTION: This configuration snippet shows how to tune RisingWave's metadata service settings to disable automatic parallelism control and set a fixed default parallelism for streaming jobs. The file must be located at `risingwave/src/config/<your-config>.yaml`, and parameters like `disable_automatic_parallelism_control` and `default_parallelism` should be adjusted before spinning up jobs. Expected inputs are the YAML file and settings; the output is a new default parallelism behavior for future jobs. Ensure you reload the service or cluster for changes to take effect.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-a-large-number-of-streaming-jobs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[meta]\ndisable_automatic_parallelism_control=true\ndefault_parallelism=8\n```\n\n----------------------------------------\n\nTITLE: Installing PostgreSQL Client on Debian/Ubuntu\nDESCRIPTION: Installs only the PostgreSQL client packages on Debian/Ubuntu systems, which includes psql without the full PostgreSQL server.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install postgresql-client\n```\n\n----------------------------------------\n\nTITLE: Calculating Stable Memory Usage Target (Bash)\nDESCRIPTION: Illustrates how to calculate the target stable memory usage percentage based on the configured reserved memory proportion and the stable cache eviction threshold (`memory_controller_threshold_stable`). This example shows that with 30% reserved memory and a stable threshold of 0.8, RisingWave aims to keep memory usage around 56% of total memory during normal operation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/tune-reserved-memory.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nMemory usage = 1.0 * (1 - 0.30) * 0.8 = 0.56 = 56%\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW CREATE VIEW Syntax in SQL\nDESCRIPTION: The basic syntax for the SHOW CREATE VIEW command, which requires specifying the name of the view to display its definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-create-view.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE VIEW view_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Automatic Schema Mapping in PostgreSQL CDC\nDESCRIPTION: Creates a table that automatically maps and ingests all columns from a PostgreSQL source table using the wildcard (*) selector. This approach eliminates the need to manually define individual columns.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE <table_name> (*) FROM <source_name> TABLE '<schema_name>.<table_name>';\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Source with SASL/SCRAM Authentication without SSL in RisingWave SQL\nDESCRIPTION: This example illustrates creating a Kafka source table with SASL/SCRAM authentication without SSL encryption. It specifies the SCRAM-SHA-256 mechanism and SASL credentials in the WITH clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/kafka.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS table_4 (\n   column1 varchar,\n   column2 integer,\n)\nWITH (\n   connector='kafka',\n   topic='quickstart-events',\n   properties.bootstrap.server='localhost:9093',\n   scan.startup.mode='earliest',\n   properties.sasl.mechanism='SCRAM-SHA-256',\n   properties.security.protocol='SASL_PLAINTEXT',\n   properties.sasl.username='admin',\n   properties.sasl.password='admin-secret'\n) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Changing View Owner with ALTER VIEW OWNER TO in SQL\nDESCRIPTION: Syntax for changing the owner of an existing SQL view using the `ALTER VIEW ... OWNER TO` clause. Requires the view name (`view_name`) and the username of the new owner (`new_user`). The user executing this command must own the view.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER VIEW view_name\n    OWNER TO new_user;\n```\n```\n\n----------------------------------------\n\nTITLE: Checking Helm Release Status\nDESCRIPTION: Command to check the current status of the RisingWave Helm release and its output showing version information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm list -f <risingwave-cluster>\n```\n\nLANGUAGE: sql\nCODE:\n```\nNAME       NAMESPACE  REVISION UPDATED                                  STATUS   CHART                        APP VERSION\nrisingwave default     21       2023-09-20 13:20:58.389424056 +0000 UTC  deployed risingwave-0.1.16 v1.3.0\n```\n\n----------------------------------------\n\nTITLE: Setting Runtime Parameter Values Using SET Command in SQL\nDESCRIPTION: This snippet shows how to set or reset the value of a runtime parameter for the current session using the SET SQL command. Dependencies include an active SQL session; no further prerequisites are needed. The key parameters are 'parameter_name' (the configuration variable) and the new 'value', which could be a bare value, a quoted value, or 'DEFAULT' to reset. The command only affects the current session, and the new value takes effect immediately.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/view-configure-runtime-parameters.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET parameter_name { TO | = } { value | 'value' | DEFAULT};\n```\n\n----------------------------------------\n\nTITLE: Installing libpq PostgreSQL Client Tools on macOS\nDESCRIPTION: Installs the libpq package via Homebrew on macOS, which includes psql and other PostgreSQL client utilities without the full server.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbrew install libpq\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Local Pub/Sub Emulator\nDESCRIPTION: Shows how to configure a docker-compose.yaml file to set up a local Google Pub/Sub emulator for testing purposes. The emulator runs on port 8900 and is configured with a demo project.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/google-pub-sub.mdx#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  pubsub-emulator:\n    image: google/cloud-sdk:latest\n    command: >\n      gcloud beta emulators pubsub start --project=demo --host-port=0.0.0.0:8900\n    ports:\n      - \"8900:8900\"\n```\n\n----------------------------------------\n\nTITLE: System and Storage Configuration Example\nDESCRIPTION: Complete example of system and storage configurations including barrier interval, checkpoint frequency, and cache refill settings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[system]\nbarrier_interval_ms = 1000\ncheckpoint_frequency = 1\nstate_store = \"hummock+minio://hummockadmin:hummockadmin@127.0.0.1:9301/hummock001\"\ndata_directory = \"hummock_001\"\nbackup_storage_url = \"minio://hummockadmin:hummockadmin@127.0.0.1:9301/hummock001\"\nbackup_storage_directory = \"hummock_001/backup\"\n\n[storage.cache_refill]\ndata_refill_levels = []\ntimeout_ms = 6000\nconcurrency = 10\nunit = 64\nthreshold = 0.5\nrecent_filter_layers = 6\nrecent_filter_rotate_interval_ms = 10000\n```\n\n----------------------------------------\n\nTITLE: Using IF EXISTS to Drop Database Safely - RisingWave SQL\nDESCRIPTION: This snippet illustrates using the IF EXISTS clause with DROP DATABASE to prevent errors if the target database does not exist. No additional dependencies are required, and the expected input is the database name. The output is that the database is removed if it exists, or no error is returned if it does not. This is especially useful in automated or repeatable scripts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-database.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE IF EXISTS rw_db;\n```\n\n----------------------------------------\n\nTITLE: Window Frame Exclusion Options in RisingWave SQL\nDESCRIPTION: Shows the syntax for window frame exclusion options which specify which rows within the frame should be excluded from calculations. Currently supports excluding the current row or excluding no rows.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXCLUDE CURRENT ROW\nEXCLUDE NO OTHERS\n```\n\n----------------------------------------\n\nTITLE: SHOW CONNECTIONS Example Output in RisingWave\nDESCRIPTION: Sample output of the SHOW CONNECTIONS command showing connection name, type, properties including provider details, service names, endpoint IDs, availability zones, and any associated sources and sinks.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-connections.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nName             | Type        |   Properties\n-----------------+-------------+----------------\nconnection_name  | privatelink | provider: aws\n                 |             | service_name: com.amazonaws.xyz.us-east-1.abc-xyz-0000\n                 |             | endpoint_id: xyz-0000\n                 |             | availability_zones: [\"use1-az6\", \"use1-az4\"]\n                 |             | sources: [\"tcp_metrics\"]\n                 |             | sinks: [\"sink1\"]\n\n```\n\n----------------------------------------\n\nTITLE: Installing WarpStream Agent using curl (Bash)\nDESCRIPTION: This command downloads and executes an installation script from WarpStream's console URL to install the WarpStream Agent or CLI. This tool is required to interact with the WarpStream cluster.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://console.warpstream.com/install.sh | bash\n```\n\n----------------------------------------\n\nTITLE: Configuring DEBEZIUM AVRO Format in RisingWave\nDESCRIPTION: SQL syntax for Debezium-formatted Avro data. Requires specification of the main message and schema registry URL. The ignore_key option controls whether to consume only the payload.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT DEBEZIUM\nENCODE AVRO (\n    message = 'main_message',\n    schema.registry = 'schema_registry_url [, ...]',\n    [ignore_key = 'true | false']\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN BYTES Format in RisingWave\nDESCRIPTION: SQL syntax for reading data streams without decoding. This allows handling raw binary data, but the table or source can have exactly one field of BYTEA data type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE BYTES\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Sink in RisingWave SQL\nDESCRIPTION: This SQL snippet demonstrates the syntax for creating a Kafka sink in RisingWave. It includes placeholders for sink name, data source, Kafka connector parameters, and data format options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/apache-kafka.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SINK [ IF NOT EXISTS ] sink_name\n[FROM sink_from | AS select_query]\nWITH (\n   connector='kafka',\n   connector_parameter = 'value', ...\n)\nFORMAT data_format ENCODE data_encode [ (\n    key = 'value'\n) ]\n[KEY ENCODE key_encode [(...)]]\n;\n```\n\n----------------------------------------\n\nTITLE: Performing Ad-hoc Queries on Kafka Source with Time Filtering\nDESCRIPTION: This SQL query directly queries a Kafka source with time-based filtering, demonstrating ad-hoc ingestion during query processing. It uses the special _rw_kafka_timestamp field to filter for recent messages.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/overview.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM source_name\nWHERE _rw_kafka_timestamp > now() - interval '10 minute';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table from PostgreSQL CDC Source in RisingWave\nDESCRIPTION: SQL syntax for creating a table from a PostgreSQL CDC source. This requires specifying a primary key that matches the upstream table and the PostgreSQL table name to select from.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/sources/pg-cdc-config.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE [ IF NOT EXISTS ] table_name (\n   column_name data_type PRIMARY KEY , ...\n   PRIMARY KEY ( column_name, ... )\n)\n[ INCLUDE timestamp AS column_name ]\nWITH (\n    snapshot='true'\n)\nFROM source TABLE pg_table_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Superuser Role in Citus Cluster for CDC\nDESCRIPTION: SQL commands to create a superuser role named 'dbz' on both the coordinator and worker nodes of a Citus cluster. This role is required for CDC operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/citus-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n---create role on coordinator node\nCREATE ROLE dbz Superuser LOGIN;\n---create role on worker nodes\nSELECT run_command_on_workers ($cmd$\nCREATE ROLE dbz Superuser LOGIN;\n$cmd$);\n```\n\n----------------------------------------\n\nTITLE: Checking User Table Privileges in PostgreSQL (SQL)\nDESCRIPTION: This SQL query checks the privileges granted to a specific user ('<username>') on tables within the database by querying the `information_schema.role_table_grants` system view. It helps verify if the user has the required `SELECT` privileges for CDC.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\npostgres=# SELECT table_name, grantee, privilege_type\nFROM information_schema.role_table_grants\nWHERE  grantee='<username>';\n```\n\n----------------------------------------\n\nTITLE: Querying Total Number of Streaming Actors in RisingWave (SQL)\nDESCRIPTION: This SQL command retrieves the total count of actors (parallel processing units) currently active in the RisingWave cluster by querying the `rw_actors` system table. Useful for monitoring cluster health and resource usage, the command outputs a single integer result. No special dependencies are required beyond access to the database.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/manage-a-large-number-of-streaming-jobs.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect count(*) from rw_actors;\n```\n\n----------------------------------------\n\nTITLE: Converting JSONB to Map Type\nDESCRIPTION: Converts JSONB data into a map type by merging key-value pairs. Supports both null maps and existing maps as base arguments.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT jsonb_populate_map(\n    null::map(varchar, int),\n    '{\"a\": 1, \"b\": 2}'::jsonb\n);\n```\n\n----------------------------------------\n\nTITLE: Creating an Iceberg Source in RisingWave\nDESCRIPTION: SQL syntax for creating a source that connects to an Apache Iceberg table. It includes various configuration parameters for specifying the connection details, catalog type, and table information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE [ IF NOT EXISTS ] source_name\nWITH (\n   connector='iceberg',\n   connector_parameter='value', ...\n);\n```\n\n----------------------------------------\n\nTITLE: Automatically Mapping Upstream Table Schema in RisingWave\nDESCRIPTION: This SQL snippet demonstrates how to create a table in RisingWave that automatically maps all columns from an upstream PostgreSQL table using the '*' syntax. This is a Premium Edition feature.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_17\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE supplier (*) FROM pg_source TABLE 'public.supplier';\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View for Stream Performance\nDESCRIPTION: SQL statement to create a materialized view that summarizes streaming performance metrics every 10 minutes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/live-stream-metrics-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW live_video_qos_10min AS\nSELECT\n    window_start AS report_ts,\n    room_id,\n    SUM(video_total_freeze_duration) AS video_total_freeze_duration,\n    AVG(video_lost_pps) AS video_lost_pps,\n    AVG(video_rtt) AS video_rtt\nFROM\n    TUMBLE(\n        live_stream_metrics,\n        report_timestamp,\n        INTERVAL '10' MINUTE\n    )\nGROUP BY\n    window_start,\n    room_id;\n```\n\n----------------------------------------\n\nTITLE: Copying JDK Truststore for Kafka\nDESCRIPTION: This bash command copies the JDK truststore file to create a Kafka client truststore, which is used for SSL connections to Kafka brokers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncp /usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/security/cacerts ~/kafka.client.truststore.jks\n```\n\n----------------------------------------\n\nTITLE: Monitoring WAL Replication Slot Status\nDESCRIPTION: Query to check WAL (Write-Ahead Log) accumulation status on the upstream PostgreSQL server, including replication slot lag and activity status.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSELECT slot_name,\n       pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS raw,\n       pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS replicationSlotLag,\n       active\nFROM pg_replication_slots;\n```\n\n----------------------------------------\n\nTITLE: least Function in SQL\nDESCRIPTION: Demonstrates the least function, which returns the smallest value from a list of expressions, ignoring NULL values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/conditional.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nleast(value1, value2, ...) → ANY\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id INT, v1 INT2, v2 INT4, v3 INT8);\n\ninsert into t values (1, 1, 2, 3), (2, 2, NULL, 5), (3, NULL, NULL, 8), (4, NULL, NULL, NULL);\n\nselect least(1, 2, 3); -- results: 1\n\nselect least(v1, v2, v3) from t order by id;\n------ results\n1, 2, 8, NULL\n```\n\n----------------------------------------\n\nTITLE: RisingWave System Tables Structure\nDESCRIPTION: Documentation of three core system tables in RisingWave database that store user information, view definitions, and worker node details. These tables are essential for database administration and system management.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n| `rw_users`                            | Contains information about users that are available in the database, including their unique IDs, names, and boolean flags indicating whether they are a superuser, whether they can create databases, whether they can create other users, and whether can log in.                                                                                                           |\n| `rw_views`                            | Contains information about views that are available in the database, including their unique IDs, names, schema IDs, owner IDs, definitions, and more.                                                                                                                                                                                                                        |\n| `rw_worker_nodes`                     | Contains information about worker nodes available in the database, such as meta nodes, compactor nodes, and compute nodes. The detailed information includes their unique IDs, hostnames, ports, types, states, parallelism levels, boolean flags (indicating whether they are used for streaming, serving, or are unschedulable), kernel versions, memory, CPU, and uptime. |\n```\n\n----------------------------------------\n\nTITLE: Querying Market Summary Materialized View in SQL\nDESCRIPTION: Retrieves and displays a sample of records from the market_summary materialized view, showing positions with their latest market prices from different bookmakers.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM market_summary LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Using array_remove Function in SQL\nDESCRIPTION: Returns an array with all occurrences of the specified element removed. The function also supports multidimensional arrays.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\narray_remove ( array, any_compatible ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_remove(array[array[1],array[2],array[3],array[2]], array[2]) → {{1},{3}}\n```\n\n----------------------------------------\n\nTITLE: Using POSITION Function in SQL\nDESCRIPTION: The position() function returns the starting index of the specified substring within the input string, or zero if it is not present.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_19\n\nLANGUAGE: SQL\nCODE:\n```\nposition ( substring in input_string ) → integer_output\n```\n\nLANGUAGE: SQL\nCODE:\n```\nposition('ing' in 'rising') → 4\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View in RisingWave (SQL)\nDESCRIPTION: This SQL query retrieves all rows and columns from the previously created materialized view 'visits_stream_mv'. This allows users to inspect the aggregated website traffic and engagement data processed by RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM visits_stream_mv;\n```\n\n----------------------------------------\n\nTITLE: Inserting Additional Data into Exam Scores Table\nDESCRIPTION: SQL command to insert five more rows of data into the exam_scores table to demonstrate how materialized views automatically update with new data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO exam_scores (score_id, exam_id, student_id, score, exam_date)\nVALUES\n  (11, 101, 1004, 89.5, '2022-05-05'),\n  (12, 101, 1005, 93.2, '2022-05-05'),\n  (13, 102, 1004, 87.1, '2022-06-10'),\n  (14, 102, 1005, 91.7, '2022-06-10'),\n  (15, 102, 1006, 84.3, '2022-06-10');\n```\n\n----------------------------------------\n\nTITLE: Setting Pause on Next Bootstrap in SQL\nDESCRIPTION: This SQL command sets the 'pause_on_next_bootstrap' system parameter to true, which is used as part of the solution for continuous OOM of compute nodes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/troubleshoot/troubleshoot-recovery-failure.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nalter system set pause_on_next_bootstrap to true;\n```\n\n----------------------------------------\n\nTITLE: Calling Recursive SQL UDF\nDESCRIPTION: This snippet shows how to call the previously created foo function, which returns a string representation of its signature regardless of the input.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/sql-udfs.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nselect foo(114514);\n----RESULT\nfoo(INT)\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v2.1.0 Standalone in Docker\nDESCRIPTION: Command to run the RisingWave v2.1.0 standalone version in a Docker container, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v2.1.0-standalone single_node\n```\n\n----------------------------------------\n\nTITLE: Creating Iceberg Source with S3 Configuration\nDESCRIPTION: SQL statement to create an Iceberg source with S3 warehouse configuration and credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE iceberg_source\nWITH (\n    connector = 'iceberg',\n    warehouse.path = 's3a://my-iceberg-bucket/path/to/warehouse,\n    s3.endpoint = 'https://s3.ap-southeast-1.amazonaws.com',\n    s3.access.key = '${ACCESS_KEY}',\n    s3.secret.key = '${SECRET_KEY},\n    catalog.name='demo',\n    database.name='dev',\n    table.name='table'\n);\n```\n\n----------------------------------------\n\nTITLE: Querying a Materialized View in RisingWave\nDESCRIPTION: Queries the materialized view 'counter' to retrieve real-time aggregated data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/nodejs.mdx#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Pool } = require('pg');\n\nconst credentials = {\n    user: 'root',\n    host: '127.0.0.1',\n    database: 'dev',\n    password: 'secret',\n    port: 4566,\n}\n\nconst start = async () => {\n    const pool = new Pool(credentials);\n    const res = await pool.query(\"SELECT * from counter;\");\n    console.log(res.rows); // Print out only the actual data.\n    await pool.end();\n}\nstart().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Mathematical Function Examples in SQL\nDESCRIPTION: Examples of common mathematical functions including absolute value, rounding, logarithms, and exponential operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/mathematical.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nabs(-3) → 3\n@(-3) → 3\ncbrt(27) → 3\nceil(1.23559) → 2\nceiling(-1.23559) → -1\nexp(2.0) → 7.38905609893065\nfloor(1.23559) → 1\nfloor(-1.23559) → -2\nln(10) → 2.302585092994046\nlog10(25) → 1.3979400086720377\nmin_scale(8.4100) → 2\npow(2.0, 3.0) → 8\npower(2.0, 3.0) → 8\nround(1.23559, 2) → 1.24\nround(1.23559) → 1\nscale(8.4100) → 4\nsign(8.64) → 1\nsign(-8.64) → -1\nsqrt(16) → 4\ntrim_scale(8.4100) → 8.41\ntrunc(-20.0932) → -20\n```\n\n----------------------------------------\n\nTITLE: Verifying License Key Validity in RisingWave\nDESCRIPTION: SQL query to check if your RisingWave license key is valid. Returns 't' if the key is valid or an error message if invalid.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-premium-edition-intro.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT rw_test_paid_tier();\n```\n\n----------------------------------------\n\nTITLE: Checking Column Access Privilege in SQL\nDESCRIPTION: Demonstrates the use of has_any_column_privilege() function to check if a user has access to any column of a table in a specific way. Currently, this function is identical to has_table_privilege().\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-admin.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nhas_any_column_privilege([user,] table, privilege) -> boolean\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT has_any_column_privilege('test_user', 'foo_view'::regclass, 'INSERT');\n----RESULT\nf\n```\n\n----------------------------------------\n\nTITLE: Using sum Function with rw_int256 in SQL\nDESCRIPTION: Demonstrates how to use the sum function to calculate the sum of all rw_int256 values in a set.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sum(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Expected Final Materialized View Output (bash/console)\nDESCRIPTION: This is the expected output from querying the materialized view 'mv' after deletions. It shows the recalculated aggregates (9, 90) based on the current state of table 't'. There are no code parameters; this is sample, non-executable console output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n v1_sum | v2_sum\n--------+--------\n      9 |     90\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Generate Series with Numbers Example\nDESCRIPTION: Example showing how to generate a simple sequence of numbers from 1 to 5 using generate_series()\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/set-returning.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM generate_series(1, 5);\n```\n\n----------------------------------------\n\nTITLE: Creating an Append-Only Source in RisingWave\nDESCRIPTION: SQL command to create an append-only source in RisingWave using the datagen connector. This source generates sequential and random data for testing purposes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/destinations/clickhouse.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SOURCE s1_source (\n    seq_id integer,\n    user_id integer,\n    user_name varchar)\nWITH (\n    connector ='datagen',\n    fields.seq_id.kind ='sequence',\n    fields.seq_id.start ='1',\n    fields.seq_id.end ='10000000',\n    fields.user_id.kind ='random',\n    fields.user_id.min ='1',\n    fields.user_id.max ='10000000',\n    fields.user_name.kind ='random',\n    fields.user_name.length ='10',\n    datagen.rows.per.second ='20000'\n ) FORMAT PLAIN ENCODE JSON;\n```\n\n----------------------------------------\n\nTITLE: Nested Array Constructor Example in RisingWave SQL\nDESCRIPTION: Shows how to create a multi-dimensional array by nesting array constructors. Each nested ARRAY constructor creates a subarray that becomes an element of the outer array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/value-exp.mdx#2025-04-23_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ARRAY[ARRAY[1, 2], ARRAY[3, 4]];\n----------\n {{1,2},{3,4}}\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Using REGEXP_COUNT Function in SQL\nDESCRIPTION: The regexp_count() function returns the number of times a POSIX regular expressions pattern appears in input_string. It supports various regex features and optional flags for case-sensitive or case-insensitive matching.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nregexp_count( input_string, pattern [, start_int [, optional_flag ]] ) → output_int\n```\n\nLANGUAGE: SQL\nCODE:\n```\nregexp_count('ABCABCAXYaxy', 'A.', 1, 'c') → 3\nregexp_count('ABCABCAXYaxy', 'A.', 2, 'c') → 2\n```\n\n----------------------------------------\n\nTITLE: Using array_sort Function in SQL\nDESCRIPTION: Sorts the elements of an array in ascending order. NULL values are sorted to the end of the array.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\narray_sort ( array ) → array\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_sort(array[-1000, 2000, 0]) → {-1000,0,2000}\n\narray_sort(array['abcdef', 'aacedf', 'aaadef']) → {aaadef,aacedf,abcdef}\n\narray_sort(array[3, 2, NULL, 1, NULL]) → {1,2,3,NULL,NULL}\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes ConfigMap for Hadoop Configuration\nDESCRIPTION: This Bash command creates a Kubernetes ConfigMap named 'hadoop-conf' from the Hadoop configuration files.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create configmap hadoop-conf --from-file $HADOOP_HOME/etc/hadoop\n```\n\n----------------------------------------\n\nTITLE: Canceling Statement Execution Example\nDESCRIPTION: Demonstrates how to cancel a running CREATE MATERIALIZED VIEW statement using CTRL+C, showing the resulting error message.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-statement-progress.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW mv2 AS SELECT * FROM mv1;\n------------------------\n^CCancel request sent\nERROR:  QueryError: Scheduler error: Cancelled: create\n```\n\n----------------------------------------\n\nTITLE: Basic Iceberg Source Query\nDESCRIPTION: Simple query to select all data from an Iceberg source.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/apache-iceberg.mdx#2025-04-23_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM iceberg_source;\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL User for Replication\nDESCRIPTION: SQL command to create a new user in MySQL specifically for RisingWave CDC replication. Replace 'user' and 'password' with actual credentials.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mysql-cdc.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'user'@'%' IDENTIFIED BY 'password';\n```\n\n----------------------------------------\n\nTITLE: Example: Revoking Materialized View Privileges in SQL\nDESCRIPTION: Example showing how to revoke the SELECT privilege for a materialized view within a specific schema and database from a user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-revoke.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE SELECT\nON MATERIALIZED VIEW mv1 IN SCHEMA db1.schema1\nFROM user1;\n```\n\n----------------------------------------\n\nTITLE: Checking User Role Attributes\nDESCRIPTION: SQL command example showing how to list user roles and their attributes in PostgreSQL.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ndev-# \\du\n                                   List of roles\nRole name |                         Attributes                         | Member of\n-----------+-----------------------------------------------------------+---------\nrw        | Create DB, Replication                                     | {}\npostgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}\n```\n\n----------------------------------------\n\nTITLE: JSON Type Validation Syntax\nDESCRIPTION: Shows the syntax for using the IS JSON predicate to validate if an expression is valid JSON and optionally check its specific type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nexpression IS [ NOT ] JSON [ VALUE | ARRAY | OBJECT | SCALAR ] → bool\n```\n\n----------------------------------------\n\nTITLE: Equivalent GROUPING SETS for CUBE in SQL\nDESCRIPTION: Demonstrates the equivalent GROUPING SETS clause for a CUBE operation, showing all possible combinations of columns for subtotals.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/group-by-clause.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nGROUP BY GROUPING SETS (\n            (c1,c2,c3),\n            (c1,c2),\n            (c1,c3),\n            (c2,c3),\n            (c1),\n            (c2),\n            (c3),\n            ()\n        )\n```\n\n----------------------------------------\n\nTITLE: Generating MD5 Hash of Binary String in SQL\nDESCRIPTION: The md5 function returns the MD5 hash of a binary string as a hexadecimal. It takes a bytea input and returns a varchar.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmd5 ( bytea ) -> varchar\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT md5('risingwave'::bytea);\n------RESULT\n7ad0245ddf6c26f4f6ae269a644ac00a\n```\n\n----------------------------------------\n\nTITLE: Querying Ingested Data from AMQ Streams in RisingWave\nDESCRIPTION: SQL query to retrieve data from the created table in RisingWave, demonstrating how to access the ingested AMQ Streams data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/redhat-amq-streams.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM financial_transactions LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Test Data for Kafka Topic\nDESCRIPTION: Example of JSON formatted test data to be written to the Kafka topic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": 1,\n  \"name\": \"testuser\",\n  \"timestamp\": \"2023-11-10T12:00:00\",\n  \"status\": \"active\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PLAIN AVRO Format in RisingWave\nDESCRIPTION: SQL syntax for standard Avro ingestion. A schema registry is required for Avro format in RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/getting-started/formats-and-encoding-options.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nFORMAT PLAIN\nENCODE AVRO (\n    schema.registry = 'schema_registry_url [, ...]',\n)\n```\n\n----------------------------------------\n\nTITLE: Granting Required Privileges\nDESCRIPTION: SQL commands for granting necessary database privileges to users for CDC operations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nGRANT CONNECT ON DATABASE <database_name> TO <username>;\nGRANT USAGE ON SCHEMA <schema_name> TO <username>;\nGRANT SELECT ON ALL TABLES IN SCHEMA <schema_name> TO <username>;\nGRANT CREATE ON DATABASE <database_name> TO <username>;\n```\n\n----------------------------------------\n\nTITLE: Calculating Octet Length of Binary String in SQL\nDESCRIPTION: The octet_length (or length) function returns the number of bytes in a binary string. It takes a bytea input and returns an integer.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\noctet_length ( bytea ) -> integer\n-- or\nlength ( bytea ) -> integer\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT octet_length('😇'::bytea);\n------RESULT\n4\n```\n\n----------------------------------------\n\nTITLE: Renaming Materialized View Syntax in SQL\nDESCRIPTION: Shows the syntax for changing the name of a materialized view using the `RENAME TO` clause.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER MATERIALIZED VIEW materialized_view_name\n    RENAME TO new_name;\n```\n\n----------------------------------------\n\nTITLE: Querying Sink Decoupling Status in RisingWave SQL\nDESCRIPTION: This SQL query retrieves the sink decoupling status for created sinks from the internal system table 'rw_sink_decouple'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/delivery/overview.mdx#2025-04-23_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nselect sink_id, is_decouple from rw_sink_decouple;\n```\n\n----------------------------------------\n\nTITLE: Inserting Additional Rows into Table in RisingWave (SQL)\nDESCRIPTION: This snippet demonstrates the insertion of two more rows into existing table 't'. Dependencies include a previously created table 't'. The values (4,40) and (5,50) are added, increasing the number of rows for the aggregate computations in dependent materialized views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/deletes-and-updates.mdx#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\ninsert into t values (4,40), (5,50);\n```\n\n----------------------------------------\n\nTITLE: Example of Renaming an Index using ALTER INDEX RENAME TO in SQL\nDESCRIPTION: Demonstrates how to rename an index named 'idx_1' to 'idx_2' using the `ALTER INDEX ... RENAME TO` command in SQL. This operation changes the identifier used to refer to the index without affecting the stored data.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the name of the index \"idx_1\" to \"idx_2\"\nALTER INDEX idx_1 RENAME TO idx_2.\n```\n\n----------------------------------------\n\nTITLE: Setting Time Zone to a Specific Location\nDESCRIPTION: Example of setting the time zone to America/New_York using the SET TIME ZONE command.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-set-time-zone.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET TIME ZONE \"America/New_York\";\n```\n\n----------------------------------------\n\nTITLE: Setting Replica Identity for CDC Table in Citus\nDESCRIPTION: SQL command to set the replica identity to FULL for the table from which data will be ingested. This is executed on the coordinator node.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/citus-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n---execute on coordinator node\nALTER TABLE github_events REPLICA IDENTITY FULL;\n```\n\n----------------------------------------\n\nTITLE: Monitoring Uninstallation Status\nDESCRIPTION: Command to check the status of pods during the uninstallation process. This helps verify when the uninstallation is complete.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/uninstall-risingwave-k8s.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods\n```\n\n----------------------------------------\n\nTITLE: Installing Mintlify CLI for Documentation Preview\nDESCRIPTION: Command to install the Mintlify CLI globally using npm, which is required to preview documentation changes locally.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i -g mintlify\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.13 Docker Container\nDESCRIPTION: Docker command to run RisingWave v0.1.13 in playground mode with port mappings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_37\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.1.13 playground\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.14 Docker Container\nDESCRIPTION: Docker command to run RisingWave v0.1.14 in playground mode with port mappings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_36\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.1.14 playground\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom State Store Directory for RisingWave\nDESCRIPTION: Command to run RisingWave with a custom state store directory instead of the default ~/.risingwave location.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# Reconfigure RisingWave to be stored under 'projects' folder instead.\nrisingwave --state-store-directory ~/projects/risingwave\n```\n\n----------------------------------------\n\nTITLE: Setting WAL Level for CDC\nDESCRIPTION: SQL command to set the WAL level to logical for enabling CDC functionality.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/neon-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET wal_level = logical;\n```\n\n----------------------------------------\n\nTITLE: JSON Data Structure Example\nDESCRIPTION: Example of JSON data structure before parsing with struct type.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/struct.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n{\n  \"nested\": \"{\\\"v1\\\": 10, \\\"v2\\\": \\\"hello\\\"}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Example Usage of the COMMIT Command in SQL\nDESCRIPTION: Provides an example of executing the `COMMIT` command in RisingWave SQL. This demonstrates how to finalize a transaction, typically after starting one with `BEGIN READ ONLY` or `START TRANSACTION READ ONLY`. The expected result `COMMIT` indicates successful commitment of the transaction.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-commit.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCOMMIT;\n-------RESULT\nCOMMIT\n```\n```\n\n----------------------------------------\n\nTITLE: Querying Position Overview Materialized View in SQL\nDESCRIPTION: Retrieves and displays a sample of records from the position_overview materialized view, showing position information, profit/loss, and risk levels.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM position_overview LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Using stddev_samp function in SQL\nDESCRIPTION: Calculates the sample standard deviation of input values. Returns NULL if there are fewer than two non-null values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nstddev_samp ( expression ) -> output_value\n```\n\n----------------------------------------\n\nTITLE: Deleting Map Entries in SQL\nDESCRIPTION: The map_delete function removes a key-value pair from a map. It has no effect if the key is not found in the map.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/map.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmap_delete ( map, key ) → map\n```\n\nLANGUAGE: sql\nCODE:\n```\nmap_delete(MAP{1:100,2:200}, 1) -> {2:200}\nmap_delete(MAP{1:100,2:200}, 3) -> {1:100,2:200}\n```\n\n----------------------------------------\n\nTITLE: Example Usage of SHOW SCHEMAS Command in RisingWave\nDESCRIPTION: Shows a basic example of how to list all schemas in a database using the SHOW SCHEMAS command without any filtering.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-schemas.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SCHEMAS;\n```\n\n----------------------------------------\n\nTITLE: System Tables Schema Overview\nDESCRIPTION: Comprehensive list of system tables in RisingWave database, including tables for storing metadata, configuration, and operational state. These tables track everything from version deltas to user secrets and resource configurations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/system-catalogs/rw-catalog.mdx#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nrw_hummock_version_deltas\nrw_iceberg_files\nrw_iceberg_snapshots\nrw_indexes\nrw_internal_table_info\nrw_internal_tables\nrw_materialized_views\nrw_meta_snapshot\nrw_parallel_units\nrw_rate_limit\nrw_relation_info\nrw_relations\nrw_resource_groups\nrw_schemas\nrw_secrets\nrw_sinks\nrw_sources\nrw_streaming_jobs\nrw_streaming_parallelism\nrw_system_tables\nrw_table_fragments\nrw_table_stats\nrw_tables\nrw_types\nrw_user_secrets\n```\n\n----------------------------------------\n\nTITLE: Output of Internal Tables Query\nDESCRIPTION: Displays the list of internal tables in RisingWave, including the backfill executor state table for the newly created table and the source connector table.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nName\n---------------------------------\n__internal_t3_3_streamcdcscan_4\n__internal_mssql_source_1_source_2\n(2 rows)\n```\n\n----------------------------------------\n\nTITLE: SQL Syntax for ORDER BY Clause\nDESCRIPTION: Basic syntax of the ORDER BY clause in SQL. It allows sorting by multiple expressions and specifying ASC/DESC order and NULL positioning.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/query-syntax/order-by-clause.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT select_list\n    FROM table_expression\n    ORDER BY sort_expression1 [ ASC | DESC ] [ NULLS { FIRST | LAST } ]\n             [, sort_expression2 [ ASC | DESC ] [ NULLS { FIRST | LAST } ] ...]\n```\n\n----------------------------------------\n\nTITLE: Cloning the RisingWave Repository\nDESCRIPTION: Command to clone the RisingWave GitHub repository to your local machine. This is the first step required to access the Docker Compose configuration files for deploying RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/risingwave.git\n```\n\n----------------------------------------\n\nTITLE: Generating SHA-1 Hash of Binary String in SQL\nDESCRIPTION: The sha1 function returns the SHA-1 hash of a binary string. It takes a bytea input and returns a bytea.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nsha1 ( bytea ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sha1('risingwave'::bytea);\n------RESULT\n\\x48d3478f8350c86fa2e6f65a5883c2046523c8bb\n```\n\n----------------------------------------\n\nTITLE: Querying Thread Views by Time Interval\nDESCRIPTION: SQL query to fetch thread views within a specific time interval for a particular thread.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/clickstream-analysis.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM thread_view_count\nWHERE window_start > ('2022-09-23 06:50Z' :: TIMESTAMP WITH TIME ZONE - INTERVAL '1 day')\nAND window_start <\n('2022-09-23 07:40Z' :: TIMESTAMP WITH TIME ZONE - INTERVAL '1 day' + INTERVAL '10 minutes')\nAND target_id = 'thread58'\nORDER BY window_start;\n```\n\n----------------------------------------\n\nTITLE: Example Output of the DESCRIBE Command\nDESCRIPTION: Illustrates the typical output format when executing the `DESCRIBE customers;` command. The output is a table detailing column names, types, visibility (Is Hidden), descriptions (from comments), primary key, distribution key, index definitions (`idx_customers_email`), and the table description.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-describe.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n| Name                | Type                                                                  | Is Hidden | Description                         |\n| :------------------ | :-------------------------------------------------------------------- | :-------- | :---------------------------------- |\n| customer_id         | bigint                                                                | false     | Unique identifier for each customer |\n| name                | character varying                                                     | false     | Name of the customer                |\n| email               | character varying                                                     | false     | Email address of the customer       |\n| primary key         | customer_id                                                           |           |                                     |\n| distribution key    | customer_id                                                           |           |                                     |\n| idx_customers_email | index(email ASC, customer_id ASC) include(name) distributed by(email) |           |                                     |\n| table description   | customers                                                             |           | All customer records                |\n\n```\n\n----------------------------------------\n\nTITLE: Creating Example Tables 'customers' and 'orders' in SQL\nDESCRIPTION: Demonstrates how to create two sample tables, `customers` and `orders`, using SQL DDL statements in RisingWave. These tables include various column definitions (INTEGER, VARCHAR, NUMERIC, DATE) and define primary keys (`c_custkey`, `o_orderkey`). They serve as prerequisites for the subsequent index creation examples.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE customers (\n    c_custkey INTEGER,\n    c_name VARCHAR,\n    c_address VARCHAR,\n    c_nationkey INTEGER,\n    c_phone VARCHAR,\n    c_acctbal NUMERIC,\n    c_mktsegment VARCHAR,\n    c_comment VARCHAR,\n    PRIMARY KEY (c_custkey)\n);\n\nCREATE TABLE orders (\n    o_orderkey BIGINT,\n    o_custkey INTEGER,\n    o_orderstatus VARCHAR,\n    o_totalprice NUMERIC,\n    o_orderdate DATE,\n    o_orderpriority VARCHAR,\n    o_clerk VARCHAR,\n    o_shippriority INTEGER,\n    o_comment VARCHAR,\n    PRIMARY KEY (o_orderkey)\n);\n```\n\n----------------------------------------\n\nTITLE: Using mode function in SQL\nDESCRIPTION: Computes the mode (most frequent value) of the aggregated argument. For multiple equally-frequent values, it chooses the first one encountered.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/aggregate.mdx#2025-04-23_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nmode () WITHIN GROUP ( ORDER BY sort_expression ) -> same as sort_expression\n```\n\n----------------------------------------\n\nTITLE: Generating Demo Kafka Topic and Data (Bash)\nDESCRIPTION: This command uses the WarpStream CLI to create a Kafka topic named 'demo-stream' and automatically populate it with sample clickstream data. This is useful for testing the data ingestion pipeline.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwarpstream demo\n```\n\n----------------------------------------\n\nTITLE: Using CHR Function in SQL\nDESCRIPTION: The chr() function returns the character with the Unicode code point equivalent to the input integer value provided.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/string.mdx#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nchr ( input_int ) → string\n```\n\nLANGUAGE: SQL\nCODE:\n```\nchr(65) → 'A'\n```\n\n----------------------------------------\n\nTITLE: SHOW MATERIALIZED VIEWS Syntax in RisingWave\nDESCRIPTION: Defines the syntax for the SHOW MATERIALIZED VIEWS command, which can optionally filter results by schema name or using a LIKE pattern matching expression.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-mv.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW MATERIALIZED VIEWS [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Checking PostgreSQL Replication Lag\nDESCRIPTION: This SQL query should be run on the PostgreSQL server to check for replication lag. It shows the difference between the current WAL position and the position of each replication slot, which helps identify if RisingWave is falling behind.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/monitor-cdc-progress.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT slot_name,\n       pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS raw,\n       pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS replicationSlotLag,\n       active\nFROM pg_replication_slots;\n```\n\n----------------------------------------\n\nTITLE: SHOW CONNECTIONS Example Query in RisingWave\nDESCRIPTION: Example of executing the SHOW CONNECTIONS command to list all connections in the system.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-connections.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW CONNECTIONS;\n```\n\n----------------------------------------\n\nTITLE: SHOW SOURCES Command Syntax in RisingWave SQL\nDESCRIPTION: The basic syntax for the SHOW SOURCES command, which allows listing existing sources with optional schema specification and pattern matching filters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-sources.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW SOURCES [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: DESCRIBE Command Syntax Definition\nDESCRIPTION: Defines the basic syntax for the `DESCRIBE` command, which is used to show information about a specific database relation (table, source, sink, view, or materialized view). The `relation_name` parameter specifies the target relation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-describe.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nDESCRIBE relation_name;\n```\n\n----------------------------------------\n\nTITLE: Creating a New BYOC Environment with Custom Settings\nDESCRIPTION: This Bash command creates a new BYOC environment using the RisingWave CLI (rwc), specifying the CIDR, cloud account ID, environment name, and path to custom settings file.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ rwc byoc create \\\n\t--cidr $BYOC_CIDR \\\n\t--cloud-account-id $ACCOUNT_ID \\\n\t--name $BYOC_NAME \\\n\t--custom-settings-path $BYOC_CONFIG\n```\n\n----------------------------------------\n\nTITLE: Using SHOW PROCESSLIST Command in RisingWave\nDESCRIPTION: Displays the current workload of the system, showing process IDs, users, hosts, databases, execution times, and the statements being executed. Note that this command only shows the frontend received processlist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-processlist.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW PROCESSLIST;\n```\n\n----------------------------------------\n\nTITLE: Example: Changing Materialized View Owner in SQL\nDESCRIPTION: Demonstrates how to change the owner of the materialized view named `materialized_view1` to `user1`.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-materialized-view.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Change the owner of the materialized view named \"materialized_view1\" to user \"user1\"\nALTER MATERIALIZED VIEW materialized_view1 OWNER TO user1;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Database Name in SQL\nDESCRIPTION: The current_database() function returns the name of the current database. It can be used in SQL commands, functions, and operators.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncurrent_database() → *current_database_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT current_database(); →  `db_name`\nSELECT count(current_database()); → 1\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Topic using Command-line Tools\nDESCRIPTION: Command to create a Kafka topic named 'example_topic' with 1 partition and replication factor of 1.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n./kafka-topics.sh --create --topic example_topic --bootstrap-server 10.0.96.4:9092 --partitions 1 --replication-factor 1\n```\n\n----------------------------------------\n\nTITLE: Invalid SQL Temporal Filter Syntax with Multiple ORs under AND\nDESCRIPTION: Shows an invalid SQL syntax where multiple expressions, conjoined by AND, each contain a temporal filter disjoined with OR. RisingWave requires that each expression conjoined by AND should have at most one temporal filter disjoined with OR.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/temporal-filters.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Invalid\n(t < NOW() - INTERVAL '1 hour' OR t > NOW() OR a < 1)\nAND (t < NOW() - INTERVAL '1 hour' OR a < 1)\n```\n\n----------------------------------------\n\nTITLE: Creating a DataGen Source in RisingWave\nDESCRIPTION: Creates a walk data source using the datagen connector to generate mock data with distance and duration fields. Includes connection setup and automatic commit configuration.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/python.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport psycopg2\n\nconn = psycopg2.connect(host=\"localhost\", port=4566, user=\"root\", dbname=\"dev\")\nconn.autocommit = True\n\nwith conn.cursor() as cur:\n    cur.execute(\"\"\"\nCREATE TABLE walk(distance INT, duration INT)\nWITH (\n    connector = 'datagen',\n    fields.distance.kind = 'sequence',\n    fields.distance.start = '1',\n    fields.distance.end  = '60',\n    fields.duration.kind = 'sequence',\n    fields.duration.start = '1',\n    fields.duration.end = '30',\n    datagen.rows.per.second='15',\n    datagen.split.num = '1'\n) FORMAT PLAIN ENCODE JSON\"\"\")\n\nconn.close()\n```\n\n----------------------------------------\n\nTITLE: Starting RisingWave with Custom Storage Backend\nDESCRIPTION: Command to start a RisingWave cluster with a specific storage backend configuration. This uses the corresponding Docker Compose file for the selected state or meta store.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose -f docker-compose-with-storage_backend_name.yml up\n```\n\n----------------------------------------\n\nTITLE: Example of Using KILL Command to Terminate Processes in RisingWave\nDESCRIPTION: Shows how to use the KILL command to terminate specific processes after identifying them with SHOW PROCESSLIST. The example demonstrates terminating both a long-running insert operation and a materialized view creation process.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-processlist.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PROCESSLIST;\n------RESULT\n Id | User |      Host       | Database |  Time   |                            Info\n----+------+-----------------+----------+---------+------------------------------------------------------------\n 0  | root | 127.0.0.1:60858 | dev      | 35363ms | insert into t select i from generate_series(1, 1000000) i;\n 1  | root | 127.0.0.1:60935 | dev      | 0ms     | show processlist;\n 2  | root | 127.0.0.1:60941 | dev      | 4304ms  | create materialized view mv2 as select * from t;\n(3 rows)\n\nKILL 2;\n------RESULT\nKILL\n\nKILL 0;\n------RESULT\nKILL\n```\n\n----------------------------------------\n\nTITLE: Dropping a Schema in the Default Database using SQL\nDESCRIPTION: This example shows how to remove the `rw_schema` schema from the current default database (assumed to be `dev` in the context). The database name is omitted.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-schema.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP SCHEMA rw_schema;\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data into Table 't' in RisingWave (SQL)\nDESCRIPTION: SQL statement populating the previously created table 't' with multiple rows of sample data. This data is used to illustrate the behavior of the Top-N query example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/top-n-by-group.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t (x, y, z) VALUES\n  (1, 10, 50),\n  (1, 10, 60),\n  (1, 10, 70),\n  (1, 11, 55),\n  (1, 11, 65),\n  (2, 20, 30),\n  (2, 20, 40),\n  (2, 21, 25),\n  (2, 21, 35),\n  (2, 21, 45);\n\n```\n\n----------------------------------------\n\nTITLE: Listing Internal Tables for CDC\nDESCRIPTION: Shows how to list internal tables to find relevant backfill executor state information.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INTERNAL TABLES;\n```\n\n----------------------------------------\n\nTITLE: Creating Materialized View Exceeding Soft Limit in SQL\nDESCRIPTION: This SQL snippet shows the command to create a materialized view named `test_cluster_limit_exceed_soft`. The accompanying result block indicates that executing this command when the soft actor limit is exceeded will succeed but generate a `NOTICE` message warning about potential cluster overload and recommending scaling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/cluster-limit.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW test_cluster_limit_exceed_soft AS SELECT * FROM test;\n\n----RESULT\nNOTICE:\n- Actor count per parallelism exceeds the recommended limit.\n- Depending on your workload, this may overload the cluster and cause performance/stability issues. Scaling the cluster is recommended.\n- Contact us via Slack or https://risingwave.com/contact-us/ for further enquiry.\n- You can bypass this check via SQL `SET bypass_cluster_limits TO true`.\n- You can check actor count distribution via SQL `SELECT * FROM rw_worker_actor_count`.\nActorCountPerParallelism { critical limit: 8, recommended limit: 7. worker_id_to_actor_count: [\"1 -> WorkerActorCount { actor_count: 32, parallelism: 4 }\"] }\nCREATE_MATERIALIZED_VIEW\n```\n\n----------------------------------------\n\nTITLE: Delaying Execution with pg_sleep in SQL\nDESCRIPTION: The pg_sleep function makes the current session's process sleep for a specified number of seconds. It takes a double precision number as input, allowing for fractional-second delays.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/datetime.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\npg_sleep ( double precision )\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_sleep(1.5);\n```\n\n----------------------------------------\n\nTITLE: Setting PostgreSQL WAL Level to Logical (Bash)\nDESCRIPTION: This bash command executes the `ALTER SYSTEM SET wal_level = logical;` SQL command within PostgreSQL (implied via `psql`). It changes the Write-Ahead Log level to `logical`, which is required for Change Data Capture (CDC). A restart of the PostgreSQL instance is required for this change to take effect.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nALTER SYSTEM SET wal_level = logical;\n```\n\n----------------------------------------\n\nTITLE: Compiling Protobuf Schema with protoc for RisingWave (Bash)\nDESCRIPTION: This snippet shows how to use the protoc compiler in Bash to generate a FileDescriptorSet from a .proto file, required by RisingWave when specifying Protobuf schema locations. The command outputs a descriptor set `.pb` file (schema.pb) from the input `.proto` file, and can include dependencies via the include path. Dependencies: `protoc` must be installed, and the path variables and the schema files should be accessible.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/pulsar.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprotoc -I=$include_path --include_imports --descriptor_set_out=schema.pb schema.proto\n```\n\n----------------------------------------\n\nTITLE: Using array_lower Function in SQL\nDESCRIPTION: Returns the lower bound of the requested array dimension. This is always 1 or null in this implementation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\narray_lower ( array, int ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_lower(array[2, 3, 4], 1) → 1\n```\n\n----------------------------------------\n\nTITLE: Computing Relation Size in SQL\nDESCRIPTION: The pg_relation_size() function computes the disk space used by one \"fork\" of the specified relation. It can be used to determine if the main data fork of a relation exists.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\npg_relation_size ( relation regclass [, 'main' ] ) → bigint\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT pg_relation_size('t') != 0; → t\nSELECT pg_relation_size('t', 'main') != 0; → t\n```\n\n----------------------------------------\n\nTITLE: Querying Generated Data from RisingWave Source Table\nDESCRIPTION: This SQL query selects all columns from the 's1' table, orders the results by the 'i1' column, and limits the output to 20 rows. It's used to verify the data generated by the datagen connector.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/ingestion/advanced/generate-test-data.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM s1 ORDER BY i1 LIMIT 20;\n```\n\n----------------------------------------\n\nTITLE: Syntax for DROP AGGREGATE Command in SQL\nDESCRIPTION: Defines the syntax structure for removing a user-defined aggregate function (UDAF) in RisingWave. It includes optional clauses like `IF EXISTS` to prevent errors if the function doesn't exist, and optional argument type specification `( argument_type [, ...] )` for cases where the function name is not unique within the schema.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-aggregate.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDROP AGGREGATE [ IF EXISTS ] function_name [ ( argument_type [, ...] ) ] ;\n```\n\n----------------------------------------\n\nTITLE: Installing pg Driver with npm\nDESCRIPTION: Command to install the Node.js PostgreSQL driver (pg) via npm package manager.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/client-libraries/nodejs.mdx#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install pg\n```\n\n----------------------------------------\n\nTITLE: Using array_length Function in SQL (Two Parameters)\nDESCRIPTION: Returns the length of the requested array dimension. The second parameter must be 1 (as only one-dimensional arrays are supported).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\narray_length ( array, int ) → int\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_length(array[2, 3, 4], 1) → 3\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current User Name in SQL\nDESCRIPTION: The current_user function returns the name of the current effective user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/sys-info.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncurrent_user → *user_name*\ncurrent_user() → *user_name*\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT current_user(); → `root`\n```\n\n----------------------------------------\n\nTITLE: Angle Conversion Functions in SQL\nDESCRIPTION: Functions for converting between degrees and radians measurements.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/mathematical.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ndegrees(pi()/2) → 90\nradians(180) → 3.141592653589793\n```\n\n----------------------------------------\n\nTITLE: Displaying System Parameters in RisingWave using SHOW PARAMETERS\nDESCRIPTION: This command displays a list of system parameters in RisingWave, including their names, current values, and whether they are mutable. The output includes various configuration settings such as barrier interval, checkpoint frequency, and storage-related parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-parameters.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSHOW PARAMETERS;\n\n----RESULT\n\n Name                         |     Value      | Mutable\n----------------------------------------+----------------+---------\n barrier_interval_ms                    | 1000           | t\n checkpoint_frequency                   | 1              | t\n sstable_size_mb                        | 256            | f\n parallel_compact_size_mb               | 512            | f\n block_size_kb                          | 64             | f\n bloom_false_positive                   | 0.001          | f\n state_store                            | hummock+memory | f\n data_directory                         | hummock_001    | f\n backup_storage_url                     | memory         | t\n backup_storage_directory               | hummock_001/backup | t\n max_concurrent_creating_streaming_jobs | 1              | t\n pause_on_next_bootstrap                | false          | t\n enable_tracing                         | false          | t\n```\n\n----------------------------------------\n\nTITLE: Port-Forwarding Grafana Web Interface to Localhost (Bash)\nDESCRIPTION: Uses kubectl port-forward to expose Grafana's web interface (running in the monitoring namespace as svc/prometheus-grafana) on port 3000 of the local machine. Prerequisites: kubectl access to the Kubernetes cluster, and monitoring stack must be deployed. This command makes Grafana accessible on http://localhost:3000 for local administration, without exposing it externally.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl port-forward -n monitoring svc/prometheus-grafana 3000:http-web\n```\n\n----------------------------------------\n\nTITLE: Database Connection Parameters for RisingWave in Python\nDESCRIPTION: Python dictionary defining the default connection parameters for connecting to a local RisingWave instance using psycopg2.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndefault_params = {\n    \"dbname\": \"dev\",\n    \"user\": \"root\",\n    \"password\": \"\",\n    \"host\": \"localhost\",\n    \"port\": \"4566\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v2.2.0 Standalone in Docker\nDESCRIPTION: Command to run the RisingWave v2.2.0 standalone version in a Docker container, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v2.2.0-standalone single_node\n```\n\n----------------------------------------\n\nTITLE: Database Connection Parameters in Python\nDESCRIPTION: Python dictionary containing default connection parameters for RisingWave database connection.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndefault_params = {\n    \"dbname\": \"dev\",\n    \"user\": \"root\",\n    \"password\": \"\",\n    \"host\": \"localhost\",\n    \"port\": \"4566\"\n}\n```\n\n----------------------------------------\n\nTITLE: Generating SHA-384 Hash of Binary String in SQL\nDESCRIPTION: The sha384 function returns the SHA-384 hash of a binary string. It takes a bytea input and returns a bytea.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/binarystring.mdx#2025-04-23_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nsha384 ( bytea ) -> bytea\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sha384('risingwave'::bytea);\n------RESULT\n\\x7f6f71a068f04e3ed6338e06fec75941b48a2dadff58dffc4c39211b1dcc4a5f000168d1be49fd7b7e44094e7a7e627e\n```\n\n----------------------------------------\n\nTITLE: SHOW CURSORS Example with Results\nDESCRIPTION: An example of executing the SHOW CURSORS command and its output format. The result displays a single column named 'Name' that lists all cursor names, with 'my_cursor' being the only cursor in this example.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-cursors.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CURSORS;\n\n------RESULT\n Name\n-----------\n my_cursor\n(1 row)\n```\n\n----------------------------------------\n\nTITLE: Using array_dims Function in SQL\nDESCRIPTION: Returns the dimensions of a one-dimensional array as a string in the format [x:y] where x is the lower bound and y is the upper bound.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/array.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\narray_dims ( array ) → string\n```\n\nLANGUAGE: sql\nCODE:\n```\narray_dims(array[2,3,4]) → [1:3]\n```\n\n----------------------------------------\n\nTITLE: Schema Definition for the Example Table 'taxi_trips'\nDESCRIPTION: Provides the schema definition for the `taxi_trips` table used in the documentation examples. The table contains three columns: `id` of type INT (non-nullable), `distance` of type DOUBLE PRECISION (non-nullable), and `city` of type VARCHAR (nullable). This structure is relevant for understanding the subsequent INSERT examples.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": INT NOT NULL,\n  \"distance\": DOUBLE PRECISION NOT NULL,\n  \"city\": VARCHAR\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Float Type Aliases\nDESCRIPTION: Example showing the migration from FLOAT4/FLOAT8 type aliases to REAL/DOUBLE PRECISION.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n- @udf(input_types=['FLOAT4', 'FLOAT8'], result_type='INT')\n+ @udf(input_types=['REAL', 'DOUBLE PRECISION'], result_type='INT')\n```\n\n----------------------------------------\n\nTITLE: Displaying All Internal Tables in RisingWave\nDESCRIPTION: Example of using SHOW INTERNAL TABLES command to list all internal tables in RisingWave with their names, which represent intermediate states of queries.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-internal-tables.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSHOW INTERNAL TABLES;\n                   Name\n------------------------------------------\n __internal_v_20_hashjoinright_1019\n __internal_v_20_hashjoindegreeleft_1018\n __internal_v_18_grouptopnnode_1011\n __internal_v_20_hashjoindegreeright_1020\n __internal_v_17_topnnode_1010\n __internal_v_19_hashjoindegreeleft_1014\n __internal_v_20_hashjoinleft_1017\n __internal_v_18_hashaggresult_1012\n __internal_v_19_hashjoinright_1015\n __internal_v_19_hashjoindegreeright_1016\n __internal_v_19_hashjoinleft_1013\n(11 rows)\n```\n\n----------------------------------------\n\nTITLE: Twitter Data Schema Definition\nDESCRIPTION: JSON schema showing the structure of tweet and author data that will be processed.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"data\": {\n        \"created_at\": \"2020-02-12T17:09:56.000Z\",\n        \"id\": \"1227640996038684673\",\n        \"text\": \"Doctors: Googling stuff online does not make you a doctor\\n\\nDevelopers: https://t.co/mrju5ypPkb\",\n        \"lang\": \"English\"\n    },\n    \"author\": {\n        \"created_at\": \"2013-12-14T04:35:55.000Z\",\n        \"id\": \"2244994945\",\n        \"name\": \"Singularity Data\",\n        \"username\": \"singularitty\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection in Python\nDESCRIPTION: Sets up the default connection parameters for connecting to the RisingWave database using psycopg2.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndefault_params = {\n    \"dbname\": \"dev\",\n    \"user\": \"root\",\n    \"password\": \"\",\n    \"host\": \"localhost\",\n    \"port\": \"4566\"\n}\n```\n\n----------------------------------------\n\nTITLE: Examples of Encryption Type Parameters\nDESCRIPTION: Shows examples of how to format the type parameter for encryption functions, demonstrating different combinations of algorithm, mode, and padding options.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/cryptographic.mdx#2025-04-23_snippet_2\n\nLANGUAGE: text\nCODE:\n```\naes-cbc/pad:pkcs => AES algorithm, cbc mode, enabling padding\naes => AES algorithm, cbc mode, enabling padding\naes-ecb => AES algorithm, ecb mode, enabling padding\n```\n\n----------------------------------------\n\nTITLE: Searching Available RisingWave Versions\nDESCRIPTION: Commands to check available versions of RisingWave Helm charts and their output.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/upgrade-risingwave-k8s.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nhelm search repo risingwavelabs/risingwave -l\n```\n\nLANGUAGE: bash\nCODE:\n```\nNAME                               CHART VERSION APP VERSION DESCRIPTION\nrisingwavelabs/risingwave          0.1.16        v1.1.3      The distributed streaming database SQL stream p...\nrisingwavelabs/risingwave          0.1.15        v1.1.2      The distributed streaming database SQL stream p...\nrisingwavelabs/risingwave          0.1.14        v1.1.1      The distributed streaming database SQL stream p...\n```\n\n----------------------------------------\n\nTITLE: Viewing RisingWave Configuration Options\nDESCRIPTION: Command to display all available configuration options for RisingWave in single node mode.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave single --help\n```\n\n----------------------------------------\n\nTITLE: New Syntax for Defining Table with Primary Key as Table Constraint\nDESCRIPTION: The new syntax for creating a table with a connector where the primary key is defined as a table constraint rather than within the column definition.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE debezium_non_compact (PRIMARY KEY(order_id)) WITH ( ...\n```\n\n----------------------------------------\n\nTITLE: Swapping View Names with ALTER VIEW SWAP WITH in SQL\nDESCRIPTION: Syntax for swapping the names of two existing SQL views using the `ALTER VIEW ... SWAP WITH` clause. Requires the name of the first view (`name`) and the name of the second view (`target_name`). This effectively exchanges the identifiers of the two views.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-alter-view.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER VIEW name\nSWAP WITH target_name;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Read-only Grafana User in RisingWave\nDESCRIPTION: SQL command to create a dedicated read-only user for Grafana integration with a specified password.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/grafana.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER grafanareader WITH PASSWORD 'password';\n```\n\n----------------------------------------\n\nTITLE: Starting RisingWave with Default MinIO Configuration\nDESCRIPTION: Command to start a standalone RisingWave cluster using the default configuration with MinIO as the state store. This runs RisingWave in detached mode with all components in a single process.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Selecting All Rows After Deletion (SQL)\nDESCRIPTION: Retrieves all rows from the `taxi_trips` table after the previous `DELETE` operations have been performed. This command is used to verify the state of the table and confirm that the rows have been removed as expected.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Compiling Protobuf Schema using protoc in Bash\nDESCRIPTION: Shows the `protoc` command used to compile a `.proto` schema definition file into a `FileDescriptorSet` (`.pb` file). This format is required by RisingWave when specifying a schema location for Protobuf sources. The command includes import paths and specifies the output file.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/kafka.mdx#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nprotoc -I=$include_path --include_imports --descriptor_set_out=schema_descriptor.pb schema.proto\n```\n\n----------------------------------------\n\nTITLE: Installing AWS CLI and Java on EC2\nDESCRIPTION: This bash script installs the AWS CLI and Java 8 on an EC2 instance. It downloads the AWS CLI, unzips it, installs it, and then installs OpenJDK 8.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install unzip\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\nsudo apt install openjdk-8-jdk -y\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave metadata migration command from etcd to SQL backend\nDESCRIPTION: Command to migrate RisingWave metadata from etcd to SQL backend. The command requires specifying the etcd endpoints and SQL endpoint addresses. The -f flag forces the migration in case of any issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/migrate-to-sql-backend.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave ctl meta migration --etcd-endpoints <etcd_address> --sql-endpoint <sql_address> -f\n```\n\n----------------------------------------\n\nTITLE: Attempting to Drop a Non-Unique Function by Name in SQL\nDESCRIPTION: Shows an attempt to drop the function `f1` by name only. This command will fail because multiple functions named `f1` (with different argument signatures) exist, making the name ambiguous.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-drop-function.mdx#2025-04-23_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nDROP FUNCTION f1;\n```\n\n----------------------------------------\n\nTITLE: SHOW VIEWS Command Syntax in SQL\nDESCRIPTION: Defines the syntax for the SHOW VIEWS command, which lists existing views in a specified schema with optional pattern matching using LIKE expressions.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-show-views.mdx#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VIEWS [ FROM schema_name ] [ LIKE_expression ];\n```\n\n----------------------------------------\n\nTITLE: Checking Kubernetes Cluster Info\nDESCRIPTION: Command to verify the Kubernetes cluster is properly created and running\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl cluster-info\n```\n\n----------------------------------------\n\nTITLE: Analyzing High Join Amplification Log Output - Bash\nDESCRIPTION: This snippet demonstrates an example of a RisingWave log message output showing high join amplification during a streaming join operation. It provides key diagnostic details, such as matched rows, involved table IDs, join key, actor and fragment IDs. Observing such logs is crucial for pinpointing inefficient queries causing streaming bottlenecks. No dependencies are required, though access to RisingWave server logs is necessary. The log fields should be interpreted by administrators for troubleshooting join performance issues.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/performance/troubleshoot-high-latency.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhash_join_amplification: large rows matched for join key matched_rows_len=200000 update_table_id=31 match_table_id=33 join_key=OwnedRow([Some(Int32(1)), Some(Utf8(\"abc\"))]) actor_id=119 fragment_id=30\n```\n\n----------------------------------------\n\nTITLE: Defining company Table Schema in YAML\nDESCRIPTION: This YAML snippet defines the schema for the company table, including columns for company_id and taxi_id.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-select.mdx#2025-04-23_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n{\n  \"company_id\": VARCHAR,\n  \"taxi_id\": VARCHAR\n}\n```\n\n----------------------------------------\n\nTITLE: Linking libpq Binaries to System Path on macOS\nDESCRIPTION: Forces linking of all libpq binaries to /usr/local/bin on macOS to make the PostgreSQL client tools accessible from the command line without specifying the full path.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/install-psql-without-postgresql.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbrew link --force libpq\n```\n\n----------------------------------------\n\nTITLE: System Configuration Section Example\nDESCRIPTION: Example of basic system configuration settings including storage and backup parameters.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[system]\nbarrier_interval_ms = 1000\ncheckpoint_frequency = 1\nstate_store = \"hummock+minio://hummockadmin:hummockadmin@127.0.0.1:9301/hummock001\"\ndata_directory = \"hummock_001\"\nbackup_storage_url = \"minio://hummockadmin:hummockadmin@127.0.0.1:9301/hummock001\"\nbackup_storage_directory = \"hummock_001/backup\"\n```\n\n----------------------------------------\n\nTITLE: Enabling SQL Server Agent via mssql-conf (Shell)\nDESCRIPTION: This shell command enables the SQL Server Agent using the `mssql-conf` tool, typically run within the SQL Server container or environment. Enabling the agent requires restarting the SQL Server instance and may impact performance. Alternatively, the agent can be enabled by setting the environment variable `MSSQL_AGENT_ENABLED: \"true\"` when starting the container.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/sql-server-cdc.mdx#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n/opt/mssql/bin/mssql-conf set sqlagent.enabled true\n```\n\n----------------------------------------\n\nTITLE: Connecting and Logging In as Root - psql Bash Command\nDESCRIPTION: This bash command demonstrates connecting to RisingWave as the root user via psql. This is typically used to perform administrative actions such as user creation. The command requires valid credentials for the root account and the psql client.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: JSON Type Validation Example Results\nDESCRIPTION: Shows the output of testing different values against JSON type validations, displaying boolean results for each type check.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/functions/json.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\n js         | json? | scalar? | object? | array?\n------------+-------+---------+---------+---------\n 123        | t     | t       | f       | f\n \"abc\"      | t     | t       | f       | f\n {\"a\": \"b\"} | t     | f       | t       | f\n [1,2]      | t     | f       | f       | t\n abc        | f     | f       | f       | f\n```\n\n----------------------------------------\n\nTITLE: Using max Function with rw_int256 in SQL\nDESCRIPTION: Illustrates the usage of the max function to find the maximum value in a set of rw_int256 values.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/data-types/rw-int256.mdx#2025-04-23_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT max(v) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Disconnecting from RisingWave\nDESCRIPTION: Command to disconnect from the RisingWave session when finished with the tutorial.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/server-performance-anomaly-detection.mdx#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n\\q\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry via Environment Variable - Bash\nDESCRIPTION: This snippet shows how to set an environment variable to disable telemetry collection in RisingWave on macOS or Linux. By exporting \\\"ENABLE_TELEMETRY=false\\\" in the terminal before starting the cluster, users temporarily override telemetry collection for the session or process. No dependencies are required beyond a bash-compatible shell. This method is session-specific and doesn't persist across reboots or shells unless added to profile scripts.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/telemetry.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ENABLE_TELEMETRY=false\n\n```\n\n----------------------------------------\n\nTITLE: Checking Kubernetes Pod Status for RisingWave\nDESCRIPTION: Command to check the status of RisingWave pods in the specified namespace, filtering by the release name provided during installation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl -n risingwave get pods -l app.kubernetes.io/instance=<my-risingwave>\n```\n\n----------------------------------------\n\nTITLE: Syntax for the FLUSH Command (Bash)\nDESCRIPTION: This snippet shows the basic syntax for executing the `FLUSH` command within a shell or command-line interface connected to RisingWave. It triggers the synchronous persistence of pending data changes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-flush.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n```bash\nFLUSH;\n```\n```\n\n----------------------------------------\n\nTITLE: Granting PostgreSQL Privileges for CDC User (SQL)\nDESCRIPTION: These SQL statements grant the necessary privileges to a specified user for accessing and replicating data from a PostgreSQL database for CDC purposes. It grants connection rights, schema usage, select rights on all tables within the schema, and database creation rights.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/postgresql-cdc.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nGRANT CONNECT ON DATABASE <database_name> TO <username>;\nGRANT USAGE ON SCHEMA <schema_name> TO <username>;\nGRANT SELECT ON ALL TABLES IN SCHEMA <schema_name> TO <username>;\nGRANT CREATE ON DATABASE <database_name> TO <username>;\n```\n\n----------------------------------------\n\nTITLE: Downloading root certificate for SSL on Mac/Linux\nDESCRIPTION: Downloads the RisingWave Cloud root certificate to resolve SSL verification errors on Mac/Linux systems. Places the certificate in the standard PostgreSQL certificate location.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connection-errors.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L --create-dirs -o $HOME/.postgresql/root.crt 'https://risingwave.cloud/rootca/root.crt'\n```\n\n----------------------------------------\n\nTITLE: Executing Random Range Selects in SQL\nDESCRIPTION: This SQL query represents the 'select_random_ranges' workload. It counts the occurrences of 'k' within two specified ranges.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-benchmarks-query.mdx#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(k) FROM sbtest WHERE k BETWEEN ? AND ? OR k BETWEEN ? AND ?;\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding to Access RisingWave Service\nDESCRIPTION: Command to forward your local machine's port 4567 to the RisingWave service port, enabling access to the RisingWave cluster from your local machine.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-k8s-helm.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nkubectl -n risingwave port-forward svc/my-risingwave 4567:svc\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Format for Prometheus Metrics\nDESCRIPTION: Example of the JSON format used by Prometheus-kafka-adapter to send metrics to Kafka.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/use-risingwave-to-monitor-risingwave-metrics.mdx#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"labels\": {\n    \"__name__\": \"prometheus_template_text_expansions_total\",\n    \"instance\": \"prometheus-0:9500\",\n    \"job\": \"prometheus\"\n  },\n  \"name\": \"prometheus_template_text_expansions_total\",\n  \"timestamp\": \"2022-10-26T01:46:37Z\",\n  \"value\": \"0\"\n}\n```\n\n----------------------------------------\n\nTITLE: Syntax for RECOVER Command in Bash\nDESCRIPTION: This snippet shows the basic syntax for executing the `RECOVER` command in a Bash shell, typically used within a SQL client connected to RisingWave. This command initiates a manual, ad-hoc recovery process.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-recover.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nRECOVER;\n```\n\n----------------------------------------\n\nTITLE: Downloading root certificate for SSL on Windows\nDESCRIPTION: Downloads the RisingWave Cloud root certificate to resolve SSL verification errors on Windows systems. Creates the PostgreSQL certificate directory if it doesn't exist.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/connection-errors.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p $env:appdata\\postgresql\\; Invoke-WebRequest -Uri https://risingwave.cloud/rootca/root.crt\n```\n\n----------------------------------------\n\nTITLE: Generating a Grafana Dashboard JSON Model for Multiple Clusters (Bash)\nDESCRIPTION: Runs the generate.sh script with four environment variables to customize the resulting dashboard: enabling namespace and cluster-name filtering, supporting dynamic data sources, and assigning a unique dashboard UID. Assumes presence of generate.sh (from the risingwave repo) and necessary dependencies. Outputs one or more .gen.json files for import into Grafana; supports multi-cluster visualization.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nDASHBOARD_NAMESPACE_FILTER_ENABLED=true \\\nDASHBOARD_RISINGWAVE_NAME_FILTER_ENABLED=true \\\nDASHBOARD_DYNAMIC_SOURCE=true \\\nDASHBOARD_UID=risingwave_dashboard \\\n./generate.sh\n```\n\n----------------------------------------\n\nTITLE: Selecting All Rows from taxi_trips Table (SQL)\nDESCRIPTION: Retrieves all columns and rows currently present in the `taxi_trips` table. This command is used to show the initial state of the table before demonstrating the `DELETE` operation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-delete.mdx#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM taxi_trips;\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Docker Resources\nDESCRIPTION: Command to remove containers and generated data after completing the tutorial.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/fast-twitter-events-processing.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Displaying SQL Query Output in RisingWave Shell\nDESCRIPTION: Shows the shell output from querying the view v3. Values reflect joined columns from the view, and output is formatted as a table in a typical shell or SQL client. This snippet is for illustrative purposes to show expected output and does not require execution.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-view.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n a1  | i1 |        c1\n-----+----+------------------\n 115 |  1 | pGWJLsbmPJZZWpBe\n 585 |  2 | FT7BRdifYMrRgIyI\n 601 |  3 | 0zsMbNLxQh9yYtHh\n```\n\n----------------------------------------\n\nTITLE: Applying Custom Settings to a New BYOC Environment\nDESCRIPTION: This Bash command applies the custom settings to the newly created BYOC environment using the RisingWave CLI (rwc).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ rwc byoc apply --name $BYOC_NAME\n```\n\n----------------------------------------\n\nTITLE: Deleting a BYOC Environment Using RisingWave Cloud CLI\nDESCRIPTION: Commands to terminate and delete a RisingWave Cloud BYOC environment using the rwc CLI tool. The process involves first terminating the environment (taking 2-3 minutes) and then deleting it (taking 30-40 minutes).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/project-byoc.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ rwc byoc terminate --name default-byoc-environment # This may take 2-3 minutes.\n$ rwc byoc delete --name default-byoc-environment # This may take 30-40 minutes.\n```\n\n----------------------------------------\n\nTITLE: RisingWave Node Startup Command\nDESCRIPTION: Command to start a RisingWave node with a specific configuration file path.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/node-specific-configurations.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave --config-path=/path/to/risingwave.toml\n```\n\n----------------------------------------\n\nTITLE: Initiating WarpStream Playground (Bash)\nDESCRIPTION: This command starts the WarpStream playground environment locally. The playground provides a self-contained WarpStream instance for development and testing purposes.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/warpstream.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwarpstream playground\n```\n\n----------------------------------------\n\nTITLE: Running Bytebase Docker Container\nDESCRIPTION: Command to run Bytebase using Docker. It sets up a container named 'bytebase', publishes port 8080, and mounts a volume for data persistence.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/visualization/bytebase.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --init \\\n  --name bytebase \\\n  --publish 8080:8080 --pull always \\\n  --volume ~/.bytebase/data:/var/opt/bytebase \\\n  bytebase/bytebase:3.5.0\n```\n\n----------------------------------------\n\nTITLE: Connecting to RisingWave Database\nDESCRIPTION: This SQL command connects to a RisingWave database instance using psql, specifying the host, port, database name, and user.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\npsql -h localhost -p 4566 -d dev -U root\n```\n\n----------------------------------------\n\nTITLE: Creating Meta Snapshot using risectl\nDESCRIPTION: Command to create a new meta snapshot using the risectl tool.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/meta-backup.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nrisectl meta backup-meta\n```\n\n----------------------------------------\n\nTITLE: Constructing the RisingWave Webhook URL for RudderStack\nDESCRIPTION: Defines the required format for the RisingWave webhook URL that needs to be configured in RudderStack. It includes placeholders for the RisingWave host, database name, schema name, and the target table name (`wbhtable` in the examples).\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/rudderstack-webhook.mdx#2025-04-23_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nhttps://<HOST>/webhook/<database>/<schema_name>/<table_name>\n```\n\n----------------------------------------\n\nTITLE: Unregistering Workers in Cluster with RiseCTL\nDESCRIPTION: This command uses the 'risectl' tool to unregister workers from the cluster, which is part of the solution for unconventional compute node scaling.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/troubleshoot/troubleshoot-recovery-failure.mdx#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nrisectl meta unregister-workers --workers <worker_id or worker_host, ...>\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository in Bash\nDESCRIPTION: Clones the awesome-stream-processing repository containing the data generator script.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/inventory-management-forecast.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/awesome-stream-processing.git\n```\n\n----------------------------------------\n\nTITLE: Example Complete Time Windows Output - Bash\nDESCRIPTION: Example output for a SQL query that fills all expected time windows, inserting zeros where there is no data, allowing for continuous time series reports.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/sql/time-windows.mdx#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n window_start         | window_end           | trip_count \\n----------------------+----------------------+------------\\n 2022-07-01 22:00:00  | 2022-07-01 22:02:00  | 2          \\n 2022-07-01 22:02:00  | 2022-07-01 22:04:00  | 2          \\n 2022-07-01 22:04:00  | 2022-07-01 22:06:00  | 0          \\n 2022-07-01 22:06:00  | 2022-07-01 22:08:00  | 1          \\n 2022-07-01 22:08:00  | 2022-07-01 22:10:00  | 1          \n```\n\n----------------------------------------\n\nTITLE: Configuring Maven POM File\nDESCRIPTION: XML configuration for Maven project setup including RisingWave UDF dependencies and test configurations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-java.mdx#2025-04-23_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>com.example</groupId>\n    <artifactId>udf-example</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.risingwave.java</groupId>\n            <artifactId>risingwave-udf</artifactId>\n            <version>0.1.1</version>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v1.6.0 Docker Container\nDESCRIPTION: Command to run the RisingWave v1.6.0 Docker container, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v1.6.0-standalone single_node\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Cluster with Kind\nDESCRIPTION: Command to create a local Kubernetes cluster using Kind tool\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-kubernetes.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkind create cluster\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave in In-Memory Mode\nDESCRIPTION: Command to run RisingWave in in-memory mode where metadata and state data are not persisted to disk.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave --in-memory\n```\n\n----------------------------------------\n\nTITLE: SSL Connection Status Output\nDESCRIPTION: Example output showing successful SSL connection details including protocol version, cipher, and compression status.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/secure-connections-with-ssl-tls.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n```\n\n----------------------------------------\n\nTITLE: Sample Output of IoT Sensor Data Query (Bash/Pseudo-shell)\nDESCRIPTION: This snippet displays a formatted example output of the query run on 'iot_sensor_data', showing device measurements with corresponding timestamps and status fields. Intended for demonstration, it reflects what users may see as query results in an interactive SQL shell or command-line interface. No dependencies beyond query execution and ingested data; output rows correspond to records from the configured MQTT topic.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/mqtt.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n device_id  |       ts               | temperature | humidity |  device_status\\n------------+------------------------+-------------+----------+----------\\n device_001 | 2024-01-26 00:00:00+00 |        25.5 |     60.2 | normal\\n device_002 | 2024-01-26 00:00:01+00 |        10.8 |       22 | abnormal\\n device_003 | 2024-01-26 00:00:02+00 |        40.2 |     70.5 | normal\\n device_001 | 2024-01-26 00:00:03+00 |          10 |       80 | abnormal\\n device_002 | 2024-01-26 00:00:04+00 |        32.5 |     52.8 | normal\\n(5 rows)\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.15 from Docker\nDESCRIPTION: Command to run RisingWave version 0.1.15 from Docker, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_34\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.1.15 playground\n```\n\n----------------------------------------\n\nTITLE: Example Output of Querying 'taxi_trips' Table\nDESCRIPTION: Shows the expected output format when querying the `taxi_trips` table after the example `INSERT` operation using `VALUES`. It displays the `id`, `distance`, and `city` columns for the four inserted rows, formatted as a typical SQL result set in a command-line interface.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-insert.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n id | distance |   city\n----+----------+----------\n  1 |       16 | Dallas\n  2 |       23 | New York\n  3 |        6 | Chicago\n  4 |        9 |\n\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS IAM Credentials on EC2\nDESCRIPTION: This bash command starts the AWS CLI configuration process, prompting the user to enter their AWS access key ID, secret access key, default region, and output format.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\naws configure\n```\n\n----------------------------------------\n\nTITLE: Starting RisingWave After Script Installation\nDESCRIPTION: Command to start a RisingWave instance after installation via the script method.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nrisingwave\n```\n\n----------------------------------------\n\nTITLE: Quitting the SQL Shell - psql Bash Command\nDESCRIPTION: The following bash command is used to quit the psql PostgreSQL interactive terminal. There are no dependencies other than having psql running. This command is typically invoked when switching users or ending the current SQL session.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/commands/sql-create-user.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n\\q\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.16 from Docker\nDESCRIPTION: Command to run RisingWave version 0.1.16 from Docker, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_33\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.1.16 playground\n```\n\n----------------------------------------\n\nTITLE: Writing Test Data to Kafka Topic using Command-line Tools\nDESCRIPTION: Command to write JSON test data to the created Kafka topic 'example_topic'.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/automq-kafka.mdx#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\necho '{\"id\": 1, \"name\": \"testuser\", \"timestamp\": \"2023-11-10T12:00:00\", \"status\": \"active\"}' | sh kafka-console-producer.sh --broker-list 10.0.96.4:9092 --topic example_topic\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.12 Docker Container\nDESCRIPTION: Docker command to run RisingWave v0.1.12 in playground mode with port mappings.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_38\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 ghcr.io/risingwavelabs/risingwave:v0.1.12 playground\n```\n\n----------------------------------------\n\nTITLE: Creating Market Summary Materialized View in SQL\nDESCRIPTION: Creates a materialized view that displays current market data for each betting position, joining positions and market_data to include the most recent market price for each bookmaker.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW market_summary AS\nSELECT\n    p.position_id,\n    p.position_name,\n    p.league,\n    m.bookmaker,\n    m.market_price,\n    m.timestamp AS last_update\nFROM\n    positions AS p\nJOIN\n    (SELECT position_id, bookmaker, market_price, timestamp,\n            ROW_NUMBER() OVER (PARTITION BY position_id, bookmaker ORDER BY timestamp DESC) AS row_num\n     FROM market_data) AS m\nON p.position_id = m.position_id\nWHERE m.row_num = 1;\n```\n\n----------------------------------------\n\nTITLE: Starting Prometheus for RisingWave Monitoring\nDESCRIPTION: Command to start Prometheus with a custom configuration file for monitoring RisingWave. It sets up Prometheus to listen on port 9500.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nprometheus --config.file=./standalone/prometheus.yml --web.listen-address=0.0.0.0:9500\n```\n\n----------------------------------------\n\nTITLE: Installing and Running RisingWave via Homebrew\nDESCRIPTION: Commands to install and start RisingWave using Homebrew package manager for macOS.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/quickstart.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbrew tap risingwavelabs/risingwave\nbrew install risingwave\nrisingwave\n```\n\n----------------------------------------\n\nTITLE: Updating Import Statements\nDESCRIPTION: Migration example showing how to update import statements from risingwave.udf to arrow_udf.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n- from risingwave.udf import udf, udtf, UdfServer\n+ from arrow_udf import udf, udtf, UdfServer\n```\n\n----------------------------------------\n\nTITLE: Installing arrow-udf Package\nDESCRIPTION: Command to install the arrow-udf package using pip package manager.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/sql/udfs/use-udfs-in-python.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install arrow-udf\n```\n\n----------------------------------------\n\nTITLE: Old Syntax for Specifying CSV Format\nDESCRIPTION: The deprecated syntax for specifying CSV format options without headers and with delimiter settings in CREATE SOURCE and CREATE TABLE commands.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nROW FORMAT csv WITHOUT HEADER DELIMITED BY ',';\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Position Risk Management Demo Folder\nDESCRIPTION: Changes directory to the position risk management demo folder containing the data generator script and related files.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/sports-risk-profit-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd awesome-stream-processing/02-simple-demos/sports_betting/position_risk_management\n```\n\n----------------------------------------\n\nTITLE: Navigating to Docker Directory\nDESCRIPTION: Command to change into the docker directory within the cloned repository. This directory contains all the Docker Compose configuration files needed for setting up RisingWave.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/deploy/risingwave-docker-compose.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd docker\n```\n\n----------------------------------------\n\nTITLE: Declaring a Sample Data Table in Bash - Bash\nDESCRIPTION: This snippet provides a textual representation of the 'sales_data' table's structure and contents, illustrating sample data rows. Although presented in Bash code block format, it serves as a data visualization rather than executable code, and has no operational dependencies. The two columns are 'product_id' and 'sales_amount', used in subsequent SQL demonstrations.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/processing/overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nproduct_id | sales_amount\\n------------+--------------\\n          1 |           75\\n          2 |          150\\n          2 |          125\\n          1 |          100\\n          3 |          200\n```\n\n----------------------------------------\n\nTITLE: Running RisingWave v0.1.17 from Docker\nDESCRIPTION: Command to run RisingWave version 0.1.17 from Docker, exposing ports 4566 and 5691.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/changelog/release-notes.mdx#2025-04-23_snippet_32\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -it --pull=always -p 4566:4566 -p 5691:5691 risingwavelabs/risingwave:v0.1.17 playground\n```\n\n----------------------------------------\n\nTITLE: Sample Output for ServiceMonitor Query (Plaintext)\nDESCRIPTION: Displays the expected tabular results from querying ServiceMonitor resources in Kubernetes, confirming presence of risingwave-service-monitor in the monitoring namespace. This validates integration of Prometheus with RisingWave monitoring stack. No input or execution is required; output-only reference.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/operate/monitor-risingwave-cluster.mdx#2025-04-23_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nNAMESPACE    NAME                         AGE\nmonitoring   risingwave-service-monitor   119m\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Kafka Client\nDESCRIPTION: These bash commands download a specific version of the Kafka client (2.6.2) and extract it on the EC2 instance.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/integrations/sources/amazon-msk.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nwget https://archive.apache.org/dist/kafka/2.6.2/kafka_2.12-2.6.2.tgz\ntar -xzf kafka_2.12-2.6.2.tgz\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository via Bash\nDESCRIPTION: Commands to clone the awesome-stream-processing repository and navigate to the betting behavior demo directory.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/demos/betting-behavior-analysis.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/risingwavelabs/awesome-stream-processing.git\ncd awesome-stream-processing/tree/main/02-simple-demos/sports_betting/user_betting_behavior\n```\n\n----------------------------------------\n\nTITLE: Importing Button Component in MDX\nDESCRIPTION: Imports the Button component from a snippets directory for use in the documentation.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/cloud/console-overview.mdx#2025-04-23_snippet_0\n\nLANGUAGE: mdx\nCODE:\n```\nimport { Button } from '/snippets/button.mdx';\n```\n\n----------------------------------------\n\nTITLE: Refreshing License Key to Enable Free Trial\nDESCRIPTION: SQL command to refresh the license key and activate the free trial for Premium features in an existing RisingWave deployment.\nSOURCE: https://github.com/risingwavelabs/risingwave-docs/blob/main/get-started/rw-premium-edition-intro.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER SYSTEM SET license_key TO DEFAULT;\n```"
  }
]