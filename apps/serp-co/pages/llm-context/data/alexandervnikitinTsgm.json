[
  {
    "owner": "alexandervnikitin",
    "repo": "tsgm",
    "content": "TITLE: Training and Generating Synthetic Time Series with VAE in Python\nDESCRIPTION: This example illustrates the process of creating a synthetic dataset, scaling it, defining a VAE architecture, training the model, and generating new samples. It demonstrates the core workflow of using TSGM for time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\nfrom tensorflow import keras\n\nn, n_ts, n_features  = 1000, 24, 5\ndata = tsgm.utils.gen_sine_dataset(n, n_ts, n_features)\nscaler = tsgm.utils.TSFeatureWiseScaler()        \nscaled_data = scaler.fit_transform(data)\narchitecture = tsgm.models.zoo[\"vae_conv5\"](n_ts, n_features, 10)\nencoder, decoder = architecture.encoder, architecture.decoder\nvae = tsgm.models.cvae.BetaVAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\n\nvae.fit(scaled_data, epochs=1, batch_size=64)\nvae.generate(10)\n```\n\n----------------------------------------\n\nTITLE: Training a Generative Model with TSGM\nDESCRIPTION: This Python snippet demonstrates how to train a generative model using TSGM. It includes steps for selecting an architecture from the zoo, initializing a GAN object, compiling the model, training it, and generating synthetic samples.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n\n# ... Define hyperparameters ...\n# dataset is a tensor of shape n_samples x seq_len x feature_dim\n\n# Zoo contains several prebuilt architectures: we choose a conditional GAN architecture\narchitecture = tsgm.models.architectures.zoo[\"cgan_base_c4_l1\"](\n    seq_len=seq_len, feat_dim=feature_dim,\n    latent_dim=latent_dim, output_dim=0)\ndiscriminator, generator = architecture.discriminator, architecture.generator\n\n# Initialize GAN object with selected discriminator and generator\ngan = tsgm.models.cgan.GAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n)\ngan.fit(dataset, epochs=N_EPOCHS)\n\n# Generate 100 synthetic samples\nresult = gan.generate(100)\n```\n\n----------------------------------------\n\nTITLE: Defining and Training TimeGAN Model in Python\nDESCRIPTION: This snippet defines a TimeGAN model using tsgm.models.timeGAN.TimeGAN, compiles it, and trains it using the fit method. The model uses GRU modules with specified parameters for sequence length, hidden dimensions, and number of features.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/TimeGAN.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = tsgm.models.timeGAN.TimeGAN(\n    seq_len=24,\n    module=\"gru\",\n    hidden_dim=24,\n    n_features=5,\n    n_layers=3,\n    batch_size=256,\n    gamma=1.0,\n)\n# .compile() sets all optimizers to Adam by default\nmodel.compile()\n\nmodel.fit(\n    data=scaled_data,\n    epochs=100,\n)\n```\n\n----------------------------------------\n\nTITLE: Using TSGM to generate synthetic time series data with a conditional GAN\nDESCRIPTION: This Python code demonstrates how to use TSGM to create and train a conditional GAN model for generating synthetic time series data. It includes model initialization, compilation, training, and generation of synthetic samples.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/index.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n\n# ... Define hyperparameters ...\n# dataset is a tensor of shape n_samples x seq_len x feature_dim\n\n# Zoo contains several prebuilt architectures: we choose a conditional GAN architecture\narchitecture = tsgm.models.architectures.zoo[\"cgan_base_c4_l1\"](\n    seq_len=seq_len, feat_dim=feature_dim,\n    latent_dim=latent_dim, output_dim=0)\ndiscriminator, generator = architecture.discriminator, architecture.generator\n\n# Initialize GAN object with selected discriminator and generator\ngan = tsgm.models.cgan.GAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n)\ngan.fit(dataset, epochs=1)\n\n# Generate 10 synthetic samples\nresult = gan.generate(10)\n```\n\n----------------------------------------\n\nTITLE: Using TSGM's Architecture Zoo for Model Creation in Python\nDESCRIPTION: This example demonstrates how to use TSGM's Architecture Zoo to create a Conditional GAN (cGAN) model. It shows the flexibility of TSGM in allowing users to easily access and customize pre-defined model architectures.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n\nmodel_type = tsgm.models.architectures.zoo[\"cgan_lstm_n\"]\narch = model_type(\n    seq_len=seq_len, feat_dim=feat_dim,\n    latent_dim=latent_dim, output_dim=output_dim)\narch_dict = arch.get()\n# arch will store `.generator` and `.discriminator` fields for cGAN\n```\n\n----------------------------------------\n\nTITLE: Implementing Privacy Membership Inference Attack Metric for Time Series in TSGM with Python\nDESCRIPTION: Demonstrates the use of a privacy metric to measure the possibility of membership inference attacks using synthetic data. Utilizes TSGM's PrivacyMembershipInferenceMetric and a custom one-class SVM classifier.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Metrics Tutorial.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass FlattenTSOneClassSVM:\n    def __init__(self, clf):\n        self._clf = clf\n\n    def fit(self, X):\n        X_fl = X.reshape(X.shape[0], -1)\n        self._clf.fit(X_fl)\n\n    def predict(self, X):\n        X_fl = X.reshape(X.shape[0], -1)\n        return self._clf.predict(X_fl)\n```\n\nLANGUAGE: python\nCODE:\n```\nattacker = FlattenTSOneClassSVM(sklearn.svm.OneClassSVM())\nprivacy_metric = tsgm.metrics.PrivacyMembershipInferenceMetric(\n    attacker=attacker\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nXr, yr = tsgm.utils.gen_sine_vs_const_dataset(10, 100, 20, max_value=2, const=1)\nd_test = tsgm.dataset.Dataset(Xr, yr)\n\nprivacy_metric(d_real, d_syn, d_test)\n```\n\n----------------------------------------\n\nTITLE: Defining and Training Conditional GAN for Time Series Generation in Python\nDESCRIPTION: This code defines the conditional GAN model, compiles it with Adam optimizers, and trains it using the prepared dataset. It also sets up a monitor callback to track the training progress and performance.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncond_gan = tsgm.models.cgan.ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ncond_gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ncbk = tsgm.models.monitors.GANMonitor(num_samples=3, latent_dim=latent_dim, save=False, labels=y, save_path=\"/tmp\")\ncond_gan.fit(dataset, epochs=1000, callbacks=[cbk])\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Time Series Data with TimeGAN in Python\nDESCRIPTION: This code generates synthetic time series data using the trained TimeGAN model. It creates 10 new samples and shows the shape of the generated data, which is (n_samples, sequence_length, n_features).\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/TimeGAN.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nnew_x = model.generate(n_samples=10)\n# synthetic data have shape (n_samples, sequence_lenght, n_features)\nnew_x.shape\n```\n\n----------------------------------------\n\nTITLE: Defining and Training the Conditional GAN Model\nDESCRIPTION: Creates a temporal conditional GAN model, compiles it with Adam optimizers and binary cross-entropy loss, and trains the model on the prepared dataset for one epoch.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncond_gan = tsgm.models.cgan.ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim,\n    temporal=True,\n)\ncond_gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ncond_gan.fit(dataset, epochs=1)\n```\n\n----------------------------------------\n\nTITLE: Augmenting Time Series Data with Gaussian Noise in Python\nDESCRIPTION: This snippet demonstrates how to use TSGM to generate a synthetic sine wave dataset and apply Gaussian noise augmentation to it. It showcases the basic usage of the augmentation module in TSGM.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\nX = tsgm.utils.gen_sine_dataset(100, 64, 2, max_value=20)\naug_model = tsgm.models.augmentations.GaussianNoise(variance=0.2)\nsamples = aug_model.generate(X=X, n_samples=10)\n```\n\n----------------------------------------\n\nTITLE: Implementing Downstream Performance Metric for Time Series in TSGM with Python\nDESCRIPTION: Sets up a downstream performance metric to evaluate the quality of generated time series data by comparing model performance on real data vs. real data augmented with synthetic data. Uses TSGM's DownstreamPerformanceMetric.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Metrics Tutorial.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndownstream_model = tsgm.models.zoo[\"clf_cl_n\"](seq_len, feat_dim, n_classes, n_conv_lstm_blocks=1).model\ndownstream_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nevaluator = EvaluatorConvLSTM(downstream_model)\n\ndownstream_perf_metric = tsgm.metrics.DownstreamPerformanceMetric(evaluator)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(downstream_perf_metric(d_real, d_syn))\n```\n\n----------------------------------------\n\nTITLE: Compiling and Training Standard Conditional GAN\nDESCRIPTION: Sets up, compiles, and trains the conditional GAN with Adam optimizers, binary cross-entropy loss, and custom monitoring callbacks for visualizing generation progress.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncond_gan = tsgm.models.cgan.ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ncond_gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ncbk = tsgm.models.monitors.GANMonitor(num_samples=3, latent_dim=latent_dim, save=False, save_path=\"/tmp\", labels=y)\ncond_gan.fit(dataset, epochs=2, callbacks=[cbk])\n```\n\n----------------------------------------\n\nTITLE: Generating Samples from Trained Conditional GAN for Time Series in Python\nDESCRIPTION: This snippet generates samples from the trained conditional GAN model using a subset of the original labels. It prepares the generated data for visualization and analysis.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlimit = 500\nX_gen = cond_gan.generate(y[:limit])\nX_gen = X_gen.numpy()\ny_gen = y[:limit]\n```\n\n----------------------------------------\n\nTITLE: Defining and Training the cVAE Model\nDESCRIPTION: Creates a conditional Beta Variational Autoencoder, sets up learning rate decay, compiles the model with Adam optimizer, and trains it on the prepared data. The model is conditioned on class labels.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nencoder, decoder = architecture._encoder, architecture._decoder\n\n#vae = cBetaVAE(encoder, decoder, latent_dim=latent_dim, temporal=False)\nvae = tsgm.models.cvae.cBetaVAE(encoder, decoder, latent_dim=latent_dim, temporal=False)\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.0003,\n    decay_steps=100,\n    decay_rate=0.9)\noptimizer = keras.optimizers.Adam(lr_schedule)\nvae.compile(optimizer=keras.optimizers.Adam())\n\nvae.fit(X, y, epochs=1, batch_size=128)\n```\n\n----------------------------------------\n\nTITLE: Visualizing t-SNE Embeddings of Original and Generated Data\nDESCRIPTION: Creates a scatter plot of the t-SNE embeddings with different colors for each class and different markers for historical (original) and generated samples to visually assess the quality of generated data.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.figure(figsize=(8, 6), dpi=80)\nsns.scatterplot(x=X_emb[:, 0], y=X_emb[:, 1], hue=c[:], style=point_styles[:], markers={\"hist\": \"<\", \"gen\": \"H\"}, alpha=0.7)\n#sns.scatterplot(x=X_emb[limit:, 0], y=X_emb[limit:, 1], hue=c[limit:], style=point_styles[limit:], marker=\"s\", alpha=0.5)\nplt.legend()\nplt.box(False)\nplt.axis('off')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Defining and Compiling cGAN Model with TPU Strategy\nDESCRIPTION: Creates the Conditional GAN model within the TPU strategy scope. It sets up the generator and discriminator architectures, compiles the model with Adam optimizers, and configures the loss function for distributed training on TPU.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith strategy.scope():\n    dataset = tf.data.Dataset.from_tensor_slices((X_train, y))\n    dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n    architecture = tsgm.models.architectures.zoo[\"cgan_base_c4_l1\"](\n      seq_len=seq_len, feat_dim=feature_dim,\n      latent_dim=latent_dim, output_dim=output_dim)\n    discriminator, generator = architecture.discriminator, architecture.generator\n\n    cond_gan = tsgm.models.cgan.ConditionalGAN(\n      discriminator=discriminator, generator=generator, latent_dim=latent_dim\n    )\n    cond_gan.compile(\n      d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n      g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n      loss_fn=keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE),\n    )\n```\n\n----------------------------------------\n\nTITLE: Applying Gaussian Noise Augmentation to Time Series Data in Python\nDESCRIPTION: This code shows how to use the GaussianNoise augmentation model from TSGM to add jittering to time series data. It generates 10 samples with a variance of 0.2.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.GaussianNoise()\nsamples = aug_model.generate(X=X, n_samples=10, variance=0.2)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Original vs Reconstructed Time Series\nDESCRIPTION: Visualizes a comparison between the original time series and their reconstructions from the cVAE model to assess reconstruction quality visually.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_original_and_reconst_ts(X, x_decoded, num=10)\n```\n\n----------------------------------------\n\nTITLE: Building LSTM-based Conditional GAN Architecture\nDESCRIPTION: Creates the GAN architecture using LSTM networks for both generator and discriminator components, designed specifically for conditional time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\narchitecture = tsgm.models.architectures.cGAN_LSTMnArchitecture(\n    seq_len=seq_len, feat_dim=feature_dim,\n    latent_dim=latent_dim, output_dim=output_dim)\ndiscriminator, generator = architecture._discriminator, architecture._generator\n```\n\n----------------------------------------\n\nTITLE: Training cGAN Model on TPU\nDESCRIPTION: Executes the training process for the Conditional GAN model using the prepared dataset. The model is trained for 2 epochs using the TPU-accelerated strategy.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%%time\ncond_gan.fit(dataset, epochs=2)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Synthetic Time Series using TSGM Metrics in Python\nDESCRIPTION: This snippet showcases how to use TSGM's metrics module to evaluate the quality of synthetic time series data. It demonstrates the creation of custom distance metrics and their application to compare real and synthetic datasets.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\nimport functools\nimport numpy as np\n\nXr, yr = tsgm.utils.gen_sine_vs_const_dataset(10, 100, 20, max_value=2, const=1)  # real data\nXs, ys = Xr + 1e-5, yr  # synthetic data\n\nd_real = tsgm.dataset.Dataset(Xr, yr)\nd_syn = tsgm.dataset.Dataset(Xs, ys)\n\nstatistics = [\n\tfunctools.partial(tsgm.metrics.statistics.axis_max_s, axis=None),\n    functools.partial(tsgm.metrics.statistics.axis_min_s, axis=None)]\nsim_metric = tsgm.metrics.DistanceMetric(\n\tstatistics=statistics, discrepancy=lambda x, y: np.linalg.norm(x - y)\n)\nsim_metric = tsgm.metrics.DistanceMetric(\n\tstatistics=statistics, discrepancy=discrepancy_func\n)\nsim_metric(d_real, d_syn)\n```\n\n----------------------------------------\n\nTITLE: Training Privacy-Preserving Conditional GAN\nDESCRIPTION: Compiles and trains a privacy-preserving version of the conditional GAN using differential privacy optimizers from TensorFlow Privacy while maintaining the same model architecture.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ncond_gan = tsgm.models.cgan.ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ncond_gan.compile(\n    d_optimizer=d_optimizer,\n    g_optimizer=g_optimizer,\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ncbk = tsgm.models.monitors.GANMonitor(num_samples=3, latent_dim=latent_dim, save=False, save_path=\"/tmp\", labels=y)\ncond_gan.fit(dataset, epochs=2, callbacks=[cbk])\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Time Series Data with Conditional GAN\nDESCRIPTION: Creates random latent vectors with corresponding labels and feeds them to the trained generator to produce synthetic time series data that matches the original data's class structure.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nn_samples = 5\n\ntmp_latent = tf.random.normal(shape=(n_samples, seq_len, latent_dim))\nrandom_vector_labels = tf.concat(\n    [tmp_latent, y[:n_samples, :, None]], axis=2\n)\n\ngenerated_images = cond_gan.generator(random_vector_labels)\n```\n\n----------------------------------------\n\nTITLE: Selecting VAE Architecture for Time Series Generation in Python\nDESCRIPTION: This code selects a predefined VAE architecture from the 'tsgm' module, specifically the 'vae_conv5' model with parameters for time series length, number of features, and latent dimension.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\narchitecture = tsgm.models.zoo[\"vae_conv5\"](24, 5, 10)\nencoder, decoder = architecture.encoder, architecture.decoder\n```\n\n----------------------------------------\n\nTITLE: Defining Objective Function for TSGM Optimization\nDESCRIPTION: This function defines the objective for Optuna optimization. It loads data, builds a TimeGAN model with trial-suggested parameters, trains the model, generates synthetic data, and computes the optimization metric.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef objective(trial):\n    # Get data\n    train_data = get_data()\n\n    # Define the search space\n    n_layers = trial.suggest_int(name=\"n_layers\", low=1, high=10)\n    num_hidden = trial.suggest_int(name=\"num_hidden\", low=4, high=128, log=True)\n    \n    # Build TimeGAN model\n    model = tsgm.models.timeGAN.TimeGAN(\n        seq_len=24,\n        module=\"gru\",\n        hidden_dim=num_hidden,\n        n_features=5,\n        n_layers=n_layers,\n        batch_size=256,\n        gamma=1.0,\n    )\n    # get optimizer\n    optimizer = _create_optimizer(trial)\n    \n    # compile model\n    model.compile(optimizer)\n\n    # Training and validating\n    EPOCHS = 100\n    model.fit(data=train_data, epochs=EPOCHS)\n    \n    # Generate 10 samples of synthetic data\n    _y = model.generate(n_samples=10)\n    \n    # Evaluate them vs the first 10 samples of training data\n    objective_to_optimize = metric_to_optimize(_y, np.array(train_data[:10]))\n    \n    # Return last validation score\n    return objective_to_optimize\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Time Series Data\nDESCRIPTION: Uses the trained conditional GAN to generate synthetic time series data based on the provided labels.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nX_gen = cond_gan.generate(y)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generated Data with Distance Metrics\nDESCRIPTION: Computes a distance metric between real and generated time series data using maximum and minimum statistics along a specified axis to measure similarity.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nstatistics = [functools.partial(tsgm.metrics.statistics.axis_max_s, axis=1),\n              functools.partial(tsgm.metrics.statistics.axis_min_s, axis=1)]\n\nsim_metric = tsgm.metrics.DistanceMetric(\n    statistics=statistics, discrepancy=lambda x, y: np.linalg.norm(x - y)\n)\n\nprint(f\"Distance metric: {sim_metric(X, X_gen)}\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Generated Time Series Samples using t-SNE in Python\nDESCRIPTION: This code uses t-SNE (t-distributed stochastic neighbor embedding) to visualize both the original and generated time series data, allowing for a comparison of the distribution and quality of the generated samples.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_tsne(X_train[:limit], y[:limit], X_gen, y_gen)\n```\n\n----------------------------------------\n\nTITLE: Defining and Training VAE Model for Time Series Generation in Python\nDESCRIPTION: This code defines a Beta-VAE model using the previously selected encoder and decoder, compiles it with Adam optimizer, and trains it on the scaled data for 100 epochs.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvae = tsgm.models.cvae.BetaVAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\n\nvae.fit(scaled_data, epochs=100, batch_size=64)\n```\n\n----------------------------------------\n\nTITLE: Defining Optimizer Search Space for TSGM\nDESCRIPTION: This function creates a search space for optimizers (RMSprop, Adam, SGD) and their hyperparameters to be used in the TSGM model optimization.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef _create_optimizer(trial):\n    kwargs = {}\n    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n    if optimizer_selected == \"RMSprop\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\n            \"rmsprop_learning_rate\", 1e-5, 1e-1, log=True\n        )\n        kwargs[\"momentum\"] = trial.suggest_float(\n            \"rmsprop_momentum\", 1e-5, 1e-1, log=True\n        )\n    elif optimizer_selected == \"Adam\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\n            \"adam_learning_rate\", 1e-5, 1e-1, log=True\n        )\n    elif optimizer_selected == \"SGD\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\n            \"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True\n        )\n        kwargs[\"momentum\"] = trial.suggest_float(\n            \"sgd_opt_momentum\", 1e-5, 1e-1, log=True\n        )\n\n    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n    return optimizer\n```\n\n----------------------------------------\n\nTITLE: Generating and Preprocessing Time Series Data\nDESCRIPTION: Creates a synthetic dataset with two classes (sine waves vs. constant values) and applies feature-wise scaling to normalize data between 0 and 1. Also converts the class labels to one-hot encoding.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nX, y_i = tsgm.utils.gen_sine_vs_const_dataset(5000, 256, 1, max_value=20, const=10)\n\nscaler = tsgm.utils.TSFeatureWiseScaler((0, 1))\nX = scaler.fit_transform(X).astype(np.float32)\ny = keras.utils.to_categorical(y_i, output_dim).astype(np.float32)\n```\n\n----------------------------------------\n\nTITLE: Implementing Consistency Metric for Time Series in TSGM with Python\nDESCRIPTION: Creates a consistency metric to measure whether a family of models show consistent performance on real and synthetic datasets. Uses TSGM's ConsistencyMetric class and custom evaluator.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Metrics Tutorial.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport sklearn\n\nclass EvaluatorConvLSTM():\n    '''\n    NB an oversimplified classifier, for educational purposes only.\n    '''\n    \n    def __init__(self, model):\n        self._model = model\n\n    def evaluate(self, D: tsgm.dataset.Dataset) -> float:\n        X, y = D.Xy\n        \n        X_train , X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)\n        y_train = keras.utils.to_categorical(y_train, 2)\n        self._model.fit(X_train, y_train)\n        \n        y_pred = np.argmax(self._model.predict(X_test), 1)\n        return sklearn.metrics.accuracy_score(y_pred, y_test)\n\n\nseq_len, feat_dim, n_classes = *Xr.shape[1:], 2\nmodels = [tsgm.models.zoo[\"clf_cl_n\"](seq_len, feat_dim, n_classes, n_conv_lstm_blocks=i) for i in range(1, 4)]\nfor m in models:\n    m.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nevaluators = [EvaluatorConvLSTM(m.model) for m in models]\n```\n\nLANGUAGE: python\nCODE:\n```\nconsistency_metric = tsgm.metrics.ConsistencyMetric(evaluators=evaluators)\n```\n\nLANGUAGE: python\nCODE:\n```\nconsistency_metric(d_real, d_syn)\n```\n\n----------------------------------------\n\nTITLE: Defining Optimization Metric for TSGM\nDESCRIPTION: This code defines a custom distance metric using TSGM's statistics and discrepancy functions for model evaluation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmetric_to_optimize = tsgm.metrics.metrics.DistanceMetric(\n            statistics=[\n                functools.partial(tsgm.metrics.statistics.axis_max_s, axis=None),\n                functools.partial(tsgm.metrics.statistics.axis_min_s, axis=None),\n                functools.partial(tsgm.metrics.statistics.axis_max_s, axis=1),\n                functools.partial(tsgm.metrics.statistics.axis_min_s, axis=1),\n            ],\n            discrepancy=lambda x, y: np.linalg.norm(x - y),\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Distance Metric for Time Series in TSGM with Python\nDESCRIPTION: Defines a distance metric using summary statistics and a discrepancy function to measure the similarity between real and synthetic datasets. Uses the TSGM library's DistanceMetric class.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Metrics Tutorial.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nstatistics = [functools.partial(tsgm.metrics.statistics.axis_max_s, axis=None),\n              functools.partial(tsgm.metrics.statistics.axis_min_s, axis=None),\n              functools.partial(tsgm.metrics.statistics.axis_max_s, axis=1),\n              functools.partial(tsgm.metrics.statistics.axis_min_s, axis=1)]\n```\n\nLANGUAGE: python\nCODE:\n```\ndiscrepancy_func = lambda x, y: np.linalg.norm(x - y)\n```\n\nLANGUAGE: python\nCODE:\n```\nsim_metric = tsgm.metrics.DistanceMetric(\n    statistics=statistics, discrepancy=discrepancy_func\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nsim_metric(d_real, d_syn)\n```\n\n----------------------------------------\n\nTITLE: Running Optuna Optimization for TSGM\nDESCRIPTION: This code executes the Optuna optimization process for the TSGM model using the defined objective function and number of trials.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nstudy.optimize(objective, n_trials=10)\n```\n\n----------------------------------------\n\nTITLE: Selecting Architecture from TSGM Model Zoo\nDESCRIPTION: Selects a predefined convolutional architecture (cvae_conv5) from the tsgm model zoo and initializes it with the specified parameters. The architecture includes both encoder and decoder components.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel_type = tsgm.models.architectures.zoo[\"cvae_conv5\"]\narchitecture = model_type(seq_len=seq_len, feat_dim=feat_dim, latent_dim=latent_dim, output_dim=2)\n\nencoder, decoder = architecture._encoder, architecture._decoder\n```\n\n----------------------------------------\n\nTITLE: Configuring Temporal Conditional GAN Architecture\nDESCRIPTION: Selects and configures the t-cgan_c4 architecture from the TSGM library's model zoo, specifying sequence length, feature dimension, latent dimension, and output dimension for the GAN components.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\narchitecture = tsgm.models.architectures.zoo[\"t-cgan_c4\"](\n    seq_len=seq_len, feat_dim=feature_dim,\n    latent_dim=latent_dim, output_dim=output_dim)\ndiscriminator, generator = architecture.discriminator, architecture.generator\n```\n\n----------------------------------------\n\nTITLE: Defining GAN Parameters for Time Series Generation\nDESCRIPTION: Sets up the key parameters for the GAN model including latent dimension, output dimension (number of classes), feature dimension, and sequence length for the time series data.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 128\n\nlatent_dim = 1\nfeature_dim = 1\nseq_len = 123\noutput_dim = 1\n\ngenerator_in_channels = latent_dim + output_dim\ndiscriminator_in_channels = feature_dim + output_dim\n```\n\n----------------------------------------\n\nTITLE: Preparing and Scaling Time Series Dataset\nDESCRIPTION: Generates a sine vs constant dataset, applies feature-wise scaling, and prepares the data for training. The dataset is then converted to a TensorFlow Dataset object for efficient batching and shuffling.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nX, y_i = tsgm.utils.gen_sine_vs_const_dataset(5000, seq_len, 1, max_value=20, const=10)\n\nscaler = tsgm.utils.TSFeatureWiseScaler((-1, 1))\nX_train = scaler.fit_transform(X)\ny = keras.utils.to_categorical(y_i, 2)\n\nX_train = X_train.astype(np.float32)\ny = y.astype(np.float32)\n\ndataset = tf.data.Dataset.from_tensor_slices((X_train, y))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Generating and Preprocessing Sine Wave Dataset\nDESCRIPTION: Creates a synthetic dataset of sine waves versus constant values, normalizes it using a feature-wise scaler, and prepares it for training by creating a TensorFlow dataset with shuffling and batching.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nX, y_i = tsgm.utils.gen_sine_vs_const_dataset(5_000, seq_len, 1, max_value=20, const=10)\n\nscaler = tsgm.utils.TSFeatureWiseScaler((-1, 1))\nX_train = scaler.fit_transform(X)\ny = keras.utils.to_categorical(y_i, 2)\n\nX_train = X_train.astype(np.float32)\ny = y.astype(np.float32)\n\ndataset = tf.data.Dataset.from_tensor_slices((X_train, y))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Defining cVAE Model Parameters\nDESCRIPTION: Sets up the key parameters for the Conditional Variational Autoencoder model, including sequence length, feature dimensions, output dimensions (number of classes), and latent space dimension.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nseq_len = 256\nfeat_dim = 1\noutput_dim = 2\nlatent_dim = 32\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Time Series Data for Conditional GAN in Python\nDESCRIPTION: This snippet generates a toy dataset using a custom utility function, scales the features, converts labels to categorical, and prepares the data for training. It uses TensorFlow's Dataset API for efficient data handling.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nX, y_i = tsgm.utils.gen_sine_vs_const_dataset(5_000, seq_len, 1, max_value=20, const=10)\n\nscaler = tsgm.utils.TSFeatureWiseScaler((-1, 1))\nX_train = scaler.fit_transform(X)\ny = keras.utils.to_categorical(y_i, 2)\n\nX_train = X_train.astype(np.float32)\ny = y.astype(np.float32)\n\ndataset = tf.data.Dataset.from_tensor_slices((X_train, y))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Time Series Data for VAE in Python\nDESCRIPTION: This snippet generates a toy dataset of sine waves and scales the features to the range [0, 1] using custom utility functions from the 'tsgm' module.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndata = tsgm.utils.gen_sine_dataset(10000, 24, 5)\nscaler = tsgm.utils.TSFeatureWiseScaler()        \nscaled_data = scaler.fit_transform(data)\n```\n\n----------------------------------------\n\nTITLE: Implementing Slice and Shuffle Augmentation for Time Series in Python\nDESCRIPTION: This code applies the SliceAndShuffle augmentation technique, which cuts a time series into segments and shuffles them. It's useful for time series with temporal invariance, generating 10 samples with 3 segments each.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.SliceAndShuffle()\nsamples = aug_model.generate(X=X, n_samples=10, n_segments=3)\n```\n\n----------------------------------------\n\nTITLE: Loading Physionet 2012 ICU Dataset with TSGM\nDESCRIPTION: Loads the Physionet 2012 dataset which contains ICU patient data for mortality prediction. The code retrieves training, testing, and validation splits and prints their shapes.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_X, train_y, test_X, test_y, val_X, val_y = tsgm.utils.get_physionet2012()\nprint(\"Train data: \", train_X.shape, train_y.shape)\nprint(\"Test data: \", test_X.shape, test_y.shape)\nprint(\"Val data: \", val_X.shape, val_y.shape)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Time Series Data\nDESCRIPTION: Generates a synthetic sine-constant switch dataset, applies feature-wise scaling to normalize values to [-1, 1] range, and prepares the data for training by creating TensorFlow datasets with proper batching.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nX, y = tsgm.utils.gen_sine_const_switch_dataset(50_000, seq_len, 1, max_value=20, const=10)\n\nscaler = tsgm.utils.TSFeatureWiseScaler((-1, 1))\nX_train = scaler.fit_transform(X)\n\n\nX_train = X_train.astype(np.float32)\ny = y.astype(np.float32)\n\ndataset = tf.data.Dataset.from_tensor_slices((X_train, y))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n```\n\n----------------------------------------\n\nTITLE: Shuffling Features in Multivariate Time Series using TSGM in Python\nDESCRIPTION: This snippet demonstrates the Shuffle augmentation technique, which permutes features in multivariate time series. It's suitable for time series where features represent independent measurements from various sensors.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.Shuffle()\nsamples = aug_model.generate(X=X, n_samples=3)\n```\n\n----------------------------------------\n\nTITLE: Implementing Window Warping for Time Series Augmentation in Python\nDESCRIPTION: This code demonstrates the WindowWarping technique, which speeds up or slows down selected windows in time series data. It generates 10 samples with a scale of 0.5 and a window ratio of 0.5.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.WindowWarping()\nsamples = aug_model.generate(X=X, n_samples=10, scales=(0.5,), window_ratio=0.5)\n```\n\n----------------------------------------\n\nTITLE: Applying Dynamic Time Warping Barycentric Average (DTWBA) in Python\nDESCRIPTION: This snippet shows how to use the DTWBarycentricAveraging augmentation technique, which is based on Dynamic Time Warping. It generates 10 samples using randomly selected initial time series from the dataset.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.DTWBarycentricAveraging()\ninitial_timeseries = random.sample(range(X.shape[0]), 10)\ninitial_timeseries = X[initial_timeseries]\nsamples = aug_model.generate(X=X, n_samples=10, initial_timeseries=initial_timeseries)\n```\n\n----------------------------------------\n\nTITLE: Applying Magnitude Warping to Time Series Data using TSGM in Python\nDESCRIPTION: This snippet shows how to use the MagnitudeWarping augmentation, which scales the magnitude of time series using a cubic spline curve. It generates 10 samples with a sigma value of 1 for the random magnitude distribution.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\naug_model = tsgm.models.augmentations.MagnitudeWarping()\nsamples = aug_model.generate(X=X, n_samples=10, sigma=1)\n```\n\n----------------------------------------\n\nTITLE: Reconstructing Time Series Data with Trained VAE in Python\nDESCRIPTION: This snippet uses the trained VAE to reconstruct the input data, which is a crucial step in validating the model's performance.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nx_decoded = vae.predict(scaled_data)\n```\n\n----------------------------------------\n\nTITLE: Defining Model Parameters for cGAN\nDESCRIPTION: Sets up key parameters for the Conditional GAN model, including latent dimension, output dimension, feature dimension, sequence length, and batch size. These parameters define the structure and input/output characteristics of the generator and discriminator.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlatent_dim = 64\noutput_dim = 2\nfeature_dim = 1\nseq_len = 100\nbatch_size = 128\n\n\ngenerator_in_channels = latent_dim + output_dim\ndiscriminator_in_channels = feature_dim + output_dim\n```\n\n----------------------------------------\n\nTITLE: Visualizing Original and Reconstructed Time Series in Python\nDESCRIPTION: This code uses a utility function from the 'tsgm' module to visually compare the original and reconstructed time series data, helping to assess the VAE's reconstruction quality.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_original_and_reconst_ts(scaled_data, x_decoded, num=10)\n```\n\n----------------------------------------\n\nTITLE: Predicting Time Series Reconstructions\nDESCRIPTION: Uses the trained cVAE model to predict (reconstruct) the input time series data, which will be used to evaluate the model's performance.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nx_decoded = vae.predict([X, y])\n```\n\n----------------------------------------\n\nTITLE: Defining GAN Parameters for Conditional Time Series Generation in Python\nDESCRIPTION: This code defines the key parameters for the Generative Adversarial Network (GAN), including latent dimension, output dimension, feature dimension, sequence length, and batch size. It also calculates the input channels for the generator and discriminator.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlatent_dim = 64\noutput_dim = 2\nfeature_dim = 1\nseq_len = 100\nbatch_size = 128\n\n\ngenerator_in_channels = latent_dim + output_dim\ndiscriminator_in_channels = feature_dim + output_dim\n```\n\n----------------------------------------\n\nTITLE: Loading and Scaling Time Series Data in Python\nDESCRIPTION: This code generates a toy dataset using tsgm.utils.gen_sine_dataset and scales it using tsgm.utils.TSFeatureWiseScaler. The data is scaled featurewise to the range [0, 1].\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/TimeGAN.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = tsgm.utils.gen_sine_dataset(10000, 24, 5)\nscaler = tsgm.utils.TSFeatureWiseScaler()        \nscaled_data = scaler.fit_transform(data)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Generated Time Series Data\nDESCRIPTION: Creates a visualization of the synthetically generated time series data to compare with the original data, saving the output as a PDF file for comparison.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_ts_lineplot(generated_images, y, 5)\nplt.savefig(\"synth_data_temporal_gan.pdf\", bbox_inches='tight')\n```\n\n----------------------------------------\n\nTITLE: Loading UCR Dataset in Python using TSGM\nDESCRIPTION: This snippet shows how to use TSGM's data management utilities to load a dataset from the UCR (University of California, Riverside) Time Series Classification Archive. It demonstrates the ease of accessing pre-defined datasets in TSGM.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n\nucr_data_manager = tsgm.utils.UCRDataManager(ds=\"gunpoint\")\nassert ucr_data_manager.summary() is None\nX_train, y_train, X_test, y_test = ucr_data_manager.get()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Original Time Series Data\nDESCRIPTION: Uses the TSGM utility function to create a line plot visualization of the original time series data with class labels, saving the output as a PDF file.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_ts_lineplot(X_train, y, 5)\nplt.savefig(\"data_temporal_gan.pdf\", bbox_inches='tight')\n```\n\n----------------------------------------\n\nTITLE: Loading UCR ECG200 Dataset with TSGM\nDESCRIPTION: Demonstrates how to load the ECG200 dataset from the UCR repository using TSGM's UCRDataManager utility. The code retrieves training and test data, then prints their shapes and unique labels.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nucr_manager = tsgm.utils.UCRDataManager(ds=\"ECG200\")\nX_train, y_train, X_test, y_test = ucr_manager.get()\nprint(\"Train Data: \", X_train.shape, y_train.shape)\nprint(\"Test Data: \", X_test.shape, y_test.shape)\nprint(\"Unique Labels: \", set(list(y_train) + list(y_test)))\n```\n\n----------------------------------------\n\nTITLE: Displaying Generator Model Summary\nDESCRIPTION: Shows the layer structure and parameter counts of the generator model using Keras' summary method.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\narchitecture._generator.summary()\n```\n\n----------------------------------------\n\nTITLE: Loading EEG Eye State Dataset with TSGM\nDESCRIPTION: Loads the EEG Eye State dataset using TSGM's utility function and prints the shapes of the feature matrix X and target vector y.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nX, y = tsgm.utils.get_eeg()\nprint(X.shape, y.shape)\n```\n\n----------------------------------------\n\nTITLE: Configuring Privacy-Preserving GAN Parameters\nDESCRIPTION: Sets up parameters for differential privacy in the GAN, including L2 norm clipping, noise multiplier, number of microbatches, and learning rate for privacy-preserving optimization.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nl2_norm_clip = 1.5\nnoise_multiplier = 1.3\nnum_microbatches = 1\nlearning_rate = 0.01\n\n\nd_optimizer = tf_privacy.DPKerasSGDOptimizer(\n    l2_norm_clip=l2_norm_clip,\n    noise_multiplier=noise_multiplier,\n    num_microbatches=num_microbatches,\n    learning_rate=learning_rate\n)\n\n\ng_optimizer = tf_privacy.DPKerasSGDOptimizer(\n    l2_norm_clip=l2_norm_clip,\n    noise_multiplier=noise_multiplier,\n    num_microbatches=num_microbatches,\n    learning_rate=learning_rate\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying Discriminator Model Summary\nDESCRIPTION: Shows the layer structure and parameter counts of the discriminator model using Keras' summary method.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\narchitecture._discriminator.summary()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Time Series Data\nDESCRIPTION: Displays a line plot visualization of the time series data using a utility function from the TSGM library, showing examples from different classes.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_ts_lineplot(X_train, y_i, num=2)\n```\n\n----------------------------------------\n\nTITLE: Visualizing EEG Channel Correlations\nDESCRIPTION: Creates a correlation matrix heatmap to visualize relationships between different EEG channels in the dataset. This helps identify which channels have similar or opposing patterns.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.DataFrame(X, columns=[f'Channel_{i+1}' for i in range(X.shape[1])])\n\ncorr_matrix = df.corr()\n\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\nplt.title('Correlation Matrix of EEG Channels')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Defining Model Dimensions and Parameters\nDESCRIPTION: Sets up key parameters for the GAN model including latent dimension, output dimension, feature dimension, sequence length, and batch size for time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlatent_dim = 64\noutput_dim = 2\nfeature_dim = 1\nseq_len = 100\nbatch_size = 128\n\n\ngenerator_in_channels = latent_dim + output_dim\ndiscriminator_in_channels = feature_dim + output_dim\n```\n\n----------------------------------------\n\nTITLE: Visualizing ECG200 Dataset Time Series\nDESCRIPTION: Creates a visualization of the ECG200 dataset by sampling 5 signals from each class and plotting them as line charts. The code transforms the data into a format suitable for visualization with seaborn.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.DataFrame(X_train, columns=[f'Time_{i+1}' for i in range(X_train.shape[1])])\ndf['Label'] = y_train\n\n# Sample a few signals from each class to plot (5 samples per class)\nsampled_df = df.groupby('Label').apply(lambda x: x.sample(5)).reset_index(drop=True)\n\nmelted_df = sampled_df.melt(id_vars='Label', var_name='Time', value_name='Amplitude')\nmelted_df['Time'] = melted_df['Time'].str.replace('Time_', '').astype(int)\n\n# Plot the line plots\nplt.figure(figsize=(14, 8))\nsns.lineplot(data=melted_df, x='Time', y='Amplitude', hue='Label', style='Label', markers=True, dashes=False)\nplt.title('ECG Signals Over Time for Different Classes')\nplt.xlabel('Time Point')\nplt.ylabel('Amplitude')\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM on Apple M1 and M2 chips\nDESCRIPTION: This code block provides instructions for installing TSGM on Apple M1 and M2 chips. It includes steps for installing TensorFlow, TSGM without dependencies, and then installing the remaining dependencies separately.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Install tensorflow\nconda install -c conda-forge tensorflow=2.9.1\n\n# Install tsgm without dependencies\npip install tsgm --no-deps\n\n# Install rest of the dependencies (separately here for clarity)\nconda install tensorflow-probability scipy antropy statsmodels dtaidistance networkx optuna prettytable seaborn scikit-learn yfinance tqdm\n```\n\n----------------------------------------\n\nTITLE: Retrieving Best Trial Parameters for TSGM\nDESCRIPTION: This snippet retrieves and displays the parameters of the best trial found during the Optuna optimization process for the TSGM model.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nstudy.best_trial\n```\n\n----------------------------------------\n\nTITLE: Displaying Encoder Model Summary\nDESCRIPTION: Displays a summary of the encoder model architecture showing layers, shapes, and parameters.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nencoder.summary()\n```\n\n----------------------------------------\n\nTITLE: Configuring TPU Distribution Strategy\nDESCRIPTION: Sets up a TPU distribution strategy for accelerated training. It resolves the TPU cluster, initializes the TPU system, and creates a TPU strategy object for distributed training across TPU cores.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nprint('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n```\n\n----------------------------------------\n\nTITLE: Creating Optuna Study for TSGM Optimization\nDESCRIPTION: This snippet creates an Optuna study object for minimizing a specified metric in the TSGM model optimization process.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nstudy = optuna.create_study(direction=\"minimize\")\n```\n\n----------------------------------------\n\nTITLE: Defining TSGM Documentation Structure in reStructuredText\nDESCRIPTION: This code snippet defines the structure of the TSGM documentation using reStructuredText directives. It includes sections for datasets, augmentations, metrics, GANs, VAEs, ABC, STS, visualization, monitors, zoo, simulators, and data processing utilities.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/modules/root.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\nTSGM\n==================\n\n.. contents:: Contents\n    :local:\n\nDatasets\n--------------\n\n.. autoclass:: tsgm.utils.UCRDataManager\n    :members:\n    :undoc-members:\n\n.. automodule:: tsgm.utils.datasets\n    :members:\n    :undoc-members:\n\n\nAugmentations\n--------------\n.. automodule:: tsgm.models.augmentations\n    :members:\n    :undoc-members:\n\nMetrics\n--------------\n.. automodule:: tsgm.metrics.metrics\n    :members:\n    :undoc-members:\n\n\nGANs\n--------------\n.. automodule:: tsgm.models.cgan\n    :members:\n    :undoc-members:\n\n\nVAEs\n--------------\n.. automodule:: tsgm.models.cvae\n    :members:\n    :undoc-members:\n\n\nABC\n--------------\n.. automodule:: tsgm.optimization.abc\n    :members:\n    :undoc-members:\n\n\nSTS\n--------------\n.. automodule:: tsgm.models.sts\n    :members:\n    :undoc-members:\n\n\nVisualization\n--------------\n.. automodule:: tsgm.utils.visualization\n    :members:\n    :undoc-members:\n\n\nMonitors\n--------------\n.. automodule:: tsgm.models.monitors\n    :members:\n    :undoc-members:\n\n\nZoo\n--------------\n.. automodule:: tsgm.models.architectures.zoo\n    :members:\n    :undoc-members:\n\n\nSimulators\n--------------\n.. automodule:: tsgm.simulator\n    :members:\n    :undoc-members:\n\n\nData Processing Utils\n--------------\n.. automodule:: tsgm.utils.data_processing\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Loading and Scaling Time Series Data for TSGM\nDESCRIPTION: This function generates a sine dataset and scales the features to the range [0, 1] using TSGM's utility functions.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef get_data():\n    data = tsgm.utils.gen_sine_dataset(10000, 24, 5)\n    scaler = tsgm.utils.TSFeatureWiseScaler()        \n    scaled_data = scaler.fit_transform(data)\n    return scaled_data\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies with Version Requirements\nDESCRIPTION: A requirements.txt file that specifies the necessary Python packages and their version constraints. It includes TensorFlow Privacy, TensorFlow, TensorFlow Probability, and various data science libraries needed for the project.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/requirements/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntensorflow_privacy==0.8.5\ntensorflow==2.9.1\ntensorflow_probability==0.17.0\nscipy>=1.7.3\nantropy==0.1.6\nnumpy>=1.21.6\nstatsmodels\ndtaidistance==2.3.10\nnetworkx\noptuna\nprettytable\nseaborn\nscikit-learn\nyfinance==0.2.28\ntqdm\n```\n\n----------------------------------------\n\nTITLE: Generating Toy Dataset for Time Series Augmentation in Python\nDESCRIPTION: This snippet demonstrates how to generate a synthetic sine wave dataset using the TSGM library for subsequent augmentation examples.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/augmentations.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\nX = tsgm.utils.gen_sine_dataset(100, 64, 2, max_value=20)\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM using pip\nDESCRIPTION: This snippet shows how to install the TSGM package using pip. It's a simple one-line command to install the framework.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install tsgm\n```\n\n----------------------------------------\n\nTITLE: Selecting GAN Architecture for Conditional Time Series Generation in Python\nDESCRIPTION: This snippet selects a pre-defined architecture for the conditional GAN from the 'tsgm' module. It sets up the discriminator and generator models based on the specified parameters.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\narchitecture = tsgm.models.architectures.zoo[\"cgan_base_c4_l1\"](\n    seq_len=seq_len, feat_dim=feature_dim,\n    latent_dim=latent_dim, output_dim=output_dim)\ndiscriminator, generator = architecture.discriminator, architecture.generator\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM using pip\nDESCRIPTION: This command installs the TSGM package using pip, the Python package installer.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install tsgm\n```\n\n----------------------------------------\n\nTITLE: Examining Physionet 2012 Training Data\nDESCRIPTION: Displays the first three rows of the Physionet 2012 training data to inspect its structure. The data contains various measurements from ICU stays with recordid as the unique identifier.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_X.head(3)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Time Series Dataset for Conditional GAN in Python\nDESCRIPTION: This code uses a custom utility function to create a line plot visualization of the time series dataset, which is useful for exploring the characteristics of the data before training the GAN.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntsgm.utils.visualize_ts_lineplot(X_train, y_i)\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM in Development Mode\nDESCRIPTION: Command to install TSGM in development mode using setup.py, which allows changes to the codebase to be immediately reflected without reinstallation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py develop\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for cGAN Time Series Generation\nDESCRIPTION: This snippet imports necessary libraries for data manipulation, deep learning, and visualization. It includes TensorFlow, Keras, NumPy, and a custom TSGM library for time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Using Multiple GPUs or TPU.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nfrom tensorflow import keras\n\nimport tensorflow as tf\n\nimport tsgm\n\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Temporal Conditional GANs\nDESCRIPTION: Imports necessary TensorFlow, Keras, NumPy, and visualization libraries required for implementing temporal conditional GANs.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tensorflow as tf\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Time Series Generation with GANs\nDESCRIPTION: Sets up the environment with necessary imports for TensorFlow, TensorFlow Privacy, and the custom TSGM library for time series generation using GANs.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/RCGAN.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport functools\nimport numpy as np\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tensorflow as tf\nimport tensorflow_privacy as tf_privacy\n\nimport tsgm\n\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Conditional GAN Time Series Generation in Python\nDESCRIPTION: This snippet imports necessary libraries for the project, including numpy for numerical operations, matplotlib for plotting, TensorFlow and Keras for deep learning, and a custom 'tsgm' module for time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/cGAN.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tensorflow as tf\n\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TSGM Model Selection\nDESCRIPTION: This snippet imports necessary libraries including numpy, sklearn, tensorflow, and custom TSGM modules for the model selection process.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport functools\nimport sklearn\nimport copy\nimport sklearn.model_selection\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment with TensorFlow and Data Visualization Libraries\nDESCRIPTION: Imports necessary libraries including TensorFlow/Keras for deep learning model implementation, matplotlib and seaborn for visualization, and enables Jupyter notebook extensions for auto-reloading modules.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport warnings\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')\n%pylab inline\n```\n\n----------------------------------------\n\nTITLE: Examining Physionet 2012 Target Labels\nDESCRIPTION: Displays the first three rows of the target labels for the Physionet 2012 dataset, showing the mortality outcomes for the corresponding ICU stays.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntrain_y.head(3)\n```\n\n----------------------------------------\n\nTITLE: Initializing Environment and Importing Libraries for TSGM in Python\nDESCRIPTION: Sets up the Jupyter notebook environment, imports necessary libraries including TSGM, and configures matplotlib for inline plotting. Also generates real and synthetic datasets for demonstration.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Metrics Tutorial.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport os\n\nimport warnings\nimport functools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n```\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n```\n\nLANGUAGE: python\nCODE:\n```\neps = 1e-5\n\nXr, yr = tsgm.utils.gen_sine_vs_const_dataset(10, 100, 20, max_value=2, const=1)\nXs, ys = Xr + eps, yr\n\nd_real = tsgm.dataset.Dataset(Xr, yr)\nd_syn = tsgm.dataset.Dataset(Xs, ys)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for VAE-based Time Series Generation in Python\nDESCRIPTION: This snippet imports necessary libraries for VAE-based time series generation, including numpy, sklearn, tensorflow, and a custom 'tsgm' module.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/VAE.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport sklearn\nimport copy\nimport sklearn.model_selection\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for TSGM Dataset Analysis\nDESCRIPTION: Initial setup for working with TSGM datasets, including imports for TSGM, pandas for data manipulation, and visualization libraries matplotlib and seaborn.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Datasets.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport tsgm\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for TimeGAN in Python\nDESCRIPTION: This snippet imports necessary libraries including numpy, sklearn, tensorflow, and a custom module 'tsgm' for time series generation.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/TimeGAN.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport sklearn\nimport copy\nimport sklearn.model_selection\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Importing TSGM Library\nDESCRIPTION: Imports the Time Series Generative Models (TSGM) library which provides implementations for temporal conditional GANs.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/GANs/Temporal cGAN.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Importing TSGM Library\nDESCRIPTION: Imports the Time Series Generative Models (tsgm) library which provides implementations of various generative models specifically designed for time series data.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tsgm\n```\n\n----------------------------------------\n\nTITLE: Installing and Testing TSGM Framework in Python\nDESCRIPTION: Instructions for cloning the TSGM repository, installing it in editable mode, running tests, and checking static typing. This is intended for contributors to the project.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone github.com/AlexanderVNikitin/tsgm\ncd tsgm\npip install -e .\n```\n\nLANGUAGE: bash\nCODE:\n```\npython -m pytest\n```\n\nLANGUAGE: bash\nCODE:\n```\nmypy\n```\n\n----------------------------------------\n\nTITLE: Running TSGM Code Linters\nDESCRIPTION: Command to run flake8 linter on the TSGM source code to ensure code quality and adherence to style guidelines.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nflake8 tsgm/\n```\n\n----------------------------------------\n\nTITLE: Building TSGM Documentation\nDESCRIPTION: Commands to build the HTML documentation for TSGM. This requires first changing to the docs directory and then using the make utility.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/CONTRIBUTING.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake html\n```\n\n----------------------------------------\n\nTITLE: Running TSGM Tests with Pytest\nDESCRIPTION: Example command to run a specific test in the TSGM project using pytest. This shows how to run a single test module or test function.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_cgan.py::test_temporal_cgan\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM Development Dependencies\nDESCRIPTION: Commands to install all required dependencies for developing TSGM. This installs main requirements, test requirements, and documentation requirements.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements/requirements.txt\npip install -r requirements/tests_requirements.txt\npip install -r requirements/docs_requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Citing TSGM in Academic Research\nDESCRIPTION: BibTeX citation for the TSGM framework paper, to be used when referencing this work in academic publications.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n@article{\n  nikitin2023tsgm,\n  title={TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series},\n  author={Nikitin, Alexander and Iannucci, Letizia and Kaski, Samuel},\n  journal={arXiv preprint arXiv:2305.11567},\n  year={2023}\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Decoder Model Summary\nDESCRIPTION: Displays a summary of the decoder model architecture showing layers, shapes, and parameters.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndecoder.summary()\n```\n\n----------------------------------------\n\nTITLE: TSGM Citation in LaTeX\nDESCRIPTION: This code block provides the BibTeX citation for the TSGM framework paper. It's intended for users who want to cite TSGM in their academic work.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/introduction.rst#2025-04-23_snippet_5\n\nLANGUAGE: latex\nCODE:\n```\n@article{nikitin2023tsgm,\n  title={TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series},\n  author={Nikitin, Alexander and Iannucci, Letizia and Kaski, Samuel},\n  journal={arXiv preprint arXiv:2305.11567},\n  year={2023}\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx toctree for Metrics Tutorial Documentation\nDESCRIPTION: This restructuredtext snippet configures a Sphinx toctree directive for the Metrics tutorial documentation. It sets a maximum depth of 2 for the table of contents and adds a caption labeled 'Contents:'. The toctree references a tutorial file located at ../../tutorials/Metrics.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/tutorials/metrics.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n   ../../tutorials/Metrics\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Dependencies in requirements.txt\nDESCRIPTION: Specifies Python packages required for documentation generation. The file includes Sphinx with version constraint, Jupyter notebook processing tools, and theme packages for documentation styling.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/requirements/docs_requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n-r requirements.txt\n\nsphinx<7.0.0\nipython\npandoc\nnbsphinx\njupytext\npydata-sphinx-theme\nsphinxcontrib-bibtex\nsphinx-autoapi==3.0.0\nsphinx_rtd_theme\n```\n\n----------------------------------------\n\nTITLE: Installing Optuna for Hyperparameter Optimization\nDESCRIPTION: This code installs the Optuna library using pip and imports it for use in hyperparameter optimization.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/Model Selection.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport sys\n!{sys.executable} -m pip install optuna\nimport optuna\n```\n\n----------------------------------------\n\nTITLE: Citation for TSGM in LaTeX format\nDESCRIPTION: This LaTeX code provides the citation information for the TSGM paper, including authors, title, journal, and year of publication.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/index.rst#2025-04-23_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\n@article{nikitin2023tsgm,\n    title={TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series},\n    author={Nikitin, Alexander and Iannucci, Letizia and Kaski, Samuel},\n    journal={arXiv preprint arXiv:2305.11567},\n    year={2023}\n}\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for t-SNE Visualization\nDESCRIPTION: Generates samples from the cVAE model and prepares data for t-SNE dimensionality reduction to visualize the distribution of original and generated samples in 2D space.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/tutorials/VAEs/cVAE.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nfrom sklearn.manifold import TSNE\n\nlimit = 1000\nX_sub, y_sub = X[:limit], y[:limit]\nX_gen, y_gen = vae.generate(y[:limit])\nX_gen = X_gen.numpy()\n\ntsne = TSNE(n_components=2, learning_rate='auto',\n                  init='random')\n\nX_all = np.concatenate((X_sub, X_gen))\ny_all = np.concatenate((y_sub, y_gen))\nc = np.argmax(np.concatenate((y_sub, y_gen)), axis=1)\ncolors = {0: \"class 0\", 1: \"class 1\"}\nc = [colors[el] for el in c]\npoint_styles = [\"hist\"] * X_sub.shape[0] + [\"gen\"] * X_gen.shape[0]\nX_emb = tsne.fit_transform(np.resize(X_all, (X_all.shape[0], X_all.shape[1] * X_all.shape[2])))\n```\n\n----------------------------------------\n\nTITLE: Python Development Dependencies\nDESCRIPTION: A list of Python packages required for development including code formatting (black, flake8, isort), type checking (mypy), and testing tools (pytest and related packages).\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/requirements/tests_requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nblack\nclick\nflake8\nisort\nmypy\npytest\npytest-cov\npytest-random-order\npytest-mock\n```\n\n----------------------------------------\n\nTITLE: Installing TSGM Package via pip\nDESCRIPTION: Command to install the TSGM package using pip package manager. This is the simplest installation method for most users.\nSOURCE: https://github.com/alexandervnikitin/tsgm/blob/main/docs/guides/installation.rst#2025-04-23_snippet_0\n\nLANGUAGE: none\nCODE:\n```\n$ pip install tsgm\n```"
  }
]