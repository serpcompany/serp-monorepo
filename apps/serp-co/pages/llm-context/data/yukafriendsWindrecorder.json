[
  {
    "owner": "yuka-friends",
    "repo": "windrecorder",
    "content": "TITLE: Generating LLM Prompt Context from Activity Data in Python\nDESCRIPTION: Creates a formatted prompt for an LLM by converting dataframes to CSV strings and structuring them with explanatory text. Includes system prompt and user message setup for analyzing user behavior based on screen time and activity data.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef convert_df_to_csv_str(df:pd.DataFrame):\n    csv_buffer = io.StringIO()\n    df.to_csv(csv_buffer, index=False)\n    csv_string = csv_buffer.getvalue()\n    return csv_string\n\nprompt_day_wintitle_activity = convert_df_to_csv_str(df_day_activity_optimize_display)\nprompt_day_records = convert_df_to_csv_str(day_records_clean_df)\n\nprompt_mount = f\"\"\"\n### Top {MAX_DAY_ACTIVITY_HEAD_TRUNCATION_FOR_LLM} activities by user screen time for the day, sorted by time, highest to lowest (CSV format):\n---Start of screen time ranking csv---\n{prompt_day_wintitle_activity}\n---END of screen time ranking csv---\n\n### Part of the user's specific activities on that day, sorted by time (CSV format) (ocr_content contains a lot of noise, please refer to it with very low weight and only focus on the key content information related to the activity title. Pay more attention to activity and only use ocr_content as an optional supplement.):\n---Start of activities csv---\n{prompt_day_records}\n---END of activities csv---\n\"\"\"\n\n# prompt_mount = f\"\"\"\n# ### Top {MAX_DAY_ACTIVITY_HEAD_TRUNCATION_FOR_LLM} activities by user screen time for the day, sorted by time, highest to lowest (CSV format):\n# ---Start of screen time ranking csv---\n# {prompt_day_wintitle_activity}\n# ---END of screen time ranking csv---\n# \"\"\"\n\nsystem_prompt = f\"\"\"\nYou are a user behavior analysis expert. Please generate a simple summary of the user's daily activities on that day based on the following computer activity records (screen time ranking, specific activity tracks) of the user ({config.user_name}) received on that day, describing what the user did and what content browsed on that day. If necessary, please retain the proper nouns or origin text of the activity content.\n\"\"\"\nprompt_end = \"\"\"\nNow, please summarize the user's daily activities in chronological order based on the above. Keep it concise, clear, simple, and insightful. Please output the results directly without adding additional instructions.\n\"\"\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": prompt_mount + prompt_end}\n]\n```\n\n----------------------------------------\n\nTITLE: Cleaning and Formatting User Activity Data in Python\nDESCRIPTION: Processes raw activity data by converting timestamps, filtering short activities, removing duplicates, and truncating OCR content to meet token limits. The result is a clean dataframe with datetime, activity name, and OCR content fields.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# convert day records datetime format\ndf_day_search_result['videofile_time'] = pd.to_datetime(df_day_search_result['videofile_time'], unit='s').dt.strftime('%Y-%m-%d %H-%M-%S')\n\n# config\nday_records_clean_df = pd.DataFrame(columns=['datetime', 'activity', 'ocr_content'])\nactivity_compare_lst = []\nactivity_always_exclude_lst = [\"explorer.exe\"]\nvaild_day_activity_lst = []\nmax_token_limit = 1000000/2.5\nmax_pre_row_token = int(max_token_limit/len(df_day_search_result))\nactivity_deduplication_trace_depth = 10\nMIN_ACTIVITY_DURATION_SECOND = 30\nMAX_DAY_ACTIVITY_HEAD_TRUNCATION_FOR_LLM = 20\n\n# Only keep long-lasting activities\nfor index, row in df_day_activity_raw.iterrows():\n    if row['Screen Time'] < MIN_ACTIVITY_DURATION_SECOND:\n        continue\n    vaild_day_activity_lst.append(row['Page'])\n\n# filtering day records\nfor index, row in df_day_search_result.iterrows():\n    activity = row['win_title']\n    \n    # 剔除过近的重复项、活动时间过短的项\n    if activity in activity_compare_lst[-activity_deduplication_trace_depth:] or activity in activity_always_exclude_lst or activity not in vaild_day_activity_lst or len(activity.split(\" | \")[0]) == 0:\n        continue\n    activity_compare_lst.append(activity)\n    ocr_text = row['ocr_text']\n    \n    row = {\n        'datetime': row['videofile_time'],\n        'activity': activity.split(\" | \")[0],\n        'ocr_content': row['ocr_text'][:max_pre_row_token],\n    }\n    day_records_clean_df.loc[len(day_records_clean_df )] = row\n\ndf_day_activity_optimize_display = df_day_activity_optimize_display.head(MAX_DAY_ACTIVITY_HEAD_TRUNCATION_FOR_LLM)\n\nday_records_clean_df\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Windrecorder Data Processing in Python\nDESCRIPTION: Sets up the working directory and imports necessary libraries for data processing, including datetime, pandas, and custom Windrecorder modules for database management and window title tracking.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Set workspace to Windrecorder dir\nimport os\nimport io\nos.chdir(\"..\")\nos.chdir(\"..\")\n# ------------------------------------------------------------\n\nimport datetime\nimport pandas as pd\n\nfrom windrecorder.db_manager import db_manager\nfrom windrecorder.oneday import OneDay\nfrom windrecorder.record_wintitle import get_wintitle_stat_in_day\nfrom windrecorder.config import config\nfrom windrecorder import llm\n```\n\n----------------------------------------\n\nTITLE: OpenAI API Configuration Example\nDESCRIPTION: Example configuration values for OpenAI's API endpoint, including base URL, API key format, and model name.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/__assets__/how_to_set_LLM_api_endpoint_en.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nbase url: https://api.openai.com/v1\napi key: sk-AbCdEfGxXXXXXXXXXXXXXXXXX\nmodelname: gpt-4o\n```\n\n----------------------------------------\n\nTITLE: Making LLM Request with Prepared Prompt in Python\nDESCRIPTION: Sends the prepared prompt to an LLM using the custom llm module's request_llm_one_shot function. A commented-out section shows an alternative approach using OpenAI's API client with a local model server.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# from openai import OpenAI\n\n# # Point to the local server\n# client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n\n# completion = client.chat.completions.create(\n#   model=\"PrunaAI/Phi-3-mini-128k-instruct-GGUF-Imatrix-smashed\",\n#   messages=messages,\n#   temperature=0.7,\n# )\n\n# print(completion.choices[0].message)\n\nsuccess, plain_text = llm.request_llm_one_shot(\n    user_content=prompt_mount + prompt_end,\n    system_prompt=system_prompt,\n    temperature=.3,\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Vector Embeddings for Vocabulary Words in Python\nDESCRIPTION: Creates a vector database and embeds each word from the vocabulary list into vector representations. Tracks progress through a counter and prints status updates for each word processed.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# embedding all words into vector\nvdb = img_embed_manager.VectorDatabase(vdb_filename=os.path.join(parent_parent_dir, SUB_DIR, OUTPUT_VDB_FILENAME), db_dir=\"\")\n\ni = 0\nall = len(words_list)\nfor word in words_list:\n    print(f\"{i}/{all}, {word=}\")\n    vector = img_embed_manager.embed_text(model=model_cpu, text_query=word, detach_numpy=False)\n    vdb.add_vector(vector=vector, rowid=i)\n    i += 1\n```\n\n----------------------------------------\n\nTITLE: Retrieving Daily Search Results in Python\nDESCRIPTION: Fetches day data for the selected date using the OneDay class's search_day_data method. The search is performed with an empty content filter to retrieve all records for the day.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf_day_search_result = OneDay().search_day_data(\n                    datetime_select,\n                    search_content=\"\",\n                )\n\ndf_day_search_result\n```\n\n----------------------------------------\n\nTITLE: Initializing Text Embedding Model in Python\nDESCRIPTION: Loads the text embedding model from Windrecorder's img_embed_manager module in CPU mode. This model will be used to generate vector representations of text.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom windrecorder import img_embed_manager\n\nmodel_cpu = img_embed_manager.get_model(mode=\"cpu\")\n```\n\n----------------------------------------\n\nTITLE: Getting Window Title Statistics in Python\nDESCRIPTION: Retrieves window title statistics for the selected date in two formats: raw data and optimized for display. This provides information about applications used and screen time spent on each activity.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf_day_activity_raw, day_time_sum = get_wintitle_stat_in_day(datetime_select, optimize_for_display=False)\ndf_day_activity_optimize_display, _ = get_wintitle_stat_in_day(datetime_select, optimize_for_display=True)\n\ndf_day_activity_optimize_display\n```\n\n----------------------------------------\n\nTITLE: LM Studio Local Configuration Example\nDESCRIPTION: Example configuration for local LM Studio setup, including localhost URL, model name, and API key.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/__assets__/how_to_set_LLM_api_endpoint_en.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nbase url: http://localhost:1234/v1\nmodelname: cognitivecomputations/dolphin-2.9-llama3-8b-gguf\napi key: lm-studio\n```\n\n----------------------------------------\n\nTITLE: Groq API Configuration Example\nDESCRIPTION: Example configuration for Groq's API endpoint, including base URL and model name for their LLaMA model.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/__assets__/how_to_set_LLM_api_endpoint_en.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nbase url: https://api.groq.com/openai/v1\nmodelname: llama-3.1-70b-versatile\n```\n\n----------------------------------------\n\nTITLE: DeepSeek API Configuration Example\nDESCRIPTION: Example configuration for DeepSeek's API endpoint, showing the base URL and model name.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/__assets__/how_to_set_LLM_api_endpoint_en.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nbase url: https://api.deepseek.com/v1\nmodelname: deepseek-chat\n```\n\n----------------------------------------\n\nTITLE: Initializing Paths and Directory Setup in Python\nDESCRIPTION: Sets up file paths and directory structure for the embedding process. Defines input vocabulary and output vector database file paths, and configures the working directory to ensure proper access to the Windrecorder library.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# add vocabulary txt, one line for each word\nVOCABULARY_TXT_FILEPATH = \"synonyms_en.txt\"\nOUTPUT_VDB_FILENAME = \"synonyms_en.index\"\n\n# Set workspace to Windrecorder dir\nimport os\nimport sys\ncurrent_dir = os.getcwd()\nparent_parent_dir = os.path.dirname(os.path.dirname(current_dir))\nsys.path.append(parent_parent_dir)\nos.chdir(\"..\")\nos.chdir(\"..\")\nSUB_DIR = \"extension\\\\i18n_create_synonyms_embedding_asset\"\n```\n\n----------------------------------------\n\nTITLE: Loading Vocabulary Words from Text File in Python\nDESCRIPTION: Reads the vocabulary text file into a list using Windrecorder's file_utils module. Each line from the file becomes an element in the words_list for further processing.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom windrecorder import file_utils\n\nwords_list = file_utils.read_txt_as_list(os.path.join(parent_parent_dir, SUB_DIR, VOCABULARY_TXT_FILEPATH))\n```\n\n----------------------------------------\n\nTITLE: Displaying Optimized Activity Display Dataframe in Python\nDESCRIPTION: Outputs the optimized activity display dataframe which contains the top activities by screen time, formatted for better readability and analysis.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf_day_activity_optimize_display\n```\n\n----------------------------------------\n\nTITLE: Saving Vector Database to File in Python\nDESCRIPTION: Persists the vector database to disk using the save_to_file method. This saves all the generated word embeddings for future use without having to regenerate them.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# save vector database to file\nvdb.save_to_file()\n```\n\n----------------------------------------\n\nTITLE: Testing Vector Embedding Search Functionality in Python\nDESCRIPTION: Tests the created vector database by searching for words semantically similar to \"love\". Embeds the query word and retrieves the top 5 similar words from the database based on vector similarity.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# test querying result\nvector_search = img_embed_manager.embed_text(model=model_cpu, text_query=\"love\", detach_numpy=True)\nprob_res = vdb.search_vector(vector=vector_search, k=5)\nword_res = [words_list[i[0]] for i in prob_res]\nprint(word_res)\n```\n\n----------------------------------------\n\nTITLE: Displaying LLM Response Output in Python\nDESCRIPTION: Prints the result of the LLM analysis, which contains a summary of the user's daily activities based on the processed screen time and activity data.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(plain_text)\n```\n\n----------------------------------------\n\nTITLE: Running OCR Benchmark in Python\nDESCRIPTION: Code to execute OCR benchmark tests and format the results using the windrecorder package. The benchmark compares different OCR engines across multiple languages and prints formatted results including recognition time and accuracy.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/__assets__/third_party_ocr_engine_benchmark_reference.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom windrecorder.ocr_manager import format_print_benchmark, ocr_benchmark\nformat_print_benchmark(ocr_benchmark())\n```\n\n----------------------------------------\n\nTITLE: Setting Target Date for Analysis in Python\nDESCRIPTION: Defines the date for which user activity data will be retrieved and analyzed. The date is set to August 19, 2024, though there's a commented alternative to use the current date.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/LLM_summary_mvp/research.ipynb#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# datetime_select = datetime.datetime.today()\ndatetime_select = datetime.datetime(2024,8,19)\n```\n\n----------------------------------------\n\nTITLE: OCR Engine Integration Points\nDESCRIPTION: Key configuration points for OCR engine integration including engine naming conventions and language support settings. The implementation requires proper registration in config.support_ocr_lst and handling of initialization states in ocr_manager.py.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/how_to_contribute_third_party_ocr_support.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Store OCR engine name\nconfig.ocr_engine = \"engine_name\"\n\n# Store supported languages\nconfig.third_party_engine_ocr_lang = [\"lang1\", \"lang2\"]\n```\n\n----------------------------------------\n\nTITLE: OCR Method Structure\nDESCRIPTION: Template for implementing OCR functionality in ocr_manager.py. Shows required method signature and initialization parameter.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/how_to_contribute_third_party_ocr_support.md#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef ocr_method(image_path, force_initialize=False):\n    # OCR implementation\n    return recognition_result\n```\n\n----------------------------------------\n\nTITLE: Starting ChineseOCR Lite Web Service\nDESCRIPTION: Instructions to start the ChineseOCR Lite web service. First navigate to the chineseocr_lite directory and then run the Python backend script.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/ocr_lib/chineseocr_lite_onnx/README.md#2025-04-18_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\ncd chineseocr_lite## 进入chineseocr目录\npython backend/main.py\n```\n\n----------------------------------------\n\nTITLE: Optional Text Preprocessing Utility in Python\nDESCRIPTION: Provides a utility function to preprocess dictionary files by extracting the first word of each line and filtering out entries with fewer than 2 characters. Includes an example of processing a TOEFL vocabulary file into the synonyms format.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/extension/i18n_create_synonyms_embedding_asset/create_synonyms_embedding_asset.ipynb#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# [optional] clean txt\n# Dictionaries can be preprocessed as needed. Here we only take the words before the first space of each line, and then remove all words with less than 2 words.\n\ndef process_file(input_file, output_file):\n    with open(input_file, 'r', encoding='utf8') as f:\n        lines = f.readlines()\n\n    processed_lines = []\n\n    for line in lines:\n        if ' ' in line:\n            line = line.split(' ')[0]\n\n        line = line.strip()\n\n        if len(line) >= 2:\n            processed_lines.append(line + '\\n')\n\n    with open(output_file, 'w', encoding='utf8') as f:\n        f.writelines(processed_lines)\n\n\nprocess_file(os.path.join(parent_parent_dir, SUB_DIR, \"TOEFL.txt\"), os.path.join(parent_parent_dir, SUB_DIR, \"synonyms_en.txt\"))\n```\n\n----------------------------------------\n\nTITLE: Installing Windrecorder via Git Clone\nDESCRIPTION: Command to clone the Windrecorder repository from GitHub to a local directory. This is part of the installation process after installing the prerequisites.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/README.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/yuka-friends/Windrecorder\n```\n\n----------------------------------------\n\nTITLE: Displaying Version and Update Information in Markdown\nDESCRIPTION: This snippet shows how to display the current version and update information using Markdown syntax. It uses placeholders for dynamic content that would be replaced with actual values.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/windrecorder/config_src/about_en.md#2025-04-18_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n**{version}** - {update_info}\n```\n\n----------------------------------------\n\nTITLE: Embedding Product Hunt Badge in Markdown\nDESCRIPTION: This snippet demonstrates how to embed a Product Hunt badge in Markdown format, linking to the Windrecorder product page.\nSOURCE: https://github.com/yuka-friends/windrecorder/blob/main/README.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<a href=\"https://www.producthunt.com/posts/windrecorder?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-windrecorder\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=441411&theme=neutral\" alt=\"Windrecorder - search&#0032;&#0038;&#0032;rewind&#0032;everything&#0032;happened&#0032;on&#0032;your&#0032;screen | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n```"
  }
]