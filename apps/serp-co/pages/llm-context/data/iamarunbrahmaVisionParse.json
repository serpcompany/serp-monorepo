[
  {
    "owner": "iamarunbrahma",
    "repo": "vision-parse",
    "content": "TITLE: Setting Up VisionParser and Converting PDF with Ollama\nDESCRIPTION: Initializes a VisionParser instance with llama3.2-vision model and processes a PDF file, converting it to markdown format. The configuration includes temperature, top_p parameters, context settings, and Ollama-specific configurations for parallel processing.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/ollama_demo.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\n\nparser = VisionParser(\n    model_name=\"llama3.2-vision:11b\",\n    temperature=0.7,\n    top_p=0.4,\n    num_ctx=4096,\n    num_predict=4096,\n    ollama_config={\n        \"OLLAMA_NUM_PARALLEL\": \"10\",\n    },\n    image_mode=\"base64\",\n    detailed_extraction=True,\n    enable_concurrency=True,\n)\n\npdf_path = \"../tests/Texas-Holdem-Rules.pdf\"\nmarkdown_pages = parser.convert_pdf(pdf_path)\n\nfor i, page_content in enumerate(markdown_pages):\n    print(f\"\\n--- Page {i+1} ---\\n{page_content}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Vision Parser with OpenAI\nDESCRIPTION: Initializes and configures a VisionParser instance with specific OpenAI parameters and processes a PDF file. The parser is configured with GPT-4 model, custom temperature, token limits, and extraction settings.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/openai_demo.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\nimport os\n\n# Initialize parser\nparser = VisionParser(\n    model_name=\"gpt-4o\",\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n    temperature=0.9,\n    top_p=0.4,\n    max_tokens=4096,\n    frequency_penalty=0.3,\n    image_mode=None,\n    detailed_extraction=True,\n    enable_concurrency=True,\n)\n\npdf_path = \"../tests/Texas-Holdem-Rules.pdf\"\nmarkdown_pages = parser.convert_pdf(pdf_path)\n\n# Print the markdown pages\nfor i, page_content in enumerate(markdown_pages):\n    print(f\"\\n--- Page {i+1} ---\\n{page_content}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing VisionParser and Converting PDF to Markdown with Google Gemini in Python\nDESCRIPTION: This code snippet demonstrates how to initialize a VisionParser object with Google Gemini configuration and use it to convert a PDF file to markdown pages. It sets various parameters for the parser and prints the resulting markdown content for each page.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/gemini_demo.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\nimport os\n\n# Initialize parser\nparser = VisionParser(\n    model_name=\"gemini-1.5-flash\",\n    api_key=os.getenv(\"GEMINI_API_KEY\"),\n    temperature=0.9,\n    top_p=0.4,\n    max_output_tokens=2048,\n    image_mode=\"url\",\n    detailed_extraction=True,\n)\n\npdf_path = \"../tests/Texas-Holdem-Rules.pdf\"\nmarkdown_pages = parser.convert_pdf(pdf_path)\n\n# Print the markdown pages\nfor i, page_content in enumerate(markdown_pages):\n    print(f\"\\n--- Page {i+1} ---\\n{page_content}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing VisionParser and Converting PDF to Markdown using DeepSeek in Python\nDESCRIPTION: This code snippet demonstrates how to initialize a VisionParser with DeepSeek configuration and use it to convert a PDF file to markdown format. It sets various parameters for the parser and then converts the PDF, printing each page's content.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/deepseek_demo.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\nimport os\n\n# Initialize parser\nparser = VisionParser(\n    model_name=\"deepseek-chat\",\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    temperature=0.9,\n    top_p=0.4,\n    image_mode=None,\n    detailed_extraction=True,\n    enable_concurrency=True,\n)\n\npdf_path = \"../tests/Texas-Holdem-Rules.pdf\"\nmarkdown_pages = parser.convert_pdf(pdf_path)\n\n# Print the markdown pages\nfor i, page_content in enumerate(markdown_pages):\n    print(f\"\\n--- Page {i+1} ---\\n{page_content}\")\n```\n\n----------------------------------------\n\nTITLE: Using Vision Parse with API-based Models\nDESCRIPTION: Examples of using Vision Parse with various API-based models including OpenAI, Azure OpenAI, Google Gemini, and DeepSeek. Shows different initialization configurations for each provider.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\n\n\n# Initialize parser with OpenAI model\nparser = VisionParser(\n    model_name=\"gpt-4o\",\n    api_key=\"your-openai-api-key\", # Get the OpenAI API key from https://platform.openai.com/api-keys\n    temperature=0.7,\n    top_p=0.4,\n    image_mode=\"url\",\n    detailed_extraction=False, # Set to True for more detailed extraction\n    enable_concurrency=True,\n)\n\n# Initialize parser with Azure OpenAI model\nparser = VisionParser(\n    model_name=\"gpt-4o\",\n    image_mode=\"url\",\n    detailed_extraction=False, # Set to True for more detailed extraction\n    enable_concurrency=True,\n    openai_config={\n        \"AZURE_ENDPOINT_URL\": \"https://****.openai.azure.com/\", # replace with your azure endpoint url\n        \"AZURE_DEPLOYMENT_NAME\": \"*******\", # replace with azure deployment name, if needed\n        \"AZURE_OPENAI_API_KEY\": \"***********\", # replace with your azure openai api key\n        \"AZURE_OPENAI_API_VERSION\": \"2024-08-01-preview\", # replace with latest azure openai api version\n    },\n)\n\n\n# Initialize parser with Google Gemini model\nparser = VisionParser(\n    model_name=\"gemini-1.5-flash\",\n    api_key=\"your-gemini-api-key\", # Get the Gemini API key from https://aistudio.google.com/app/apikey\n    temperature=0.7,\n    top_p=0.4,\n    image_mode=\"url\",\n    detailed_extraction=False, # Set to True for more detailed extraction\n    enable_concurrency=True,\n)\n\n# Initialize parser with DeepSeek model\nparser = VisionParser(\n    model_name=\"deepseek-chat\",\n    api_key=\"your-deepseek-api-key\", # Get the DeepSeek API key from https://platform.deepseek.com/api_keys\n    temperature=0.7,\n    top_p=0.4,\n    image_mode=\"url\",\n    detailed_extraction=False, # Set to True for more detailed extraction\n    enable_concurrency=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Vision Parse with Local Models\nDESCRIPTION: Basic example demonstrating how to initialize the VisionParser with a local Ollama-hosted model and convert a PDF to markdown. Shows initialization of parser and processing of PDF document.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\n\n# Initialize parser\nparser = VisionParser(\n    model_name=\"llama3.2-vision:11b\", # For local models, you don't need to provide the api key\n    temperature=0.4,\n    top_p=0.5,\n    image_mode=\"url\", # Image mode can be \"url\", \"base64\" or None\n    detailed_extraction=False, # Set to True for more detailed extraction\n    enable_concurrency=False, # Set to True for parallel processing\n)\n\n# Convert PDF to markdown\npdf_path = \"input_document.pdf\" # local path to your pdf file\nmarkdown_pages = parser.convert_pdf(pdf_path)\n\n# Process results\nfor i, page_content in enumerate(markdown_pages):\n    print(f\"\\n--- Page {i+1} ---\\n{page_content}\")\n```\n\n----------------------------------------\n\nTITLE: Customizing Ollama Configuration for Better Performance\nDESCRIPTION: Example showing how to customize Ollama configuration for improved performance. Demonstrates setting custom prompt, increasing context size, and configuring Ollama-specific parameters.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom vision_parse import VisionParser\n\ncustom_prompt = \"\"\"\nStrictly preserve markdown formatting during text extraction from scanned document.\n\"\"\"\n\n# Initialize parser with Ollama configuration\nparser = VisionParser(\n    model_name=\"llama3.2-vision:11b\",\n    temperature=0.7,\n    top_p=0.6,\n    num_ctx=4096,\n    image_mode=\"base64\",\n    custom_prompt=custom_prompt,\n    detailed_extraction=True,\n    ollama_config={\n        \"OLLAMA_NUM_PARALLEL\": 8,\n        \"OLLAMA_REQUEST_TIMEOUT\": 240,\n    },\n    enable_concurrency=True,\n)\n\n# Convert PDF to markdown\npdf_path = \"input_document.pdf\" # local path to your pdf file\nmarkdown_pages = parser.convert_pdf(pdf_path)\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Parse with pip\nDESCRIPTION: Commands for installing the Vision Parse package using pip. Shows installation of core package, additional dependencies, and installation from source.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install vision-parse\n```\n\nLANGUAGE: bash\nCODE:\n```\n# To install all the additional dependencies\npip install 'vision-parse[all]'\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install 'git+https://github.com/iamarunbrahma/vision-parse.git#egg=vision-parse[all]'\n```\n\n----------------------------------------\n\nTITLE: Building and Running Docker Container for Vision Parse\nDESCRIPTION: Commands for building, starting, and verifying the Docker container for Vision Parse application.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Build the image\ndocker compose build\n\n# Start the container in detached mode\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Running Benchmark Tests for Vision Parse\nDESCRIPTION: Commands for running benchmark tests to compare Vision Parse's performance with other document parsing tools. Shows how to install requirements and run the benchmark script.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install --no-cache-dir -r benchmarks/requirements.txt\n```\n\nLANGUAGE: bash\nCODE:\n```\n# Change `pdf_path` to your pdf file path and `benchmark_results_path` to your desired output path\npython benchmarks/scoring.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Nvidia GPU Support in Docker Compose\nDESCRIPTION: YAML configuration snippet for enabling Nvidia GPU support in the docker-compose.yml file.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndeploy:\n  resources:\n    reservations:\n      devices:\n        - driver: nvidia\n          count: 1\n          capabilities: [gpu]\n```\n\n----------------------------------------\n\nTITLE: Pulling Models and Starting Ollama Server\nDESCRIPTION: Commands to pull the llama3.2-vision model and start the Ollama server.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/ollama_setup.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nollama pull llama3.2-vision:11b\nollama serve\n```\n\n----------------------------------------\n\nTITLE: Installing Docker and GPU Support on Linux\nDESCRIPTION: Commands for installing Docker Engine, Docker Compose, and Nvidia container toolkit for GPU support on Linux systems.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Install Docker Engine\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n\n# Install Docker Compose\nsudo apt-get install docker-compose\n\n# For GPU Support (Optional)\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n\ncurl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama on Linux\nDESCRIPTION: Command for installing Ollama on Linux systems using curl.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/ollama_setup.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama on MacOS\nDESCRIPTION: Command for installing Ollama on MacOS using Homebrew.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/ollama_setup.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbrew install ollama\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Vision Parse\nDESCRIPTION: Commands for exporting required environment variables including model selection and API keys for OpenAI and Gemini.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Required: Choose one of the following models\nexport MODEL_NAME=llama3.2-vision:11b  # select the model name from the list of supported models\n\n# Optional: API keys (required only for specific models)\nexport OPENAI_API_KEY=your_openai_api_key\nexport GEMINI_API_KEY=your_gemini_api_key\n```\n\n----------------------------------------\n\nTITLE: Running Vision Parse Application in Docker\nDESCRIPTION: Command to execute the Vision Parse Python script inside the running Docker container.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Execute the python script inside the container\ndocker compose exec vision-parse python docs/examples/gradio_app.py\n```\n\n----------------------------------------\n\nTITLE: Markdown Benchmark Results Table\nDESCRIPTION: Table comparing accuracy scores between Vision Parse (0.88) and MarkItDown (0.52) parsers.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/benchmarks/benchmark_results.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Parser | Accuracy |\n|--------|----------|\n| Vision Parse | 0.88 |\n| MarkItDown | 0.52 |\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Parse Package\nDESCRIPTION: Installs the vision-parse package with OpenAI dependencies using pip.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/openai_demo.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install 'vision-parse[openai]' -Uqq # install the vision-parse package with openai\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Parse Package\nDESCRIPTION: Installs the vision-parse package using pip with quiet mode enabled and forces an update if an older version exists.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/ollama_demo.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install vision-parse -Uqq # install the vision-parse package with ollama\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Parse with Gemini Support in Python\nDESCRIPTION: This code snippet installs the vision-parse package with Gemini support using pip. The -Uqq flags ensure a quiet upgrade installation.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/gemini_demo.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install 'vision-parse[gemini]' -Uqq # install the vision-parse package with gemini\n```\n\n----------------------------------------\n\nTITLE: Installing Vision Parse Package with OpenAI Support in Python\nDESCRIPTION: This code snippet installs the vision-parse package with OpenAI support using pip. It uses the -Uqq flags for a quiet upgrade installation.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/examples/deepseek_demo.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install 'vision-parse[openai]' -Uqq # install the vision-parse package with openai\n```\n\n----------------------------------------\n\nTITLE: Running Quality Checks\nDESCRIPTION: Commands to run linting, formatting, and tests before submitting changes.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake lint    # Run code linting\nmake format  # Format code\nmake test    # Run test suite\n```\n\n----------------------------------------\n\nTITLE: Vision Parse Detailed Results\nDESCRIPTION: List showing detailed benchmark results for Vision Parse including number of runs and individual accuracy scores.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/benchmarks/benchmark_results.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Number of runs: 3\n- Individual accuracy scores: 0.90, 0.90, 0.84\n```\n\n----------------------------------------\n\nTITLE: Verifying Ollama Server Status\nDESCRIPTION: Command to verify that the Ollama server is running correctly by checking its API version.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/ollama_setup.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://localhost:11434/api/version\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker Container Status\nDESCRIPTION: Command to check if the Docker container is running correctly.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker ps\n```\n\n----------------------------------------\n\nTITLE: Viewing Docker Container Logs\nDESCRIPTION: Command to check container logs for troubleshooting Vision Parse errors.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose logs vision-parse\n```\n\n----------------------------------------\n\nTITLE: MarkItDown Detailed Results\nDESCRIPTION: List showing detailed benchmark results for MarkItDown including number of runs and individual accuracy scores.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/benchmarks/benchmark_results.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- Number of runs: 3\n- Individual accuracy scores: 0.52, 0.52, 0.52\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Vision-Parse\nDESCRIPTION: This snippet lists the required Python packages for the Vision-Parse project. It includes packages for markdown processing, natural language processing, string similarity comparison, and the main project package.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/benchmarks/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmarkitdown\nnltk\npython-Levenshtein\nvision-parse\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with uv\nDESCRIPTION: Command to install project dependencies using uv and activate the virtual environment.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuv sync --all-extras && source .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting Ollama Port Conflicts\nDESCRIPTION: Command to check if port 11434 is already in use, which might cause connection issues with Ollama-based models.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsudo lsof -i :11434\n```\n\n----------------------------------------\n\nTITLE: Managing Docker Containers for Vision Parse\nDESCRIPTION: Commands for stopping and removing Docker containers and networks for Vision Parse.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/docs/docker_setup.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# Stop the container and preserve data\ndocker compose stop\n\n# Stop and remove containers, networks\ndocker compose down\n```\n\n----------------------------------------\n\nTITLE: Cloning the Vision Parse Repository\nDESCRIPTION: Commands to fork and clone the Vision Parse repository to start contributing.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/YOUR_USERNAME/vision-parse.git\ncd vision-parse\n```\n\n----------------------------------------\n\nTITLE: Committing and Pushing Changes\nDESCRIPTION: Git commands to stage, commit, and push changes to the remote repository.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"Description of your changes\"\ngit push origin feature/your-feature-name\n```\n\n----------------------------------------\n\nTITLE: Creating Feature or Bugfix Branches\nDESCRIPTION: Git commands to create new branches for features or bug fixes.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# If you are fixing a bug\ngit checkout -b bugfix/your-bug-name\n\n# If you are adding a new feature\ngit checkout -b feature/your-feature-name\n```\n\n----------------------------------------\n\nTITLE: Installing uv Dependency Manager on Mac/Linux\nDESCRIPTION: Command to install the uv dependency manager on Mac or Linux systems.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Installing uv Dependency Manager on Windows\nDESCRIPTION: PowerShell command to install the uv dependency manager on Windows systems.\nSOURCE: https://github.com/iamarunbrahma/vision-parse/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```"
  }
]