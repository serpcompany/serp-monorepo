[
  {
    "owner": "mediar-ai",
    "repo": "screenpipe",
    "content": "TITLE: Basic Screenpipe Desktop Automation Example\nDESCRIPTION: Demonstrates basic desktop automation including opening applications, navigating websites, interacting with search fields, and handling buttons using the Operator API.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { pipe } from '@screenpipe/browser'\n\nasync function simpleAutomation() {\n  try {\n    // open an application\n    await pipe.operator.openApplication(\"Chrome\")\n    \n    // navigate to a website\n    await pipe.operator.openUrl(\"https://github.com/mediar-ai/screenpipe\")\n    \n    // find search fields by role\n    const searchFields = await pipe.operator\n      .getByRole(\"searchfield\", {\n        app: \"Chrome\",\n        activateApp: true\n      })\n      .all(3)\n    \n    if (searchFields.length > 0) {\n      // fill the search field\n      await pipe.operator\n        .getById(searchFields[0].id, { app: \"Chrome\" })\n        .fill(\"automation\")\n      \n      // click a button\n      const buttons = await pipe.operator\n        .getByRole(\"button\", { app: \"Chrome\" })\n        .all(5)\n      \n      if (buttons.length > 0) {\n        await pipe.operator\n          .getById(buttons[0].id, { app: \"Chrome\" })\n          .click()\n      }\n      \n      // scroll page content\n      await pipe.operator\n        .getById(searchFields[0].id, { app: \"Chrome\" })\n        .scroll(\"down\", 300)\n    }\n  } catch (error) {\n    console.error(\"automation failed:\", error)\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing AI Automation Agent with TypeScript and React\nDESCRIPTION: A React component that creates an AI-powered automation agent using OpenAI's GPT-4 and Screenpipe's Operator API. The component enables natural language processing to perform desktop actions like opening applications, navigating URLs, clicking elements, and filling forms.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useState } from \"react\"\nimport { streamText, convertToCoreMessages } from \"ai\"\nimport { createOpenAI } from \"@ai-sdk/openai\"\nimport { pipe } from \"@screenpipe/browser\"\nimport { z } from \"zod\"\n\nexport function AIAutomationAgent() {\n  const [input, setInput] = useState(\"\")\n  const [output, setOutput] = useState(\"\")\n  \n  const handleSubmit = async (e) => {\n    e.preventDefault()\n    setOutput(\"\")\n    \n    const model = createOpenAI({\n      apiKey: process.env.OPENAI_API_KEY\n    })(\"gpt-4o\")\n    \n    const result = streamText({\n      model,\n      messages: convertToCoreMessages([{\n        role: \"user\",\n        content: input\n      }]),\n      system: \"you are a desktop automation assistant. help users by performing actions on their computer.\",\n      tools: {\n        openApplication: {\n          description: \"open an application\",\n          parameters: z.object({\n            appName: z.string().describe(\"the name of the application to open\")\n          }),\n          execute: async ({ appName }) => {\n            const success = await pipe.operator.openApplication(appName)\n            return success\n              ? `opened ${appName} successfully`\n              : `failed to open ${appName}`\n          }\n        },\n        \n        openUrl: {\n          description: \"open a url in a browser\",\n          parameters: z.object({\n            url: z.string().describe(\"the url to open\"),\n            browser: z.string().optional().describe(\"the browser to use\")\n          }),\n          execute: async ({ url, browser }) => {\n            const success = await pipe.operator.openUrl(url, browser)\n            return success\n              ? `opened ${url} in ${browser || \"default browser\"}`\n              : `failed to open ${url}`\n          }\n        },\n        \n        findAndClick: {\n          description: \"find an element by role and click it\",\n          parameters: z.object({\n            app: z.string().describe(\"the application name\"),\n            role: z.string().describe(\"the accessibility role of the element\")\n          }),\n          execute: async ({ app, role }) => {\n            try {\n              const elements = await pipe.operator\n                .getByRole(role, { app, activateApp: true })\n                .all(5)\n                \n              if (elements.length > 0) {\n                await pipe.operator\n                  .getById(elements[0].id, { app })\n                  .click()\n                return `clicked ${role} element in ${app}`\n              }\n              return `no ${role} elements found in ${app}`\n            } catch (error) {\n              return `error: ${error.message}`\n            }\n          }\n        },\n        \n        fillText: {\n          description: \"fill text in a form field\",\n          parameters: z.object({\n            app: z.string().describe(\"the application name\"),\n            role: z.string().describe(\"the role of the element to fill\"),\n            text: z.string().describe(\"the text to enter\")\n          }),\n          execute: async ({ app, role, text }) => {\n            try {\n              const elements = await pipe.operator\n                .getByRole(role, { app, activateApp: true })\n                .all(5)\n                \n              if (elements.length > 0) {\n                await pipe.operator\n                  .getById(elements[0].id, { app })\n                  .fill(text)\n                return `filled text in ${role} element in ${app}`\n              }\n              return `no ${role} elements found in ${app}`\n            } catch (error) {\n              return `error: ${error.message}`\n            }\n          }\n        }\n      },\n      toolCallStreaming: true,\n      maxSteps: 5\n    })\n    \n    for await (const chunk of result.textStream) {\n      setOutput(prev => prev + chunk)\n    }\n  }\n  \n  return (\n    <div>\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          placeholder=\"e.g., 'open chrome and go to github'\"\n        />\n        <button type=\"submit\">run</button>\n      </form>\n      <div>{output}</div>\n    </div>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Interacting with Calculator using Terminator SDK\nDESCRIPTION: This function demonstrates how to interact with the Windows Calculator application using the Terminator SDK. It performs a simple calculation (7 + 8) and retrieves the result.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync function interactWithCalc() {\n  try {\n    console.log('opening calculator...');\n    await client.openApplication('calc');\n    await sleep(1500); // give calc time to open\n\n    // locate buttons by name (windows 11 calculator)\n    const seven = client.locator('name:Calc').locator('name:Seven');\n    const plus = client.locator('name:Calc').locator('name:Plus');\n    const eight = client.locator('name:Calc').locator('name:Eight');\n    const equals = client.locator('name:Calc').locator('name:Equals');\n    const display = client.locator('name:Calc').locator('name:CalculatorResults'); // find result display\n\n    console.log('clicking 7...');\n    await seven.click();\n    await sleep(200);\n\n    console.log('clicking +...');\n    await plus.click();\n    await sleep(200);\n\n    console.log('clicking 8...');\n    await eight.click();\n    await sleep(200);\n\n    console.log('clicking =...');\n    await equals.click();\n    await sleep(500);\n\n    // get the result\n    const result = await display.getText();\n    console.log(`calculation result: ${result.text}`); // should output something like \"display is 15\"\n\n  } catch (error) {\n    console.error('error interacting with calculator:', error);\n  }\n}\n\ninteractWithCalc();\n```\n\n----------------------------------------\n\nTITLE: Using Expectations with Python SDK\nDESCRIPTION: Function showcasing the use of expect_* methods to wait for specific conditions. It demonstrates waiting for element visibility, enabled state, and text matching in Notepad.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef use_expectations():\n    try:\n        print('opening notepad...')\n        client.open_application('notepad')\n\n        editor_locator = client.locator('window:Notepad').locator('role:RichEdit')\n\n        # wait for the editor element to be visible (default timeout)\n        print('waiting for editor to be visible...')\n        editor_element: ElementResponse = editor_locator.expect_visible()\n        print(f'editor is visible! id: {editor_element.id}')\n\n        # wait for it to be enabled (with a 5-second timeout)\n        print('waiting for editor to be enabled...')\n        editor_locator.expect_enabled(timeout=5000)\n        print('editor is enabled!')\n\n        editor_locator.type_text('initial text.')\n        sleep(1000)\n\n        # wait for the text to exactly match 'initial text.'\n        print('waiting for text to match...')\n        editor_locator.expect_text_equals('initial text.', timeout=3000)\n        print('text matched!')\n\n        # this would likely fail and raise ApiError after the timeout\n        # print('waiting for incorrect text (will timeout)...')\n        # editor_locator.expect_text_equals('wrong text', timeout=2000)\n\n    except ApiError as e:\n        print(f'expectation error: {e}')\n    except Exception as e:\n        print(f'an unexpected error occurred: {e}')\n\n# use_expectations()\n```\n\n----------------------------------------\n\nTITLE: Streaming Audio Transcriptions to LLMs for Real-time Analysis in TypeScript\nDESCRIPTION: A function that processes audio transcriptions in real-time and analyzes them using OpenAI's models. It streams transcription chunks through Screenpipe's pipe API, accumulates text, and sends it to the LLM for analysis every 30 seconds or when the transcript reaches a sufficient length. Supports multiple AI providers through configurable settings.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nimport { pipe } from \"@screenpipe/js\";\nimport { OpenAI } from \"openai\";\nimport type { Settings } from \"@screenpipe/js\";\n\n\nasync function streamMeetingInsights(settings: Settings) {\n  const openai = new OpenAI({\n    apiKey:\n      settings?.aiProviderType === \"screenpipe-cloud\"\n        ? settings?.user?.token\n        : settings?.openaiApiKey,\n    baseURL: settings?.aiUrl,\n    dangerouslyAllowBrowser: true, // for browser environments\n  });\n  let transcript = \"\";\n  \n  // stream audio transcriptions\n  for await (const chunk of pipe.streamTranscriptions()) {\n    transcript += chunk.choices[0].text + \" \";\n    \n    // analyze every 30 seconds\n    if (transcript.length > 200 && transcript.length % 30 === 0) {\n      const response = await openai.chat.completions.create({\n        model: \"gpt-4o\", // if user is using screenpipe-cloud, you can also use claude-3-7-sonnet or gemini-2.0-flash-lite\n        messages: [\n          {\n            role: \"system\",\n            content: \"provide brief insights on this ongoing meeting.\"\n          },\n          {\n            role: \"user\", \n            content: transcript\n          }\n        ]\n      });\n      \n      console.log(\"meeting insight:\", response.choices[0].message.content);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Integrating Screenpipe with LLMs using Vercel AI SDK in TypeScript\nDESCRIPTION: This code demonstrates how to integrate Screenpipe's SDK with language models using the Vercel AI SDK. It includes functions for generating structured work logs from screen data, utilizing Zod for schema validation and the Ollama AI provider for LLM integration.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { generateObject, embed } from \"ai\";\nimport { ollama } from \"ollama-ai-provider\";\nimport { pipe } from \"@screenpipe/js\";\nimport { z } from \"zod\";\n\n// define your output schema\nconst workLog = z.object({\n  title: z.string(),\n  description: z.string(),\n  tags: z.array(z.string()),\n  mediaLinks: z.array(z.string()).optional(),\n});\n\ntype WorkLog = z.infer<typeof workLog> & {\n  startTime: string;\n  endTime: string;\n};\n\nasync function generateWorkLog(screenData, model, startTime, endTime) {\n  // configure the prompt with context and instructions\n  const prompt = `You are analyzing screen recording data from Screenpipe.\n    Based on the following screen data, generate a concise work activity log entry.\n    \n    Screen data: ${JSON.stringify(screenData)}\n    \n    Return a JSON object with:\n    {\n        \"title\": \"Brief title describing the main activity\",\n        \"description\": \"Clear description of what was accomplished\",\n        \"tags\": [\"#relevant-tool\", \"#activity-type\"],\n        \"mediaLinks\": [\"<video src=\\\"file:///path/to/video.mp4\\\" controls></video>\"]\n    }`;\n\n  // use ollama provider with vercel ai sdk\n  const provider = ollama(model);\n  const response = await generateObject({\n    model: provider,\n    messages: [{ role: \"user\", content: prompt }],\n    schema: workLog, // zod schema for type safety\n  });\n\n  return {\n    ...response.object,\n    startTime: formatDate(startTime),\n    endTime: formatDate(endTime),\n  };\n}\n\n// api endpoint implementation\nasync function handleRequest() {\n  // get last hour of activity\n  const now = new Date();\n  const oneHourAgo = new Date(now.getTime() - 3600000);\n\n  // query context from screenpipe\n  const screenData = await pipe.queryScreenpipe({\n    startTime: oneHourAgo.toISOString(),\n    endTime: now.toISOString(),\n    limit: 100,\n    contentType: \"all\",\n  });\n\n  // generate structured log with ai\n  const logEntry = await generateWorkLog(\n    screenData.data,\n    \"llama3.2\", // ollama model name\n    oneHourAgo,\n    now\n  );\n\n  return { message: \"log generated successfully\", logEntry };\n}\n```\n\n----------------------------------------\n\nTITLE: Interacting with Notepad using Terminator SDK\nDESCRIPTION: This function demonstrates how to interact with the Windows Notepad application using the Terminator SDK. It opens Notepad, types text, presses keys, and retrieves the content.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nasync function interactWithNotepad() {\n  try {\n    console.log('opening notepad...');\n    await client.openApplication('notepad');\n    await sleep(1000);\n\n    const notepadWindow = client.locator('window:Notepad');\n    const editor = notepadWindow.locator('name:RichEditD2DPT'); // adjust if necessary\n\n    console.log('typing text...');\n    await editor.typeText('hello from terminator!\\nthis is a test.');\n    await sleep(500);\n\n    // press enter\n    console.log('pressing enter...');\n    await editor.pressKey('{enter}');\n    await sleep(200);\n\n    await editor.typeText('done.');\n\n    const content = await editor.getText();\n    console.log('notepad content retrieved:', content.text);\n\n  } catch (error) {\n    console.error('error interacting with notepad:', error);\n  }\n}\n\n// interactWithNotepad(); // uncomment to run\n```\n\n----------------------------------------\n\nTITLE: Checking Element State and Attributes with Python SDK\nDESCRIPTION: Function demonstrating how to check the state and attributes of UI elements. It opens the Calculator, checks visibility, retrieves attributes, and gets the bounds of the equals button.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef check_element_state():\n    try:\n        client.open_application('calc')\n        sleep(1000)\n        equals_button = client.locator('window:Calculator').locator('role:Button').locator('Name:Equals')\n\n        visible = equals_button.is_visible()\n        print(f'is equals button visible? {visible}')\n\n        attributes = equals_button.get_attributes()\n        print(f'equals button attributes: {attributes}') # attributes is a dataclass\n\n        bounds = equals_button.get_bounds()\n        print(f'equals button bounds: x={bounds.x}, y={bounds.y}, width={bounds.width}, height={bounds.height}')\n\n    except ApiError as e:\n        print(f'api error checking element state: {e}')\n    except Exception as e:\n        print(f'an unexpected error occurred: {e}')\n\n# check_element_state()\n```\n\n----------------------------------------\n\nTITLE: Streaming Vision Events\nDESCRIPTION: TypeScript example demonstrating how to stream and process vision events in real-time\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/architecture.mdx#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nfor await (const event of pipe.streamVision()) {\n  // Process each new screen event\n}\n```\n\n----------------------------------------\n\nTITLE: Deduplicating Screen Data with Embeddings in TypeScript\nDESCRIPTION: A function that removes duplicate content from screen data using embedding-based similarity detection. It leverages Ollama's embedding model to convert text content into vectors and identifies duplicates using cosine similarity with a 0.95 threshold. Includes a helper function for calculating cosine similarity between vectors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { embed } from \"ai\";\nimport { ollama } from \"ollama-ai-provider\";\nimport { ContentItem } from \"@screenpipe/js\";\n\nasync function deduplicateScreenData(screenData: ContentItem[]): Promise<ContentItem[]> {\n  if (!screenData.length) return screenData;\n\n  // use ollama's embedding model\n  const provider = ollama.embedding(\"nomic-embed-text\");\n  const embeddings: number[][] = [];\n  const uniqueData: ContentItem[] = [];\n  \n  for (const item of screenData) {\n    // extract text content depending on type\n    const textToEmbed =\n      \"content\" in item\n        ? typeof item.content === \"string\"\n          ? item.content\n          : \"text\" in item.content\n          ? item.content.text\n          : JSON.stringify(item.content)\n        : \"\";\n\n    if (!textToEmbed.trim()) {\n      uniqueData.push(item);\n      continue;\n    }\n\n    // generate embedding\n    const { embedding } = await embed({\n      model: provider,\n      value: textToEmbed,\n    });\n\n    // check for duplicates using cosine similarity\n    let isDuplicate = false;\n    for (let i = 0; i < embeddings.length; i++) {\n      const similarity = cosineSimilarity(embedding, embeddings[i]);\n      if (similarity > 0.95) {\n        isDuplicate = true;\n        break;\n      }\n    }\n\n    if (!isDuplicate) {\n      embeddings.push(embedding);\n      uniqueData.push(item);\n    }\n  }\n\n  return uniqueData;\n}\n\n// cosine similarity helper\nfunction cosineSimilarity(a: number[], b: number[]): number {\n  const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);\n  const normA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n  const normB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n  return dotProduct / (normA * normB);\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Element State and Attributes with Terminator SDK\nDESCRIPTION: This function demonstrates how to check properties like visibility and retrieve detailed attributes of UI elements using the Terminator SDK. It uses the Calculator app as an example.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nasync function checkElementState() {\n  try {\n    await client.openApplication('calc');\n    await sleep(1000);\n    const equalsButton = client.locator('button:Calculator').locator('name:Equals');\n\n    const visible = await equalsButton.isVisible();\n    console.log(`is equals button visible? ${visible}`);\n\n    const attributes = await equalsButton.getAttributes();\n    console.log('equals button attributes:', JSON.stringify(attributes, null, 2));\n\n    const bounds = await equalsButton.getBounds();\n    console.log(`equals button bounds: x=${bounds.x}, y=${bounds.y}, width=${bounds.width}, height=${bounds.height}`);\n\n  } catch (error) {\n    console.error('error checking element state:', error);\n  }\n}\n\n// checkElementState(); // uncomment to run\n```\n\n----------------------------------------\n\nTITLE: Automated Content Monitoring\nDESCRIPTION: TypeScript example showing how to monitor vision events and trigger actions based on content\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/architecture.mdx#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Monitor for specific content\nfor await (const event of pipe.streamVision()) {\n  if (event.data.text.includes(\"meeting starting\")) {\n    // Take action like sending notification\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitoring Real-Time Screen Activity with Screenpipe SDK in TypeScript\nDESCRIPTION: This function uses the Screenpipe SDK to monitor screen activity in real-time, detecting specific application usage like email clients. It demonstrates how to stream vision events and process the data for insights or logging purposes.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nasync function monitorScreenActivity() {\n  // Monitor screen content in real-time\n  for await (const event of pipe.streamVision(true)) {\n    // Check if we're looking at important apps\n    const appName = event.data.app_name?.toLowerCase() || \"\"\n    const text = event.data.text?.toLowerCase() || \"\"\n    \n    // Example: Detect when looking at email\n    if (\n      appName.includes(\"outlook\") || \n      appName.includes(\"gmail\") ||\n      text.includes(\"inbox\") ||\n      text.includes(\"compose email\")\n    ) {\n      console.log(\"Email activity detected at\", new Date().toLocaleTimeString())\n      \n      // You could log this, send notifications, etc.\n    }\n    \n    // Example: Track time spent in different applications\n    // This would require keeping state between events\n  }\n}\n\n// Start monitoring\nmonitorScreenActivity().catch(console.error)\n```\n\n----------------------------------------\n\nTITLE: Querying Screenpipe Data with JavaScript SDK\nDESCRIPTION: This TypeScript code demonstrates how to use the Screenpipe JavaScript SDK to query and process screen capture data. It retrieves content from the last 5 minutes, limiting results to 10 items, and handles both OCR and Audio content types.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/getting-started.mdx#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { pipe } from \"@screenpipe/js\";\n\nasync function queryScreenpipe() {\n  // get content from last 5 minutes\n  const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000).toISOString();\n\n  const results = await pipe.queryScreenpipe({\n    startTime: fiveMinutesAgo,\n    limit: 10,\n    contentType: \"all\", // can be \"ocr\", \"audio\", or \"all\"\n  });\n\n  if (!results) {\n    console.log(\"no results found or error occurred\");\n    return;\n  }\n\n  console.log(`found ${results.pagination.total} items`);\n\n  // process each result\n  for (const item of results.data) {\n    if (item.type === \"OCR\") {\n      console.log(`OCR: ${JSON.stringify(item.content)}`);\n    } else if (item.type === \"Audio\") {\n      console.log(`transcript: ${JSON.stringify(item.content)}`);\n    } \n  }\n}\n\nqueryScreenpipe().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Using Realtime Streams\nDESCRIPTION: Examples of using realtime streams for transcriptions and vision events, including handling of metadata and images.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// stream transcriptions\nfor await (const chunk of pipe.streamTranscriptions()) {\n  console.log(chunk.choices[0].text)\n  console.log(chunk.metadata) // { timestamp, device, isInput }\n}\n\n// stream vision events\nfor await (const event of pipe.streamVision(true)) { // true to include images\n  console.log(event.data.text)\n  console.log(event.data.app_name)\n  console.log(event.data.image) // base64 if includeImages=true\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching Recent Screen Activity\nDESCRIPTION: Example of fetching the last hour of screen activity from Chrome, including processing the results and handling base64 encoded images.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Get the last hour of screen activity from Chrome\nconst oneHourAgo = new Date(Date.now() - 60 * 60 * 1000).toISOString()\nconst now = new Date().toISOString()\n\nconst results = await pipe.queryScreenpipe({\n  contentType: \"ocr\",\n  startTime: oneHourAgo,\n  endTime: now,\n  appName: \"chrome\",\n  limit: 50,\n  includeFrames: true, // include base64 encoded images\n})\n\n// Process results\nfor (const item of results.data) {\n  console.log(`At ${item.content.timestamp}:`)\n  console.log(`Text: ${item.content.text}`)\n  \n  if (item.content.frame) {\n    // You could display or process the base64 image\n    // e.g., <img src={`data:image/png;base64,${item.content.frame}`} />\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Real-time Meeting Summarizer\nDESCRIPTION: Example of a real-time meeting summarizer using OpenAI to generate summaries from transcriptions every 30 seconds.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport OpenAI from 'openai'\n\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n})\n\nasync function summarizeMeeting() {\n  let transcript = \"\"\n  let summaryBuffer = \"\"\n  let lastSummaryTime = Date.now()\n  \n  // Stream transcriptions in real-time\n  for await (const chunk of pipe.streamTranscriptions()) {\n    const text = chunk.choices[0].text\n    transcript += text + \" \"\n    \n    // Generate summary every 30 seconds\n    if (Date.now() - lastSummaryTime > 30000 && transcript.length > 200) {\n      const summary = await openai.chat.completions.create({\n        model: \"gpt-3.5-turbo\",\n        messages: [\n          {\n            role: \"system\",\n            content: \"You summarize meeting transcripts concisely.\"\n          },\n          {\n            role: \"user\",\n            content: `Summarize this meeting transcript: ${transcript}`\n          }\n        ]\n      })\n      \n      summaryBuffer = summary.choices[0].message.content\n      lastSummaryTime = Date.now()\n      \n      // Display or store the summary\n      console.log(\"Meeting Summary Update:\", summaryBuffer)\n    }\n  }\n}\n\n// Start summarizing\nsummarizeMeeting().catch(console.error)\n```\n\n----------------------------------------\n\nTITLE: Context-Aware Response Generation\nDESCRIPTION: TypeScript example showing how to retrieve meeting context and generate responses\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/architecture.mdx#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// When user asks about a recent meeting\nconst meetingContext = await pipe.queryScreenpipe({\n  q: \"meeting\",\n  contentType: \"audio\"\n})\n\n// Use context to generate response\nconst response = await generateResponse(userQuery, meetingContext)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom OCR Server in Python\nDESCRIPTION: Example of setting up a custom OCR server using FastAPI, EasyOCR, and Python. Includes server implementation, environment setup, and integration with Screenpipe.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/cli-reference.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\nsource venv/bin/activate\n\npip install fastapi uvicorn easyocr pillow numpy\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI, HTTPException\nimport base64\nimport io\nfrom PIL import Image\nimport numpy as np\nimport time\nimport easyocr\n\napp = FastAPI()\nreader = easyocr.Reader(['en', 'ch_sim'])\n\n@app.post(\"/ocr\")\nasync def read_ocr(payload: dict):\n    image_b64 = payload.get(\"image\")\n    if not image_b64:\n        raise HTTPException(status_code=400, detail=\"no image data provided\")\n    try:\n        start = time.time()\n        image_data = base64.b64decode(image_b64)\n        image = Image.open(io.BytesIO(image_data))\n        image_np = np.array(image)\n        result = reader.readtext(image_np)\n        text = \"\\n\".join([item[1] for item in result])\n        confidence = sum([item[2] for item in result]) / len(result) if result else 0.0\n        print(f\"ocr took {time.time() - start:.2f} seconds\")\n        return {\n            \"text\": text,\n            \"structured_data\": {},\n            \"confidence\": confidence\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"ocr error: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Building a Timeline of User Activity\nDESCRIPTION: Example of fetching a full day of activity and grouping it by hour for timeline visualization, including both screen and audio data.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Get a full day of activity\nconst startOfDay = new Date()\nstartOfDay.setHours(0, 0, 0, 0)\n\nconst endOfDay = new Date() \nendOfDay.setHours(23, 59, 59, 999)\n\n// Get both screen and audio data\nconst results = await pipe.queryScreenpipe({\n  contentType: \"ocr+audio\",\n  startTime: startOfDay.toISOString(),\n  endTime: endOfDay.toISOString(),\n  limit: 1000, // Get a large sample\n})\n\n// Group by hour for timeline visualization\nconst timelineByHour = {}\n\nfor (const item of results.data) {\n  const timestamp = new Date(item.content.timestamp)\n  const hour = timestamp.getHours()\n  \n  // Initialize hour bucket if needed\n  if (!timelineByHour[hour]) {\n    timelineByHour[hour] = {\n      screenEvents: 0,\n      audioEvents: 0,\n      apps: new Set(),\n    }\n  }\n  \n  // Update counts\n  if (item.type === \"OCR\") {\n    timelineByHour[hour].screenEvents++\n    \n    if (item.content.app_name) {\n      timelineByHour[hour].apps.add(item.content.app_name)\n    }\n  } else if (item.type === \"Audio\") {\n    timelineByHour[hour].audioEvents++\n  }\n}\n\n// Now timelineByHour can be used to build a visualization\nconsole.log(timelineByHour)\n```\n\n----------------------------------------\n\nTITLE: Interacting with Notepad Using Python SDK\nDESCRIPTION: Function showing how to interact with Windows Notepad. It opens Notepad, types text, presses keys, and retrieves the content. Includes error handling for API and unexpected errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef interact_with_notepad():\n    try:\n        print('opening notepad...')\n        client.open_application('notepad')\n        sleep(1000)\n\n        editor = client.locator('window:Notepad').locator('role:RichEdit')\n\n        print('typing text...')\n        editor.type_text('hello from terminator!\\nthis is a python test.')\n        sleep(500)\n\n        print('pressing enter...')\n        editor.press_key('{Enter}')\n        sleep(200)\n\n        editor.type_text('done.')\n\n        content = editor.get_text()\n        print(f'notepad content retrieved: {content.text}')\n\n    except ApiError as e:\n        print(f'api error interacting with notepad: {e}')\n    except Exception as e:\n        print(f'an unexpected error occurred: {e}')\n\n# interact_with_notepad()\n```\n\n----------------------------------------\n\nTITLE: Fetching Website-Specific Content\nDESCRIPTION: Function to retrieve all content captured from a specific website within a given time range, useful for aggregating research materials or tracking activity on particular web applications.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * Retrieves all content captured from a specific website\n * This is useful for aggregating research materials or tracking \n * activity on particular web applications\n */\nasync function getWebsiteCaptures(domain: string, days = 7) {\n  const startTime = new Date(Date.now() - days * 24 * 60 * 60 * 1000).toISOString();\n  const endTime = new Date().toISOString();\n\n  const results = await pipe.queryScreenpipe({\n    browserUrl: domain,  // Target specific website\n    contentType: \"ocr\",  // Get both visual content and UI elements\n    startTime,\n    endTime,\n    limit: 100,\n    includeFrames: true  // Include screenshots\n  });\n\n  // Process and analyze the results\n  const captures = results.data.map(item => {\n    const timestamp = new Date(\n      item.type === \"OCR\" ? item.content.timestamp : item.content.timestamp\n    );\n    \n    return {\n      timestamp,\n      date: timestamp.toLocaleDateString(),\n      time: timestamp.toLocaleTimeString(),\n      type: item.type,\n      content: item.type === \"OCR\" ? item.content.text : item.content.text,\n      screenshot: item.type === \"OCR\" && item.content.frame ? item.content.frame : null,\n      url: item.type === \"OCR\" ? item.content.browserUrl : item.content.browserUrl\n    };\n  });\n\n  return captures;\n}\n\n// Example: Get all GitHub activity from the past week\nconst githubActivity = await getWebsiteCaptures(\"github.com\");\nconsole.log(`Found ${githubActivity.length} interactions with GitHub`);\n\n// Example: Search for specific text within a website\nconst searchTerm = \"pull request\";\nconst pullRequests = githubActivity.filter(item => \n  item.content.toLowerCase().includes(searchTerm.toLowerCase())\n);\nconsole.log(`Found ${pullRequests.length} pull request interactions`);\n```\n\n----------------------------------------\n\nTITLE: Implementing usePipeSettings Hook for Screenpipe in React\nDESCRIPTION: This React hook manages Screenpipe pipe settings, including loading, updating, and merging with default values. It handles both pipe-specific and global app settings, providing a unified interface for settings management in React components.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\n// src/lib/hooks/use-pipe-settings.tsx\nimport { useState, useEffect } from 'react'\nimport { Settings } from '@/lib/types'\nimport {\n  getScreenpipeAppSettings,\n  updateScreenpipeAppSettings,\n} from '@/lib/actions/get-screenpipe-app-settings'\n\nconst DEFAULT_SETTINGS: Partial<Settings> = {\n  customSetting: 'default value',\n  anotherSetting: 42,\n}\n\nexport function usePipeSettings() {\n  const [settings, setSettings] = useState<Partial<Settings> | null>(null)\n  const [loading, setLoading] = useState(true)\n\n  useEffect(() => {\n    loadSettings()\n  }, [])\n\n  const loadSettings = async () => {\n    try {\n      // load screenpipe app settings\n      const screenpipeSettings = await getScreenpipeAppSettings()\n\n      // get pipe specific settings from customSettings\n      const pipeSettings = {\n        ...(screenpipeSettings.customSettings?.yourPipeName && {\n          ...screenpipeSettings.customSettings.yourPipeName,\n        }),\n      }\n\n      // merge everything together\n      setSettings({\n        ...DEFAULT_SETTINGS,\n        ...pipeSettings,\n        screenpipeAppSettings: screenpipeSettings,\n      })\n    } catch (error) {\n      console.error('failed to load settings:', error)\n    } finally {\n      setLoading(false)\n    }\n  }\n\n  const updateSettings = async (newSettings: Partial<Settings>) => {\n    try {\n      // split settings\n      const { screenpipeAppSettings, ...pipeSettings } = newSettings\n\n      const mergedPipeSettings = {\n        ...DEFAULT_SETTINGS,\n        ...pipeSettings,\n      }\n\n      // update screenpipe settings if provided\n      await updateScreenpipeAppSettings({\n        ...screenpipeAppSettings,\n        customSettings: {\n          ...screenpipeAppSettings?.customSettings,\n          yourPipeName: pipeSettings,\n        },\n      })\n\n      // update state with everything\n      setSettings({\n        ...mergedPipeSettings,\n        screenpipeAppSettings:\n          screenpipeAppSettings || settings?.screenpipeAppSettings,\n      })\n      return true\n    } catch (error) {\n      console.error('failed to update settings:', error)\n      return false\n    }\n  }\n\n  return { settings, updateSettings, loading }\n}\n```\n\n----------------------------------------\n\nTITLE: Automated Form Filling Example\nDESCRIPTION: Advanced example demonstrating form automation including opening a webpage, finding form fields, filling them with data, and submitting the form.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function fillContactForm() {\n  // open the app and navigate to form\n  await pipe.operator.openApplication(\"Chrome\")\n  await pipe.operator.openUrl(\"https://example.com/contact\")\n  \n  // wait for page to load (simple delay)\n  await new Promise(resolve => setTimeout(resolve, 2000))\n  \n  // find form fields\n  const nameField = await pipe.operator\n    .getByRole(\"textfield\", { \n      app: \"Chrome\",\n      activateApp: true\n    })\n    .first()\n  \n  const emailField = await pipe.operator\n    .getByRole(\"textfield\", { \n      app: \"Chrome\"\n    })\n    .first()\n  \n  const messageField = await pipe.operator\n    .getByRole(\"textfield\", { \n      app: \"Chrome\"\n    })\n    .first()\n  \n  // fill the form\n  await pipe.operator\n    .getById(nameField.id, { app: \"Chrome\" })\n    .fill(\"john doe\")\n  \n  await pipe.operator\n    .getById(emailField.id, { app: \"Chrome\" })\n    .fill(\"john@example.com\")\n  \n  await pipe.operator\n    .getById(messageField.id, { app: \"Chrome\" })\n    .fill(\"this is an automated message from screenpipe!\")\n  \n  // find and click submit button\n  const submitButton = await pipe.operator\n    .getByRole(\"button\", { \n      app: \"Chrome\"\n    })\n    .first()\n  \n  await pipe.operator\n    .getById(submitButton.id, { app: \"Chrome\" })\n    .click()\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Screenpipe API\nDESCRIPTION: Example of using the Screenpipe API to search for content with various parameters such as content type, time range, and application filters.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst results = await pipe.queryScreenpipe({\n  q: \"john\",\n  contentType: \"ocr\", // \"ocr\" | \"audio\" | \"ui\" | \"all\" | \"audio+ui\" | \"ocr+ui\" | \"audio+ocr\"\n  limit: 10,\n  offset: 0,\n  startTime: \"2024-03-10T12:00:00Z\",\n  endTime: \"2024-03-10T13:00:00Z\",\n  appName: \"chrome\",\n  windowName: \"meeting\",\n  includeFrames: true,\n  minLength: 10,\n  maxLength: 1000,\n  speakerIds: [1, 2],\n  frameName: \"screenshot.png\",\n  browserUrl: \"github.com/mediar-ai/screenpipe\" // Filter by browser URL\n})\n```\n\n----------------------------------------\n\nTITLE: Creating Server Actions for Screenpipe App Settings in TypeScript\nDESCRIPTION: This code creates server actions to access and update Screenpipe app settings. It demonstrates how to interact with the Screenpipe SDK to manage global app settings programmatically.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\n// src/lib/actions/get-screenpipe-app-settings.ts\nimport { pipe } from '@screenpipe/js'\nimport type { Settings as ScreenpipeAppSettings } from '@screenpipe/js'\n\nexport async function getScreenpipeAppSettings() {\n  return await pipe.settings.getAll()\n}\n\nexport async function updateScreenpipeAppSettings(\n  newSettings: Partial<ScreenpipeAppSettings>\n) {\n  return await pipe.settings.update(newSettings)\n}\n```\n\n----------------------------------------\n\nTITLE: Importing and Initializing the DesktopUseClient in Python\nDESCRIPTION: Code snippet showing how to import necessary classes and initialize the DesktopUseClient for connecting to the Terminator server. It includes options for default and custom server connections.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom desktop_use import DesktopUseClient, Locator, ApiError, sleep, ElementResponse\n# import other response models or exceptions as needed\n\nclient = DesktopUseClient() # connects to default 127.0.0.1:3000\n# client = DesktopUseClient(base_url='127.0.0.1:3001') # or specify host:port\n```\n\n----------------------------------------\n\nTITLE: Opening Applications and URLs with Terminator SDK\nDESCRIPTION: This function demonstrates how to open applications by name or path, and open URLs in the default browser using the Terminator SDK. It includes error handling for API errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync function launchApps() {\n  try {\n    // open windows calculator\n    console.log('opening calculator...');\n    await client.openApplication('calc');\n    console.log('calculator opened.');\n\n    // wait a bit for the app to load (optional)\n    await sleep(1000);\n\n    // open notepad\n    console.log('opening notepad...');\n    await client.openApplication('notepad');\n    console.log('notepad opened.');\n\n    // open a url\n    console.log('opening url...');\n    await client.openUrl('https://github.com/mediar-ai/terminator');\n    console.log('url opened.');\n\n  } catch (error) {\n    if (error instanceof ApiError) {\n      console.error(`api error (${error.status}): ${error.message}`);\n    } else {\n      console.error('an unexpected error occurred:', error);\n    }\n  }\n}\n\nlaunchApps();\n\n// Utility function for delays\nfunction sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n}\n```\n\n----------------------------------------\n\nTITLE: Application Workflow Automation Example\nDESCRIPTION: Advanced example showing how to automate Photoshop workflows including launching the application, navigating menus, and applying actions.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync function processImages() {\n  // open photoshop\n  await pipe.operator.openApplication(\"Adobe Photoshop\")\n  await new Promise(resolve => setTimeout(resolve, 3000)) // wait for app to launch\n  \n  // open file\n  await pipe.operator\n    .getByRole(\"menuitem\", { \n      app: \"Adobe Photoshop\"\n    })\n    .first()\n    .then(menu => pipe.operator.getById(menu.id, { app: \"Adobe Photoshop\" }).click())\n  \n  await pipe.operator\n    .getByRole(\"menuitem\", { \n      app: \"Adobe Photoshop\"\n    })\n    .first()\n    .then(menu => pipe.operator.getById(menu.id, { app: \"Adobe Photoshop\" }).click())\n  \n  // navigate file picker (simplified)\n  // in practice, you'd need more complex logic to navigate the file picker\n  \n  // apply filter\n  await pipe.operator\n    .getByRole(\"menuitem\", { \n      app: \"Adobe Photoshop\"\n    })\n    .first()\n    .then(menu => pipe.operator.getById(menu.id, { app: \"Adobe Photoshop\" }).click())\n  \n  // and so on...\n}\n```\n\n----------------------------------------\n\nTITLE: Sending Desktop Notifications in TypeScript with Screenpipe\nDESCRIPTION: A simple example showing how to send desktop notifications using the Screenpipe SDK. The function takes a title and body for the notification content and supports asynchronous execution.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nawait pipe.sendDesktopNotification({\n  title: \"meeting starting\",\n  body: \"your standup begins in 5 minutes\",\n})\n```\n\n----------------------------------------\n\nTITLE: Initializing DesktopUseClient in Typescript\nDESCRIPTION: This code demonstrates how to import and initialize the DesktopUseClient, which is used to connect to the Terminator server. It shows both default and custom host:port initialization.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DesktopUseClient } from 'desktop-use';\n\nconst client = new DesktopUseClient(); // Connects to default 127.0.0.1:3000\n// const client = new DesktopUseClient('127.0.0.1:3001'); // Or specify host:port\n```\n\n----------------------------------------\n\nTITLE: Node.js Specific Features in Screenpipe SDK\nDESCRIPTION: Demonstrates Node.js-specific features in the Screenpipe SDK, including settings management and inbox handling. These functions allow for retrieving and updating application settings as well as managing inbox messages, which are operations not available in the browser environment.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\n// settings management\nconst settings = await pipe.settings.getAll()\nawait pipe.settings.update({ aiModel: \"gpt-4\" })\n\n// inbox management (node only)\nconst messages = await pipe.inbox.getMessages()\nawait pipe.inbox.clearMessages()\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe CLI on macOS/Linux\nDESCRIPTION: This bash command installs the Screenpipe CLI on macOS or Linux systems using curl. It downloads and executes the installation script, then runs the screenpipe command to verify the installation.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/getting-started.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -fsSL get.screenpi.pe/cli | sh\nscreenpipe\n```\n\n----------------------------------------\n\nTITLE: Interacting with Calculator Using Python SDK\nDESCRIPTION: Function demonstrating how to interact with the Windows Calculator application. It performs a simple addition operation (7 + 8) and retrieves the result. Includes error handling for API and unexpected errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef interact_with_calc():\n    try:\n        print('opening calculator...')\n        client.open_application('calc')\n        sleep(1500) # give calc time to open\n\n        # locate elements\n        calc_window = client.locator('window:Calculator')\n        seven = calc_window.locator('role:Button').locator('name:Seven')\n        plus = calc_window.locator('role:Button').locator('name:Plus')\n        eight = calc_window.locator('role:Button').locator('name:Eight')\n        equals = calc_window.locator('role:Button').locator('name:Equals')\n        display = calc_window.locator('name:CalculatorResults')\n\n        print('clicking 7...')\n        seven.click()\n        sleep(200)\n\n        print('clicking +...')\n        plus.click()\n        sleep(200)\n\n        print('clicking 8...')\n        eight.click()\n        sleep(200)\n\n        print('clicking =...')\n        equals.click()\n        sleep(500)\n\n        # get the result\n        result = display.get_text()\n        print(f'calculation result: {result.text}') # e.g., \"display is 15\"\n\n    except ApiError as e:\n        print(f'api error interacting with calculator: {e}')\n    except Exception as e:\n        print(f'an unexpected error occurred: {e}')\n\n# interact_with_calc()\n```\n\n----------------------------------------\n\nTITLE: Using Screenpipe Settings in React Component\nDESCRIPTION: This React component demonstrates how to use the usePipeSettings hook to manage and display Screenpipe pipe settings. It includes a form for updating settings and handles loading states.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nimport { usePipeSettings } from '@/lib/hooks/use-pipe-settings'\n\nexport function SettingsComponent() {\n  const { settings, updateSettings, loading } = usePipeSettings()\n\n  if (loading) return <div>loading...</div>\n\n  return (\n    <form onSubmit={async (e) => {\n      e.preventDefault()\n      const formData = new FormData(e.target as HTMLFormElement)\n      await updateSettings({\n        customSetting: formData.get('customSetting') as string,\n        anotherSetting: parseInt(formData.get('anotherSetting') as string),\n      })\n    }}>\n      <input \n        name=\"customSetting\"\n        defaultValue={settings?.customSetting}\n      />\n      <input \n        name=\"anotherSetting\"\n        type=\"number\"\n        defaultValue={settings?.anotherSetting}\n      />\n      <button type=\"submit\">save</button>\n    </form>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Installing ScreenPipe CLI on Windows\nDESCRIPTION: PowerShell command to install the ScreenPipe CLI tool on Windows systems\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\niwr get.screenpi.pe/cli.ps1 | iex\n```\n\n----------------------------------------\n\nTITLE: Configuring Vercel-like Crons\nDESCRIPTION: Example of configuring cron jobs for Screenpipe using a pipe.json file, including a sample configuration and CLI instructions for adding server actions.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"crons\": [\n    {\n      \"path\": \"/api/log\",\n      \"schedule\": \"0 */5 * * *\" // every 5 minutes\n    }\n  ]\n}\n```\n\nLANGUAGE: bash\nCODE:\n```\nbunx @screenpipe/dev@latest components add\n# select \"update-pipe-config\" from the menu\n```\n\n----------------------------------------\n\nTITLE: Installing and Creating Screenpipe Plugin\nDESCRIPTION: Commands for creating a new Screenpipe plugin using the CLI tool with Bun package manager.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/plugins.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest pipe create # or use npx @screenpipe/dev pipe create\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Python SDK for Desktop Automation\nDESCRIPTION: Example of error handling when using the Python SDK. It demonstrates catching ApiError for server/automation issues, ConnectionError for network problems, and general exceptions for unexpected errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    # attempt to find a non-existent element\n    non_existent = client.locator('name:DoesNotExist')\n    non_existent.click()\nexcept ApiError as e:\n    # handle specific api errors (e.g., element not found, timeout)\n    print(f'terminator api error (status: {e.status}): {e}')\nexcept ConnectionError as e:\n    print(f'connection error: {e}. is the server running?')\nexcept Exception as e:\n    # handle other unexpected errors\n    print(f'an unexpected python error occurred: {e}')\n```\n\n----------------------------------------\n\nTITLE: Retrieving Context from Screenpipe\nDESCRIPTION: TypeScript example showing how to query Screenpipe for contextual information with specific parameters\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/architecture.mdx#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst context = await pipe.queryScreenpipe({\n  q: \"meeting notes\",\n  contentType: \"all\",\n  limit: 10\n})\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe SDK for Browser\nDESCRIPTION: Instructions for installing the Screenpipe SDK package for browser environments using various package managers.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @screenpipe/browser\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @screenpipe/browser\n```\n\nLANGUAGE: bash\nCODE:\n```\nbun add @screenpipe/browser\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @screenpipe/browser\n```\n\n----------------------------------------\n\nTITLE: Adding Settings Management to Screenpipe Pipe using CLI\nDESCRIPTION: This bash command demonstrates how to quickly add settings management components to a Screenpipe pipe using the CLI tool. It adds necessary hooks, server actions, and TypeScript types for managing pipe settings.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest components add\n# select \"use-pipe-settings\" from the menu\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe Browser Package\nDESCRIPTION: Package installation commands for different Node.js package managers including npm, pnpm, bun, and yarn.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @screenpipe/browser\npnpm add @screenpipe/browser\nbun add @screenpipe/browser\nyarn add @screenpipe/browser\n```\n\n----------------------------------------\n\nTITLE: Using Expectations with Terminator SDK\nDESCRIPTION: This function demonstrates how to use expectations in the Terminator SDK. It waits for certain conditions to be met before proceeding, such as element visibility, enabled state, and text content matching.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nasync function useExpectations() {\n  try {\n    console.log('opening notepad...');\n    await client.openApplication('notepad.exe');\n\n    const editorLocator = client.locator('window:Notepad').locator('name:RichEditD2DPT');\n\n    // wait for the editor element to be visible (default timeout)\n    console.log('waiting for editor to be visible...');\n    const editorElement = await editorLocator.expectVisible();\n    console.log(`editor is visible! id: ${editorElement.id}`);\n\n    // wait for it to be enabled (with a 5-second timeout)\n    console.log('waiting for editor to be enabled...');\n    await editorLocator.expectEnabled(5000);\n    console.log('editor is enabled!');\n\n    await editorLocator.typeText('initial text.');\n    await sleep(1000);\n\n    // wait for the text to exactly match 'initial text.'\n    console.log('waiting for text to match...');\n    await editorLocator.expectTextEquals('initial text.', { timeout: 3000 });\n    console.log('text matched!');\n\n    // this would likely fail and throw an error after the timeout\n    // console.log('waiting for incorrect text (will timeout)...');\n    // await editorLocator.expectTextEquals('wrong text', { timeout: 2000 }); \n\n  } catch (error) {\n    console.error('expectation error:', error);\n  }\n}\n\n// useExpectations(); // uncomment to run\n```\n\n----------------------------------------\n\nTITLE: Opening Applications and URLs with Python SDK\nDESCRIPTION: Function demonstrating how to open Windows applications (Calculator and Notepad) and a URL using the DesktopUseClient. It includes error handling for API and unexpected errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef launch_apps():\n    try:\n        # open windows calculator\n        print('opening calculator...')\n        client.open_application('calc')\n        print('calculator opened.')\n\n        # wait a bit\n        sleep(1000)\n\n        # open notepad\n        print('opening notepad...')\n        client.open_application('notepad')\n        print('notepad opened.')\n\n        # open a url\n        print('opening url...')\n        client.open_url('https://github.com/mediar-ai/terminator')\n        print('url opened.')\n\n    except ApiError as e:\n        print(f'api error (status: {e.status}): {e}')\n    except Exception as e:\n        print(f'an unexpected error occurred: {e}')\n\n# launch_apps()\n```\n\n----------------------------------------\n\nTITLE: Test Results Checklist in Markdown\nDESCRIPTION: This markdown checklist outlines the key areas to be verified during Screenpipe testing. It covers installation, permissions, core functionalities, AI features, and performance aspects.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/TESTING.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### test results checklist\n- [ ] installation successful\n- [ ] permissions granted correctly\n- [ ] recording status works\n- [ ] screen capture functions correctly\n- [ ] audio capture functions correctly\n- [ ] ocr extracts text accurately\n- [ ] ai configuration successful\n- [ ] search and summary functional\n- [ ] meeting transcription accurate\n- [ ] performance within expected parameters\n- [ ] clean process exit\n- [ ] correct data management\n```\n\n----------------------------------------\n\nTITLE: Screenpipe Developer CLI Commands\nDESCRIPTION: Complete set of CLI commands for managing Screenpipe plugins, including authentication, registration, publishing, and component management.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/plugins.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# authenticate with your API key\nbunx --bun @screenpipe/dev@latest login \n\n# create a new pipe\nbunx --bun @screenpipe/dev@latest pipe register --name my-pipe [--paid --price 9.99] # MAKE SURE TO SET THE PRICE IF YOU WANT TO SELL IT - IRREVERSIBLE\n# you'll receive payouts to your stripe account on a daily basis\n\n# publish your pipe to the store\nbunx --bun @screenpipe/dev@latest pipe publish --name my-pipe\n# our team will review your pipe and publish it to the store\n# if approved, your pipe will be available in the store to everyone\n\n# list all versions of your pipe\nbunx --bun @screenpipe/dev@latest pipe list-versions --name my-pipe\n\n# add predefined components to your pipe (shadcn style)\nbunx --bun @screenpipe/dev@latest components add\n# select components from the interactive menu:\n# - use-health: health monitoring hooks\n# - use-settings: settings management\n# - route-settings: settings page routing\n# - use-sql-autocomplete: SQL query assistance\n# - sql-autocomplete-input: SQL input component\n# - use-search-history: search history management\n# - use-ai-provider: AI integration hooks\n\n# end current session\nbunx --bun @screenpipe/dev@latest logout\n```\n\n----------------------------------------\n\nTITLE: Shell Completion Configuration\nDESCRIPTION: Configuration instructions for enabling Screenpipe CLI autocompletion in various shells including Bash, Zsh, Fish, and PowerShell.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/cli-reference.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neval \"$(screenpipe completions bash)\"\n```\n\nLANGUAGE: bash\nCODE:\n```\neval \"$(screenpipe completions zsh)\"\n```\n\nLANGUAGE: fish\nCODE:\n```\nscreenpipe completions fish | source\n```\n\nLANGUAGE: powershell\nCODE:\n```\nscreenpipe completions powershell | Out-String | Invoke-Expression\n```\n\n----------------------------------------\n\nTITLE: Searching for Specific Content\nDESCRIPTION: Example of searching for specific content within a given time range and processing results based on content type (OCR, Audio, UI).\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst results = await pipe.queryScreenpipe({\n  browserUrl: \"discord*\",\n  startTime: new Date(Date.now() - 1000 * 60 * 60 * 24).toISOString(),\n  limit: 20,\n})\n\n// Process results based on content type, when using browserUrl, only OCR is available\nfor (const item of results.data) {\n  if (item.type === \"OCR\") {\n    console.log(`Screen text: ${item.content.text}`)\n  } else if (item.type === \"Audio\") {\n    console.log(`Audio transcript: ${item.content.transcription}`)\n    console.log(`Speaker: ${item.content.speaker_id}`)\n  } else if (item.type === \"UI\") {\n    console.log(`UI element: ${item.content.element_type}`)\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Publishing ScreenPipe Plugin\nDESCRIPTION: Commands to register and publish a ScreenPipe plugin to the store, with optional pricing configuration\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd foo\nbunx --bun @screenpipe/dev@latest pipe register --name foo [--paid --price 50] # subscription\nbun run build\nbunx --bun @screenpipe/dev@latest pipe publish --name foo\n```\n\n----------------------------------------\n\nTITLE: Debugging Memory Errors with Tokio Console\nDESCRIPTION: Commands to run ScreenPipe with Tokio Console for debugging memory-related issues.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# terminal 1\nRUST_LOG=\"tokio=debug,runtime=debug\" RUSTFLAGS=\"--cfg tokio_unstable\" cargo run --bin screenpipe --features debug-console\n# terminal 2\ncargo install tokio-console\ntokio-console\n```\n\n----------------------------------------\n\nTITLE: Creating ScreenPipe Plugin\nDESCRIPTION: Command to create a new ScreenPipe plugin using the development tools\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest pipe create\n```\n\n----------------------------------------\n\nTITLE: Fixing Database Migration Issues\nDESCRIPTION: SQLite commands to fix database migration issues by removing problematic migrations or resetting the migrations table.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# remove specific migration\nsqlite3 ~/.screenpipe/db.sqlite \"DELETE FROM _sqlx_migrations WHERE version = XXXXXXXXXX;\"\n\n# verify migrations\nsqlite3 ~/.screenpipe/db.sqlite \"SELECT * FROM _sqlx_migrations;\"\n\n# if issues persist, you can take the nuclear approach:\n# 1. backup your database\ncp ~/.screenpipe/db.sqlite ~/.screenpipe/db.sqlite.backup\n\n# 2. reset migrations table\nsqlite3 ~/.screenpipe/db.sqlite \"DROP TABLE _sqlx_migrations;\"\n```\n\n----------------------------------------\n\nTITLE: Locating Elements with Terminator SDK in Typescript\nDESCRIPTION: This snippet demonstrates how to use the locator method to find elements in applications. It shows basic locators and chaining locators to narrow down the search for specific UI elements.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// --- basic locators ---\n\n// locate the calculator window (windows 11 example)\nconst calcWindow = client.locator('name:Calc');\n\n// locate the 'seven' button within the calculator window\nconst sevenButton = calcWindow.locator('name:Seven');\n\n// locate the main text area in notepad\nconst notepadWindow = client.locator('window:Notepad'); // might differ\nconst editor = notepadWindow.locator('name:RichEditD2DPT'); // use accessibility insights tool to find correct class/id\n\n// --- chaining locators ---\n\n// directly locate the 'eight' button\nconst eightButton = client.locator('name:Calc').locator('name:Eight');\n\n// locate the file menu item within notepad\nconst fileMenu = client.locator('window:Notepad').locator('name:File');\n```\n\n----------------------------------------\n\nTITLE: Starting Screenpipe Pipe Development Server\nDESCRIPTION: This command starts the development server for a Screenpipe pipe, allowing for local testing and iteration.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/faq.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbun run dev\n```\n\n----------------------------------------\n\nTITLE: Building ScreenPipe Project\nDESCRIPTION: Commands to build the ScreenPipe project using Cargo with metal features.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncargo build --release --features metal\n```\n\n----------------------------------------\n\nTITLE: Starting Ollama AI Provider\nDESCRIPTION: This bash command demonstrates how to start Ollama, a local AI provider, with a specific model (phi4:14b-q4_K_M). This setup allows Screenpipe to use Ollama for AI features like search and rewind.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/getting-started.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# start ollama with your preferred model\nollama run phi4:14b-q4_K_M\n```\n\n----------------------------------------\n\nTITLE: Debugging GitHub Actions with SSH Access\nDESCRIPTION: YAML configuration to set up an SSH session for debugging GitHub Actions, specifically for Windows runners.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Setup tmate session # HACK\n  if: matrix.platform == 'windows-latest'\n  uses: mxschmitt/action-tmate@v3\n```\n\n----------------------------------------\n\nTITLE: Locating UI Elements with Python SDK\nDESCRIPTION: Examples of locating various UI elements in Windows applications using the locator() method. It demonstrates chaining selectors and using different locator strategies.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# locate the calculator window (windows 11 example)\ncalc_window = client.locator('window:Calculator')\n\n# locate the 'seven' button within the calculator window\nseven_button = calc_window.locator('role:button').locator('name:Seven')\n\n# locate the main text area in notepad (use accessibility insights tool to find correct class/id)\nnotepad_editor = client.locator('window:Notepad').locator('role:richedit')\n\n# directly locate the 'eight' button\neight_button = client.locator('window:Calculator').locator('role:button').locator('name:Eight')\n```\n\n----------------------------------------\n\nTITLE: Running the Screenpipe Node.js SDK test project using Bun\nDESCRIPTION: This command runs the main JavaScript file of the Screenpipe Node.js SDK test project using Bun runtime.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/node-sdk/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run ./dist/main.js\n```\n\n----------------------------------------\n\nTITLE: Adding Mintlify MCP Documentation\nDESCRIPTION: Command to add Mintlify MCP documentation for the mediar-ai project, allowing use of the documentation in Cursor, Claude, and other compatible platforms.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnpx mintlify/mcp add mediar-ai\n```\n\n----------------------------------------\n\nTITLE: Running Screenpipe Tests with Bun\nDESCRIPTION: This command executes the main test file (index.ts) using Bun runtime. It starts the test suite for the Screenpipe project.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/tests/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run index.ts\n```\n\n----------------------------------------\n\nTITLE: Running Benchmarks for ScreenPipe\nDESCRIPTION: Command to run benchmarks for the ScreenPipe project.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncargo bench\n```\n\n----------------------------------------\n\nTITLE: Defining Settings Types for Screenpipe Pipe in TypeScript\nDESCRIPTION: This code snippet defines TypeScript interfaces for pipe-specific settings and Screenpipe app settings. It provides a structure for type-safe settings management in a Screenpipe pipe.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\n// src/lib/types.ts\nimport type { Settings as ScreenpipeAppSettings } from '@screenpipe/js'\n\nexport interface Settings {\n  // your pipe specific settings\n  customSetting?: string\n  anotherSetting?: number\n  \n  // screenpipe app settings\n  screenpipeAppSettings?: ScreenpipeAppSettings\n}\n```\n\n----------------------------------------\n\nTITLE: Running Next.js Development Server\nDESCRIPTION: Commands to start the Next.js development server using various package managers. This allows developers to run the application locally for development and testing.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/deduplicate/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Running the Transcription Script with Bun\nDESCRIPTION: Command to execute the main transcription script (index.ts) using Bun runtime. This assumes the project is set up and dependencies are installed.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/query-screenpipe/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run index.ts\n```\n\n----------------------------------------\n\nTITLE: Running Example Terminator Client\nDESCRIPTION: Bash commands to navigate to the hello-world example directory, install dependencies, and start the development server for a sample Terminator client application.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/getting-started.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/hello-world\nnpm i\nnpm run dev\n# open http://localhost:3000\n```\n\n----------------------------------------\n\nTITLE: Running TypeScript Application with Bun\nDESCRIPTION: Command to execute the main TypeScript file (index.ts) using Bun runtime\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/capture-main-feature/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run index.ts\n```\n\n----------------------------------------\n\nTITLE: Importing Screenpipe SDK in Node.js and Browser\nDESCRIPTION: Basic usage example showing how to import the Screenpipe SDK in both Node.js and browser environments.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// node.js\nimport { pipe } from '@screenpipe/js'\n\n// browser\nimport { pipe } from '@screenpipe/browser'\n```\n\n----------------------------------------\n\nTITLE: Running the Transcription Script with Bun\nDESCRIPTION: Command to execute the main transcription script (index.ts) using Bun runtime. This assumes the project is set up and dependencies are installed.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/basic-transcription/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run index.ts\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun for Screenpipe Tests\nDESCRIPTION: This command installs the necessary dependencies for the Screenpipe project using Bun package manager. It should be run in the project's root directory.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/tests/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Launching ScreenPipe\nDESCRIPTION: Command to start the ScreenPipe application after installation\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nscreenpipe\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server for Screen Avatar Project\nDESCRIPTION: This command starts the development server for the Screen Avatar project using npm.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/pipes/screen-avatar/README.md#2025-04-23_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Pixel API Usage Example\nDESCRIPTION: Shows basic usage of the Pixel API for cross-platform automation including typing text, pressing keys, moving the mouse, and clicking.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/operator-api.mdx#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// type text\nawait pipe.operator.pixel.type(\"hello world\")\n\n// press key\nawait pipe.operator.pixel.press(\"enter\")\n\n// move mouse\nawait pipe.operator.pixel.moveMouse(100, 200)\n\n// click\nawait pipe.operator.pixel.click(\"left\") // \"left\" | \"right\" | \"middle\"\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe SDK for Node.js\nDESCRIPTION: Instructions for installing the Screenpipe SDK package for Node.js environments using various package managers.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/sdk-reference.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @screenpipe/js\n```\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @screenpipe/js\n```\n\nLANGUAGE: bash\nCODE:\n```\nbun add @screenpipe/js\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @screenpipe/js\n```\n\n----------------------------------------\n\nTITLE: Installing the Desktop Use Python Package\nDESCRIPTION: Command to install the 'desktop-use' package using pip, which is required for interacting with the Terminator server.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/python-sdk-reference.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install desktop-use\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Terminator SDK\nDESCRIPTION: This snippet demonstrates how to handle errors when using the Terminator SDK. It shows how to use try-catch blocks and check for ApiError instances to handle specific API errors and unexpected JavaScript errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ntry {\n  // attempt to find a non-existent element\n  const nonExistent = client.locator('Name:DoesNotExist');\n  await nonExistent.click(); \n} catch (error) {\n  if (error instanceof ApiError) {\n    // handle specific api errors (e.g., element not found, timeout)\n    console.error(`terminator api error (status: ${error.status}): ${error.message}`);\n  } else {\n    // handle other unexpected errors\n    console.error('an unexpected javascript error occurred:', error);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe Components using CLI\nDESCRIPTION: Command to add Screenpipe components to your project using the bunx package runner\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/src/commands/components/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest components add [component]\n```\n\n----------------------------------------\n\nTITLE: Adding Health Component Example\nDESCRIPTION: Example command showing how to add the use-health component to your project\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/src/commands/components/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest components use-health\n```\n\n----------------------------------------\n\nTITLE: Registry Component Schema Definition\nDESCRIPTION: TypeScript schema definition for Screenpipe registry components, including component name, source, target, documentation, and dependency specifications\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/src/commands/components/README.md#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const registryComponentSchema = z.object({\n  // registry defined name, used by other components if they depend on it.\n  name: z.string(),\n  // github link to download from\n  src: z.string(),\n  // file to create \n  target: z.string(),\n  // optional info to print with cli\n  docs: z.string().optional(),\n  // will be installed using bun\n  dependencies: z.array(z.string()).optional(),\n  devDependencies: z.array(z.string()).optional(),\n  // should be names of other components within the registry\n  registryDependencies: z.array(z.string()).optional(),\n})\n```\n\n----------------------------------------\n\nTITLE: Listing Available Components\nDESCRIPTION: Command to view all available Screenpipe components that can be added to your project\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/cli/src/commands/components/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest components add\n```\n\n----------------------------------------\n\nTITLE: Installing ScreenPipe CLI on MacOS/Linux\nDESCRIPTION: Command to install the ScreenPipe CLI tool on MacOS or Linux systems using curl\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -fsSL get.screenpi.pe/cli | sh\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe CLI on Windows\nDESCRIPTION: This PowerShell command installs the Screenpipe CLI on Windows systems. It downloads and executes the installation script, then runs the screenpipe.exe command to verify the installation.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/getting-started.mdx#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\niwr get.screenpi.pe/cli.ps1 | iex\nscreenpipe.exe\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun\nDESCRIPTION: Command to install project dependencies using Bun package manager\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/capture-main-feature/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies for Screenpipe Node.js SDK test project using Bun\nDESCRIPTION: This command installs the necessary dependencies for the Screenpipe Node.js SDK test project using Bun package manager.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/node-sdk/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Managing Screenpipe Pipes via CLI\nDESCRIPTION: Commands for managing Screenpipe pipes including listing, installation, enabling/disabling, and deletion operations.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/cli-reference.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# list all pipes\nscreenpipe pipe list [--output <FORMAT>] [--port <PORT>]\n\n# install a new pipe\nscreenpipe pipe install <URL> [--output <FORMAT>] [--port <PORT>]\n\n# get pipe info\nscreenpipe pipe info <ID> [--output <FORMAT>] [--port <PORT>]\n\n# enable/disable pipe\nscreenpipe pipe enable <ID> [--port <PORT>]\nscreenpipe pipe disable <ID> [--port <PORT>]\n\n# delete pipe\nscreenpipe pipe delete <ID> [-y] [--port <PORT>]\n\n# purge all pipes\nscreenpipe pipe purge [-y] [--port <PORT>]\n```\n\n----------------------------------------\n\nTITLE: Setting Up MCP Server\nDESCRIPTION: Command to set up the MCP server using Screenpipe.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nscreenpipe mcp setup\n```\n\n----------------------------------------\n\nTITLE: Testing MCP Server with Inspector\nDESCRIPTION: Command to test the Screenpipe MCP server using the Model Context Protocol inspector tool\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-integrations/screenpipe-mcp/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpx @modelcontextprotocol/inspector uv run screenpipe-mcp\n```\n\n----------------------------------------\n\nTITLE: Running Terminator Server on Windows\nDESCRIPTION: PowerShell commands to set up and run the Terminator server on Windows with debug logging enabled. This server interacts with the operating system's accessibility APIs.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/getting-started.mdx#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\npowershell -ExecutionPolicy Bypass -File .\\setup_windows.ps1\n.\\server_release\\server.exe --debug\n```\n\n----------------------------------------\n\nTITLE: Running ScreenPipe Tests\nDESCRIPTION: Command to run the test suite for the ScreenPipe project.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncargo test\n```\n\n----------------------------------------\n\nTITLE: Running ScreenPipe with Memory Sanitizers\nDESCRIPTION: Commands to run ScreenPipe with Address Sanitizer and Leak Sanitizer for detecting memory errors.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nRUSTFLAGS=\"-Z sanitizer=address\" cargo run --bin screenpipe\n# or\nRUSTFLAGS=\"-Z sanitizer=leak\" cargo run --bin screenpipe\n```\n\n----------------------------------------\n\nTITLE: Running ScreenPipe in Development Mode\nDESCRIPTION: Command to run ScreenPipe in development mode with custom port and data directory to avoid conflicts with production instance.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./target/release/screenpipe --port 3035 --data-dir /tmp/sp\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies on MacOS\nDESCRIPTION: Commands to install required dependencies including Rust, FFmpeg, and other build tools on MacOS.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nbrew install pkg-config ffmpeg jq cmake wget\n```\n\n----------------------------------------\n\nTITLE: Windows Package Installation\nDESCRIPTION: PowerShell commands to install required development tools and dependencies on Windows using winget.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: powershell\nCODE:\n```\nwinget install -e --id Microsoft.VisualStudio.2022.BuildTools\nwinget install -e --id Rustlang.Rustup\nwinget install -e --id LLVM.LLVM\nwinget install -e --id Kitware.CMake\nwinget install -e --id GnuWin32.UnZip\nwinget install -e --id Git.Git\nwinget install -e --id JernejSimoncic.Wget\nwinget install -e --id 7zip.7zip\nirm https://bun.sh/install.ps1 | iex\n```\n\n----------------------------------------\n\nTITLE: Publishing a Paid Pipe Plugin with Screenpipe CLI\nDESCRIPTION: This command demonstrates how to publish a custom pipe (plugin) to the Screenpipe store using the CLI, including options for setting it as a paid plugin with a specified price.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/faq.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest pipe publish --name your-pipe [--paid --price 50]\n```\n\n----------------------------------------\n\nTITLE: Setting Up Azure Ubuntu VM with Display and Audio\nDESCRIPTION: Azure CLI commands to set up an Ubuntu VM with display and audio capabilities, including RDP configuration and audio redirection.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# Set variables\nRG_NAME=\"my-avd-rgg\"\nLOCATION=\"westus2\" \nVM_NAME=\"ubuntu-avd\"\nIMAGE=\"Canonical:0001-com-ubuntu-server-jammy:22_04-lts-gen2:latest\"\nVM_SIZE=\"Standard_D2s_v3\"  \n\n# Create resource group\naz group create --name $RG_NAME --location $LOCATION\n\n# Create VM\naz vm create \\\n  --resource-group $RG_NAME \\\n  --name $VM_NAME \\\n  --image $IMAGE \\\n  --admin-username azureuser \\\n  --generate-ssh-keys \\\n  --size $VM_SIZE\n\n# Enable RDP\naz vm open-port --port 3389 --resource-group $RG_NAME --name $VM_NAME\n\n# Install xrdp, audio, and desktop environment\naz vm run-command invoke \\\n  --resource-group $RG_NAME \\\n  --name $VM_NAME \\\n  --command-id RunShellScript \\\n  --scripts \"\n    sudo apt update && sudo apt install -y xrdp ubuntu-desktop pulseaudio\n    sudo systemctl enable xrdp\n    sudo adduser xrdp ssl-cert\n    echo 'startxfce4' | sudo tee /etc/xrdp/startwm.sh\n    sudo systemctl restart xrdp\n    sudo ufw allow 3389/tcp\n  \"\n\n# Enable audio redirection\naz vm run-command invoke \\\n  --resource-group $RG_NAME \\\n  --name $VM_NAME \\\n  --command-id RunShellScript \\\n  --scripts \"\n    echo 'load-module module-native-protocol-tcp auth-anonymous=1' | sudo tee -a /etc/pulse/default.pa\n    sudo systemctl restart pulseaudio\n  \"\n\n# Get IP address\nIP=$(az vm list-ip-addresses --resource-group $RG_NAME --name $VM_NAME --output table | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | head -1)\n\n# Now you can open Microsoft Remote Desktop and use the IP in new PC to connect to it\n\n# RDP into the VM\nssh azureuser@$IP\n\n# Forwarding port to local \nssh -L 13389:localhost:3389 azureuser@$IP\n\n# Changing password\naz vm user update \\\n  --resource-group $RG_NAME \\\n  --name $VM_NAME \\\n  --username azureuser \\\n  --password <new-password>\n```\n\n----------------------------------------\n\nTITLE: Setting up Xcode on MacOS\nDESCRIPTION: Commands to initialize Xcode and its command line tools.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo xcodebuild -license\nxcodebuild -runFirstLaunch\n```\n\n----------------------------------------\n\nTITLE: Creating a New Screenpipe Pipe Plugin\nDESCRIPTION: This command shows how to create a new pipe (plugin) for Screenpipe using the development CLI.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/faq.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbunx --bun @screenpipe/dev@latest pipe create\n```\n\n----------------------------------------\n\nTITLE: Installing uv Package Manager on Windows\nDESCRIPTION: PowerShell command to install the uv package manager on Windows systems.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n----------------------------------------\n\nTITLE: Opening Claude Desktop Configuration on macOS\nDESCRIPTION: Bash command to open the Claude Desktop configuration file using VSCode on macOS.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncode \"~/Library/Application Support/Claude/claude_desktop_config.json\"\n```\n\n----------------------------------------\n\nTITLE: Building Screenpipe Pipe for Production\nDESCRIPTION: This command builds the Screenpipe pipe for production deployment after development and testing are complete.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/faq.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbun run build\n```\n\n----------------------------------------\n\nTITLE: Opening Claude Desktop Configuration on Windows (PowerShell)\nDESCRIPTION: PowerShell command to open the Claude Desktop configuration file using Notepad on Windows.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_5\n\nLANGUAGE: powershell\nCODE:\n```\nnotepad $env:AppData\\Claude\\claude_desktop_config.json\n```\n\n----------------------------------------\n\nTITLE: Claude Desktop MCP Configuration\nDESCRIPTION: JSON configuration for integrating Screenpipe MCP with Claude Desktop, specifying the command and arguments for the MCP server.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"mcpServers\": {\n        \"screenpipe\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"C:\\\\Users\\\\divan\\\\.screenpipe\\\\mcp\",\n                \"run\",\n                \"screenpipe-mcp\",\n                \"--port\",\n                \"3030\"\n            ]\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: MCP Server Configuration Example\nDESCRIPTION: JSON configuration example for the MCP server, specifying the command and arguments for running Screenpipe MCP.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"screenpipe\": {\n      \"args\": [\n        \"--directory\",\n        \"C:\\\\Users\\\\divan\\\\.screenpipe\\\\mcp\",\n        \"run\",\n        \"screenpipe-mcp\",\n        \"--port\",\n        \"3030\"\n      ],\n      \"command\": \"uv\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Claude Desktop MCP Servers\nDESCRIPTION: JSON configuration for Claude Desktop to integrate with Screenpipe MCP server. Defines the server command and arguments including the absolute path to screenpipe-mcp.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-integrations/screenpipe-mcp/README.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"mcpServers\": {\n        \"screenpipe\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/screenpipe-mcp\",\n                \"run\",\n                \"screenpipe-mcp\"\n            ]\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating New Database Migrations\nDESCRIPTION: Commands to install sqlx-cli and create new database migrations for ScreenPipe.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncargo install sqlx-cli\nsqlx migrate add <migration_name>\n```\n\n----------------------------------------\n\nTITLE: Generating OpenAPI YAML for ScreenPipe\nDESCRIPTION: Command to generate and open the OpenAPI YAML file for ScreenPipe documentation.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nopen http://localhost:3030/openapi.yaml\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Screen Avatar Project\nDESCRIPTION: This snippet shows how to set up environment variables for the Screen Avatar project. It includes instructions for renaming the .env file and adding necessary API keys.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/pipes/screen-avatar/README.md#2025-04-23_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nHEYGEN_API_TOKEN=your_token_here\nNEXT_PUBLIC_HEYGEN_API_KEY=your_token_here\nNEXT_PUBLIC_ELEVENLABS_API_KEY=your_token_here\n```\n\n----------------------------------------\n\nTITLE: Changelog Documentation in Markdown\nDESCRIPTION: Structured changelog documenting fixes and improvements for the Screenpipe update, including issue references and commit comparison link.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/changelogs/0.38.4.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### **Fixes:**\n- **Resolved onboarding display issue:** Fixed the issue where onboarding was showing up again unexpectedly (#1459).\n- **Fixed PowerShell infinite loop:** Addressed a potential infinite loop problem in PowerShell (#1497).\n- **Corrected sideload branch functionality:** Fixed issues related to the sideload branch in the application.\n\n### **Improvements:**\n- **Updated search and rewind version:** Bumped the version for the search and rewind functionality for better performance.\n\n#### **Full Changelog:** [94b10..53acb](https://github.com/mediar-ai/screenpipe/compare/94b10..53acb)\n```\n\n----------------------------------------\n\nTITLE: Querying Database Schema in SQLite\nDESCRIPTION: Command to view the complete database schema of Screenpipe's SQLite database\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/architecture.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsqlite3 ~/.screenpipe/db.sqlite .schema\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Terminator Typescript SDK\nDESCRIPTION: This snippet shows how to install the necessary dependencies for the Terminator Typescript SDK using npm, bun, or yarn.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/js-sdk-reference.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i # or bun install / yarn install\n```\n\n----------------------------------------\n\nTITLE: Linux Dependencies Installation\nDESCRIPTION: Commands to install required development packages and tools on Linux systems.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install -y g++ ffmpeg tesseract-ocr cmake libavformat-dev libavfilter-dev libavdevice-dev libssl-dev libtesseract-dev libxdo-dev libsdl2-dev libclang-dev libxtst-dev\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\n----------------------------------------\n\nTITLE: Running Next.js Development Server with Bun\nDESCRIPTION: Commands to install dependencies and start the Next.js development server using Bun. This allows developers to run the project locally for development and testing.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/pipes/pipe-simple-nextjs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun i\n\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Screenpipe-js with Bun\nDESCRIPTION: This command installs the necessary dependencies for the screenpipe-js project using Bun package manager.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/browser-sdk/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Running Screenpipe-js Main Script with Bun\nDESCRIPTION: This command executes the main script of the screenpipe-js project located in the dist directory using Bun runtime.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/browser-sdk/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run ./dist/main.js\n```\n\n----------------------------------------\n\nTITLE: Installing Screenpipe Pipe\nDESCRIPTION: Command to install a Screenpipe pipe for cron functionality. This is required for crons to work properly within the Screenpipe system.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/pipes/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nscreenpipe pipe install <path/to/pipe>\n```\n\n----------------------------------------\n\nTITLE: Installing uv Package Manager on macOS/Linux\nDESCRIPTION: Command to install the uv package manager on macOS or Linux systems using curl.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Screen Avatar Project\nDESCRIPTION: This command installs the necessary dependencies for the Screen Avatar project using npm. It uses legacy peer dependencies and ignores scripts during installation.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/pipes/screen-avatar/README.md#2025-04-23_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\nnpm i --legacy-peer-deps --ignore-scripts\n```\n\n----------------------------------------\n\nTITLE: Verifying uv Installation\nDESCRIPTION: Command to verify the successful installation of uv package manager by checking its version.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv --version\n```\n\n----------------------------------------\n\nTITLE: Opening Claude Desktop Configuration on Windows (CMD)\nDESCRIPTION: CMD command to open the Claude Desktop configuration file using Notepad on Windows.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/mcp-server.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnotepad %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n----------------------------------------\n\nTITLE: Cloning Terminator Repository\nDESCRIPTION: Commands to clone the Terminator repository from GitHub and navigate to the project directory.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/terminator/getting-started.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mediar-ai/terminator\ncd terminator\n```\n\n----------------------------------------\n\nTITLE: Cloning Screenpipe Repository\nDESCRIPTION: Command to clone the Screenpipe repository from GitHub\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-integrations/screenpipe-mcp/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/mediar-ai/screenpipe\n```\n\n----------------------------------------\n\nTITLE: Navigating to Pipe Directory in Bash\nDESCRIPTION: This command changes the current directory to the newly created pipe's directory for further development.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/content/docs-mintlify-mig-tmp/faq.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd your-pipe-name\n```\n\n----------------------------------------\n\nTITLE: Performance Monitoring with Instruments\nDESCRIPTION: Command to use cargo-instruments for performance monitoring and leak tracking in ScreenPipe.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncargo install cargo-instruments\n# tracking leaks over 60 minutes time limit\ncargo instruments -t Leaks --bin screenpipe --features metal --time-limit 600000 --open\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun\nDESCRIPTION: Command to install project dependencies using Bun package manager. This should be run before executing the project.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/basic-transcription/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun\nDESCRIPTION: Command to install project dependencies using Bun package manager. This should be run before attempting to execute the project.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/query-screenpipe/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Starting Next.js Development Server\nDESCRIPTION: Commands to start the Next.js development server using different package managers including npm, yarn, pnpm, and bun. The server will run on localhost:3000 by default.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-js/examples/stream-screenshots/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\n----------------------------------------\n\nTITLE: Verifying YouTube Video Playback for Meeting Transcription Test in Markdown\nDESCRIPTION: This snippet demonstrates how to set up a specific YouTube video for testing the meeting transcription feature in Screenpipe. It includes the exact URL and duration for consistent testing.\nSOURCE: https://github.com/mediar-ai/screenpipe/blob/main/TESTING.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- play test video (youtube lecture or presentation)\n  - open https://youtu.be/UF8uR6Z6KLc?t=117\n  - play for exactly 120 seconds\n```"
  }
]