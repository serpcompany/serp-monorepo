[
  {
    "owner": "prefecthq",
    "repo": "prefect",
    "content": "TITLE: Deploying a Flow with an RRule Schedule\nDESCRIPTION: This Python snippet deploys a Prefect flow with an `rrule` schedule. The `rrule` parameter of `flow.deploy` specifies a complex schedule using an `rrule` string. In this example, the `rrule` string schedules the flow to run every weekday at 9 AM.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n        # Run every weekday at 9 AM\n        rrule=\"FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR;BYHOUR=9;BYMINUTE=0\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Automation in Python Using Prefect SDK\nDESCRIPTION: This snippet demonstrates how to create an automation using the Prefect SDK with a specified trigger and action. It utilizes the Automation class and includes parameters for trigger matching criteria and action types.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.automations import Automation\nfrom prefect.events.schemas.automations import EventTrigger\nfrom prefect.events.actions import CancelFlowRun\n\n# creating an automation\nautomation = Automation(\n    name=\"woodchonk\",\n    trigger=EventTrigger(\n        expect={\"animal.walked\"},\n        match={\n            \"genus\": \"Marmota\",\n            \"species\": \"monax\",\n        },\n        posture=\"Reactive\",\n        threshold=3,\n    ),\n    actions=[CancelFlowRun()],\n).create()\nprint(automation)\n# name='woodchonk' description='' enabled=True trigger=EventTrigger(type='event', match=ResourceSpecification(__root__={'genus': 'Marmota', 'species': 'monax'}), match_related=ResourceSpecification(__root__={}), after=set(), expect={'animal.walked'}, for_each=set(), posture=Posture.Reactive, threshold=3, within=datetime.timedelta(seconds=10)) actions=[CancelFlowRun(type='cancel-flow-run')] actions_on_trigger=[] actions_on_resolve=[] owner_resource=None id=UUID('d641c552-775c-4dc6-a31e-541cb11137a6')\n\n# reading the automation\nautomation = Automation.read(id=automation.id)\n# or\nautomation = Automation.read(name=\"woodchonk\")\n\nprint(automation)\n# name='woodchonk' description='' enabled=True trigger=EventTrigger(type='event', match=ResourceSpecification(__root__={'genus': 'Marmota', 'species': 'monax'}), match_related=ResourceSpecification(__root__={}), after=set(), expect={'animal.walked'}, for_each=set(), posture=Posture.Reactive, threshold=3, within=datetime.timedelta(seconds=10)) actions=[CancelFlowRun(type='cancel-flow-run')] actions_on_trigger=[] actions_on_resolve=[] owner_resource=None id=UUID('d641c552-775c-4dc6-a31e-541cb11137a6')\n```\n\n----------------------------------------\n\nTITLE: Implementing Concurrent Task Execution in Prefect for GitHub API Requests\nDESCRIPTION: This code snippet shows how to modify the get_open_issues function to use concurrent task execution in Prefect. It uses the submit method to execute API requests concurrently and the result method to unpack the return values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef get_open_issues(repo_name: str, open_issues_count: int, per_page: int = 100):\n    issues = []\n    pages = range(1, -(open_issues_count // -per_page) + 1)\n    for page in pages:\n        issues.append(\n            get_url.submit(\n                f\"https://api.github.com/repos/{repo_name}/issues\",\n                params={\"page\": page, \"per_page\": per_page, \"state\": \"open\"},\n            )\n        )\n    return [i for p in issues for i in p.result()]\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple Triggers in YAML Configuration\nDESCRIPTION: This YAML configuration shows how to define multiple triggers in a separate file. Each trigger specifies matching conditions, expected events, and parameters to pass to the flow when triggered.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ntriggers:\n  - enabled: true\n    match:\n      prefect.resource.id: my.external.resource\n    expect:\n      - external.resource.pinged\n    parameters:\n      param_1: \"{{ event }}\"\n  - enabled: true\n    match:\n      prefect.resource.id: my.other.external.resource\n    expect:\n      - some.other.event\n    parameters:\n      param_1: \"{{ event }}\"\n```\n\n----------------------------------------\n\nTITLE: Creating Deployments with Event Triggers in Python\nDESCRIPTION: This snippet demonstrates how to create deployments with event triggers in Python using the DeploymentEventTrigger class. It shows a simple flow that prints a parameter, which is configured to run when a specific external resource event occurs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.events import DeploymentEventTrigger\n\n\n@flow(log_prints=True)\ndef decorated_fn(param_1: str):\n    print(param_1)\n\n\nif __name__==\"__main__\":\n    decorated_fn.serve(\n        name=\"my-deployment\",\n        triggers=[\n            DeploymentEventTrigger(\n                enabled=True,\n                match={\"prefect.resource.id\": \"my.external.resource\"},\n                expect=[\"external.resource.pinged\"],\n                parameters={\n                    \"param_1\": \"{{ event }}\",\n                },\n            )\n        ],\n    )\n```\n\n----------------------------------------\n\nTITLE: Complete Flow Implementation with Concurrent Execution\nDESCRIPTION: A full example of a Prefect flow using concurrent task execution with .map(). This implementation makes parallel API requests to GitHub and processes the results, significantly improving performance for multiple repository queries.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nimport httpx\nfrom prefect import flow, task\n\n\n@task(retries=3)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    return httpx.get(f\"https://api.github.com/repos/{github_repo}\").json()\n\n\n@task\ndef get_stars(repo_stats: dict[str, Any]) -> int:\n    \"\"\"Task 2: Get the number of stars from GitHub repo statistics\"\"\"\n    return repo_stats[\"stargazers_count\"]\n\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]) -> None:\n    \"\"\"Flow: Show number of GitHub repo stars\"\"\"\n\n    # Task 1: Make HTTP requests concurrently\n    stats_futures = fetch_stats.map(github_repos)\n\n    # Task 2: Once each concurrent task completes, get the star counts\n    stars = get_stars.map(stats_futures).result()\n\n    # Show the results\n    for repo, star_count in zip(github_repos, stars):\n        print(f\"{repo}: {star_count} stars\")\n\n\nif __name__ == \"__main__\":\n    # Run the flow\n    show_stars(\n        [\n            \"PrefectHQ/prefect\",\n            \"pydantic/pydantic\",\n            \"huggingface/transformers\"\n        ]\n    )\n```\n\n----------------------------------------\n\nTITLE: Basic Prefect Workflow Implementation\nDESCRIPTION: Python script demonstrating a basic Prefect workflow that processes customer IDs in parallel using flow and task decorators\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nimport random\n\n@task\ndef get_customer_ids() -> list[str]:\n    # Fetch customer IDs from a database or API\n    return [f\"customer{n}\" for n in random.choices(range(100), k=10)]\n\n@task\ndef process_customer(customer_id: str) -> str:\n    # Process a single customer\n    return f\"Processed {customer_id}\"\n\n@flow\ndef main() -> list[str]:\n    customer_ids = get_customer_ids()\n    # Map the process_customer task across all customer IDs\n    results = process_customer.map(customer_ids)\n    return results\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Create a Block with Secret Fields\nDESCRIPTION: This code demonstrates how to create a block with secret fields using the `SecretStr` type from Pydantic. This automatically obfuscates the values of those fields in the UI and logs, providing a secure way to store credentials and other sensitive information. It defines an `AwsCredentials` block with `aws_secret_access_key` as a `SecretStr`.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nfrom prefect.blocks.core import Block\nfrom pydantic import SecretStr  # if pydantic version >= 2.0, use: from pydantic.v1 import SecretStr\n\nclass AwsCredentials(Block):\n    aws_access_key_id: Optional[str] = None\n    aws_secret_access_key: Optional[SecretStr] = None\n    aws_session_token: Optional[str] = None\n    profile_name: Optional[str] = None\n    region_name: Optional[str] = None\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Data Processing Flow\nDESCRIPTION: Complete Prefect flow implementation that orchestrates multiple tasks including game data fetching, processing, storage, and analysis. Includes S3 integration, data cleaning, and artifact creation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef mlb_flow(team_name, start_date, end_date):\n    # Get recent games.\n    game_ids = get_recent_games(team_name, start_date, end_date)\n    \n    # Fetch boxscore for each game.\n    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]\n    \n    #Define file path for raw data.\n    today = datetime.now().strftime(\"%Y-%m-%d\")  # This uses the current date in the format YYYY-MM-DD.\n    flow_run_name = runtime.flow_run.name\n    raw_file_path = f\"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json\"\n    \n    # Save raw data to a local folder.\n    save_raw_data_to_file(game_data, raw_file_path)\n    \n    # Upload raw data to s3.\n    s3_file_path = upload_raw_data_to_s3(raw_file_path)\n    \n    #Download raw data from s3.\n    raw_data = download_raw_data_from_s3(s3_file_path)\n    \n    # Clean the time value.\n    clean_data = clean_time_value(raw_data)\n    \n    # Analyze the results.\n    results = analyze_games(clean_data)\n    \n    # Save the results to a file.\n    parquet_file_path = f\"./boxscore_parquet/{today}-{team_name}-{flow_run_name}-game-analysis.parquet\"\n    save_analysis_to_file(results, parquet_file_path)\n    \n    # Load the results to duckdb.\n    load_parquet_to_duckdb(parquet_file_path, team_name)\n    \n    # Save the results to an artifact.\n    game_analysis_artifact(results, raw_data)\n    \n    \nif __name__ == \"__main__\":\n    mlb_flow(\"marlins\", '06/01/2024', '06/30/2024')\n```\n\n----------------------------------------\n\nTITLE: Implementing Transaction Rollback with Prefect Tasks\nDESCRIPTION: This snippet demonstrates how to group tasks into a common transaction using the transaction context manager. It includes defining tasks with rollback hooks that execute when a transaction fails, allowing for cleanup of side effects.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom time import sleep\n\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"side-effect.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@write_file.on_rollback\ndef del_file(transaction):\n    \"Deletes file.\"\n    os.unlink(\"side-effect.txt\")\n\n\n@task\ndef quality_test():\n    \"Checks contents of file.\"\n    with open(\"side-effect.txt\", \"r\") as f:\n        data = f.readlines()\n\n    if len(data) < 2:\n        raise ValueError(\"Not enough data!\")\n\n\n@flow\ndef pipeline(contents: str):\n    with transaction():\n        write_file(contents)\n        sleep(2) # sleeping to give you a chance to see the file\n        quality_test()\n\n\nif __name__ == \"__main__\":\n    pipeline(contents=\"hello world\")\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from Git Repository\nDESCRIPTION: Example showing how to load and deploy a Prefect flow from a remote Git repository. Demonstrates using flow.from_source() to specify the source repository and entrypoint function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/username/repository.git\",\n        entrypoint=\"path/to/your/flow.py:your_flow_function\"\n    ).deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Starting a Prefect Worker\nDESCRIPTION: This bash command starts a Prefect worker associated with a specific work pool. The `--pool` argument specifies the work pool to which the worker will connect. This allows the worker to pick up flow runs scheduled for that pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool my-work-pool\n```\n\n----------------------------------------\n\nTITLE: Implementing SERIALIZABLE Cache Isolation in Python with Prefect\nDESCRIPTION: This snippet shows how to configure SERIALIZABLE cache isolation in Prefect. It uses a MemoryLockManager to ensure only one execution of a task occurs at a time for a given cache record.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport threading\n\nfrom prefect import task\nfrom prefect.cache_policies import INPUTS\nfrom prefect.locking.memory import MemoryLockManager\nfrom prefect.transactions import IsolationLevel\n\ncache_policy = INPUTS.configure(\n    isolation_level=IsolationLevel.SERIALIZABLE,\n    lock_manager=MemoryLockManager(),\n)\n\n\n@task(cache_policy=cache_policy)\ndef my_task_version_1(x: int):\n    print(\"my_task_version_1 running\")\n    return x + 42\n\n\n@task(cache_policy=cache_policy)\ndef my_task_version_2(x: int):\n    print(\"my_task_version_2 running\")\n    return x + 43\n\n\nif __name__ == \"__main__\":\n    thread_1 = threading.Thread(target=my_task_version_1, args=(2,))\n    thread_2 = threading.Thread(target=my_task_version_2, args=(2,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\n----------------------------------------\n\nTITLE: Using map() for Parallel Task Execution in Prefect\nDESCRIPTION: This example demonstrates how to use the map() method to create and submit multiple task runs for each element in an iterable. The example squares each number in a list and prints the results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef print_nums(nums: list[int]):\n    for n in nums:\n        print(n)\n\n@task\ndef square_num(num: int) -> int:\n    return num**2\n\n@flow\ndef map_flow(nums: list[int]):\n    print_nums(nums)\n    squared_nums = square_num.map(nums)\n    print_nums(squared_nums)\n\nmap_flow([1,2,3,5,8,13])\n```\n\n----------------------------------------\n\nTITLE: Using RayTaskRunner with remote Ray cluster and caching\nDESCRIPTION: Example of a Prefect flow using RayTaskRunner with a remote Ray cluster, caching, and remote result storage.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom prefect import flow, task\nfrom prefect.logging import get_run_logger\nfrom prefect.tasks import task_input_hash\nfrom prefect_aws import S3Bucket\nfrom prefect_ray.task_runners import RayTaskRunner\n\n\n@task(cache_key_fn=task_input_hash)\ndef say_hello(name: str) -> None:\n    logger = get_run_logger()\n    logger.info(f\"hello {name}!\")\n    return name\n\n\n@flow(\n    task_runner=RayTaskRunner(\n        address=\"ray://<instance_public_ip_address>:10001\",\n    ),\n    result_storage=\"s3/my-result-storage\",\n)\ndef greetings(names: List[str]) -> None:\n    say_hello.map(names).wait()\n\n\nif __name__ == \"__main__\":\n    greetings([\"arthur\", \"trillian\", \"ford\", \"marvin\"])\n```\n\n----------------------------------------\n\nTITLE: Complete Flow Implementation with Retry Logic\nDESCRIPTION: A complete example showing a Prefect flow that uses retry logic when fetching GitHub repository statistics. This includes tasks for fetching data, extracting star counts, and a main flow that processes multiple repositories sequentially.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nimport httpx\nfrom prefect import flow, task # Prefect flow and task decorators\n\n@task(retries=3)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n\n    api_response = httpx.get(f\"https://api.github.com/repos/{github_repo}\")\n    api_response.raise_for_status() # Force a retry if not a 2xx status code\n    return api_response.json()\n\n\n@task\ndef get_stars(repo_stats: dict[str, Any]) -> int:\n    \"\"\"Task 2: Get the number of stars from GitHub repo statistics\"\"\"\n\n    return repo_stats['stargazers_count']\n\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]):\n    \"\"\"Flow: Show the number of stars that GitHub repos have\"\"\"\n\n    for repo in github_repos:\n        # Call Task 1\n        repo_stats = fetch_stats(repo)\n\n        # Call Task 2\n        stars = get_stars(repo_stats)\n\n        # Print the result\n        print(f\"{repo}: {stars} stars\")\n\n\n\n# Run the flow\nif __name__ == \"__main__\":\n    show_stars([\n        \"PrefectHQ/prefect\",\n        \"pydantic/pydantic\",\n        \"huggingface/transformers\"\n    ])\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Cloud and Login\nDESCRIPTION: Commands to install uv package manager and setup Prefect Cloud authentication\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nuvx prefect-cloud login\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Retries in Python\nDESCRIPTION: This example demonstrates how to configure automatic retries for a task in Prefect, useful for operations that depend on external systems like API requests.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nfrom prefect import flow, task\n\n\n@task(retries=2, retry_delay_seconds=5)\ndef get_data_task(\n    url: str = \"https://api.brittle-service.com/endpoint\"\n) -> dict:\n    response = httpx.get(url)\n    \n    # If the response status code is anything but a 2xx, httpx will raise\n    # an exception. This task doesn't handle the exception, so Prefect will\n    # catch the exception and will consider the task run failed.\n    response.raise_for_status()\n    \n    return response.json()\n    \n\n@flow\ndef get_data_flow():\n    get_data_task()\n\n\nif __name__ == \"__main__\":\n    get_data_flow()\n```\n\n----------------------------------------\n\nTITLE: Using Prefect Variables in Python Code\nDESCRIPTION: Demonstrates the basic operations with Prefect variables including setting, getting, and unsetting values. The example shows how to create variables, retrieve their values, update existing variables with overwrite flag, and handle fallback values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/variables.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.variables import Variable\n\nassert Variable.set(\"answer\", 42) == Variable(name=\"answer\", value=42, tags=[])\n\nassert Variable.get(\"answer\") == 42\n\nassert Variable.set(\"answer\", 9001, overwrite=True) == Variable(name=\"answer\", value=9001, tags=[])\n\nassert Variable.unset(\"answer\") is True\n\nassert Variable.get(\"answer\", \"fallback\") == \"fallback\"\n```\n\n----------------------------------------\n\nTITLE: Implementing GitHub Stats Pipeline with Prefect in Python\nDESCRIPTION: A complete data pipeline implementation that fetches and displays GitHub repository star counts. Uses Prefect's flow and task decorators with features like retries, caching, rate limiting, and concurrent execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\nfrom datetime import timedelta\n\nimport httpx\nfrom prefect import flow, task\nfrom prefect.cache_policies import INPUTS\nfrom prefect.concurrency.sync import rate_limit\n\n@task(\n    retries=3,\n    cache_policy=INPUTS,\n    cache_expiration=timedelta(days=1)\n)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    rate_limit(\"github-api\")\n    return httpx.get(f\"https://api.github.com/repos/{github_repo}\").json()\n\n\n@task\ndef get_stars(repo_stats: dict[str, Any]) -> int:\n    \"\"\"Task 2: Get the number of stars from GitHub repo statistics\"\"\"\n    return repo_stats[\"stargazers_count\"]\n\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]) -> None:\n    \"\"\"Flow: Show number of GitHub repo stars\"\"\"\n\n    # Task 1: Make HTTP requests concurrently\n    stats_futures = fetch_stats.map(github_repos)\n\n    # Task 2: Once each concurrent task completes, get the star counts\n    stars = get_stars.map(stats_futures).result()\n\n    # Show the results\n    for repo, star_count in zip(github_repos, stars):\n        print(f\"{repo}: {star_count} stars\")\n\n\n# Run the flow\nif __name__ == \"__main__\":\n    show_stars([\n        \"PrefectHQ/prefect\",\n        \"pydantic/pydantic\",\n        \"huggingface/transformers\"\n    ])\n```\n\n----------------------------------------\n\nTITLE: Complete Flow Implementation with Caching, Concurrency and Rate Limiting\nDESCRIPTION: A comprehensive Prefect flow implementation combining all resilience and performance enhancements: task retries, concurrent execution, rate limiting, and result caching. This creates an efficient and robust data pipeline for fetching GitHub repository statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\nfrom datetime import timedelta\n\nimport httpx\nfrom prefect import flow, task\nfrom prefect.cache_policies import INPUTS\nfrom prefect.concurrency.sync import rate_limit\n\n@task(\n    retries=3,\n    cache_policy=INPUTS,\n    cache_expiration=timedelta(days=1)\n)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    rate_limit(\"github-api\")\n    return httpx.get(f\"https://api.github.com/repos/{github_repo}\").json()\n\n\n@task\ndef get_stars(repo_stats: dict[str, Any]) -> int:\n    \"\"\"Task 2: Get the number of stars from GitHub repo statistics\"\"\"\n    return repo_stats[\"stargazers_count\"]\n\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]) -> None:\n    \"\"\"Flow: Show number of GitHub repo stars\"\"\"\n\n    # Task 1: Make HTTP requests concurrently\n    stats_futures = fetch_stats.map(github_repos)\n\n    # Task 2: Once each concurrent task completes, get the star counts\n    stars = get_stars.map(stats_futures).result()\n\n    # Show the results\n    for repo, star_count in zip(github_repos, stars):\n        print(f\"{repo}: {star_count} stars\")\n\n\n# Run the flow\nif __name__ == \"__main__\":\n    show_stars([\n        \"PrefectHQ/prefect\",\n        \"pydantic/pydantic\",\n        \"huggingface/transformers\"\n    ])\n```\n\n----------------------------------------\n\nTITLE: Passing Arguments to State Change Hooks in Prefect\nDESCRIPTION: This example demonstrates how to pass additional arguments to state change hooks in Prefect using partial functions. It includes a flow that executes a task with a failure hook, passing custom arguments to the hook.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom functools import partial\nfrom prefect import flow, task\n\ndata = {}\n\ndef my_hook(task, task_run, state, **kwargs):\n    data.update(state=state, **kwargs)\n\n@task\ndef bad_task():\n    raise ValueError(\"meh\")\n\n@flow\ndef ok_with_failure_flow(x: str = \"foo\", y: int = 42):\n    bad_task_with_a_hook = bad_task.with_options(\n        on_failure=[partial(my_hook, **dict(x=x, y=y))]\n    )\n    # return a tuple of \"bar\" and the task run state\n    # to avoid raising the task's exception\n    return \"bar\", bad_task_with_a_hook(return_state=True)\n\n_, task_run_state = ok_with_failure_flow()\n\nassert data == {\"x\": \"foo\", \"y\": 42, \"state\": task_run_state}\n```\n\n----------------------------------------\n\nTITLE: Flow Deployment Script\nDESCRIPTION: Script for deploying the MLB flow to Prefect Cloud with source code management and dependency handling.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom pathlib import Path\n\ndef read_requirements(file_path=\"requirements.txt\"):\n    \"\"\"Read and parse requirements.txt file\"\"\"\n    requirements = Path(file_path).read_text().splitlines()\n    return [req.strip() for req in requirements if req.strip() and not req.startswith('#')]\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/PrefectHQ/dev-day-zoom-out.git\",\n        entrypoint=\"track_1_build_workflows/session_2_resilent_workflows/4_deploy_and_schedule/mlb_flow_managed.py:mlb_flow\",\n    ).deploy(\n        name=\"mlb-managed-flow\",\n        work_pool_name=\"managed-pool\",\n        parameters={\"team_name\": \"phillies\", \"start_date\": \"06/01/2024\", \"end_date\": \"06/30/2024\"},\n        job_variables={\"pip_packages\": read_requirements()}\n    )\n```\n\n----------------------------------------\n\nTITLE: Fetching GitHub Repository Information Sequentially in Python using Prefect\nDESCRIPTION: This code snippet demonstrates a Prefect flow that sequentially fetches GitHub repository information, including open issues. It uses tasks for making HTTP requests and caching responses, and calculates the average open issues per user.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nfrom datetime import timedelta\nfrom prefect import flow, task\nfrom prefect.tasks import task_input_hash\nfrom typing import Optional\n\n\n@task(cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))\ndef get_url(url: str, params: Optional[dict[str, any]] = None):\n    response = httpx.get(url, params=params)\n    response.raise_for_status()\n    return response.json()\n\n\ndef get_open_issues(repo_name: str, open_issues_count: int, per_page: int = 100):\n    issues = []\n    pages = range(1, -(open_issues_count // -per_page) + 1)\n    for page in pages:\n        issues.append(\n            get_url(\n                f\"https://api.github.com/repos/{repo_name}/issues\",\n                params={\"page\": page, \"per_page\": per_page, \"state\": \"open\"},\n            )\n        )\n    return [i for p in issues for i in p]\n\n\n@flow(retries=3, retry_delay_seconds=5, log_prints=True)\ndef get_repo_info(repo_name: str = \"PrefectHQ/prefect\"):\n    repo_stats = get_url(f\"https://api.github.com/repos/{repo_name}\")\n    issues = get_open_issues(repo_name, repo_stats[\"open_issues_count\"])\n    issues_per_user = len(issues) / len(set([i[\"user\"][\"id\"] for i in issues]))\n    print(f\"{repo_name} repository statistics 🤓:\")\n    print(f\"Stars 🌠 : {repo_stats['stargazers_count']}\")\n    print(f\"Forks 🍴 : {repo_stats['forks_count']}\")\n    print(f\"Average open issues per user 💌 : {issues_per_user:.2f}\")\n\n\nif __name__ == \"__main__\":\n    get_repo_info()\n```\n\n----------------------------------------\n\nTITLE: Prefect Flow Definition with .deploy Method in Python\nDESCRIPTION: This Python code defines a simple Prefect flow named `hello` that prints \"Hello!\". It then uses the `.deploy` method to create a deployment named \"my-deployment\", specifying the work pool, and a Docker image name with tag for the deployment's infrastructure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef hello():\n  print(\"Hello!\")\n\nif __name__ == \"__main__\":\n    hello.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my_registry/my_image:my_image_tag\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing GitHub Repository Info Flow with Prefect Tasks\nDESCRIPTION: Example showing how to create a flow with a task that fetches GitHub repository information using the GitHub API. The task demonstrates input parameters, HTTP requests, and flow configuration with retries.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nfrom prefect import flow, task\nfrom typing import Optional\n\n\n@task\ndef get_url(url: str, params: Optional[dict[str, any]] = None):\n    response = httpx.get(url, params=params)\n    response.raise_for_status()\n    return response.json()\n\n\n@flow(retries=3, retry_delay_seconds=5, log_prints=True)\ndef get_repo_info(repo_name: str = \"PrefectHQ/prefect\"):\n    url = f\"https://api.github.com/repos/{repo_name}\"\n    repo_stats = get_url(url)\n    print(f\"{repo_name} repository statistics 🤓:\")\n    print(f\"Stars 🌠 : {repo_stats['stargazers_count']}\")\n    print(f\"Forks 🍴 : {repo_stats['forks_count']}\")\n\n\nif __name__ == \"__main__\":\n    get_repo_info()\n```\n\n----------------------------------------\n\nTITLE: Implementing Concurrent Task Execution in Prefect Flow\nDESCRIPTION: This snippet shows how to modify a Prefect flow to execute tasks concurrently using the .map() method. This improves performance by making multiple API requests in parallel rather than sequentially.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]) -> None:\n    \"\"\"Flow: Show number of GitHub repo stars\"\"\"\n\n    # Task 1: Make HTTP requests concurrently\n    stats_futures = fetch_stats.map(github_repos)\n\n    # Task 2: Once each concurrent task completes, get the star counts\n    stars = get_stars.map(stats_futures).result()\n\n    # Show the results\n    for repo, star_count in zip(github_repos, stars):\n        print(f\"{repo}: {star_count} stars\")\n```\n\n----------------------------------------\n\nTITLE: Managing Concurrency Limits using Prefect Python Client\nDESCRIPTION: This snippet shows how to set, delete, and query concurrency limits programmatically using Prefect's Python client. It demonstrates the use of asynchronous functions to interact with the Prefect API, requiring the Prefect library and an async environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-run-limits.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import get_client\n\nasync with get_client() as client:\n    # set a concurrency limit of 10 on the 'small_instance' tag\n    limit_id = await client.create_concurrency_limit(\n        tag=\"small_instance\", \n        concurrency_limit=10\n        )\n```\n\nLANGUAGE: python\nCODE:\n```\nasync with get_client() as client:\n    # remove a concurrency limit on the 'small_instance' tag\n    await client.delete_concurrency_limit_by_tag(tag=\"small_instance\")\n```\n\nLANGUAGE: python\nCODE:\n```\nasync with get_client() as client:\n    # query the concurrency limit on the 'small_instance' tag\n    limit = await client.read_concurrency_limit_by_tag(tag=\"small_instance\")\n```\n\n----------------------------------------\n\nTITLE: Deploying a Flow with an Interval Schedule\nDESCRIPTION: This Python snippet deploys a Prefect flow with an interval schedule.  It uses `datetime.timedelta` to define the interval between flow runs. The `interval` parameter of `flow.deploy` specifies that the flow should run repeatedly at the given interval.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n        # Run once a minute\n        interval=timedelta(minutes=1)\n    )\n```\n\n----------------------------------------\n\nTITLE: Prefect Work Pool Creation via CLI\nDESCRIPTION: This code snippet shows how to create a Prefect work pool using the command line interface.  The `prefect work-pool create` command is used with options to configure the work pool, such as setting it as the default or specifying a base job template.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"prefect work-pool create [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Public GitLab Repository\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a public GitLab repository by specifying the repository URL directly. It uses the flow.from_source() method to define the source repository and entrypoint file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    gitlab_repo = \"https://gitlab.com/org/my-public-repo.git\"\n\n    flow.from_source(\n        source=gitlab_repo,\n        entrypoint=\"gl_public_repo.py:my_flow\"\n    ).deploy(\n        name=\"my-gitlab-deployment\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Nested Mapped Tasks in Prefect Flow (Python)\nDESCRIPTION: This snippet demonstrates how to create nested mapped tasks within a Prefect flow to analyze a batch of social media posts with multiple operations concurrently. It uses task mapping to apply word counting and email extraction to multiple texts.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport re\n\nfrom prefect import flow, task\nfrom prefect.futures import wait\n\ndef count_words(text: str) -> int:\n    \"\"\"Count the number of words in a text.\"\"\"\n    return len(text.split())\n\ndef extract_emails(text: str) -> list[str]:\n    return re.findall(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", text)\n\n@task\ndef analyze_texts(texts: list[str]) -> dict[str, list[int | list[str]]]:\n    futures = {\n        op.__name__: task(op).map(texts) for op in [count_words, extract_emails]\n    }\n    wait([f for futs in futures.values() for f in futs])\n    return {name: [f.result() for f in futs] for name, futs in futures.items()}\n\n@flow\ndef run_text_analysis():\n    \"\"\"Analyze a batch of social media posts with multiple operations.\"\"\"\n    results = analyze_texts(\n        texts=[\n            \"Just visited #Paris! Contact me at visitor@example.com #travel #vacation\",\n            \"Working on my new #project. Reach out at developer@example.com if interested!\",\n            \"Happy to announce our company event #celebration #milestone email: events@company.org\",\n        ]\n    )\n    print(\"\\nAnalysis Results:\")\n    print(f\"  Word counts: {results['count_words']}\")\n    print(f\"  Extracted emails: {results['extract_emails']}\\n\")\n    return results\n\nrun_text_analysis()\n```\n\n----------------------------------------\n\nTITLE: Configuring Adaptive Scaling with DaskTaskRunner in Prefect\nDESCRIPTION: Example demonstrating how to configure adaptive scaling for a Prefect flow using DaskTaskRunner with a FargateCluster. The configuration specifies a maximum of 10 workers to scale up to as needed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_dask import DaskTaskRunner\n\nDaskTaskRunner(\n    cluster_class=\"dask_cloudprovider.aws.FargateCluster\",\n    adapt_kwargs={\"maximum\": 10}\n)\n```\n\n----------------------------------------\n\nTITLE: Complete Prefect Flow Cancellation Script\nDESCRIPTION: Full implementation script for cancelling Prefect flow runs, including imports, helper functions, and execution logic. The script provides detailed output of which flow runs are being cancelled and continues until all targeted flow runs are processed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nfrom prefect import get_client\nfrom prefect.client.schemas.filters import FlowRunFilter, FlowRunFilterState, FlowRunFilterStateName\nfrom prefect.client.schemas.objects import FlowRun, StateType\n\nasync def list_flow_runs_with_states(states: list[str]) -> list[FlowRun]:\n    async with get_client() as client:\n        return await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state=FlowRunFilterState(\n                    name=FlowRunFilterStateName(any_=states)\n                )\n            )\n        )\n\n\nasync def cancel_flow_runs(flow_runs: list[FlowRun]):\n    async with get_client() as client:\n        for idx, flow_run in enumerate(flow_runs):\n            print(f\"[{idx + 1}] Cancelling flow run '{flow_run.name}' with ID '{flow_run.id}'\")\n            state_updates: dict[str, str] = {}\n            state_updates.setdefault(\"name\", \"Cancelled\")\n            state_updates.setdefault(\"type\", StateType.CANCELLED)\n            state = flow_run.state.copy(update=state_updates)\n            await client.set_flow_run_state(flow_run.id, state, force=True)\n\n\nasync def bulk_cancel_flow_runs():\n    states = [\"Pending\", \"Running\", \"Scheduled\", \"Late\"]\n    flow_runs = await list_flow_runs_with_states(states)\n\n    while len(flow_runs) > 0:\n        print(f\"Cancelling {len(flow_runs)} flow runs\\n\")\n        await cancel_flow_runs(flow_runs)\n        flow_runs = await list_flow_runs_with_states(states)\n    print(\"Done!\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(bulk_cancel_flow_runs())\n```\n\n----------------------------------------\n\nTITLE: Run Deployment\nDESCRIPTION: Create and execute a flow run for a given deployment with options for scheduling, parameters, and monitoring.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment run [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Accessing Runtime Information for Task Name Generation in Python\nDESCRIPTION: This example demonstrates how to access runtime information using the prefect.runtime module to generate a dynamic task run name in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runtime import flow_run, task_run\n\n\ndef generate_task_name():\n    flow_name = flow_run.flow_name\n    task_name = task_run.task_name\n\n    parameters = task_run.parameters\n    name = parameters[\"name\"]\n    limit = parameters[\"limit\"]\n\n    return f\"{flow_name}-{task_name}-with-{name}-and-{limit}\"\n\n\n@task(name=\"my-example-task\",\n      description=\"An example task for a tutorial.\",\n      task_run_name=generate_task_name)\ndef my_task(name: str, limit: int = 100):\n    pass\n\n\n@flow\ndef my_flow(name: str):\n    # creates a run with a name like \"my-flow-my-example-task-with-marvin-and-100\"\n    my_task(name=\"marvin\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating Machine Learning Models with Mapped Tasks in Prefect (Python)\nDESCRIPTION: This example demonstrates using mapped tasks in Prefect to evaluate multiple machine learning models on multiple datasets concurrently. It showcases a real-world application of concurrent task execution in data science workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport random\nfrom dataclasses import dataclass\n\nfrom prefect import flow, task\nfrom prefect.futures import PrefectFuture, wait\n\n@dataclass\nclass Dataset:\n    name: str\n\n@dataclass\nclass ModelConfig:\n    name: str\n\n@task(task_run_name=\"train on {dataset.name} with {model_config.name}\")\ndef train_model(dataset: Dataset, model_config: ModelConfig) -> dict:\n    return {\n        \"dataset\": dataset.name,\n        \"model\": model_config.name,\n        \"score\": random.random(),\n    }\n\n@flow\ndef evaluate_models(datasets: list[Dataset], model_configs: list[ModelConfig]):\n    all_futures: list[PrefectFuture[dict[str, object]]] = []\n    for dataset in datasets:\n        futures = train_model.map(\n            dataset=dataset,\n            model_config=model_configs,\n        )\n        all_futures.extend(futures)\n\n    results = [future.result() for future in wait(all_futures).done]\n\n    print(f\"\\nBest model: {max(results, key=lambda r: r['score'])}\")\n\nevaluate_models(\n    datasets=[\n        Dataset(\"customers\"), Dataset(\"products\"), Dataset(\"orders\")\n    ],\n    model_configs=[\n        ModelConfig(\"random_forest\"), ModelConfig(\"gradient_boosting\")\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Logging with Prefect in Python\nDESCRIPTION: Demonstrates how to log messages within Prefect tasks and flows using Prefect's `get_run_logger()` method and Python's standard logging methods. Logs are contextual to the Prefect flow or task run. This snippet requires Prefect setup and a flow or task context.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.logging import get_run_logger\n\n@task(name=\"log-example-task\")\ndef logger_task():\n    # this logger instance will emit logs \n    # associated with both the flow run *and* the individual task run\n    logger = get_run_logger()\n    logger.info(\"INFO level log message from a task.\")\n    logger.debug(\"DEBUG level log message from a task.\")\n\n@flow(name=\"log-example-flow\")\ndef logger_flow():\n    # this logger instance will emit logs\n    # associated with the flow run only\n    logger = get_run_logger()\n    logger.info(\"INFO level log message.\")\n    logger.debug(\"DEBUG level log message.\")\n    logger.error(\"ERROR level log message.\")\n    logger.critical(\"CRITICAL level log message.\")\n\n    logger_task()\n```\n\n----------------------------------------\n\nTITLE: Creating Flow Deployment in Python\nDESCRIPTION: Python script to create a flow deployment with scheduled execution. Configures source repository, entry point, parameters, work pool, and hourly cron schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/schedule.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n# Source for the code to deploy (here, a GitHub repo)\nSOURCE_REPO=\"https://github.com/prefecthq/demos.git\"\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=SOURCE_REPO,\n        entrypoint=\"my_workflow.py:show_stars\", # Specific flow to run\n    ).deploy(\n        name=\"my-first-deployment\",\n        parameters={\n            \"github_repos\": [\n                \"PrefectHQ/prefect\",\n                \"pydantic/pydantic\",\n                \"huggingface/transformers\"\n            ]\n        },\n        work_pool_name=\"my-work-pool\",\n        cron=\"0 * * * *\",  # Run every hour\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private GitLab Repository with Secret Block\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a private GitLab repository using a Secret block for authentication. It loads a secret containing a GitLab access token and creates a GitRepository object with the repository URL and credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect.blocks.system import Secret\n\n\nif __name__ == \"__main__\":\n    gitlab_repo = GitRepository(\n        url=\"https://gitlab.com/org/my-private-repo.git\",\n        credentials={\n            \"access_token\": Secret.load(\"my-secret-block-with-my-gl-credentials\")\n        },\n    )\n\n    flow.from_source(   \n        source=gitlab_repo,\n        entrypoint=\"gl_private_repo_secret_block.py:my_flow\",\n    ).deploy(\n        name=\"private-gitlab-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Serving a Flow with an Interval Schedule (Prefect >= 3.1.16)\nDESCRIPTION: This code snippet shows how to serve a Prefect flow with an interval schedule. It utilizes the `Interval` class from `prefect.schedules` to define a schedule that triggers a flow run every 10 minutes, starting at a specific date and time in the `America/Chicago` timezone. This example is compatible with Prefect versions 3.1.16 and newer.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta, datetime\nfrom prefect.schedules import Interval\n\nfrom myproject.flows import my_flow\n\nmy_flow.serve(\n  name=\"flowing\",\n  schedule=Interval(\n    timedelta(minutes=10),\n    anchor_date=datetime(2026, 1, 1, 0, 0),\n    timezone=\"America/Chicago\"\n  )\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Caching with Flow Run ID in Prefect\nDESCRIPTION: This snippet shows how to implement caching for a Prefect task using both input arguments and flow run ID. This ensures that caching only occurs for repeated calls within the same flow run.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.cache_policies import INPUTS, RUN_ID\n\n\n@task(cache_policy=INPUTS + RUN_ID, cache_expiration=timedelta(days=1))\ndef hello_task(name_input):\n    # Doing some work\n    print(\"Saying hello\")\n    return \"hello \" + name_input\n\n\n@flow(log_prints=True)\ndef hello_flow(name_input):\n    # reruns each time the flow is run\n    hello_task(name_input) \n\n    # but the same call within the same flow run is Cached\n    hello_task(name_input) \n```\n\n----------------------------------------\n\nTITLE: MLB Flow with Transaction Block\nDESCRIPTION: Complete MLB data processing flow implementation with transaction management, including data fetching, quality checks, and various data processing steps.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef mlb_flow_rollback(team_name, start_date, end_date):\n    game_ids = get_recent_games(team_name, start_date, end_date)\n    \n    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]\n    \n    today = datetime.now().strftime(\"%Y-%m-%d\")\n    flow_run_name = runtime.flow_run.name\n    raw_file_path = f\"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json\"\n    \n    with transaction() as txn:\n        txn.set(\"filepath\", raw_file_path)\n        save_raw_data_to_file(game_data, raw_file_path)\n        time.sleep(10)\n        quality_test(raw_file_path)\n        s3_file_path = upload_raw_data_to_s3(raw_file_path)\n    \n    raw_data = download_raw_data_from_s3(s3_file_path)\n    clean_data = clean_time_value(raw_data)\n    results = analyze_games(clean_data)\n    \n    parquet_file_path = f\"./boxscore_parquet/{today}-{team_name}-{flow_run_name}-game-analysis.parquet\"\n    save_analysis_to_file(results, parquet_file_path)\n    \n    load_parquet_to_duckdb(parquet_file_path, team_name)\n    game_analysis_artifact(results, raw_data)\n```\n\n----------------------------------------\n\nTITLE: Exponential Backoff Retries in Prefect Task\nDESCRIPTION: Shows how to implement exponential backoff retry strategy using Prefect's built-in exponential_backoff utility. The task retries 3 times with delays of 10, 20, and 40 seconds.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.tasks import exponential_backoff\n\n\n@task(retries=3, retry_delay_seconds=exponential_backoff(backoff_factor=10))\ndef some_task_with_exponential_backoff_retries():\n   (rest of code follows)\n```\n\n----------------------------------------\n\nTITLE: Structuring Code with Nested Flows and Tasks in Prefect\nDESCRIPTION: This example demonstrates how to structure a data pipeline using nested flows and tasks in Prefect. It shows the hierarchical organization of an analytics pipeline that analyzes GitHub repository issues, with each component focused on a specific responsibility.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom prefect import flow, task\n\n\n@flow\ndef analyze_repo_health(repos: List[str]):\n    \"\"\"Analyze issue health metrics for GitHub repositories\"\"\"\n    for repo in repos:\n        \n        # Fetch and analyze all issues\n        issues = fetch_repo_issues(repo)\n        \n        # Calculate metrics\n        resolution_rate = calculate_resolution_rate(issues)\n        # ...\n\n\n@flow\ndef fetch_repo_issues(repo: str):\n    \"\"\"Nested flow: Fetch all data for a single repository\"\"\"\n\n    # ...\n\n\n@task\ndef calculate_resolution_rate(issues: List[dict]) -> float:\n    \"\"\"Task: Calculate the percentage of closed issues\"\"\"\n\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow using Python\nDESCRIPTION: Python code snippet for deploying a Prefect flow named 'build_names' using the flow.deploy method. It specifies the deployment name, work pool, and image.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\nbuild_names.deploy(\n    name=\"deploy-build-names\",\n    work_pool_name=\"tutorial-process-pool\"\n    image=\"my_registry/my_image:my_image_tag\",\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Workflow\nDESCRIPTION: Command to deploy the workflow to Prefect's Serverless Compute using repository source\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuvx prefect-cloud deploy 01_getting_started.py:main \\\n--name my_first_deployment \\\n--from https://github.com/PrefectHQ/quickstart\n```\n\n----------------------------------------\n\nTITLE: XGBoost Model Inference Flow with S3 Integration\nDESCRIPTION: A Prefect flow that loads a trained XGBoost model from S3 and uses it to make predictions on sample data. Includes tasks for model loading and prediction generation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_aws import S3Bucket\nimport xgboost as xgb\nimport numpy as np\nimport tempfile\nimport os\nfrom typing import Union\n\n# Load the saved model:\n@task\ndef load_model(filename: str) -> xgb.Booster:\n    \"\"\"Load a saved XGBoost model from S3\"\"\"\n\n    # Get the S3 bucket block\n    s3_bucket = S3Bucket.load(\"s3-bucket-block\")\n\n    # Create a temporary file to store the model\n    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n        temp_path = temp_file.name\n        \n        # Download the model file\n        s3_bucket.download_object_to_path(\n            from_path=filename,\n            to_path=temp_path\n        )\n        \n        # Load the XGBoost model\n        model = xgb.Booster()\n        model.load_model(temp_path)\n    \n    # Clean up the temporary file\n    os.unlink(temp_path)\n\n    return model\n\n# Run inference with loaded model:\n@task\ndef predict(model: xgb.Booster, X: Union[list[list[float]], np.ndarray]) -> np.ndarray:\n    \"\"\"Make predictions using the loaded model\n    Args:\n        model: Loaded XGBoost model\n        X: Features array/matrix in the same format used during training\n    \"\"\"\n    # Convert input to DMatrix (optional but recommended)\n    dtest = xgb.DMatrix(np.array(X))\n    # Get predictions\n    predictions = model.predict(dtest)\n    return predictions\n\n@flow(log_prints=True)\ndef run_inference(samples: Union[list[list[float]], None] = None) -> None:\n    samples = samples or [[5.0,3.4,1.5,0.2], [6.4,3.2,4.5,1.5], [7.2,3.6,6.1,2.5]]\n    model = load_model('xgboost-model')\n    predictions = predict(model, samples)\n    for sample, prediction in zip(samples, predictions):\n        print(f\"Prediction for sample {sample}: {prediction}\")\n```\n\n----------------------------------------\n\nTITLE: MLB Flow Pipeline Implementation in Python\nDESCRIPTION: Main flow function that orchestrates the entire MLB data processing pipeline, including fetching game data, cleaning, analysis, and storage. Demonstrates the complete workflow implementation using Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef mlb_flow(team_name, start_date, end_date):\n    # Get recent games.\n    game_ids = get_recent_games(team_name, start_date, end_date)\n    \n    # Fetch boxscore for each game.\n    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]\n    \n    #Define file path for raw data.\n    today = datetime.now().strftime(\"%Y-%m-%d\")  # This uses the current date in the format YYYY-MM-DD.\n    flow_run_name = runtime.flow_run.name\n    raw_file_path = f\"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json\"\n    \n    # Save raw data to a local folder.\n    save_raw_data_to_file(game_data, raw_file_path)\n    \n    # Upload raw data to s3.\n    s3_file_path = upload_raw_data_to_s3(raw_file_path)\n    \n    # Download raw data from s3.\n    raw_data = download_raw_data_from_s3(s3_file_path)\n    \n    # Clean the time value.\n    clean_data = clean_time_value(raw_data)\n    \n    # Analyze the results.\n    results = analyze_games(clean_data)\n    \n    # Save the results to a file.\n    parquet_file_path = f\"./boxscore_parquet/{today}-{team_name}-{flow_run_name}-game-analysis.parquet\"\n    save_analysis_to_file(results, parquet_file_path)\n    \n    # Load the results to duckdb\n    load_parquet_to_duckdb(parquet_file_path, team_name)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Results from Mapped Tasks in Prefect\nDESCRIPTION: This code shows two equivalent ways to retrieve results from futures created by the map() method. You can use the bulk result() method on the collection of futures or use a list comprehension to get individual results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfutures = some_task.map(some_iterable)\nresults = futures.result()\n```\n\nLANGUAGE: python\nCODE:\n```\nfutures = some_task.map(some_iterable)\nresults = [future.result() for future in futures]\n```\n\n----------------------------------------\n\nTITLE: Throttling Task Submission with Rate Limiting in Prefect\nDESCRIPTION: Demonstrates how to use the rate_limit function to control the rate at which tasks are submitted in a Prefect flow. This helps avoid overloading resources or comply with external rate limits by ensuring tasks are submitted at a controlled rate governed by the slot_decay_per_second setting.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/global-concurrency-limits.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.concurrency.sync import rate_limit\n\n\n@task\ndef my_task(i):\n    return i\n\n\n@flow\ndef my_flow():\n    for _ in range(100):\n        rate_limit(\"slow-my-flow\", occupy=1)\n        my_task.submit(1)\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Logic for API Requests in Prefect Tasks\nDESCRIPTION: This snippet demonstrates how to add retry functionality to a Prefect task that fetches GitHub repository statistics. The task will retry up to 3 times if the API request fails, improving resilience against network issues or temporary API outages.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nimport httpx\nfrom prefect import task\n\n\n@task(retries=3)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n\n    api_response = httpx.get(f\"https://api.github.com/repos/{github_repo}\")\n    api_response.raise_for_status() # Force a retry if not a 2xx status code\n    return api_response.json()\n```\n\n----------------------------------------\n\nTITLE: Basic Synchronous Prefect Task Implementation\nDESCRIPTION: Simple example of creating a synchronous task that prints a message using the @task decorator.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n\n@task\ndef print_message():\n    print(\"Hello, I'm a task\")\n\n\nif __name__ == \"__main__\":\n    print_message()\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Result Caching in Prefect\nDESCRIPTION: This snippet demonstrates how to implement caching for Prefect task results based on input parameters. The cache expires after one day, preventing redundant API calls for the same repository within that timeframe, saving resources and avoiding rate limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\nfrom datetime import timedelta\n\nfrom prefect import task\nfrom prefect.cache_policies import INPUTS\n\n@task(cache_policy=INPUTS, cache_expiration=timedelta(days=1))\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Data Processing and MotherDuck Integration Tasks in Python\nDESCRIPTION: A collection of Prefect tasks for cleaning game time data, analyzing game statistics, saving results to Parquet files, and loading data into MotherDuck database. Includes error handling and data transformation logic.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef clean_time_value(data_file_path):\n    '''This task will clean the time value.'''\n    \n    try:\n        with open(data_file_path, 'r') as f:\n            game_data_list = json.load(f)\n    except FileNotFoundError:\n        raise ValueError(f\"File not found: {data_file_path}\") \n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON file: {data_file_path}\")\n    \n    # Process each game in the list.\n    for game_data in game_data_list:\n        # Remove any extra text like '(1:16 delay)'\n        if '(' in game_data['game_time']:\n            game_data['game_time'] = game_data['game_time'].split('(')[0]\n        \n        # Remove any non-digit, non-colon characters.\n        game_data['game_time'] = ''.join(char for char in game_data['game_time'] if char.isdigit() or char == ':')\n        \n        hours, minutes = map(int, game_data['game_time'].split(':'))\n        game_data['game_time_in_minutes'] = hours * 60 + minutes\n    \n    # Save the modified data back to the file\n    with open(data_file_path, 'w') as f:\n        json.dump(game_data_list, f, indent=4, sort_keys=True)\n    \n    return data_file_path\n```\n\n----------------------------------------\n\nTITLE: Complete Get Recent Flows Example in Python\nDESCRIPTION: Full implementation to fetch N completed flow runs. The script contains checks for the retrieval logic and prerequisites such as importing necessary modules.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom prefect import get_client\nfrom prefect.client.schemas.filters import FlowRunFilter\nfrom prefect.client.schemas.objects import FlowRun\nfrom prefect.client.schemas.sorting import FlowRunSort\n\nasync def get_most_recent_flow_runs(\n    n: int,\n    states: list[str] | None = None\n) -> list[FlowRun]:    \n    async with get_client() as client:\n        return await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state={'type': {'any_': states or [\"COMPLETED\"]}}\n            ),\n            sort=FlowRunSort.END_TIME_DESC,\n            limit=n,\n        )\n\n\nif __name__ == \"__main__\":\n    flow_runs: list[FlowRun] = asyncio.run(\n        get_most_recent_flow_runs(n=3)\n    )\n    assert len(flow_runs) == 3\n    \n    assert all(\n        run.state.is_completed() for run in flow_runs\n    )\n    assert (\n        end_times := [run.end_time for run in flow_runs]\n    ) == sorted(end_times, reverse=True)\n```\n\n----------------------------------------\n\nTITLE: XGBoost Model Training Flow with SageMaker\nDESCRIPTION: A Prefect flow that trains an XGBoost model on the Iris dataset using AWS SageMaker. It includes tasks for session creation, input preparation, script generation, and model training.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_aws import AwsCredentials\nfrom prefect.cache_policies import NONE\nfrom prefect.blocks.system import Secret\nimport sagemaker\nfrom sagemaker.xgboost.estimator import XGBoost\nimport boto3\nfrom sagemaker.session import Session\nfrom typing import TypedDict, Union\n\nclass TrainingInputs(TypedDict):\n    train: str\n    validation: str\n\n@task(log_prints=True)\ndef get_sagemaker_session(aws_credentials: AwsCredentials) -> Session:\n    \"\"\"Create a SageMaker session using AWS credentials.\"\"\"\n    boto_session = boto3.Session(\n        aws_access_key_id=aws_credentials.aws_access_key_id,\n        aws_secret_access_key=aws_credentials.aws_secret_access_key.get_secret_value(),\n        region_name=aws_credentials.region_name\n    )\n    return sagemaker.Session(boto_session=boto_session)\n\n@task\ndef get_training_inputs(data_bucket: str) -> TrainingInputs:\n    \"\"\"Get the S3 paths for training and test data.\"\"\"\n    return {\n        \"train\": f\"s3://{data_bucket}/train.csv\",\n        \"validation\": f\"s3://{data_bucket}/test.csv\"\n    }\n\n@task\ndef create_training_script(model_bucket: str) -> None:\n    \"\"\"Create the training script dynamically from template\"\"\"\n    # Read the template\n    with open(\"templates/sagemaker_script_template.py\", \"r\") as f:\n        training_script = f.read()\n\n    # Format the script with the model bucket\n    training_script = training_script.format(model_bucket=model_bucket)\n\n    # Write the formatted script\n    with open(\"train.py\", \"w\") as f:\n        f.write(training_script)\n\n@task(cache_policy=NONE)\ndef create_xgboost_estimator(sagemaker_session: Session, role_arn: str) -> XGBoost:\n    \"\"\"Create and configure the XGBoost estimator.\"\"\"\n    hyperparameters = {\n        \"max_depth\": 5,\n        \"eta\": 0.2,\n        \"gamma\": 4,\n        \"min_child_weight\": 6,\n        \"subsample\": 0.8,\n        \"objective\": \"multi:softmax\",\n        \"num_class\": 3,\n        \"num_round\": 100,\n        \"tree_method\": \"gpu_hist\"\n    }\n\n    return XGBoost(\n        entry_point=\"train.py\",\n        hyperparameters=hyperparameters,\n        role=role_arn,\n        instance_count=1,\n        instance_type=\"ml.g4dn.xlarge\",\n        framework_version=\"1.7-1\",\n        py_version=\"py3\",\n        sagemaker_session=sagemaker_session\n    )\n\n@flow(log_prints=True)\ndef train_model(data_bucket: Union[str, None] = None, model_bucket: Union[str, None] = None) -> XGBoost:\n    \"\"\"Main flow to train XGBoost model on Iris dataset using SageMaker.\"\"\"\n    data_bucket = data_bucket or \"prefect-ml-data\"\n    model_bucket = model_bucket or \"prefect-model\"\n\n    # Load AWS credentials from Prefect Block\n    aws_credentials = AwsCredentials.load(\"aws-credentials\")\n    \n    # Get SageMaker role ARN from Prefect Secret Block\n    role_arn = Secret.load(\"sagemaker-role-arn\").get()\n    \n    # Create SageMaker session\n    sagemaker_session = get_sagemaker_session(aws_credentials)\n\n    # Get training inputs\n    training_inputs = get_training_inputs(data_bucket)\n    create_training_script(model_bucket)\n    \n    # Create and train estimator\n    estimator = create_xgboost_estimator(sagemaker_session, role_arn)\n\n    estimator.fit(training_inputs, wait=True)\n    \n    return estimator\n```\n\n----------------------------------------\n\nTITLE: Using unmapped for Static Iterables in Prefect map() Operation\nDESCRIPTION: This example demonstrates how to use the unmapped annotation to prevent an iterable parameter from being mapped over. This is useful when you want to pass the same iterable to each task run created by map().\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task, unmapped\n\n@task\ndef sum_plus(x, static_iterable):\n    return x + sum(static_iterable)\n\n@flow\ndef sum_it(numbers, static_iterable):\n    futures = sum_plus.map(numbers, unmapped(static_iterable))\n    return futures.result()\n\nresulting_sum = sum_it([4, 5, 6], [1, 2, 3])\nassert resulting_sum == [10, 11, 12]\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Prefect Flow in Python\nDESCRIPTION: This Python snippet defines a simple Prefect flow named `my_flow` that accepts an optional `name` argument and prints a greeting.  It uses the `@flow` decorator to register the function as a Prefect flow. The `log_prints=True` argument enables printing output to the Prefect logs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n```\n\n----------------------------------------\n\nTITLE: Dynamic Task Creation in Prefect Flow\nDESCRIPTION: Demonstrates how to create tasks dynamically within a flow using inline task decoration. Shows mapping functionality with a lambda function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@flow\ndef dynamic_flow() -> list[int]:\n    return task(name=\"dynamic-task\")(lambda x: x + 1).map([1, 2, 3]).result()\n\nassert dynamic_flow() == [2, 3, 4]\n```\n\n----------------------------------------\n\nTITLE: Error Handling for API Requests in Prefect Tasks\nDESCRIPTION: This code demonstrates how to handle errors when fetching data from a GitHub API. It uses a Prefect task with error handling to gracefully manage failed API requests by catching exceptions and returning None when errors occur.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nfrom prefect import task\n\n@task(log_prints=True)\ndef fetch_page_of_issues(repo: str, page: int = 1) -> Optional[dict]:\n    \"\"\"Fetch a page of issues for a GitHub repository\"\"\"\n    try:\n        response = httpx.get(\n            f\"https://api.github.com/repos/{repo}/issues\",\n            params={\"page\": page, \"state\": \"all\", \"per_page\": 100}\n        )\n        response.raise_for_status() # Raise an exception if the response is not a 2xx status code\n        return response.json()\n    except Exception as e:\n        print(f\"Error fetching issues for {repo}: {e}\")\n        return None\n```\n\n----------------------------------------\n\nTITLE: Deploying Local and Remote Prefect Flows\nDESCRIPTION: This snippet shows how to deploy both local and remote Prefect flows using the 'deploy' function. It demonstrates deploying a local flow and a flow from a remote GitHub repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef local_flow():\n    print(\"I'm a flow!\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        local_flow.to_deployment(name=\"example-deploy-local-flow\"),\n        flow.from_source(\n            source=\"https://github.com/org/repo.git\",\n            entrypoint=\"flows.py:my_flow\",\n        ).to_deployment(\n            name=\"example-deploy-remote-flow\",\n        ),\n        work_pool_name=\"my-docker-pool\",\n        image=\"my-registry/my-image:dev\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Returning Custom States from a Task in Prefect\nDESCRIPTION: Example showing how to explicitly return Prefect state objects from tasks, demonstrating how returning a Failed state causes a task to fail while returning a Completed state marks it as successful.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\nfrom prefect.states import Completed, Failed\n\n\n@task\ndef toggle_task(fail: bool):\n    if fail:\n        return Failed(message=\"I was instructed to fail.\")\n    else:\n        return Completed(message=\"I was instructed to succeed.\")\n\n\n@flow\ndef example():\n    # this run will be set to a `Failed` state\n    state_one = toggle_task(fail=True)\n\n    # this run will be set to a `Completed` state\n    state_two = toggle_task(fail=False)\n\n    # similarly, the flow run will fail because we return a `Failed` state\n    return state_one, state_two\n```\n\n----------------------------------------\n\nTITLE: Creating Email Notification Automation in Prefect\nDESCRIPTION: Script for creating a Prefect automation that sends email notifications for failed or crashed flow runs. Demonstrates programmatic creation of blocks and automations using the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/scripts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Reference to create_automation.py\n```\n\n----------------------------------------\n\nTITLE: Managing Database Connections with Prefect Concurrency Limits\nDESCRIPTION: Shows how to limit the maximum number of concurrent database connections using Prefect's concurrency context manager. This prevents database resource exhaustion by ensuring the number of connections never exceeds a predefined limit.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/global-concurrency-limits.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task, concurrency\nfrom myproject import db\n\n@task\ndef database_query(query):\n    # Here we request a single slot on the 'database' concurrency limit. This\n    # will block in the case that all of the database connections are in use\n    # ensuring that we never exceed the maximum number of database connections.\n    with concurrency(\"database\", occupy=1):\n        result = db.execute(query)\n        return result\n\n@flow\ndef my_flow():\n    queries = [\"SELECT * FROM table1\", \"SELECT * FROM table2\", \"SELECT * FROM table3\"]\n\n    for query in queries:\n        database_query.submit(query)\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Retry Handler in Python\nDESCRIPTION: Python code snippet defining a custom retry handler function that determines whether to retry a task based on specific conditions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef retry_handler(task, task_run, state) -> bool:\n    \"\"\"Custom retry handler that specifies when to retry a task\"\"\"\n    try:\n        # Attempt to get the result of the task.\n        state.result()\n    except Exception as e:\n        # If Exception is a TimeoutError, retry.\n        if isinstance(e, TimeoutError):\n            return True\n        # For any other exception, do not retry.\n        return False\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private GitLab Repository with Credentials Block\nDESCRIPTION: This snippet shows how to create a Prefect deployment from a private GitLab repository using a GitLabCredentials block for authentication. It creates a GitRepository object with the repository URL and credentials before passing it to flow.from_source().\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_gitlab import GitLabCredentials\n\n\nif __name__ == \"__main__\":\n\n    gitlab_repo = GitRepository(\n        url=\"https://gitlab.com/org/my-private-repo.git\",\n        credentials=GitLabCredentials.load(\"my-gitlab-credentials-block\")\n    )\n    \n    flow.from_source(\n        source=gitlab_repo,\n        entrypoint=\"gl_private_repo_credentials_block.py:my_flow\",\n    ).deploy(\n        name=\"private-gitlab-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: API Integration Flow with Task-Based Data Processing\nDESCRIPTION: This example demonstrates a complete flow that fetches data from an external API, processes it through multiple tasks, and logs the results. It shows how to structure a data pipeline with logging at each stage.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task, get_run_logger\nimport requests\nimport json\n\n@task\ndef fetch(url: str):\n    logger = get_run_logger()\n    response = requests.get(url)\n    raw_data = response.json()\n    logger.info(f\"Raw response: {raw_data}\")\n    return raw_data\n\n@task\ndef clean(raw_data: dict):\n    print(raw_data.get('results')[0])\n    results = raw_data.get('results')[0]\n    logger = get_run_logger()\n    logger.info(f\"Cleaned results: {results}\")\n    return results['name']\n\n@flow\ndef build_names(num: int = 10):\n    df = []\n    url = \"https://randomuser.me/api/\"\n    logger = get_run_logger()\n    copy = num\n    while num != 0:\n        raw_data = fetch(url)\n        df.append(clean(raw_data))\n        num -= 1\n    logger.info(f\"Built {copy} names: {df}\")\n    return df\n\nif __name__ == \"__main__\":\n    list_of_names = build_names()\n```\n\n----------------------------------------\n\nTITLE: Setting Concurrency Limits with prefect deploy CLI\nDESCRIPTION: Example showing how to set concurrency limits and collision strategy when deploying a flow using the prefect deploy CLI command.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy ... --concurrency-limit 3 --collision-strategy ENQUEUE\n```\n\n----------------------------------------\n\nTITLE: Creating Table Artifacts in Prefect Flow\nDESCRIPTION: Illustrates creating table artifacts with a list of dictionaries to track and visualize structured data, such as customer churn probabilities or other tabular information.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.artifacts import create_table_artifact\n\n\ndef my_fn():\n    highest_churn_possibility = [\n       {'customer_id':'12345', 'name': 'John Smith', 'churn_probability': 0.85 }, \n       {'customer_id':'56789', 'name': 'Jane Jones', 'churn_probability': 0.65 } \n    ]\n\n    create_table_artifact(\n        key=\"personalized-reachout\",\n        table=highest_churn_possibility,\n        description= \"# Marvin, please reach out to these customers today!\"\n    )\n\n\nif __name__ == \"__main__\":\n    my_fn()\n```\n\n----------------------------------------\n\nTITLE: Converting an Airflow ETL Pipeline to Prefect Flow\nDESCRIPTION: This example shows how an ETL pipeline originally written as an Airflow DAG looks after conversion to a Prefect flow. It demonstrates the use of task and flow decorators, built-in retries, and the cleaner Python-native approach that Prefect enables.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task(retries=1, log_prints=True)\ndef extract_data():\n    # fetch data from API (simulated)\n    data = get_data_from_api()  \n    return data\n\n@task\ndef transform_data(data):\n    # process the data\n    processed = transform(data)\n    return processed\n\n@task\ndef load_data(data):\n    # load data to database\n    load_into_db(data)\n\n@flow(name=\"etl_pipeline\")\ndef etl_pipeline_flow():\n    raw = extract_data()\n    processed = transform_data(raw)\n    load_data(processed)\n\nif __name__ == \"__main__\":\n    # For local testing\n    etl_pipeline_flow()\n```\n\n----------------------------------------\n\nTITLE: Register a Block Type with Prefect\nDESCRIPTION: This code defines a custom block class `Cube` and registers it as a block type with the Prefect API. This allows the block's schema to be inspected and discovered in the UI. The `register_type_and_schema` method is called to register the block type under the slug 'cube'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.core import Block\n\n\nclass Cube(Block):\n    edge_length_inches: float\n\n\n# register the block type under the slug 'cube'\nCube.register_type_and_schema()\n```\n\n----------------------------------------\n\nTITLE: Running a Prefect Deployment Remotely\nDESCRIPTION: Example of triggering a remote deployment run using prefect-client within a Lambda function. Demonstrates passing parameters and setting timeout.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/client/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.deployments import run_deployment\n\n\ndef my_lambda(event):\n    ...\n    run_deployment(\n        name=\"my-flow/my-deployment\",\n        parameters={\"foo\": \"bar\"},\n        timeout=0,\n    )\n\nmy_lambda({})\n```\n\n----------------------------------------\n\nTITLE: Configuring ThreadPoolTaskRunner for Concurrent Task Execution in Prefect\nDESCRIPTION: This code demonstrates how to configure a Prefect flow with ThreadPoolTaskRunner to execute tasks concurrently using multiple threads. The example creates an elevator flow that stops at different floors concurrently, using up to 3 worker threads.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.futures import wait\nfrom prefect.task_runners import ThreadPoolTaskRunner\nimport time\n\n@task\ndef stop_at_floor(floor):\n    print(f\"elevator moving to floor {floor}\")\n    time.sleep(floor)\n    print(f\"elevator stops on floor {floor}\")\n\n@flow(task_runner=ThreadPoolTaskRunner(max_workers=3))\ndef elevator():\n    floors = []\n\n    for floor in range(10, 0, -1):\n        floors.append(stop_at_floor.submit(floor))\n\n    wait(floors) # wait for the sequence of futures to complete\n```\n\n----------------------------------------\n\nTITLE: Converting Airflow DAG to Prefect Flow - Prefect Flow Definition\nDESCRIPTION: Creating a Prefect flow that orchestrates the tasks in sequence. The flow demonstrates how task dependencies are handled implicitly through function calls, eliminating the need for explicit operators or XComs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef etl_pipeline():\n    data = extract_data()         # calls extract_data task\n    processed = transform_data(data)  # uses output of extract_data\n    load_data(processed)          # calls load_data with result of transform_data\n```\n\n----------------------------------------\n\nTITLE: Creating a Google Cloud Run Push Work Pool with Automatic Infrastructure Provisioning\nDESCRIPTION: Command to create a new Google Cloud Run push work pool with automatic infrastructure setup. This activates the Cloud Run API, creates a service account, and generates a key for authenticating with GCP.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type cloud-run:push --provision-infra my-cloud-run-pool \n```\n\n----------------------------------------\n\nTITLE: List Flow Runs\nDESCRIPTION: Command to view recent flow runs or filter flow runs by specific criteria. Supports filtering by flow name, state, and state type, with a configurable limit on the number of results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Data Quality Check with Rollback Implementation\nDESCRIPTION: Defines tasks for data quality checking and file deletion on rollback. Includes a test to ensure file contains at least 5 game entries, with automatic cleanup on failure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@save_raw_data_to_file.on_rollback\ndef del_file(txn):\n    \"Deletes file.\"\n    os.unlink(txn.get(\"filepath\"))\n    \n@task\ndef quality_test(file_path):\n    \"Checks contents of file.\"\n    with open(file_path, \"r\") as f:\n        data = json.load(f)\n        \n    if len(data) < 5:\n        raise ValueError(f\"Not enough data! There are only {len(data)} games in the file.\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Zombie Flow Detection Automation in Prefect\nDESCRIPTION: Python script that creates an automation to detect and mark zombie flow runs as crashed. It monitors flow run heartbeats and changes the state if heartbeats stop within a specified time window, demonstrating Prefect's proactive monitoring capabilities.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta\n\nfrom prefect.automations import Automation\nfrom prefect.client.schemas.objects import StateType\nfrom prefect.events.actions import ChangeFlowRunState\nfrom prefect.events.schemas.automations import EventTrigger, Posture\nfrom prefect.events.schemas.events import ResourceSpecification\n\n\nmy_automation = Automation(\n    name=\"Crash zombie flows\",\n    trigger=EventTrigger(\n        after={\"prefect.flow-run.heartbeat\"},\n        expect={\n            \"prefect.flow-run.heartbeat\",\n            \"prefect.flow-run.Completed\",\n            \"prefect.flow-run.Failed\",\n            \"prefect.flow-run.Cancelled\",\n            \"prefect.flow-run.Crashed\",\n        },\n        match=ResourceSpecification({\"prefect.resource.id\": [\"prefect.flow-run.*\"]}),\n        for_each={\"prefect.resource.id\"},\n        posture=Posture.Proactive,\n        threshold=1,\n        within=timedelta(seconds=90),\n    ),\n    actions=[\n        ChangeFlowRunState(\n            state=StateType.CRASHED,\n            message=\"Flow run marked as crashed due to missing heartbeats.\",\n        )\n    ],\n)\n\nif __name__ == \"__main__\":\n    my_automation.create()\n```\n\n----------------------------------------\n\nTITLE: Running a Deployment with Parameters using Python SDK\nDESCRIPTION: Shows how to trigger a deployment programmatically using the run_deployment function from the Prefect Python SDK, including how to pass parameters, job variables, and set a timeout.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.deployments import run_deployment\n\n\nrun_deployment(\n    name=\"my-first-flow/my-first-deployment\",\n    parameters={\"my_param\": \"42\"},\n    job_variables={\"env\": {\"MY_ENV_VAR\": \"staging\"}},\n    timeout=0, # don't wait for the run to finish\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow from Private GitHub Repository\nDESCRIPTION: Example showing how to create a deployment using flow code stored in a private GitHub repository using credentials\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_github import GitHubCredentials\n\n\nif __name__ == \"__main__\":\n\n    source = GitRepository(\n        url=\"https://github.com/org/private-repo.git\",\n        credentials=GitHubCredentials.load(\"my-github-credentials-block\")\n    )\n\n    flow.from_source(source=source, entrypoint=\"my_file.py:my_flow\").deploy(\n        name=\"private-github-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Retry Handler in Prefect Task\nDESCRIPTION: Implements a custom retry handler for HTTP requests that retries on specific status codes. The task retries on all HTTP errors except 401 and 404, with specific handling for connection errors.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\nfrom prefect import flow, task\n\n\ndef retry_handler(task, task_run, state) -> bool:\n    \"\"\"Custom retry handler that specifies when to retry a task\"\"\"\n    try:\n        # Attempt to get the result of the task\n        state.result()\n    except httpx.HTTPStatusError as exc:\n        # Retry on any HTTP status code that is not 401 or 404\n        do_not_retry_on_these_codes = [401, 404]\n        return exc.response.status_code not in do_not_retry_on_these_codes\n    except httpx.ConnectError:\n        # Do not retry\n        return False\n    except:\n        # For any other exception, retry\n        return True\n\n\n@task(retries=1, retry_condition_fn=retry_handler)\ndef my_api_call_task(url):\n    response = httpx.get(url)\n    response.raise_for_status()\n    return response.json()\n\n\n@flow\ndef get_data_flow(url):\n    my_api_call_task(url=url)\n\n\nif __name__ == \"__main__\":\n    get_data_flow(url=\"https://httpbin.org/status/503\")\n```\n\n----------------------------------------\n\nTITLE: Serving Multiple Prefect Flows in a Single Process\nDESCRIPTION: This code demonstrates how to serve multiple Prefect flows using the `serve` and `to_deployment` methods. The flows need to share a common Python environment but can execute and be scheduled independently.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport time\nfrom prefect import flow, serve\n\n\n@flow\ndef slow_flow(sleep: int = 60):\n    \"Sleepy flow - sleeps the provided amount of time (in seconds).\"\n    time.sleep(sleep)\n\n\n@flow\ndef fast_flow():\n    \"Fastest flow this side of the Mississippi.\"\n    return\n\n\nif __name__ == \"__main__\":\n    slow_deploy = slow_flow.to_deployment(name=\"sleeper\", interval=45)\n    fast_deploy = fast_flow.to_deployment(name=\"fast\")\n    serve(slow_deploy, fast_deploy)\n```\n\n----------------------------------------\n\nTITLE: Deploying a Flow to Prefect Managed Execution\nDESCRIPTION: This Python script demonstrates how to deploy a flow to Prefect Managed Execution. It retrieves the flow from a Git repository and deploys it to a specified managed work pool, allowing remote execution without infrastructure setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/prefecthq/demo.git\",\n        entrypoint=\"flow.py:my_flow\",\n    ).deploy(\n        name=\"test-managed-flow\",\n        work_pool_name=\"my-managed-pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Launching Databricks Notebook with Prefect Flow\nDESCRIPTION: A comprehensive Prefect flow that demonstrates launching a new Databricks cluster and running a notebook. It includes cluster configuration, notebook task settings, and job submission.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-databricks/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_databricks import DatabricksCredentials\nfrom prefect_databricks.jobs import jobs_runs_submit\nfrom prefect_databricks.models.jobs import (\n    AutoScale,\n    AwsAttributes,\n    JobTaskSettings,\n    NotebookTask,\n    NewCluster,\n)\n\n\n@flow\ndef jobs_runs_submit_flow(notebook_path, **base_parameters):\n    databricks_credentials = DatabricksCredentials.load(\"my-block\")\n\n    # specify new cluster settings\n    aws_attributes = AwsAttributes(\n        availability=\"SPOT\",\n        zone_id=\"us-west-2a\",\n        ebs_volume_type=\"GENERAL_PURPOSE_SSD\",\n        ebs_volume_count=3,\n        ebs_volume_size=100,\n    )\n    auto_scale = AutoScale(min_workers=1, max_workers=2)\n    new_cluster = NewCluster(\n        aws_attributes=aws_attributes,\n        autoscale=auto_scale,\n        node_type_id=\"m4.large\",\n        spark_version=\"10.4.x-scala2.12\",\n        spark_conf={\"spark.speculation\": True},\n    )\n\n    # specify notebook to use and parameters to pass\n    notebook_task = NotebookTask(\n        notebook_path=notebook_path,\n        base_parameters=base_parameters,\n    )\n\n    # compile job task settings\n    job_task_settings = JobTaskSettings(\n        new_cluster=new_cluster,\n        notebook_task=notebook_task,\n        task_key=\"prefect-task\"\n    )\n\n    run = jobs_runs_submit(\n        databricks_credentials=databricks_credentials,\n        run_name=\"prefect-job\",\n        tasks=[job_task_settings]\n    )\n\n    return run\n\nif __name__ == \"__main__\":\n    jobs_runs_submit_flow(\"/Users/username@gmail.com/example.ipynb\", name=\"Marvin\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private GitHub Repository with Credentials Block\nDESCRIPTION: This snippet shows how to create a Prefect deployment from a private GitHub repository using a GitHubCredentials block for authentication. It creates a GitRepository object with the repository URL and credentials before passing it to flow.from_source().\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_github import GitHubCredentials\n\n\nif __name__ == \"__main__\":\n\n    github_repo = GitRepository(\n        url=\"https://github.com/org/my-private-repo.git\",\n        credentials=GitHubCredentials.load(\"my-github-credentials-block\"),\n    )\n\n    flow.from_source(\n        source=github_repo,\n        entrypoint=\"gh_private_repo_credentials_block.py:my_flow\",\n    ).deploy(\n        name=\"private-github-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Delete a Block Document via CLI (ID)\nDESCRIPTION: This command demonstrates how to delete a specific block document using the Prefect CLI, identified by its unique ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nprefect block delete --id <my-id>\n```\n\n----------------------------------------\n\nTITLE: Mapping Over Iterables with Static Values in Prefect\nDESCRIPTION: This code shows how to map a task over one iterable while using a static non-iterable value for another parameter. By default, non-iterable values are not mapped over.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef add_together(x, y):\n    return x + y\n\n@flow\ndef sum_it(numbers: list[int], static_value: int):\n    futures = add_together.map(numbers, static_value)\n    return futures.result()\n\nresulting_sum = sum_it([1, 2, 3], 5)\nassert resulting_sum == [6, 7, 8]\n```\n\n----------------------------------------\n\nTITLE: Synchronous Variables in Prefect Flows\nDESCRIPTION: Shows how to use Prefect variables in a synchronous flow function. The example retrieves crew members from a variable and uses them in a space mission flow, with a default value as fallback.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/variables.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.variables import Variable\n\n@flow(log_prints=True)\ndef space_mission_sync(mission_name: str):\n    crew = Variable.get(\"crew_members\", default=[\"Backup1\", \"Backup2\"])\n    print(f\"Launching {mission_name} with crew: {', '.join(crew)}\")\n\nif __name__ == \"__main__\":\n    Variable.set(\"crew_members\", [\"Zaphod\", \"Arthur\", \"Trillian\"])\n    space_mission_sync(\"Mars Expedition\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Deployment Configuration in YAML\nDESCRIPTION: This YAML configuration defines a Prefect deployment for an ETL pipeline. It specifies the flow name, entrypoint file, scheduling with a daily cron pattern, and the target work pool for execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\n# prefect.yaml\ndeployments:\n  - name: etl-pipeline-prod\n    flow_name: etl_pipeline_flow\n    entrypoint: etl_flow.py:etl_pipeline_flow # file and function where the flow is defined\n    parameters: {}\n    schedule: \"@daily\"\n    work_pool:\n      name: prod-k8s-pool\n      # other infra settings like image, etc., if needed\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Branching in Prefect with Python Control Flow\nDESCRIPTION: This snippet demonstrates how to implement conditional branching in Prefect using native Python if/else logic instead of specialized operators like Airflow's BranchPythonOperator. This approach simplifies workflow design by leveraging standard Python control flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef my_flow():\n    result = extract_data()\n    if some_condition(result):\n        outcome = branch_task_a()  # a task or subflow for branch A\n    else:\n        outcome = branch_task_b()  # branch B\n    final_task(outcome)\n```\n\n----------------------------------------\n\nTITLE: Accessing Task Results with result() Method in Prefect\nDESCRIPTION: This code demonstrates how to access the result of a submitted task using the .result() method of the PrefectFuture object. The result() method blocks execution until the task completes and returns the result.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    return 42\n\n@flow\ndef my_flow():\n    future = my_task.submit()\n    result = future.result()\n    print(result)\n\nmy_flow()\n```\n\n----------------------------------------\n\nTITLE: Synchronous Database Operations Flow\nDESCRIPTION: Complete example of a synchronous Prefect flow performing database operations including table creation, data insertion, and data fetching.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_sqlalchemy import SqlAlchemyConnector\n\n\n@task\ndef setup_table(block_name: str) -> None:\n    with SqlAlchemyConnector.load(block_name) as connector:\n        connector.execute(\n            \"CREATE TABLE IF NOT EXISTS customers (name varchar, address varchar);\"\n        )\n        connector.execute(\n            \"INSERT INTO customers (name, address) VALUES (:name, :address);\",\n            parameters={\"name\": \"Marvin\", \"address\": \"Highway 42\"},\n        )\n        connector.execute_many(\n            \"INSERT INTO customers (name, address) VALUES (:name, :address);\",\n            seq_of_parameters=[\n                {\"name\": \"Ford\", \"address\": \"Highway 42\"},\n                {\"name\": \"Unknown\", \"address\": \"Highway 42\"},\n            ],\n        )\n\n@task\ndef fetch_data(block_name: str) -> list:\n    all_rows = []\n    with SqlAlchemyConnector.load(block_name) as connector:\n        while True:\n            new_rows = connector.fetch_many(\"SELECT * FROM customers\", size=2)\n            if len(new_rows) == 0:\n                break\n            all_rows.append(new_rows)\n    return all_rows\n\n@flow\ndef sqlalchemy_flow(block_name: str) -> list:\n    setup_table(block_name)\n    all_rows = fetch_data(block_name)\n    return all_rows\n\n\nif __name__ == \"__main__\":\n    sqlalchemy_flow(\"BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Prefect Deployment Configuration using prefect.yaml\nDESCRIPTION: This YAML file configures a Prefect deployment using a `prefect.yaml` file. It defines build and push steps for a Docker image, and then defines a deployment named \"my-deployment\" that uses the built image. It specifies the entrypoint to the flow within the `flow.py` file and configures the work pool and work queue.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: cicd-example\nprefect-version: 3.0.0\n\nbuild:\n  - prefect_docker.deployments.steps.build_docker_image:\n      id: build-image\n      requires: prefect-docker>=0.3.1\n      image_name: my_registry/my_image\n      tag: my_image_tag\n      dockerfile: auto\n\npush:\n  - prefect_docker.deployments.steps.push_docker_image:\n      requires: prefect-docker>=0.3.1\n      image_name: \"{{ build-image.image_name }}\"\n      tag: \"{{ build-image.tag }}\"\n\npull: null\n\ndeployments:\n  - name: my-deployment\n    entrypoint: flow.py:hello\n    work_pool:\n      name: my-work-pool\n      work_queue_name: default\n      job_variables:\n        image: \"{{ build-image.image }}\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Systemd Service for Prefect Worker\nDESCRIPTION: This snippet demonstrates how to create a systemd service unit file for a Prefect worker that will automatically restart.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n[Unit]\nDescription=Prefect worker\n\n[Service]\nUser=prefect\nWorkingDirectory=/home\nExecStart=prefect worker start --pool YOUR_WORK_POOL_NAME\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n----------------------------------------\n\nTITLE: Create and Save Block Documents\nDESCRIPTION: This snippet demonstrates how to create and save block documents, which are instantiations of a block type with specific values. It creates two `Cube` block documents, `rubiks_cube` and `tiny_cube`, and saves them to the Prefect server for future use using the `.save()` method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.core import Block\n\n\nclass Cube(Block):\n    edge_length_inches: float\n\n\n# instantiate the type with specific values\nrubiks_cube = Cube(edge_length_inches=2.25)\n\n# store those values in a block document \n# on the server for future use\nrubiks_cube.save(\"rubiks-cube\")\n\n\n# instantiate and save another block document\ntiny_cube = Cube(edge_length_inches=0.001)\ntiny_cube.save(\"tiny\")\n```\n\n----------------------------------------\n\nTITLE: Creating State Dependencies Between Tasks with wait_for Parameter in Prefect\nDESCRIPTION: This code demonstrates how to create state dependencies between tasks that don't share data dependencies using the wait_for parameter. This allows controlling the execution order of tasks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef task_a():\n    pass\n\n@task\ndef task_b():\n    pass\n\n@task\ndef task_c():\n    pass\n    \n@task\ndef task_d():\n    pass\n\n@flow\ndef my_flow():\n    a = task_a.submit()\n    b = task_b.submit()\n    # Wait for task_a and task_b to complete\n    c = task_c.submit(wait_for=[a, b])\n    # task_d will wait for task_c to complete\n    # Note: If waiting for one task it must still be in a list.\n    d = task_d(wait_for=[c])\n```\n\n----------------------------------------\n\nTITLE: Creating Prefect AWS Credentials Block with Python SDK\nDESCRIPTION: Python code to create an AWS Credentials block in Prefect, storing AWS access key ID and secret access key for authentication with AWS services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\n\n\nAwsCredentials(\n    aws_access_key_id=\"PLACEHOLDER\",  # Replace this with your access key id.\n    aws_secret_access_key=\"PLACEHOLDER\",  # Replace this with your secret access key.\n    region_name=\"us-east-2\"  # Replace this with your region.\n).save(\"BLOCK-NAME-PLACEHOLDER\")  # Replace this with a descriptive block name.\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Caching with TASK_SOURCE Policy in Prefect\nDESCRIPTION: Demonstrates how to use the TASK_SOURCE cache policy which bases caching solely on the task's code definition. This allows the task to run once and only once until its underlying code is altered.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE\n\nimport time\n\n\n@task(cache_policy=TASK_SOURCE)\ndef my_stateful_task():\n    print('sleeping')\n    time.sleep(10)\n    return 42\n\nmy_stateful_task() # sleeps\nmy_stateful_task() # does not sleep\n```\n\n----------------------------------------\n\nTITLE: BigQuery Interaction Example\nDESCRIPTION: Example flow demonstrating BigQuery operations including creating dataset, defining table, inserting rows, and fetching data.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_gcp.bigquery import GcpCredentials, BigQueryWarehouse\n\n@flow\ndef bigquery_flow():\n    all_rows = []\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\n    client = gcp_credentials.get_bigquery_client()\n    client.create_dataset(\"test_example\", exists_ok=True)\n\n    with BigQueryWarehouse(gcp_credentials=gcp_credentials) as warehouse:\n        warehouse.execute(\n            \"CREATE TABLE IF NOT EXISTS test_example.customers (name STRING, address STRING);\"\n        )\n        warehouse.execute_many(\n            \"INSERT INTO test_example.customers (name, address) VALUES (%(name)s, %(address)s);\",\n            seq_of_parameters=[\n                {\"name\": \"Marvin\", \"address\": \"Highway 42\"},\n                {\"name\": \"Ford\", \"address\": \"Highway 42\"},\n                {\"name\": \"Unknown\", \"address\": \"Highway 42\"},\n            ],\n        )\n        while True:\n            new_rows = warehouse.fetch_many(\"SELECT * FROM test_example.customers\", size=2)\n            if len(new_rows) == 0:\n                break\n            all_rows.extend(new_rows)\n    return all_rows\n\n\nif __name__ == \"__main__\":\n    bigquery_flow()\n```\n\n----------------------------------------\n\nTITLE: Load and Use a Block Class\nDESCRIPTION: This code shows how to load a block document as a Python class and use its methods. It loads the `rubiks-cube` block document as a `Cube` object and calls its `get_volume()` method to calculate the volume of the cube. It assumes that the `Cube` class has already been defined and the `rubiks-cube` document has been saved.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.core import Block\n\nclass Cube(Block):\n    edge_length_inches: float\n\n    def get_volume(self):\n        return self.edge_length_inches ** 3\n\n    def get_surface_area(self):\n        return 6 * self.edge_length_inches ** 2\n\n\nrubiks_cube = Cube.load(\"rubiks-cube\")\nrubiks_cube.get_volume() # 11.390625\n```\n\n----------------------------------------\n\nTITLE: Triggering a Prefect Flow Run\nDESCRIPTION: This bash command triggers a run of a specific deployment within Prefect.  The deployment is identified by its flow name and deployment name in the format 'flow_name/deployment_name'. This command initiates the execution of the deployed flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run 'my-flow/my-deployment'\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment with Deploy Method in Python\nDESCRIPTION: In this snippet, the 'deploy' method from the Prefect library is used to create a deployment that includes a work pool and Docker image. The flow 'my_flow' is set to push to a specified image and scheduled to run every minute.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow\ndef my_flow():\n    print(\"Hello, Prefect!\")\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-second-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-image\",\n        push=False,\n        cron=\"* * * * *\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Emitting Custom Events in Python with Prefect SDK\nDESCRIPTION: Demonstrates how to create and emit custom events using the Prefect Python SDK's emit_event function, allowing developers to track custom actions and resource interactions\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/events.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.events import emit_event\\n\\ndef some_function(name: str=\\\"kiki\\\") -> None:\\n    print(f\\\"hi {name}!\\\")\\n    emit_event(event=f\\\"{name}.sent.event!\\\", resource={\\\"prefect.resource.id\\\": f\\\"coder.{name}\\\"})\n```\n\n----------------------------------------\n\nTITLE: Creating or Updating Prefect Automation from YAML using Python\nDESCRIPTION: Python function to create or update a Prefect automation using a YAML file. It reads the YAML configuration and uses the Prefect API to create or update the automation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport yaml\n\nfrom myproject.utils import post, put\n\ndef create_or_update_automation(path: str = \"automation.yaml\"):\n    \"\"\"Create or update an automation from a local YAML file\"\"\"\n    # Load the definition\n    with open(path, \"r\") as fh:\n        payload = yaml.safe_load(fh)\n\n    # Find existing automations by name\n    automations = post(\"/automations/filter\")\n    existing_automation = [a[\"id\"] for a in automations if a[\"name\"] == payload[\"name\"]]\n    automation_exists = len(existing_automation) > 0\n\n    # Create or update the automation\n    if automation_exists:\n        print(f\"Automation '{payload['name']}' already exists and will be updated\")\n        put(f\"/automations/{existing_automation[0]}\", payload=payload)\n    else:\n        print(f\"Creating automation '{payload['name']}'\") \n        post(\"/automations/\", payload=payload)\n\nif __name__ == \"__main__\":\n    create_or_update_automation()\n```\n\n----------------------------------------\n\nTITLE: Basic DBT Core Runner Implementation\nDESCRIPTION: Simple implementation of PrefectDbtRunner for executing DBT Core commands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner().invoke([\"build\"])\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n----------------------------------------\n\nTITLE: Instantiate an S3Bucket Block\nDESCRIPTION: This code shows how to instantiate an `S3Bucket` block from the `prefect_aws.s3` module. It creates a block document that stores an S3 bucket name. The S3Bucket class is imported from prefect_aws.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws.s3 import S3Bucket\n\n# note that the S3Bucket contains many other fields\nbucket_block = S3Bucket(bucket_name=\"data-bucket\")\n```\n\n----------------------------------------\n\nTITLE: Loading Saved SQLAlchemy Connector\nDESCRIPTION: Example of loading a previously saved SQLAlchemy connector block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_sqlalchemy import SqlAlchemyConnector\n\nSqlAlchemyConnector.load(\"BLOCK_NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Idempotent Workflows with Prefect Transactions\nDESCRIPTION: This code demonstrates how to ensure functional idempotency by using transaction keys. The flow checks if a transaction has already been committed and exits early if so, preventing duplicate operations like API downloads.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef download_data():\n    \"\"\"Imagine this downloads some data from an API\"\"\"\n    return \"some data\"\n\n\n@task\ndef write_data(data: str):\n    \"\"\"This writes the data to a file\"\"\"\n    with open(\"data.txt\", \"w\") as f:\n        f.write(data)\n\n\n@flow(log_prints=True)\ndef pipeline():\n    with transaction(key=\"download-and-write-data\") as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_data(data)\n\n\nif __name__ == \"__main__\":\n    pipeline()\n```\n\n----------------------------------------\n\nTITLE: Pausing a Flow Run with Timeout in Prefect\nDESCRIPTION: This snippet demonstrates how to pause a Prefect flow run using the `pause_flow_run` function.  It defines two tasks, `marvin_setup` and `marvin_punchline`, and uses `pause_flow_run` to halt execution for a specified timeout period (10 minutes) before executing the punchline. The timeout parameter determines how long the flow run will remain paused before automatically failing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow, pause_flow_run, resume_flow_run\n\n@task\nasync def marvin_setup():\n    return \"a raft of ducks walk into a bar...\"\n\n\n@task\nasync def marvin_punchline():\n    return \"it's a wonder none of them ducked!\"\n\n\n@flow\nasync def inspiring_joke():\n    await marvin_setup()\n    await pause_flow_run(timeout=600)  # pauses for 10 minutes\n    await marvin_punchline()\n```\n\n----------------------------------------\n\nTITLE: Serializable Transaction Implementation in Python\nDESCRIPTION: Shows how to prevent race conditions using SERIALIZABLE isolation level with a FileSystemLockManager. This ensures that only one transaction with a given key can run at a time.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport threading\nimport uuid\nfrom prefect import flow, task\nfrom prefect.locking.filesystem import FileSystemLockManager\nfrom prefect.results import ResultStore\nfrom prefect.settings import PREFECT_HOME\nfrom prefect.transactions import IsolationLevel, transaction\n\n\n@task\ndef download_data():\n    return f\"{threading.current_thread().name} is the winner!\"\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"race-condition.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@flow\ndef pipeline(transaction_key: str):\n    with transaction(\n        key=transaction_key,\n        isolation_level=IsolationLevel.SERIALIZABLE,\n        store=ResultStore(\n            lock_manager=FileSystemLockManager(\n                lock_files_directory=PREFECT_HOME.value() / \"locks\"\n            )\n        ),\n    ) as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_file(data)\n\n\nif __name__ == \"__main__\":\n    transaction_key = f\"race-condition-{uuid.uuid4()}\"\n    thread_1 = threading.Thread(target=pipeline, name=\"Thread 1\", args=(transaction_key,))\n    thread_2 = threading.Thread(target=pipeline, name=\"Thread 2\", args=(transaction_key,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\n----------------------------------------\n\nTITLE: Load a Block with a Unique Slug\nDESCRIPTION: This snippet demonstrates how to load a block using its unique slug, which is a combination of the block type slug and the block name. It loads the `S3Bucket` block from the example above using the slug `s3-bucket/my_s3_bucket_block` and prints the bucket name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws.s3 import S3Bucket\n\ns3_block = Block.load(\"s3-bucket/my_s3_bucket_block\")\nprint(s3_bucket.bucket_name) # data-bucket\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from Azure Blob Storage without Storage Block\nDESCRIPTION: This code deploys a Prefect flow from an Azure Blob Storage container without using a storage block. It directly references the Azure container and includes the necessary prefect-azure dependency in the job variables.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"az://mycontainer/myfolder\",\n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"my-azure-deployment\",\n        work_pool_name=\"my-work-pool\",\n        job_variables={\"env\": {\"EXTRA_PIP_PACKAGES\": \"prefect-azure\"} }, \n    )\n```\n\n----------------------------------------\n\nTITLE: Prefect Work Pool Update via CLI\nDESCRIPTION: This code snippet shows how to update a Prefect work pool's base job template using the command line interface. The `prefect work-pool update` command is used with the `--base-job-template` option to specify the path to a JSON file containing the new base job template.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"prefect work-pool update --base-job-template base-job-template.json my-work-pool\"\n```\n\n----------------------------------------\n\nTITLE: Using result() with Error Handling in Prefect\nDESCRIPTION: This example shows how to handle potential task failures when using the result() method by setting raise_on_failure=False. This allows for custom handling of task failures by checking the task's state.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    return \"I'm a task!\"\n\n\n@flow\ndef my_flow():\n    future = my_task.submit()\n    result = future.result(raise_on_failure=False)\n    if future.state.is_failed():\n        # `result` is an exception! handle accordingly\n        ...\n    else:\n        # `result` is the expected return value of our task\n        ...\n```\n\n----------------------------------------\n\nTITLE: Run Get Most Recent Flow Example in Python\nDESCRIPTION: Illustrates how to use the `get_most_recent_flow_runs` function to retrieve the last 3 completed flow runs. Relies on asyncio to execute asynchronous code.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nflow_runs: list[FlowRun] = asyncio.run(\n    get_most_recent_flow_runs(n=3)\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing GitHub Repository Analysis Pipeline with Prefect\nDESCRIPTION: Complete implementation of a Prefect workflow that analyzes GitHub repository health metrics. Features include pagination of API requests, concurrent task execution, error handling, caching, and rate limiting. The flow fetches repository issues and calculates metrics like average response time and resolution rate.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta, datetime\nfrom statistics import mean\nfrom typing import List, Optional\nimport httpx\n\nfrom prefect import flow, task\nfrom prefect.tasks import task_input_hash\nfrom prefect.concurrency.sync import rate_limit\n\n\n@flow(log_prints=True)\ndef analyze_repo_health(repos: List[str]):\n    \"\"\"Analyze issue health metrics for GitHub repositories\"\"\"\n    for repo in repos:\n        print(f\"Analyzing {repo}...\")\n        \n        # Fetch and analyze all issues\n        issues = fetch_repo_issues(repo)\n        \n        # Calculate metrics\n        avg_response_time = calculate_response_times(issues)\n        resolution_rate = calculate_resolution_rate(issues)\n        \n        print(f\"Average response time: {avg_response_time:.1f} hours\")\n        print(f\"Resolution rate: {resolution_rate:.1f}%\")\n\n\n@flow\ndef fetch_repo_issues(repo: str):\n    \"\"\"Fetch all issues for a single repository\"\"\"\n    all_issues = []\n    page = 1\n    \n    for page in range(1, 3):  # Limit to 2 pages to avoid hitting rate limits\n        issues = fetch_page_of_issues(repo, page)\n        if not issues or len(issues) == 0:\n            break\n        all_issues.extend(issues)\n        page += 1\n\n    issue_details = []\n    for issue in all_issues[:5]:  # Limit to 5 issues to avoid hitting rate limits\n        issue_details.append(\n            fetch_issue_details.submit(repo, issue['number'])\n        )\n    \n    details = []\n    for issue in issue_details:\n        details.append(issue.result())\n\n    return details\n\n\n@task(log_prints=True, retries=3, cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))\ndef fetch_page_of_issues(repo: str, page: int = 1) -> Optional[dict]:\n    \"\"\"Fetch a page of issues for a GitHub repository\"\"\"\n    rate_limit(\"github-api\")\n    try:\n        response = httpx.get(\n            f\"https://api.github.com/repos/{repo}/issues\",\n            params={\"page\": page, \"state\": \"all\", \"per_page\": 100}\n        )\n        response.raise_for_status()\n        return response.json()\n    except Exception as e:\n        print(f\"Error fetching issues for {repo}: {e}\")\n        return None\n\n\n@task(retries=3, cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))\ndef fetch_issue_details(repo: str, issue_number: int) -> dict:\n    \"\"\"Fetch detailed information about a specific issue\"\"\"\n    rate_limit(\"github-api\")\n    response = httpx.get(f\"https://api.github.com/repos/{repo}/issues/{issue_number}\")\n    issue_data = response.json()\n    \n    # Fetch comments for the issue\n    comments = fetch_comments(issue_data['comments_url'])\n    issue_data['comments_data'] = comments\n    \n    return issue_data\n\n\n@task(log_prints=True, retries=3, cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))\ndef fetch_comments(comments_url: str) -> List[dict]:\n    \"\"\"Fetch comments for an issue\"\"\"\n    rate_limit(\"github-api\")\n    try:\n        response = httpx.get(comments_url)\n        response.raise_for_status()\n        return response.json()\n    except Exception as e:\n        print(f\"Error fetching comments: {e}\")\n        return []\n\n\n@task\ndef calculate_response_times(issues: List[dict]) -> float:\n    \"\"\"Calculate average time to first response for issues\"\"\"\n    response_times = []\n    \n    for issue in issues:\n        comments_data = issue.get('comments_data', [])\n        if comments_data:  # If there are comments\n            created = datetime.fromisoformat(issue['created_at'].replace('Z', '+00:00'))\n            first_comment = datetime.fromisoformat(\n                comments_data[0]['created_at'].replace('Z', '+00:00')\n            )\n            response_time = (first_comment - created).total_seconds() / 3600\n            response_times.append(response_time)\n\n    return mean(response_times) if response_times else 0\n\n\n@task\ndef calculate_resolution_rate(issues: List[dict]) -> float:\n    \"\"\"Calculate the percentage of closed issues\"\"\"\n    if not issues:\n        return 0\n    closed = sum(1 for issue in issues if issue['state'] == 'closed')\n    return (closed / len(issues)) * 100\n\n\nif __name__ == \"__main__\":\n    analyze_repo_health([\n        \"PrefectHQ/prefect\",\n        \"pydantic/pydantic\",\n        \"huggingface/transformers\"\n    ])\n```\n\n----------------------------------------\n\nTITLE: Jittered Exponential Backoff in Prefect Task\nDESCRIPTION: Demonstrates how to add jitter to exponential backoff delays to prevent thundering herd problems. Adds random variance up to 100% of the base delay time.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.tasks import exponential_backoff\n\n\n@task(\n    retries=3,\n    retry_delay_seconds=exponential_backoff(backoff_factor=10),\n    retry_jitter_factor=1,\n)\n\n\ndef some_task_with_exponential_backoff_retries():\n   (rest of code follows)\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment with Serve in Python\nDESCRIPTION: This snippet demonstrates how to create a simple deployment using the 'serve' method from the Prefect library. The flow defined here, 'my_flow', prints a message and is scheduled to run every minute using the cron syntax.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow\ndef my_flow():\n    print(\"Hello, Prefect!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.serve(name=\"my-first-deployment\", cron=\"* * * * *\")\n```\n\n----------------------------------------\n\nTITLE: Serving a Prefect Flow Locally in Python\nDESCRIPTION: This snippet demonstrates how to define and serve a Prefect flow locally. By calling the `serve` method, a deployment is created which monitors the Prefect server for work, executing tasks in isolated subprocesses. Dependencies include Prefect, and key parameters such as `name`, `tags`, `parameters`, and `interval` can be configured.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef hello_world(name: str = \"world\", goodbye: bool = False):\n    print(f\"Hello {name} from Prefect! 🤗\")\n\n    if goodbye:\n        print(f\"Goodbye {name}!\")\n\n\nif __name__ == \"__main__\":\n    # creates a deployment and starts a long-running\n    # process that listens for scheduled work\n    hello_world.serve(name=\"my-first-deployment\",\n        tags=[\"onboarding\"],\n        parameters={\"goodbye\": True},\n        interval=60\n    )\n```\n\n----------------------------------------\n\nTITLE: Sending Slack Notifications on Flow Failure in Prefect\nDESCRIPTION: This snippet shows how to use a state change hook to send a Slack notification when a Prefect flow fails. It demonstrates loading a Slack webhook block and sending a detailed notification message including flow run details and a link to the Prefect UI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.blocks.core import Block\nfrom prefect.settings import PREFECT_API_URL\n\ndef notify_slack(flow, flow_run, state):\n    slack_webhook_block = Block.load(\n        \"slack-webhook/my-slack-webhook\"\n    )\n\n    slack_webhook_block.notify(\n        (\n            f\"Your job {flow_run.name} entered {state.name} \"\n            f\"with message:\\n\\n\"\n            f\"See <https://{PREFECT_API_URL.value()}/flow-runs/\"\n            f\"flow-run/{flow_run.id}|the flow run in the UI>\\n\\n\"\n            f\"Tags: {flow_run.tags}\\n\\n\"\n            f\"Scheduled start: {flow_run.expected_start_time}\"\n        )\n    )\n\n@flow(on_failure=[notify_slack], retries=1)\ndef failing_flow():\n    raise ValueError(\"oops!\")\n\nif __name__ == \"__main__\":\n    failing_flow()\n```\n\n----------------------------------------\n\nTITLE: Parallel Data Processing with Prefect Concurrency Limits\nDESCRIPTION: Illustrates how to limit the number of parallel processing tasks using Prefect's concurrency context manager in an async function. The example ensures that only a specific number of data processing tasks run simultaneously by requesting multiple slots on a concurrency limit.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/global-concurrency-limits.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom prefect.concurrency.sync import concurrency\n\n\nasync def process_data(data):\n    print(f\"Processing: {data}\")\n    await asyncio.sleep(1)\n    return f\"Processed: {data}\"\n\n\nasync def main():\n    data_items = list(range(100))\n    processed_data = []\n\n    while data_items:\n        with concurrency(\"data-processing\", occupy=5):\n            chunk = [data_items.pop() for _ in range(5)]\n            processed_data += await asyncio.gather(\n                *[process_data(item) for item in chunk]\n            )\n\n    print(processed_data)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Configuring EventBridge Rule for Training Data Changes\nDESCRIPTION: JSON event pattern for an AWS EventBridge rule that triggers model training when new objects are uploaded to the S3 bucket for training data. This rule is essential for automating the training process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source\": [\"aws.s3\"],\n  \"detail-type\": [\"Object Created\"],\n  \"detail\": {\n    \"bucket\": {\n      \"name\": [\"prefect-ml-data\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Serving Multiple Prefect Tasks\nDESCRIPTION: Demonstrates serving multiple tasks using the `serve()` function from `prefect.task_worker`.  This allows a single task worker to listen for and execute runs of multiple different tasks. The example uses `add.map` and `multiply.map` with `deferred=True` to enqueue multiple task runs to the background.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.task_worker import serve\n\n@task(log_prints=True)\ndef add(a: int, b: int):\n    print(f\"{a} + {b} = {a + b}\")\n\n@task(log_prints=True)\ndef multiply(a: int, b: int):\n    print(f\"{a} * {b} = {a * b}\")\n\nA = [1, 2, 3]\nB = [4, 5, 6]\n\nadd.map(A, B, deferred=True) # background 3 task runs - i.e. zip(A, B)\nmultiply.map(A, B, deferred=True) # background 3 task runs - i.e. zip(A, B)\n\nserve(add, multiply) # start a task worker listening for both `add` and `multiply`\n```\n\n----------------------------------------\n\nTITLE: Updated MLB Flow with S3 Integration\nDESCRIPTION: Enhanced version of the MLB data processing flow that incorporates S3 upload and download tasks. This flow combines game data fetching with S3 storage operations in a complete pipeline.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@flow\ndef mlb_flow(team_name, start_date, end_date):\n    # Get recent games.\n    game_ids = get_recent_games(team_name, start_date, end_date)\n    \n    # Fetch boxscore for each game.\n    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]\n    \n    # Define file path for raw data.\n    today = datetime.now().strftime(\"%Y-%m-%d\")  # This uses the current date in the format YYYY-MM-DD.\n    flow_run_name = runtime.flow_run.name\n    raw_file_path = f\"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json\"\n    \n    # Save raw data to a local folder.\n    save_raw_data_to_file(game_data, raw_file_path)\n    \n    # Upload raw data to s3.\n    s3_file_path = upload_raw_data_to_s3(raw_file_path)\n    \n    # Download raw data from s3.\n    raw_data = download_raw_data_from_s3(s3_file_path)\n\nif __name__ == \"__main__\":\n    mlb_flow(\"marlins\", '06/01/2024', '06/30/2024')\n```\n\n----------------------------------------\n\nTITLE: Combining Cache Policies in Prefect Tasks\nDESCRIPTION: Demonstrates how to combine multiple cache policies (TASK_SOURCE and INPUTS) to create a more complex caching behavior. The task will rerun when either inputs change or the code changes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE, INPUTS\n@task(cache_policy=TASK_SOURCE + INPUTS)\ndef my_cached_task(x: int):\n    return x + 42\n```\n\n----------------------------------------\n\nTITLE: Configuring Job Variables in Prefect Flow Deployment\nDESCRIPTION: Shows how to set default job variables for a Prefect flow deployment using the job_variables keyword argument. Demonstrates environment variable configuration and infrastructure customization.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom prefect import flow\n\n\n@flow\ndef my_flow():\n    name = os.getenv(\"NAME\", \"world\")\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        # Will print \"Hello, Marvin!\" by default instead of \"Hello, world!\"\n        job_variables={\"env\": {\"NAME\": \"Marvin\"}},\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n    )\n```\n\n----------------------------------------\n\nTITLE: Demonstrating READ_COMMITTED Cache Isolation in Python with Prefect\nDESCRIPTION: This snippet demonstrates the default READ_COMMITTED cache isolation level in Prefect. It shows how concurrent task runs can execute simultaneously despite using the same cache key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import INPUTS\nimport threading\n\n\ncache_policy = INPUTS\n\n@task(cache_policy=cache_policy)\ndef my_task_version_1(x: int):\n    print(\"my_task_version_1 running\")\n    return x + 42\n\n@task(cache_policy=cache_policy)\ndef my_task_version_2(x: int):\n    print(\"my_task_version_2 running\")\n    return x + 43\n\nif __name__ == \"__main__\":\n    thread_1 = threading.Thread(target=my_task_version_1, args=(1,))\n    thread_2 = threading.Thread(target=my_task_version_2, args=(1,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequence Trigger with Compound Trigger in Prefect\nDESCRIPTION: A sequence trigger that first waits for a specific flow to complete before starting to watch for three file-writing events from other flows. The sequence must complete within two hours and the compound events within one hour.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  // the outer trigger is now a \"sequence\" trigger\n  \"type\": \"sequence\",\n  \"within\": 7200,\n  \"triggers\": [\n    // with the first child trigger expecting a Completed event\n    {\n      \"type\": \"event\",\n      \"posture\": \"Reactive\",\n      \"expect\": [\"prefect.flow-run.Completed\"],\n      \"match_related\": {\n        \"prefect.resource.name\": \"daily-export-initiator\",\n        \"prefect.resource.role\": \"flow\"\n      }\n    },\n    // and the second child trigger being the compound trigger from the prior example\n    {\n      \"type\": \"compound\",\n      \"require\": \"all\",\n      \"within\": 3600,\n      \"triggers\": [\n        {\n          \"type\": \"event\",\n          \"posture\": \"Reactive\",\n          \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n          \"match_related\": {\n            \"prefect.resource.name\": \"daily-customer-export\",\n            \"prefect.resource.role\": \"flow\"\n          }\n        },\n        {\n          \"type\": \"event\",\n          \"posture\": \"Reactive\",\n          \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n          \"match_related\": {\n            \"prefect.resource.name\": \"daily-revenue-export\",\n            \"prefect.resource.role\": \"flow\"\n          }\n        },\n        {\n          \"type\": \"event\",\n          \"posture\": \"Reactive\",\n          \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n          \"match_related\": {\n            \"prefect.resource.name\": \"daily-expenses-export\",\n            \"prefect.resource.role\": \"flow\"\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Static Webhook Template Using JSON\nDESCRIPTION: This JSON template is used in a Prefect webhook to notify when a machine learning model is updated. It statically defines the event name and resource identifiers for a specific recommendation model by the Data Science team. There's no need for dynamic request handling, making it suitable for systems with constrained capabilities. The output is a Prefect event in the cloud workspace each time it's triggered.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"event\": \"model.refreshed\",\n    \"resource\": {\n        \"prefect.resource.id\": \"product.models.recommendations\",\n        \"prefect.resource.name\": \"Recommendations [Products]\",\n        \"producing-team\": \"Data Science\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Email Sending Flow\nDESCRIPTION: Example flow demonstrating how to send emails using the email_send_message task.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_email import EmailServerCredentials, email_send_message\n\n\n@flow\ndef example_email_send_message_flow(email_addresses):\n    email_server_credentials = EmailServerCredentials.load(\"BLOCK-NAME-PLACEHOLDER\")\n    for email_address in email_addresses:\n        subject = email_send_message.with_options(name=f\"email {email_address}\").submit(\n            email_server_credentials=email_server_credentials,\n            subject=\"Example Flow Notification using Gmail\",\n            msg=\"This proves email_send_message works!\",\n            email_to=email_address,\n        )\n\n\nif __name__ == \"__main__\":\n    example_email_send_message_flow([\"EMAIL-ADDRESS-PLACEHOLDER\"])\n```\n\n----------------------------------------\n\nTITLE: Data Ingestion with Pagination in Prefect Flow\nDESCRIPTION: This code shows how to ingest large amounts of data using pagination with the GitHub API. It demonstrates a Prefect flow that fetches multiple pages of issues for multiple repositories and submits analysis tasks concurrently to improve efficiency.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef analyze_repo_health(repos: List[str]):\n    \"\"\"Analyze issue health metrics for GitHub repositories\"\"\"\n    all_issues = []\n\n    for repo in repos:\n        for page in range(1, 3):  # Get first 2 pages\n            issues = fetch_page_of_issues(repo, page)\n            if not issues:\n                break\n            all_issues.extend(issues)\n    \n    # Run issue analysis tasks concurrently\n    for issue in all_issues:\n        analyze_issue.submit(issue) # Submit each task to a task runner\n    \n    # Wait for all analysis tasks to complete\n    for detail in issue_details:\n        result = detail.result() # Block until the task has completed\n        print(f\"Analyzed issue #{result['number']}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing S3 Data Transfer Tasks with Prefect\nDESCRIPTION: Defines tasks for uploading and downloading data to/from S3 using Prefect's S3Bucket integration. These tasks handle the transfer of MLB game data between local storage and S3 bucket storage.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef upload_raw_data_to_s3(file_path):\n    '''This task will upload the raw data to s3.'''\n    \n    s3_bucket = S3Bucket.load(\"mlb-raw-data\")  # Replace this with your S3 bucket block name.\n    s3_bucket_path = s3_bucket.upload_from_path(file_path)\n    \n    print(s3_bucket_path)\n    return s3_bucket_path\n    \n\n@task\ndef download_raw_data_from_s3(s3_file_path):\n    '''Download the raw data from s3.'''\n    \n    s3_bucket = S3Bucket.load(\"mlb-raw-data\")  # Replace this with your S3 bucket block name.\n    local_file_path = f\"./boxscore_analysis/{s3_file_path}\"\n    s3_bucket.download_object_to_path(s3_file_path, local_file_path)\n    \n    return local_file_path\n```\n\n----------------------------------------\n\nTITLE: Running a Kubernetes Job from YAML with Prefect Flow\nDESCRIPTION: Demonstrates how to specify a Kubernetes Job using a YAML file, create a Prefect flow to run the job, and execute it. Includes handling of credentials and logging.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, get_run_logger\nfrom prefect_kubernetes.credentials import KubernetesCredentials\nfrom prefect_kubernetes.flows import run_namespaced_job # this is a flow\nfrom prefect_kubernetes.jobs import KubernetesJob\n\nk8s_creds = KubernetesCredentials.load(\"k8s-creds\")\n\njob = KubernetesJob.from_yaml_file( # or create in the UI with a dict manifest\n    credentials=k8s_creds,\n    manifest_path=\"path/to/job.yaml\",\n)\n\njob.save(\"my-k8s-job\", overwrite=True)\n\n\n@flow\ndef kubernetes_orchestrator():\n    # run the flow and send logs to the parent flow run's logger\n    logger = get_run_logger()\n    run_namespaced_job(job, print_func=logger.info)\n\n\nif __name__ == \"__main__\":\n    kubernetes_orchestrator()\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private GitHub Repository with Secret Block\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a private GitHub repository using a Secret block for authentication. It loads a secret containing a GitHub access token and creates a GitRepository object with the repository URL and credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect.blocks.system import Secret\n\n\nif __name__ == \"__main__\":\n\n    github_repo = GitRepository(\n        url=\"https://github.com/org/my-private-repo.git\",\n        credentials={\n            \"access_token\": Secret.load(\"my-secret-block-with-my-gh-credentials\")\n        },\n    )\n\n    flow.from_source(\n        source=github_repo,\n        entrypoint=\"gh_private_repo_secret_block.py:my_flow\",\n    ).deploy(\n        name=\"private-github-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Handling Non-Serializable Objects with Custom Cache Key Function in Python\nDESCRIPTION: This snippet shows how to handle non-serializable objects in Prefect cache keys using a custom cache key function. It demonstrates creating a task that can work with objects containing non-serializable components.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.cache_policies import CacheKeyFnPolicy, RUN_ID\nfrom prefect.context import TaskRunContext\nfrom pydantic import BaseModel, ConfigDict\n\nclass NotSerializable:\n    def __getstate__(self):\n        raise TypeError(\"NooOoOOo! I will not be serialized!\")\n\nclass ContainsNonSerializableObject(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str\n    bad_object: NotSerializable\n\ndef custom_cache_key_fn(context: TaskRunContext, parameters: dict) -> str:\n    return parameters[\"some_object\"].name\n\n@task(cache_policy=CacheKeyFnPolicy(cache_key_fn=custom_cache_key_fn) + RUN_ID)\ndef use_object(some_object: ContainsNonSerializableObject) -> str:\n    return f\"Used {some_object.name}\"\n\n\n@flow\ndef demo_flow():\n    obj = ContainsNonSerializableObject(name=\"test\", bad_object=NotSerializable())\n    state = use_object(obj, return_state=True) # Not cached!\n    assert state.name == \"Completed\"\n    other_state = use_object(obj, return_state=True) # Cached!\n    assert other_state.name == \"Cached\"\n    assert state.result() == other_state.result()\n```\n\n----------------------------------------\n\nTITLE: Python Flow Execution for Prefect with Coiled\nDESCRIPTION: Defines and deploys a Prefect flow using Coiled for execution, specifying Docker image and work pool. Requires Prefect and Coiled libraries.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n#example_flow.py\nfrom prefect import flow, task\n\n@task\ndef f(n):\n    return n**2\n\n@task\ndef do_something(x):\n    print(x)\n\n@flow(log_prints=True)\ndef my_flow():\n    print(\"Hello from your Prefect flow!\")\n    X = f.map(list(range(10)))\n    do_something(X)\n    return X\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"example-coiled-deployment\",\n        work_pool_name=\"example-coiled-pool\",\n        image=\"my-image\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Registering an On-Commit Hook for Prefect Tasks\nDESCRIPTION: This example shows how to register an on_commit hook that executes whenever a task's transaction is committed. The hook provides confirmation of the transaction commitment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@write_file.on_commit\ndef confirmation(transaction):\n    print(\"committing a record now using the task's cache key!\")\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Prefect Task Implementation\nDESCRIPTION: Example of creating an asynchronous task using async/await syntax with the @task decorator.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nimport asyncio\n\n\n@task\nasync def print_message():\n    await asyncio.sleep(1)\n    print(\"Hello, I'm an async task\")\n\n\nasyncio.run(print_message())\n```\n\n----------------------------------------\n\nTITLE: Using Custom Python Module for Secret Retrieval in Prefect YAML\nDESCRIPTION: This example demonstrates using a custom Python module packaged into a Docker image to retrieve secrets using the Azure Python SDK.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n- retrieve_secrets.main:\n    id: get-access-token\n- prefect.deployments.steps.git_clone:\n    repository: https://bitbucket.org/samples/deployments.git\n    branch: master\n    access_token: '{{ get-access-token.access_token }}'\n```\n\n----------------------------------------\n\nTITLE: Implementing Order Completion Deployment in Prefect\nDESCRIPTION: Python script that creates a deployment triggered when a user completes an order. It demonstrates conditional event triggering with parameters passed from the event to the flow, using for_each to track per-user events.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.events.schemas.deployment_triggers import DeploymentEventTrigger\n\norder_complete = DeploymentEventTrigger(\n    expect={\"order.complete\"},\n    after={\"order.created\"},\n    for_each={\"prefect.resource.id\"},\n    parameters={\"user_id\": \"{{ event.resource.id }}\"},\n)\n\n\n@flow(log_prints=True)\ndef post_order_complete(user_id: str):\n    print(f\"User {user_id} has completed an order -- doing stuff now\")\n\n\nif __name__ == \"__main__\":\n    post_order_complete.serve(triggers=[order_complete])\n```\n\n----------------------------------------\n\nTITLE: Mermaid Diagram of Work Pool Deployment\nDESCRIPTION: This code snippet represents a Mermaid diagram illustrating the conceptual elements involved in a work-pool-based deployment. It visually outlines the relationship between the Deployment Definition, Prefect API (Deployment), Remote Storage (Flow Code), Worker, and Infrastructure (Flow Run).\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\n \"%%{\n  init: {\n    'theme': 'neutral',\n    'themeVariables': {\n      'margin': '10px'\n    }\n  }\n}%%\n\nflowchart LR\n\n    B(Deployment Definition)\n\n    subgraph Server [Prefect API]\n        C(Deployment)\n    end\n\n    subgraph Remote Storage [Remote Storage]\n        D(Flow Code)\n    end\n\n    E(Worker)\n\n    subgraph Infrastructure [Infrastructure]\n        F((Flow Run))\n    end\n\n    B --> C\n    B -.-> D\n    C --> E\n    D -.-> E\n    E -.-> F\"\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from AWS S3 with Storage Block\nDESCRIPTION: This code deploys a Prefect flow from an AWS S3 bucket using an S3Bucket storage block. It shows how to either load an existing storage block or create a new one with credentials. It also demonstrates how to include required dependencies through job variables.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws.s3 import S3Bucket\n\nif __name__ == \"__main__\":\n    s3_bucket_block = S3Bucket.load(\"my-code-storage-block\")\n\n    # or:\n    # s3_bucket_block = S3Bucket(\n    #     bucket=\"my-bucket\",\n    #     folder=\"my-folder\",\n    #     credentials=AWSCredentials.load(\"my-credentials-block\")\n    # )\n\n    flow.from_source(\n        source=s3_bucket_block, \n        entrypoint=\"my_file.py:my_flow\"\n    ).deploy(\n        name=\"my-aws-s3-deployment\", \n        work_pool_name=\"my-work-pool\"\n        job_variables={\"env\": {\"EXTRA_PIP_PACKAGES\": \"prefect-aws\"} }, \n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Link Artifacts in Prefect Flow\nDESCRIPTION: Demonstrates how to create link artifacts with keys to track artifact history, including optional link text and descriptions. Used for tracking data sources and external resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.artifacts import create_link_artifact\n\n\n@task\ndef my_first_task():\n        create_link_artifact(\n            key=\"irregular-data\",\n            link=\"https://nyc3.digitaloceanspaces.com/my-bucket-name/highly_variable_data.csv\",\n            description=\"## Highly variable data\",\n        )\n\n\n@task\ndef my_second_task():\n        create_link_artifact(\n            key=\"irregular-data\",\n            link=\"https://nyc3.digitaloceanspaces.com/my-bucket-name/low_pred_data.csv\",\n            description=\"# Low prediction accuracy\",\n        )\n\n\n@flow\ndef my_flow():\n    my_first_task()\n    my_second_task()\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Creating a Compound Trigger with Multiple Event Conditions in Prefect\nDESCRIPTION: A compound trigger that fires when three different flows have written their results to a remote filesystem. The trigger requires all underlying events to occur within an hour and resets after firing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"compound\",\n  \"require\": \"all\",\n  \"within\": 3600,\n  \"triggers\": [\n    {\n      \"type\": \"event\",\n      \"posture\": \"Reactive\",\n      \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n      \"match_related\": {\n        \"prefect.resource.name\": \"daily-customer-export\",\n        \"prefect.resource.role\": \"flow\"\n      }\n    },\n    {\n      \"type\": \"event\",\n      \"posture\": \"Reactive\",\n      \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n      \"match_related\": {\n        \"prefect.resource.name\": \"daily-revenue-export\",\n        \"prefect.resource.role\": \"flow\"\n      }\n    },\n    {\n      \"type\": \"event\",\n      \"posture\": \"Reactive\",\n      \"expect\": [\"prefect.block.remote-file-system.write_path.called\"],\n      \"match_related\": {\n        \"prefect.resource.name\": \"daily-expenses-export\",\n        \"prefect.resource.role\": \"flow\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Exponential Backoff Retry in Python Task\nDESCRIPTION: Python code snippet demonstrating how to implement an exponential backoff retry strategy using the exponential_backoff utility in the @task decorator.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@task(retries=4, retry_delay_seconds=exponential_backoff(backoff_factor=2))\ndef get_recent_games(team_name, start_date, end_date):\n    # Simulate random API failure (70% chance).\n    if random.random() < 0.1:\n        raise Exception(\"Simulated API failure: MLB Stats API is temporarily unavailable\")\n    \n    # Get all games for the provided team and date range.\n    team = statsapi.lookup_team(team_name)\n    schedule = statsapi.schedule(team=team[0][\"id\"], start_date=start_date, end_date=end_date)\n    for game in schedule:\n        print(game['game_id'])\n    return [game['game_id'] for game in schedule]\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Task Caching with Expiration in Prefect\nDESCRIPTION: This snippet demonstrates how to implement basic caching for a Prefect task with a cache expiration time. The task caches results based on input arguments and returns cached values for repeated calls with the same input.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta\nfrom prefect import flow, task\nfrom prefect.cache_policies import INPUTS\n@task(cache_policy=INPUTS, cache_expiration=timedelta(days=1))\ndef hello_task(name_input):\n    # Doing some work\n    print(\"Saying hello\")\n    return \"hello \" + name_input\n\n@flow(log_prints=True)\ndef hello_flow(name_input):\n    hello_task(name_input)\n    hello_task(name_input) # does not rerun\n```\n\n----------------------------------------\n\nTITLE: Parallel Flow Implementation with DaskTaskRunner\nDESCRIPTION: Enhanced version of the image download flow using DaskTaskRunner for parallel execution. Demonstrates how to parallelize tasks using Dask integration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom pathlib import Path\n\nimport httpx\nfrom prefect import flow, task\nfrom prefect_dask import DaskTaskRunner\n\nURL_FORMAT = (\n    \"https://www.cpc.ncep.noaa.gov/products/NMME/archive/\"\n    \"{year:04d}{month:02d}0800/current/images/nino34.rescaling.ENSMEAN.png\"\n)\n\n@task\ndef download_image(year: int, month: int, directory: Path) -> Path:\n    # download image from URL\n    url = URL_FORMAT.format(year=year, month=month)\n    resp = httpx.get(url)\n\n    # save content to directory/YYYYMM.png\n    file_path = (directory / url.split(\"/\")[-1]).with_stem(f\"{year:04d}{month:02d}\")\n    file_path.write_bytes(resp.content)\n    return file_path\n\n@flow(task_runner=DaskTaskRunner(cluster_kwargs={\"processes\": False}))\ndef download_nino_34_plumes_from_year(year: int) -> List[Path]:\n    # create a directory to hold images\n    directory = Path(\"data\")\n    directory.mkdir(exist_ok=True)\n\n    # download all images\n    file_paths = []\n    for month in range(1, 12 + 1):\n        file_path = download_image.submit(year, month, directory)\n        file_paths.append(file_path)\n    return file_paths\n\nif __name__ == \"__main__\":\n    download_nino_34_plumes_from_year(2022)\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple Retry in Python Task\nDESCRIPTION: Python code snippet demonstrating how to implement a simple retry strategy using the @task decorator in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@task(retries=10)\ndef get_recent_games(team_name, start_date, end_date):\n     # Simulate random API failure (70% chance).\n    if random.random() < 0.7:\n        time.sleep(2)  # Add a delay to see the retries in action.\n        raise Exception(\"Simulated API failure: MLB Stats API is temporarily unavailable\")\n    \n    # Get all games for the provided team and date range.\n    team = statsapi.lookup_team(team_name)\n    schedule = statsapi.schedule(team=team[0][\"id\"], start_date=start_date, end_date=end_date)\n    for game in schedule:\n        print(game['game_id'])\n    return [game['game_id'] for game in schedule]\n```\n\n----------------------------------------\n\nTITLE: Markdown Artifact Generation Task in Python\nDESCRIPTION: Task for creating markdown artifacts to visualize game analysis results in the Prefect Cloud UI. Includes formatting for key statistics and metrics from the analysis.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef game_analysis_artifact(game_analysis, game_data_path):\n    '''This task will create an artifact with the game analysis.'''\n    \n    # First read the JSON data from the file.\n    with open(game_data_path, 'r') as f:\n        game_data = json.load(f)\n    \n    # Now create the DataFrame from the loaded data.\n    df = pd.DataFrame(game_data)\n    \n    # Create the markdown report.\n    markdown_report=f\"\"\" # Game Analysis Report\n## Search Parameters\nSearch Start Date: {game_analysis['search_start_date']}\nSearch End Date: {game_analysis['search_end_date']}\nChosen Team Name: {game_analysis['chosen_team_name']}\n\n## Summary Statistics\nMax game time: {game_analysis['max_game_time']:.2f}\nMin game time: {game_analysis['min_game_time']:.2f}\nMedian game time: {game_analysis['median_game_time']:.2f}\nAverage game time: {game_analysis['average_game_time']:.2f}\nMax differential: {game_analysis['max_differential']:.2f}\nMin differential: {game_analysis['min_differential']:.2f}\nMedian differential: {game_analysis['median_differential']:.2f}\nAverage differential: {game_analysis['average_differential']:.2f}\nCorrelation between game time and score differential: {game_analysis['time_differential_correlation']:.2f}\n\"\n```\n\n----------------------------------------\n\nTITLE: AWS ECS Deployment Script Example\nDESCRIPTION: Python script demonstrating how to deploy a flow to the AWS ECS work pool using the provisioned infrastructure. The script builds and pushes a Docker image to the ECR registry with automatic namespace handling.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.docker import DockerImage\n\n@flow(log_prints=True)            \ndef my_flow(name: str = \"world\"):                          \n    print(f\"Hello {name}! I'm a flow running in a ECS task!\") \n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\", \n        work_pool_name=\"my-work-pool\",\n        image=DockerImage(                                                 \n            name=\"my-repository:latest\",\n            platform=\"linux/amd64\",\n        )                                                                      \n    )       \n```\n\n----------------------------------------\n\nTITLE: Generator Tasks in Prefect\nDESCRIPTION: Example of implementing generator tasks that can yield values to be consumed by other tasks in the workflow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n\n@task\ndef generator():\n    for i in range(10):\n        yield i\n\n\n@task\ndef consumer(x):\n    print(x)\n\n\nfor val in generator():\n    consumer(val)\n```\n\n----------------------------------------\n\nTITLE: Suspending a Prefect Flow Run with Reschedule\nDESCRIPTION: This snippet demonstrates how to suspend a Prefect flow run using the `suspend_flow_run` function, combined with task persistence and rescheduling. The `foo` task is defined with `persist_result=True` to cache its result. The `noblock_pausing` flow suspends execution using `pause_flow_run` with `reschedule=True`, causing the flow to exit and be rescheduled for later resumption. The timeout parameter determines how long the flow run will remain suspended before automatically failing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, pause_flow_run, task\n\n@task(persist_result=True)\ndef foo():\n    return 42\n\n@flow(persist_result=True)\ndef noblock_pausing():\n    x = foo.submit()\n    pause_flow_run(timeout=30, reschedule=True)\n    y = foo.submit()\n    z = foo(wait_for=[x])\n    alpha = foo(wait_for=[y])\n    omega = foo(wait_for=[x, y])\n```\n\n----------------------------------------\n\nTITLE: Setting Up Metric Trigger for Production Flow Run Failures in JSON\nDESCRIPTION: Defines a metric trigger monitoring Prefect workspace flows for a failure rate using 'metric' parameters such as 'name', 'threshold', 'operator', 'range', and 'firing_for'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"metric\",\n  \"match\": {\n    \"prefect.resource.id\": \"prefect.flow-run.*\"\n  },\n  \"match_related\": {\n    \"prefect.resource.id\": \"prefect.tag.production\",\n    \"prefect.resource.role\": \"tag\"\n  },\n  \"metric\": {\n    \"name\": \"successes\",\n    \"threshold\": 0.9,\n    \"operator\": \"<\",\n    \"range\": 3600,\n    \"firing_for\": 0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sending Slack Messages in Asynchronous Prefect Flow\nDESCRIPTION: Example of an asynchronous Prefect flow that sends a Slack message upon completion. It demonstrates the use of SlackCredentials and the send_chat_message function in an async context.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-slack/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.context import get_run_context\nfrom prefect_slack import SlackCredentials\nfrom prefect_slack.messages import send_chat_message\n\n\n@flow\nasync def example_send_message_flow():\n   context = get_run_context()\n\n   # Run other tasks or flows here\n\n   token = \"xoxb-your-bot-token-here\"\n   await send_chat_message(\n        slack_credentials=SlackCredentials(token),\n        channel=\"#prefect\",\n        text=f\"Flow run {context.flow_run.name} completed :tada:\"\n   )\n\nif __name__ == \"__main__\":\n    asyncio.run(example_send_message_flow())\n```\n\n----------------------------------------\n\nTITLE: Define a Custom Block Type\nDESCRIPTION: This code shows how to define a custom block type by subclassing the `Block` class. It defines a `Cube` block with an `edge_length_inches` field. It then registers the block type and schema, making it available for use in Prefect workflows. It builds on Pydantic's `BaseModel`.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.core import Block\n\nclass Cube(Block):\n    edge_length_inches: float\n\n\nCube.register_type_and_schema()\n```\n\n----------------------------------------\n\nTITLE: Conditional Pause Implementation in Prefect Flow\nDESCRIPTION: This snippet shows how to conditionally pause a Prefect flow based on the state of a task. It submits `task_one`, checks its terminal state, and pauses the flow only if the task completes successfully, using `pause_flow_run`. The timeout parameter specifies the maximum duration the flow will remain paused.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow, pause_flow_run\n\n@task\ndef task_one():\n    for i in range(3):\n        sleep(1)\n        print(i)\n\n@flow(log_prints=True)\ndef my_flow():\n    terminal_state = task_one.submit(return_state=True)\n    if terminal_state.type == StateType.COMPLETED:\n        print(\"Task one succeeded! Pausing flow run..\")\n        pause_flow_run(timeout=2)\n    else:\n        print(\"Task one failed. Skipping pause flow run..\")\n```\n\n----------------------------------------\n\nTITLE: Base Structure for prefect.yaml\nDESCRIPTION: This YAML structure defines the metadata and steps necessary for deployment configurations in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# generic metadata\nprefect-version: null\nname: null\n\n# preparation steps\nbuild: null\npush: null\n\n# runtime steps\npull: null\n\n# deployment configurations\ndeployments:\n- # base metadata\n  name: null\n  version: null\n  tags: []\n  description: null\n  schedule: null\n\n  # flow-specific fields\n  entrypoint: null\n  parameters: {}\n\n  # infra-specific fields\n  work_pool:\n    name: null\n    work_queue_name: null\n    job_variables: {}\n```\n\n----------------------------------------\n\nTITLE: Complete Flow Implementation with Rate Limiting\nDESCRIPTION: A full example of a Prefect flow with rate limiting applied to API requests. This implementation prevents hitting GitHub API rate limits while still benefiting from concurrent task execution and retry logic.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nimport httpx\nfrom prefect import flow, task\nfrom prefect.concurrency.sync import rate_limit\n\n@task(retries=3)\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    rate_limit(\"github-api\")\n    return httpx.get(f\"https://api.github.com/repos/{github_repo}\").json()\n\n\n@task\ndef get_stars(repo_stats: dict[str, Any]) -> int:\n    \"\"\"Task 2: Get the number of stars from GitHub repo statistics\"\"\"\n    return repo_stats[\"stargazers_count\"]\n\n\n@flow(log_prints=True)\ndef show_stars(github_repos: list[str]) -> None:\n    \"\"\"Flow: Show number of GitHub repo stars\"\"\"\n\n    # Task 1: Make HTTP requests concurrently\n    stats_futures = fetch_stats.map(github_repos)\n\n    # Task 2: Once each concurrent task completes, get the star counts\n    stars = get_stars.map(stats_futures).result()\n\n    # Show the results\n    for repo, star_count in zip(github_repos, stars):\n        print(f\"{repo}: {star_count} stars\")\n\n\n# Run the flow\nif __name__ == \"__main__\":\n    show_stars([\n        \"PrefectHQ/prefect\",\n        \"pydantic/pydantic\",\n        \"huggingface/transformers\"\n    ])\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Database Operations Flow\nDESCRIPTION: Complete example of an asynchronous Prefect flow performing database operations including table creation, data insertion, and data fetching.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_sqlalchemy import SqlAlchemyConnector\nimport asyncio\n\n\n@task\nasync def setup_table(block_name: str) -> None:\n    async with await SqlAlchemyConnector.load(block_name) as connector:\n        await connector.execute(\n            \"CREATE TABLE IF NOT EXISTS customers (name varchar, address varchar);\"\n        )\n        await connector.execute(\n            \"INSERT INTO customers (name, address) VALUES (:name, :address);\",\n            parameters={\"name\": \"Marvin\", \"address\": \"Highway 42\"},\n        )\n        await connector.execute_many(\n            \"INSERT INTO customers (name, address) VALUES (:name, :address);\",\n            seq_of_parameters=[\n                {\"name\": \"Ford\", \"address\": \"Highway 42\"},\n                {\"name\": \"Unknown\", \"address\": \"Highway 42\"},\n            ],\n        )\n\n@task\nasync def fetch_data(block_name: str) -> list:\n    all_rows = []\n    async with await SqlAlchemyConnector.load(block_name) as connector:\n        while True:\n            new_rows = await connector.fetch_many(\"SELECT * FROM customers\", size=2)\n            if len(new_rows) == 0:\n                break\n            all_rows.append(new_rows)\n    return all_rows\n\n@flow\nasync def sqlalchemy_flow(block_name: str) -> list:\n    await setup_table(block_name)\n    all_rows = await fetch_data(block_name)\n    return all_rows\n\n\nif __name__ == \"__main__\":\n    asyncio.run(sqlalchemy_flow(\"BLOCK-NAME-PLACEHOLDER\"))\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Cache Storage in Prefect\nDESCRIPTION: Demonstrates how to configure a custom local storage location for cache records separate from task results using the .configure method with a key_storage argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE, INPUTS\n\ncache_policy = (TASK_SOURCE + INPUTS).configure(key_storage=\"/path/to/cache/storage\")\n\n@task(cache_policy=cache_policy)\ndef my_cached_task(x: int):\n    return x + 42\n```\n\n----------------------------------------\n\nTITLE: Creating Modal Push Work Pool with Infrastructure Provisioning\nDESCRIPTION: This command creates a new push work pool for Modal with automatic infrastructure provisioning. It sets up a ModalCredentials block in the Prefect Cloud workspace.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type modal:push --provision-infra my-modal-pool\n```\n\n----------------------------------------\n\nTITLE: Reusing Configuration with YAML Aliases in prefect.yaml\nDESCRIPTION: Example of using YAML aliases to share configuration across multiple deployments, including work pools, schedules, and build actions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nbuild: ...\npush: ...\npull: ...\n\ndefinitions:\n    work_pools:\n        my_docker_work_pool: &my_docker_work_pool\n            name: my-docker-work-pool\n            work_queue_name: default\n            job_variables:\n                image: \"{{ build-image.image }}\"\n    schedules:\n        every_ten_minutes: &every_10_minutes\n            interval: 600\n    actions:\n        docker_build: &docker_build\n            - prefect_docker.deployments.steps.build_docker_image: &docker_build_config\n                id: build-image\n                requires: prefect-docker>=0.3.0\n                image_name: my-example-image\n                tag: dev\n                dockerfile: auto\n        \n        docker_push: &docker_push\n            - prefect_docker.deployments.steps.push_docker_image: &docker_push_config\n                requires: prefect-docker>=0.6.0\n                image_name: my-example-image\n                tag: dev\n                credentials: \"{{ prefect.blocks.docker-registry-credentials.dev-registry }}\"\n\ndeployments:\n  - name: deployment-1\n    entrypoint: flows/hello.py:my_flow\n    schedule: *every_10_minutes\n    parameters:\n        number: 42,\n        message: Don't panic!\n    work_pool: *my_docker_work_pool\n    build: *docker_build # Uses the full docker_build action with no overrides\n    push: *docker_push\n\n  - name: deployment-2\n    entrypoint: flows/goodbye.py:my_other_flow\n    work_pool: *my_docker_work_pool\n    build:\n        - prefect_docker.deployments.steps.build_docker_image:\n            <<: *docker_build_config # Uses the docker_build_config alias and overrides the dockerfile field\n            dockerfile: Dockerfile.custom\n    push: *docker_push\n\n  - name: deployment-3\n    entrypoint: flows/hello.py:yet_another_flow\n    schedule: *every_10_minutes\n    work_pool:\n        name: my-process-work-pool\n        work_queue_name: primary-queue\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from GitHub Repository\nDESCRIPTION: This snippet demonstrates how to deploy a Prefect flow by pulling code from a GitHub repository. It uses the 'from_source' method to specify the source and entrypoint of the flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        \"https://github.com/my_github_account/my_repo/my_file.git\",\n        entrypoint=\"flows/no-image.py:hello_world\",\n    ).deploy(\n        name=\"no-image-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        build=False\n    )\n```\n\n----------------------------------------\n\nTITLE: Invoking AWS Lambda Functions using Prefect\nDESCRIPTION: Python script demonstrating how to invoke AWS Lambda functions using Prefect's LambdaFunction block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws.lambda_function import LambdaFunction\nfrom prefect_aws.credentials import AwsCredentials\n\ncredentials = AwsCredentials()\nlambda_function = LambdaFunction(\n    function_name=\"test_lambda_function\",\n    aws_credentials=credentials,\n)\nresponse = lambda_function.invoke(\n    payload={\"foo\": \"bar\"},\n    invocation_type=\"RequestResponse\",\n)\nresponse[\"Payload\"].read()\n```\n\n----------------------------------------\n\nTITLE: Creating Event-Driven Automation in Prefect using Python\nDESCRIPTION: Python function to programmatically create an event-driven automation in Prefect using the REST API. It configures a trigger and action for redeploying a flow based on specific conditions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef create_event_driven_automation():\n    api_url = f\"https://api.prefect.cloud/api/accounts/{account_id}/workspaces/{workspace_id}/automations/\"\n    data = {\n        \"name\": \"Event Driven Redeploy\",\n        \"description\": \"Programmatically created an automation to redeploy a flow based on an event\",\n        \"enabled\": \"true\",\n        \"trigger\": {\n            \"after\": [\n                \"string\"\n            ],\n            \"expect\": [\n                \"prefect.flow-run.Running\"\n            ],\n            \"for_each\": [\n                \"prefect.resource.id\"\n            ],\n            \"posture\": \"Proactive\",\n            \"threshold\": 30,\n            \"within\": 0\n        },\n        \"actions\": [\n            {\n                \"type\": \"run-deployment\",\n                \"source\": \"selected\",\n                \"deployment_id\": \"YOUR-DEPLOYMENT-ID\",\n                \"parameters\": \"10\"\n            }\n        ],\n        \"owner_resource\": \"string\"\n    }\n\n    headers = {\"Authorization\": f\"Bearer {PREFECT_API_KEY}\"}\n    response = requests.post(api_url, headers=headers, json=data)\n\n    print(response.json())\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: SageMaker Training Script Template for XGBoost\nDESCRIPTION: Template script for SageMaker to train an XGBoost model on the Iris dataset. It handles data loading, preprocessing, model training with hyperparameters, and saving the model to S3.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport boto3\nimport os\nimport json\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    # Hyperparameters are described here.\n    parser.add_argument(\n        \"--max_depth\",\n        type=int,\n    )\n    parser.add_argument(\"--eta\", type=float)\n    parser.add_argument(\"--gamma\", type=float)\n    parser.add_argument(\"--min_child_weight\", type=float)\n    parser.add_argument(\"--subsample\", type=float)\n    parser.add_argument(\"--verbosity\", type=int)\n    parser.add_argument(\"--objective\", type=str)\n    parser.add_argument(\"--num_round\", type=int)\n    parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n    parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n    parser.add_argument(\"--num_class\", type=int)\n\n    # Sagemaker specific arguments. Defaults are set in the environment variables.\n    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n    parser.add_argument(\"--validation\", type=str, default=os.environ[\"SM_CHANNEL_VALIDATION\"])\n    parser.add_argument(\"--num-round\", type=int, default=100)\n\n    args, _ = parser.parse_known_args()\n\n    # Load training and validation data with appropriate column names\n    column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target']\n    train_data = pd.read_csv(os.path.join(args.train, \"train.csv\"), \n                            names=column_names, \n                            header=None)\n    validation_data = pd.read_csv(os.path.join(args.validation, \"test.csv\"), \n                                names=column_names, \n                                header=None)\n\n    # For XGBoost, we need to convert the text labels to numeric values\n    # Create a label encoder\n    label_encoder = LabelEncoder()\n    y_train = label_encoder.fit_transform(train_data['target'])\n    y_validation = label_encoder.transform(validation_data['target'])\n\n    # Get features (all columns except target)\n    X_train = train_data.drop('target', axis=1)\n    X_validation = validation_data.drop('target', axis=1)\n\n    # Create DMatrix for XGBoost\n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n\n    hyperparameters = {\n        \"max_depth\": args.max_depth,\n        \"eta\": args.eta,\n        \"gamma\": args.gamma,\n        \"min_child_weight\": args.min_child_weight,\n        \"subsample\": args.subsample,\n        \"verbosity\": args.verbosity,\n        \"objective\": args.objective,\n        \"tree_method\": args.tree_method,\n        \"predictor\": args.predictor,\n        \"num_class\": args.num_class\n    }\n\n    # Train the model\n    watchlist = [(dtrain, \"train\"), (dvalidation, \"validation\")]\n    model = xgb.train(\n        hyperparameters,\n        dtrain,\n        num_boost_round=args.num_round,\n        evals=watchlist,\n        early_stopping_rounds=10\n    )\n\n    # Save the model\n    filename = \"xgboost-model\"\n    model_location = os.path.join(args.model_dir, filename)\n    model.save_model(model_location)\n\n    # Save the model parameters\n    hyperparameters_location = os.path.join(args.model_dir, \"hyperparameters.json\")\n    with open(hyperparameters_location, \"w\") as f:\n        json.dump(hyperparameters, f)\n\n    # Upload the model to an S3 bucket for inference using boto3\n    s3_client = boto3.client('s3')\n    bucket_name = \"{model_bucket}\"\n    s3_client.upload_file(\n        model_location,\n        bucket_name,\n        filename\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Image Artifacts with Prefect Flow\nDESCRIPTION: Demonstrates how to create an image artifact using Prefect's create_image_artifact() function within a flow and task. The code creates a task that generates an image URL and registers it as an artifact.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.artifacts import (\n    create_image_artifact,\n)\n\n\n@task\ndef create_image():\n    # Do something to create an image and upload to a url\n    image_url = \"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExZmQydzBjOHQ2M3BhdWJ4M3V1MGtoZGxuNmloeGh6b2dvaHhpaHg0eSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3KC2jD2QcBOSc/giphy.gif\"\n    create_image_artifact(image_url=image_url, description=\"A gif.\", key=\"gif\")\n    return image_url\n\n\n@flow\ndef my_flow():\n    return create_image()\n\n\nif __name__ == \"__main__\":\n    image_url = my_flow()\n    print(f\"Image URL: {image_url}\")\n```\n\n----------------------------------------\n\nTITLE: Create Nested Blocks\nDESCRIPTION: This code demonstrates how to create nested blocks by using one block as a field within another block. It creates an `AwsCredentials` block and then uses it as the `credentials` field within an `S3Bucket` block. This allows for sharing configuration across multiple block documents.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.s3 import S3Bucket\n\ncredentials = AwsCredentials(aws_access_key_id=\"AKIAJKLJKLJKLJKLJKLJK\", \n                             aws_secret_access_key=\"password\")\nmy_bucket_block = S3Bucket(bucket_name=\"my-bucket\", credentials=credentials)\nmy_bucket_block.save(\"my_s3_bucket\")\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Variables in Prefect Flows\nDESCRIPTION: Demonstrates using Prefect variables in an asynchronous flow function. Similar to the synchronous example but uses async/await syntax and runs with asyncio.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/variables.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom prefect import flow\nfrom prefect.variables import Variable\n\n@flow(log_prints=True)\nasync def space_mission_async(mission_name: str):\n    crew = await Variable.get(\"crew_members\", default=[\"Backup1\", \"Backup2\"])\n    print(f\"Launching {mission_name} with crew: {', '.join(crew)}\")\n\nif __name__ == \"__main__\":\n    Variable.set(\"crew_members\", [\"Zaphod\", \"Arthur\", \"Trillian\"])\n    asyncio.run(space_mission_async(\"Mars Expedition\"))\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Workflow with Prefect\nDESCRIPTION: A simple Prefect workflow that fetches the number of GitHub stars for a repository. It demonstrates the use of flow and task decorators to orchestrate and observe the workflow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nimport httpx\n\n\n@task(log_prints=True)\ndef get_stars(repo: str):\n    url = f\"https://api.github.com/repos/{repo}\"\n    count = httpx.get(url).json()[\"stargazers_count\"]\n    print(f\"{repo} has {count} stars!\")\n\n\n@flow(name=\"GitHub Stars\")\ndef github_stars(repos: list[str]):\n    for repo in repos:\n        get_stars(repo)\n\n\n# run the flow!\nif __name__ == \"__main__\":\n    github_stars([\"PrefectHQ/Prefect\"])\n```\n\n----------------------------------------\n\nTITLE: Complete Background Task Example with Prefect\nDESCRIPTION: A complete example demonstrating how to define a Prefect task, background task runs, and start a task worker. This shows the entire workflow from task definition to execution, including the use of `.delay()` for backgrounding and `.serve()` for starting a worker.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n@task(log_prints=True)\ndef add(a: int, b: int):\n    print(f\"{a} + {b} = {a + b}\")\n\nadd.delay(1, 2) # background one task run\nadd.delay(42, 100) # background another task run\n\nadd.serve() # start a task worker and execute any waiting task runs\n```\n\n----------------------------------------\n\nTITLE: Getting Most Recent Flow Runs with Prefect API in Python\nDESCRIPTION: Fetch the last N completed flow runs in the workspace using Prefect's client and filtering schemas. The example uses an asynchronous context manager to interact with the client to retrieve flow runs based on their states and sorting by end time.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync def get_most_recent_flow_runs(\n    n: int,\n    states: list[str] | None = None\n) -> list[FlowRun]:    \n    async with get_client() as client:\n        return await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state={'type': {'any_': states or [\"COMPLETED\"]}}\n            ),\n            sort=FlowRunSort.END_TIME_DESC,\n            limit=n,\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Timeouts in Python\nDESCRIPTION: This snippet shows how to set a timeout for a task using the timeout_seconds argument in Prefect, which prevents unintentional long-running tasks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nimport time\n\n\n@task(timeout_seconds=1, log_prints=True)\ndef show_timeouts():\n    print(\"I will execute\")\n    time.sleep(5)\n    print(\"I will not execute\")\n```\n\n----------------------------------------\n\nTITLE: Excluding Parameters from Caching in Prefect\nDESCRIPTION: Shows how to modify the INPUTS cache policy to ignore specific parameters when computing the cache key. In this example, the 'debug' parameter doesn't affect caching behavior.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import INPUTS\n\n\nmy_custom_policy = INPUTS - 'debug'\n\n@task(cache_policy=my_custom_policy)\ndef my_cached_task(x: int, debug: bool = False):\n    print('running...')\n    return x + 42\n\n\nmy_cached_task(1)\nmy_cached_task(1, debug=True) # still uses the cache\n```\n\n----------------------------------------\n\nTITLE: Configuring PostgreSQL Connection\nDESCRIPTION: Example of creating and saving a PostgreSQL database connection using SqlAlchemyConnector.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_sqlalchemy import SqlAlchemyConnector, ConnectionComponents, SyncDriver\n\nconnector = SqlAlchemyConnector(\n    connection_info=ConnectionComponents(\n        driver=SyncDriver.POSTGRESQL_PSYCOPG2,\n        username=\"USERNAME-PLACEHOLDER\",\n        password=\"PASSWORD-PLACEHOLDER\",\n        host=\"localhost\",\n        port=5432,\n        database=\"DATABASE-PLACEHOLDER\",\n    )\n)\n\nconnector.save(\"BLOCK_NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Artifacts in Prefect Flow\nDESCRIPTION: Demonstrates creating Markdown artifacts with a key for tracking history, which can include formatted reports, summaries, and detailed insights about flow run results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.artifacts import create_markdown_artifact\n\n\n@task\ndef markdown_task():\n    na_revenue = 500000\n    markdown_report = f\"\"\"# Sales Report\n\n## Summary\n\nIn the past quarter, our company saw a significant increase in sales, with a total revenue of $1,000,000. \nThis represents a 20% increase over the same period last year.\n\n## Sales by Region\n\n| Region        | Revenue |\n|:--------------|-------:|\n| North America | ${na_revenue:,} |\n| Europe        | $250,000 |\n| Asia          | $150,000 |\n| South America | $75,000 |\n| Africa        | $25,000 |\n\n## Top Products\n\n1. Product A - $300,000 in revenue\n2. Product B - $200,000 in revenue\n3. Product C - $150,000 in revenue\n\n## Conclusion\n\nOverall, these results are very encouraging and demonstrate the success of our sales team in increasing revenue \nacross all regions. However, we still have room for improvement and should focus on further increasing sales in \nthe coming quarter.\n\"\"\"\n    create_markdown_artifact(\n        key=\"gtm-report\",\n        markdown=markdown_report,\n        description=\"Quarterly Sales Report\",\n    )\n\n\n@flow()\ndef my_flow():\n    markdown_task()\n    \n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Prefect-FastAPI Integration\nDESCRIPTION: This YAML configuration defines the services for a Prefect-FastAPI application, including the Prefect server, task worker, and API server. It specifies build contexts, environment variables, volume mounts, and dependencies between services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/static-infrastructure-examples/background-tasks.mdx#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n\n  prefect-server:\n    build:\n      context: .\n      target: server\n    ports:\n      - \"4200:4200\"\n    volumes:\n      - prefect-data:/root/.prefect # Persist Prefect DB\n    environment:\n      # Allow connections from other containers\n      PREFECT_SERVER_API_HOST: 0.0.0.0\n  # Task Worker\n  task:\n    build:\n      context: .\n      target:\n    deploy:\n      replicas: 1 # task workers are safely horizontally scalable (think redis stream consumer groups)\n    volumes:\n      # Mount storage for results\n      - ./task-storage:/task-storage\n    depends_on:\n      prefect-server:\n        condition: service_started\n    environment:\n      PREFECT_API_URL: http://prefect-server:4200/api\n      PREFECT_LOCAL_STORAGE_PATH: /task-storage\n      PREFECT_LOGGING_LOG_PRINTS: \"true\"\n      PREFECT_RESULTS_PERSIST_BY_DEFAULT: \"true\"\n      MARVIN_ENABLE_DEFAULT_PRINT_HANDLER: \"false\"\n      OPENAI_API_KEY: ${OPENAI_API_KEY}\n\n    develop:\n      # Optionally watch for code changes for development\n      watch:\n        - action: sync\n          path: .\n          target: /app\n          ignore:\n            - .venv/\n            - task-storage/\n        - action: rebuild\n          path: uv.lock\n\n  api:\n    build:\n      context: .\n      target: api\n    volumes:\n      # Mount storage for results\n      - ./task-storage:/task-storage\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      task:\n        condition: service_started\n      prefect-server:\n        condition: service_started\n    environment:\n      PREFECT_API_URL: http://prefect-server:4200/api\n      PREFECT_LOCAL_STORAGE_PATH: /task-storage\n    develop:\n      # Optionally watch for code changes for development\n      watch:\n        - action: sync\n          path: .\n          target: /app\n          ignore:\n            - .venv/\n            - task-storage/\n        - action: rebuild\n          path: uv.lock\n\nvolumes:\n  # Named volumes for data persistence\n  prefect-data: {}\n  task-storage: {}\n```\n\n----------------------------------------\n\nTITLE: Handling CloudEvents with Jinja2 Template\nDESCRIPTION: This Jinja2 template processes incoming CloudEvents, converting the structured data into Prefect's event format. It handles the mapping of CloudEvent data fields to Prefect payload structure, ensuring seamless event data exchange.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_8\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ body|from_cloud_event(headers) }}\n```\n\n----------------------------------------\n\nTITLE: Configuring RayTaskRunner with local Ray instance\nDESCRIPTION: Example of configuring a Prefect flow to use RayTaskRunner with a local, temporary Ray instance.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_ray.task_runners import RayTaskRunner\n\n@flow(task_runner=RayTaskRunner())\ndef my_flow():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Logging Print Statements in Prefect Flows and Tasks\nDESCRIPTION: Illustrates how to automatically log print statements in Prefect flows and tasks by enabling the `log_prints` option. This feature redirects `print` outputs to the Prefect logger.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\n\n@task\ndef my_task():\n    print(\"we're logging print statements from a task\")\n\n@flow(log_prints=True)\ndef my_flow():\n    print(\"we're logging print statements from a flow\")\n    my_task()\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect in UV Virtual Environment\nDESCRIPTION: Commands to create a Python 3.12 virtual environment using UV, activate it, and install the latest version of Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuv venv --python 3.12 && source .venv/bin/activate\nuv pip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Configuring Bitbucket Repository in prefect.yaml\nDESCRIPTION: This YAML snippet shows how to configure a Bitbucket repository in the prefect.yaml configuration file. It includes commented options for specifying credentials using either a credentials block or a Secret block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n# relevant section of the file:\npull:\n    - prefect.deployments.steps.git_clone:\n        repository: https://bitbucket.org/org/my-private-repo.git\n        # Uncomment the following line if using a credentials block\n        # credentials: \"{{ prefect.blocks.bitbucket-credentials.my-bitbucket-credentials-block }}\"\n        # Uncomment the following line if using a Secret block\n        # access_token: \"{{ prefect.blocks.secret.my-block-name }}\"\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Data Ingestion Tasks with Prefect\nDESCRIPTION: Defines core tasks and flow for fetching MLB game data including schedules and boxscores using the statsapi package. Includes tasks for retrieving game IDs and detailed game statistics, with data storage in local files.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task, runtime\nfrom prefect.artifacts import create_markdown_artifact\nfrom prefect_aws.s3 import S3Bucket\nfrom prefect.blocks.system import Secret\nfrom datetime import datetime\nimport statsapi\nimport json\nimport pandas as pd\nimport duckdb\n\n@task\ndef get_recent_games(team_name, start_date, end_date):\n    '''This task will fetch the schedule for the provided team and date range and return the game ids.'''\n    team = statsapi.lookup_team(team_name)\n    schedule = statsapi.schedule(team=team[0][\"id\"], start_date=start_date, end_date=end_date)\n    for game in schedule:\n        print(game['game_id'])\n    return [game['game_id'] for game in schedule]\n\n\n@task\ndef fetch_single_game_boxscore(game_id, start_date, end_date, team_name):\n    '''This task will fetch the boxscore for a single game and return the game data.'''\n    boxscore = statsapi.boxscore_data(game_id)\n    \n    # Extract the relevant data.\n    home_score = boxscore['home']['teamStats']['batting']['runs']\n    away_score = boxscore['away']['teamStats']['batting']['runs']\n    home_team = boxscore['teamInfo']['home']['teamName']\n    away_team = boxscore['teamInfo']['away']['teamName']\n    time_value = next(item['value'] for item in boxscore['gameBoxInfo'] if item['label'] == 'T')\n    \n    #Create a dictionary with the game data.\n    game_data = {\n        'search_start_date': start_date,\n        'search_end_date': end_date,\n        'chosen_team_name': team_name,\n        'game_id': game_id,\n        'home_team': home_team,\n        'away_team': away_team,\n        'home_score': home_score,\n        'away_score': away_score,\n        'score_differential': abs(home_score - away_score),\n        'game_time': time_value,\n    }\n    \n    print(game_data)\n    return game_data\n\n@flow\ndef mlb_flow(team_name, start_date, end_date):\n    # Get recent games.\n    game_ids = get_recent_games(team_name, start_date, end_date)\n    \n    # Fetch boxscore for each game.\n    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]\n    \n    #Define file path for raw data.\n    today = datetime.now().strftime(\"%Y-%m-%d\")  # This uses the current date in the format YYYY-MM-DD.\n    flow_run_name = runtime.flow_run.name\n    raw_file_path = f\"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json\"\n    \n    # Save raw data to a local folder.\n    save_raw_data_to_file(game_data, raw_file_path)\n\nif __name__ == \"__main__\":\n    mlb_flow(\"marlins\", '06/01/2024', '06/30/2024')\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Task Runners in Prefect Flow (Python)\nDESCRIPTION: This code snippet illustrates how to use multiple task runners within a single Prefect flow. It demonstrates using the default ThreadPoolTaskRunner for local tasks and the DaskTaskRunner for tasks that benefit from parallel execution on a Dask cluster.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.task_runners import ThreadPoolTaskRunner\nfrom prefect_dask.task_runners import DaskTaskRunner\nimport time\n\n@task\ndef hello_local(name: str):\n    time.sleep(2)\n    print(f\"Hello {name}!\")\n\n@flow # implicitly uses the default task runner, ThreadPoolTaskRunner\ndef concurrent_nested_flow():\n    marvin = hello_local.submit(\"marvin\")\n    ford = hello_local.submit(\"ford\")\n    marvin.wait(), ford.wait()\n\n@task\ndef hello_dask():\n    print(\"Hello from Dask!\")\n\n@flow(task_runner=DaskTaskRunner())\ndef dask_nested_flow():\n    hello_dask.submit().wait()\n\n@flow # implicitly uses the default task runner, ThreadPoolTaskRunner\ndef parent_flow():\n    concurrent_nested_flow()\n    dask_nested_flow()\n\nif __name__ == \"__main__\":\n    parent_flow()\n```\n\n----------------------------------------\n\nTITLE: Creating Lambda Function Block in Python\nDESCRIPTION: Python script to create a LambdaFunction block for invoking AWS Lambda functions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws.lambda_function import LambdaFunction\nfrom prefect_aws.credentials import AwsCredentials\n\nLambdaFunction(\n    function_name=\"test_lambda_function\",\n    aws_credentials=credentials,\n).save(\"LAMBDA-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Scaling Prefect Task with Coiled Decorator\nDESCRIPTION: Integrates Coiled for scaling Prefect tasks by annotating with memory specifications. Requires Prefect and Coiled libraries.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nimport coiled                               # new!\n\n@task\ndef f(n):\n    return n**2\n\n@task\n@coiled.function(memory=\"64 GiB\")           # new!\ndef do_something(x):\n    print(x)\n\n@flow(log_prints=True)\ndef my_flow():\n    print(\"Hello from your Prefect flow!\")\n    X = f.map(list(range(10)))\n```\n\n----------------------------------------\n\nTITLE: Implementing Rate Limiting in Prefect Tasks\nDESCRIPTION: This snippet shows how to apply a global concurrency limit to a Prefect task using the rate_limit function. This ensures API requests don't exceed the configured rate limits, preventing throttling or blocking from the API service.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\nfrom prefect import task\nfrom prefect.concurrency.sync import rate_limit\n\n@task\ndef fetch_stats(github_repo: str) -> dict[str, Any]:\n    \"\"\"Task 1: Fetch the statistics for a GitHub repo\"\"\"\n    rate_limit(\"github-api\")\n    return httpx.get(f\"https://api.github.com/repos/{github_repo}\").json()\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow to Managed Work Pool using Python\nDESCRIPTION: Python script demonstrating how to deploy a flow from a remote source to a Prefect Managed work pool, enabling remote execution without infrastructure management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/managed.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/prefecthq/demo.git\",\n        entrypoint=\"flow.py:my_flow\",\n    ).deploy(\n        name=\"test-managed-flow\",\n        work_pool_name=\"my-managed-pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Cache Key Function in Prefect\nDESCRIPTION: Demonstrates how to implement a custom cache key function that returns a static cache key. This makes all task runs use the same cache regardless of inputs or code changes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef static_cache_key(context, parameters):\n    # return a constant\n    return \"static cache key\"\n\n\n@task(cache_key_fn=static_cache_key)\ndef my_cached_task(x: int):\n    return x + 1\n```\n\n----------------------------------------\n\nTITLE: Bulk Cancellation Implementation for Prefect Flow Runs\nDESCRIPTION: Main function that implements the bulk cancellation process for Prefect flow runs. It identifies runs in Pending, Running, Scheduled, or Late states and cancels them in batches until none remain.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nasync def bulk_cancel_flow_runs():\n    states = [\"Pending\", \"Running\", \"Scheduled\", \"Late\"]\n    flow_runs = await list_flow_runs_with_states(states)\n\n    while flow_runs:\n        print(f\"Cancelling {len(flow_runs)} flow runs\")\n        await cancel_flow_runs(flow_runs)\n        flow_runs = await list_flow_runs_with_states(states)\n\nasyncio.run(bulk_cancel_flow_runs())\n```\n\n----------------------------------------\n\nTITLE: Class Method Tasks in Prefect\nDESCRIPTION: Demonstration of using @task decorator with different types of class methods including instance methods, class methods, and static methods.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n\nclass MyClass:\n\n    @task\n    def my_instance_method(self):\n        pass\n\n\n    @classmethod\n    @task\n    def my_class_method(cls):\n        pass\n\n\n    @staticmethod\n    @task\n    def my_static_method():\n        pass\n\n\nMyClass().my_instance_method()\nMyClass.my_class_method()\nMyClass.my_static_method()\n```\n\n----------------------------------------\n\nTITLE: Static Task Definition in Prefect\nDESCRIPTION: Shows the recommended way to define static tasks using the @task decorator in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n@task\ndef my_static_task(): ...\n```\n\n----------------------------------------\n\nTITLE: Converting Airflow DAG to Prefect Flow - Airflow Example\nDESCRIPTION: Example of a simple ETL workflow implemented as an Airflow DAG, using PythonOperator for extract, transform, and load operations with explicitly defined dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Airflow DAG example (simplified ETL)\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime\n\n# Airflow task functions (to be used by PythonOperator)\ndef extract_fn():\n    # ... (extract data, e.g., query an API or database)\n    return data\n\ndef transform_fn(data):\n    # ... (transform the data)\n    return processed_data\n\ndef load_fn(processed_data):\n    # ... (load data to target, e.g., save to DB or file)\n\nwith DAG(\"etl_pipeline\", start_date=datetime(2023,1,1), schedule_interval=\"@daily\", catchup=False) as dag:\n    extract = PythonOperator(task_id='extract_data', python_callable=extract_fn)\n    transform = PythonOperator(task_id='transform_data', python_callable=transform_fn)\n    load = PythonOperator(task_id='load_data', python_callable=load_fn)\n    \n    # Set task dependencies\n    extract >> transform >> load\n```\n\n----------------------------------------\n\nTITLE: Google Cloud Storage Example\nDESCRIPTION: Example flow showing file upload and download operations with Google Cloud Storage.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom prefect import flow\nfrom prefect_gcp import GcpCredentials, GcsBucket\n\n\n@flow\ndef cloud_storage_flow():\n    # create a dummy file to upload\n    file_path = Path(\"test-example.txt\")\n    file_path.write_text(\"Hello, Prefect!\")\n\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n    gcs_bucket = GcsBucket(\n        bucket=\"BUCKET-NAME\",\n        gcp_credentials=gcp_credentials\n    )\n\n    gcs_bucket_path = gcs_bucket.upload_from_path(file_path)\n    downloaded_file_path = gcs_bucket.download_object_to_path(\n        gcs_bucket_path, \"downloaded-test-example.txt\"\n    )\n    return downloaded_file_path.read_text()\n\n\nif __name__ == \"__main__\":\n    cloud_storage_flow()\n```\n\n----------------------------------------\n\nTITLE: Handling Non-Serializable Objects with Pydantic Custom Serialization in Python\nDESCRIPTION: This snippet demonstrates how to handle non-serializable objects in Prefect cache keys using Pydantic's custom serialization. It shows how to create a Pydantic model that can safely serialize objects with non-serializable components.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict, model_serializer\nfrom prefect import flow, task\nfrom prefect.cache_policies import INPUTS, RUN_ID\n\nclass NotSerializable:\n    def __getstate__(self):\n        raise TypeError(\"NooOoOOo! I will not be serialized!\")\n\nclass ContainsNonSerializableObject(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str\n    bad_object: NotSerializable\n\n    @model_serializer\n    def ser_model(self) -> dict:\n        \"\"\"Only serialize the name, not the problematic object\"\"\"\n        return {\"name\": self.name}\n\n@task(cache_policy=INPUTS + RUN_ID)\ndef use_object(some_object: ContainsNonSerializableObject) -> str:\n    return f\"Used {some_object.name}\"\n\n@flow\ndef demo_flow():\n    some_object = ContainsNonSerializableObject(\n        name=\"test\",\n        bad_object=NotSerializable()\n    )\n    state = use_object(some_object, return_state=True) # Not cached!\n    assert state.name == \"Completed\"\n    other_state = use_object(some_object, return_state=True) # Cached!\n    assert other_state.name == \"Cached\"\n    assert state.result() == other_state.result()\n```\n\n----------------------------------------\n\nTITLE: Load Nested Blocks\nDESCRIPTION: This example shows how to load a previously saved `AwsCredentials` block and use it within an `S3Bucket` block. This allows changes to the credentials to propagate to the bucket configuration. Then the S3 bucket block is saved.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmy_bucket_block = S3Bucket(\n    bucket_name=\"my-bucket\",\n    credentials=AwsCredentials.load(\"my_aws_credentials\")\n)\n\nmy_bucket_block.save(\"my_s3_bucket\")\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Server\nDESCRIPTION: Starts a Prefect server instance. This command allows specifying options such as host, port, log level, and whether to run in the background.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server start [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Creating Progress Artifacts in Prefect Flow\nDESCRIPTION: Shows how to create and update progress artifacts to track the progress of long-running tasks, with dynamic updates in the Prefect UI. Useful for monitoring batch processing and data extraction.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom time import sleep\n\nfrom prefect import flow, task\nfrom prefect.artifacts import (\n    create_progress_artifact,\n    update_progress_artifact,\n)\n\n\ndef fetch_batch(i: int):\n    # Simulate fetching a batch of data\n    sleep(2)\n\n\n@task\ndef fetch_in_batches():\n    progress_artifact_id = create_progress_artifact(\n        progress=0.0,\n        description=\"Indicates the progress of fetching data in batches.\",\n    )\n    for i in range(1, 11):\n        fetch_batch(i)\n        update_progress_artifact(artifact_id=progress_artifact_id, progress=i * 10)\n\n\n@flow\ndef etl():\n    fetch_in_batches()\n\n\nif __name__ == \"__main__\":\n    etl()\n```\n\n----------------------------------------\n\nTITLE: Listing and Cancelling Flow Runs in Prefect\nDESCRIPTION: Functions for listing flow runs with specific states and cancelling them using the Prefect Client API. The code uses the client.read_flow_runs method with filters to get runs in specified states, then uses client.set_flow_run_state to change their states to Cancelled.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nasync def list_flow_runs_with_states(states: list[str]) -> list[FlowRun]:\n    async with get_client() as client:\n        return await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state=FlowRunFilterState(\n                    name=FlowRunFilterStateName(any_=states)\n                )\n            )\n        )\n\nasync def cancel_flow_runs(flow_runs: list[FlowRun]):\n    async with get_client() as client:\n        for flow_run in flow_runs:\n            state = flow_run.state.copy(\n                update={\"name\": \"Cancelled\", \"type\": StateType.CANCELLED}\n            )\n            await client.set_flow_run_state(flow_run.id, state, force=True)\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Deployment\nDESCRIPTION: YAML configuration for deploying Prefect flows, including build, push, and deployment settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nname: flows\nprefect-version: 3.0.0\n\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build-image\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ $PREFECT_IMAGE_NAME }}\"\n    tag: latest\n    dockerfile: auto\n    platform: \"linux/amd64\"\n\npush:\n- prefect_docker.deployments.steps.push_docker_image:\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ build-image.image_name }}\"\n    tag: \"{{ build-image.tag }}\"\n\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /opt/prefect/flows\n\ndefinitions:\n  tags: &common_tags\n    - \"eks\"\n  work_pool: &common_work_pool\n    name: \"kubernetes\"\n    job_variables:\n      image: \"{{ build-image.image }}\"\n\ndeployments:\n- name: \"default\"\n  tags: *common_tags\n  schedule: null\n  entrypoint: \"flows/hello.py:hello\"\n  work_pool: *common_work_pool\n\n- name: \"arthur\"\n  tags: *common_tags\n  schedule: null\n  entrypoint: \"flows/hello.py:hello\"\n  parameters:\n    name: \"Arthur\"\n  work_pool: *common_work_pool\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with Parameters\nDESCRIPTION: This example shows how to deploy a Prefect flow with parameters using the 'deploy' method. It demonstrates passing a dictionary of key-value pairs as parameters to the flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow\ndef hello_world(name: str):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    hello_world.deploy(\n        name=\"pass-params-deployment\",\n        work_pool_name=\"my-docker-pool\",\n        parameters=dict(name=\"Prefect\"),\n        image=\"my_registry/my_image:my_image_tag\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Writing Task Results to AWS S3 Storage\nDESCRIPTION: Demonstrates how to configure task result storage in AWS S3 using Prefect's cloud storage integration, reducing memory usage by storing results externally\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/big-data.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws.s3 import S3Bucket\n\nmy_s3_block = S3Bucket.load(\"MY_BLOCK_NAME\")\n\n@task(result_storage=my_s3_block)\n```\n\n----------------------------------------\n\nTITLE: Pausing a Flow Run and Waiting for Input\nDESCRIPTION: This snippet demonstrates pausing a flow run and waiting for user input using `pause_flow_run` and a custom `RunInput` subclass.  It defines a `UserNameInput` model with a `name` field and uses it as the `wait_for_input` argument in `pause_flow_run`.  When the flow pauses, it waits for the user to provide a value for the `name` field before resuming, which is then used to print a greeting.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, pause_flow_run\nfrom prefect.input import RunInput\n\n\nclass UserNameInput(RunInput):\n    name: str\n\n\n@flow(log_prints=True)\nasync def greet_user():\n    user_input = await pause_flow_run(\n        wait_for_input=UserNameInput\n    )\n\n    print(f\"Hello, {user_input.name}!\")\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Docker Container\nDESCRIPTION: Command to run a Docker container with local code mounted and installed. Includes options for background execution, container naming, and API configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect dev container [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Docker Deployment Python Implementation\nDESCRIPTION: Python code showing how to deploy a flow that uses Docker-based storage. This example creates a simple flow and deploys it with Docker image configuration, setting the push flag to false.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow\ndef my_flow():\n    print(\"Hello from inside a Docker container!\")\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-docker-deploy\",\n        work_pool_name=\"my_pool\",\n        image=\"my-docker-image:latest\",\n        push=False\n    )\n```\n\n----------------------------------------\n\nTITLE: Customizing Prefect Flow Options for Kubernetes Job Execution\nDESCRIPTION: Example of using with_options to customize a Prefect flow for running a Kubernetes job, including setting a name, retries, and retry delay.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_kubernetes.flows import run_namespaced_job\n\ncustomized_run_namespaced_job = run_namespaced_job.with_options(\n    name=\"My flow running a Kubernetes Job\",\n    retries=2,\n    retry_delay_seconds=10,\n) # this is now a new flow object that can be called\n```\n\n----------------------------------------\n\nTITLE: Deploying a Prefect Flow with Docker\nDESCRIPTION: This Python snippet demonstrates how to deploy a Prefect flow using the `flow.deploy` method. It defines a deployment named \"my-deployment\" that uses the specified work pool and Docker image. The `push=False` argument prevents pushing the image to a registry, suitable for local development.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False # switch to True to push to your image registry\n    )\n```\n\n----------------------------------------\n\nTITLE: Load and Use an S3Bucket Block in a Flow\nDESCRIPTION: This code shows how to load an `S3Bucket` block document within a Prefect flow and use its attributes. It loads the `my-data-bucket-block` block document using the `S3Bucket.load()` method and prints the bucket name. It requires the prefect and prefect_aws packages.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws.s3 import S3Bucket\n\n@flow\ndef what_is_the_bucket():\n    bucket = S3Bucket.load(\"my-data-bucket-block\")\n    print(bucket.bucket_name)\n\nif __name__ == \"__main__\":\n    what_is_the_bucket() # data-bucket\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect with prefect.toml\nDESCRIPTION: A complete example of a prefect.toml file that sets the logging level to DEBUG. This configuration file can be committed to repositories to ensure consistency across environments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[logging]\nlevel = \"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Secrets with AWS Secrets Manager using Prefect Flow\nDESCRIPTION: Prefect flow demonstrating how to write, read, and delete secrets using AWS Secrets Manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws import AwsCredentials, AwsSecret\n\n\n@flow\ndef secrets_manager_flow():\n    aws_credentials = AwsCredentials.load(\"BLOCK-NAME-PLACEHOLDER\")\n    aws_secret = AwsSecret(secret_name=\"test-example\", aws_credentials=aws_credentials)\n    aws_secret.write_secret(secret_data=b\"Hello, Prefect!\")\n    secret_data = aws_secret.read_secret()\n    aws_secret.delete_secret()\n    return secret_data\n\n\nif __name__ == \"__main__\":\n    secrets_manager_flow()\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing Files to AWS S3 using Prefect Flow\nDESCRIPTION: Prefect flow demonstrating how to upload a file to an AWS S3 bucket and download it under a different filename.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom prefect import flow\nfrom prefect_aws import AwsCredentials, S3Bucket\n\n\n@flow\ndef s3_flow():\n    # create a dummy file to upload\n    file_path = Path(\"test-example.txt\")\n    file_path.write_text(\"Hello, Prefect!\")\n\n    aws_credentials = AwsCredentials.load(\"BLOCK-NAME-PLACEHOLDER\")\n    s3_bucket = S3Bucket(\n        bucket_name=\"BUCKET-NAME-PLACEHOLDER\",\n        credentials=aws_credentials\n    )\n\n    s3_bucket_path = s3_bucket.upload_from_path(file_path)\n    downloaded_file_path = s3_bucket.download_object_to_path(\n        s3_bucket_path, \"downloaded-test-example.txt\"\n    )\n    return downloaded_file_path.read_text()\n\n\nif __name__ == \"__main__\":\n    s3_flow()\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow to GCP Cloud Run Push Work Pool\nDESCRIPTION: This Python script demonstrates how to deploy a flow to a GCP Cloud Run push work pool. It uses the default Docker build namespace set during infrastructure provisioning.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.docker import DockerImage\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow running on Cloud Run!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"above-ground\",\n        image=DockerImage(\n            name=\"my-image:latest\",\n            platform=\"linux/amd64\",\n        )\n    )\n```\n\n----------------------------------------\n\nTITLE: Python Flow Definition for Dockerless Execution\nDESCRIPTION: Defines a Prefect flow that can be deployed without a Docker image, suitable for Dockerless execution using Coiled’s Package Sync.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef foo(n):\n    return n**2\n\n@task\ndef do_something(x):\n    print(x)\n\n@flow(log_prints=True)\ndef my_flow():\n    print(\"Hello from your Prefect flow!\")\n    X = foo.map(list(range(10)))\n    do_something(X)\n    return X\n```\n\n----------------------------------------\n\nTITLE: Example Output from AWS ECS Work Pool Creation\nDESCRIPTION: Sample console output showing the infrastructure components being created during AWS ECS work pool provisioning, including IAM users, policies, ECS clusters, VPC setup, and ECR repositories.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n_____________________________________________________________________________________________\n| Provisioning infrastructure for your work pool my-ecs-pool will require:                   |\n|                                                                                            |\n|          - Creating an IAM user for managing ECS tasks: prefect-ecs-user                   |\n|          - Creating and attaching an IAM policy for managing ECS tasks: prefect-ecs-policy |\n|          - Storing generated AWS credentials in a block                                    |\n|          - Creating an ECS cluster for running Prefect flows: prefect-ecs-cluster          |\n|          - Creating a VPC with CIDR 172.31.0.0/16 for running ECS tasks: prefect-ecs-vpc   |\n|          - Creating an ECR repository for storing Prefect images: prefect-flows            |\n_____________________________________________________________________________________________\nProceed with infrastructure provisioning? [y/n]: y\nProvisioning IAM user\nCreating IAM policy\nGenerating AWS credentials\nCreating AWS credentials block\nProvisioning ECS cluster\nProvisioning VPC\nCreating internet gateway\nSetting up subnets\nSetting up security group\nProvisioning ECR repository\nAuthenticating with ECR\nSetting default Docker build namespace\nProvisioning Infrastructure ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00\nInfrastructure successfully provisioned!\nCreated work pool 'my-ecs-pool'!\n```\n\n----------------------------------------\n\nTITLE: Implementing SecretDict Block in Python\nDESCRIPTION: Example of creating a custom block class using SecretDict to automatically obfuscate sensitive data while keeping regular variables visible.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict\n\nfrom prefect.blocks.core import Block\nfrom prefect.blocks.fields import SecretDict\n\n\nclass SystemConfiguration(Block):\n    system_secrets: SecretDict\n    system_variables: Dict\n\n\nsystem_configuration_block = SystemConfiguration(\n    system_secrets={\n        \"password\": \"p@ssw0rd\",\n        \"api_token\": \"token_123456789\",\n        \"private_key\": \"<private key here>\",\n    },\n    system_variables={\n        \"self_destruct_countdown_seconds\": 60,\n        \"self_destruct_countdown_stop_time\": 7,\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Email Highlighting in Flow Logs\nDESCRIPTION: Example flow that demonstrates how the custom email highlighting works. The flow logs an email address which will be highlighted according to the custom configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.logging import get_run_logger\n\n@flow\ndef log_email_flow():\n    logger = get_run_logger()\n    logger.info(\"my@email.com\")\n\nlog_email_flow()\n```\n\n----------------------------------------\n\nTITLE: Deploying a Flow with a Cron Schedule\nDESCRIPTION: This Python snippet deploys a Prefect flow with a cron schedule.  The `cron` parameter of `flow.deploy` specifies the schedule using a cron string. In this example, the cron string \"0 0 * * *\" schedules the flow to run once a day at midnight.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n        # Run once a day at midnight\n        cron=\"0 0 * * *\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Serving a Flow with a Cron Schedule in Python\nDESCRIPTION: This code snippet demonstrates how to serve a Prefect flow with a cron schedule defined directly within the Python code. It imports the necessary modules, defines the flow, and uses the `flow.serve` method to deploy the flow with the specified cron expression, which triggers a flow run every minute.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nfrom myproject.flows import my_flow\n\nmy_flow.serve(name=\"flowing\", cron=\"* * * * *\")\n```\n\n----------------------------------------\n\nTITLE: Creating Snowflake Credentials Block\nDESCRIPTION: Python code to create and save Snowflake credentials using the SnowflakeCredentials block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_snowflake import SnowflakeCredentials\n\ncredentials = SnowflakeCredentials(\n    account=\"ACCOUNT-PLACEHOLDER\",  # resembles nh12345.us-east-2.snowflake\n    user=\"USER-PLACEHOLDER\",\n    password=\"PASSWORD-PLACEHOLDER\"\n)\ncredentials.save(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual Backoff Retries in Prefect Task\nDESCRIPTION: Demonstrates how to configure a task with manual retry intervals using the retry_delay_seconds parameter. The task will retry 3 times with increasing delays of 1, 10, and 100 seconds.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n\n@task(retries=3, retry_delay_seconds=[1, 10, 100])\ndef some_task_with_manual_backoff_retries():\n   (rest of code follows)\n```\n\n----------------------------------------\n\nTITLE: Submitting AWS Glue Jobs using Prefect Flow\nDESCRIPTION: Prefect flow demonstrating how to submit and wait for completion of AWS Glue jobs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.glue_job import GlueJobBlock\n\n\n@flow\ndef example_run_glue_job():\n    aws_credentials = AwsCredentials(\n        aws_access_key_id=\"your_access_key_id\",\n        aws_secret_access_key=\"your_secret_access_key\"\n    )\n    glue_job_run = GlueJobBlock(\n        job_name=\"your_glue_job_name\",\n        arguments={\"--YOUR_EXTRA_ARGUMENT\": \"YOUR_EXTRA_ARGUMENT_VALUE\"},\n    ).trigger()\n\n    return glue_job_run.wait_for_completion()\n\n\nif __name__ == \"__main__\":\n    example_run_glue_job()\n```\n\n----------------------------------------\n\nTITLE: Using Dask Priority Annotations with Prefect Tasks\nDESCRIPTION: Example showing how to use Dask annotations to set priority levels for tasks in a Prefect flow. Tasks with higher priority values will be scheduled before those with lower priority values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport dask\nfrom prefect import flow, task\nfrom prefect_dask.task_runners import DaskTaskRunner\n\n\n@task\ndef show(x):\n    print(x)\n\n\n@flow(task_runner=DaskTaskRunner())\ndef my_flow():\n    with dask.annotate(priority=-10):\n        future = show.submit(1)  # low priority task\n\n    with dask.annotate(priority=10):\n        future = show.submit(2)  # high priority task\n```\n\n----------------------------------------\n\nTITLE: Complete Reschedule Flow Example in Python\nDESCRIPTION: Full implementation of the logic to reschedule and delete late flow runs with Prefect client. This example includes checks for rescheduling logic and prerequisites such as importing the necessary modules.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport asyncio\nfrom datetime import datetime, timedelta, timezone\n\nfrom prefect import get_client\nfrom prefect.client.schemas.filters import DeploymentFilter, FlowRunFilter\nfrom prefect.client.schemas.objects import FlowRun\nfrom prefect.client.schemas.sorting import FlowRunSort\nfrom prefect.states import Scheduled\n\nasync def reschedule_late_flow_runs(\n    deployment_name: str,\n    delay: timedelta,\n    most_recent_n: int,\n    delete_remaining: bool = True,\n    states: list[str] | None = None\n) -> list[FlowRun]:\n    states = states or [\"Late\"]\n\n    async with get_client() as client:\n        flow_runs = await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state=dict(name=dict(any_=states)),\n                expected_start_time=dict(before_=datetime.now(timezone.utc)),\n            ),\n            deployment_filter=DeploymentFilter(name={'like_': deployment_name}),\n            sort=FlowRunSort.START_TIME_DESC,\n            limit=most_recent_n if not delete_remaining else None\n        )\n\n        if not flow_runs:\n            print(f\"No flow runs found in states: {states!r}\")\n            return []\n        \n        rescheduled_flow_runs: list[FlowRun] = []\n        for i, run in enumerate(flow_runs):\n            await client.delete_flow_run(flow_run_id=run.id)\n            if i < most_recent_n:\n                new_run = await client.create_flow_run_from_deployment(\n                    deployment_id=run.deployment_id,\n                    state=Scheduled(scheduled_time=run.expected_start_time + delay),\n                )\n                rescheduled_flow_runs.append(new_run)\n            \n        return rescheduled_flow_runs\n\n\nif __name__ == \"__main__\":\n    rescheduled_flow_runs = asyncio.run(\n        reschedule_late_flow_runs(\n            deployment_name=\"healthcheck-storage-test\",\n            delay=timedelta(hours=6),\n            most_recent_n=3,\n        )\n    )\n    \n    print(f\"Rescheduled {len(rescheduled_flow_runs)} flow runs\")\n    \n    assert all(run.state.is_scheduled() for run in rescheduled_flow_runs)\n    assert all(\n        run.expected_start_time > datetime.now(timezone.utc)\n        for run in rescheduled_flow_runs\n    )\n```\n\n----------------------------------------\n\nTITLE: Preventing Cache Refresh for a Prefect Task\nDESCRIPTION: This snippet shows how to prevent a Prefect task from refreshing its cache when the global refresh setting is enabled. It uses a static cache key function and sets the refresh_cache option to False.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@task(cache_key_fn=static_cache_key, refresh_cache=False)\ndef caching_task():\n    return random.random()\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow from Private GitLab Repository\nDESCRIPTION: Example showing how to deploy a flow from a private GitLab repository using credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_gitlab import GitLabCredentials\n\n\nif __name__ == \"__main__\":\n\n    source = GitRepository(\n        url=\"https://gitlab.com/org/private-repo.git\",\n        credentials=GitLabCredentials.load(\"my-gitlab-credentials-block\")\n    )\n\n    source = GitRepository(\n    flow.from_source(\n        source=source,\n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"private-gitlab-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Customize Prefect Logging Message Format with Bash\nDESCRIPTION: Demonstrates how to customize the log message format for Prefect flows by setting the `PREFECT_LOGGING_FORMATTERS_STANDARD_FLOW_RUN_FMT` environment variable using Bash.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_LOGGING_FORMATTERS_STANDARD_FLOW_RUN_FMT=\"%(asctime)s.%(msecs)03d | %(levelname)-7s | %(flow_run_id)s - %(message)s\"\n```\n\n----------------------------------------\n\nTITLE: Configuring DaskTaskRunner for Local Parallel Execution in Prefect\nDESCRIPTION: Enables multi-process execution on a single machine using DaskTaskRunner as a decorator on a flow function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@flow(task_runner=DaskTaskRunner())\n```\n\n----------------------------------------\n\nTITLE: Deploying with Python using Local Process with Prefect\nDESCRIPTION: This Python script defines a Prefect flow and uses the `from_source` method to deploy it. The flow code is stored locally, and the deployment is configured to use a Process work pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom pathlib import Path\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"World\"):\n    print(f\"Hello {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.from_source(\n        source=str(Path(__file__).parent),  # code stored in local directory\n        entrypoint=\"local_process_deploy_local_code.py:my_flow\",\n    ).deploy(\n        name=\"local-process-deploy-local-code\",\n        work_pool_name=\"my-process-pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Create EKS Cluster on AWS\nDESCRIPTION: This snippet uses `eksctl` to create an EKS cluster with FARGATE. It then authenticates to the cluster using `aws eks update-kubeconfig`. Replace `<CLUSTER-NAME>` with your desired cluster name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Replace the cluster name with your own value\neksctl create cluster --fargate --name <CLUSTER-NAME>\n\n# Authenticate to the cluster.\naws eks update-kubeconfig --name <CLUSTER-NAME>\n```\n\n----------------------------------------\n\nTITLE: Visualizing Dynamic Workflows with Mock Return Values in Prefect\nDESCRIPTION: This example shows how to visualize dynamic workflows with loops by using mock return values. The viz_return_value parameter is used to provide a sample return value for visualization purposes when the actual flow structure depends on runtime values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/visualize-flow-structure.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n@task(viz_return_value=[4])\ndef get_list():\n    return [1, 2, 3]\n\n@task\ndef append_one(n):\n    return n.append(6)\n\n@flow\ndef viz_return_value_tracked():\n    l = get_list()\n    for num in range(3):\n        l.append(5)\n        append_one(l)\n\nif __name__ == \"__main__\":\n    viz_return_value_tracked.visualize()\n```\n\n----------------------------------------\n\nTITLE: Submitting Tasks to a Task Runner and Accessing Results in Prefect\nDESCRIPTION: This example shows how to submit tasks to a task runner and pass the PrefectFuture between tasks. When a future is passed to another task, Prefect automatically resolves it to its result value before passing it to the downstream task.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-runners.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef say_hello(name):\n    return f\"Hello {name}!\"\n\n@task\ndef print_result(result):\n    print(type(result))\n    print(result)\n\n@flow(name=\"hello-flow\")\ndef hello_world():\n    future = say_hello.submit(\"Marvin\")\n    print_result.submit(future).wait()\n\nhello_world()\n```\n\n----------------------------------------\n\nTITLE: Setting up GCP Credentials\nDESCRIPTION: Python code to create and save GCP credentials block using service account information.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gcp import GcpCredentials\n\n# replace this PLACEHOLDER dict with your own service account info\nservice_account_info = {\n  \"type\": \"service_account\",\n  \"project_id\": \"PROJECT_ID\",\n  \"private_key_id\": \"KEY_ID\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nPRIVATE_KEY\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"SERVICE_ACCOUNT_EMAIL\",\n  \"client_id\": \"CLIENT_ID\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/SERVICE_ACCOUNT_EMAIL\"\n}\n\nGcpCredentials(\n    service_account_info=service_account_info\n).save(\"CREDENTIALS-BLOCK-NAME\")\n```\n\n----------------------------------------\n\nTITLE: Submitting AWS Batch Jobs using Prefect Flow\nDESCRIPTION: Prefect flow demonstrating how to submit AWS Batch jobs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.batch import batch_submit\n\n\n@flow\ndef example_batch_submit_flow():\n    aws_credentials = AwsCredentials(\n        aws_access_key_id=\"access_key_id\",\n        aws_secret_access_key=\"secret_access_key\"\n    )\n    job_id = batch_submit(\n        \"job_name\",\n        \"job_queue\",\n        \"job_definition\",\n        aws_credentials\n    )\n    return job_id\n\n\nif __name__ == \"__main__\":\n    example_batch_submit_flow()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Retry Handler in Python Task\nDESCRIPTION: Python code snippet showing how to use a custom retry handler in a task using the retry_condition_fn parameter in the @task decorator.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@task(retries=10, retry_condition_fn=retry_handler)\ndef get_recent_games(team_name, start_date, end_date):\n    # Generate random number.\n    failure_chance = random.random()\n    \n    # Simulate different types of failures.\n    if failure_chance < 0.3:\n        time.sleep(2)  # Allow us to see the retries in action.\n        raise Exception(\"Simulated API failure: MLB Stats API is temporarily unavailable\")\n    elif failure_chance >= 0.4:\n        time.sleep(2)  # Allow us to see the retries in action.\n        raise TimeoutError(\"Simulated timeout: Request took too long\") # Simulate empty response.\n    \n    # If no failure, proceed with actual API call.\n    team = statsapi.lookup_team(team_name)\n    schedule = statsapi.schedule(team=team[0][\"id\"], start_date=start_date, end_date=end_date)\n    for game in schedule:\n        print(game['game_id'])\n    return [game['game_id'] for game in schedule]\n```\n\n----------------------------------------\n\nTITLE: Starting a Prefect Worker from Command Line\nDESCRIPTION: Command to start a Prefect worker that polls a specified work pool for flow runs to execute. This replaces the previous agent start command used in Prefect 2.0.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -p <work pool name>\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Task Caching with Transactions in Python using Prefect\nDESCRIPTION: This snippet demonstrates how to implement multi-task caching in Prefect using transactions. It shows how to ensure that multiple tasks are always executed together or not at all, with caches only being written when the transaction is committed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task(cache_key_fn=lambda *args, **kwargs: \"static-key-1\")\ndef load_data():\n    return \"some-data\"\n\n\n@task(cache_key_fn=lambda *args, **kwargs: \"static-key-2\")\ndef process_data(data, fail):\n    if fail:\n        raise RuntimeError(\"Error! Abort!\")\n\n    return len(data)\n\n\n@flow\ndef multi_task_cache(fail: bool = True):\n    with transaction():\n        data = load_data()\n        process_data(data=data, fail=fail)\n```\n\n----------------------------------------\n\nTITLE: Configuring Concurrency Limits with flow.deploy() in Python\nDESCRIPTION: Demonstrates how to set concurrency limits when deploying a flow using the flow.deploy() method, including how to use the ConcurrencyLimitConfig and ConcurrencyLimitStrategy classes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.client.schemas.objects import (\n    ConcurrencyLimitConfig, \n    ConcurrencyLimitStrategy\n)\n\nmy_flow.deploy(..., concurrency_limit=3)\n\nmy_flow.deploy(\n    ...,\n    concurrency_limit=ConcurrencyLimitConfig(\n        limit=3, collision_strategy=ConcurrencyLimitStrategy.CANCEL_NEW\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Concurrency Limits with flow.serve() in Python\nDESCRIPTION: Shows how to configure concurrency limits when serving a flow using the flow.serve() method, including both simple integer limits and more complex configuration with collision strategies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.client.schemas.objects import (\n    ConcurrencyLimitConfig, \n    ConcurrencyLimitStrategy\n)\n\nmy_flow.serve(..., global_limit=3)\n\nmy_flow.serve(\n    ...,\n    global_limit=ConcurrencyLimitConfig(\n        limit=3, collision_strategy=ConcurrencyLimitStrategy.CANCEL_NEW\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying Multiple Prefect Flows\nDESCRIPTION: This example demonstrates deploying multiple Prefect flows using the 'deploy' function. It shows how to create deployments for different flows in the same image.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities.\")\n\n\n@flow(log_prints=True)\ndef sell():\n    print(\"Selling securities.\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        buy.to_deployment(name=\"buy-deploy\"),\n        sell.to_deployment(name=\"sell-deploy\"),\n        work_pool_name=\"my-docker-pool\",\n        image=\"my-registry/my-image:dev\",\n        push=False,\n    )\n```\n\n----------------------------------------\n\nTITLE: Cloning Private GitHub Repository using GitHubCredentials in Prefect YAML\nDESCRIPTION: This example demonstrates how to use an existing GitHubCredentials block to clone a private GitHub repository in the pull section of a prefect.yaml file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.git_clone:\n    repository: https://github.com/org/repo.git\n    credentials: \"{{ prefect.blocks.github-credentials.my-credentials }}\"\n```\n\n----------------------------------------\n\nTITLE: Listing Kubernetes Jobs in a Namespace using Prefect Flow\nDESCRIPTION: Demonstrates how to create a Prefect flow that lists Kubernetes jobs in a specified namespace using KubernetesCredentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_kubernetes.credentials import KubernetesCredentials\nfrom prefect_kubernetes.jobs import list_namespaced_job\n\n\n@flow\ndef kubernetes_orchestrator():\n    v1_job_list = list_namespaced_job(\n        kubernetes_credentials=KubernetesCredentials.load(\"k8s-creds\"),\n        namespace=\"my-namespace\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Work Pool from Existing Infrastructure Block in Python\nDESCRIPTION: This snippet demonstrates how to convert an existing Kubernetes infrastructure block into a work pool with identical configuration using the publish_as_work_pool() method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.infrastructure import KubernetesJob\n\n\nKubernetesJob.load(\"my-k8s-job\").publish_as_work_pool()\n```\n\n----------------------------------------\n\nTITLE: Implementing Exception Notification Flow\nDESCRIPTION: Example flow showing how to send email notifications when exceptions occur in a flow run.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.context import get_run_context\nfrom prefect_email import EmailServerCredentials, email_send_message\n\n\ndef notify_exc_by_email(exc):\n    context = get_run_context()\n    flow_run_name = context.flow_run.name\n    email_server_credentials = EmailServerCredentials.load(\"email-server-credentials\")\n    email_send_message(\n        email_server_credentials=email_server_credentials,\n        subject=f\"Flow run {flow_run_name!r} failed\",\n        msg=f\"Flow run {flow_run_name!r} failed due to {exc}.\",\n        email_to=email_server_credentials.username,\n    )\n\n@flow\ndef example_flow():\n    try:\n        1 / 0\n    except Exception as exc:\n        notify_exc_by_email(exc)\n        raise\n\n\nif __name__ == \"__main__\":\n    example_flow()\n```\n\n----------------------------------------\n\nTITLE: Rescheduling Late Flow Runs with Prefect API in Python\nDESCRIPTION: Reschedule late flow runs by deleting and recreating them with a delay. Imports are required from prefect and datetime. Allows fetching and rescheduling flow runs that are in a 'Late' state, using an asynchronous context manager to manage the flow runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasync def reschedule_late_flow_runs(\n    deployment_name: str,\n    delay: timedelta,\n    most_recent_n: int,\n    delete_remaining: bool = True,\n    states: list[str] | None = None\n) -> list[FlowRun]:\n    states = states or [\"Late\"]\n\n    async with get_client() as client:\n        flow_runs = await client.read_flow_runs(\n            flow_run_filter=FlowRunFilter(\n                state=dict(name=dict(any_=states)),\n                expected_start_time=dict(before_=datetime.now(timezone.utc)),\n            ),\n            deployment_filter=DeploymentFilter(name={'like_': deployment_name}),\n            sort=FlowRunSort.START_TIME_DESC,\n            limit=most_recent_n if not delete_remaining else None\n        )\n\n        rescheduled_flow_runs: list[FlowRun] = []\n        for i, run in enumerate(flow_runs):\n            await client.delete_flow_run(flow_run_id=run.id)\n            if i < most_recent_n:\n                new_run = await client.create_flow_run_from_deployment(\n                    deployment_id=run.deployment_id,\n                    state=Scheduled(scheduled_time=run.expected_start_time + delay),\n                )\n                rescheduled_flow_runs.append(new_run)\n            \n        return rescheduled_flow_runs\n```\n\n----------------------------------------\n\nTITLE: Implementing Shell Commands in Prefect Flow\nDESCRIPTION: Python code demonstrating how to integrate shell commands within a Prefect flow, including examples of both short-running operations using run() and long-running operations using context managers.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom datetime import datetime\nfrom prefect_shell import ShellOperation\n\n\n@flow\ndef download_data():\n    today = datetime.today().strftime(\"%Y%m%d\")\n\n    # for short running operations, you can use the `run` method\n    # which automatically manages the context\n    ShellOperation(\n        commands=[\n            \"mkdir -p data\",\n            \"mkdir -p data/${today}\"\n        ],\n        env={\"today\": today}\n    ).run()\n\n    # for long running operations, you can use a context manager\n    with ShellOperation(\n        commands=[\n            \"curl -O https://masie_web.apps.nsidc.org/pub/DATASETS/NOAA/G02135/north/daily/data/N_seaice_extent_daily_v3.0.csv\",\n        ],\n        working_dir=f\"data/{today}\",\n    ) as download_csv_operation:\n\n        # trigger runs the process in the background\n        download_csv_process = download_csv_operation.trigger()\n\n        # then do other things here in the meantime, like download another file\n        ...\n\n        # when you're ready, wait for the process to finish\n        download_csv_process.wait_for_completion()\n\n        # if you'd like to get the output lines, you can use the `fetch_result` method\n        output_lines = download_csv_process.fetch_result()\n\n\nif __name__ == \"__main__\":\n    download_data()\n```\n\n----------------------------------------\n\nTITLE: Deploying a Flow with Multiple Schedules\nDESCRIPTION: This Python snippet deploys a Prefect flow with multiple schedules defined using the `schedules` parameter. It uses the `Interval` schedule from `prefect.schedules` to define a recurring schedule. The example sets up a schedule to run every 10 minutes, starting from January 1, 2023, at 00:00 Central Time.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import datetime, timedelta\nfrom prefect import flow\nfrom prefect.schedules import Interval\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n        # Run every 10 minutes starting from January 1, 2023\n        # at 00:00 Central Time\n        schedules=[\n            Interval(\n                timedelta(minutes=10),\n                anchor_date=datetime(2023, 1, 1, 0, 0),\n                timezone=\"America/Chicago\"\n            )\n        ]\n    )\n```\n\n----------------------------------------\n\nTITLE: Deploying and Serving a Prefect Flow with Advanced Options\nDESCRIPTION: This snippet illustrates how to leverage additional options like `cron`, `tags`, `description`, and `version` when serving a Prefect flow. The example sets a cron schedule and assigns metadata to the deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nif __name__ == \"__main__\":\n    get_repo_info.serve(\n        name=\"my-first-deployment\",\n        cron=\"* * * * *\",\n        tags=[\"testing\", \"tutorial\"],\n        description=\"Given a GitHub repository, logs repository statistics for that repo.\",\n        version=\"tutorial/deployments\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Starting a Worker in Prefect\nDESCRIPTION: This snippet demonstrates how to start a worker using the Prefect CLI. You must specify the work pool name. If the work pool does not exist, it will be created if the type flag is used.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/workers.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -p [work pool name]\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -p \"my-pool\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -p \"my-pool\" --type \"process\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool \"my-pool\" --limit 5\n```\n\n----------------------------------------\n\nTITLE: Scheduling Shell Commands with Prefect CLI using Serve\nDESCRIPTION: This snippet illustrates using the `serve` command to schedule a shell command with Prefect. It sets up a deployment to fetch weather updates for Chicago daily, achieving automated execution with customizable parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/cli-shell.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect shell serve \"curl http://wttr.in/Chicago?format=3\" --flow-name \"Daily Chicago Weather Report\" --cron-schedule \"0 9 * * *\" --deployment-name \"Chicago Weather\"\n```\n\n----------------------------------------\n\nTITLE: Removing Task Introspection with Quote in Python\nDESCRIPTION: Demonstrates how to use Prefect's quote utility to speed up task execution by disabling argument introspection for large data structures like DataFrames\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/big-data.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\nfrom prefect.utilities.annotations import quote\nimport pandas as pd\n\n\n@task\ndef extract(url: str):\n    \"\"\"Extract data\"\"\"\n    df_raw = pd.read_parquet(url)\n    print(df_raw.info())\n    return df_raw\n\n\n@task\ndef transform(df: pd.DataFrame):\n    \"\"\"Basic transformation\"\"\"\n    df[\"tip_fraction\"] = df[\"tip_amount\"] / df[\"total_amount\"]\n    print(df.info())\n    return df\n\n\n@flow(log_prints=True)\ndef et(url: str):\n    \"\"\"ET pipeline\"\"\"\n    df_raw = extract(url)\n    df = transform(quote(df_raw))\n\n\nif __name__ == \"__main__\":\n    url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet\"\n    et(url)\n```\n\n----------------------------------------\n\nTITLE: Register Blocks from a File (CLI)\nDESCRIPTION: This command demonstrates how to register a custom block created in a `.py` file using the Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register --file my_block.py\n```\n\n----------------------------------------\n\nTITLE: Dask Integration with Existing Client\nDESCRIPTION: Example showing how to integrate Prefect with an existing Dask client and cluster for distributed data processing using dask.dataframe.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport dask.dataframe\nimport dask.distributed\nfrom prefect import flow, task\nfrom prefect_dask import DaskTaskRunner, get_dask_client\n\n\nclient = dask.distributed.Client()\n\n@task\ndef read_data(start: str, end: str) -> dask.dataframe.DataFrame:\n    df = dask.datasets.timeseries(start, end, partition_freq=\"4w\")\n    return df\n\n@task\ndef process_data(df: dask.dataframe.DataFrame) -> dask.dataframe.DataFrame:\n    with get_dask_client():\n        df_yearly_avg = df.groupby(df.index.year).mean()\n        return df_yearly_avg.compute()\n\n@flow(task_runner=DaskTaskRunner(address=client.scheduler.address))\ndef dask_pipeline():\n    df = read_data.submit(\"1988\", \"2022\")\n    df_yearly_average = process_data.submit(df)\n    return df_yearly_average\n\n\nif __name__ == \"__main__\":\n    dask_pipeline()\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from GCP GCS with Storage Block\nDESCRIPTION: This code deploys a Prefect flow from a Google Cloud Storage bucket using a GCSBucket storage block. It demonstrates loading an existing block or creating a new one with GCP credentials, and includes the necessary prefect-gcp dependency in job variables.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_gcp import GcpCredentials, GCSBucket\n\n\nif __name__ == \"__main__\":\n\n    gcs_bucket_block = GCSBucket.load(\"my-code-storage-block\")\n\n    # or \n    # gcs_bucket_block = GCSBucket(\n    #     bucket=\"my-bucket\",\n    #     folder=\"my-folder\",\n    #     credentials=GcpCredentials.load(\"my-credentials-block\")\n    # )\n\n    flow.from_source(\n        source=gcs_bucket_block,\n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"my-gcs-deployment\",\n        work_pool_name=\"my_pool\",\n        job_variables={\"env\": {\"EXTRA_PIP_PACKAGES\": \"prefect-gcp\"} }, \n    )\n```\n\n----------------------------------------\n\nTITLE: Sending Message from Prefect Flow to Slack\nDESCRIPTION: This Python snippet defines a Prefect flow to send a message to a Slack channel using 'prefect-slack'. It requires a Slack Bot user OAuth token and the Prefect SlackCredentials class. The flow retrieves its context and sends a completion message to a specified channel. Ensure your Slack app is configured with necessary permissions and tokens.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-slack/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.context import get_run_context\nfrom prefect_slack import SlackCredentials\nfrom prefect_slack.messages import send_chat_message\n\n\n@flow\ndef example_send_message_flow():\n   context = get_run_context()\n\n   # Run other tasks and subflows here\n\n   token = \"xoxb-your-bot-token-here\"\n   send_chat_message(\n         slack_credentials=SlackCredentials(token),\n         channel=\"#prefect\",\n         text=f\"Flow run {context.flow_run.name} completed :tada:\"\n   )\n\nexample_send_message_flow()\n```\n\n----------------------------------------\n\nTITLE: Converting Airflow DAG to Prefect Flow - Prefect Tasks\nDESCRIPTION: Converting Airflow tasks to Prefect tasks by decorating functions with @task. Each function contains the same core logic but utilizes Prefect's simpler orchestration model.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Prefect tasks for ETL\nfrom prefect import task, flow\n\n@task\ndef extract_data():\n    # ... (extract data as before)\n    return data\n\n@task\ndef transform_data(data):\n    # ... (transform data as before)\n    return processed_data\n\n@task\ndef load_data(processed_data):\n    # ... (load data as before)\n```\n\n----------------------------------------\n\nTITLE: Server Tasks Scheduling Configuration\nDESCRIPTION: Configuration settings for server-side task scheduling, including retry queue size and pending task timeout settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\nserver.tasks.scheduling.max_retry_queue_size = 100\nserver.tasks.scheduling.pending_task_timeout = \"PT0S\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Work Pool for Modal\nDESCRIPTION: Creates a Prefect work pool of type 'modal:push' that will be used to provision infrastructure for flow runs. The work pool remains inactive when not in use.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nuv run prefect work-pool create --type modal:push --provision-infra pref-modal-pool\n```\n\n----------------------------------------\n\nTITLE: Implementing Snowflake Flow with Tasks\nDESCRIPTION: Complete example of a Prefect flow using Snowflake connector to create tables, insert data, and fetch results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_snowflake import SnowflakeConnector\n\n\n@task\ndef setup_table(block_name: str) -> None:\n    with SnowflakeConnector.load(block_name) as connector:\n        connector.execute(\n            \"CREATE TABLE IF NOT EXISTS customers (name varchar, address varchar);\"\n        )\n        connector.execute_many(\n            \"INSERT INTO customers (name, address) VALUES (%(name)s, %(address)s);\",\n            seq_of_parameters=[\n                {\"name\": \"Ford\", \"address\": \"Highway 42\"},\n                {\"name\": \"Unknown\", \"address\": \"Space\"},\n                {\"name\": \"Me\", \"address\": \"Myway 88\"},\n            ],\n        )\n\n@task\ndef fetch_data(block_name: str) -> list:\n    all_rows = []\n    with SnowflakeConnector.load(block_name) as connector:\n        while True:\n            # Repeated fetch* calls using the same operation will\n            # skip re-executing and instead return the next set of results\n            new_rows = connector.fetch_many(\"SELECT * FROM customers\", size=2)\n            if len(new_rows) == 0:\n                break\n            all_rows.append(new_rows)\n    return all_rows\n\n@flow\ndef snowflake_flow(block_name: str) -> list:\n    setup_table(block_name)\n    all_rows = fetch_data(block_name)\n    return all_rows\n\n\nif __name__==\"__main__\":\n    snowflake_flow()\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with GitHub Storage\nDESCRIPTION: Example of deploying a Prefect flow using a GitHub storage block to load flow code\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.filesystems import GitHub\n\n  \n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a GitHub repo!\")\n\n\nif __name__ == \"__main__\":\n    Deployment.build_from_flow(\n        my_flow,\n        name=\"my-deployment\",\n        storage=GitHub.load(\"demo-repo\"),\n        parameters=dict(name=\"Marvin\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: GitHub Actions Workflow for Prefect Deployment (.deploy)\nDESCRIPTION: This YAML file defines a GitHub Actions workflow that triggers on pushes to the `main` branch.  It checks out the repository, logs into Docker Hub, sets up Python, and then installs dependencies and executes the `flow.py` script to deploy the Prefect flow.  Environment variables for the Prefect API key and URL are sourced from repository secrets.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nname: Deploy Prefect flow\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n\n      - name: Prefect Deploy\n        env:\n          PREFECT_API_KEY: ${{ secrets.PREFECT_API_KEY }}\n          PREFECT_API_URL: ${{ secrets.PREFECT_API_URL }}\n        run: |\n          pip install -r requirements.txt\n          python flow.py\n```\n\n----------------------------------------\n\nTITLE: Creating GitLab Repository Block\nDESCRIPTION: Example of creating and saving a GitLab repository block with specific branch or tag reference.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gitlab import GitLabRepository\n\n\ndef save_private_gitlab_block():\n    private_gitlab_block = GitLabRepository(\n        repository=\"https://gitlab.com/testing/my-repository.git\",\n        access_token=\"YOUR_GITLAB_PERSONAL_ACCESS_TOKEN\",\n        reference=\"branch-or-tag-name\",\n    )\n\n    private_gitlab_block.save(\"my-private-gitlab-block\")\n\n\nif __name__ == \"__main__\":\n    save_private_gitlab_block()\n```\n\n----------------------------------------\n\nTITLE: Defining SLAs with Terraform Provider\nDESCRIPTION: This HCL configuration demonstrates how to define Service Level Agreements (SLAs) using the Prefect Terraform provider. It sets up a flow, a deployment, and then defines three SLAs (time-to-completion, lateness, and frequency) using the `prefect_resource_sla` resource. Each SLA is configured with a name, severity, and duration/within/stale_after parameter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/slas.mdx#2025-04-21_snippet_3\n\nLANGUAGE: hcl\nCODE:\n```\n\"provider \\\"prefect\\\" {}\n\nresource \\\"prefect_flow\\\" \\\"my_flow\\\" {\n  name = \\\"my-flow\\\"\n}\n\nresource \\\"prefect_deployment\\\" \\\"my_deployment\\\" {\n  name    = \\\"my-deployment\\\"\n  flow_id = prefect_flow.my_flow.id\n}\n\nresource \\\"prefect_resource_sla\\\" \\\"slas\\\" {\n  resource_id = \\\"prefect.deployment.${prefect_deployment.my_deployment.id}\\\"\n  slas = [\n    {\n      name     = \\\"my-time-to-completion-sla\\\"\n      severity = \\\"high\\\"\n      duration = 30\n    },\n    {\n      name     = \\\"my-lateness-sla\\\"\n      severity = \\\"high\\\"\n      within   = 600\n    },\n    {\n      name        = \\\"my-frequency-sla\\\"\n      severity    = \\\"high\\\"\n      stale_after = 3600\n    }\n  ]\n}\"\n```\n\n----------------------------------------\n\nTITLE: Listing Databricks Jobs with Prefect Flow\nDESCRIPTION: A Prefect flow that demonstrates how to list jobs on a Databricks instance using DatabricksCredentials and the jobs_list function from prefect_databricks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-databricks/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_databricks import DatabricksCredentials\nfrom prefect_databricks.jobs import jobs_list\n\n\n@flow\ndef example_execute_endpoint_flow():\n    databricks_credentials = DatabricksCredentials.load(\"my-block\")\n    jobs = jobs_list(\n        databricks_credentials,\n        limit=5\n    )\n    return jobs\n\nif __name__ == \"__main__\":\n    example_execute_endpoint_flow()\n```\n\n----------------------------------------\n\nTITLE: Setting the concurrency limit for a Prefect work pool\nDESCRIPTION: Configures the maximum number of concurrent work items that a work pool can process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_10\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool set-concurrency-limit [OPTIONS] NAME CONCURRENCY_LIMIT\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Webhook JSON Configuration in Prefect\nDESCRIPTION: JSON configuration to create a custom webhook that captures model update events with dynamic parameters from HTTP request bodies. This defines the event structure and resource properties that will be available to downstream automations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_19\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"event\": \"model-update\",\n    \"resource\": {\n        \"prefect.resource.id\": \"product.models.{{ body.model_id}}\",\n        \"prefect.resource.name\": \"{{ body.friendly_name }}\",\n        \"run_count\": \"{{body.run_count}}\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing a Simple Flow Structure in Prefect\nDESCRIPTION: This example demonstrates how to create and visualize a basic Prefect flow with two dependent tasks. The flow calls the visualize() method to generate a diagram of the flow structure without executing the flow itself.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/visualize-flow-structure.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task(name=\"Print Hello\")\ndef print_hello(name):\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@task(name=\"Print Hello Again\")\ndef print_hello_again(name):\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@flow(name=\"Hello Flow\")\ndef hello_world(name=\"world\"):\n    message = print_hello(name)\n    message2 = print_hello_again(message)\n\nif __name__ == \"__main__\":\n    hello_world.visualize()\n```\n\n----------------------------------------\n\nTITLE: Configuring Async SQLite Connection\nDESCRIPTION: Example of creating and saving an async SQLite database connection.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_sqlalchemy import SqlAlchemyConnector, ConnectionComponents, AsyncDriver\n\nconnector = SqlAlchemyConnector(\n    connection_info=ConnectionComponents(\n        driver=AsyncDriver.SQLITE_AIOSQLITE,\n        database=\"DATABASE-PLACEHOLDER.db\"\n    )\n)\n\nif __name__ == \"__main__\":\n    connector.save(\"BLOCK_NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Triggering a Deployment from CLI\nDESCRIPTION: Demonstrates how to trigger a deployment run using the Prefect command-line interface by referencing the deployment's unique identifying name in the format {FLOW_NAME}/{DEPLOYMENT_NAME}.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run my-first-flow/my-first-deployment\n```\n\n----------------------------------------\n\nTITLE: Accessing Task State Objects with return_state Flag in Prefect\nDESCRIPTION: Example demonstrating how to retrieve the state object of a task using the return_state flag, allowing for conditional logic based on the task's state.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n\n@task\ndef add_one(x):\n    return x + 1\n\n\n@flow\ndef my_flow():\n    result = add_one(1)\n    assert isinstance(result, int) and result == 2\n\n    state = add_one(1, return_state=True)\n    assert state.is_completed() is True\n    assert state.result() == 2\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Prefect Workflow\nDESCRIPTION: Code modification to turn a Prefect workflow into a scheduled deployment that runs every minute using a cron expression. Creates a persistent process that executes the workflow on schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    github_stars.serve(\n        name=\"first-deployment\",\n        cron=\"* * * * *\",\n        parameters={\"repos\": [\"PrefectHQ/prefect\"]}\n    )\n```\n\n----------------------------------------\n\nTITLE: Flow failure handling with return_state in Prefect 3.0\nDESCRIPTION: Example showing how to check task states using return_state=True to conditionally fail a flow when a task fails. This approach gives explicit control over flow states based on task outcomes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.states import Failed\n\n@task\ndef failing_task():\n    raise ValueError(\"Task failed\")\n\n@flow\ndef my_flow():\n    state = failing_task(return_state=True)\n    if state.is_failed():\n        raise ValueError(state.result())\n    return \"Flow completed successfully\"\n\ntry:\n    print(my_flow())\nexcept ValueError as e:\n    print(f\"Flow failed: {e}\")  # Output: Flow failed: Task failed\n```\n\n----------------------------------------\n\nTITLE: Implementing Flow with Environment Variables in Python\nDESCRIPTION: This Python snippet defines a flow that uses environment variables to execute a task, raising an error if the necessary variable is not set.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom prefect import flow, task\n\n\n@task\ndef do_something_important(not_so_secret_value: str) -> None:\n    print(f\"Doing something important with {not_so_secret_value}!\\n\")\n\n\n@flow(log_prints=True)\ndef some_work():\n    environment = os.environ.get(\"EXECUTION_ENVIRONMENT\", \"local\")\n    \n    print(f\"Coming to you live from {environment}!\\n\")\n    \n    not_so_secret_value = os.environ.get(\"MY_NOT_SO_SECRET_CONFIG\")\n    \n    if not_so_secret_value is None:\n        raise ValueError(\"You forgot to set MY_NOT_SO_SECRET_CONFIG!\")\n\n    do_something_important(not_so_secret_value)\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private Bitbucket Repository with Credentials Block\nDESCRIPTION: This snippet shows how to create a Prefect deployment from a private Bitbucket repository using a BitBucketCredentials block for authentication. It creates a GitRepository object with the repository URL and credentials before passing it to flow.from_source().\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_bitbucket import BitBucketCredentials\n\nif __name__ == \"__main__\":\n\n    github_repo = GitRepository(\n        url=\"https://bitbucket.com/org/my-private-repo.git\",\n        credentials=BitBucketCredentials.load(\"my-bitbucket-credentials-block\")\n    )\n\n    flow.from_source(\n        source=source,\n        entrypoint=\"bb_private_repo_credentials_block.py:my_flow\",\n    ).deploy(\n        name=\"private-bitbucket-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Emitting Prefect Events\nDESCRIPTION: Example of emitting events in an event-driven system using prefect-client. Shows how to emit a custom event with associated resource metadata.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/client/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.events import emit_event\n\n\ndef something_happened():\n    emit_event(\"my-event\", resource={\"prefect.resource.id\": \"foo.bar\"})\n\nsomething_happened()\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Task State Change Hooks in Python with Prefect\nDESCRIPTION: This snippet demonstrates how to define and attach state change hooks to a Prefect task. It includes two hooks: one defined separately and another defined using a decorator. The hooks are executed when the task completes successfully.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# for type hints only\nfrom prefect import Task\nfrom prefect.client.schemas.objects import TaskRun\nfrom prefect.states import State\n\n\ndef first_task_hook(tsk: Task, run: TaskRun, state: State) -> None:\n    if not state.name == 'Cached':\n        print('I run anytime this task executes successfully')\n    else:\n        print('and can condition my behavior on details of this run')\n\n\n@task(log_prints=True, on_completion=[first_task_hook])\ndef nice_task(name: str):\n    print(f\"Hello {name}!\")\n\n\n# alternatively hooks can be specified via decorator\n@nice_task.on_completion\ndef second_hook(tsk: Task, run: TaskRun, state: State) -> None:\n    print('another hook')\n\nnice_task(name='Marvin')\n```\n\n----------------------------------------\n\nTITLE: Creating Deployments with Compound Triggers in Python\nDESCRIPTION: This snippet shows how to use DeploymentCompoundTrigger to create more complex trigger conditions. It configures a deployment that requires multiple events to occur before the flow runs, using the 'require' parameter set to 'all'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.events import DeploymentCompoundTrigger\n\n\n@flow(log_prints=True)\ndef decorated_fn(param_1: str):\n    print(param_1)\n\n\nif __name__==\"__main__\":\n    decorated_fn.deploy(\n        name=\"my-deployment\",\n        image=\"my-image-registry/my-image:my-tag\",\n        triggers=[\n            DeploymentCompoundTrigger(\n                enabled=True,\n                name=\"my-compound-trigger\",\n                require=\"all\",\n                triggers=[\n                    {\n                      \"type\": \"event\",\n                      \"match\": {\"prefect.resource.id\": \"my.external.resource\"},\n                      \"expect\": [\"external.resource.pinged\"],\n                    },\n                    {\n                      \"type\": \"event\",\n                      \"match\": {\"prefect.resource.id\": \"my.external.resource\"},\n                      \"expect\": [\"external.resource.replied\"],\n                    },\n                ],\n                parameters={\n                    \"param_1\": \"{{ event }}\",\n                },\n            )\n        ],\n        work_pool_name=\"my-work-pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with Git Repository Source\nDESCRIPTION: Example of deploying a Prefect flow using GitRepository as the source with authentication\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.blocks.system import Secret\nfrom prefect.runner.storage import GitRepository\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a GitHub repo!\")\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=GitRepository(\n            url=\"https://github.com/me/myrepo.git\",\n            credentials={\"username\": \"oauth2\", \"access_token\": Secret.load(\"my-github-pat\")},\n        ),\n        entrypoint=\"example.py:my_flow\"\n    ).deploy(\n        name=\"my-deployment\",\n        parameters=dict(name=\"Marvin\"),\n        work_pool_name=\"local\", # or the name of your work pool\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Private Bitbucket Repository with Secret Block\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a private Bitbucket repository using a Secret block for authentication. It loads a secret containing a Bitbucket access token and creates a GitRepository object with the repository URL and credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect.blocks.system import Secret\n\n\nif __name__ == \"__main__\":\n    github_repo=GitRepository(\n        url=\"https://bitbucket.com/org/my-private-repo.git\",\n        credentials={\n            \"access_token\": Secret.load(\"my-secret-block-with-my-bb-credentials\")\n        },\n    )\n    \n    flow.from_source(\n        source=github_repo,\n        entrypoint=\"bb_private_repo_secret_block.py:my_flow\",\n    ).deploy(\n        name=\"private-bitbucket-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Databricks Notebook Example\nDESCRIPTION: A sample Databricks notebook that accepts a name parameter and prints a welcome message. This notebook is used in the subsequent Prefect flow example.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-databricks/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nname = dbutils.widgets.get(\"name\")\nmessage = f\"Don't worry {name}, I got your request! Welcome to prefect-databricks!\"\nprint(message)\n```\n\n----------------------------------------\n\nTITLE: Implementing Delayed Retry in Python Task\nDESCRIPTION: Python code snippet showing how to implement a delayed retry strategy using the retry_delay_seconds parameter in the @task decorator.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@task(retries=10, retry_delay_seconds=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndef get_recent_games(team_name, start_date, end_date):\n    # Simulate random API failure (70% chance).\n    if random.random() < 0.7:\n        raise Exception(\"Simulated API failure: MLB Stats API is temporarily unavailable\")\n    \n    # If no failure, proceed with actual API call.\n    team = statsapi.lookup_team(team_name)\n    schedule = statsapi.schedule(team=team[0][\"id\"], start_date=start_date, end_date=end_date)\n    for game in schedule:\n        print(game['game_id'])\n    return [game['game_id'] for game in schedule]\n```\n\n----------------------------------------\n\nTITLE: Emitting Events in Prefect Flow Function in Python\nDESCRIPTION: A Prefect flow emits events 'table-missing' or 'table-empty' based on the state of a database table. Dependencies include prefect and a database module.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.events import emit_event\nfrom myproject.db import Table\n\n\n@flow\ndef transform(table_name: str):\n  table = Table(table_name)\n\n  if not table.exists():\n    emit_event(\n        event=\"table-missing\",\n        resource={\"prefect.resource.id\": \"etl-events.transform\"}\n    )\n  elif table.is_empty():\n    emit_event(\n        event=\"table-empty\",\n        resource={\"prefect.resource.id\": \"etl-events.transform\"}\n    )\n  else:\n    # transform data\n    ...\n```\n\n----------------------------------------\n\nTITLE: Previewing scheduled work for a Prefect work pool\nDESCRIPTION: Shows a preview of the scheduled work across all queues in a work pool, with an option to specify the time horizon.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_13\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool preview [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Configuring Task with Name and Description in Python\nDESCRIPTION: This snippet demonstrates how to use the task decorator to provide optional name and description arguments to a task in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@task(name=\"hello-task\", description=\"This task says hello.\")\ndef my_task():\n    print(\"Hello, I'm a task\")\n```\n\n----------------------------------------\n\nTITLE: Setting Default Parameters in Prefect Flow Deployment\nDESCRIPTION: Demonstrates how to set default parameters for a Prefect flow deployment using the parameters keyword argument in flow.deploy(). Shows parameter overriding for customized behavior.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",\n        # Will print \"Hello, Marvin!\" by default instead of \"Hello, world!\"\n        parameters={\"name\": \"Marvin\"},\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n    )\n```\n\n----------------------------------------\n\nTITLE: Scheduling Prefect Workflow\nDESCRIPTION: Command to schedule the workflow to run daily at 8:00 AM using cron syntax\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuvx prefect-cloud schedule main/my_first_deployment \"0 8 * * *\"\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub Credentials Block\nDESCRIPTION: Python code to create and save a GitHub credentials block with an access token\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_github import GitHubCredentials\n\n\ngithub_credentials_block = GitHubCredentials(token=\"my_token\")\ngithub_credentials_block.save(name=\"my-github-credentials-block\")\n```\n\n----------------------------------------\n\nTITLE: Creating MLB Game Analysis Markdown Artifact\nDESCRIPTION: Python code that generates a markdown report as an artifact containing MLB game analysis data. Uses pandas for data formatting and Prefect's create_markdown_artifact for artifact creation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n## Raw Data\\n{df.to_markdown(index=False)}\\n\\n\\\"\\\"\\\"\n    create_markdown_artifact(\n        key=\"game-analysis\",\n        markdown=markdown_report,\n        description=\"Game analysis report\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with GitHub Actions in YAML\nDESCRIPTION: This snippet presents a complete GitHub Actions workflow for deploying a Prefect flow. It includes steps for checking out code, logging into Docker Hub, setting up Python, authenticating with Prefect, and running Prefect deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nname: Deploy Prefect flow\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n\n      - name: Prefect Auth\n        uses: PrefectHQ/actions-prefect-auth@v1\n        with:\n          prefect-api-key: ${{ secrets.PREFECT_API_KEY }}\n          prefect-workspace: ${{ secrets.PREFECT_WORKSPACE }}\n\n      - name: Run Prefect Deploy\n        uses: PrefectHQ/actions-prefect-deploy@v4\n        with:\n          deployment-names: my-deployment\n          requirements-file-paths: requirements.txt\n```\n\n----------------------------------------\n\nTITLE: List Schedules\nDESCRIPTION: Display all schedules associated with a specific deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_10\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule ls [OPTIONS] DEPLOYMENT_NAME\n```\n\n----------------------------------------\n\nTITLE: Running Commands on Azure Container Instances with Prefect\nDESCRIPTION: Example flow that demonstrates running a command on an Azure Container Instance using AzureContainerInstanceJob, which requires credentials and Azure resource configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_azure import AzureContainerInstanceCredentials\nfrom prefect_azure.container_instance import AzureContainerInstanceJob\n\n\n@flow\ndef container_instance_job_flow():\n    aci_credentials = AzureContainerInstanceCredentials.load(\"MY_BLOCK_NAME\")\n    container_instance_job = AzureContainerInstanceJob(\n        aci_credentials=aci_credentials,\n        resource_group_name=\"azure_resource_group.example.name\",\n        subscription_id=\"<MY_AZURE_SUBSCRIPTION_ID>\",\n        command=[\"echo\", \"hello world\"],\n    )\n    return container_instance_job.run()\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Prefect Deployments\nDESCRIPTION: This snippet shows how to create multiple Prefect deployments using the 'deploy' function. It demonstrates deploying the same flow with different configurations in the same codebase.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import deploy, flow\n\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        buy.to_deployment(name=\"dev-deploy\", work_pool_name=\"my-docker-pool\"),\n        buy.to_deployment(name=\"prod-deploy\", work_pool_name=\"my-other-docker-pool\"),\n        image=\"my-registry/my-image:dev\",\n        push=False,\n    )\n```\n\n----------------------------------------\n\nTITLE: Prefect Logging with Disabled Print Logging in Python\nDESCRIPTION: Demonstrates configuring a task to not log print statements using `log_prints=False` while the parent flow is set to log prints. Highlighting control over print logging at the task level.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\n\n@task(log_prints=False)\ndef my_task():\n    print(\"not logging print statements in this task\")\n\n@flow(log_prints=True)\ndef my_flow():\n    print(\"we're logging print statements from a flow\")\n    my_task()\n```\n\n----------------------------------------\n\nTITLE: Deploying Model Inference Flow to Prefect Cloud\nDESCRIPTION: Command to deploy the model_inference.py flow to Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython model_inference.py\n```\n\n----------------------------------------\n\nTITLE: Loading a Prefect Flow from Remote Source in Python\nDESCRIPTION: This code snippet allows users to define how to retrieve a Prefect flow from remote sources using `flow.from_source`. It requires the `source` of the flow and the `entrypoint` to identify where the flow is located within the source. Supported source types include URLs and Git repositories.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom prefect import flow\n\n\nmy_flow = flow.from_source(\n    source=\"https://github.com/PrefectHQ/prefect.git\",\n    entrypoint=\"flows/hello_world.py:hello\"\n)\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Running Job Variable Overrides via CLI\nDESCRIPTION: This Bash snippet demonstrates how to run a deployment from the command line interface, passing job variables directly through command flags.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run \\\n  --id \"fb8e3073-c449-474b-b993-851fe5e80e53\" \\\n  --job-variable MY_NEW_ENV_VAR=42 \\\n  --job-variable HELLO=THERE\n```\n\n----------------------------------------\n\nTITLE: Running Shell Script to Get Git Commit Hash in Prefect YAML\nDESCRIPTION: This example demonstrates using the run_shell_script utility step to retrieve a short Git commit hash and use it as a Docker image tag during the build process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nbuild:\n- prefect.deployments.steps.run_shell_script:\n    id: get-commit-hash\n    script: git rev-parse --short HEAD\n    stream_output: false\n- prefect_docker.deployments.steps.build_docker_image:\n    requires: prefect-docker>=0.3.0\n    image_name: my-image\n    tag: \"{{ get-commit-hash.stdout }}\"\n    dockerfile: auto\n```\n\n----------------------------------------\n\nTITLE: Scheduled Flow Deployment\nDESCRIPTION: Enhanced deployment script with cron scheduling to run the flow daily at midnight.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom pathlib import Path\n\ndef read_requirements(file_path=\"requirements.txt\"):\n    \"\"\"Read and parse requirements.txt file\"\"\"\n    requirements = Path(file_path).read_text().splitlines()\n    return [req.strip() for req in requirements if req.strip() and not req.startswith('#')]\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/PrefectHQ/dev-day-zoom-out.git\",\n        entrypoint=\"track_1_build_workflows/session_2_resilent_workflows/4_deploy_and_schedule/mlb_flow_managed.py:mlb_flow\",\n    ).deploy(\n        name=\"mlb-managed-flow\",\n        work_pool_name=\"managed-pool\",\n        parameters={\"team_name\": \"phillies\", \"start_date\": \"06/01/2024\", \"end_date\": \"06/30/2024\"},\n        job_variables={\"pip_packages\": read_requirements()},\n        cron=\"0 0 * * *\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Managed Work Pool\nDESCRIPTION: This command creates a Prefect Managed Work Pool, which allows running flows without setting up infrastructure or maintaining workers. Prefect Managed execution handles compute, execution, and scheduling automatically.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create my-managed-pool --type prefect:managed\n```\n\n----------------------------------------\n\nTITLE: Defining SLAs using .deploy method in Python\nDESCRIPTION: This Python snippet illustrates how to define Service Level Agreements (SLAs) using the `.deploy` method in Prefect. It defines a flow `my_flow` and deploys it with three SLAs: `TimeToCompletionSla`, `LatenessSla`, and `FrequencySla`. These SLAs are configured with specific names, durations/within periods/stale_after periods, and 'high' severity.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/slas.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"    from prefect import flow\n    from prefect._experimental.sla.objects import TimeToCompletionSla, LatenessSla, FrequencySla\n\n    @flow\n    def my_flow():\n        pass\n\n    flow.from_source(\n        source=source,\n        entrypoint=\\\"my_file.py:my_flow\\\",\n    ).deploy(\n        name=\\\"my-deployment\\\",\n        work_pool_name=\\\"my_pool\\\",\n        _sla=[\n            TimeToCompletionSla(name=\\\"my-time-to-completion-sla\\\", duration=30, severity=\\\"high\\\"),\n            LatenessSla(name=\\\"my-lateness-sla\\\", within=timedelta(minutes=10), severity=\\\"high\\\"),\n            FrequencySla(name=\\\"my-frequency-sla\\\", stale_after=timedelta(hours=1), severity=\\\"high\\\"),\n        ]\n    )\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Compound Trigger with Mixed Event and Metric Conditions in Prefect\nDESCRIPTION: A compound trigger that fires if any of the specified conditions occur: a flow run stuck in Pending state, a work pool becoming unready, or the average lateness exceeding 10 minutes. This demonstrates mixing proactive events, reactive events, and metrics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"compound\",\n  \"require\": \"any\",\n  \"triggers\": [\n    {\n      \"type\": \"event\",\n      \"posture\": \"Proactive\",\n      \"after\": [\"prefect.flow-run.Pending\"],\n      \"expect\": [\"prefect.flow-run.Running\", \"prefect.flow-run.Crashed\"],\n      \"for_each\": [\"prefect.resource.id\"],\n      \"match_related\": {\n        \"prefect.resource.name\": \"daily-customer-export\",\n        \"prefect.resource.role\": \"flow\"\n      }\n    },\n    {\n      \"type\": \"event\",\n      \"posture\": \"Reactive\",\n      \"expect\": [\"prefect.work-pool.not-ready\"],\n      \"match\": {\n        \"prefect.resource.name\": \"kubernetes-workers\",\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"metric\": {\n        \"name\": \"lateness\",\n        \"operator\": \">\",\n        \"threshold\": 600,\n        \"range\": 3600,\n        \"firing_for\": 300\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Cache Storage with S3 in Prefect\nDESCRIPTION: Shows how to configure cache storage using an S3 bucket for remote cache record storage. This allows cache records to be stored in a cloud object store separate from task results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE, INPUTS\n\nfrom prefect_aws import S3Bucket\n\ncache_policy = (TASK_SOURCE + INPUTS).configure(key_storage=S3Bucket.load(\"my-bucket\"))\n\n@task(cache_policy=cache_policy)\ndef my_cached_task(x: int):\n    return x + 42\n```\n\n----------------------------------------\n\nTITLE: PostgreSQL Docker Container Setup\nDESCRIPTION: Docker command to start a PostgreSQL instance for use with Prefect, including volume mounting and environment configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name prefect-postgres -v prefectdb:/var/lib/postgresql/data -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=yourTopSecretPassword -e POSTGRES_DB=prefect postgres:latest\n```\n\n----------------------------------------\n\nTITLE: Accessing Runtime Information in Python Flow and Task\nDESCRIPTION: Shows how to access runtime context information for flow runs, task runs, and deployments using the Prefect runtime module\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/runtime-context.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect import runtime\n\n@flow(log_prints=True)\ndef my_flow(x):\n    print(\"My name is\", runtime.flow_run.name)\n    print(\"I belong to deployment\", runtime.deployment.name)\n    my_task(2)\n\n@task\ndef my_task(y):\n    print(\"My name is\", runtime.task_run.name)\n    print(\"Flow run parameters:\", runtime.flow_run.parameters)\n\nif __name__ == \"__main__\":\n    my_flow(1)\n```\n\n----------------------------------------\n\nTITLE: Saving Shell Commands as Prefect Blocks\nDESCRIPTION: Example showing how to save and load shell commands as reusable Prefect blocks for use across multiple flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_shell import ShellOperation\n\n\nping_op = ShellOperation(commands=[\"ping -t 1 prefect.io\"])\nping_op.save(\"block-name\")\n\n# Load the saved block:\nping_op = ShellOperation.load(\"block-name\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Log Highlighter and Handler in Python\nDESCRIPTION: Demonstrates how to extend Prefect's logging system with a custom highlighter that can highlight email addresses in logs. This code creates a custom console handler that can be referenced in the logging configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom typing import Dict, Union\n\nfrom rich.highlighter import Highlighter\n\nfrom prefect.logging.handlers import PrefectConsoleHandler\nfrom prefect.logging.highlighters import PrefectConsoleHighlighter\n\nclass CustomConsoleHighlighter(PrefectConsoleHighlighter):\n    base_style = \"log.\"\n    highlights = PrefectConsoleHighlighter.highlights + [\n        # ?P<email> is naming this expression as `email`\n        r\"(?P<email>[\\w-]+@([\\w-]+\\.)+[\\w-]+)\",\n    ]\n\nclass CustomConsoleHandler(PrefectConsoleHandler):\n    def __init__(\n        self,\n        highlighter: Highlighter = CustomConsoleHighlighter,\n        styles: Dict[str, str] = None,\n        level: Union[int, str] = logging.NOTSET,\n   ):\n        super().__init__(highlighter=highlighter, styles=styles, level=level)\n```\n\n----------------------------------------\n\nTITLE: Azure Container Instances Deployment Script Example\nDESCRIPTION: Python script demonstrating how to deploy a flow to the Azure Container Instances work pool using the provisioned infrastructure. The script builds and pushes a Docker image to the ACR registry.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.docker import DockerImage                                \n\n\n@flow(log_prints=True)                                                         \ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow running on an Azure Container Instance!\") \n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(                                                            \n        name=\"my-deployment\",\n        work_pool_name=\"my-work-pool\",                                    \n        image=DockerImage(                                                 \n            name=\"my-image:latest\",                                       \n            platform=\"linux/amd64\",                                            \n        )                                                                 \n    )       \n```\n\n----------------------------------------\n\nTITLE: Delete a Block Document\nDESCRIPTION: This code shows how to delete a block document using the `.delete()` method. It deletes the `s3-bucket/my-data-bucket-block` block document. It uses the generic Block class.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.core import Block\n\nBlock.delete(\"s3-bucket/my-data-bucket-block\")\n```\n\n----------------------------------------\n\nTITLE: Serving a Prefect Flow from Remote Storage\nDESCRIPTION: This snippet demonstrates how to serve a Prefect flow that is loaded from a remote storage source. The `serve` method functions the same as with local flows, enabling periodic polling of remote storage for updates.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/org/repo.git\",\n        entrypoint=\"flows.py:my_flow\"\n    ).serve(name=\"my-deployment\")\n```\n\n----------------------------------------\n\nTITLE: Pause Schedule\nDESCRIPTION: Command to temporarily pause a deployment schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule pause [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Worker for Self-Hosted Server\nDESCRIPTION: YAML configuration for connecting a Prefect worker to a self-hosted Prefect server in the same cluster.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nworker:\n  apiConfig: selfHostedServer\n  config:\n    workPool: kube-test\n  selfHostedServerApiConfig:\n    apiUrl: http://prefect-server.prefect.svc.cluster.local:4200/api\n```\n\n----------------------------------------\n\nTITLE: Prefect YAML Configuration for AWS S3 Deployment\nDESCRIPTION: This YAML configuration defines how to push code to and pull code from an AWS S3 bucket for a Prefect deployment. It includes optional credentials reference for private buckets and defines the deployment configuration with work pool settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\nbuild: null\n\npush:\n- prefect_aws.deployments.steps.push_to_s3:\n    id: push_code\n    requires: prefect-aws>=0.5\n    bucket: my-bucket\n    folder: my-folder\n    credentials: \"{{ prefect.blocks.aws-credentials.my-credentials-block }}\" # if explicit authentication is required\n\npull:\n- prefect_aws.deployments.steps.pull_from_s3:\n    id: pull_code\n    requires: prefect-aws>=0.5\n    bucket: '{{ push_code.bucket }}'\n    folder: '{{ push_code.folder }}'\n    credentials: \"{{ prefect.blocks.aws-credentials.my-credentials-block }}\" # if explicit authentication is required \n\ndeployments:\n- name: my-aws-deployment\n  version: null\n  tags: []\n  concurrency_limit: null\n  description: null\n  entrypoint: my_file.py:my_flow\n  parameters: {}\n  work_pool:\n    name: my-work-pool\n    work_queue_name: null\n    job_variables: {}\n  enforce_parameter_schema: true\n  schedules: []\n```\n\n----------------------------------------\n\nTITLE: Setting Up Coiled with Cloud Account\nDESCRIPTION: Connects Coiled to a cloud account (AWS, Google Cloud, Azure) using an interactive CLI. Necessary for running flows in the cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncoiled setup\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment with Prefect YAML\nDESCRIPTION: This YAML configuration file defines a Prefect deployment, specifying a local working directory and a work pool. This method allows for interactive creation and modification of deployment settings via the CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /my_directory\n\ndeployments:\n- name: local-process-deploy-local-code\n  entrypoint: local_process_deploy_local_code.py:my_flow\n  work_pool:\n    name: my-process-pool\n```\n\n----------------------------------------\n\nTITLE: View Flow Run Logs\nDESCRIPTION: Command to view logs for a specific flow run. Supports options for viewing head/tail of logs, setting number of logs to display, and reversing log order.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs logs [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Resuming a Paused Prefect Flow Run\nDESCRIPTION: This snippet demonstrates how to resume a paused Prefect flow run using the `resume_flow_run` function. It requires the `FLOW_RUN_ID` of the flow run to be resumed.  The `resume_flow_run` function is called to continue the execution of the paused flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import resume_flow_run\n\nresume_flow_run(FLOW_RUN_ID)\n```\n\n----------------------------------------\n\nTITLE: Adding Dependencies to Managed Flow Deployment\nDESCRIPTION: Python deployment configuration showing how to specify additional Python package dependencies that will be installed at runtime in the managed flow container.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/managed.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/prefecthq/demo.git\",\n        entrypoint=\"flow.py:my_flow\",\n    ).deploy(\n        name=\"test-managed-flow\",\n        work_pool_name=\"my-managed-pool\",\n        job_variables={\"pip_packages\": [\"pandas\", \"prefect-aws\"]}\n    )\n```\n\n----------------------------------------\n\nTITLE: List Deployments\nDESCRIPTION: Command to view all deployments or filter deployments for specific flows, with options to sort by creation date.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Access flow code from private Bitbucket (Python)\nDESCRIPTION: This code demonstrates how to access flow code stored in a private Bitbucket repository using the GitRepository storage and the BitBucketCredentials block.  It loads the saved credentials block and passes it to the GitRepository constructor.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.runner.storage import GitRepository\nfrom prefect_bitbucket import BitBucketCredentials\n\n\nif __name__ == \"__main__\":\n    \n    source = GitRepository(\n        url=\"https://bitbucket.com/org/private-repo.git\",\n        credentials=BitBucketCredentials.load(\"my-bitbucket-credentials-block\")\n        )\n\n    flow.from_source(\n        source=source,\n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"private-bitbucket-deploy\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Running DBT Cloud Job Flow\nDESCRIPTION: Async Python flow to execute a DBT Cloud job and wait for completion.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt.cloud import DbtCloudJob\nfrom prefect_dbt.cloud.jobs import run_dbt_cloud_job\nimport asyncio\n\n@flow\nasync def run_dbt_job_flow():\n    result = await run_dbt_cloud_job(\n        dbt_cloud_job = await DbtCloudJob.load(\"JOB-BLOCK-NAME-PLACEHOLDER\"),\n        targeted_retries = 0,\n    )\n    return await result\n\nif __name__ == \"__main__\":\n    asyncio.run(run_dbt_job_flow())\n```\n\n----------------------------------------\n\nTITLE: DBT Programmatic Invocation Example\nDESCRIPTION: Shows how to use dbt's programmatic invocation with Prefect tasks\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt.cli.tasks import from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command, dbt_build_task\n\n\n@flow\ndef dbt_build_flow():\n    trigger_dbt_cli_command(\n        command=\"dbt deps\", project_dir=\"/Users/test/my_dbt_project_dir\",\n    )\n    dbt_build_task(\n        project_dir = \"/Users/test/my_dbt_project_dir\",\n        create_summary_artifact = True,\n        summary_artifact_key = \"dbt-build-task-summary\",\n        extra_command_args=[\"--select\", \"foo_model\"]\n    )\n\n\nif __name__ == \"__main__\":\n    dbt_build_flow()\n```\n\n----------------------------------------\n\nTITLE: Running Deployment Script in Bash\nDESCRIPTION: Commands to execute the deployment creation script and schedule a flow run.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/schedule.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython create_deployment.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run 'show-stars/my-first-deployment'\n```\n\n----------------------------------------\n\nTITLE: Caching Docker Builds with build-push-action in YAML\nDESCRIPTION: This snippet shows how to use the docker/build-push-action with GitHub Actions caching. It builds and pushes a Docker image, using environment variables for tagging and enabling GHA caching for faster subsequent builds.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Build and push\n  id: build-docker-image\n  env:\n      GITHUB_SHA: ${{ steps.get-commit-hash.outputs.COMMIT_HASH }}\n  uses: docker/build-push-action@v5\n  with:\n    context: ${{ env.PROJECT_NAME }}/\n    push: true\n    tags: ${{ secrets.DOCKER_USERNAME }}/${{ env.PROJECT_NAME }}:${{ env.GITHUB_SHA }}-stg\n    cache-from: type=gha\n    cache-to: type=gha,mode=max\n```\n\n----------------------------------------\n\nTITLE: Complete Prefect YAML File with Templating Examples\nDESCRIPTION: This example provides a complete prefect.yaml file that demonstrates various templating options including step outputs, blocks, variables, and environment variables for Docker-based deployments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build-image\n    requires: prefect-docker>=0.6.0\n    image_name: my-repo/my-image\n    tag: my-tag\n    dockerfile: auto\n\npush:\n- prefect_docker.deployments.steps.push_docker_image:\n    requires: prefect-docker>=0.6.0\n    image_name: my-repo/my-image\n    tag: my-tag\n    credentials: \"{{ prefect.blocks.docker-registry-credentials.dev-registry }}\"\n\ndeployments:\n- # base metadata\n  name: null\n  version: \"{{ build-image.tag }}\"\n  tags:\n  - \"{{ $my_deployment_tag }}\"\n  - \"{{ prefect.variables.some_common_tag }}\"\n  description: null\n  schedule: null\n  concurrency_limit: null\n\n  # flow-specific fields\n  entrypoint: null\n  parameters: {}\n\n  # infra-specific fields\n  work_pool:\n    name: \"my-k8s-work-pool\"\n    work_queue_name: null\n    job_variables:\n      image: \"{{ build-image.image }}\"\n      cluster_config: \"{{ prefect.blocks.kubernetes-cluster-config.my-favorite-config }}\"\n```\n\n----------------------------------------\n\nTITLE: Jinja Templating Example for Notifications\nDESCRIPTION: This code shows how to use Jinja templating in automation notifications to dynamically include details about flow runs. It demonstrates how to access properties of flow run objects and format them in notification messages.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nFlow run {{ flow_run.name }} entered state {{ flow_run.state.name }}.\n\n    Timestamp: {{ flow_run.state.timestamp }}\n    Flow ID: {{ flow_run.flow_id }}\n    Flow Run ID: {{ flow_run.id }}\n    State message: {{ flow_run.state.message }}\n```\n\n----------------------------------------\n\nTITLE: Defining Triggers in YAML for Deployment\nDESCRIPTION: This YAML snippet illustrates how to define a deployment with triggers that respond to events. It shows how to specify expectations and matching resources for automation related to deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n  - name: my-deployment\n    entrypoint: path/to/flow.py:decorated_fn\n    work_pool:\n      name: my-work-pool\n    triggers:\n      - type: event\n        enabled: true\n        match:\n          prefect.resource.id: my.external.resource\n        expect:\n          - external.resource.pinged\n        parameters:\n          param_1: \"{{ event }}\"\n```\n\n----------------------------------------\n\nTITLE: Save an S3Bucket Block Document\nDESCRIPTION: This snippet demonstrates how to save an `S3Bucket` block document for future use. It uses the `.save()` method to store the block document with the name \"my-data-bucket-block\". It also demonstrates how to overwrite an existing block document by passing `overwrite=True` to the `.save()` method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nbucket_block.save(name=\"my-data-bucket-block\")\n```\n\nLANGUAGE: python\nCODE:\n```\nbucket_block.save(overwrite=True)\n```\n\n----------------------------------------\n\nTITLE: Configuring Resource Annotations with DaskTaskRunner\nDESCRIPTION: Example demonstrating how to use resource annotations with Dask in Prefect. It creates a LocalCluster with specified resources (GPU and process) and shows how to annotate tasks to require specific resources, controlling task execution based on resource availability.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport dask\nfrom prefect import flow, task\nfrom prefect_dask.task_runners import DaskTaskRunner\n\n\n@task\ndef show(x):\n    print(x)\n\n# Create a `LocalCluster` with some resource annotations\n# Annotations are abstract in dask and not inferred from your system.\n# Here, we claim that our system has 1 GPU and 1 process available per worker\n@flow(\n    task_runner=DaskTaskRunner(\n        cluster_kwargs={\"n_workers\": 1, \"resources\": {\"GPU\": 1, \"process\": 1}}\n    )\n)\n\ndef my_flow():\n    with dask.annotate(resources={'GPU': 1}):\n        future = show(0)  # this task requires 1 GPU resource on a worker\n\n    with dask.annotate(resources={'process': 1}):\n        # These tasks each require 1 process on a worker; because we've\n        # specified that our cluster has 1 process per worker and 1 worker,\n        # these tasks will run sequentially\n        future = show(1)\n        future = show(2)\n        future = show(3)\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Using Rich Markup in Flow Logs\nDESCRIPTION: Example flow that demonstrates how to use Rich's markup syntax in Prefect logs to add formatting. This example highlights the word 'fancy' in bold red text.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.logging import get_run_logger\n\n@flow\ndef my_flow():\n    logger = get_run_logger()\n    logger.info(\"This is [bold red]fancy[/]\")\n\nmy_flow()\n```\n\n----------------------------------------\n\nTITLE: Specifying remote options for Ray tasks\nDESCRIPTION: Example of using the remote_options context to control task's remote options such as CPU and GPU allocation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect_ray.task_runners import RayTaskRunner\nfrom prefect_ray.context import remote_options\n\n\n@task\ndef process(x):\n    return x + 1\n\n\n@flow(task_runner=RayTaskRunner())\ndef my_flow():\n    with remote_options(num_cpus=4, num_gpus=2):\n        process.submit(42).wait()\n```\n\n----------------------------------------\n\nTITLE: Attaching AmazonECSTaskExecutionRolePolicy to IAM Role\nDESCRIPTION: This AWS CLI command attaches the AmazonECSTaskExecutionRolePolicy to the previously created IAM role, granting necessary permissions for ECS task execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naws iam attach-role-policy \\\n    --role-name ecsTaskExecutionRole \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\n```\n\n----------------------------------------\n\nTITLE: GitHub Repository Interaction Flow\nDESCRIPTION: Example flow demonstrating how to interact with GitHub API to add a star to a repository using prefect-github\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_github import GitHubCredentials\nfrom prefect_github.repository import query_repository\nfrom prefect_github.mutations import add_star_starrable\n\n\n@flow()\ndef github_add_star_flow():\n    github_credentials = GitHubCredentials.load(\"github-token\")\n    repository_id = query_repository(\n        \"PrefectHQ\",\n        \"Prefect\",\n        github_credentials=github_credentials,\n        return_fields=\"id\"\n    )[\"id\"]\n    starrable = add_star_starrable(\n        repository_id,\n        github_credentials\n    )\n    return starrable\n\n\nif __name__ == \"__main__\":\n    github_add_star_flow()\n```\n\n----------------------------------------\n\nTITLE: Resolving Dask Futures with Sync=True Parameter\nDESCRIPTION: Example showing how to resolve Dask futures when using the Dask client in Prefect. This approach uses the sync=True parameter to ensure futures are resolved before exiting the context manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith get_dask_client() as client:\n    df = dask.datasets.timeseries(\"2000\", \"2001\", partition_freq=\"4w\")\n    summary_df = client.compute(df.describe(), sync=True)\n```\n\n----------------------------------------\n\nTITLE: Advanced Jinja Templating for Flow and Deployment Properties\nDESCRIPTION: This code demonstrates more advanced Jinja templating for automation notifications, showing how to access additional properties from flow, deployment, and work pool objects for more detailed notifications.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nFlow run {{ flow_run.name }} for flow {{ flow.name }}\nentered state {{ flow_run.state.name }}\nwith message {{ flow_run.state.message }}\n\nFlow tags: {{ flow_run.tags }}\nDeployment name: {{ deployment.name }}\nDeployment version: {{ deployment.version }}\nDeployment parameters: {{ deployment.parameters }}\n```\n\n----------------------------------------\n\nTITLE: Python Flow with Scheduled Parameters\nDESCRIPTION: Implements a send_email flow with multiple cron schedules and different parameters for each schedule\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.schedules import Cron\n\n@flow\ndef send_email(to: str, message: str = \"Stop goofing off!\"):\n    print(f\"Sending email to {to} with message: {message}\")\n\nsend_email.serve(\n  name=\"my-flow\",\n  schedules=[\n    Cron(\n      \"0 8 * * *\",\n      slug=\"jim-email\",\n      parameters={\"to\": \"jim.halpert@dundermifflin.com\"}\n    ),\n    Cron(\n      \"5 8 * * *\",\n      slug=\"dwight-email\",\n      parameters={\n        \"to\": \"dwight.schrute@dundermifflin.com\",\n        \"message\": \"Stop goofing off! You're assistant _to_ the regional manager!\"\n      }\n    )\n  ]\n)\n```\n\n----------------------------------------\n\nTITLE: Delete Concurrency Limit\nDESCRIPTION: Removes the concurrency limit associated with a specified tag.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit delete [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Generating Kubernetes Client from KubernetesClusterConfig\nDESCRIPTION: Example of creating a Kubernetes client using KubernetesClusterConfig and KubernetesCredentials, then using it to list namespaces.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# with minikube / docker desktop & a valid ~/.kube/config this should ~just work~\nfrom prefect_kubernetes.credentials import KubernetesCredentials, KubernetesClusterConfig\n\nk8s_config = KubernetesClusterConfig.from_file('~/.kube/config')\n\nk8s_credentials = KubernetesCredentials(cluster_config=k8s_config)\n\nwith k8s_credentials.get_client(\"core\") as v1_core_client:\n    for namespace in v1_core_client.list_namespace().items:\n        print(namespace.metadata.name)\n```\n\n----------------------------------------\n\nTITLE: Defining a Background Task with Prefect\nDESCRIPTION: Defines a Prefect task using the `@task` decorator. This example demonstrates a simple addition task with logging enabled using `log_prints=True`. The task takes two integer arguments and prints their sum.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\n\n@task(log_prints=True)\ndef add(a: int, b: int):\n    print(f\"{a} + {b} = {a + b}\")\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for POST /api/automations/ Endpoint\nDESCRIPTION: Defines the OpenAPI specification for creating new automations in the Prefect API. The endpoint is defined as a POST method to /api/automations/.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/create-automation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/automations/\n```\n\n----------------------------------------\n\nTITLE: Serve Prefect Flow Command\nDESCRIPTION: Command to serve a flow via an entrypoint. Supports various configuration options including deployment naming, scheduling, and concurrency limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flows.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect flows serve [OPTIONS] ENTRYPOINT\n```\n\n----------------------------------------\n\nTITLE: Create Bitbucket Credentials Block (Python)\nDESCRIPTION: This code creates a BitBucketCredentials block, used for authenticating with Bitbucket repositories. The token parameter holds the authentication token. The block is then saved with a specified name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_bitbucket import BitBucketCredentials\n\n\nbitbucket_credentials_block = BitBucketCredentials(token=\"x-token-auth:my-token\")\nbitbucket_credentials_block.save(name=\"my-bitbucket-credentials-block\")\n```\n\n----------------------------------------\n\nTITLE: Prefect YAML Configuration for Azure Blob Storage Deployment\nDESCRIPTION: This YAML configuration defines how to push code to and pull code from Azure Blob Storage for a Prefect deployment. It includes the required prefect-azure library and configuration for container and folder paths, with optional credentials for private storage.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_23\n\nLANGUAGE: yaml\nCODE:\n```\nbuild: null\n\npush:\n- prefect_azure.deployments.steps.push_to_azure_blob_storage:\n    id: push_code\n    requires: prefect-azure>=0.4\n    container: my-prefect-azure-container\n    folder: my-folder\n    credentials: \"{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}\" \n    # if explicit authentication is required\n\npull:\n- prefect_azure.deployments.steps.pull_from_azure_blob_storage:\n    id: pull_code\n    requires: prefect-azure>=0.4\n    container: '{{ push_code.container }}'\n    folder: '{{ push_code.folder }}'\n    credentials: \"{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}\" # if explicit authentication is required\n\ndeployments:\n- name: my-azure-deployment\n  version: null\n  tags: []\n  concurrency_limit: null\n  description: null\n  entrypoint: my_file.py:my_flow\n  parameters: {}\n  work_pool:\n    name: my-work-pool\n    work_queue_name: null\n    job_variables: {}\n  enforce_parameter_schema: true\n  schedules: []\n```\n\n----------------------------------------\n\nTITLE: List Prefect Profiles\nDESCRIPTION: This command lists all available Prefect profile names. It provides a simple way to view existing profiles.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles ls [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Creating DBT Profiles with Prefect Blocks\nDESCRIPTION: Demonstrates how to create and use a DbtCliProfile block to generate profiles.yml\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\n\n@flow\ndef trigger_dbt_flow():\n    dbt_cli_profile = DbtCliProfile.load(\"DBT-CORE-OPERATION-BLOCK-PLACEHOLDER\")\n    with DbtCoreOperation(\n        commands=[\"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\",\n        dbt_cli_profile=dbt_cli_profile,\n    ) as dbt_operation:\n        dbt_process = dbt_operation.trigger()\n        # do other things before waiting for completion\n        dbt_process.wait_for_completion()\n        result = dbt_process.fetch_result()\n    return result\n\n\nif __name__ == \"__main__\":\n    trigger_dbt_flow()\n```\n\n----------------------------------------\n\nTITLE: Sequential Flow Implementation\nDESCRIPTION: Example of a Prefect flow that downloads images sequentially without parallel processing. Downloads ENSO images for a specific year with basic task and flow structure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom pathlib import Path\n\nimport httpx\nfrom prefect import flow, task\n\nURL_FORMAT = (\n    \"https://www.cpc.ncep.noaa.gov/products/NMME/archive/\"\n    \"{year:04d}{month:02d}0800/current/images/nino34.rescaling.ENSMEAN.png\"\n)\n\n@task\ndef download_image(year: int, month: int, directory: Path) -> Path:\n    # download image from URL\n    url = URL_FORMAT.format(year=year, month=month)\n    resp = httpx.get(url)\n\n    # save content to directory/YYYYMM.png\n    file_path = (directory / url.split(\"/\")[-1]).with_stem(f\"{year:04d}{month:02d}\")\n    file_path.write_bytes(resp.content)\n    return file_path\n\n@flow\ndef download_nino_34_plumes_from_year(year: int) -> List[Path]:\n    # create a directory to hold images\n    directory = Path(\"data\")\n    directory.mkdir(exist_ok=True)\n\n    # download all images\n    file_paths = []\n    for month in range(1, 12 + 1):\n        file_path = download_image(year, month, directory)\n        file_paths.append(file_path)\n    return file_paths\n\nif __name__ == \"__main__\":\n    download_nino_34_plumes_from_year(2022)\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect work pool\nDESCRIPTION: Creates a new work pool or updates an existing one. Supports various options for configuration including specifying the work pool type, base job template, and initial state.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool create [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository for Prefect Flow Deployments\nDESCRIPTION: Commands to clone the Prefect demos repository which contains the flow code to be deployed to Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/demos.git\ncd demos/\n```\n\n----------------------------------------\n\nTITLE: Creating S3 Bucket Block in Python\nDESCRIPTION: Python script to create an S3Bucket block for reading and writing files to S3.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.s3 import S3Bucket\n\nS3Bucket(\n    bucket_name=\"BUCKET-NAME-PLACEHOLDER\",\n    credentials=aws_credentials\n).save(\"S3-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Managing Concurrency Limits using Prefect CLI\nDESCRIPTION: This snippet demonstrates how to manage task run concurrency limits using the Prefect CLI. It includes commands for creating, deleting, and inspecting limits. It requires the Prefect CLI to be installed and configured on the user's system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-run-limits.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect concurrency-limit [command] [arguments]\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect concurrency-limit create small_instance 10\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect concurrency-limit delete small_instance\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect concurrency-limit inspect small_instance\n```\n\n----------------------------------------\n\nTITLE: Docker Deployment YAML Configuration\nDESCRIPTION: YAML configuration for a Docker-based deployment, showing build, push, pull, and deployment sections. This example demonstrates how to build and use a Docker image for flow deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\n# build section allows you to manage and build docker images\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n    requires: prefect-docker>=0.6.1\n    id: build-image\n    dockerfile: auto\n    image_name: my-registry/my-image\n    tag: latest\n\n# push section allows you to manage if and how this project is uploaded to remote locations\npush: null\n\n# pull section allows you to provide instructions for cloning this project in remote locations\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /opt/prefect/my_directory\n\n\n# the deployments section allows you to provide configuration for deploying flows\ndeployments:\n- name: my-docker-deployment\n  entrypoint: my_file.py:my_flow\n  work_pool:\n    name: my_pool\n    job_variables:\n      image: '{{ build-image.image }}'\n```\n\n----------------------------------------\n\nTITLE: Nginx Reverse Proxy Configuration\nDESCRIPTION: Example Nginx configuration for hosting Prefect server behind a reverse proxy with SSL support.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name prefect.example.com;\n    location / {\n        return 301 https://$host$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name prefect.example.com;\n\n    ssl_certificate /path/to/ssl/certificate.pem;\n    ssl_certificate_key /path/to/ssl/certificate_key.pem;\n\n    location /api {\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Authorization $http_authorization;\n        proxy_pass_header Authorization;\n        proxy_pass  http://127.0.0.1:4200;\n    }\n\n    location / {\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_pass http://127.0.0.1:4200;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from GCP GCS without Storage Block\nDESCRIPTION: This code deploys a Prefect flow from a Google Cloud Storage bucket without using a storage block. It directly references the GCS bucket location and does not require explicit credentials if the environment is already authenticated to GCP.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"gs://my-bucket/my-folder\",  \n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"my-gcs-deployment\",\n        work_pool_name=\"my-work-pool\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Running DBT Core Commands with Prefect Flow\nDESCRIPTION: Demonstrates how to create a Prefect flow that executes dbt Core commands using DbtCoreOperation with existing profiles directory\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt.cli.commands import DbtCoreOperation\n\n\n@flow\ndef trigger_dbt_flow() -> str:\n    result = DbtCoreOperation(\n        commands=[\"pwd\", \"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\"\n    ).run()\n    return result\n\n\nif __name__ == \"__main__\":\n    trigger_dbt_flow()\n```\n\n----------------------------------------\n\nTITLE: Defining Deployment Schema Structure in Python\nDESCRIPTION: This code defines the Deployment class that represents the schema structure for Prefect deployments. It includes required fields like name and flow_id, as well as optional configuration for scheduling, parameters, concurrency limits, and metadata.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Deployment:\n    \"\"\"\n    Structure of the schema defining a deployment\n    \"\"\"\n\n    # required defining data\n    name: str\n    flow_id: UUID\n    entrypoint: str\n    path: Optional[str] = None\n\n    # workflow scheduling and parametrization\n    parameters: Optional[Dict[str, Any]] = None\n    parameter_openapi_schema: Optional[Dict[str, Any]] = None\n    schedules: list[Schedule] = None\n    paused: bool = False\n    trigger: Trigger = None\n\n    # concurrency limiting\n    concurrency_limit: Optional[int] = None\n    concurrency_options: Optional[\n        ConcurrencyOptions(collision_strategy=Literal['ENQUEUE', 'CANCEL_NEW'])\n    ] = None\n\n    # metadata for bookkeeping\n    version: Optional[str] = None\n    description: Optional[str] = None\n    tags: Optional[list] = None\n\n    # worker-specific fields\n    work_pool_name: Optional[str] = None\n    work_queue_name: Optional[str] = None\n    job_variables: Optional[Dict[str, Any]] = None\n    pull_steps: Optional[Dict[str, Any]] = None\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Specification for Deactivating Deployment Schedules\nDESCRIPTION: YAML specification for an OpenAPI endpoint that deactivates a deployment's schedule via POST request to /api/deployments/{id}/set_schedule_inactive\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/pause-deployment-1.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/set_schedule_inactive\n```\n\n----------------------------------------\n\nTITLE: Creating Task with Dynamic Run Name in Python\nDESCRIPTION: This example shows how to create a task with a dynamic run name using string formatting and flow parameters in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport datetime\nfrom prefect import flow, task\n\n\n@task(name=\"My Example Task\", \n      description=\"An example task for a tutorial.\",\n      task_run_name=\"hello-{name}-on-{date:%A}\")\ndef my_task(name, date):\n    pass\n\n\n@flow\ndef my_flow():\n    # creates a run with a name like \"hello-marvin-on-Thursday\"\n    my_task(name=\"marvin\", date=datetime.datetime.now(datetime.timezone.utc))\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Basic Transaction Race Condition Example in Python\nDESCRIPTION: Demonstrates a race condition that can occur when running concurrent transactions with READ_COMMITTED isolation level. Uses threading to show how multiple transactions with the same key can potentially overwrite each other.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport threading\n\nfrom prefect import flow, task\nfrom prefect.transactions import transaction\n\n\n@task\ndef download_data():\n    return f\"{threading.current_thread().name} is the winner!\"\n\n\n@task\ndef write_file(contents: str):\n    \"Writes to a file.\"\n    with open(\"race-condition.txt\", \"w\") as f:\n        f.write(contents)\n\n\n@flow\ndef pipeline(transaction_key: str):\n    with transaction(key=transaction_key) as txn:\n        if txn.is_committed():\n            print(\"Data file has already been written. Exiting early.\")\n            return\n        data = download_data()\n        write_file(data)\n\n\nif __name__ == \"__main__\":\n    # Run the pipeline twice to see the race condition\n    transaction_key = f\"race-condition-{uuid.uuid4()}\"\n    thread_1 = threading.Thread(target=pipeline, name=\"Thread 1\", args=(transaction_key,))\n    thread_2 = threading.Thread(target=pipeline, name=\"Thread 2\", args=(transaction_key,))\n\n    thread_1.start()\n    thread_2.start()\n\n    thread_1.join()\n    thread_2.join()\n```\n\n----------------------------------------\n\nTITLE: Running a Prefect Managed Execution Deployment\nDESCRIPTION: This command executes a Python script that deploys a flow to Prefect Managed Execution. After deployment, the flow can be triggered from the Prefect UI or CLI without needing to provision workers or infrastructure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython managed-execution.py\n```\n\n----------------------------------------\n\nTITLE: Configure Prefect Logging Prints with Bash\nDESCRIPTION: Configures Prefect to enable logging of print statements globally via Bash commands, adjusting settings through the `PREFECT_LOGGING_LOG_PRINTS` environment variable.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_LOGGING_LOG_PRINTS=True\n```\n\n----------------------------------------\n\nTITLE: Data Extraction using DLT Library\nDESCRIPTION: Script demonstrating how to extract Prefect Cloud data including deployments, flows, and flow runs using the dlt library, storing the results in a DuckDB database.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/scripts.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Reference to extract_with_dlt.py\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for AWS and Prefect Configuration\nDESCRIPTION: Bash commands to set environment variables for Prefect authentication, AWS credentials, and Terraform variables. These variables are essential for configuring the cloud resources and running the ML pipeline.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# Prefect auth\nexport PREFECT_API_KEY=<Your Prefect API key>\nexport PREFECT_CLOUD_ACCOUNT_ID=<Your account ID>\n\n# AWS auth\nexport AWS_ACCESS_KEY_ID=<Your AWS access key ID>\nexport AWS_SECRET_ACCESS_KEY=<Your AWS secret access key>\nexport AWS_REGION=us-east-1\n\n# Terraform variables\nexport TF_VAR_prefect_workspace_id=<Your workspace ID>\nexport TF_VAR_data_bucket_name=prefect-ml-data # You may need to change this if the bucket name is already taken\nexport TF_VAR_model_bucket_name=prefect-model  # ...\nexport TF_VAR_model_training_deployment_id=<Your model-training deployment ID>\nexport TF_VAR_model_inference_deployment_id=<Your model-inference deployment ID>\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Deployment Command\nDESCRIPTION: Base command for managing Prefect deployments with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Implementing Flow Timeout in Python\nDESCRIPTION: Demonstrates how to set a timeout for a flow using the `timeout_seconds` parameter, which will interrupt the flow if execution exceeds the specified duration\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/cancel.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nimport time\n\n@flow(timeout_seconds=1, log_prints=True)\ndef show_timeouts():\n    print(\"I will execute\")\n    time.sleep(5)\n    print(\"I will not execute\")\n```\n\n----------------------------------------\n\nTITLE: Populate Default Prefect Profiles\nDESCRIPTION: This command populates the profiles configuration with default base profiles. It preserves existing user profiles during the population process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles populate-defaults [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Initializing State Hooks in Prefect\nDESCRIPTION: Partial code snippet showing the beginning of how to implement state hooks using decorator syntax or keyword arguments for both tasks and flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task, flow\n\n\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with Infrastructure and Storage Blocks\nDESCRIPTION: Example showing deployment using both infrastructure (Kubernetes) and storage (GitHub) blocks\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.deployments import Deployment\nfrom prefect.filesystems import GitHub # this block class no longer exists\nfrom prefect.infrastructure.kubernetes import KubernetesJob\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a GitHub repo!\")\n\nrepo = GitHub.load(\"demo-repo\")\n\nif __name__ == \"__main__\":\n    Deployment.build_from_flow(\n        my_flow,\n        name=\"my-deployment\",\n        storage=repo,\n        entrypoint=\"example.py:my_flow\",\n        infrastructure=KubernetesJob.load(\"my-k8s-job\"),\n        infra_overrides=dict(pull_policy=\"Never\"),\n        parameters=dict(name=\"Marvin\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: Adding Tags to Tasks in Python\nDESCRIPTION: This snippet shows how to add tags to tasks using the task decorator in Prefect, which can be used for filtering and setting concurrency limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@task(name=\"hello-task\", tags=[\"test\"])\ndef my_task():\n    print(\"Hello, I'm a task\")\n```\n\n----------------------------------------\n\nTITLE: Defining API Endpoint for Flow Runs Filtering in OpenAPI\nDESCRIPTION: The snippet outlines an HTTP POST request endpoint for filtering flow runs in the context of the Prefect framework. Prerequisites include access to the Prefect infrastructure. It likely accepts specific filtering parameters to tailor the flow runs' data, with output being a collection of filtered flow run metadata. This is defined using OpenAPI standards.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/paginate-flow-runs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\npost /api/flow_runs/filter\n```\n\n----------------------------------------\n\nTITLE: Serving Prefect Shell Command with Schedule\nDESCRIPTION: The `prefect shell serve` command creates and serves a Prefect deployment running a specified shell command, with options for scheduling via cron, tagging, concurrency limits, and streaming output. This command aids in integrating shell commands into Prefect workflows, supporting both scheduled and ad-hoc executions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/shell.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect shell serve [OPTIONS] COMMAND\n```\n\n----------------------------------------\n\nTITLE: Prefect Flow Definition in Python\nDESCRIPTION: This Python code defines a simple Prefect flow named `hello` that prints \"Hello!\". This is the core flow definition that will be used by the Prefect deployment defined in the `prefect.yaml` file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef hello():\n  print(\"Hello!\")\n```\n\n----------------------------------------\n\nTITLE: Migrating from Airflow PostgresHook to Prefect SQLAlchemy Connector\nDESCRIPTION: Example of replacing Airflow's PostgresHook with Prefect's SQLAlchemy Connector for database connectivity.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nhook = PostgresHook(postgres_conn_id=my_conn_id)\nengine = hook.get_sqlalchemy_engine()\nsession = sessionmaker(bind=engine)()\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_sqlalchemy import SqlAlchemyConnector\n\nSqlAlchemyConnector.load(\"BLOCK_NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Runs List Command\nDESCRIPTION: The `ls` subcommand lists recent task runs. It allows filtering by task run name, limit, state, and state type.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task-runs.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect task-runs ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect UI API URL in TOML File\nDESCRIPTION: This snippet shows how to configure the API URL for a Prefect UI instance hosted behind a reverse proxy. It sets the 'ui.api_url' setting in a prefect.toml configuration file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[ui]\napi_url = \"https://prefect-server.example.com/api\"\n```\n\n----------------------------------------\n\nTITLE: Setting Prefect Configuration with Environment Variables\nDESCRIPTION: Example showing how to use environment variables to temporarily override Prefect settings for a single flow run or shell session. This approach has the highest precedence in the configuration hierarchy.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_LOGGING_LEVEL=\"DEBUG\" python my_flow.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport PREFECT_LOGGING_LEVEL=\"DEBUG\"\nprefect run my_flow.py\n```\n\n----------------------------------------\n\nTITLE: Defining SLAs in prefect.yaml\nDESCRIPTION: This YAML snippet demonstrates how to define Service Level Agreements (SLAs) within a `prefect.yaml` file. It configures two SLAs for the 'my-deployment' deployment: one for 'time-to-completion' with a duration of 10 seconds and another for 'lateness' with a 'within' period of 600 seconds; both are assigned a 'high' severity.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/slas.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"deployments:\\n  my-deployment:\\n    sla:\\n        - name: \\\"time-to-completion\\\"\\n          duration: 10\n          severity: \\\"high\\\"\\n        - name: \\\"lateness\\\"\\n          within: 600\n          severity: \\\"high\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Prefect Worker Class\nDESCRIPTION: Complete example of a custom worker implementation including configuration, variables, and result classes. Shows the core structure of a worker with fields for memory and CPU allocation, along with the main run method that handles flow execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.workers.base import BaseWorker, BaseWorkerResult, BaseJobConfiguration, BaseVariables\n\nclass MyWorkerConfiguration(BaseJobConfiguration):\n    memory: str = Field(\n        default=\"1024Mi\",\n        description=\"Memory allocation for the execution environment.\"\n        json_schema_extra=dict(template=\"{{ memory_request }}Mi\")\n    )\n    cpu: str = Field(\n        default=\"500m\", \n        description=\"CPU allocation for the execution environment.\"\n        json_schema_extra=dict(template=\"{{ cpu_request }}m\")\n    )\n\nclass MyWorkerTemplateVariables(BaseVariables):\n    memory_request: int = Field(\n        default=1024,\n        description=\"Memory allocation for the execution environment.\"\n    )\n    cpu_request: int = Field(\n        default=500, \n        description=\"CPU allocation for the execution environment.\"\n    )\n\nclass MyWorkerResult(BaseWorkerResult):\n    \"\"\"Result returned by the MyWorker.\"\"\"\n\nclass MyWorker(BaseWorker):\n    type: str = \"my-worker\"\n    job_configuration = MyWorkerConfiguration\n    job_configuration_variables = MyWorkerTemplateVariables\n    _documentation_url = \"https://example.com/docs\"\n    _logo_url = \"https://example.com/logo\"\n    _description = \"My worker description.\"\n\n    async def run(\n        self, flow_run: FlowRun, configuration: BaseJobConfiguration, task_status: Optional[anyio.abc.TaskStatus] = None,\n    ) -> BaseWorkerResult:\n        # Create the execution environment and start execution\n        job = await self._create_and_start_job(configuration)\n\n        if task_status:\n            # Use a unique ID to mark the run as started. This ID is later used to tear down infrastructure\n            # if the flow run is cancelled.\n            task_status.started(job.id) \n\n        # Monitor the execution\n        job_status = await self._watch_job(job, configuration)\n\n        exit_code = job_status.exit_code if job_status else -1 # Get result of execution for reporting\n        return MyWorkerResult(\n            status_code=exit_code,\n            identifier=job.id,\n        )\n```\n\n----------------------------------------\n\nTITLE: Secret Manager Operations Example\nDESCRIPTION: Example flow demonstrating secret management operations using Google Secret Manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_gcp import GcpCredentials, GcpSecret\n\n\n@flow\ndef secret_manager_flow():\n    gcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n    gcp_secret = GcpSecret(secret_name=\"test-example\", gcp_credentials=gcp_credentials)\n    gcp_secret.write_secret(secret_data=b\"Hello, Prefect!\")\n    secret_data = gcp_secret.read_secret()\n    gcp_secret.delete_secret()\n    return secret_data\n\n\nif __name__ == \"__main__\":\n    secret_manager_flow()\n```\n\n----------------------------------------\n\nTITLE: Viewing Test Script Contents\nDESCRIPTION: Displays the contents of the 'test' script, which is used to start the web server and task worker, send a demo request, and clean up.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncat test\n```\n\n----------------------------------------\n\nTITLE: Defining GitHub Actions Workflow for Prefect Deployment\nDESCRIPTION: Configures a GitHub Actions workflow that automatically deploys Prefect flows when code is pushed to the main branch. The workflow uses secrets for Prefect API authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nname: Deploy Prefect flow\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n\n      - name: Prefect Deploy\n        env:\n          PREFECT_API_KEY: ${{ secrets.PREFECT_API_KEY }}\n          PREFECT_API_URL: ${{ secrets.PREFECT_API_URL }}\n        run: |\n          make prefect-deploy\n```\n\n----------------------------------------\n\nTITLE: Accepting Prefect Events Unmodified with Jinja2\nDESCRIPTION: A Jinja2 template that accepts an incoming request body as JSON and passes it directly through, useful when the client's control is higher and the payload structure aligns with Prefect's requirements.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_7\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ body|tojson }}\n```\n\n----------------------------------------\n\nTITLE: Creating a Flow Run with Curl in Prefect Cloud\nDESCRIPTION: This bash script demonstrates how to create a flow run in Prefect Cloud using curl. It sends a POST request to the deployments endpoint with proper authentication headers. The example includes environment variables for account ID, workspace ID, and API key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nACCOUNT_ID=\"abc-my-cloud-account-id-goes-here\"\nWORKSPACE_ID=\"123-my-workspace-id-goes-here\"\nPREFECT_API_URL=\"https://api.prefect.cloud/api/accounts/$ACCOUNT_ID/workspaces/$WORKSPACE_ID\"\nPREFECT_API_KEY=\"123abc_my_api_key_goes_here\"\nDEPLOYMENT_ID=\"my_deployment_id\"\n\ncurl --location --request POST \"$PREFECT_API_URL/deployments/$DEPLOYMENT_ID/create_flow_run\" \\\n  --header \"Content-Type: application/json\" \\\n  --header \"Authorization: Bearer $PREFECT_API_KEY\" \\\n  --header \"X-PREFECT-API-VERSION: 0.8.4\" \\\n  --data-raw \"{}\"\n```\n\n----------------------------------------\n\nTITLE: Fixed Python Code without Simulated Failures\nDESCRIPTION: The updated version of simulate_failures.py with the problematic code removed. This fixes the flow by removing the conditional that raises an exception after a certain number of runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/debug.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport asyncio\nfrom typing import Optional\nfrom prefect import flow, task\nfrom prefect.client.orchestration import get_client\n\n@task\ndef process_data(run: int, fail_at_run: Optional[int] = None) -> bool:\n    \"\"\"Simulate data processing with failures\"\"\"\n    \n    return True\n\n# ...\n```\n\n----------------------------------------\n\nTITLE: Using Tags Context Manager in Python\nDESCRIPTION: This example demonstrates how to use the tags context manager to specify tags when a task is called, rather than in its definition in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect import tags\n\n\n@task\ndef my_task():\n    print(\"Hello, I'm a task\")\n\n\n@flow\ndef my_flow():\n    with tags(\"test\"):\n        my_task()\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Defining Prefect Automation in YAML\nDESCRIPTION: YAML configuration for a Prefect automation that cancels long-running flows. It defines the trigger conditions and the action to cancel the flow run.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nname: Cancel long running flows\ndescription: Cancel any flow run after an hour of execution\ntrigger:\n  match:\n    \"prefect.resource.id\": \"prefect.flow-run.*\"\n  match_related: {}\n  after:\n    - \"prefect.flow-run.Failed\"\n  expect:\n    - \"prefect.flow-run.*\"\n  for_each:\n    - \"prefect.resource.id\"\n  posture: \"Proactive\"\n  threshold: 1\n  within: 30\nactions:\n  - type: \"cancel-flow-run\"\n```\n\n----------------------------------------\n\nTITLE: Listing all work queues\nDESCRIPTION: Command to display a list of all available work queues with optional filtering by name prefix or work pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Updating Custom S3Bucket Block in Python\nDESCRIPTION: Example showing how to add a new field to an existing custom block type and update existing block instances.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nclass S3Bucket(Block):\n    bucket_name: str\n    credentials: AwsCredentials\n    bucket_folder: Optional[str] = None\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\n# Bypass Pydantic validation to allow your local Block class to load the old block version\nmy_s3_bucket_block = S3Bucket.load(\"my-s3-bucket\", validate=False)\n\n# Set the new field to an appropriate value\nmy_s3_bucket_block.bucket_path = \"my-default-bucket-path\"\n\n# Overwrite the old block values and update the expected fields on the block\nmy_s3_bucket_block.save(\"my-s3-bucket\", overwrite=True)\n```\n\n----------------------------------------\n\nTITLE: Simulating User Events for Order Processing in Prefect\nDESCRIPTION: Python script that simulates order creation and completion events for different users. This demonstrates how to emit custom events with user IDs as resources to trigger the order completion deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom prefect.events import emit_event\n\nuser_id_1, user_id_2 = \"123\", \"456\"\nfor event_name, user_id in [\n    (\"order.created\", user_id_1),\n    (\"order.created\", user_id_2), # other user\n    (\"order.complete\", user_id_1),\n]:\n    event = emit_event(\n        event=event_name,\n        resource={\"prefect.resource.id\": user_id},\n    )\n    time.sleep(1)\n    print(f\"{user_id} emitted {event_name}\")\n```\n\n----------------------------------------\n\nTITLE: Prefect Event Trigger Matching Example 1\nDESCRIPTION: This JSON configuration demonstrates how to filter events whose primary resource is a flow run with a name starting with 'cute-' or 'radical-'. It uses the `match` field to specify the filtering criteria based on the `prefect.resource.id` and `prefect.resource.name` labels.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"match\": {\n  \"prefect.resource.id\": \"prefect.flow-run.*\",\n  \"prefect.resource.name\": [\"cute-*\", \"radical-*\"]\n},\n\"match_related\": {},\n...\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Prefect Flow in Python\nDESCRIPTION: Python code defining a simple Prefect flow that logs a message. This flow will be used to test the ECS worker setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.logging import get_run_logger\n\n@flow\ndef my_flow():\n    logger = get_run_logger()\n    logger.info(\"Hello from ECS!!\")\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Runs Base Command\nDESCRIPTION: The base command for interacting with task runs in Prefect.  It provides access to subcommands for inspecting, listing, and viewing logs for task runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task-runs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect task-runs [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Running a Python Script to Deploy a Flow\nDESCRIPTION: This bash command executes a Python script to deploy a Prefect flow. It assumes the script contains the necessary `flow.deploy` configuration.  This is a single command to deploy your flow to the Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython example.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Settings with prefect.toml\nDESCRIPTION: A simple example of using prefect.toml to set the logging level to DEBUG for development purposes. This file is placed in the project directory and applies to all workflow runs in that directory.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Set more detailed logging while developing\n[logging]\nlevel = \"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Run Rescheduling Example in Python\nDESCRIPTION: Demonstrates how to use the `reschedule_late_flow_runs` function to reschedule specific flow runs. This requires asyncio to execute the asynchronous function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrescheduled_flow_runs = asyncio.run(\n    reschedule_late_flow_runs(\n        deployment_name=\"healthcheck-storage-test\",\n        delay=timedelta(hours=6),\n        most_recent_n=3,\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Email Server Credentials\nDESCRIPTION: Python code to save email server credentials as a Prefect block for authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_email import EmailServerCredentials\n\n\ncredentials = EmailServerCredentials(\n    username=\"EMAIL-ADDRESS-PLACEHOLDER\",\n    password=\"PASSWORD-PLACEHOLDER\",  # must be an application password\n)\ncredentials.save(\"BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Watching Prefect Shell Command as Flow\nDESCRIPTION: The `prefect shell watch` command executes a shell command as a Prefect flow, observing its execution. This command allows for command output logging, naming of flows, and optionally streaming the output or tagging the flow for easier management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/shell.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect shell watch [OPTIONS] COMMAND\n```\n\n----------------------------------------\n\nTITLE: Configuring CPU Request in Kubernetes Work Pool\nDESCRIPTION: JSON configuration to add CPU request settings to the Kubernetes work pool template, allowing specification of CPU allocation for pods.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n\"cpu_request\": {\n  \"title\": \"CPU Request\",\n  \"description\": \"The CPU allocation to request for this pod.\",\n  \"default\": \"default\",\n  \"type\": \"string\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Webhook JSON Template for Model Inference\nDESCRIPTION: JSON template for configuring the Prefect webhook for model inference. This template defines the event structure that will be sent when the webhook is called for inference tasks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"event\": \"webhook.called\",\n    \"resource\": {\n        \"prefect.resource.id\": \"webhook.resource.id\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: List Prefect Automations\nDESCRIPTION: Command to list all available automations in the Prefect system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect automations ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Querying Artifacts via REST API\nDESCRIPTION: Example of using the Prefect REST API to fetch the five most recently created artifacts with filtering and sorting.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n\nPREFECT_API_URL=\"https://api.prefect.cloud/api/accounts/abc/workspaces/xyz\"\nPREFECT_API_KEY=\"pnu_ghijk\"\ndata = {\n    \"sort\": \"CREATED_DESC\",\n    \"limit\": 5,\n    \"artifacts\": {\n        \"key\": {\n            \"exists_\": True\n        }\n    }\n}\n\nheaders = {\"Authorization\": f\"Bearer {PREFECT_API_KEY}\"}\nendpoint = f\"{PREFECT_API_URL}/artifacts/filter\"\n\nresponse = requests.post(endpoint, headers=headers, json=data)\nassert response.status_code == 200\nfor artifact in response.json():\n    print(artifact)\n```\n\n----------------------------------------\n\nTITLE: Defining Schedules in YAML\nDESCRIPTION: This YAML snippet illustrates how to define schedules for a Prefect deployment within a `prefect.yaml` file. It showcases three cron-based schedules with different timezones and slugs. The `active` property determines whether the schedule is enabled or disabled. This is useful for configuring schedules as code, and allows managing the schedules via the command line.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n  ...\n  schedules:\n    - cron: \"0 0 * * *\"\n      slug: \"chicago-schedule\"\n      timezone: \"America/Chicago\"\n      active: false\n    - cron: \"0 12 * * *\"\n      slug: \"new-york-schedule\"\n      timezone: \"America/New_York\"\n      active: true\n    - cron: \"0 18 * * *\"\n      slug: \"london-schedule\"\n      timezone: \"Europe/London\"\n      active: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Worker CLI Integration\nDESCRIPTION: Example of setting up entry points in package setup to enable CLI integration for a custom worker. This allows the worker to be started using the prefect worker start command.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nentry_points={\n    \"prefect.collections\": [\n        \"my_package_name = my_worker_module\",\n    ]\n},\n```\n\n----------------------------------------\n\nTITLE: Backgrounding and Serving a Prefect Task\nDESCRIPTION: Demonstrates how to background task runs using `.delay()` and start a task worker using `.serve()`.  The `.delay()` method schedules the task for execution by a task worker, while `.serve()` starts a worker that listens for and executes task runs of that specific task.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nadd.delay(1, 2) # background one task run\nadd.delay(42, 100) # background another task run\n\nadd.serve() # start a task worker and execute any waiting task runs\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from AWS S3 without Storage Block\nDESCRIPTION: This code deploys a Prefect flow from an AWS S3 bucket without using a storage block. It directly references the S3 bucket location and does not require explicit credentials if the environment is already authenticated to AWS.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"s3://my-bucket/my-folder\",\n        entrypoint=\"my_file.py:my_flow\",\n    ).deploy(\n        name=\"my-aws-s3-deployment\",\n        work_pool_name=\"my-work-pool\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating ECS Trust Policy JSON for IAM Role\nDESCRIPTION: This JSON defines a trust policy that allows ECS tasks to assume the IAM role. It's used when creating the IAM role for the ECS task execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"ecs-tasks.amazonaws.com\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Shell Script Execution in YAML\nDESCRIPTION: This YAML configuration specifies shell script steps for installing dependencies and synchronizing the environment before running the flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n- prefect.deployments.steps.run_shell_script:\n    directory: '{{ clone-step.directory }}'\n    script: pip install --upgrade 'uv>=0.5.6,<0.6'\n- prefect.deployments.steps.run_shell_script:\n    directory: '{{ clone-step.directory }}'\n    script: uv sync --no-editable --no-dev\n```\n\n----------------------------------------\n\nTITLE: Prefect YAML Configuration for GCP GCS Deployment\nDESCRIPTION: This YAML configuration defines how to push code to and pull code from a Google Cloud Storage bucket for a Prefect deployment. It includes settings for the required prefect-gcp library and bucket/folder configuration, with optional credentials for private buckets.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_26\n\nLANGUAGE: yaml\nCODE:\n```\nbuild: null\n\npush:\n- prefect_gcp.deployment.steps.push_to_gcs:\n    id: push_code\n    requires: prefect-gcp>=0.6\n    bucket: my-bucket\n    folder: my-folder\n    credentials: \"{{ prefect.blocks.gcp-credentials.my-credentials-block }}\" # if explicit authentication is required \n\npull:\n- prefect_gcp.deployment.steps.pull_from_gcs:\n    id: pull_code\n    requires: prefect-gcp>=0.6\n    bucket: '{{ push_code.bucket }}'\n    folder: '{{ pull_code.folder }}'\n    credentials: \"{{ prefect.blocks.gcp-credentials.my-credentials-block }}\" # if explicit authentication is required \n\ndeployments:\n- name: my-gcs-deployment\n    version: null\n    tags: []\n    concurrency_limit: null\n```\n\n----------------------------------------\n\nTITLE: Querying Flows using PrefectClient with Self-Hosted Server\nDESCRIPTION: This snippet demonstrates how to use the PrefectClient from the Prefect Python SDK to fetch a list of flows from a self-hosted Prefect server. It creates an asynchronous function that retrieves up to 5 flows and prints their names and IDs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom prefect.client.orchestration import get_client\n\n\nasync def get_flows():\n    client = get_client()\n    r = await client.read_flows(limit=5)\n    return r\n\n\nr = asyncio.run(get_flows())\n\nfor flow in r:\n    print(flow.name, flow.id)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(get_flows())\n```\n\n----------------------------------------\n\nTITLE: Schedule Parameters in prefect.yaml\nDESCRIPTION: Configures flow schedules and parameters directly in the Prefect configuration file\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n  name: send-email\n  entrypoint: send_email_flow.py:send_email\n  schedules:\n    - cron: \"0 8 * * *\"\n      slug: \"jim-email\"\n      parameters:\n        to: \"jim.halpert@dundermifflin.com\"\n    - cron: \"5 8 * * *\"\n      slug: \"dwight-email\"\n      parameters:\n        to: \"dwight.schrute@dundermifflin.com\"\n        message: \"Stop goofing off! You're assistant _to_ the regional manager!\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Prefect Flow\nDESCRIPTION: Python code defining a basic Prefect flow that logs a greeting message.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, tags\nfrom prefect.logging import get_run_logger\n\n@flow\ndef hello(name: str = \"Marvin\"):\n    logger = get_run_logger()\n    logger.info(f\"Hello, {name}!\")\n\nif __name__ == \"__main__\":\n    with tags(\"local\"):\n        hello()\n```\n\n----------------------------------------\n\nTITLE: Creating a Modal Authentication Token\nDESCRIPTION: Generates a new Modal token that will be used by Prefect to access Modal services for workflow execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nuv run modal token new\n```\n\n----------------------------------------\n\nTITLE: Configuring RayTaskRunner with existing Ray instance\nDESCRIPTION: Example of configuring a Prefect flow to use RayTaskRunner with an existing Ray instance at a specified address.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_ray.task_runners import RayTaskRunner\n\n@flow(\n    task_runner=RayTaskRunner(\n        address=\"ray://<head_node_host>:10001\",\n        init_kwargs={\"runtime_env\": {\"pip\": [\"prefect-ray\"]}},\n    )\n)\ndef my_flow():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Authenticating to Prefect and Installing Dependencies\nDESCRIPTION: This bash script demonstrates how to create a virtual environment, install project dependencies, and authenticate to Prefect using the CLI. It ensures a consistent environment for deploying flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n# Create a virtualenv & activate it\nvirtualenv prefect-demo\nsource prefect-demo/bin/activate\n\n# Install dependencies of your flow\nprefect-demo/bin/pip install -r requirements.txt\n\n# Authenticate to Prefect & select the appropriate\n# workspace to deploy your flows to\nprefect-demo/bin/prefect cloud login\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prefect Server Database\nDESCRIPTION: Upgrades the Prefect database schema.  This command is used to apply migrations to the database to keep it up-to-date with the current version of Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database upgrade [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment with YAML File\nDESCRIPTION: This snippet describes how to create a deployment interactively using the Prefect CLI that results in a 'prefect.yaml' file. The generated file includes build steps for Docker image management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy\n```\n\n----------------------------------------\n\nTITLE: Manually Configuring Prefect API Settings\nDESCRIPTION: Set the PREFECT_API_URL and PREFECT_API_KEY configuration values to manually authenticate with Prefect Cloud. Replace [ACCOUNT-ID], [WORKSPACE-ID], and [API-KEY] with your specific values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/connect-to-cloud.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_URL=\"https://api.prefect.cloud/api/accounts/[ACCOUNT-ID]/workspaces/[WORKSPACE-ID]\"\nprefect config set PREFECT_API_KEY=\"[API-KEY]\"\n```\n\n----------------------------------------\n\nTITLE: Interacting with Prefect API\nDESCRIPTION: Example of using the Prefect client to interact directly with the API. Demonstrates querying concurrency limits using an async context manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/client/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.client.orchestration import get_client\n\n\nasync def query_api():\n    async with get_client() as client:\n        limits = await client.read_concurrency_limits(limit=10, offset=0)\n        print(limits)\n\n\nquery_api()\n```\n\n----------------------------------------\n\nTITLE: Creating AWS Credentials Block in Python\nDESCRIPTION: Python script to create an AwsCredentials block for authentication with AWS services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\n\n\nAwsCredentials(\n    aws_access_key_id=\"PLACEHOLDER\",\n    aws_secret_access_key=\"PLACEHOLDER\",\n    aws_session_token=None,  # replace this with token if necessary\n    region_name=\"us-east-2\"\n).save(\"BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Automations Command\nDESCRIPTION: Base command for accessing automation-related functionality in Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect automations [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Viewing and Validating Prefect Configuration\nDESCRIPTION: CLI commands to view all available Prefect settings including their default values, and to validate the current configuration setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect config view --show-defaults\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect config validate\n```\n\n----------------------------------------\n\nTITLE: Configuring Git Repository in prefect.yaml\nDESCRIPTION: This YAML snippet shows how to configure a Git repository in the prefect.yaml configuration file. It includes commented options for specifying credentials using either a credentials block or a Secret block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# relevant section of the file:\npull:\n    - prefect.deployments.steps.git_clone:\n        repository: https://gitlab.com/org/my-repo.git\n        # Uncomment the following line if using a credentials block\n        # credentials: \"{{ prefect.blocks.github-credentials.my-github-credentials-block }}\"\n        # Uncomment the following line if using a Secret block\n        # access_token: \"{{ prefect.blocks.secret.my-block-name }}\"\n```\n\n----------------------------------------\n\nTITLE: Logging into Prefect Cloud\nDESCRIPTION: This snippet provides the command to log into a Prefect Cloud account using an API key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login -k YOUR_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Server Services\nDESCRIPTION: Starts all enabled Prefect services in one process. This command allows running the services in the background.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_12\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services start-services [OPTIONS]\"\n```\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services start [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: RRule Schedule Configuration in YAML\nDESCRIPTION: Demonstrates an RRule schedule with weekly frequency on specific days until a certain date\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nschedule:\n  rrule: 'FREQ=WEEKLY;BYDAY=MO,WE,FR;UNTIL=20240730T040000Z'\n```\n\n----------------------------------------\n\nTITLE: Accessing HTTP Headers with Jinja2 Template\nDESCRIPTION: This Jinja2 code demonstrates accessing HTTP headers in a flexible manner, respecting case insensitivity. The header 'Content-Length' is accessed using different variations in casing, reflecting the robust nature of header access in templates.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_5\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ headers['Content-Length'] }}\n\n{{ headers['content-length'] }}\n\n{{ headers['CoNtEnt-LeNgTh'] }}\n```\n\n----------------------------------------\n\nTITLE: Cancelling Flow Run via CLI\nDESCRIPTION: Command to cancel a specific flow run using the Prefect CLI by providing the flow run's unique identifier\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/cancel.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect flow-run cancel 'a55a4804-9e3c-4042-8b59-b3b6b7618736'\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Public GitHub Repository\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a public GitHub repository by specifying the repository URL directly. It uses the flow.from_source() method to define the source repository and entrypoint file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/org/my-public-repo.git\",\n        entrypoint=\"gh_public_repo.py:my_flow\",\n    ).deploy(\n        name=\"my-github-deployment\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Generating Task Run Name with Function in Python\nDESCRIPTION: This snippet illustrates how to use a function to generate a dynamic task run name in Prefect, incorporating the current date.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport datetime\nfrom prefect import flow, task\n\n\ndef generate_task_name():\n    date = datetime.datetime.now(datetime.timezone.utc)\n    return f\"{date:%A}-is-a-lovely-day\"\n\n\n@task(name=\"My Example Task\",\n      description=\"An example task for the docs.\",\n      task_run_name=generate_task_name)\ndef my_task(name):\n    pass\n\n\n@flow\ndef my_flow():\n    # creates a run with a name like \"Thursday-is-a-lovely-day\"\n    my_task(name=\"marvin\")\n\n\nif __name__ == \"__main__\":\n    my_flow()\n```\n\n----------------------------------------\n\nTITLE: Create Global Concurrency Limit\nDESCRIPTION: Command to create a new global concurrency limit with specified name, limit value, and optional parameters for active slots and decay rate.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit create [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Implementing Event-Driven Deployments in Prefect\nDESCRIPTION: Python script that demonstrates how to create upstream and downstream flow deployments with event triggers. The downstream flow automatically runs when the upstream flow completes successfully, using DeploymentEventTrigger to connect them.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, serve\nfrom prefect.events import DeploymentEventTrigger\n\n\n@flow(log_prints=True)\ndef upstream_flow():\n    print(\"upstream flow\")\n\n\n@flow(log_prints=True)\ndef downstream_flow():\n    print(\"downstream flow\")\n\n\nif __name__ == \"__main__\":\n    upstream_deployment = upstream_flow.to_deployment(name=\"upstream_deployment\")\n    downstream_deployment = downstream_flow.to_deployment(\n        name=\"downstream_deployment\",\n        triggers=[\n            DeploymentEventTrigger(\n                expect={\"prefect.flow-run.Completed\"},\n                match_related={\"prefect.resource.name\": \"upstream_deployment\"},\n            )\n        ],\n    )\n\n    serve(upstream_deployment, downstream_deployment)\n```\n\n----------------------------------------\n\nTITLE: Defining Deployment Triggers Using Terraform\nDESCRIPTION: This HCL snippet illustrates how to set up deployment triggers for automations using Terraform. It defines both a deployment resource and an associated automation that responds to specific events.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_3\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"prefect_deployment\" \"my_deployment\" {\n  name            = \"my-deployment\"\n  work_pool_name  = \"my-work-pool\"\n  work_queue_name = \"default\"\n  entrypoint      = \"path/to/flow.py:decorated_fn\"\n}\n\nresource \"prefect_automation\" \"event_trigger\" {\n  name = \"my-automation\"\n  trigger = {\n    event = {\n      posture   = \"Reactive\"\n      expect    = [\"external.resource.pinged\"]\n      threshold = 1\n      within    = 0\n    }\n  }\n  actions = [\n    {\n      type          = \"run-deployment\"\n      source        = \"selected\"\n      deployment_id = prefect_deployment.my_deployment.id\n      parameters = jsonencode({\n        \"param_1\" : \"{{ event }}\"\n      })\n    },\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Delete Flow Run Input OpenAPI Specification\nDESCRIPTION: OpenAPI specification defining an endpoint to delete a specific input key from a flow run. The endpoint requires a flow run ID and input key as path parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/delete-flow-run-input.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/flow_runs/{id}/input/{key}\n```\n\n----------------------------------------\n\nTITLE: Creating ACI Worker Container Instance\nDESCRIPTION: Deploys a container instance running a Prefect ACI worker with specified environment variables and configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/aci_worker.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naz container create \\\n    --name <work-pool-name> \\\n    --resource-group $RG_NAME \\\n    --assign-identity $IDENTITY_ID \\\n    --image \"prefecthq/prefect:3-python3.12\" \\\n    --secure-environment-variables PREFECT_API_URL=$PREFECT_API_URL PREFECT_API_KEY=$PREFECT_API_KEY \\\n    --command-line \"/bin/bash -c 'pip install prefect-azure && prefect worker start --pool <work-pool-name> --type azure-container-instance'\"\n```\n\n----------------------------------------\n\nTITLE: Downloading a Blob from Azure Blob Storage using Prefect\nDESCRIPTION: Python code example demonstrating how to download a blob from Azure Blob Storage using prefect-azure. It includes creating credentials and using the blob_storage_download function within a Prefect flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nfrom prefect_azure import AzureBlobStorageCredentials\nfrom prefect_azure.blob_storage import blob_storage_download\n\n@flow\ndef example_blob_storage_download_flow():\n    connection_string = \"connection_string\"\n    blob_storage_credentials = AzureBlobStorageCredentials(\n        connection_string=connection_string,\n    )\n    data = blob_storage_download(\n        blob=\"prefect.txt\",\n        container=\"prefect\",\n        blob_storage_credentials=blob_storage_credentials,\n    )\n    return data\n\nexample_blob_storage_download_flow()\n```\n\n----------------------------------------\n\nTITLE: Deploying Multiple Prefect Flows\nDESCRIPTION: Example of deploying multiple Prefect flows simultaneously using the deploy function. Shows how to specify both individual and shared configuration for multiple deployments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-via-python.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, deploy\n\n\n@flow\ndef my_flow_1():\n    print(\"I'm number one!\")\n\n\n@flow\ndef my_flow_2():\n    print(\"Always second...\")\n\n\nif __name__ == \"__main__\":\n    deploy(\n        # Use the `to_deployment` method to specify configuration \n        #specific to each deployment\n        my_flow_1.to_deployment(\"my-deployment-1\"),\n        my_flow_2.to_deployment(\"my-deployment-2\"),\n\n        # Specify shared configuration for both deployments\n        image=\"my-registry.com/my-docker-image:my-tag\",\n        push=False,\n        work_pool_name=\"my-work-pool\",  \n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Webhook JSON Template for Model Training\nDESCRIPTION: JSON template for configuring the Prefect webhook for model training. This template defines the event structure that will be sent when the webhook is called.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"event\": \"webhook.called\",\n    \"resource\": {\n        \"prefect.resource.id\": \"webhook.resource.id\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Prefect Deployment\nDESCRIPTION: This example demonstrates how to set environment variables for a Prefect deployment. It shows adding an extra pip package using the 'EXTRA_PIP_PACKAGES' environment variable in the 'job_variables' argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    get_repo_info.deploy(\n        name=\"my-deployment-never-pull\",\n        work_pool_name=\"my-docker-pool\",\n        job_variables={\"env\": {\"EXTRA_PIP_PACKAGES\": \"boto3\"} },\n        image=\"my-image:my-tag\",\n        push=False\n    )\n```\n\n----------------------------------------\n\nTITLE: Processing Incoming Events with Jinja2 Template\nDESCRIPTION: This Jinja2 template generates an event representation when the model is updated. It uses template variables to include dynamic model identifiers and names within the event resource ID and name fields, allowing for tailored event categorization based on the model.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_4\n\nLANGUAGE: jinja2\nCODE:\n```\n{\n    \"event\": \"model.refreshed\",\n    \"resource\": {\n        \"prefect.resource.id\": \"product.models.{{ body.model }}\",\n        \"prefect.resource.name\": \"{{ body.friendly_name }}\",\n        \"producing-team\": \"Data Science\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Incorrect usage of async blocks in Prefect 3.0\nDESCRIPTION: Example showing incorrect usage of an asynchronous block load method without awaiting it, which results in an AttributeError. This illustrates a common issue when working with async functions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.system import Secret\n\nasync def my_async_function():\n    my_secret = Secret.load(\"my-secret\")\n    print(my_secret.get()) # AttributeError: 'coroutine' object has no attribute 'get'\n```\n\n----------------------------------------\n\nTITLE: Setting Up an Azure Container Instance Work Pool\nDESCRIPTION: Commands to create an Azure Container Instance work pool and start a worker that pulls jobs from this pool, enabling workflows to run on Azure Container Instances.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create -t azure-container-instance my-aci-work-pool\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -n my-aci-worker -p my-aci-work-pool\n```\n\n----------------------------------------\n\nTITLE: Global Retry Configuration in Prefect\nDESCRIPTION: Shows how to set default retry behavior globally using Prefect configuration settings. Sets default retry count to 2 and retry delays to 1, 10, and 100 seconds.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/write-tasks.mdx#2025-04-21_snippet_19\n\nLANGUAGE: text\nCODE:\n```\nprefect config set PREFECT_TASK_DEFAULT_RETRIES=2\nprefect config set PREFECT_TASK_DEFAULT_RETRY_DELAY_SECONDS = [1, 10, 100]\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Dockerless Prefect Deployment\nDESCRIPTION: Configures Prefect deployment using YAML for Dockerless execution, specifying environment synchronization with Coiled.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\npush:\n- prefect_coiled.deployments.steps.build_package_sync_senv:\n    id: coiled_senv\n\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /scratch/batch\n\ndeployments:\n- name: example-coiled-deploy\n  build: null\n  entrypoint: example_flow:my_flow\n  work_pool:\n    name: example-coiled-pool\n    job_variables:\n      software: '{{ coiled_senv.name }}'\n```\n\n----------------------------------------\n\nTITLE: Creating Prefect S3 Bucket Block with Python SDK\nDESCRIPTION: Python code to create an S3 Bucket block in Prefect, referencing the previously created AWS Credentials block to connect to a specific S3 bucket.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import S3Bucket, AwsCredentials\n\naws_credentials = AwsCredentials.load(\"NAME-OF-YOUR-AWS-CREDENTIALS-BLOCK\") #Replace this with your AWS credentials block name.\n\nS3Bucket(\n    bucket_name=\"YOUR-S3-BUCKET-NAME\", #Replace this with your S3 bucket name.\n    credentials=aws_credentials #Replace this with your AWS credentials block name.\n).save(\"BLOCK-NAME-PLACEHOLDER\") #Replace this with a descriptive block name.\n```\n\n----------------------------------------\n\nTITLE: Sample Pipeline Execution Output\nDESCRIPTION: Example terminal output showing the flow execution with cached results, demonstrating the successful implementation of task caching.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n20:03:04.398 | INFO | prefect.engine - Created flow run 'laughing-nightingale' for flow 'show-stars'\n20:03:05.146 | INFO | Task run 'fetch_stats-90f' - Finished in state Cached(type=COMPLETED)\n20:03:05.149 | INFO | Task run 'fetch_stats-258' - Finished in state Cached(type=COMPLETED)\n20:03:05.153 | INFO | Task run 'fetch_stats-924' - Finished in state Cached(type=COMPLETED)\n20:03:05.159 | INFO | Task run 'get_stars-3a9' - Finished in state Completed()\n20:03:05.159 | INFO | Task run 'get_stars-ed3' - Finished in state Completed()\n20:03:05.161 | INFO | Task run 'get_stars-39c' - Finished in state Completed()\n20:03:05.162 | INFO | Flow run 'laughing-nightingale' - PrefectHQ/prefect: 17756 stars\n20:03:05.163 | INFO | Flow run 'laughing-nightingale' - pydantic/pydantic: 21613 stars\n20:03:05.163 | INFO | Flow run 'laughing-nightingale' - huggingface/transformers: 136166 stars\n20:03:05.339 | INFO | Flow run 'laughing-nightingale' - Finished in state Completed()\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Worker with Custom Values\nDESCRIPTION: Command to install the Prefect worker using a custom values file for configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nhelm install prefect-worker prefect/prefect-worker \\\n  --namespace prefect \\\n  -f worker-values.yaml\n```\n\n----------------------------------------\n\nTITLE: Sample Prefect Flow for ACI\nDESCRIPTION: Demonstrates a simple Prefect flow implementation with Docker image deployment configuration for ACI execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/aci_worker.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.logging import get_run_logger\nfrom prefect.docker import DockerImage\n\n@flow\ndef my_flow():\n    logger = get_run_logger()\n    logger.info(\"Hello from ACI!\")\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"aci-deployment\",\n        image=DockerImage(\n            name=\"<registry-name>.azurecr.io/example:latest\",\n            platform=\"linux/amd64\",\n        ),\n        work_pool_name=\"<work-pool-name>\",\n    )\n```\n\n----------------------------------------\n\nTITLE: SQL Example of OR Condition for Scheduling\nDESCRIPTION: Demonstrates an SQL example showing the 'OR' logical operation used to explain scheduling behavior\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employees WHERE first_name = 'Ford' OR last_name = 'Prefect';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * from employees WHERE first_name = 'Zaphod' AND last_name = 'Beeblebrox';\n```\n\n----------------------------------------\n\nTITLE: Stopping Prefect Server\nDESCRIPTION: Stops a Prefect server instance that is running in the background.  This command is used to shut down a Prefect server process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server stop [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Advanced Jinja Templating with Control Structures\nDESCRIPTION: This code demonstrates how to use Jinja control structures like loops to iterate through event data in automation notifications, showing automation details and related resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nAutomation: {{ automation.name }}\nDescription: {{ automation.description }}\n\nEvent: {{ event.id }}\nResource:\n{% for label, value in event.resource %}\n{{ label }}: {{ value }}\n{% endfor %}\nRelated Resources:\n{% for related in event.related %}\n    Role: {{ related.role }}\n    {% for label, value in related %}\n    {{ label }}: {{ value }}\n    {% endfor %}\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Client using pip\nDESCRIPTION: Command to install the prefect-client package using pip package manager. Requires Python 3.9 or later.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/client/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-client\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Deployment Manually\nDESCRIPTION: Command to manually trigger a specific Prefect deployment from the command line, useful for testing or one-off executions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nuv run prefect deployment run main/prefect-modal-example\n```\n\n----------------------------------------\n\nTITLE: Creating DBT Cloud Job Block\nDESCRIPTION: Python script to create and save a DBT Cloud job configuration as a Prefect block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"CREDENTIALS-BLOCK-PLACEHOLDER\")\ndbt_cloud_job = DbtCloudJob(\n    dbt_cloud_credentials=dbt_cloud_credentials,\n    job_id=\"JOB-ID-PLACEHOLDER\"\n).save(\"JOB-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Download Repository Contents (Python)\nDESCRIPTION: This code snippet demonstrates how to load a previously created BitbucketRepository block and use the get_directory() method to download the contents of the repository to the local filesystem. It provides an example of interacting with a Bitbucket repository using the library.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_bitbucket.repositories import BitbucketRepository\n\n\ndef fetch_repo():\n    bitbucket_block = BitbucketRepository.load(\"my-bitbucket-block\")\n    bitbucket_block.get_directory()\n\n\nif __name__ == \"__main__\":\n    fetch_repo()\n```\n\n----------------------------------------\n\nTITLE: Pausing a work queue\nDESCRIPTION: Command to pause a work queue, preventing it from accepting new flow runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues pause [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Cross-Workspace Flow Run Analysis\nDESCRIPTION: Script that aggregates and analyzes flow run statistics across all workspaces in a Prefect account. Provides counts by state and date to help understand usage patterns.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/scripts.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Reference to cross_workspace_flow_runs.py\n```\n\n----------------------------------------\n\nTITLE: Using RedisLockManager for Distributed Cache Locking in Python with Prefect\nDESCRIPTION: This snippet demonstrates how to use RedisLockManager from prefect-redis for managing locks in a distributed setting. It configures a cache policy with SERIALIZABLE isolation level using a shared Redis instance.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import task\nfrom prefect.cache_policies import TASK_SOURCE, INPUTS\nfrom prefect.transactions import IsolationLevel\n\nfrom prefect_redis import RedisLockManager\n\ncache_policy = (INPUTS + TASK_SOURCE).configure(\n    isolation_level=IsolationLevel.SERIALIZABLE,\n    lock_manager=RedisLockManager(host=\"my-redis-host\"),\n)\n\n@task(cache_policy=cache_policy)\ndef my_cached_task(x: int):\n    return x + 42\n```\n\n----------------------------------------\n\nTITLE: Setting Up Metric Trigger for Kubernetes Workload Lateness in JSON\nDESCRIPTION: Monitors average lateness of Kubernetes workloads, defining a trigger to fire based on lateness thresholds and duration parameters in a specified time range.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"metric\",\n  \"match\": {\n    \"prefect.resource.id\": \"prefect.flow-run.*\"\n  },\n  \"match_related\": {\n    \"prefect.resource.id\": \"prefect.work-pool.kubernetes\",\n    \"prefect.resource.role\": \"work-pool\"\n  },\n  \"metric\": {\n    \"name\": \"lateness\",\n    \"threshold\": 300,\n    \"operator\": \">\",\n    \"range\": 86400,\n    \"firing_for\": 600\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with Docker Image\nDESCRIPTION: Example of deploying a Prefect flow using a Docker image with custom configuration\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a Docker image!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.deploy(\n        name=\"my-deployment\",\n        image=\"my-repo/my-image:latest\",\n        work_pool_name=\"my-k8s-job\",\n        job_variables=dict(pull_policy=\"Never\"),\n        parameters=dict(name=\"Marvin\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: Running Flows in Staging Workspace\nDESCRIPTION: Switch to the staging workspace and run flows with simulated failures using a Python script.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# Run flows in the staging workspace \nprefect cloud workspace set --workspace \"<account handle>/staging\"\npython simulate_failures.py --fail-at-run 3\n```\n\n----------------------------------------\n\nTITLE: Passing Triggers via CLI with prefect deploy\nDESCRIPTION: This snippet demonstrates how to pass trigger configurations to the 'prefect deploy' command, either as JSON strings directly in the command or by referencing external YAML or JSON files containing trigger definitions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Pass a trigger as a JSON string\nprefect deploy -n test-deployment \\\n  --trigger '{\n    \"enabled\": true,\n    \"match\": {\n      \"prefect.resource.id\": \"prefect.flow-run.*\"\n    },\n    \"expect\": [\"prefect.flow-run.Completed\"]\n  }'\n\n# Pass a trigger using a JSON/YAML file\nprefect deploy -n test-deployment --trigger triggers.yaml\nprefect deploy -n test-deployment --trigger my_stuff/triggers.json\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Cache Invalidation with Code Changes in Prefect\nDESCRIPTION: Shows how changing the task's code definition invalidates the cache when using the TASK_SOURCE cache policy, causing the task to execute again.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@task(cache_policy=TASK_SOURCE)\ndef my_stateful_task():\n    print('sleeping')\n    time.sleep(10)\n\n    # change the return value, for example\n    return 43 \n\nmy_stateful_task() # sleeps again\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Development Server\nDESCRIPTION: Command to start a complete development environment with hot-reloading API, UI, and agent processes. Services can be selectively enabled/disabled.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect dev start [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Problematic Python Code with Simulated Failures\nDESCRIPTION: The original simulate_failures.py file containing a deliberate failure condition. When the run count exceeds fail_at_run, an exception is raised causing the flow to fail.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/debug.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport asyncio\nfrom typing import Optional\n\nfrom prefect import flow, task\nfrom prefect.client.orchestration import get_client\n\n\n@task\ndef process_data(run: int, fail_at_run: Optional[int] = None) -> bool:\n    \"\"\"Simulate data processing with failures\"\"\"\n    \n    # Simulate persistent failures\n    if fail_at_run and run > fail_at_run:\n        raise Exception(f\"Run failed\")\n    \n    return True\n\n# ...\n```\n\n----------------------------------------\n\nTITLE: Getting a Synchronous Prefect Client in Python\nDESCRIPTION: Provide a synchronous context manager to interact with Prefect client. Requires importing get_client with sync_client set to True. This example demonstrates how to print a JSON response using the synchronous client.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import get_client\n\nwith get_client(sync_client=True) as client:\n    response = client.hello()\n    print(response.json()) # 👋\n```\n\n----------------------------------------\n\nTITLE: Defining Expected Events and Threshold in JSON\nDESCRIPTION: Configure Prefect triggers to evaluate specific events and thresholds. Requires understanding of 'expect' and 'threshold' parameters, and may require 'within' for timing constraints.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n\"expect\": [\n  \"prefect.flow-run.Completed\"\n],\n\"threshold\": 2,\n\"within\": 60,\n...\n```\n\n----------------------------------------\n\nTITLE: Flow Run Logs Viewing Command\nDESCRIPTION: Command to view logs for a specific flow run with options for filtering and ordering log output.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run logs [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Setting up a Python Environment with uv\nDESCRIPTION: Sets up a Python virtual environment using `uv`. Then it activates the environment and installs prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuv venv\n```\n\nLANGUAGE: bash unix\nCODE:\n```\nsource .venv/bin/activate\n```\n\nLANGUAGE: bash windows\nCODE:\n```\n.\\.venv\\Scripts\\activate\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow Using Python's .deploy() Method\nDESCRIPTION: This Python snippet shows how to deploy a flow using the .deploy() method, specifying job variables in a Python dictionary format.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/zzstoatzz/prefect-monorepo.git\",\n        entrypoint=\"src/demo_project/demo_flow.py:some_work\"\n    ).deploy(\n        name=\"demo-deployment\",\n        work_pool_name=\"local\",\n        job_variables={\n            \"env\": {\n                \"EXECUTION_ENVIRONMENT\": os.environ.get(\"EXECUTION_ENVIRONMENT\", \"local\"),\n                \"MY_NOT_SO_SECRET_CONFIG\": os.environ.get(\"MY_NOT_SO_SECRET_CONFIG\")\n            }\n        }\n    )\n```\n\n----------------------------------------\n\nTITLE: State Change Hook Signatures in Prefect\nDESCRIPTION: Code snippet showing the function signatures for task and flow state hooks, which execute in response to client-side state changes, allowing for custom actions on specific state transitions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef my_task_state_hook(task: Task, run: TaskRun, state: State) -> None:\n    ...\n\ndef my_flow_state_hook(flow: Flow, run: FlowRun, state: State) -> None:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Build Action Example for Deployment\nDESCRIPTION: This snippet shows how to set up the build action in the prefect.yaml file using a step to build a Docker image, along with its requirements and parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n  requires: prefect-docker>=0.3.0\n  image_name: my-repo/my-image\n  tag: my-tag\n  dockerfile: auto\n```\n\n----------------------------------------\n\nTITLE: Creating Prefect Secret Block for MotherDuck Access Token\nDESCRIPTION: Python code to create a Secret block in Prefect to securely store a MotherDuck access token for database authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_secrets import Secret\n\nSecret(\n    value=\"YOUR-MOTHERDUCK-TOKEN\", #Replace this with your motherduck access token.\n    name=\"motherduck-access-token\" #Replace this with a name that will help you identify the secret.\n).save(\"BLOCK-NAME-PLACEHOLDER\") #Replace this with a descriptive block name.\n```\n\n----------------------------------------\n\nTITLE: Executing Prefect Flow with Deployment\nDESCRIPTION: Runs a deployed Prefect flow using a pre-specified Coiled deployment. Assumes deployment exists.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run 'my-flow/example-coiled-deployment'\n```\n\n----------------------------------------\n\nTITLE: Prefect Server Services Command\nDESCRIPTION: The main command for interacting with the Prefect server loop services. It provides access to subcommands for managing and controlling the background services that support Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services [OPTIONS] COMMAND [ARGS]...\"\n```\n\n----------------------------------------\n\nTITLE: Authenticating to Prefect Cloud Using UV\nDESCRIPTION: This command is for authenticating to Prefect Cloud using a personal access token. It registers and creates a block for GitHub integration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuv run prefect cloud login\n```\n\n----------------------------------------\n\nTITLE: Inspecting Artifacts via CLI\nDESCRIPTION: CLI command to inspect all versions of an artifact with a specific key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect artifact inspect <my_key>\n```\n\n----------------------------------------\n\nTITLE: Create Concurrency Limit\nDESCRIPTION: Creates a concurrency limit for a specified tag to control how many task runs with that tag may simultaneously be in a Running state.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit create [OPTIONS] TAG CONCURRENCY_LIMIT\n```\n\n----------------------------------------\n\nTITLE: Running Shell Commands with Prefect CLI using Watch\nDESCRIPTION: This snippet demonstrates how to use the `watch` command in Prefect CLI to execute a shell command immediately. It helps integrate shell commands into Prefect workflows for quick tasks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/cli-shell.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect shell watch \"curl http://wttr.in/Chicago?format=3\"\n```\n\n----------------------------------------\n\nTITLE: Upgrading prefect and prefect-redis packages\nDESCRIPTION: This command upgrades both Prefect and prefect-redis to their latest versions using pip.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-redis/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Server with Default Values\nDESCRIPTION: Command to deploy the Prefect server using default values from the Helm chart.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nhelm install prefect-server prefect/prefect-server --namespace prefect\n```\n\n----------------------------------------\n\nTITLE: Getting an Asynchronous Prefect Client in Python\nDESCRIPTION: Provide an asynchronous context manager to interact with Prefect client. Requires importing get_client from prefect. This example demonstrates how to print a JSON response using the async client.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/interact-with-api.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import get_client\n\nasync with get_client() as client:\n    response = await client.hello()\n    print(response.json()) # 👋\n```\n\n----------------------------------------\n\nTITLE: GitHub Actions Workflow for Prefect Deployment (prefect.yaml)\nDESCRIPTION: This YAML file defines a GitHub Actions workflow that triggers on pushes to the `main` branch. It checks out the repository, logs into Docker Hub, sets up Python, and then installs dependencies and uses the `prefect deploy` command to deploy the flow based on the `prefect.yaml` file.  Environment variables for the Prefect API key and URL are sourced from repository secrets.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nname: Deploy Prefect flow\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n\n      - name: Prefect Deploy\n        env:\n          PREFECT_API_KEY: ${{ secrets.PREFECT_API_KEY }}\n          PREFECT_API_URL: ${{ secrets.PREFECT_API_URL }}\n        run: |\n          pip install -r requirements.txt\n          prefect deploy -n my-deployment\n```\n\n----------------------------------------\n\nTITLE: Deleting a work queue\nDESCRIPTION: Command to permanently delete a work queue by its name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues delete [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Directly Accessing Run Context in Python\nDESCRIPTION: Demonstrates how to access flow run and task run contexts directly using context methods, with error handling for context availability\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/runtime-context.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.context import FlowRunContext, TaskRunContext\n\nflow_run_ctx = FlowRunContext.get()\ntask_run_ctx = TaskRunContext.get()\n```\n\n----------------------------------------\n\nTITLE: Configuring EventBridge Rule for Model Changes\nDESCRIPTION: JSON event pattern for an AWS EventBridge rule that triggers model inference when new objects are uploaded to the S3 bucket for models. This rule automates the inference process when new models are available.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source\": [\"aws.s3\"],\n  \"detail-type\": [\"Object Created\"],\n  \"detail\": {\n    \"bucket\": {\n      \"name\": [\"prefect-model\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Compound Triggers in YAML for Deployment\nDESCRIPTION: This YAML snippet demonstrates how to create a compound trigger for a deployment. It shows an example of an automation response based on multiple event conditions from an external resource.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n  - name: my-deployment\n    entrypoint: path/to/flow.py:decorated_fn\n    work_pool:\n      name: my-work-pool\n    triggers:\n      - type: compound\n        require: all\n        parameters:\n          param_1: \"{{ event }}\"\n        triggers:\n          - type: event\n            match:\n              prefect.resource.id: my.external.resource\n            expect:\n              - external.resource.pinged\n          - type: event\n            match:\n              prefect.resource.id: my.external.resource\n            expect:\n              - external.resource.replied\n```\n\n----------------------------------------\n\nTITLE: Using Variables in YAML Deployment Configuration\nDESCRIPTION: Shows how to reference Prefect variables in a prefect.yaml file for deployment configuration. The example demonstrates variable syntax and use case in git clone deployment steps.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/variables.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.git_clone:\n    repository: https://github.com/PrefectHQ/hello-projects.git\n    branch: \"{{ prefect.variables.deployment_branch }}\"\n```\n\n----------------------------------------\n\nTITLE: Inspect Prefect Automation\nDESCRIPTION: Command to inspect details of a specific automation by name or ID. Supports output in YAML or JSON format.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect automations inspect [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Flow failure handling with try/except in Prefect 3.0\nDESCRIPTION: Example demonstrating how to use try/except blocks to handle task failures and return appropriate flow states. This provides fine-grained control over flow behavior when tasks fail.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\nfrom prefect.states import Failed\n\n@task\ndef failing_task():\n    raise ValueError(\"Task failed\")\n\n@flow\ndef my_flow():\n    try:\n        failing_task()\n    except ValueError:\n        return Failed(message=\"Flow failed due to task failure\")\n    return \"Flow completed successfully\"\n\nprint(my_flow())  # Output: Failed(message='Flow failed due to task failure')\n```\n\n----------------------------------------\n\nTITLE: Configuring SQLite Connection\nDESCRIPTION: Example of creating and saving a SQLite database connection.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_sqlalchemy import SqlAlchemyConnector, ConnectionComponents, SyncDriver\n\nconnector = SqlAlchemyConnector(\n    connection_info=ConnectionComponents(\n        driver=SyncDriver.SQLITE_PYSQLITE,\n        database=\"DATABASE-PLACEHOLDER.db\"\n    )\n)\n\nconnector.save(\"BLOCK_NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Retrieving Access Token from Azure Key Vault in Prefect YAML\nDESCRIPTION: This example shows how to retrieve an access token from Azure Key Vault using a shell script and use it for private repository cloning.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.run_shell_script:\n    id: get-access-token\n    script: az keyvault secret show --name <secret name> --vault-name <secret vault> --query \"value\" --output tsv\n    stream_output: false\n- prefect.deployments.steps.git_clone:\n    repository: https://bitbucket.org/samples/deployments.git\n    branch: master\n    access_token: \"{{ get-access-token.stdout }}\"\n```\n\n----------------------------------------\n\nTITLE: Opening Prefect Dashboard in Browser\nDESCRIPTION: Command to launch the Prefect UI dashboard in the default web browser. This provides a direct way to access the graphical interface for managing Prefect workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dashboard.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect dashboard open [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-gitlab Package\nDESCRIPTION: Commands to install and upgrade the prefect-gitlab package along with its dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[gitlab]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[gitlab]\"\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Server via CLI\nDESCRIPTION: Command to initiate a self-hosted Prefect server instance with UI using the CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/cli.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect server start\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment Job Variables in YAML\nDESCRIPTION: Example of configuring deployment-specific job variables in a prefect.yaml file to override work pool defaults.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n- name: demo-deployment\n  entrypoint: demo_project/demo_flow.py:some_work\n  work_pool:\n    name: above-ground  \n    job_variables:\n        stream_output: false\n```\n\n----------------------------------------\n\nTITLE: Configuring Job Variables for Prefect Deployment\nDESCRIPTION: This snippet illustrates how to configure job variables for a Prefect deployment. It shows overriding the image pull policy using the 'job_variables' argument in the 'deploy' method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/docker.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    get_repo_info.deploy(\n        name=\"my-deployment-never-pull\",\n        work_pool_name=\"my-docker-pool\",\n        job_variables={\"image_pull_policy\": \"Never\"},\n        image=\"my-image:my-tag\",\n        push=False\n    )\n```\n\n----------------------------------------\n\nTITLE: Defining Job Variables in JSON Format\nDESCRIPTION: This snippet defines a set of job variables in JSON format for use in a work pool's runtime environment, allowing dynamic configuration for deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"EXECUTION_ENV\": \"staging\",\n  \"MY_NOT_SO_SECRET_CONFIG\": \"plumbus\"\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Prefect UI via Port Forwarding\nDESCRIPTION: Command to set up port forwarding to access the Prefect UI on localhost.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --namespace prefect port-forward svc/prefect-server 4200:4200\n```\n\n----------------------------------------\n\nTITLE: Listing Prefect Server Services\nDESCRIPTION: Lists all available Prefect services and their status. This command is used to check which services are running and their current state.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_11\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services list-services [OPTIONS]\"\n```\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services ls [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Resuming a Suspended Prefect Flow Run\nDESCRIPTION: This snippet demonstrates how to resume a suspended Prefect flow run using the `resume_flow_run` function. It requires the `FLOW_RUN_ID` of the flow run to be resumed.  The `resume_flow_run` function is called to continue the execution of the suspended flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import resume_flow_run\n\nresume_flow_run(FLOW_RUN_ID)\n```\n\n----------------------------------------\n\nTITLE: Create ECR Repository on AWS\nDESCRIPTION: This snippet creates an ECR repository using the AWS CLI and authenticates the Docker daemon.  Replace `<IMAGE-NAME>` with the name of the repository, `<REGION>` with the AWS region, and `<AWS_ACCOUNT_ID>` with your AWS account ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Replace the image name with your own value\naws ecr create-repository --repository-name <IMAGE-NAME>\n\n# Login to ECR\n# Replace the region and account ID with your own values\naws ecr get-login-password --region <REGION> | docker login \\\n  --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect with Pip\nDESCRIPTION: This snippet shows how to install the Prefect library using pip for a global installation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip3 install prefect\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Serve Command\nDESCRIPTION: This command is used to serve Prefect tasks, enabling their execution within the Prefect engine. It requires specifying one or more entrypoints to the task definitions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect task serve [OPTIONS] ENTRYPOINTS...\n```\n\n----------------------------------------\n\nTITLE: Running an Event-Driven Deployment in Prefect\nDESCRIPTION: Bash commands to run a Python script for event-driven deployments and trigger the upstream deployment, which will automatically trigger the downstream deployment when completed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\npython event_driven_deployments.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run upstream-flow/upstream_deployment\n```\n\n----------------------------------------\n\nTITLE: Prefect Worker Architecture Diagram\nDESCRIPTION: This snippet visualizes the architecture of a worker-based work pool deployment using a flowchart. It represents the relationships between workers, flow runs, and the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/workers.mdx#2025-04-21_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\n%%{\n  init: {\n    'theme': 'neutral',\n    'themeVariables': {\n      'margin': '10px'\n    }\n  }\n}%%\n\nflowchart TD\n    subgraph your_infra[\"Your Execution Environment\"]\n        worker[\"Worker\"]\n        subgraph flow_run_infra[Infrastructure]\n            flow_run_a(__(\"Flow Run A\"))\n        end\n        subgraph flow_run_infra_2[Infrastructure]\n            flow_run_b(__(\"Flow Run B\"))\n        end      \n    end\n\n    subgraph api[\"Prefect API\"]\n    Deployment --> |assigned to| work_pool\n        work_pool([\"Work Pool\"])\n    end\n\n    worker --> |polls| work_pool\n    worker --> |creates| flow_run_infra\n    worker --> |creates| flow_run_infra_2\n```\n\n----------------------------------------\n\nTITLE: In-Memory SQLite Configuration\nDESCRIPTION: Command to configure Prefect to use an in-memory SQLite database for testing purposes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_DATABASE_CONNECTION_URL=\"sqlite+aiosqlite:///file::memory:?cache=shared&uri=true&check_same_thread=false\"\n```\n\n----------------------------------------\n\nTITLE: Authenticate to Azure\nDESCRIPTION: This snippet authenticates to Azure using the Azure CLI. It requires the Azure CLI to be installed and configured.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naz login\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Prefect API Key\nDESCRIPTION: Bash command to create a Kubernetes secret containing the Prefect Cloud API key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic prefect-api-key \\\n--namespace=prefect --from-literal=key=your-prefect-cloud-api-key\n```\n\n----------------------------------------\n\nTITLE: Previewing Scheduled Flow Runs Using Prefect CLI\nDESCRIPTION: The command to preview scheduled flow runs for a specific work pool with an option to specify the number of hours to look ahead (default is 1 hour).\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool preview 'test-pool' --hours 12\n```\n\n----------------------------------------\n\nTITLE: Defining SLAs with Prefect CLI\nDESCRIPTION: This bash command demonstrates how to define a Service Level Agreement (SLA) using the Prefect CLI. It uses the `prefect deploy` command with the `--sla` option to specify the SLA configuration as a JSON string. The SLA is named \"my-time-to-completion-sla\" with a duration of 10 seconds and 'high' severity.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/slas.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n\"prefect deploy --sla '{\\\"name\\\": \\\"my-time-to-completion-sla\\\", \\\"duration\\\": 10, \\\"severity\\\": \\\"high\\\"}'\"\n```\n\n----------------------------------------\n\nTITLE: Event-Related Resources JSON Example in Prefect\nDESCRIPTION: Sample JSON showing the structure of a flow-run completion event's related resources. This demonstrates the information available to match against in deployment triggers, including flow, deployment, and user resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_23\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"related\": [\n    {\n      \"prefect.resource.id\": \"prefect.flow.10e099ec-8358-4146-b188-be68027ee58f\",\n      \"prefect.resource.role\": \"flow\",\n      \"prefect.resource.name\": \"upstream-flow\"\n    },\n    {\n      \"prefect.resource.id\": \"prefect.deployment.be777bbd-4b15-49f3-bc1f-4d109374cee2\",\n      \"prefect.resource.role\": \"deployment\",\n      \"prefect.resource.name\": \"upstream_deployment\"\n    },\n    {\n      \"prefect.resource.id\": \"prefect-cloud.user.80546602-9f31-4396-ab4b-e873a5377feb\",\n      \"prefect.resource.role\": \"creator\",\n      \"prefect.resource.name\": \"stoat\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Prefect Flow Run Event Example\nDESCRIPTION: This JSON snippet showcases a `prefect.flow-run.Completed` event with details about the primary resource (flow run) and related resources (flow and deployment). It illustrates the structure of the `resource` and `related` fields, including IDs, names, and roles.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"resource\": {\n  \"prefect.resource.id\": \"prefect.flow-run.925eacce-7fe5-4753-8f02-77f1511543db\",\n  \"prefect.resource.name\": \"cute-kittiwake\"\n}\n\"related\": [\n  {\n    \"prefect.resource.id\": \"prefect.flow.cb6126db-d528-402f-b439-96637187a8ca\",\n    \"prefect.resource.role\": \"flow\",\n    \"prefect.resource.name\": \"hello\"\n  },\n  {\n    \"prefect.resource.id\": \"prefect.deployment.37ca4a08-e2d9-4628-a310-cc15a323378e\",\n    \"prefect.resource.role\": \"deployment\",\n    \"prefect.resource.name\": \"example\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating AWS Secret Block in Python\nDESCRIPTION: Python script to create an AwsSecret block for interacting with AWS Secret Manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.secrets_manager import AwsSecret\n\nAwsSecret(\n    secret_name=\"test_secret_name\",\n    aws_credentials=credentials,\n).save(\"AWS-SECRET-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Clearing the concurrency limit for a Prefect work pool\nDESCRIPTION: Removes any concurrency limits from a work pool, allowing it to process an unlimited number of concurrent work items.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_11\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool clear-concurrency-limit [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Inspect Deployment Details\nDESCRIPTION: Command to view detailed information about a specific deployment, including its configuration, parameters, and infrastructure settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments inspect [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Sending Slack Messages in Synchronous Prefect Flow\nDESCRIPTION: Example of a synchronous Prefect flow that sends a Slack message upon completion. It demonstrates the use of SlackCredentials and the send_chat_message function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-slack/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom prefect import flow\nfrom prefect.context import get_run_context\nfrom prefect_slack import SlackCredentials\nfrom prefect_slack.messages import send_chat_message\n\n@flow\ndef example_send_message_flow():\n   context = get_run_context()\n\n   # Run other tasks or flows here\n\n   token = \"xoxb-your-bot-token-here\"\n   asyncio.run(\n        send_chat_message(\n            slack_credentials=SlackCredentials(token),\n            channel=\"#prefect\",\n            text=f\"Flow run {context.flow_run.name} completed :tada:\"\n        )\n    )\n\nif __name__ == \"__main__\":\n    example_send_message_flow()\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Worker with Local Pool\nDESCRIPTION: Command to start a Prefect worker and create a local Process work pool if it doesn't exist\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool local\n```\n\n----------------------------------------\n\nTITLE: Run Deployment\nDESCRIPTION: Command to create and execute a flow run for a specified deployment, with options for scheduling, parameters, and monitoring.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments run [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: GitLab Repository Configuration in YAML\nDESCRIPTION: YAML configuration snippet for specifying a GitLab repository as flow code storage. This shows repository URL and commented authentication options using credentials or secret blocks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nrepository: https://gitlab.com/org/my-private-repo.git\n# Uncomment the following line if using a credentials block\n# credentials: \"{{ prefect.blocks.gitlab-credentials.my-gitlab-credentials-block }}\"\n# Uncomment the following line if using a Secret block\n# access_token: \"{{ prefect.blocks.secret.my-block-name }}\"\n```\n\n----------------------------------------\n\nTITLE: Jinja Templating for Work Pool Status Alerts\nDESCRIPTION: This code shows how to use Jinja templating specifically for work pool status alerts in automation notifications, accessing properties of the work pool object.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nWork pool status alert!\n\nName: {{ work_pool.name }}\nLast polled: {{ work_pool.last_polled }}\n```\n\n----------------------------------------\n\nTITLE: Inspect Deployment Details\nDESCRIPTION: Command to view detailed information about a specific deployment including its configuration, parameters, and infrastructure settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment inspect [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Registering Blocks from AWS Integration\nDESCRIPTION: Command to register blocks from a Prefect integration package, making them available in the Prefect Cloud UI\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/use-integrations.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_aws\n```\n\n----------------------------------------\n\nTITLE: Starting a Prefect Worker\nDESCRIPTION: Starts a Prefect worker connected to the 'local' work pool. This worker will execute tasks and flows as part of the performance testing setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool local\n```\n\n----------------------------------------\n\nTITLE: Configuring Base Job Template in JSON\nDESCRIPTION: Example of a base job template that defines job configuration and variables for work pool execution. Includes configuration for command, environment variables, labels, name, output streaming, and working directory settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"job_configuration\": {\n    \"command\": \"{{ command }}\",\n    \"env\": \"{{ env }}\",\n    \"labels\": \"{{ labels }}\",\n    \"name\": \"{{ name }}\",\n    \"stream_output\": \"{{ stream_output }}\",\n    \"working_dir\": \"{{ working_dir }}\"\n  },\n  \"variables\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"title\": \"Name\",\n        \"description\": \"Name given to infrastructure created by a worker.\",\n        \"type\": \"string\"\n      },\n      \"env\": {\n        \"title\": \"Environment Variables\",\n        \"description\": \"Environment variables to set when starting a flow run.\",\n        \"type\": \"object\",\n        \"additionalProperties\": {\n          \"type\": \"string\"\n        }\n      },\n      \"labels\": {\n        \"title\": \"Labels\",\n        \"description\": \"Labels applied to infrastructure created by a worker.\",\n        \"type\": \"object\",\n        \"additionalProperties\": {\n          \"type\": \"string\"\n        }\n      },\n      \"command\": {\n        \"title\": \"Command\",\n        \"description\": \"The command to use when starting a flow run. In most cases, this should be left blank and the command will be automatically generated by the worker.\",\n        \"type\": \"string\"\n      },\n      \"stream_output\": {\n        \"title\": \"Stream Output\",\n        \"description\": \"If enabled, workers will stream output from flow run processes to local standard output.\",\n        \"default\": true,\n        \"type\": \"boolean\"\n      },\n      \"working_dir\": {\n        \"title\": \"Working Directory\",\n        \"description\": \"If provided, workers will open flow run processes within the specified path as the working directory. Otherwise, a temporary directory will be created.\",\n        \"type\": \"string\",\n        \"format\": \"path\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Resume Schedule\nDESCRIPTION: Command to resume a paused deployment schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule resume [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment with YAML File\nDESCRIPTION: This YAML snippet illustrates how to define a deployment in a `prefect.yaml` file, specifying the entrypoint and associated configurations like scheduling.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n- name: demo-deployment\n  entrypoint: demo_project/demo_flow.py:some_work\n  work_pool:\n    name: local\n  schedule: null\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect API URL for Prefect Cloud\nDESCRIPTION: Configures the Prefect API URL to point to Prefect Cloud, including the account and workspace IDs. This allows the examples to connect to Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash cloud\nCODE:\n```\nprefect config set PREFECT_API_URL=https://api.prefect.cloud/api/accounts/{account_id}/workspaces/{workspace_id}\n```\n\n----------------------------------------\n\nTITLE: Pausing a Prefect work pool\nDESCRIPTION: Pauses a specific work pool, which prevents it from accepting new work items.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool pause [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Worker with Helm\nDESCRIPTION: Bash command to install the Prefect worker using Helm with custom values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nhelm install prefect-worker prefect/prefect-worker \\\n  --namespace=prefect \\\n  -f values.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring GCS Bucket\nDESCRIPTION: Setup for Google Cloud Storage bucket integration with Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gcp import GcpCredentials, GcsBucket\n\ngcs_bucket = GcsBucket(\n    bucket=\"BUCKET-NAME\",\n    gcp_credentials=GcpCredentials.load(\"BIGQUERY-BLOCK-NAME\")\n)\ngcs_bucket.save(\"GCS-BLOCK-NAME\")\n```\n\n----------------------------------------\n\nTITLE: Repository URL for Demo Code\nDESCRIPTION: GitHub repository URL containing the demo code for the tutorial.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/schedule.mdx#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://github.com/prefecthq/demos.git\n```\n\n----------------------------------------\n\nTITLE: Setting Prefect Configuration Values\nDESCRIPTION: Command to change configuration values in the current Prefect profile. Requires settings to be specified as arguments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/config.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect config set [OPTIONS] SETTINGS...\n```\n\n----------------------------------------\n\nTITLE: Defining Deployment Configuration in YAML for Prefect\nDESCRIPTION: YAML configuration for deploying a Prefect flow named 'build_names'. It specifies the deployment name, entrypoint, work pool, and other settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nname: automations-guide\nprefect-version: 3.0.0\nbuild: null\npush: null\npull:\n- prefect.deployments.steps.set_working_directory:\n    directory: /Users/src/prefect/Playground/automations-guide\ndeployments:\n- name: deploy-build-names\n  version: null\n  tags: []\n  description: null\n  entrypoint: test-automations.py:build_names\n  parameters: {}\n  work_pool:\n    name: tutorial-process-pool\n    work_queue_name: null\n    job_variables: {}\n  schedule: null\n```\n\n----------------------------------------\n\nTITLE: Creating a work queue in Prefect\nDESCRIPTION: Command for creating a new work queue with optional concurrency limits, work pool specification, and priority assignment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues create [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Worker Authentication\nDESCRIPTION: Command to create a Kubernetes secret for storing the basic authentication credentials for the Prefect worker.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic worker-auth-secret \\\n  --namespace prefect --from-literal auth-string='admin:password123'\n```\n\n----------------------------------------\n\nTITLE: Creating GitLab Credentials Block\nDESCRIPTION: Python code to create and save GitLab credentials block for authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gitlab import GitLabCredentials\n\n\ngitlab_credentials_block = GitLabCredentials(token=\"my_token\")\ngitlab_credentials_block.save(name=\"my-gitlab-credentials-block\")\n```\n\n----------------------------------------\n\nTITLE: Using a Prefect Profile\nDESCRIPTION: This command sets the specified profile as the active Prefect profile. This determines which configuration is used for subsequent Prefect operations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile use [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Scheduler Settings in Bash\nDESCRIPTION: This snippet shows the default configuration settings for the Prefect Scheduler service. These settings control various aspects of the scheduler's behavior, such as batch sizes, minimum and maximum runs, and scheduling time ranges.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_API_SERVICES_SCHEDULER_DEPLOYMENT_BATCH_SIZE='100'\nPREFECT_API_SERVICES_SCHEDULER_ENABLED='True'\nPREFECT_API_SERVICES_SCHEDULER_INSERT_BATCH_SIZE='500'\nPREFECT_API_SERVICES_SCHEDULER_LOOP_SECONDS='60.0'\nPREFECT_API_SERVICES_SCHEDULER_MIN_RUNS='3'\nPREFECT_API_SERVICES_SCHEDULER_MAX_RUNS='100'\nPREFECT_API_SERVICES_SCHEDULER_MIN_SCHEDULED_TIME='1:00:00'\nPREFECT_API_SERVICES_SCHEDULER_MAX_SCHEDULED_TIME='100 days, 0:00:00'\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Deployment YAML\nDESCRIPTION: YAML configuration for a Prefect deployment specifying the entrypoint, work pool settings, and other deployment parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_27\n\nLANGUAGE: yaml\nCODE:\n```\ndescription: null\nentrypoint: my_file.py:my_flow\nparameters: {}\nwork_pool:\n  name: my-work-pool\n  work_queue_name: null\n  job_variables: {}\nenforce_parameter_schema: true\nschedules: []\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Authentication in .env File\nDESCRIPTION: This snippet demonstrates how to set up basic authentication for a self-hosted Prefect server using environment variables. It includes settings for both the server and client side authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_SERVER_API_AUTH_STRING=\"admin:pass\"\nPREFECT_API_AUTH_STRING=\"admin:pass\"\n```\n\n----------------------------------------\n\nTITLE: Create ACR Registry on Azure\nDESCRIPTION: This snippet creates an Azure Container Registry (ACR) and attaches it to an AKS cluster.  Replace `<RESOURCE-GROUP-NAME>` with the resource group name, `<REPOSITORY-NAME>` with the name of the registry, and `<CLUSTER-NAME>` with the name of the Kubernetes cluster.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# Name must be a lower-case alphanumeric\n# Tier SKU can easily be updated later, e.g. az acr update --name <REPOSITORY-NAME> --sku Standard\naz acr create --resource-group <RESOURCE-GROUP-NAME> \\\n  --name <REPOSITORY-NAME> \\\n  --sku Basic\n\n# Attach ACR to AKS cluster\n# You need Owner, Account Administrator, or Co-Administrator role on your Azure subscription as per Azure docs\naz aks update --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME> --attach-acr <REPOSITORY-NAME>\n\n# You can verify AKS can now reach ACR\naz aks check-acr --resource-group RESOURCE-GROUP-NAME> --name <CLUSTER-NAME> --acr <REPOSITORY-NAME>.azurecr.io\n```\n\n----------------------------------------\n\nTITLE: Starting a Prefect Server\nDESCRIPTION: Commands to start a Prefect server, either blocking the current terminal session or running in a detached container. The `docker run` command starts a Prefect server in a detached Docker container, mapping port 4200.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# blocks the current terminal session\nprefect server start\n\n# run in a detached container\ndocker run -d -p 4200:4200 --name prefect-server prefecthq/prefect:3-latest prefect server start --host 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Creating Snowflake Connector Block\nDESCRIPTION: Python code to create and save a SnowflakeConnector block using saved credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_snowflake import SnowflakeCredentials, SnowflakeConnector\n\ncredentials = SnowflakeCredentials.load(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\n\nconnector = SnowflakeConnector(\n    credentials=credentials,\n    database=\"DATABASE-PLACEHOLDER\",\n    schema=\"SCHEMA-PLACEHOLDER\",\n    warehouse=\"COMPUTE_WH\",\n)\nconnector.save(\"CONNECTOR-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Displaying SecretDict Block Output in Python\nDESCRIPTION: Demonstrates how SecretDict automatically obfuscates sensitive values while regular dictionary values remain visible when the block is printed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nprint(system_configuration_block)\n# SystemConfiguration(\n#   system_secrets=SecretDict('{\"password\": \"**********\", \"api_token\": \"**********\", \"private_key\": \"**********\"}'), \n#   system_variables={'self_destruct_countdown_seconds': 60, 'self_destruct_countdown_stop_time': 7}\n# )\n```\n\n----------------------------------------\n\nTITLE: Managing Webhooks with Prefect CLI\nDESCRIPTION: This snippet illustrates how to manage webhooks in Prefect Cloud through the Prefect CLI. It includes commands to create, retrieve, list, disable, and rotate webhook endpoints. Dependencies include having Prefect CLI installed and configured to interact with Prefect Cloud. Key parameters include 'webhook-id' and 'webhook-url-slug' for specifying the targeted webhook. Outputs are command-line responses indicating the success or failure of operations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud webhook --help\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud webhook create your-webhook-name \\\n    --description \"Receives webhooks from your system\" \\\n    --template '{ \"event\": \"your.event.name\", \"resource\": { \"prefect.resource.id\": \"your.resource.id\" } }'\n```\n\nLANGUAGE: bash\nCODE:\n```\n# get webhook by ID\nprefect cloud webhook get <webhook-id>\n\n# list all configured webhooks in your workspace\nprefect cloud webhook ls\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud webhook toggle <webhook-id>\nWebhook is now disabled\n\nprefect cloud webhook toggle <webhook-id>\nWebhook is now enabled\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud webhook rotate <webhook-url-slug>\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Deployment with Azure Container Instance\nDESCRIPTION: Command to build a Prefect deployment using a previously saved Azure Container Instance infrastructure block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment build a_flow_module.py:log_hello_flow --name aci-dev -ib container-instance-job/aci-dev\n```\n\n----------------------------------------\n\nTITLE: Register Block Command\nDESCRIPTION: Command to register block types from a Python module or file to make them available in the UI\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect block register [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting Worker Template\nDESCRIPTION: Command to troubleshoot worker deployment by rendering the Helm template with custom values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nhelm template prefect-worker prefect/prefect-worker -f worker-values.yaml\n```\n\n----------------------------------------\n\nTITLE: GitHub Repository Configuration in YAML\nDESCRIPTION: YAML configuration snippet for specifying a GitHub repository as flow code storage. This includes URL and credentials options, with commented references to authentication methods using Prefect blocks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nrepository: https://github.com/org/my-private-repo.git\n# Uncomment the following line if using a credentials block\n# credentials: \"{{ prefect.blocks.github-credentials.my-github-credentials-block }}\"\n# Uncomment the following line if using a Secret block\n# access_token: \"{{ prefect.blocks.secret.my-block-name }}\"\n```\n\n----------------------------------------\n\nTITLE: Deploying a Flow to Kubernetes Work Pool\nDESCRIPTION: Example of deploying a Python flow to a Kubernetes work pool with container image specification.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n@flow(log_prints=True)\ndef buy():\n    print(\"Buying securities\")\n\nif __name__ == \"__main__\":\n    buy.deploy(\n        name=\"my-code-baked-into-an-image-deployment\",\n        work_pool_name=\"k8s-pool\",\n        image=\"my_registry/my_image:my_image_tag\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Cloning Private Repository using Access Token in Prefect YAML\nDESCRIPTION: This example shows how to use a Secret block to securely provide an access token for cloning repositories from Bitbucket, GitLab, or GitHub in the pull section.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.git_clone:\n    repository: https://bitbucket.org/org/repo.git\n    access_token: \"{{ prefect.blocks.secret.bitbucket-token }}\"\n```\n\n----------------------------------------\n\nTITLE: Starting Development UI\nDESCRIPTION: Commands for building and running the Prefect UI in development mode.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect dev ui\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect dev build-ui\n```\n\n----------------------------------------\n\nTITLE: Alternative command for provisioning work pool infrastructure\nDESCRIPTION: An alias for the provision-infrastructure command, provides the same functionality with a shorter name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool provision-infra [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Modifying Prefect Flow Serve Behavior on Shutdown\nDESCRIPTION: This code allows for configuration adjustments regarding flow scheduling upon shutdown by using `pause_on_shutdown=False`. This prevents the default auto-pausing behavior when the serving process is stopped.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/run-flows-in-local-processes.mdx#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nif __name__ == \"__main__\":\n    hello_world.serve(\n        name=\"my-first-deployment\",\n        tags=[\"onboarding\"],\n        parameters={\"goodbye\": True},\n        pause_on_shutdown=False,\n        interval=60\n    )\n```\n\n----------------------------------------\n\nTITLE: Running Test Script for Minimal Local Setup\nDESCRIPTION: Sets execute permissions for the test script and runs it to demonstrate the functionality of the minimal local setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nchmod +x test\n./test\n```\n\n----------------------------------------\n\nTITLE: Cancel Flow Run\nDESCRIPTION: Command to cancel an active flow run. Requires a flow run ID as argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs cancel [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Running the Prefect Pipeline in Bash\nDESCRIPTION: Commands to execute the data pipeline script, demonstrating the caching behavior between runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# Run the tasks and cache the results\npython my_data_pipeline.py\n\n# Run again (notice the cached results)\npython my_data_pipeline.py\n```\n\n----------------------------------------\n\nTITLE: List Deployments\nDESCRIPTION: View all deployments or filter deployments for specific flows with optional sorting by creation date.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Installing DBT Core Additional Capabilities\nDESCRIPTION: Installation commands for additional dbt Core capabilities with different databases\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[dbt]\"\npip install \"prefect-dbt[snowflake]\"\npip install \"prefect-dbt[bigquery]\"\npip install \"prefect-dbt[postgres]\"\npip install -U \"prefect-dbt[all_extras]\"\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for Prefect API\nDESCRIPTION: This requirements file specifies the exact versions of Python packages needed for the Prefect API to function correctly. It includes FastAPI for the web framework, Uvicorn as the ASGI server, uv package installer, WebSockets for real-time communication, Python-SOCKS for SOCKS proxy support, and HTTPX for HTTP requests.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/scripts/proxy-test/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfastapi==0.111.1\nuvicorn==0.28.1\nuv==0.5.7\nwebsockets==13.1\npython-socks==2.5.3\nhttpx==0.28.1\n```\n\n----------------------------------------\n\nTITLE: Prefect YAML Configuration for Deployment\nDESCRIPTION: This YAML configuration file stores metadata and deployment settings for Prefect flows, including how to pull from a GitHub repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# Welcome to your prefect.yaml file! You can use this file for storing and managing\n# configuration for deploying your flows. We recommend committing this file to source\n# control along with your flow code.\n\n# Generic metadata about this project\nname: prefect-modal\nprefect-version: 3.1.15\n\n# build section allows you to manage and build docker images\nbuild: null\n\n# push section allows you to manage if and how this project is uploaded to remote locations\npush: null\n\n# pull section allows you to provide instructions for cloning this project in remote locations\npull:\n- prefect.deployments.steps.git_clone:\n    repository: https://github.com/Ben-Epstein/prefect-modal\n    branch: main\n    access_token: null\n\n# the deployments section allows you to provide configuration for deploying flows\ndeployments:\n- name: null\n  version: null\n  tags: []\n  description: null\n  schedule: {}\n  flow_name: null\n  entrypoint: null\n  parameters: {}\n  work_pool:\n    name: null\n    work_queue_name: null\n    job_variables: {}\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Flows Command\nDESCRIPTION: The base command for accessing Prefect flow-related functionality. Used to view and serve flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flows.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect flows [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Prefect Flow\nDESCRIPTION: This snippet contains a basic example of a Prefect flow defined in a Python script, ready for serving.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef say_hi():\n    print(\"Hello!\")\n\nif __name__==\"__main__\":\n    say_hi.serve(name=\"served and daemonized deployment\")\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for POST /api/concurrency_limits/ Endpoint\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the POST endpoint of the concurrency limits API. It specifies the request body structure, response formats, and potential error responses for this endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/create-concurrency-limit.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/concurrency_limits/\n```\n\n----------------------------------------\n\nTITLE: Task Runner and Scheduling Configuration\nDESCRIPTION: Settings for task runner behavior including thread pool configuration and scheduling parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\ntasks.runner.thread_pool_max_workers = null\ntasks.scheduling.default_storage_block = null\ntasks.scheduling.delete_failed_submissions = true\n```\n\n----------------------------------------\n\nTITLE: Instantiate and Print a Block with Secret Fields\nDESCRIPTION: This code shows how the `SecretStr` field type obfuscates the value of the `aws_secret_access_key` field when the `AwsCredentials` block is printed. The actual secret key is not exposed in the output.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\naws_credentials_block = AwsCredentials(\n    aws_access_key_id=\"AKIAJKLJKLJKLJKLJKLJK\",\n    aws_secret_access_key=\"secret_access_key\"\n)\n\nprint(aws_credentials_block)\n```\n\n----------------------------------------\n\nTITLE: Enable Prefect Automation\nDESCRIPTION: Command to enable a disabled automation specified by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect automations enable [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Initializing and Applying Terraform Configuration\nDESCRIPTION: Bash commands to initialize Terraform and apply the configuration to provision the required cloud resources. This step creates the necessary AWS S3 buckets, EventBridge rules, and Prefect webhooks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd infra/\nterraform init\nterraform apply\n```\n\n----------------------------------------\n\nTITLE: Querying Artifacts using Python Requests with Prefect Cloud\nDESCRIPTION: This example uses the Python Requests library to interact with Prefect Cloud's REST API. It queries the 5 newest artifacts by sending a POST request to the artifacts endpoint with appropriate authentication headers and filtering criteria.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n\nPREFECT_API_URL=\"https://api.prefect.cloud/api/accounts/abc-my-cloud-account-id-is-here/workspaces/123-my-workspace-id-is-here\"\nPREFECT_API_KEY=\"123abc_my_api_key_goes_here\"\ndata = {\n    \"sort\": \"CREATED_DESC\",\n    \"limit\": 5,\n    \"artifacts\": {\n        \"key\": {\n            \"exists_\": True\n        }\n    }\n}\n\nheaders = {\"Authorization\": f\"Bearer {PREFECT_API_KEY}\"}\nendpoint = f\"{PREFECT_API_URL}/artifacts/filter\"\n\nresponse = requests.post(endpoint, headers=headers, json=data)\nassert response.status_code == 200\nfor artifact in response.json():\n    print(artifact)\n```\n\n----------------------------------------\n\nTITLE: Create Prefect Profile\nDESCRIPTION: This command creates a new Prefect profile with the given name. Optionally, it can copy settings from an existing profile.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles create [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Forcing Cache Refresh for a Prefect Task\nDESCRIPTION: This snippet demonstrates how to force a Prefect task to ignore the existing cache and always update it. It uses a static cache key function and sets the refresh_cache option to True.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\n\ndef static_cache_key(context, parameters):\n    # return a constant\n    return \"static cache key\"\n\n\n@task(cache_key_fn=static_cache_key, refresh_cache=True)\ndef caching_task():\n    return random.random()\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Deployments\nDESCRIPTION: OpenAPI specification that defines the POST endpoint path for creating deployments at /api/deployments/\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/create-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/\n```\n\n----------------------------------------\n\nTITLE: Creating Coiled Push Work Pool with Infrastructure Provisioning\nDESCRIPTION: This command creates a new push work pool for Coiled with automatic infrastructure provisioning. It sets up a CoiledCredentials block in the Prefect Cloud workspace.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type coiled:push --provision-infra my-coiled-pool\n```\n\n----------------------------------------\n\nTITLE: Enabling Rich Markup in Prefect Logs\nDESCRIPTION: Shows how to enable Rich's markup syntax in Prefect logs by setting the PREFECT_LOGGING_MARKUP environment variable to True.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_LOGGING_MARKUP=True\n```\n\n----------------------------------------\n\nTITLE: Execute Flow Run\nDESCRIPTION: Command to execute a flow run. Takes an optional flow run ID as argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs execute [OPTIONS] [ID]\n```\n\n----------------------------------------\n\nTITLE: Interval Schedule Configuration in YAML\nDESCRIPTION: Defines an interval schedule with a 600-second interval and timezone configuration\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nschedule:\n  interval: 600\n  timezone: America/Chicago\n```\n\n----------------------------------------\n\nTITLE: Example Bash command to trigger flow\nDESCRIPTION: This is an example of running the `inspiring_joke` flow from the command line. This will execute the flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nawait inspiring_joke()\n> \"a raft of ducks walk into a bar...\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment for Push Work Pool in YAML\nDESCRIPTION: This YAML snippet shows how to configure a deployment to use a specific push work pool. It's part of a prefect.yaml file used for deploying flows to Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\n  work_pool:\n    name: my-push-pool\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-dask Package\nDESCRIPTION: Commands for installing prefect-dask using pip or uv package managers. Includes options for fresh installation and upgrading existing installations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[dask]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install \"prefect[dask]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[dask]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install -U \"prefect[dask]\"\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Event Command\nDESCRIPTION: The base command for interacting with Prefect events, serving as an entry point for event-related subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/event.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect event [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Getting Default Base Job Template Using CLI\nDESCRIPTION: Command to retrieve the default base job template for a process work pool type using the Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool get-default-base-job-template --type process\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Flow Run Creation Endpoint Definition\nDESCRIPTION: YAML specification for the POST /api/flow_runs/ API endpoint that handles flow run creation requests.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/create-flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/flow_runs/\n```\n\n----------------------------------------\n\nTITLE: List Prefect Flows Command\nDESCRIPTION: Command to view and list existing Prefect flows. Includes an optional limit parameter to restrict the number of results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flows.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect flows ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Filter Query Body Structure for Prefect API\nDESCRIPTION: This JSON example demonstrates the structure of a filter request body for the Prefect API. It shows how to structure nested objects and use filter operators in a query request.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"objects\": {\n        \"object_field\": {\n            \"field_operator_\": <field_value>\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ECS Work Pool using Prefect CLI\nDESCRIPTION: This Prefect CLI command creates a new work pool of type 'ecs' named 'my-ecs-pool'. This work pool will be used by the ECS worker to pull work from.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type ecs my-ecs-pool\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Path Definition - POST /api/deployments/filter\nDESCRIPTION: YAML definition specifying the OpenAPI path for filtering deployments endpoint\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/read-deployments.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/filter\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Server with Basic Authentication\nDESCRIPTION: YAML configuration for enabling basic authentication in the Prefect server deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nserver:\n  basicAuth:\n    enabled: true\n    existingSecret: server-auth-secret\n```\n\n----------------------------------------\n\nTITLE: Configuring Pull Settings in prefect.yaml\nDESCRIPTION: This snippet updates the Pull section in the Prefect YAML file to use GitHub credentials for cloning the repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.git_clone:\n    id: clone-step\n    repository: https://github.com/Ben-Epstein/prefect-modal\n    branch: main\n    credentials: '{{ prefect.blocks.github-credentials.prefect-modal }}'\n```\n\n----------------------------------------\n\nTITLE: Inspect Flow Run\nDESCRIPTION: Command to view detailed information about a specific flow run. Requires a flow run ID as argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs inspect [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Retrieving Flow Run Logs via CLI\nDESCRIPTION: Shows how to use the Prefect command-line interface to retrieve logs for a specific flow run. The second example demonstrates saving the logs to a local file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nprefect flow-run logs MY-FLOW-RUN-ID\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Definition for Concurrency Limits\nDESCRIPTION: YAML specification defining the API endpoint for managing concurrency limits in Prefect\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/create-concurrency-limit-v2.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/v2/concurrency_limits/\n```\n\n----------------------------------------\n\nTITLE: Filtering Flows with Tags and Failed Flow Runs\nDESCRIPTION: This JSON example shows how to filter flows with specific tags and state conditions. It demonstrates a complex filter query body that combines multiple filter criteria using the Prefect REST API's filter endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"flows\": {\n        \"tags\": {\n            \"all_\": [\"database\"]\n        }\n    },\n    \"flow_runs\": {\n        \"state\": {\n            \"type\": {\n              \"any_\": [\"FAILED\"]\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Reference Bitbucket Credentials in prefect.yaml\nDESCRIPTION: This YAML snippet demonstrates how to reference a Bitbucket Credentials block within a prefect.yaml file, specifically within the 'pull' step of a deployment. This allows authentication when cloning a private repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n    - prefect.deployments.steps.git_clone:\n        credentials: https://bitbucket.org/org/private-repo.git\n        credentials: \"{{ prefect.blocks.bitbucket-credentials.my-bitbucket-credentials-block }}\"\n```\n\n----------------------------------------\n\nTITLE: Prefect Event Stream Command\nDESCRIPTION: Command to subscribe to and stream events from a Prefect workspace. Events can be output as JSON or text format and optionally written to a file. Supports account-wide event streaming and single-event retrieval.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/event.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect event stream [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Sending POST Request with Model Data in Bash\nDESCRIPTION: This Bash script sends a POST request to a specified API endpoint with URL-encoded form data. It includes the model ID and a friendly name as form fields which the webhook will use to process different model updates.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl \\\n    -d \"model=recommendations\" \\\n    -d \"friendly_name=Recommendations%20[Products]\" \\\n    -X POST https://api.prefect.cloud/hooks/AERylZ_uewzpDx-8fcweHQ\n```\n\n----------------------------------------\n\nTITLE: List Block Types Command\nDESCRIPTION: Command to list all available block types\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect block types ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Image Build with Git SHA in YAML\nDESCRIPTION: This YAML snippet demonstrates how to use shell scripts to get the Git commit hash and use it to tag a Docker image during the build process. It also shows how to set common tags and work pool configurations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\nbuild:\n- prefect.deployments.steps.run_shell_script:\n    id: get-commit-hash\n    script: git rev-parse --short HEAD\n    stream_output: false\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build-image\n    requires: prefect-docker>=0.4.0\n    image_name: \"{{ $PREFECT_IMAGE_NAME }}\"\n    tag: \"{{ get-commit-hash.stdout }}\"\n    dockerfile: auto\n    platform: \"linux/amd64\"\n\ndefinitions:\n  tags: &common_tags\n    - \"eks\"\n    - \"{{ get-commit-hash.stdout }}\"\n  work_pool: &common_work_pool\n    name: \"kubernetes\"\n    job_variables:\n      image: \"{{ build-image.image }}\"\n```\n\n----------------------------------------\n\nTITLE: Creating GCP Push Work Pool with Infrastructure Provisioning\nDESCRIPTION: This command creates a new push work pool for Google Cloud Platform (GCP) with automatic infrastructure provisioning. It sets up necessary GCP resources and configures Prefect workspace.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type cloud-run:push --provision-infra my-cloud-run-pool\n```\n\n----------------------------------------\n\nTITLE: Using the prefect work-pool command\nDESCRIPTION: The main command for managing Prefect work pools. It provides access to various subcommands for work pool operations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Flow Run Cancellation Command\nDESCRIPTION: Command to cancel a specific flow run by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run cancel [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Log Handler in YAML\nDESCRIPTION: Shows the YAML configuration needed to use a custom console handler for Prefect logging. This example sets up styling for email highlighting using the custom handler defined in the previous snippet.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n    console_flow_runs:\n        level: 0\n        class: my_package_or_module.CustomConsoleHandler\n        formatter: flow_runs\n        styles:\n            log.email: magenta\n            # other styles can be appended here, e.g.\n            # log.completed_state: green\n```\n\n----------------------------------------\n\nTITLE: Creating Managed Work Pool\nDESCRIPTION: Command to create a new Prefect managed work pool for serverless execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create managed-pool --type prefect:managed\n```\n\n----------------------------------------\n\nTITLE: Updating Prefect Deployment Configuration for Hardware\nDESCRIPTION: Adds CPU and memory job variables to a Prefect deployment call for configuring cloud resources. Requires Prefect CLI access.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmy_flow.deploy(\n    ...,\n    job_variables={\"cpu\": 16, \"memory\": \"32GB\"}\n)\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification - POST Deployment Flow Run Creation Endpoint\nDESCRIPTION: YAML specification defining the API endpoint for creating a new flow run from an existing deployment. Defines the route /api/deployments/{id}/create_flow_run as a POST endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/create-flow-run-from-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/create_flow_run\n```\n\n----------------------------------------\n\nTITLE: Executing Prefect Version Command\nDESCRIPTION: This snippet shows the command to retrieve the current Prefect version along with integration information. The command accepts various options to customize the output, such as omitting integration details.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/version.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect version [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Create Schedule\nDESCRIPTION: Command to create a new schedule for a deployment, supporting interval, cron, and rrule scheduling options.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule create [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Listing Prefect work pools\nDESCRIPTION: Lists all available work pools in the Prefect environment. Can show additional information when the verbose flag is used.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Updating a Prefect work pool\nDESCRIPTION: Updates the configuration of an existing work pool, including options to modify the base job template, concurrency limit, and description.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool update [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Starting Production Worker\nDESCRIPTION: Switch to the production workspace and start a worker for the production work pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Switch to the production workspace\nprefect cloud workspace set --workspace \"<account handle>/production\"\n\n# Start a worker for the production work pool\nprefect worker start --pool default-work-pool\n```\n\n----------------------------------------\n\nTITLE: Task Run Dashboard Counts API Endpoint\nDESCRIPTION: Defines an API endpoint for retrieving aggregated task run counts used in dashboard visualization and reporting\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/task-runs/read-dashboard-task-run-counts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nopenapi: post /api/ui/task_runs/dashboard/counts\n```\n\n----------------------------------------\n\nTITLE: Defining ECS Task Definition for Prefect Worker in JSON\nDESCRIPTION: JSON configuration for an ECS task definition specifying the Docker image, resources, and command for the Prefect worker. It includes environment variables for the Prefect API URL and key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"family\": \"prefect-worker-task\",\n    \"networkMode\": \"awsvpc\",\n    \"requiresCompatibilities\": [\n        \"FARGATE\"\n    ],\n    \"cpu\": \"512\",\n    \"memory\": \"1024\",\n    \"executionRoleArn\": \"<ecs-task-role-arn>\",\n    \"taskRoleArn\": \"<ecs-task-role-arn>\",\n    \"containerDefinitions\": [\n        {\n            \"name\": \"prefect-worker\",\n            \"image\": \"prefecthq/prefect:3-latest\",\n            \"cpu\": 512,\n            \"memory\": 1024,\n            \"essential\": true,\n            \"command\": [\n                \"/bin/sh\",\n                \"-c\",\n                \"pip install prefect-aws && prefect worker start --pool my-ecs-pool --type ecs\"\n            ],\n            \"environment\": [\n                {\n                    \"name\": \"PREFECT_API_URL\",\n                    \"value\": \"prefect-api-url>\"\n                },\n                {\n                    \"name\": \"PREFECT_API_KEY\",\n                    \"value\": \"<prefect-api-key>\"\n                }\n            ]\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GitLab Repository in prefect.yaml\nDESCRIPTION: This YAML snippet shows the beginning of how to configure a GitLab repository in the prefect.yaml configuration file. It only includes the initial structure as the example was incomplete in the original content.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\n# relevant section of the file:\npull:\n    - prefect.deployments.steps.git_clone:\n```\n\n----------------------------------------\n\nTITLE: Manage Deployment Schedules\nDESCRIPTION: Base command for managing deployment schedules with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Inspect Global Concurrency Limit\nDESCRIPTION: Command to inspect details of a specific global concurrency limit, with options for output format and file export.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit inspect [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect with pyproject.toml\nDESCRIPTION: Example of setting Prefect configuration in a pyproject.toml file under the [tool.prefect] table. This allows consolidating all project configuration in a single file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[tool.prefect]\nlogging.level = \"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Running the Repository Analysis Script\nDESCRIPTION: Command to execute the repository analysis script and example output showing the analysis results for multiple repositories.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython repo_analysis.py\n```\n\nLANGUAGE: bash\nCODE:\n```\n10:59:13.933 | INFO    | prefect.engine - Created flow run 'robust-kangaroo' for flow 'analyze-repo-health'\n10:59:13.934 | INFO    | prefect.engine - View at http://127.0.0.1:4200/runs/flow-run/abdf7f46-6d59-4857-99cd-9e265cadc4a7\n10:59:13.954 | INFO    | Flow run 'robust-kangaroo' - Analyzing PrefectHQ/prefect...\n...\n10:59:27.631 | INFO    | Flow run 'robust-kangaroo' - Average response time: 0.4 hours\n10:59:27.631 | INFO    | Flow run 'robust-kangaroo' - Resolution rate: 40.0%\n10:59:27.632 | INFO    | Flow run 'robust-kangaroo' - Analyzing pydantic/pydantic...\n...\n10:59:40.990 | INFO    | Flow run 'robust-kangaroo' - Average response time: 0.0 hours\n10:59:40.991 | INFO    | Flow run 'robust-kangaroo' - Resolution rate: 0.0%\n10:59:40.991 | INFO    | Flow run 'robust-kangaroo' - Analyzing huggingface/transformers...\n...\n10:59:54.225 | INFO    | Flow run 'robust-kangaroo' - Average response time: 1.1 hours\n10:59:54.225 | INFO    | Flow run 'robust-kangaroo' - Resolution rate: 0.0%\n10:59:54.240 | INFO    | Flow run 'robust-kangaroo' - Finished in state Completed()\n```\n\n----------------------------------------\n\nTITLE: GitHub Credentials in YAML Configuration\nDESCRIPTION: YAML configuration example showing how to reference GitHub credentials in a deployment pull step\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n    - prefect.deployments.steps.git_clone:\n        repository: https://github.com/org/repo.git\n        credentials: \"{{ prefect.blocks.github-credentials.my-github-credentials-block }}\"\n```\n\n----------------------------------------\n\nTITLE: Setting Prefect API URL for Self-Hosted Server\nDESCRIPTION: This snippet allows users to configure the Prefect API URL to connect to a self-hosted Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_URL=http://your-prefect-server-IP:4200\n```\n\n----------------------------------------\n\nTITLE: Creating a Deployment from a Public Bitbucket Repository\nDESCRIPTION: This snippet demonstrates how to create a Prefect deployment from a public Bitbucket repository by specifying the repository URL directly. It uses the flow.from_source() method to define the source repository and entrypoint file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://bitbucket.com/org/my-public-repo.git\",\n        entrypoint=\"bb_public_repo.py:my_flow\",\n    ).deploy(\n        name=\"my-bitbucket-deployment\",\n        work_pool_name=\"my_pool\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow from Azure Blob Storage with Storage Block\nDESCRIPTION: This code deploys a Prefect flow from Azure Blob Storage using an AzureBlobStorage block. It demonstrates how to load an existing block or create a new one with credentials from an AzureBlobCredentials block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/store-flow-code.mdx#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_azure import AzureBlobCredentials, AzureBlobStorage\n\n\nif __name__ == \"__main__\":\n\n    azure_blob_storage_block = AzureBlobStorage.load(\"my-code-storage-block\")\n\n    # or \n    # azure_blob_storage_block = AzureBlobStorage(   \n    #     container=\"my-prefect-azure-container\",\n    #     folder=\"my-folder\",\n    #     credentials=AzureBlobCredentials.load(\"my-credentials-block\")\n    # )\n\n    flow.from_source(source=azure_blob_storage_block, entrypoint=\"my_file.py:my_flow\").deploy(\n        name=\"my-azure-deployment\", work_pool_name=\"my-work-pool\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Prefect Logging Level in Bash\nDESCRIPTION: These commands demonstrate how to set the Prefect logging level to DEBUG using either the CLI or environment variables. This is useful for obtaining more detailed logs during troubleshooting.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Using the CLI\nprefect config set PREFECT_LOGGING_LEVEL=DEBUG\n\n# Using environment variables\nexport PREFECT_LOGGING_LEVEL=DEBUG\n```\n\n----------------------------------------\n\nTITLE: Prefect Event Trigger Schema\nDESCRIPTION: This section defines the schema for an event trigger in Prefect, outlining the properties used to configure the trigger's behavior. The schema includes properties for matching resources, defining the posture (reactive or proactive), specifying expected events, and setting thresholds and time windows for event evaluation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Flow Run Listing Command\nDESCRIPTION: Command to list recent flow runs or flow runs for specific flows with options for filtering by state and state type.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Deploy Fixed Code to Staging Workspace\nDESCRIPTION: Bash commands to set the active Prefect Cloud workspace to staging and run the fixed script with the fail-at-run parameter to verify the fix.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/debug.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud workspace set --workspace \"<account handle>/staging\"\npython simulate_failures.py --fail-at-run 3\n```\n\n----------------------------------------\n\nTITLE: Creating Managed Work Pool in Bash\nDESCRIPTION: Command to create a managed work pool for Prefect Cloud deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/schedule.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create my-work-pool --type prefect:managed\n```\n\n----------------------------------------\n\nTITLE: Displaying Prefect Cloud Workspaces in Shell\nDESCRIPTION: This snippet shows the output of the 'prefect cloud workspace ls' command, displaying available workspaces and highlighting the active workspace.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n┏━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃   Available Workspaces: ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│   g-gadflow/g-workspace │\n│    * prefect/workinonit │\n━━━━━━━━━━━━━━━━━━━━━━━━━━━\n    * active workspace\n```\n\n----------------------------------------\n\nTITLE: Resume Prefect Automation\nDESCRIPTION: Command to resume a paused automation specified by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect automations resume [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Visualizing State Transitions with Mermaid Diagram\nDESCRIPTION: A Mermaid flowchart diagram visualizing the possible state transitions in Prefect, showing how states flow from Scheduled through various intermediate states to terminal states like Completed, Failed, Crashed, or Cancelled.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\n%%{\n  init: {\n    'theme': 'neutral',\n    'flowchart': {\n      'curve' : 'linear',\n      'rankSpacing': 80,\n      'nodeSpacing': 70,\n      'width': 5\n    }\n  }\n}%%\n\nflowchart TD\n    %% Style definitions\n    classDef scheduled fill:#fcd14edb,stroke:#fcd14edb\n    classDef pending fill:#A99FADdb,stroke:#A99FAD\n    classDef running fill:#1860f2db,stroke:#1860f2db\n    classDef paused fill:#a99faddb,stroke:#a99faddb\n    classDef completed fill:#2ac769db,stroke:#2ac769db,stroke-width:2px\n    classDef failed fill:#fb4e4ef5,stroke:#fb4e4ef5,stroke-width:2px\n    classDef crashed fill:#f97316db,stroke:#f97316db,stroke-width:2px\n    classDef cancelled fill:#3d3d3da8,stroke:#3d3d3da8,stroke-width:2px\n    classDef awaiting_concurrency_slot fill:#ede7f6,stroke:#4527a0,stroke-width:2px\n\n    %% States\n    subgraph scheduled_type[Scheduled]\n    Scheduled[Scheduled]:::scheduled\n    Late[Late]:::scheduled\n    AwaitingConcurrencySlot[AwaitingConcurrencySlot]:::scheduled\n    end\n\n    Running[Running]:::running\n\n    Failed[Failed]:::failed\n\n    subgraph scheduled_type2[Scheduled]\n    AwaitingRetry[Awaiting Retry]:::scheduled\n    end\n\n    subgraph running_type[Running]\n    Retrying[Retrying]:::running\n    end\n\n    Pending[Pending]:::pending\n\n\n\n    Cancelling[Cancelling]:::cancelled\n    Cancelled[Cancelled]:::cancelled\n    \n    Cached[Cached]:::completed\n    RolledBack[Rolled Back]:::completed\n    Crashed[Crashed]:::crashed\n\n    Paused[Paused]:::paused\n\n    Completed[Completed]:::completed\n\n    %% Connections\n    Scheduled --> |Scheduled start time passes without entering Pending| Late\n    Scheduled --> |Worker/Runner successfully submits run| Pending\n    Scheduled --> |Worker encounters concurrency limit| AwaitingConcurrencySlot\n\n    AwaitingConcurrencySlot --> Pending\n    \n    Late -->  Pending\n\n    Pending --> |Preconditions met| Running    \n\n\n    Running -.-> |Success| Completed\n\n    %%problematic section:\n    Retrying -.-> |Success| Completed\n    Failed --> |Retries remaining| AwaitingRetry\n    AwaitingRetry --> |Retry attempt| Retrying\n    Retrying -.-> |Failure| Failed\n    \n    \n\n    Running -.-> |Error| Failed\n\n    Running -.-> |Infrastructure issue| Crashed\n    Running -.-> |Cache hit| Cached\n    Running -.-> |Transaction rollback| RolledBack\n    Running --> |User cancels| Cancelling\n\n    Running --> |Manual pause| Paused\n    Paused --> |Resume| Running\n    \n    Cancelling -.-> |Cleanup complete| Cancelled\n\n\n\n\n```\n\n----------------------------------------\n\nTITLE: Using Existing Environment Variables in YAML\nDESCRIPTION: This YAML snippet demonstrates how to use existing environment variables set in the local environment as templates in the deployment configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n- name: demo-deployment\n  entrypoint: demo_project/demo_flow.py:some_work\n  work_pool:\n    name: local\n    job_variables:\n        env:\n            EXECUTION_ENVIRONMENT: \"{{ $EXECUTION_ENVIRONMENT }}\"\n            MY_NOT_SO_SECRET_CONFIG: \"{{ $MY_NOT_SO_SECRET_CONFIG }}\"\n  schedule: null\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow using CLI\nDESCRIPTION: Command-line instruction to deploy the Prefect flow to the Prefect Cloud or a self-managed server instance. This command uses the configuration specified in the prefect.yaml file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy my_flow.py:my_ecs_deployment\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Deleting Automations by Resource Owner\nDESCRIPTION: Defines the OpenAPI specification for the DELETE endpoint that removes automations associated with a specific resource owner ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/delete-automations-owned-by-resource.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/automations/owned-by/{resource_id}\n```\n\n----------------------------------------\n\nTITLE: Creating a Kubernetes Work Pool\nDESCRIPTION: Command to create a Kubernetes-type work pool for container-based execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create k8s-pool --type kubernetes\n```\n\n----------------------------------------\n\nTITLE: Create Artifact Registry on GCP\nDESCRIPTION: This snippet creates an Artifact Registry repository and configures Docker authentication using the gcloud CLI.  Replace `<REPOSITORY-NAME>` with the desired repository name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Create artifact registry repository to host your custom image\n# Replace the repository name with your own value; it can be the\n# same name as your image\ngcloud artifacts repositories create <REPOSITORY-NAME> \\\n--repository-format=docker --location=us\n\n# Authenticate to artifact registry\ngcloud auth configure-docker us-docker.pkg.dev\n```\n\n----------------------------------------\n\nTITLE: Configuring Helm Chart Values\nDESCRIPTION: YAML configuration for customizing the Prefect worker deployment with account, workspace, and work pool settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nworker:\n  cloudApiConfig:\n    accountId: <target account ID>\n    workspaceId: <target workspace ID>\n  config:\n    workPool: <target work pool name>\n```\n\n----------------------------------------\n\nTITLE: List Global Concurrency Limits\nDESCRIPTION: Command to list all existing global concurrency limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Modal from Command Line\nDESCRIPTION: Initializes Modal authentication to establish a connection between your local environment and Modal services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nuv run modal setup\n```\n\n----------------------------------------\n\nTITLE: Starting Staging Worker\nDESCRIPTION: Switch to the staging workspace and start a worker for the staging work pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Switch to the staging workspace\nprefect cloud workspace set --workspace \"<account handle>/staging\"\n\n# Start a worker for the staging work pool\nprefect worker start --pool default-work-pool\n```\n\n----------------------------------------\n\nTITLE: Defining POST Endpoint for Incrementing Concurrency Limits in OpenAPI\nDESCRIPTION: OpenAPI specification for a POST endpoint to increment concurrency limits. The endpoint is defined as '/api/concurrency_limits/increment' using the YAML format.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/increment-concurrency-limits-v1.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/concurrency_limits/increment\n```\n\n----------------------------------------\n\nTITLE: Block Type Version Listing\nDESCRIPTION: Script that generates a table displaying all block types in a workspace along with their versions, creation dates, and checksums for auditing purposes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/scripts.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Reference to list_block_type_versions.py\n```\n\n----------------------------------------\n\nTITLE: Building Prefect API Documentation\nDESCRIPTION: Command to build REST API reference documentation for static display. Takes an optional schema path parameter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect dev build-docs [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring BigQuery Warehouse\nDESCRIPTION: Setup for BigQuery integration with Prefect using GCP credentials.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gcp.bigquery import GcpCredentials, BigQueryWarehouse\n\ngcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\nbigquery_block = BigQueryWarehouse(\n    gcp_credentials = gcp_credentials,\n    fetch_size = 1  # Optional: specify a default number of rows to fetch when calling fetch_many\n)\nbigquery_block.save(\"BIGQUERY-BLOCK-NAME\")\n```\n\n----------------------------------------\n\nTITLE: Invoke Webhook through curl\nDESCRIPTION: This bash command illustrates how to invoke a Prefect webhook using curl. It sends a simple GET request to the webhook URL, notifying Prefect of the event specified in the webhook template. It requires the curl command-line tool and correct webhook endpoint configuration. No HTTP request body is necessary, enabling integration with systems limited to basic HTTP methods.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://api.prefect.cloud/hooks/AERylZ_uewzpDx-8fcweHQ\n```\n\n----------------------------------------\n\nTITLE: Loading Snowflake Connector Block\nDESCRIPTION: Simple example of loading a saved SnowflakeConnector block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_snowflake import SnowflakeCredentials, SnowflakeConnector\n\nSnowflakeConnector.load(\"CONNECTOR-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Viewing Prefect Configuration in Bash\nDESCRIPTION: This command displays the current Prefect configuration, including the active profile, API key, and API URL. It's useful for verifying the correct setup for Prefect Cloud access.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ prefect config view\n```\n\n----------------------------------------\n\nTITLE: Accessing Data Within Transactions in Python\nDESCRIPTION: Demonstrates how to set and access key-value pairs within a transaction, including usage in rollback hooks. Shows file operations with transaction-scoped data access.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/transactions.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom time import sleep\n\nfrom prefect import task, flow\nfrom prefect.transactions import transaction\n\n\n@task\ndef write_file(filename: str, contents: str):\n    \"Writes to a file.\"\n    with open(filename, \"w\") as f:\n        f.write(contents)\n\n\n@write_file.on_rollback\ndef del_file(txn):\n    \"Deletes file.\"\n    os.unlink(txn.get(\"filename\"))\n\n\n@task\ndef quality_test(filename):\n    \"Checks contents of file.\"\n    with open(filename, \"r\") as f:\n        data = f.readlines()\n\n    if len(data) < 2:\n        raise ValueError(f\"Not enough data!\")\n\n\n@flow\ndef pipeline(filename: str, contents: str):\n    with transaction() as txn:\n        txn.set(\"filename\", filename)\n        write_file(filename, contents)\n        sleep(2)  # sleeping to give you a chance to see the file\n        quality_test(filename)\n\n\nif __name__ == \"__main__\":\n    pipeline(\n        filename=\"side-effect.txt\",\n        contents=\"hello world\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Docker Image Name for Different Cloud Platforms\nDESCRIPTION: These bash commands show how to set the PREFECT_IMAGE_NAME environment variable for different cloud platforms (AWS, GCP, Azure). This variable is used in the Prefect YAML configuration for specifying the Docker image registry.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nexport PREFECT_IMAGE_NAME=<AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/<IMAGE-NAME>\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport PREFECT_IMAGE_NAME=us-docker.pkg.dev/<GCP-PROJECT-NAME>/<REPOSITORY-NAME>/<IMAGE-NAME>\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport PREFECT_IMAGE_NAME=<REPOSITORY-NAME>.azurecr.io/<IMAGE-NAME>\n```\n\n----------------------------------------\n\nTITLE: List Schedules\nDESCRIPTION: Command to view all schedules associated with a specific deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_10\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule ls [OPTIONS] DEPLOYMENT_NAME\n```\n\n----------------------------------------\n\nTITLE: Register Blocks from a Module (CLI)\nDESCRIPTION: This command shows how to register all blocks found within a Python module using the Prefect CLI. This is useful for registering blocks from Prefect Integration libraries.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register --module prefect_aws.credentials\n```\n\n----------------------------------------\n\nTITLE: Getting the default base job template for a Prefect work pool type\nDESCRIPTION: Retrieves the default base job template for a specified work pool type, with an option to write the output to a file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_12\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool get-default-base-job-template [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Verifying Prefect Installation with Version Command\nDESCRIPTION: Command to check if Prefect was installed successfully by displaying the version information.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect version\n```\n\n----------------------------------------\n\nTITLE: Clear Schedules\nDESCRIPTION: Command to remove all schedules from a deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_11\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule clear [OPTIONS] DEPLOYMENT_NAME\n```\n\n----------------------------------------\n\nTITLE: Starting FastAPI Server with Uvicorn in Docker\nDESCRIPTION: This command is used in a Dockerfile to start the FastAPI server using Uvicorn. It specifies the host, port, and the application module to run.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/static-infrastructure-examples/background-tasks.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nCMD [\"uvicorn\", \"src.foo.api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n----------------------------------------\n\nTITLE: Creating a Systemd Service for Prefect Serve\nDESCRIPTION: This snippet shows how to create a systemd service unit file for a Prefect `.serve` process that will restart automatically.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n[Unit]\nDescription=Prefect serve\n\n[Service]\nUser=prefect\nWorkingDirectory=/home\nExecStart=python3 my_file.py\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow Using Deployment.build_from_flow (Old Method)\nDESCRIPTION: Example of the legacy method for creating a flow deployment using Deployment.build_from_flow in Prefect 2.0. This shows the pattern that users would be migrating from.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a Python script!\")\n\n\nif __name__ == \"__main__\":\n    Deployment.build_from_flow(\n        my_flow,\n        name=\"my-deployment\",\n        parameters=dict(name=\"Marvin\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for POST /api/concurrency_limits/decrement\nDESCRIPTION: YAML specification defining the API endpoint for decrementing concurrency limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/decrement-concurrency-limits-v1.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/concurrency_limits/decrement\n```\n\n----------------------------------------\n\nTITLE: Retrieving Variable by ID in Prefect API\nDESCRIPTION: Endpoint for fetching a specific variable using its unique identifier. Allows retrieval of variable details through a REST API call.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/variables/read-variable.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\nget /api/variables/{id}\n```\n\n----------------------------------------\n\nTITLE: Delete Block Type Command\nDESCRIPTION: Command to delete an unprotected block type\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect block types delete [OPTIONS] SLUG\n```\n\n----------------------------------------\n\nTITLE: Disable Global Concurrency Limit\nDESCRIPTION: Command to deactivate a specific global concurrency limit.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit disable [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Pausing a Work Pool Using Prefect CLI\nDESCRIPTION: The command to pause a work pool, which stops the delivery of work to workers while keeping deployment schedules active.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool pause 'test-pool'\n```\n\n----------------------------------------\n\nTITLE: Starting a Worker in the Created Work Pool\nDESCRIPTION: This command starts a worker in the previously created 'my-work-pool' work pool using the Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool my-work-pool\n```\n\n----------------------------------------\n\nTITLE: Testing Nested API Endpoints with Different Slash Requirements\nDESCRIPTION: Example demonstrating how nested URL endpoints may have the opposite behavior, requiring no trailing slash for proper operation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nasync def test_nested_example(client):\n    response = await client.post(\"/my_route/filter/\")\n    assert response.status_code == 307\n\n    response = await client.post(\"/my_route/filter\")\n    assert response.status_code == 200\n```\n\n----------------------------------------\n\nTITLE: Saving Flow Run Logs to a File\nDESCRIPTION: Demonstrates how to retrieve logs for a specific flow run and redirect them to a local file using standard shell redirection.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nprefect flow-run logs  MY-FLOW-RUN-ID > flow.log\n```\n\n----------------------------------------\n\nTITLE: Serving a Remote Flow from GitHub Storage\nDESCRIPTION: This snippet demonstrates how to serve a Prefect flow from a remote source, specifically a GitHub repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/org/repo.git\",\n        entrypoint=\"path/to/my_remote_flow_code_file.py:say_hi\",\n    ).serve(name=\"deployment-with-github-storage\")\n```\n\n----------------------------------------\n\nTITLE: Customizing Prefect Flow Options\nDESCRIPTION: Python code example showing how to use the with_options method to customize options on an existing Prefect flow, such as changing the name, retries, and retry delay.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncustom_blob_storage_download_flow = example_blob_storage_download_flow.with_options(\n    name=\"My custom task name\",\n    retries=2,\n    retry_delay_seconds=10,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring DBT Cloud Credentials\nDESCRIPTION: Python script to create and save DBT Cloud credentials as a Prefect block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_dbt.cloud import DbtCloudCredentials\n\nDbtCloudCredentials(\n    api_key=\"API-KEY-PLACEHOLDER\",\n    account_id=\"ACCOUNT-ID-PLACEHOLDER\"\n).save(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: List Concurrency Limits\nDESCRIPTION: Displays all configured concurrency limits with optional pagination using limit and offset parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Create Modal API token\nDESCRIPTION: This command generates a Modal API token, which is necessary for authenticating and authorizing Prefect to run flows on the Modal platform.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"modal token new\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect API URL for Self-Hosted Server\nDESCRIPTION: Command to set the API URL to point to a self-hosted Prefect server instance. This configuration can be saved in a Prefect profile for persistent use.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/cli.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_URL=\"http://127.0.0.1:4200/api\"\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI GET Endpoint for Task Run States\nDESCRIPTION: OpenAPI specification defining the GET endpoint path for retrieving task run states by ID. The endpoint follows the pattern /api/task_run_states/{id} where {id} is the task run state identifier.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/task-run-states/read-task-run-state.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/task_run_states/{id}\n```\n\n----------------------------------------\n\nTITLE: Resolving Dask Futures with Result Method\nDESCRIPTION: Example demonstrating an alternative approach to resolve Dask futures when using the Dask client in Prefect. This method uses the result() function to ensure futures are resolved before exiting the context manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dask/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith get_dask_client() as client:\n    df = dask.datasets.timeseries(\"2000\", \"2001\", partition_freq=\"4w\")\n    summary_df = client.compute(df.describe()).result()\n```\n\n----------------------------------------\n\nTITLE: Creating DBT Core Operation Block\nDESCRIPTION: Shows how to create and save a DbtCoreOperation block for execution\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\n\ndbt_cli_profile = DbtCliProfile.load(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\ndbt_core_operation = DbtCoreOperation(\n    commands=[\"DBT-CLI-COMMANDS-PLACEHOLDER\"],\n    dbt_cli_profile=dbt_cli_profile,\n    overwrite_profiles=True,\n)\ndbt_core_operation.save(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Disable Prefect Automation\nDESCRIPTION: Command to disable an enabled automation specified by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect automations disable [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Inspect Block Command\nDESCRIPTION: Command to display details about a configured block using either a slug or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks inspect [OPTIONS] [SLUG]\n```\n\n----------------------------------------\n\nTITLE: Provisioning Infrastructure for Existing Push Work Pool\nDESCRIPTION: This command provisions infrastructure for an existing push work pool. It creates necessary resources and configures the Prefect workspace accordingly.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool provision-infra my-work-pool\n```\n\n----------------------------------------\n\nTITLE: Customizing Prefect Flows with with_options\nDESCRIPTION: Example demonstrating how to customize an existing flow with options like name, retries, and retry delay using the with_options method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncustom_blob_storage_download_flow = example_blob_storage_download_flow.with_options(\n    name=\"My custom task name\",\n    retries=2,\n    retry_delay_seconds=10,\n)\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prefect Docker Package\nDESCRIPTION: Command to upgrade both Prefect and prefect-docker packages to their latest versions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-docker/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[docker]\"\n```\n\n----------------------------------------\n\nTITLE: Executing Prefect Development Commands\nDESCRIPTION: Base command for accessing Prefect's internal development tools. Requires additional dependencies like npm and MkDocs for certain functionalities.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect dev [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Inspect Concurrency Limit\nDESCRIPTION: Displays detailed information about a specific concurrency limit, including active slots showing TaskRun IDs currently using concurrency slots.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits inspect [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Docker Compose Resources\nDESCRIPTION: These bash commands stop and remove the Docker Compose services. The second command also removes the named volumes used for data persistence.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/static-infrastructure-examples/background-tasks.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down\n\n# also remove the named volumes\ndocker compose down -v\n```\n\n----------------------------------------\n\nTITLE: Caching Python Dependencies with setup-python Action in YAML\nDESCRIPTION: This snippet demonstrates how to use the setup-python action with caching enabled for pip packages. It specifies Python version 3.12 and enables caching for pip to avoid repeated downloads.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Setup Python\n  uses: actions/setup-python@v5\n  with:\n    python-version: \"3.12\"\n    cache: \"pip\"\n```\n\n----------------------------------------\n\nTITLE: Creating an Azure Container Instances Push Work Pool with Automatic Infrastructure Provisioning\nDESCRIPTION: Command to create a new Azure Container Instances push work pool with automatic infrastructure setup. This provisions a resource group, app registration, service account, and Azure Container Registry.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type azure-container-instance:push --provision-infra my-aci-pool\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Definition - Get Scheduled Flow Runs\nDESCRIPTION: OpenAPI specification defining the endpoint path for retrieving scheduled flow runs from Prefect deployments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/get-scheduled-flow-runs-for-deployments.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/get_scheduled_flow_runs\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Artifact Command\nDESCRIPTION: The base command for accessing Prefect's artifact management functionality.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/artifact.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect artifact [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Renaming a Prefect Profile\nDESCRIPTION: This command renames an existing Prefect profile. It requires both the current name and the new name for the profile.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile rename [OPTIONS] NAME NEW_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Process Work Pool via CLI\nDESCRIPTION: Command to create a new process-type work pool for distributed task execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create prod-work-pool --type process\n```\n\n----------------------------------------\n\nTITLE: Creating Prefect Push Work Pool\nDESCRIPTION: Creates a push work pool in Prefect using Coiled resources named 'example-coiled-pool'. Requires Prefect CLI access.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type coiled:push --provision-infra 'example-coiled-pool'\n```\n\n----------------------------------------\n\nTITLE: Defining Frontmatter for Prefect GitHub SDK Documentation\nDESCRIPTION: This markdown frontmatter defines metadata for the Prefect GitHub SDK documentation page. It specifies the title as 'SDK docs' and provides the URL where the full reference documentation can be found.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_github/\"\n---\n```\n\n----------------------------------------\n\nTITLE: Serving a Flow with an Interval Schedule (Prefect < 3.1.16)\nDESCRIPTION: This code snippet demonstrates how to serve a Prefect flow with an interval schedule for versions older than 3.1.16. It utilizes the `IntervalSchedule` class from `prefect.client.schemas.schedules` to define a schedule that runs the flow every 10 minutes. An `anchor_date` and `timezone` are also specified to define the schedule's starting point and timezone.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/add-schedules.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta, datetime\nfrom prefect.client.schemas.schedules import IntervalSchedule\n\nfrom myproject.flows import my_flow\n\nmy_flow.serve(\n  name=\"flowing\",\n  schedules=[\n    IntervalSchedule(\n      interval=timedelta(minutes=10),\n      anchor_date=datetime(2026, 1, 1, 0, 0),\n      timezone=\"America/Chicago\"\n    )\n  ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating ECS Fargate Service for Prefect Worker\nDESCRIPTION: AWS CLI command to create an ECS Fargate service that will manage the Prefect worker. It specifies the service name, cluster, task definition, and network configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\naws ecs create-service \\\n    --service-name prefect-worker-service \\\n    --cluster <ecs-cluster> \\\n    --task-definition <task-definition-arn> \\\n    --launch-type FARGATE \\\n    --desired-count 1 \\\n    --network-configuration \"awsvpcConfiguration={subnets=[<subnet-ids>],securityGroups=[<security-group-ids>],assignPublicIp='ENABLED'}\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Prefect Flow with a Task that May Fail\nDESCRIPTION: This code defines a Prefect flow called `my_flow` with a single task `add_one` that attempts to add 1 to a string. The `return_state=True` argument ensures that the state of the task is returned, even if it fails. The flow then asserts that the task state is failed, but since the flow function returns without error or a failed state, it will be marked as `COMPLETED` unless the state is returned from the flow function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/final-flow-state.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task \n\n\n@task \ndef add_one(x):\n    return x + 1\n\n\n@flow \ndef my_flow():\n    # avoided raising an exception via `return_state=True`\n    state = add_one(\"1\", return_state=True)\n    assert state.is_failed()\n\n    # the flow function returns successfully!\n    return\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Dev Environment with UV\nDESCRIPTION: Commands for setting up a development environment using UV package manager, including dependency sync and version verification.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv sync\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv run prefect --version\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Deployments\nDESCRIPTION: This bash snippet shows how to run Prefect deployments using the CLI. It demonstrates running specific deployments by name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment run hello/default\nprefect deployment run hello/arthur\n```\n\n----------------------------------------\n\nTITLE: Enabling IP Allowlist\nDESCRIPTION: Command to enable IP allowlist enforcement for the Prefect Cloud account. This activates the IP-based access restrictions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-ip-address.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud ip-allowlist enable\n```\n\n----------------------------------------\n\nTITLE: Inspecting a Prefect Profile\nDESCRIPTION: This command displays the settings of a given Prefect profile. If no profile name is provided, it defaults to displaying the settings of the active profile.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile inspect [OPTIONS] [NAME]\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Deployment Configuration - Prefect Command\nDESCRIPTION: The `prefect init` command initializes a new deployment configuration recipe in Prefect. It includes options for specifying the deployment name and providing fields in key=value format to pass to the recipe. It is a command-line interface tool requiring no additional dependencies. Expected input is the command and optional parameters, outputting a setup deployment configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/init.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect init [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Deploying Specific Deployments with Prefect CLI\nDESCRIPTION: Commands for deploying individual or multiple deployments using the Prefect CLI, including pattern matching.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy --name deployment-1\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy --name deployment-1 --name deployment-2\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy --name my_flow/deployment-1 --name my_other_flow/deployment-1\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy --all\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy -n my-flow/* -n *dev/my-deployment -n dep*prod\n```\n\n----------------------------------------\n\nTITLE: Installing Minimal Prefect Client\nDESCRIPTION: Command to install the lightweight prefect-client library, designed for interacting with Prefect Cloud or remote self-hosted Prefect server instances.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install -U prefect-client\n```\n\n----------------------------------------\n\nTITLE: List Concurrency Limits\nDESCRIPTION: Displays all existing concurrency limits with options for limiting and offsetting results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Delete Deployment\nDESCRIPTION: Remove a deployment using either its name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment delete [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Delete Prefect Profile\nDESCRIPTION: This command deletes the given Prefect profile. The profile name is required.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles delete [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Executing Prefect Dashboard Base Command\nDESCRIPTION: The base command for interacting with the Prefect UI dashboard. This command serves as the entry point for dashboard-related operations and accepts additional options and subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dashboard.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect dashboard [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Create GKE Cluster on GCP\nDESCRIPTION: This snippet creates a GKE cluster using the gcloud CLI. Replace `<CLUSTER-NAME>` with your desired cluster name and `<AVAILABILITY-ZONE>` with your chosen zone.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Create cluster\n# Replace the cluster name with your own value\ngcloud container clusters create <CLUSTER-NAME> --num-nodes=1 \\\n--machine-type=n1-standard-2\n\n# Authenticate to the cluster\ngcloud container clusters <CLUSTER-NAME> --region <AVAILABILITY-ZONE>\n```\n\n----------------------------------------\n\nTITLE: Deploying Model Training Flow to Prefect Cloud\nDESCRIPTION: Command to deploy the model_training.py flow to Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython model_training.py\n```\n\n----------------------------------------\n\nTITLE: Creating an AWS ECS Push Work Pool with Automatic Infrastructure Provisioning\nDESCRIPTION: Command to create a new ECS push work pool with automatic infrastructure setup in AWS. This provisions IAM users, policies, ECS clusters using Fargate, VPC, and ECR repositories.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type ecs:push --provision-infra my-ecs-pool\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Specification\nDESCRIPTION: Defines the OpenAPI specification for the POST /api/block_documents/ endpoint path\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/create-block-document.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_documents/\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-redis via pip\nDESCRIPTION: This command installs a version of prefect-redis compatible with the installed version of Prefect. If Prefect is not installed, it will install the newest version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-redis/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Delete Flow Run\nDESCRIPTION: Command to delete a specific flow run from the system. Requires a flow run ID as argument.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs delete [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Setting concurrency limits on a work queue\nDESCRIPTION: Command to set a concurrency limit on an existing work queue, specifying how many flow runs can execute simultaneously.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues set-concurrency-limit [OPTIONS] NAME LIMIT\n```\n\n----------------------------------------\n\nTITLE: List Blocks Command\nDESCRIPTION: Command to view all configured blocks in the system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring General Server Settings in TOML\nDESCRIPTION: TOML configuration for general Prefect server settings, including logging level, analytics, metrics, and block registration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\nserver.logging_level = \"WARNING\"\nserver.analytics_enabled = true\nserver.metrics_enabled = false\nserver.log_retryable_errors = false\nserver.register_blocks_on_start = true\nserver.memoize_block_auto_registration = true\nserver.deployment_schedule_max_scheduled_runs = 50\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Role Definition for ACI\nDESCRIPTION: Defines a custom role with permissions for container instance management including creation, deletion, and monitoring capabilities.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/aci_worker.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naz role definition create --role-definition '{\n  \"Name\": \"Container Instances Contributor\",\n  \"IsCustom\": true,\n  \"Description\": \"Can create, delete, and monitor container instances.\",\n  \"Actions\": [\n    \"Microsoft.ManagedIdentity/userAssignedIdentities/assign/action\",\n    \"Microsoft.Resources/deployments/*\",\n    \"Microsoft.ContainerInstance/containerGroups/*\"\n  ],\n  \"NotActions\": [\n  ],\n  \"AssignableScopes\": [\n    '\"\\\"$RG_SCOPE\\\"\"'\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Loading Saved DBT Core Operation Block\nDESCRIPTION: Demonstrates how to load a previously saved DbtCoreOperation block\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_dbt.cloud import DbtCoreOperation\n\n\nDbtCoreOperation.load(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Running Development Server\nDESCRIPTION: Commands for starting Prefect services in development mode with hot-reloading.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect dev start\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect dev api\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Server with Custom Values\nDESCRIPTION: Command to install the Prefect server using a custom values file for configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhelm install prefect-server prefect/prefect-server \\\n  --namespace prefect \\\n  -f server-values.yaml\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for GET Deployment Endpoint in Prefect API\nDESCRIPTION: Defines the OpenAPI specification for retrieving a specific deployment by ID in the Prefect API. The endpoint path is '/api/deployments/{id}' and uses the GET HTTP method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/read-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/deployments/{id}\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect .env Configuration File\nDESCRIPTION: Example of a .env file that sets the logging level to DEBUG. This file is automatically detected when placed in the working directory and applies to all runs in that directory across different shell sessions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_LOGGING_LEVEL=\"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Defining DELETE Endpoint for Concurrency Limits in OpenAPI YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI configuration for deleting a concurrency limit via the Prefect API. It defines the endpoint path with a parameter for the limit's ID or name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/delete-concurrency-limit-v2.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/v2/concurrency_limits/{id_or_name}\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image with Commit Hash\nDESCRIPTION: This YAML snippet illustrates a step in a build action that retrieves the current Git commit hash and uses it to tag a Docker image, showcasing dependency chaining.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nbuild:\n- prefect.deployments.steps.run_shell_script:\n    id: get-commit-hash\n    script: git rev-parse --short HEAD\n    stream_output: false\n- prefect_docker.deployments.steps.build_docker_image:\n    requires: prefect-docker\n    image_name: my-image\n    image_tag: \"{{ get-commit-hash.stdout }}\"\n    dockerfile: auto\n```\n\n----------------------------------------\n\nTITLE: Listing Work Pools Using Prefect CLI\nDESCRIPTION: The command to list all configured work pools on the Prefect server, displaying their names, types, IDs, and concurrency limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool ls\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-azure Package with pip\nDESCRIPTION: Commands for installing the prefect-azure package and its optional components for Blob Storage, Cosmos DB, and ML Datastore integration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-azure\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[blob_storage]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[cosmos_db]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[ml_datastore]\"\n```\n\n----------------------------------------\n\nTITLE: Base Flow Runs Command\nDESCRIPTION: Base command for interacting with Prefect flow runs. Used as a prefix for all flow run related commands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-runs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-runs [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-gcp Package\nDESCRIPTION: Commands for installing the prefect-gcp package and its extras using pip or uv package managers.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[gcp]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect-gcp[all_extras]\"\n```\n\n----------------------------------------\n\nTITLE: Create Concurrency Limit\nDESCRIPTION: Creates a new concurrency limit for a specified tag to control how many task runs with that tag can run simultaneously.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits create [OPTIONS] TAG CONCURRENCY_LIMIT\n```\n\n----------------------------------------\n\nTITLE: Delete Concurrency Limit\nDESCRIPTION: Removes a concurrency limit configuration for a specified tag completely from the system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits delete [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Initialize Prefect Deployment Configuration\nDESCRIPTION: Command to initialize a new prefect.yaml file for deployments configuration\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy\n```\n\n----------------------------------------\n\nTITLE: Main Block Command\nDESCRIPTION: Base command for managing Prefect blocks\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect block [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Running Local Prefect Workflow\nDESCRIPTION: Commands to clone the quickstart repository and run the workflow locally\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/quickstart && cd quickstart\nuv run 01_getting_started.py\n```\n\n----------------------------------------\n\nTITLE: Create Block Command\nDESCRIPTION: Command to generate a UI link for creating a new block\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect block create [OPTIONS] BLOCK_TYPE_SLUG\n```\n\n----------------------------------------\n\nTITLE: Markdown Tables - Automation Permissions\nDESCRIPTION: Defines the available permissions for automations in custom roles within Prefect Cloud workspaces.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/manage-roles.mdx#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| Permission                           | Description                                                                                                     |\n| ------------------------------------ | --------------------------------------------------------------------------------------------------------------- |\n| View automations                     | User can see configured automations within a workspace.                                                         |\n| Create, edit, and delete automations | User can create, edit, and delete automations within a workspace. Includes permissions of **View automations**. |\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI GET Endpoint for Collections View in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for a GET endpoint to retrieve a specific view from the collections API. It includes the path parameter 'view' and outlines possible response codes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/collections/read-view-content.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/collections/views/{view}\n```\n\n----------------------------------------\n\nTITLE: Starting IPython Shell with UV and Prefect\nDESCRIPTION: Command for power users to start an IPython shell with Python 3.12 and Prefect installed using the UV package manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuvx --python 3.12 --with prefect ipython\n```\n\n----------------------------------------\n\nTITLE: BigQuery DBT Profile Configuration\nDESCRIPTION: Example of creating BigQuery target configs and profile blocks for dbt Core\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gcp.credentials import GcpCredentials\nfrom prefect_dbt.cli import BigQueryTargetConfigs, DbtCliProfile\n\n\ncredentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"SCHEMA-NAME-PLACEHOLDER\",  # also known as dataset\n    credentials=credentials,\n)\ntarget_configs.save(\"TARGET-CONFIGS-BLOCK-NAME-PLACEHOLDER\")\n\ndbt_cli_profile = DbtCliProfile(\n    name=\"PROFILE-NAME-PLACEHOLDER\",\n    target=\"TARGET-NAME-placeholder\",\n    target_configs=target_configs,\n)\ndbt_cli_profile.save(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\n```\n\n----------------------------------------\n\nTITLE: Clearing concurrency limits from a work queue\nDESCRIPTION: Command to remove any existing concurrency limits from a specified work queue.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues clear-concurrency-limit [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Delete Deployment\nDESCRIPTION: Command to remove a deployment from the system, with support for deletion by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments delete [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Setting up GitHub API Rate Limit in Prefect\nDESCRIPTION: Command to configure the GitHub API rate limit in Prefect. Sets up a limit of 60 unauthenticated requests per hour with a slot decay rate of 0.016 requests per second.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/scraping.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect gcl create github-api --limit 60 --slot-decay-per-second 0.016\n```\n\n----------------------------------------\n\nTITLE: Expanding Environment Variables in Shell Script in Prefect YAML\nDESCRIPTION: This example shows how to expand environment variables in a shell script by setting expand_env_vars to true in the run_shell_script step.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n- prefect.deployments.steps.run_shell_script:\n    id: get-user\n    script: echo $USER\n    stream_output: true\n    expand_env_vars: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Proactive Trigger in JSON\nDESCRIPTION: Setup a proactive trigger to fire if an expected event is not seen within a specified time window. Key parameters are 'match', 'after', 'expect', 'threshold', and 'within'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"match\": {\n    \"prefect.resource.id\": \"prefect.flow-run.*\"\n  },\n  \"match_related\": {},\n  \"after\": [\n    \"prefect.flow-run.Running\"\n  ],\n  \"expect\": [\n    \"prefect.flow-run.Completed\"\n  ],\n  \"for_each\": [\n    \"prefect.resource.id\"\n  ],\n  \"posture\": \"Proactive\",\n  \"threshold\": 1,\n  \"within\": 60\n}\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Server in Docker Container\nDESCRIPTION: Command to run a Prefect server in a Docker container, port-forwarded to the local machine's port 4200.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 4200:4200 prefecthq/prefect:3-latest -- prefect server start --host 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Creating Managed Work Pool via CLI\nDESCRIPTION: Command to create a new Prefect Managed work pool using the Prefect CLI, which sets up infrastructure for flow execution without additional configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/managed.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create my-managed-pool --type prefect:managed\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Endpoint for Filtering Latest Artifacts in Prefect\nDESCRIPTION: This snippet specifies the OpenAPI definition for a POST endpoint that allows filtering the latest artifacts in Prefect. The endpoint path is '/api/artifacts/latest/filter' which is used to query and retrieve artifact data based on specific filtering criteria.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/read-latest-artifacts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/artifacts/latest/filter\n```\n\n----------------------------------------\n\nTITLE: Type Checking Import Pattern\nDESCRIPTION: Demonstrates how to handle imports used only for type signatures using TYPE_CHECKING flag.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Correct\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from prefect.server.schemas.states import State\n\ndef foo(state: \"State\"):\n    pass\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Flow Run States Endpoint Definition\nDESCRIPTION: OpenAPI specification defining the GET endpoint for retrieving flow run states by ID. Defines the API path and HTTP method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-run-states/read-flow-run-state.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/flow_run_states/{id}\n```\n\n----------------------------------------\n\nTITLE: Running Flows in Production Workspace\nDESCRIPTION: Switch to the production workspace and run flows using a Python script.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Run flows in the production workspace\nprefect cloud workspace set --workspace \"<account handle>/production\"\npython simulate_failures.py\n```\n\n----------------------------------------\n\nTITLE: Viewing Prefect Configuration\nDESCRIPTION: Command to display current configuration settings with options to show defaults, value sources, and secrets.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/config.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect config view [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Inspecting a work queue by name or ID\nDESCRIPTION: Command to view detailed information about a specific work queue.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues inspect [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up the Prefect Recipes Repository with Git\nDESCRIPTION: This snippet demonstrates how to clone the Prefect Recipes repository and create a new branch for adding your own recipe. It shows the basic Git commands needed to start contributing to the Prefect Recipes collection.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/recipes.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Clone the repository\ngit clone git@github.com:PrefectHQ/prefect-recipes.git\ncd prefect-recipes\n\n# Create and checkout a new branch\n\ngit checkout -b new_recipe_branch_name\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Tests\nDESCRIPTION: Commands for running Prefect test suite using pytest with different targeting options.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# run all tests\npytest tests\n\n# run a specific file\npytest tests/test_flows.py\n\n# run all tests that match a pattern\npytest tests/test_tasks.py -k cache_policy\n```\n\n----------------------------------------\n\nTITLE: Cloning the Prefect Examples Repository\nDESCRIPTION: Commands to clone the PrefectHQ/examples repository and navigate to the examples directory.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/examples.git\ncd examples\n```\n\n----------------------------------------\n\nTITLE: Testing Email Alert for Failed Flow Run in Prefect Cloud\nDESCRIPTION: This bash script switches to the staging workspace in Prefect Cloud and runs a Python script to simulate a failed flow run, triggering the email alert.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/alerts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Switch to the staging workspace (if not already in it)\nprefect cloud workspace set --workspace \"<account handle>/staging\"\n\n# Run the script to simulate a failed flow run\npython simulate_failures.py --fail-at-run 1 --runs 1\n```\n\n----------------------------------------\n\nTITLE: Deleting Artifacts via CLI by Key\nDESCRIPTION: CLI command to delete an artifact using its key.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nprefect artifact delete <my_key>\n```\n\n----------------------------------------\n\nTITLE: Managing Prefect Profiles via CLI\nDESCRIPTION: Series of CLI commands that demonstrate how to manage Prefect profiles, including setting configuration values, creating new profiles, switching between profiles, and inspecting current settings.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/settings-and-profiles.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect profile use ephemeral\nprefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n\nprefect profile create new-profile --from ephemeral\nprefect profile use new-profile\nprefect config set PREFECT_RESULTS_PERSIST_BY_DEFAULT=true PREFECT_LOGGING_LEVEL=\"ERROR\"\n\nprefect profile inspect\nprefect config unset PREFECT_LOGGING_LEVEL -y\n```\n\n----------------------------------------\n\nTITLE: Viewing Docker Compose Logs\nDESCRIPTION: Displays the logs from all services in the Docker Compose stack, allowing monitoring of the application and Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose logs -f\n```\n\n----------------------------------------\n\nTITLE: Displaying Minimal Docker Compose Setup Directory Structure\nDESCRIPTION: Shows the file structure of the minimal-docker-compose directory, including the main components of the Docker Compose setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_17\n\nLANGUAGE: plaintext\nCODE:\n```\n├── README.md\n├── _types.py\n├── compose.yaml\n├── main.py\n├── pyproject.toml\n└── tasks.py\n```\n\n----------------------------------------\n\nTITLE: DBT Profiles Configuration\nDESCRIPTION: YAML configuration for DBT profiles with templating support for different environments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nexample:\n  outputs:\n    dev:\n      type: duckdb\n      path: dev.duckdb\n      threads: 1\n\n    prod:\n      type: snowflake\n      account: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.account }}\"\n      user: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.user }}\"\n      password: \"{{ prefect.blocks.snowflake-credentials.warehouse-access.password }}\"\n      database: \"{{ prefect.blocks.snowflake-connector.prod-connector.database }}\"\n      schema: \"{{ prefect.blocks.snowflake-connector.prod-connector.schema }}\"\n      warehouse: \"{{ prefect.blocks.snowflake-connector.prod-connector.warehouse }}\"\n      threads: 4\n\n  target: \"{{ prefect.variables.target }}\"\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Docker Package\nDESCRIPTION: Command to install a version of prefect-docker that is compatible with the existing Prefect installation. If Prefect is not installed, it will install the latest version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-docker/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[docker]\"\n```\n\n----------------------------------------\n\nTITLE: Delete Prefect Artifact Command\nDESCRIPTION: Command to delete a specific artifact, which can be identified either by its key or ID using the appropriate options.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/artifact.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect artifact delete [OPTIONS] [KEY]\n```\n\n----------------------------------------\n\nTITLE: Adding Prefect Helm Repository\nDESCRIPTION: Commands to add the Prefect Helm repository and update it.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add prefect https://prefecthq.github.io/prefect-helm\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Delete a Block Document via CLI (Slug)\nDESCRIPTION: This command demonstrates how to delete a specific block document using the Prefect CLI, identified by its slug.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/blocks.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nprefect block delete s3-bucket/my-data-bucket-block\n```\n\n----------------------------------------\n\nTITLE: Prefect Event Trigger Matching Example 2\nDESCRIPTION: This JSON configuration shows how to filter events related to a specific deployment using the `match_related` field. It targets events where the deployment's ID matches the specified value, demonstrating filtering based on related resource IDs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"match\": {},\n\"match_related\": {\n  \"prefect.resource.id\": \"prefect.deployment.37ca4a08-e2d9-4628-a310-cc15a323378e\"\n},\n...\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Server with UV in Ephemeral Environment\nDESCRIPTION: Command to start a Prefect server in an ephemeral Python environment using UV package manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuvx prefect server start\n```\n\n----------------------------------------\n\nTITLE: PostgreSQL Database Configuration\nDESCRIPTION: Command to configure Prefect to use a PostgreSQL database by setting the connection URL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_DATABASE_CONNECTION_URL=\"postgresql+asyncpg://postgres:yourTopSecretPassword@localhost:5432/prefect\"\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Runs Inspect Command\nDESCRIPTION: The `inspect` subcommand allows viewing detailed information about a specific task run, identified by its ID. The ID argument is required.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task-runs.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect task-runs inspect [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Submodule Usage Example\nDESCRIPTION: Demonstrates how to use imported submodules as namespaced objects, specifically for schema and model modules.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport prefect.server.schemas as schemas\n\n# The full module is accessible now\nschemas.core.FlowRun\n```\n\n----------------------------------------\n\nTITLE: Direct Function Call for Kubernetes Job Execution\nDESCRIPTION: Shows how to call the underlying function directly without Prefect features for running a Kubernetes job.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrun_namespaced_job.fn(job, print_func=print)\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Server in Docker Container\nDESCRIPTION: Command to start a Prefect server in a Docker container with port forwarding. The command maps port 4200 to the host, runs in detached mode, and sets the server to listen on all interfaces (0.0.0.0).\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/docker.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 4200:4200 -d --rm prefecthq/prefect:3-latest -- prefect server start --host 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Retrieving Artifacts in Python\nDESCRIPTION: Shows how to retrieve an existing artifact using the Artifact.get class method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.artifacts import Artifact\n\n\nmy_retrieved_artifact = Artifact.get(\"my_artifact_key\")\n```\n\n----------------------------------------\n\nTITLE: Generating OpenAPI Document for Prefect Server\nDESCRIPTION: This Python snippet shows how to generate a complete OpenAPI document for the Prefect server API. It imports the necessary modules, creates the app, and extracts the OpenAPI documentation, which can be used to generate API clients or for testing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.server.api.server import create_app\n\n\napp = create_app()\nopenapi_doc = app.openapi()\n```\n\n----------------------------------------\n\nTITLE: Fetching GitLab Repository Contents\nDESCRIPTION: Example demonstrating how to download repository contents using the GitLab repository block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gitlab.repositories import GitLabRepository\n\n\ndef fetch_repo():\n    private_gitlab_block = GitLabRepository.load(\"my-gitlab-block\")\n    private_gitlab_block.get_directory()\n\n\nif __name__ == \"__main__\":\n    fetch_repo()\n```\n\n----------------------------------------\n\nTITLE: Defining Prefect Requirements\nDESCRIPTION: Requirements file specifying the necessary Python packages for the Prefect deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nprefect>=3.0.0\nprefect-docker>=0.4.0\nprefect-kubernetes>=0.3.1\n```\n\n----------------------------------------\n\nTITLE: Inspecting a Prefect work pool\nDESCRIPTION: Displays detailed information about a specific work pool by name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool inspect [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Creating New Branch for Prefect Integration\nDESCRIPTION: Command to create a new branch in the local Git repository. This isolates the changes for the integration contribution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/contribute-integrations.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b my-new-branch\n```\n\n----------------------------------------\n\nTITLE: Running a Prefect Example with pip\nDESCRIPTION: Command to run a Hello World flow example using pip, with a reminder to install dependencies first.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Remember to `pip install` any dependencies first\npython flows/hello_world.py\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect DBT Package\nDESCRIPTION: Commands to install and upgrade the prefect-dbt package with compatibility for existing Prefect installations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[dbt]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[dbt]\"\n```\n\n----------------------------------------\n\nTITLE: Deleting Artifacts via CLI by ID\nDESCRIPTION: CLI command to delete an artifact using its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nprefect artifact delete --id <my_id>\n```\n\n----------------------------------------\n\nTITLE: Setting Prefect Cloud Workspace via CLI\nDESCRIPTION: Change the Prefect Cloud workspace to sync with using the Prefect CLI command. Pass the account handle and workspace name as arguments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/connect-to-cloud.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud workspace set --workspace \"prefect/my-workspace\"\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-shell Package\nDESCRIPTION: Commands to install and upgrade the prefect-shell package along with its dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[shell]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[shell]\"\n```\n\n----------------------------------------\n\nTITLE: Define OpenAPI POST Endpoint for Log Filtering\nDESCRIPTION: This snippet defines an OpenAPI endpoint for filtering logs using a POST request. It specifies the path as /api/logs/filter and the HTTP method as POST.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/logs/read-logs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"openapi: post /api/logs/filter\\n---\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect with pip and uv\nDESCRIPTION: Shows two different ways to install or upgrade the Prefect package using either pip (Python's default package manager) or uv (a faster alternative package manager). The -U flag ensures installation of the latest version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/installation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U prefect\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Stopping Prefect Server Services\nDESCRIPTION: Stops any background Prefect services that were started. This command is used to shut down the background services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_13\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services stop-services [OPTIONS]\"\n```\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services stop [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Resuming a paused work queue\nDESCRIPTION: Command to resume a previously paused work queue, allowing it to accept flow runs again.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues resume [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: OpenAPI DELETE Endpoint Specification for Concurrency Limit Tag\nDESCRIPTION: OpenAPI specification defining the DELETE endpoint for removing a concurrency limit tag in Prefect. This endpoint allows users to delete a specific tag from the concurrency limits system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/delete-concurrency-limit-by-tag.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/concurrency_limits/tag/{tag}\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Server Authentication\nDESCRIPTION: Command to create a Kubernetes secret for storing the basic authentication credentials for the Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic server-auth-secret \\\n  --namespace prefect --from-literal auth-string='admin:password123'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies from Requirements File in Prefect YAML\nDESCRIPTION: This example demonstrates how to use the pip_install_requirements step to install dependencies from a requirements.txt file after cloning a repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n- prefect.deployments.steps.git_clone:\n    id: clone-step # needed to be referenced in subsequent steps\n    repository: https://github.com/org/repo.git\n- prefect.deployments.steps.pip_install_requirements:\n    directory: \"{{ clone-step.directory }}\" # `clone-step` is a user-provided `id` field\n    requirements_file: requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-databricks Package\nDESCRIPTION: Commands to install the prefect-databricks package, ensuring compatibility with the installed Prefect version. Also includes an upgrade command for the latest versions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-databricks/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[databricks]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[databricks]\"\n```\n\n----------------------------------------\n\nTITLE: Customize Logging Configuration in Prefect with Bash\nDESCRIPTION: Shows how to customize Prefect logging settings by changing environment variables or configuration profiles using Bash. This example sets the logging level for flow runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_LOGGING_LOGGERS_PREFECT_FLOW_RUNS_LEVEL=\"ERROR\"\nexport PREFECT_LOGGING_LOGGERS_PREFECT_FLOW_RUNS_LEVEL=\"ERROR\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a prepare_for_flow_run Method for Custom Worker Labeling in Python\nDESCRIPTION: This code shows how to customize a worker's configuration by implementing the prepare_for_flow_run method to add custom labels to the execution environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_for_flow_run(\n    self, flow_run, deployment = None, flow = None, work_pool = None, worker_name = None\n):  \n    super().prepare_for_flow_run(flow_run, deployment, flow, work_pool, worker_name)  \n    self.labels.append(\"my-custom-label\")\n```\n\n----------------------------------------\n\nTITLE: Output Message Formatting\nDESCRIPTION: Shows how to format CLI output messages using textwrap.dedent for proper spacing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom textwrap import dedent\n...\noutput_msg = dedent(\n    f\"\"\"\n    Created work queue with properties:\n        name - {name!r}\n        uuid - {result}\n        tags - {tags or None}\n        deployment_ids - {deployment_ids or None}\n\n    Start an agent to pick up flows from the created work queue:\n        prefect agent start -q {name!r}\n\n    Inspect the created work queue:\n        prefect work-queue inspect {name!r}\n    \"\"\"\n)\n```\n\n----------------------------------------\n\nTITLE: Interact with Bitbucket Repository (Python)\nDESCRIPTION: This code shows how to create and save a BitbucketRepository block, specifying the repository URL and a specific branch or tag to reference.  The block can then be loaded and used to interact with the repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_bitbucket import BitbucketRepository\n\n\ndef save_bitbucket_block():\n    bitbucket_block = BitbucketRepository(\n        repository=\"https://bitbucket.org/testing/my-repository.git\",\n        reference=\"branch-or-tag-name\",\n    )\n\n    bitbucket_block.save(\"my-bitbucket-block\")\n\n\nif __name__ == \"__main__\":\n    save_bitbucket_block()\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Worker Template Variables\nDESCRIPTION: Implementation of custom worker template variables by extending BaseVariables class. Demonstrates how to add configurable memory and CPU request parameters for worker execution environments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import Field\nfrom prefect.workers.base import BaseVariables\n\nclass MyWorkerTemplateVariables(BaseVariables):\n    memory_request: int = Field(\n            default=1024,\n            description=\"Memory allocation for the execution environment.\"\n        )\n    cpu_request: int = Field(\n            default=500, \n            description=\"CPU allocation for the execution environment.\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Submitting Prefect Integration Changes\nDESCRIPTION: Series of Git commands to stage, commit, and push changes to the Prefect integration. This prepares the contribution for a pull request.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/contribute-integrations.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"My new integration\"\ngit push origin my-new-branch\n```\n\n----------------------------------------\n\nTITLE: Pause Schedule\nDESCRIPTION: Temporarily disable a deployment schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule pause [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-aws Package\nDESCRIPTION: Commands to install the prefect-aws package and upgrade to the latest versions of prefect and prefect-aws.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[aws]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[aws]\"\n```\n\n----------------------------------------\n\nTITLE: Sample Flow Execution Output\nDESCRIPTION: Example output showing the execution of a Prefect flow with shell commands, including progress indicators and status messages.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n14:48:16.550 | INFO    | prefect.engine - Created flow run 'tentacled-chachalaca' for flow 'download-data'\n14:48:17.977 | INFO    | Flow run 'tentacled-chachalaca' - PID 19360 triggered with 2 commands running inside the '.' directory.\n14:48:17.987 | INFO    | Flow run 'tentacled-chachalaca' - PID 19360 completed with return code 0.\n14:48:17.994 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 triggered with 1 commands running inside the PosixPath('data/20230201') directory.\n14:48:18.009 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dl\n14:48:18.010 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\noad  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n14:48:18.840 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\n 11 1630k   11  192k    0     0   229k      0  0:00:07 --:--:--  0:00:07  231k\n14:48:19.839 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\n 83 1630k   83 1368k    0     0   745k      0  0:00:02  0:00:01  0:00:01  747k\n14:48:19.993 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\n100 1630k  100 1630k    0     0   819k      0  0\n14:48:19.994 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 stream output:\n:00:01  0:00:01 --:--:--  821k\n14:48:19.996 | INFO    | Flow run 'tentacled-chachalaca' - PID 19363 completed with return code 0.\n14:48:19.998 | INFO    | Flow run 'tentacled-chachalaca' - Successfully closed all open processes.\n14:48:20.203 | INFO    | Flow run 'tentacled-chachalaca' - Finished in state Completed()\n```\n\n----------------------------------------\n\nTITLE: Cloning the Background Task Examples Repository\nDESCRIPTION: Clones the `prefect-background-task-examples` repository from GitHub.  This provides the initial step for setting up and exploring the example applications.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/prefect-background-task-examples.git\ncd prefect-background-task-examples\n```\n\n----------------------------------------\n\nTITLE: Registering DBT Block Types\nDESCRIPTION: Command to register prefect-dbt block types for availability in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_dbt\n```\n\n----------------------------------------\n\nTITLE: Checking Prefect Cloud Workspace Memberships in Bash\nDESCRIPTION: This curl command retrieves the workspace memberships for the authenticated user or service account. It's helpful for verifying access to specific workspaces in Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s -H \"Authorization: Bearer $PREFECT_API_KEY\" \"https://api.prefect.cloud/api/me/workspaces\"\n```\n\n----------------------------------------\n\nTITLE: Logging into Prefect Cloud via CLI\nDESCRIPTION: Use the Prefect CLI command to log into Prefect Cloud from your environment. This command provides an interactive login experience.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/connect-to-cloud.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login\n```\n\n----------------------------------------\n\nTITLE: SQLite Version Check\nDESCRIPTION: Command to verify SQLite installation and version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsqlite3 --version\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Label Patch Endpoint\nDESCRIPTION: Defines an API operation to modify labels for a specific flow run by its ID, allowing dynamic label updates\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/update-flow-run-labels.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/flow_runs/{id}/labels\n```\n\n----------------------------------------\n\nTITLE: Triggering a Webhook with curl Command in Prefect\nDESCRIPTION: Example curl command that triggers a Prefect webhook endpoint with custom parameters. This sends model_id, run_count, and friendly_name values that populate the webhook event template.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\ncurl -X POST https://api.prefect.cloud/hooks/34iV2SFke3mVa6y5Y-YUoA -d \"model_id=adhoc\" -d \"run_count=10\" -d \"friendly_name=test-user-input\"\n```\n\n----------------------------------------\n\nTITLE: Flow Run Inspection Command\nDESCRIPTION: Command to view detailed information about a specific flow run by ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run inspect [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Runs Logs Command\nDESCRIPTION: The `logs` subcommand retrieves and displays logs for a specific task run, identified by its ID. Options allow for showing the first or last N logs, reversing the order, and specifying the number of logs to display.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task-runs.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect task-runs logs [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: OpenAPI DELETE Endpoint for Work Queue by ID\nDESCRIPTION: This snippet defines the OpenAPI specification for a DELETE endpoint used to remove a specific work queue identified by its ID.  It specifies the HTTP method (DELETE) and the endpoint path, including the ID as a path parameter. It serves as documentation and contract for the API endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-queues/delete-work-queue.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n---\nopenapi: delete /api/work_queues/{id}\n---\n```\n\n----------------------------------------\n\nTITLE: Running Remote Prefect Workflow\nDESCRIPTION: Command to execute the deployed workflow remotely\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/quickstart.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuvx prefect-cloud run main/my_first_deployment\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect AWS Integration Package\nDESCRIPTION: Demonstrates methods to install Prefect AWS integration package using pip, either directly or as an extra\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/use-integrations.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-aws\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install 'prefect[aws]'\n```\n\n----------------------------------------\n\nTITLE: Stopping Prefect Server Docker Container\nDESCRIPTION: Stops the previously started Prefect server Docker container to avoid conflicts with the new setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ndocker kill prefect-server\n```\n\n----------------------------------------\n\nTITLE: Creating Process Work Pool in Bash\nDESCRIPTION: Command to create a Process work pool for self-hosted Prefect server deployment and verify its creation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/schedule.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type process my-work-pool\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool ls\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start --pool my-work-pool\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Definition\nDESCRIPTION: Defines a POST endpoint in OpenAPI for counting work pools.  This snippet specifies the path, HTTP method, and likely expects a request body related to the criteria for counting work pools.  Further details about request and response schemas would typically be defined alongside this snippet in a complete OpenAPI specification.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-pools/count-work-pools.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"openapi: post /api/work_pools/count\\n---\n```\n\n----------------------------------------\n\nTITLE: Deploying Prefect Flow with YAML Configuration\nDESCRIPTION: Deploys a Prefect flow using the specified YAML configuration with Coiled for Dockerless execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nprefect deploy --prefect-file prefect.yaml --all\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect in Python\nDESCRIPTION: Use pip to install the latest version of Prefect in the environment where you want to execute flow runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/connect-to-cloud.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Server Services TOML Configuration Example\nDESCRIPTION: Configuration settings for Prefect server services including cancellation cleanup, event logger, event persister, flow run notifications, foreman service, late runs service, pause expirations, and scheduler service. Each service has specific settings for enabling/disabling, loop intervals, batch sizes, and timeouts.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nserver.services.cancellation_cleanup.loop_seconds = 20\nserver.services.event_logger.enabled = false\nserver.services.event_persister.enabled = true\nserver.services.event_persister.batch_size = 20\nserver.services.event_persister.flush_interval = 5\nserver.services.event_persister.batch_size_delete = 10000\nserver.services.flow_run_notifications.enabled = true\nserver.services.foreman.enabled = true\nserver.services.foreman.loop_seconds = 15\nserver.services.foreman.inactivity_heartbeat_multiple = 3\nserver.services.foreman.fallback_heartbeat_interval_seconds = 30\nserver.services.foreman.deployment_last_polled_timeout_seconds = 60\nserver.services.foreman.work_queue_last_polled_timeout_seconds = 60\nserver.services.late_runs.enabled = true\nserver.services.late_runs.loop_seconds = 5\nserver.services.late_runs.after_seconds = \"PT15S\"\nserver.services.pause_expirations.enabled = true\nserver.services.pause_expirations.loop_seconds = 5\nserver.services.scheduler.enabled = true\nserver.services.scheduler.loop_seconds = 60\nserver.services.scheduler.deployment_batch_size = 100\nserver.services.scheduler.max_runs = 100\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Profile\nDESCRIPTION: This command creates a new Prefect profile with a specified name. An optional `--from` flag allows copying settings from an existing profile.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile create [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for GET Block Schema Endpoint in YAML\nDESCRIPTION: OpenAPI specification defining the GET /api/block_schemas/{id} endpoint which retrieves a specific block schema by its ID. The specification includes the endpoint path, operation details, and response structure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-schemas/read-block-schema-by-id.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_schemas/{id}\n```\n\n----------------------------------------\n\nTITLE: Inspect Block Command\nDESCRIPTION: Command to display details about a configured block using its slug or ID\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect block inspect [OPTIONS] [SLUG]\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for POST /api/block_schemas/ Endpoint\nDESCRIPTION: This OpenAPI specification defines the POST endpoint for creating a new block schema in the Prefect API. The endpoint is located at /api/block_schemas/.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-schemas/create-block-schema.mdx#2025-04-21_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nopenapi: post /api/block_schemas/\n```\n\n----------------------------------------\n\nTITLE: Reset Concurrency Limit\nDESCRIPTION: Resets the concurrency limit slots for a specified tag, clearing any active slot allocations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits reset [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Unsetting Prefect Configuration Values\nDESCRIPTION: Command to restore default values for specified settings by removing them from the current profile. Requires setting names as arguments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/config.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect config unset [OPTIONS] SETTING_NAMES...\n```\n\n----------------------------------------\n\nTITLE: Compressing Task Results with Serialization\nDESCRIPTION: Shows how to compress task results written to disk to save storage space using Prefect's result serialization options\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/big-data.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@task(result_serializer=\"compressed/json\")\n```\n\n----------------------------------------\n\nTITLE: Push Code to Cloud Storage Example\nDESCRIPTION: This snippet indicates how to configure the push action in a prefect.yaml file for deployment with S3, including necessary parameters and templating for folder structure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\npush:\n- prefect_aws.deployments.steps.push_to_s3:\n    id: push-code\n    requires: prefect-aws>=0.3.0\n    bucket: my-bucket\n    folder: project-name\n    credentials: null\n\npull:\n- prefect_aws.deployments.steps.pull_from_s3:\n    requires: prefect-aws>=0.3.0\n    bucket: my-bucket\n    folder: \"{{ push-code.folder }}\"\n    credentials: null\n```\n\n----------------------------------------\n\nTITLE: Sample Prefect Version Output\nDESCRIPTION: Example output from the 'prefect version' command showing version information, Python version, build details, and server configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nVersion:             3.1.10\nAPI version:         0.8.4\nPython version:      3.12.2\nGit commit:          d6bdb075\nBuilt:               Thu, Apr 11, 2024 6:58 PM\nOS/Arch:             darwin/arm64\nProfile:              local\nServer type:         ephemeral\nServer:\n  Database:          sqlite\n  SQLite version:    3.45.2\n```\n\n----------------------------------------\n\nTITLE: List Block Types Command\nDESCRIPTION: Command to list all available block types in the system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks types ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Checking Prefect Cloud Authentication in Bash\nDESCRIPTION: This curl command checks the authentication status with Prefect Cloud using an API key. It's useful for verifying that your API key is valid and properly configured.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s -H \"Authorization: Bearer $PREFECT_API_KEY\" \"https://api.prefect.cloud/api/me/\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for POST /api/automations/filter\nDESCRIPTION: YAML specification defining the OpenAPI/Swagger schema for the automations filter endpoint that accepts POST requests.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/read-automations.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/automations/filter\n```\n\n----------------------------------------\n\nTITLE: Listing Prefect Deployments using CLI\nDESCRIPTION: Bash command to list Prefect deployments using the CLI, which displays deployment names and their corresponding IDs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/automations-triggers.mdx#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nprefect deployment ls\n```\n\n----------------------------------------\n\nTITLE: Inspect Block Type Command\nDESCRIPTION: Command to display details about a specific block type using its slug.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks types inspect [OPTIONS] SLUG\n```\n\n----------------------------------------\n\nTITLE: Inspect Prefect Profile\nDESCRIPTION: This command displays the settings for a specified Prefect profile. If no profile name is provided, it defaults to the active profile.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles inspect [OPTIONS] [NAME]\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Block Document Retrieval Endpoint\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the GET /api/block_documents/{id} endpoint, which retrieves a block document by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/read-block-document-by-id.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_documents/{id}\n```\n\n----------------------------------------\n\nTITLE: Install Coiled and Prefect-Coiled packages using pip\nDESCRIPTION: This command installs both the `coiled` and `prefect-coiled` packages using pip. These packages are essential for using Coiled as a serverless compute platform with Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n\"pip install coiled prefect-coiled\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Server Services in TOML\nDESCRIPTION: TOML configuration for enabling or disabling various Prefect server services, including task run recorder and triggers.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\nserver.services.task_run_recorder.enabled = true\nserver.services.triggers.enabled = true\n```\n\n----------------------------------------\n\nTITLE: Installing Mintlify and Setting Up Local Development Environment\nDESCRIPTION: A sequence of commands to clone the repository, navigate to the docs directory, set up the correct Node.js version, install Mintlify globally, and start the development server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/docs-contribute.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nnvm use node\nnpm i -g mintlify\nmintlify dev\n```\n\n----------------------------------------\n\nTITLE: Running Prefect Server with Tracing\nDESCRIPTION: Commands to run the Prefect server with tracing enabled. Supports both SQLite (default) and PostgreSQL databases. The script handles database configuration and container management for PostgreSQL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Run with SQLite (default)\n./load_testing/run-server.sh\n\n# Run with PostgreSQL 15\n./load_testing/run-server.sh postgres:15\n```\n\n----------------------------------------\n\nTITLE: Example Output from Google Cloud Run Work Pool Creation\nDESCRIPTION: Partial sample console output showing the beginning of the infrastructure provisioning process for Google Cloud Run, displaying the required components to be created.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n____________________________________________________________________________________________________________\n| Provisioning infrastructure for your work pool my-cloud-run-pool will require:                           |\n```\n\n----------------------------------------\n\nTITLE: Logging into Prefect Cloud\nDESCRIPTION: Logs the user into Prefect Cloud. Requires a Prefect Cloud account.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login\n```\n\n----------------------------------------\n\nTITLE: Validating Prefect Configuration\nDESCRIPTION: Command to validate the current profile configuration. Automatically converts deprecated settings to new names unless both are explicitly set.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/config.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect config validate [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Running tasks in parallel with Ray using Prefect\nDESCRIPTION: Example of a Prefect flow that uses RayTaskRunner to count to a specified number in parallel.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nfrom prefect import flow, task\nfrom prefect_ray import RayTaskRunner\n\n@task\ndef shout(number):\n    time.sleep(0.5)\n    print(f\"#{number}\")\n\n@flow(task_runner=RayTaskRunner)\ndef count_to(highest_number):\n    shout.map(range(highest_number)).wait()\n\nif __name__ == \"__main__\":\n    count_to(10)\n```\n\n----------------------------------------\n\nTITLE: Base Global Concurrency Limit Command\nDESCRIPTION: The base command for accessing global concurrency limit functionality in Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Resetting Prefect Server Database\nDESCRIPTION: Drops and recreates all Prefect database tables. This command is useful for cleaning the database and starting with a fresh schema.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database reset [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Prefect Server Main Command\nDESCRIPTION: The main command for interacting with the Prefect server.  It provides access to subcommands for starting, stopping, and managing the server and its database.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server [OPTIONS] COMMAND [ARGS]...\"\n```\n\n----------------------------------------\n\nTITLE: Corrected API Test with Trailing Slash in Python\nDESCRIPTION: Fixed version of the test function that includes the trailing slash in the API route URL to avoid the 307 redirect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nasync def test_example(client):\n    response = await client.post(\"/my_route/\")\n    assert response.status_code == 201\n```\n\n----------------------------------------\n\nTITLE: Installing ML Datastore Support for prefect-azure\nDESCRIPTION: Command to install additional ML Datastore capabilities for the prefect-azure package after installing the main library.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[ml_datastore]\"\n```\n\n----------------------------------------\n\nTITLE: Registering prefect-azure Block Types\nDESCRIPTION: Command to register the block types in the prefect-azure module, making them available for use in Prefect workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_azure\n```\n\n----------------------------------------\n\nTITLE: Deployment Concurrency Limit Update\nDESCRIPTION: Script for updating deployment concurrency limits through the Prefect API, particularly useful for Prefect 2.x installations where direct model updates are not supported.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/scripts.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Reference to update_deployment_concurrency_limit.py\n```\n\n----------------------------------------\n\nTITLE: Logging into Prefect Cloud via CLI\nDESCRIPTION: This command logs the user into their Prefect Cloud account using the command-line interface.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for GET Concurrency Limits by Tag Endpoint\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the GET /api/concurrency_limits/tag/{tag} endpoint. It specifies the path, parameters, and potential responses for retrieving concurrency limits associated with a specific tag in the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/read-concurrency-limit-by-tag.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/concurrency_limits/tag/{tag}\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-slack Package\nDESCRIPTION: Commands to install the prefect-slack package and its dependencies, ensuring compatibility with the installed Prefect version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-slack/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[slack]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[slack]\"\n```\n\n----------------------------------------\n\nTITLE: Pause Prefect Automation\nDESCRIPTION: Command to pause a running automation specified by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect automations pause [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Inspect Prefect Artifact Command\nDESCRIPTION: Command to view detailed information about a specific artifact identified by its key. Returns artifact metadata including ID, creation date, type, and associated flow run information.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/artifact.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect artifact inspect [OPTIONS] KEY\n```\n\n----------------------------------------\n\nTITLE: Defining Next Runs Endpoint - OpenAPI\nDESCRIPTION: This snippet describes an endpoint configuration in OpenAPI for fetching the next scheduled flows within the Prefect application. There are no specific parameters mentioned, but it implies an HTTP POST request to interact with the API. The endpoint is designed to help users retrieve upcoming run information in their Prefect flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flows/next-runs-by-flow.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI Specification\nCODE:\n```\npost /api/ui/flows/next-runs\n```\n\n----------------------------------------\n\nTITLE: Database Model Example\nDESCRIPTION: Example of adding a new column to the flow_run table in the SQLAlchemy model.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# src/prefect/server/database/orm_models.py\n\nclass FlowRun(Run):\n    \"\"\"SQLAlchemy model of a flow run.\"\"\"\n    ...\n    new_column: Mapped[Union[str, None]] = mapped_column(sa.String, nullable=True) # <-- add this line\n```\n\n----------------------------------------\n\nTITLE: GitLab Deployment YAML Configuration\nDESCRIPTION: YAML configuration for deploying using GitLab credentials block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\npull:\n    - prefect.deployments.steps.git_clone:\n        repository: https://github.com/org/repo.git\n        credentials: \"{{ prefect.blocks.gitlab-credentials.my-gitlab-credentials-block }}\"\n```\n\n----------------------------------------\n\nTITLE: Install prefect-bitbucket\nDESCRIPTION: This command installs the prefect-bitbucket library, ensuring compatibility with the installed Prefect version. It also installs Prefect if it's not already present.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[bitbucket]\"\n```\n\n----------------------------------------\n\nTITLE: Enabling and Starting the Systemd Service\nDESCRIPTION: This snippet provides the commands required to enable and start the newly created systemd service for Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl daemon-reload\n```\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl enable my-prefect-service\n```\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start my-prefect-service\n```\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl status my-prefect-service\n```\n\n----------------------------------------\n\nTITLE: Delete Prefect Automation\nDESCRIPTION: Command to permanently delete an automation specified by name or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/automations.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect automations delete [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prefect with AWS integration\nDESCRIPTION: Command to upgrade Prefect with the AWS integration package. This illustrates how to update Prefect with additional integration packages or extras.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -U 'prefect[aws]'\n```\n\n----------------------------------------\n\nTITLE: Adding Prefect to Active UV Project\nDESCRIPTION: Command to add Prefect as a dependency to an active project using UV package manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuv add prefect\n```\n\n----------------------------------------\n\nTITLE: Create AKS Cluster on Azure\nDESCRIPTION: This snippet creates an AKS cluster using the Azure CLI. Replace `<RESOURCE-GROUP-NAME>` with your resource group name, `<LOCATION>` with the desired location, and `<CLUSTER-NAME>` with your desired cluster name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Create a Resource Group at the desired location, e.g. westus\naz group create --name <RESOURCE-GROUP-NAME> --location <LOCATION>\n\n# Create a kubernetes cluster with default kubernetes version, default SKU load balancer (Standard) and default vm set type (VirtualMachineScaleSets)\naz aks create --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME>\n\n# Configure kubectl to connect to your Kubernetes cluster\naz aks get-credentials --resource-group <RESOURCE-GROUP-NAME> --name <CLUSTER-NAME>\n\n# Verify the connection by listing the cluster nodes\nkubectl get nodes\n```\n\n----------------------------------------\n\nTITLE: Customizing Prefect Flow Options\nDESCRIPTION: Example of using the with_options method to customize an existing Prefect flow, including changing the name, retries, and retry delay.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-databricks/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncustom_example_execute_endpoint_flow = example_execute_endpoint_flow.with_options(\n    name=\"My custom flow name\",\n    retries=2,\n    retry_delay_seconds=10,\n)\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Endpoint for Variable by Name\nDESCRIPTION: This snippet defines an OpenAPI specification for a GET endpoint that retrieves a variable by its name. The endpoint is `/api/variables/name/{name}`, where `{name}` is a path parameter representing the variable's name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/variables/read-variable-by-name.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"openapi: get /api/variables/name/{name}\"\n```\n\n----------------------------------------\n\nTITLE: Base Concurrency Limits Command\nDESCRIPTION: Root command for accessing concurrency limit management functionality in Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limits.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limits [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Using the prefect work-queues base command\nDESCRIPTION: The base command for accessing all work queue management functionality in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Registering GCP Block Types\nDESCRIPTION: Command to register the GCP block types in Prefect for use in workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_gcp\n```\n\n----------------------------------------\n\nTITLE: Setting Up Pre-commit Hooks\nDESCRIPTION: Commands for installing and running pre-commit hooks to ensure code quality standards.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv run pre-commit install\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv run pre-commit run --all-files\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-ray package\nDESCRIPTION: Commands to install prefect-ray and upgrade to the latest versions of prefect and prefect-ray.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[ray]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[ray]\"\n```\n\n----------------------------------------\n\nTITLE: Register prefect-bitbucket block types\nDESCRIPTION: This command registers the block types provided by the prefect-bitbucket module. This makes them available for use within Prefect workflows and deployments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_bitbucket\n```\n\n----------------------------------------\n\nTITLE: Registering prefect-shell Blocks\nDESCRIPTION: Command to register block types from the prefect-shell module to make them available for use.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_shell\n```\n\n----------------------------------------\n\nTITLE: Building Prefect Docker Image\nDESCRIPTION: Command to build a Docker image for development with configurable architecture, Python version, and flavor options.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect dev build-image [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Setup Coiled\nDESCRIPTION: This command configures the connection between Coiled and your cloud account. It allows Prefect flows running on Coiled to access resources in your cloud environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n\"coiled setup\"\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Concurrency Limit Decrement Endpoint in YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the POST endpoint to decrement concurrency limits in the Prefect API. It specifies the endpoint path '/api/v2/concurrency_limits/decrement'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/bulk-decrement-active-slots.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/v2/concurrency_limits/decrement\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Email Package\nDESCRIPTION: Commands to install and upgrade the prefect-email package along with its dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[email]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[email]\"\n```\n\n----------------------------------------\n\nTITLE: Clear Schedules\nDESCRIPTION: Remove all schedules from a deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_11\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule clear [OPTIONS] DEPLOYMENT_NAME\n```\n\n----------------------------------------\n\nTITLE: Logging into Prefect Cloud with Workspace Specification\nDESCRIPTION: Log into Prefect Cloud and set the current workspace in a single command using the --workspace or -w option.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/connect-to-cloud.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login --workspace \"prefect/my-workspace\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Flow Runs Filter Endpoint Definition\nDESCRIPTION: YAML specification for the POST /api/flow_runs/filter endpoint that defines the API route for filtering flow run data.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/read-flow-runs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/flow_runs/filter\n```\n\n----------------------------------------\n\nTITLE: Validating PrivateLink Connectivity with Curl in Bash\nDESCRIPTION: This command uses curl to validate the connectivity to the Prefect service endpoint through PrivateLink. It sends a request to the health check API to ensure the connection is working properly.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-private-link.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -i https://api-internal.private.prefect.cloud/api/health\n```\n\n----------------------------------------\n\nTITLE: Adding Prefect Deployment Make Command\nDESCRIPTION: Adds a prefect-deploy target to the Makefile that runs the setup dependencies and then deploys all Prefect flows defined in the prefect.yaml configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_15\n\nLANGUAGE: makefile\nCODE:\n```\nprefect-deploy: setup\n    uv run prefect deploy --prefect-file prefect.yaml --all\n```\n\n----------------------------------------\n\nTITLE: Registering Email Block Types\nDESCRIPTION: Command to register the email-related block types in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_email\n```\n\n----------------------------------------\n\nTITLE: Revising Prefect Server Database\nDESCRIPTION: Creates a new migration for the Prefect database. This command is used when changes to the database schema are needed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database revision [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Adding Prefect Helm Repository\nDESCRIPTION: Bash commands to add and update the Prefect Helm repository in the local Helm client.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add prefect https://prefecthq.github.io/prefect-helm\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect 3.0 using pip\nDESCRIPTION: Command to upgrade to Prefect 3.0 from a previous version using pip. This is the primary command used to update the core Prefect package.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Using Native Snowflake Connector with Pandas\nDESCRIPTION: Example showing how to use the underlying Snowflake connection with pandas for direct data writing.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom prefect import flow\nfrom prefect_snowflake.database import SnowflakeConnector\nfrom snowflake.connector.pandas_tools import write_pandas\n\n\n@flow\ndef snowflake_write_pandas_flow():\n    connector = SnowflakeConnector.load(\"my-block\")\n    with connector.get_connection() as connection:\n        table_name = \"TABLE_NAME\"\n        ddl = \"NAME STRING, NUMBER INT\"\n        statement = f'CREATE TABLE IF NOT EXISTS {table_name} ({ddl})'\n        with connection.cursor() as cursor:\n            cursor.execute(statement)\n\n        # case sensitivity matters here!\n        df = pd.DataFrame([('Marvin', 42), ('Ford', 88)], columns=['NAME', 'NUMBER'])\n        success, num_chunks, num_rows, _ = write_pandas(\n            conn=connection,\n            df=df,\n            table_name=table_name,\n            database=snowflake_connector.database,\n            schema=snowflake_connector.schema_  # note the \"_\" suffix\n        )\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-azure with All Extra Features\nDESCRIPTION: Command to install prefect-azure with all additional capabilities after installing the main package.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[all_extras]\"\n```\n\n----------------------------------------\n\nTITLE: Schedule Management Base Command\nDESCRIPTION: Root command for managing deployment schedules with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Worker Configuration Settings\nDESCRIPTION: Worker-specific settings including heartbeat intervals, query timing, and webserver configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\nworker.heartbeat_seconds = 30\nworker.query_seconds = 10\nworker.prefetch_seconds = 10\nworker.webserver.host = \"0.0.0.0\"\nworker.webserver.port = 8080\n```\n\n----------------------------------------\n\nTITLE: Correct Module Import Syntax\nDESCRIPTION: Demonstrates the recommended way to import modules using the import statement with optional aliases.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Correct\nimport prefect.server.schemas  # use with the full name\nimport prefect.server.schemas as schemas  # use the shorter name\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prefect via pip in Bash\nDESCRIPTION: This command upgrades Prefect to the latest version using pip. It's an essential step in troubleshooting to ensure you're using the most up-to-date version with potential bug fixes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade prefect\n```\n\n----------------------------------------\n\nTITLE: Running a Prefect Example with uv\nDESCRIPTION: Command to run a Hello World flow example using the uv package manager.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/examples/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv run flows/hello_world.py\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prefect server database\nDESCRIPTION: Command to update the database schema for self-hosted Prefect servers after upgrading to version 3.0. This ensures compatibility between the new version and existing data.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect server database upgrade\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Development API\nDESCRIPTION: Command to start a hot-reloading development API server with configurable host, port, log level, and services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect dev api [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: CLI Output Example\nDESCRIPTION: Shows the proper formatting for CLI command output messages including creation confirmation, properties list, and next steps.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n$ prefect work-queue create testing\n\nCreated work queue with properties:\n    name - 'abcde'\n    uuid - 940f9828-c820-4148-9526-ea8107082bda\n    tags - None\n    deployment_ids - None\n\nStart an agent to pick up flows from the created work queue:\n    prefect agent start -q 'abcde'\n\nInspect the created work queue:\n    prefect work-queue inspect 'abcde'\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Deployment Count Endpoint Specification\nDESCRIPTION: YAML OpenAPI specification defining the POST endpoint /api/deployments/count\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/count-deployments.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/count\n```\n\n----------------------------------------\n\nTITLE: Registering Prefect GitHub Blocks\nDESCRIPTION: Command to register the block types from the prefect-github module\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_github\n```\n\n----------------------------------------\n\nTITLE: Starting Prefect Development UI\nDESCRIPTION: Command to start a hot-reloading development UI server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect dev ui [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Prefect Cloud\nDESCRIPTION: Log into Prefect Cloud using the CLI to authenticate for further operations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login\n```\n\n----------------------------------------\n\nTITLE: Flow Run Execution Command\nDESCRIPTION: Command to execute a flow run with an optional ID parameter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run execute [OPTIONS] [ID]\n```\n\n----------------------------------------\n\nTITLE: Simplified Prefect Flow Deployment with Source\nDESCRIPTION: Updated example showing simplified deployment using flow.from_source and flow.deploy\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nif __name__ == \"__main__\":\n    flow.from_source(\n        source=\"https://github.com/me/myrepo.git\",\n        entrypoint=\"example.py:my_flow\"\n    ).deploy(\n        name=\"my-deployment\",\n        work_pool_name=\"my-k8s-job\",\n        job_variables=dict(pull_policy=\"Never\"),\n        parameters=dict(name=\"Marvin\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Using Makefile\nDESCRIPTION: This Makefile manages the Python environment for the Prefect project. It checks for dependencies, installs them, and sets up the environment if necessary.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_0\n\nLANGUAGE: makefile\nCODE:\n```\nexport PYTHONPATH = .venv\n\n.PHONY: uv\nuv:\n\tpip install --upgrade 'uv>=0.5.6,<0.6'\n\tuv venv\n\nsetup:\n\t@if [ ! -d \".venv\" ] || ! command -v uv > /dev/null; then \\\n\t\techo \"UV not installed or .venv does not exist, running uv\"; \\\n\t\tmake uv; \\\n\tfi\n\t@if [ ! -f \"uv.lock\" ]; then \\\n\t\techo \"Can't find lockfile. Locking\"; \\\n\t\tuv lock; \\\n\tfi\n\tuv sync --all-extras --all-groups\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect and Coiled Packages using pip\nDESCRIPTION: This command installs the necessary Python packages: Prefect, Coiled, and Prefect-Coiled. Ensure pip is installed and active in your environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect coiled prefect-coiled\n```\n\n----------------------------------------\n\nTITLE: Registering prefect-aws Block Types\nDESCRIPTION: Command to register the block types in prefect-aws to make them available for use.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_aws\n```\n\n----------------------------------------\n\nTITLE: Use Prefect Profile\nDESCRIPTION: This command sets the specified profile as the active profile. The active profile determines the configuration used by Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles use [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Resetting Prefect Database\nDESCRIPTION: CLI command to reset the Prefect database by clearing all data and reapplying the schema.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect server database reset -y\n```\n\n----------------------------------------\n\nTITLE: Configuring SDK Documentation URL Path for Prefect SQLAlchemy\nDESCRIPTION: YAML frontmatter configuration that specifies the title and URL path for the Prefect SQLAlchemy SDK documentation reference page.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_sqlalchemy/\"\n---\n```\n\n----------------------------------------\n\nTITLE: Listing Prefect Profiles\nDESCRIPTION: This command lists all available Prefect profile names. It provides a quick overview of the existing profiles that can be used for configuring Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile ls [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Declaring Multiple Deployments in prefect.yaml\nDESCRIPTION: Example of a prefect.yaml file containing multiple deployment declarations with unique names and configurations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nbuild: ...\npush: ...\npull: ...\n\ndeployments:\n  - name: deployment-1\n    entrypoint: flows/hello.py:my_flow\n    parameters:\n        number: 42,\n        message: Don't panic!\n    work_pool:\n        name: my-process-work-pool\n        work_queue_name: primary-queue\n\n  - name: deployment-2\n    entrypoint: flows/goodbye.py:my_other_flow\n    work_pool:\n        name: my-process-work-pool\n        work_queue_name: secondary-queue\n\n  - name: deployment-3\n    entrypoint: flows/hello.py:yet_another_flow\n    work_pool:\n        name: my-docker-work-pool\n        work_queue_name: tertiary-queue\n```\n\n----------------------------------------\n\nTITLE: Example Output from Azure Container Instances Work Pool Creation\nDESCRIPTION: Sample console output showing the infrastructure components being created during Azure Container Instances work pool provisioning, including resource group, app registration, service principal, and container registry setup.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n_____________________________________________________________________________________________\n| Provisioning infrastructure for your work pool my-aci-work-pool will require:             |\n|                                                                                           |\n|     Updates in subscription Azure subscription 1                                          |\n|                                                                                           |\n|         - Create a resource group in location eastus                                      |\n|         - Create an app registration in Azure AD prefect-aci-push-pool-app                |\n|         - Create/use a service principal for app registration                             |\n|         - Generate a secret for app registration                                          |\n|         - Create an Azure Container Registry with prefix prefect                           |\n|         - Create an identity prefect-acr-identity to allow access to the created registry |\n|         - Assign Contributor role to service account                                      |\n|         - Create an ACR registry for image hosting                                        |\n|         - Create an identity for Azure Container Instance to allow access to the registry |\n|                                                                                           |\n|     Updates in Prefect workspace                                                          |\n|                                                                                           |\n|         - Create Azure Container Instance credentials block aci-push-pool-credentials     |\n|                                                                                           |\n_____________________________________________________________________________________________\nProceed with infrastructure provisioning? [y/n]:     \nCreating resource group\nCreating app registration\nGenerating secret for app registration\nCreating ACI credentials block\nACI credentials block 'aci-push-pool-credentials' created in Prefect Cloud\nAssigning Contributor role to service account\nCreating Azure Container Registry\nCreating identity\nProvisioning infrastructure... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00\nInfrastructure successfully provisioned for 'my-aci-work-pool' work pool!\nCreated work pool 'my-aci-work-pool'!\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-azure Package with pip\nDESCRIPTION: Command to install the prefect-azure package compatible with the installed Prefect version. If Prefect is not installed, it will install the latest version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[azure]\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Minimal Local Setup Directory Structure\nDESCRIPTION: Shows the file structure of the minimal-local-setup directory, including the main components of the FastAPI application.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_10\n\nLANGUAGE: plaintext\nCODE:\n```\n├── README.md\n├── api.py\n├── requirements.txt\n├── tasks.py\n└── test\n```\n\n----------------------------------------\n\nTITLE: Executing Prefect Shell Command\nDESCRIPTION: The `prefect shell` command is used to execute shell commands in the context of Prefect flows. It takes options and arguments to manage these command executions within Prefect's environment. The command requires a shell command as an argument for its operation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/shell.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect shell [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Adding Single IP Address to Allowlist\nDESCRIPTION: Command to add a single IP address to the Prefect Cloud allowlist with a descriptive note. Requires the requestor's current IP to be on the list to prevent lockouts.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-ip-address.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud ip-allowlist add <your-ip-address> --description \"My home IP address\"\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Dev Environment with Pip\nDESCRIPTION: Commands for setting up a Python virtual environment and installing Prefect with development dependencies using pip.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv .venv\nsource .venv/bin/activate\n\n# Installs the package with development dependencies\npip install -e \".[dev]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect --version\n```\n\n----------------------------------------\n\nTITLE: Listing All Artifacts via CLI\nDESCRIPTION: CLI command to view all artifacts in the system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/artifacts.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nprefect artifact ls\n```\n\n----------------------------------------\n\nTITLE: Deleting a Prefect Profile\nDESCRIPTION: This command deletes the specified Prefect profile. This action is permanent and removes the profile from the configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile delete [OPTIONS] NAME\"\n```\n\n----------------------------------------\n\nTITLE: Update Global Concurrency Limit\nDESCRIPTION: Command to modify existing global concurrency limit properties including limit value, active slots, and decay rate.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit update [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Installing s3fs for S3 storage support\nDESCRIPTION: Command to install s3fs on both local and remote machines for S3 storage support.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install s3fs\n```\n\n----------------------------------------\n\nTITLE: Base Job Template in YAML Format for Custom Worker Configuration\nDESCRIPTION: This YAML configuration represents the base job template that would be generated from the custom worker configuration class, showing how configuration attributes are mapped to template variables.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\njob_configuration:\n    name: \"{{ name }}\"\n    env: \"{{ env }}\"\n    labels: \"{{ labels }}\"\n    command: \"{{ command }}\"\n    memory: \"{{ memory }}\"\n    cpu: \"{{ cpu }}\"\nvariables:\n    type: object\n    properties:\n        name:\n          title: Name\n          description: Name given to infrastructure created by a worker.\n          type: string\n        env:\n          title: Environment Variables\n          description: Environment variables to set when starting a flow run.\n          type: object\n          additionalProperties:\n            type: string\n        labels:\n          title: Labels\n          description: Labels applied to infrastructure created by a worker.\n          type: object\n          additionalProperties:\n            type: string\n        command:\n          title: Command\n          description: The command to use when starting a flow run. In most cases,\n            this should be left blank and the command will be automatically generated\n            by the worker.\n          type: string\n        memory:\n            title: Memory\n            description: Memory allocation for the execution environment.\n            type: integer\n            default: 1024\n        cpu:\n            title: CPU\n            description: CPU allocation for the execution environment.\n            type: integer\n            default: 500\n```\n\n----------------------------------------\n\nTITLE: Registering Prefect GitLab Blocks\nDESCRIPTION: Command to register the block types from the prefect-gitlab module.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gitlab/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_gitlab\n```\n\n----------------------------------------\n\nTITLE: Previewing a work queue's scheduled runs\nDESCRIPTION: Command to preview upcoming flow runs in a work queue, with configurable time window.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues preview [OPTIONS] [NAME]\n```\n\n----------------------------------------\n\nTITLE: Starting a Prefect Worker for a Work Pool\nDESCRIPTION: Command to start a worker process and assign it to a specific work pool.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nprefect worker start -p prod-work-pool\n```\n\n----------------------------------------\n\nTITLE: Rename Prefect Profile\nDESCRIPTION: This command changes the name of an existing Prefect profile. Both the current name and the new name are required.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles rename [OPTIONS] NAME NEW_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect API URL for OSS Server\nDESCRIPTION: Configures the Prefect API URL to point to a local Prefect server. This allows the examples to connect to the local Prefect instance.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash oss server\nCODE:\n```\nprefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n```\n\n----------------------------------------\n\nTITLE: Customized Job Configuration with Templates in YAML\nDESCRIPTION: This YAML snippet shows how the job_configuration section would appear after custom templates have been defined for memory and CPU attributes with units.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\njob_configuration:\n    name: \"{{ name }}\"\n    env: \"{{ env }}\"\n    labels: \"{{ labels }}\"\n    command: \"{{ command }}\"\n    memory: \"{{ memory_request }}Mi\"\n    cpu: \"{{ cpu_request }}m\"\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-aws Package via pip\nDESCRIPTION: Command to install the prefect-aws package using pip. This package allows users to leverage AWS capabilities in their Prefect flows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-aws/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-aws\n```\n\n----------------------------------------\n\nTITLE: Upgrading prefect and prefect-azure Packages\nDESCRIPTION: Command to upgrade both Prefect and prefect-azure packages to their latest versions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[azure]\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Definition - YAML\nDESCRIPTION: OpenAPI specification defining the /api/templates/validate POST endpoint path\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/validate-template.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/templates/validate\n```\n\n----------------------------------------\n\nTITLE: Base Blocks Command\nDESCRIPTION: Root command for managing Prefect blocks with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Populating Default Prefect Profiles\nDESCRIPTION: This command populates the profiles configuration with default base profiles, preserving existing user profiles. It ensures that default profiles are available without overwriting user-defined configurations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile populate-defaults [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Definition for Saved Searches Filter\nDESCRIPTION: This snippet defines the OpenAPI specification for the `/api/saved_searches/filter` endpoint using a POST request.  It outlines how to filter saved searches via the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/savedsearches/read-saved-searches.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"openapi: post /api/saved_searches/filter\\n---\n```\n\n----------------------------------------\n\nTITLE: Disabling Prefect Logging Colors in Bash\nDESCRIPTION: Shows how to toggle off color highlighting in Prefect console logs by setting the PREFECT_LOGGING_COLORS environment variable to False.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/logging.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_LOGGING_COLORS=False\n```\n\n----------------------------------------\n\nTITLE: Navigating to Retry Examples Directory\nDESCRIPTION: Bash command to change directory to the location containing complete examples of retry strategies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/2_retries\n```\n\n----------------------------------------\n\nTITLE: Cloning Prefect Demo Repository\nDESCRIPTION: Clone the Prefect demo repository to get started with the tutorial.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Clone the demo repository\ngit clone https://github.com/PrefectHQ/demos.git\ncd demos\n```\n\n----------------------------------------\n\nTITLE: Creating an ECS Push-based Work Pool\nDESCRIPTION: Command to create an AWS ECS work pool with infrastructure provisioning enabled.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/airflow.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create --type ecs:push --provision-infra my-ecs-pool\n```\n\n----------------------------------------\n\nTITLE: Reading runs from a work queue\nDESCRIPTION: Command to retrieve and display flow runs in a work queue, triggering an artificial poll of the queue.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-queues.mdx#2025-04-21_snippet_10\n\nLANGUAGE: command\nCODE:\n```\nprefect work-queues read-runs [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Running Development Server with Hot Reload\nDESCRIPTION: Starts the development server with hot-reload capability for real-time development updates.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run serve\n```\n\n----------------------------------------\n\nTITLE: Delete Schedule\nDESCRIPTION: Remove a specific schedule from a deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule delete [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: Markdown Tables - Account Level Roles Definition\nDESCRIPTION: Defines the built-in account-level roles (Owner, Admin, Member) and their associated permissions in Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/manage-roles.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Role   | Abilities                                                                                                                                                                                                                                                                                                                                                                                 |\n| ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Owner  | - Set/change all account profile settings allowed to be set/changed by a Prefect user. <br /> - Add and remove account members, and their account roles. <br /> - Create and delete service accounts in the account. <br /> - Create workspaces in the account. <br /> - Implicit workspace owner access on all workspaces in the account. <br /> - Bypass SSO. |\n| Admin  | - Set/change all account profile settings allowed to be set/changed by a Prefect user. <br /> - Add and remove account members, and their account roles. <br /> - Create and delete service accounts in the account. <br /> - Create workspaces in the account. <br /> - Implicit workspace owner access on all workspaces in the account. <br /> - Cannot bypass SSO.  |\n| Member | - View account profile settings. <br /> - View workspaces you have access to in the account. <br /> - View account members and their roles. <br /> - View service accounts in the account.\n```\n\n----------------------------------------\n\nTITLE: Delete Block Type Command\nDESCRIPTION: Command to delete an unprotected block type using its slug.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks types delete [OPTIONS] SLUG\n```\n\n----------------------------------------\n\nTITLE: Main Prefect Config Command\nDESCRIPTION: Base command for accessing Prefect configuration management functionality.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/config.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect config [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Deploy Fixed Code to Production Workspace\nDESCRIPTION: Bash commands to switch to the production workspace and run the updated script, ensuring the fix is applied to the production environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/debug.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud workspace set --workspace \"<account handle>/production\"\npython simulate_failures.py\n```\n\n----------------------------------------\n\nTITLE: Base Flow Run Command\nDESCRIPTION: Base command for interacting with flow runs in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Viewing Prefect Profile Information in CLI\nDESCRIPTION: This bash snippet shows the output from running the Prefect CLI command to inspect a profile. It displays the API URL and API key needed for authenticating with Prefect Cloud's REST API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_API_URL='https://api.prefect.cloud/api/accounts/abc-my-account-id-is-here/workspaces/123-my-workspace-id-is-here'\nPREFECT_API_KEY='123abc_my_api_key_is_here'\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Worker Configuration Class in Python\nDESCRIPTION: This snippet demonstrates how to extend BaseJobConfiguration to create a custom worker configuration with memory and CPU allocation parameters as Pydantic fields.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import Field\nfrom prefect.workers.base import BaseJobConfiguration\n\nclass MyWorkerConfiguration(BaseJobConfiguration):\n    memory: int = Field(\n            default=1024,\n            description=\"Memory allocation for the execution environment.\"\n        )\n    cpu: int = Field(\n            default=500, \n            description=\"CPU allocation for the execution environment.\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Running Full Benchmark Suite in Prefect\nDESCRIPTION: Command to run all benchmarks in the Prefect project using pytest-benchmark.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/benches/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython benches\n```\n\n----------------------------------------\n\nTITLE: Setting up GCP Secret Manager\nDESCRIPTION: Configuration for using GCP Secret Manager with Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-gcp/index.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_gcp import GcpCredentials, GcpSecret\ngcp_credentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME\")\n\ngcp_secret = GcpSecret(\n    secret_name = \"your-secret-name\",\n    secret_version = \"latest\",\n    gcp_credentials = gcp_credentials\n)\n\ngcp_secret.save(\"SECRET-BLOCK-NAME\")\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect Snowflake Integration\nDESCRIPTION: Commands for installing and upgrading the prefect-snowflake package and its dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-snowflake/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[snowflake]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[snowflake]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_snowflake\n```\n\n----------------------------------------\n\nTITLE: List Prefect Artifacts Command\nDESCRIPTION: Command to list artifacts with options to limit results and show all versions. Supports filtering through --limit and --all flags.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/artifact.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect artifact ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Delete Global Concurrency Limit\nDESCRIPTION: Command to remove a specific global concurrency limit from the system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit delete [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Defining Hard-Coded Job Variables in YAML\nDESCRIPTION: This YAML snippet provides a way to define job variables directly in the deployment definition, setting specific environment variables for the flow deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/customize.mdx#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ndeployments:\n- name: demo-deployment\n  entrypoint: demo_project/demo_flow.py:some_work\n  work_pool:\n    name: local\n    job_variables:\n        env:\n            EXECUTION_ENVIRONMENT: staging\n            MY_NOT_SO_SECRET_CONFIG: plumbus\n  schedule: null\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Prefect\nDESCRIPTION: Install the required dependencies for the Prefect project using pip.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Install dependencies\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Verifying Prefect CLI Installation\nDESCRIPTION: Check that the Prefect CLI is installed correctly by displaying its version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/platform.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Show that the Prefect CLI is installed\nprefect --version\n```\n\n----------------------------------------\n\nTITLE: Starting Task Worker for Minimal Local Setup\nDESCRIPTION: Starts the Prefect task worker using the specified requirements and tasks file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nuv run --with-requirements requirements.txt tasks.py\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Route Definition for Events Filtering\nDESCRIPTION: YAML definition for the POST /api/events/filter endpoint in the Prefect API specification\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/events/read-events.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/events/filter\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Prefect Cloud using API Key\nDESCRIPTION: Command to log into Prefect Cloud using a generated API key. The API key should be replaced with your actual key value generated from the Prefect Cloud UI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/api-keys.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud login -k '<my-api-key>'\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Clients and Workers for PrivateLink in Bash\nDESCRIPTION: These commands set the necessary environment variables for Prefect clients and workers to use the PrivateLink endpoint. PREFECT_API_URL is set for the specific account and workspace, while PREFECT_CLOUD_API_URL is set for the general API access.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-private-link.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_URL=https://api-internal.private.prefect.cloud/api/accounts/<ACCOUNT_ID>/workspaces/<WORKSPACE_ID>\nprefect config set PREFECT_CLOUD_API_URL=https://api-internal.private.prefect.cloud/api\n```\n\n----------------------------------------\n\nTITLE: Delete Schedule\nDESCRIPTION: Command to remove a specific schedule from a deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments schedule delete [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: Prefect Profiles Command\nDESCRIPTION: This is the base command for managing Prefect profiles. It allows users to interact with different profiles for different Prefect configurations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profiles.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profiles [OPTIONS] COMMAND [ARGS]...\"\n```\n\n----------------------------------------\n\nTITLE: Base Prefect Concurrency Limit Command\nDESCRIPTION: Base command for managing task-level concurrency limits in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Credentials in Prefect Worker\nDESCRIPTION: Example of configuring AWS credentials in a custom worker configuration class using Prefect blocks. This allows users to provide AWS credentials through the UI for worker authentication.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_aws import AwsCredentials\n\nclass MyWorkerConfiguration(BaseJobConfiguration):\n    aws_credentials: AwsCredentials = Field(\n        default=None,\n        description=\"AWS credentials to use when creating AWS resources.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Delete Block Command\nDESCRIPTION: Command to delete a configured block using its slug or ID\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect block delete [OPTIONS] [SLUG]\n```\n\n----------------------------------------\n\nTITLE: Database Migration Commands\nDESCRIPTION: CLI commands for managing database migrations using Alembic, including upgrade and downgrade operations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nprefect server database upgrade -y\nprefect server database downgrade -y\nprefect server database downgrade -y -r -1\nprefect server database downgrade -y -r d20618ce678e\n```\n\n----------------------------------------\n\nTITLE: Authenticate to gcloud\nDESCRIPTION: This snippet configures the gcloud CLI with authentication and project/zone settings. Replace `<GCP-PROJECT-NAME>` with your GCP project name and `<AVAILABILITY-ZONE>` with your desired availability zone.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Authenticate to gcloud\ngcloud auth login\n\n# Specify the project & zone to deploy the cluster to\n# Replace the project name with your GCP project name\ngcloud config set project <GCP-PROJECT-NAME>\ngcloud config set compute/zone <AVAILABILITY-ZONE>\n```\n\n----------------------------------------\n\nTITLE: Running Linter\nDESCRIPTION: Executes the linter to check and automatically fix code style issues according to project standards.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run lint\n```\n\n----------------------------------------\n\nTITLE: Registering prefect-kubernetes Block Types\nDESCRIPTION: Command to register the block types from the prefect-kubernetes module, making them available for use in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_kubernetes\n```\n\n----------------------------------------\n\nTITLE: Deleting a variable by name using OpenAPI\nDESCRIPTION: This snippet defines an OpenAPI endpoint for deleting a variable by its name. It specifies the HTTP method as DELETE and the path to the endpoint as /api/variables/name/{name}. The {name} parameter indicates that the variable's name should be passed as part of the URL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/variables/delete-variable-by-name.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\n\"openapi: delete /api/variables/name/{name}\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Prefect Worker Deployment\nDESCRIPTION: Bash command to check the status of Prefect worker pods in Kubernetes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods -n prefect\n```\n\n----------------------------------------\n\nTITLE: DBT Profile Configuration Example\nDESCRIPTION: Example YAML configuration for a dbt profile using environment variables\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nprofile:\n  target: prod\n  outputs:\n    prod:\n      type: postgres\n      host: 127.0.0.1\n      # IMPORTANT: Make sure to quote the entire Jinja string here\n      user: dbt_user\n      password: \"{{ env_var('DBT_PASSWORD') }}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Work Pool in Prefect YAML File\nDESCRIPTION: Updates the prefect.yaml configuration file to specify the work pool and job variables. The UV_PROJECT_ENVIRONMENT variable tells uv to use the root Python environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n...\nwork_pool:\n    name: \"pref-modal-pool\"\n    work_queue_name: \"default\"\n    job_variables: {\n        \"env\": {\"UV_PROJECT_ENVIRONMENT\": \"/usr/local\"}\n    }\n```\n\n----------------------------------------\n\nTITLE: Installing Blob Storage Support for prefect-azure\nDESCRIPTION: Command to install additional Blob Storage capabilities for the prefect-azure package after installing the main library.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[blob_storage]\"\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose Stack\nDESCRIPTION: Starts the Docker Compose stack in detached mode, which includes the FastAPI application, Prefect server, and required services.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Displaying IP Allowlist Help Documentation\nDESCRIPTION: Command to view the complete help documentation for IP allowlist-related commands in the Prefect CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-ip-address.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud ip-allowlist --help\n```\n\n----------------------------------------\n\nTITLE: OpenAPI PATCH Deployment Endpoint Specification\nDESCRIPTION: OpenAPI specification defining the PATCH endpoint for modifying an existing deployment by ID. The endpoint path includes a deployment ID parameter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/update-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/deployments/{id}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Work Queue Check Endpoint Definition\nDESCRIPTION: OpenAPI specification defining the GET endpoint for checking a deployment's work queue status at /api/deployments/{id}/work_queue_check\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/work-queue-check-for-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/deployments/{id}/work_queue_check\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for POST /api/artifacts/ Endpoint in YAML\nDESCRIPTION: This code snippet specifies the OpenAPI definition for the POST /api/artifacts/ endpoint. It outlines the structure and requirements for creating new artifacts in the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/create-artifact.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/artifacts/\n```\n\n----------------------------------------\n\nTITLE: Block Types Command\nDESCRIPTION: Base command for inspecting and managing block types\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect block types [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Prefect Task Command\nDESCRIPTION: This command is used to interact with task scheduling within the Prefect ecosystem. It serves as the parent command for various subcommands related to task management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/task.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect task [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Registering SQLAlchemy Block Types\nDESCRIPTION: Command to register SQLAlchemy block types in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_sqlalchemy\n```\n\n----------------------------------------\n\nTITLE: Custom Worker Configuration with Template Customization in Python\nDESCRIPTION: This code demonstrates how to customize templates for configuration attributes by specifying the template string and units for memory and CPU resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import Field\nfrom prefect.workers.base import BaseJobConfiguration\n\nclass MyWorkerConfiguration(BaseJobConfiguration):\n    memory: str = Field(\n        default=\"1024Mi\",\n        description=\"Memory allocation for the execution environment.\"\n        json_schema_extra=dict(template=\"{{ memory_request }}Mi\")\n    )\n    cpu: str = Field(\n        default=\"500m\", \n        description=\"CPU allocation for the execution environment.\"\n        json_schema_extra=dict(template=\"{{ cpu_request }}m\")\n    )\n```\n\n----------------------------------------\n\nTITLE: Enable Global Concurrency Limit\nDESCRIPTION: Command to activate a specific global concurrency limit.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/global-concurrency-limit.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect global-concurrency-limit enable [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Setting Up Prefect Integration Environment\nDESCRIPTION: Series of commands to set up the development environment for a Prefect integration. It includes changing directory, creating a virtual environment, activating it, and installing dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/contribute-integrations.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd src/integrations/my-integration\nuv venv --python 3.12\nsource .venv/bin/activate\nuv pip install -e \".[dev]\"\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Namespace\nDESCRIPTION: Bash command to create a new Kubernetes namespace for the Prefect worker deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/kubernetes.mdx#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create namespace prefect\n```\n\n----------------------------------------\n\nTITLE: Navigating to Minimal Local Setup Directory\nDESCRIPTION: Changes the current directory to the minimal-local-setup folder containing a FastAPI application with background tasks.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncd minimal-local-setup\n```\n\n----------------------------------------\n\nTITLE: Flow Run Deletion Command\nDESCRIPTION: Command to delete a specific flow run by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/flow-run.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect flow-run delete [OPTIONS] ID\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for PATCH /api/block_types/{id} Endpoint in YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the PATCH /api/block_types/{id} endpoint. It specifies the HTTP method and the endpoint path for updating a specific block type by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/update-block-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/block_types/{id}\n```\n\n----------------------------------------\n\nTITLE: Running Tests for Prefect Integration\nDESCRIPTION: Command to run tests for the Prefect integration using pytest. This ensures that new changes don't break existing functionality.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/contribute-integrations.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npytest tests\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables with Prefect Secret Blocks\nDESCRIPTION: Shows how to use Prefect Secret blocks to manage environment variables for dbt profiles\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom prefect.blocks.system import Secret\n\n\nsecret_block = Secret.load(\"DBT_PASSWORD_PLACEHOLDER\")\n\n# Access the stored secret\nDBT_PASSWORD = secret_block.get()\nos.environ[\"DBT_PASSWORD\"] = DBT_PASSWORD\n```\n\n----------------------------------------\n\nTITLE: Server UI Configuration\nDESCRIPTION: Settings for the Prefect UI server including API URL, base URL path, and static file serving configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\nserver.ui.enabled = true\nserver.ui.serve_base = \"/\"\nserver.ui.api_url = null\nserver.ui.static_directory = null\n```\n\n----------------------------------------\n\nTITLE: Creating Python Project with UV\nDESCRIPTION: This bash command initializes a new Python project in a directory, specifying the Python version to use for the Prefect project.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv init --lib --name prefect_modal --python 3.12\n```\n\n----------------------------------------\n\nTITLE: Importing Prefect Transaction Module\nDESCRIPTION: Basic import statement for the Prefect transaction module required for implementing transaction management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.transactions import transaction\n```\n\n----------------------------------------\n\nTITLE: Creating a Linux User for Prefect\nDESCRIPTION: This snippet demonstrates how to create a dedicated user for running Prefect processes on a Linux system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/daemonize-processes.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo useradd -m prefect\nsudo passwd prefect\n```\n\nLANGUAGE: bash\nCODE:\n```\nsudo su prefect\n```\n\n----------------------------------------\n\nTITLE: Resource Representation in JSON Event Structure\nDESCRIPTION: Illustrates how resources are defined in Prefect events, showing resource identifiers, optional labels, and related resources with their roles and attributes\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/events.mdx#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\\n    \\\"resource\\\": {\\n        \\\"prefect.resource.id\\\": \\\"prefect-cloud.automation.5b9c5c3d-6ca0-48d0-8331-79f4b65385b3.action.0\\\",\\n        \\\"prefect-cloud.action.type\\\": \\\"call-webhook\\\"\\n    },\\n    \\\"related\\\": [\\n        {\\n            \\\"prefect.resource.id\\\": \\\"prefect-cloud.automation.5b9c5c3d-6ca0-48d0-8331-79f4b65385b3\\\",\\n            \\\"prefect.resource.role\\\": \\\"automation\\\",\\n            \\\"prefect-cloud.name\\\": \\\"webhook_body_demo\\\",\\n            \\\"prefect-cloud.posture\\\": \\\"Reactive\\\"\\n        }\\n    ]\\n}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Block Documents Filter Endpoint\nDESCRIPTION: This code snippet defines the OpenAPI specification for the POST endpoint used to filter block documents in the Prefect API. It specifies the API path, request method, and structure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/read-block-documents.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_documents/filter\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Definition - POST /api/automations/count\nDESCRIPTION: OpenAPI specification for the /api/automations/count endpoint that accepts POST requests. The endpoint appears to be part of the Prefect API for counting automations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/count-automations.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/automations/count\n```\n\n----------------------------------------\n\nTITLE: Building Prefect UI\nDESCRIPTION: Command to install dependencies and build the UI locally. Requires npm and includes an option to skip installation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect dev build-ui [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: List Blocks Command\nDESCRIPTION: Command to view all configured blocks\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect block ls [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Prefect Server Services Manager Command\nDESCRIPTION: This is an internal entrypoint used by `prefect server services start --background`.  Users do not call this directly.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_10\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server services manager [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Resuming a Paused Prefect Flow Run Output\nDESCRIPTION: This is an example of the output after resuming a flow.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/pause-resume.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n> \"it's a wonder none of them ducked!\"\n```\n\n----------------------------------------\n\nTITLE: GitHub Actions Trigger Configuration\nDESCRIPTION: This YAML snippet configures the `on` trigger for a GitHub Actions workflow. It specifies that the workflow should run whenever a push event occurs on either the `stg` or `main` branches, but only if the changes are within the `project_1` directory.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\non:\n  push:\n    branches:\n      - stg\n      - main\n    paths:\n      - \"project_1/**\"\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub Actions Workflow File\nDESCRIPTION: Creates a new YAML file for defining the GitHub Actions workflow that will handle the Prefect deployment process.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntouch .github/workflows/prefect_cd.yaml\n```\n\n----------------------------------------\n\nTITLE: Register Blocks Command\nDESCRIPTION: Command to register block types from a Python module or file, making them available for configuration via the UI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_1\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks register [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring Flow Schedule in Prefect 2.0\nDESCRIPTION: Shows how to set up a scheduled flow in Prefect 2.0 using IntervalSchedule with the 'schedule' parameter. Uses a one-minute interval for the flow execution.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta\nfrom prefect import flow\nfrom prefect.client.schemas.schedules import IntervalSchedule\n\n@flow\ndef my_flow():\n    pass\n\nmy_flow.serve(\n    name=\"my-flow\",\n    schedule=IntervalSchedule(interval=timedelta(minutes=1))\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying Metadata Badges in Markdown\nDESCRIPTION: This code snippet shows how to display PyPI version and download statistics badges for the prefect-redis package using Markdown syntax. It includes links to the PyPI page and download statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-redis/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-redis/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-redis?color=0052FF&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-redis/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-redis?color=0052FF&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Deleting a Prefect work pool\nDESCRIPTION: Removes a work pool from the Prefect environment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool delete [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Exporting Work Pools Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'work_pools' that contains links to Prefect work pool documentation, covering the CLI, API, and Terraform resources. It provides a central location for accessing documentation related to managing work pools in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport const work_pools = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/work-pool\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Work-Pools\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/work_pool\",\n}\n```\n\n----------------------------------------\n\nTITLE: Running Specific Benchmark File in Prefect\nDESCRIPTION: Command to run a specific benchmark file in the Prefect project, using 'bench_flows.py' as an example.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/benches/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython benches bench_flows.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Scheduler Settings in TOML\nDESCRIPTION: TOML configuration for Prefect scheduler settings, including minimum runs, maximum scheduled time, and batch insertion size.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/settings-ref.mdx#2025-04-21_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nserver.services.scheduler.min_runs = 3\nserver.services.scheduler.max_scheduled_time = \"P100D\"\nserver.services.scheduler.min_scheduled_time = \"PT1H\"\nserver.services.scheduler.insert_batch_size = 500\nserver.services.scheduler.recent_deployments_loop_seconds = 5\n```\n\n----------------------------------------\n\nTITLE: Installing prefect on remote Ray cluster\nDESCRIPTION: Command to install prefect on a remote Ray cluster to resolve module not found errors.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-ray/index.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Tutorial Directory\nDESCRIPTION: Command to navigate to the directory containing the tutorial code for resilient workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/1_starting_flow\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose Setup with OpenAI API Key\nDESCRIPTION: This bash command starts the Docker Compose services, building the images and watching for changes. It requires an OpenAI API key to be provided as an environment variable.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/static-infrastructure-examples/background-tasks.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=<your-openai-api-key> docker compose up --build --watch\n```\n\n----------------------------------------\n\nTITLE: Running Benchmarks with Custom Options in Prefect\nDESCRIPTION: Command to run benchmarks with additional options, demonstrating how to set the minimum number of rounds to 2.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/benches/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython benches --min-rounds 2\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for GET /api/admin/settings Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI structure for the GET /api/admin/settings endpoint. It defines the API path, HTTP method, and likely includes details about request parameters, responses, and authentication requirements.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/admin/read-settings.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/admin/settings\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Database Clearing Endpoint\nDESCRIPTION: Specifies an OpenAPI endpoint configuration for clearing database data via POST to '/api/admin/database/clear'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/admin/clear-database.mdx#2025-04-21_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nopenapi: post /api/admin/database/clear\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Schema Checksum Endpoint\nDESCRIPTION: OpenAPI specification for a GET endpoint that retrieves block schema data based on a checksum parameter. Endpoint path is /api/block_schemas/checksum/{checksum}.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-schemas/read-block-schema-by-checksum.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_schemas/checksum/{checksum}\n```\n\n----------------------------------------\n\nTITLE: Cloning the Tutorial Repository\nDESCRIPTION: Command to clone the dev-day-zoom-out repository which contains the example code for the tutorial.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/dev-day-zoom-out.git\n```\n\n----------------------------------------\n\nTITLE: Prefect Profile Command\nDESCRIPTION: This is the base command for interacting with Prefect profiles. It allows users to execute various subcommands for managing their Prefect configurations.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/profile.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\n\"prefect profile [OPTIONS] COMMAND [ARGS]...\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI PATCH Flow Endpoint Specification\nDESCRIPTION: OpenAPI YAML specification defining the PATCH endpoint for modifying flow records at '/api/flows/{id}'\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flows/update-flow.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/flows/{id}\n```\n\n----------------------------------------\n\nTITLE: Flow failure handling with unhandled exceptions in Prefect 3.0\nDESCRIPTION: Example demonstrating how a flow fails when a task raises an unhandled exception. This reflects Prefect 3.0's approach where exceptions propagate to the flow level.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\ndef failing_task():\n    raise ValueError(\"Task failed\")\n\n@flow\ndef my_flow():\n    failing_task()  # Exception propagates, causing flow failure\n\ntry:\n    my_flow()\nexcept ValueError as e:\n    print(f\"Flow failed: {e}\")  # Output: Flow failed: Task failed\n```\n\n----------------------------------------\n\nTITLE: Create Block Command\nDESCRIPTION: Command to generate a link to the Prefect UI for creating a new block of a specific type.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks create [OPTIONS] BLOCK_TYPE_SLUG\n```\n\n----------------------------------------\n\nTITLE: Navigating to Minimal Docker Compose Setup Directory\nDESCRIPTION: Changes the current directory to the minimal-docker-compose folder containing a FastAPI application with Docker Compose configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\ncd minimal-docker-compose\n```\n\n----------------------------------------\n\nTITLE: Error Stack Trace in Prefect Flow Run Logs\nDESCRIPTION: An example of an error stack trace from the logs section of a Prefect flow run detail page, showing an exception being raised in the simulate_failures.py file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/debug.mdx#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nFile \"/opt/prefect/demos/simulate_failures.py\", line 12, in process_data\n    raise Exception(f\"Run failed\")\n```\n\n----------------------------------------\n\nTITLE: Adding CIDR Block to Allowlist\nDESCRIPTION: Command to add a range of IP addresses using CIDR notation. This example adds 256 IP addresses in a single entry, which helps work within the 25-entry limit.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-ip-address.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud ip-allowlist add \"192.168.1.0/24\" -d \"A CIDR block containing 256 IP addresses from 192.168.1.0 to 192.168.1.255\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for DELETE Block Schema Endpoint\nDESCRIPTION: Defines the OpenAPI specification for the DELETE operation on a block schema endpoint. This endpoint allows for the deletion of a block schema by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-schemas/delete-block-schema.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/block_schemas/{id}\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-github Package\nDESCRIPTION: Commands to install and upgrade the prefect-github package and its dependencies\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-github/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[github]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[github]\"\n```\n\n----------------------------------------\n\nTITLE: Default Prefect Database Settings\nDESCRIPTION: Default environment variables for configuring the Prefect database connection and behavior.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPREFECT_API_DATABASE_CONNECTION_URL='sqlite+aiosqlite:///${PREFECT_HOME}/prefect.db'\nPREFECT_API_DATABASE_ECHO='False'\nPREFECT_API_DATABASE_MIGRATE_ON_START='True'\nPREFECT_API_DATABASE_PASSWORD='None'\n```\n\n----------------------------------------\n\nTITLE: Create Schedule\nDESCRIPTION: Create a new schedule for a deployment with options for interval, cron, or rrule-based scheduling.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule create [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Role for ECS Task Execution using AWS CLI\nDESCRIPTION: This AWS CLI command creates an IAM role named 'ecsTaskExecutionRole' using the trust policy defined in the JSON file.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naws iam create-role \\\n    --role-name ecsTaskExecutionRole \\\n    --assume-role-policy-document file://ecs-trust-policy.json\n```\n\n----------------------------------------\n\nTITLE: Listing Prefect Cloud Workspaces in Bash\nDESCRIPTION: This command lists the available Prefect Cloud workspaces for the current user. It helps in verifying workspace access and identifying the active workspace.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud workspace ls\n```\n\n----------------------------------------\n\nTITLE: Starting Local OpenTelemetry Stack for Prefect\nDESCRIPTION: This command starts the local OpenTelemetry stack in the background, including Jaeger for trace viewing at http://localhost:16686 and Prometheus for metrics at http://localhost:9090.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/local-telemetry/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./local-telemetry/start\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Endpoint for Pausing Deployments\nDESCRIPTION: OpenAPI specification header indicating the endpoint path for pausing a deployment. The endpoint accepts a deployment ID parameter and uses the POST HTTP method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/pause-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/pause_deployment\n```\n\n----------------------------------------\n\nTITLE: Retrieving Flow Run Graph Endpoint\nDESCRIPTION: OpenAPI specification for fetching the graph representation of a specific flow run using its unique identifier. Allows users to visualize the workflow and task relationships.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/read-flow-run-graph-v2.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\nget /api/flow_runs/{id}/graph-v2\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Type Deletion Endpoint Specification\nDESCRIPTION: OpenAPI specification defining the DELETE endpoint for removing block types by their unique identifier. The endpoint path includes a required ID parameter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/delete-block-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/block_types/{id}\n```\n\n----------------------------------------\n\nTITLE: Installing Cosmos DB Support for prefect-azure\nDESCRIPTION: Command to install additional Cosmos DB capabilities for the prefect-azure package after installing the main library.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/index.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect-azure[cosmos_db]\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving ECS Task Role ARN using AWS CLI\nDESCRIPTION: AWS CLI command to retrieve the ARN of the IAM role created for the ECS task. This command outputs the role name and ARN.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\naws iam get-role --role-name taskExecutionRole --query 'Role.[RoleName, Arn]' --output text\n```\n\n----------------------------------------\n\nTITLE: OpenAPI DELETE Endpoint for Worker Deletion\nDESCRIPTION: Defines the DELETE endpoint for deleting a worker from a specific work pool, using the worker's name and the work pool's name as path parameters. This operation requires knowledge of the work pool name and the worker's name to correctly identify and delete the worker.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-pools/delete-worker.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\n\"openapi: delete /api/work_pools/{work_pool_name}/workers/{name}\"\n```\n\n----------------------------------------\n\nTITLE: Deployment Actions Structure\nDESCRIPTION: Defines the structure and requirements for deployment actions within the prefect.yaml file, specifying the format for the build, push, and pull actions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/prefect-yaml.mdx#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsection:\n- prefect_package.path.to.importable.step:\n  id: \"step-id\" # optional\n  requires: \"pip-installable-package-spec\" # optional\n  kwarg1: value\n  kwarg2: more-values\n```\n\n----------------------------------------\n\nTITLE: Login to Coiled\nDESCRIPTION: This command authenticates with the Coiled platform, allowing Prefect to execute flows on Coiled's serverless infrastructure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n\"coiled login\"\n```\n\n----------------------------------------\n\nTITLE: Reset Concurrency Limit\nDESCRIPTION: Resets the concurrency limit slots for a specified tag.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_4\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit reset [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Concurrency Limits Filter\nDESCRIPTION: YAML specification defining the OpenAPI endpoint for filtering concurrency limits through a POST request to /api/v2/concurrency_limits/filter.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/read-all-concurrency-limits-v2.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/v2/concurrency_limits/filter\n```\n\n----------------------------------------\n\nTITLE: Markdown Tables - Workspace Level Roles Definition\nDESCRIPTION: Defines the built-in workspace-level roles (Viewer, Runner, Developer, Owner, Worker) and their associated permissions in Prefect Cloud.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/manage-roles.mdx#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Role      | Abilities                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| --------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Viewer    | - View flow runs within a workspace. <br /> - View deployments within a workspace. <br /> - View all work pools within a workspace. <br /> - View all blocks within a workspace. <br /> - View all automations within a workspace. <br /> - View workspace handle and description.                                                                                                                                                                |\n| Runner    | All Viewer abilities, _plus_: <br /> - Run deployments within a workspace.                                                                                                                                                                                                                                                                                                                                                                         |\n| Developer | All Runner abilities, _plus_: <br /> - Run flows within a workspace. <br /> - Delete flow runs within a workspace. <br /> - Create, edit, and delete deployments within a workspace. <br /> - Create, edit, and delete work pools within a workspace. <br /> - Create, edit, and delete all blocks and their secrets within a workspace. <br /> - Create, edit, and delete automations within a workspace. <br /> - View all workspace settings. |\n| Owner     | All Developer abilities, _plus_: <br /> - Add and remove account members, and set their role within a workspace. <br /> - Set the workspace's default workspace role for all users in the account. <br /> - Set, view, edit workspace settings.    |\n| Worker     | The minimum scopes required for a worker to poll for and submit work.|\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub Actions Workflow Directory Structure\nDESCRIPTION: Creates the necessary directory structure for GitHub Actions workflows to enable CI/CD for Prefect deployments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p .github/workflows\n```\n\n----------------------------------------\n\nTITLE: Cloning Forked Prefect Repository\nDESCRIPTION: Commands to clone a forked version of the Prefect repository to local machine and navigate to the project directory.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/fork.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/GITHUB-USERNAME/prefect.git\ncd prefect\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Path Definition - GET Concurrency Limit Endpoint\nDESCRIPTION: YAML definition for a GET endpoint that retrieves concurrency limit information. The endpoint accepts either an ID or name parameter to identify the specific limit to fetch.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/read-concurrency-limit-v2.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/v2/concurrency_limits/{id_or_name}\n```\n\n----------------------------------------\n\nTITLE: Set Task Run State Endpoint\nDESCRIPTION: OpenAPI specification for an endpoint that allows updating the state of a specific task run using its unique identifier. Enables state management and tracking of workflow task execution status.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/task-runs/set-task-run-state.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\nopenapi: post /api/task_runs/{id}/set_state\n```\n\n----------------------------------------\n\nTITLE: Populating Prefect Server with Test Data\nDESCRIPTION: Executes a script to populate the Prefect server with test data, including creating a work pool and deployments. This step is essential for performance testing with realistic data.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./load_testing/populate-server.sh\n```\n\n----------------------------------------\n\nTITLE: Implementing Worker Run Method\nDESCRIPTION: Method signature for implementing the required run method in a custom worker. Shows the method parameters and return type structure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nasync def run(\n    self,\n    flow_run: FlowRun,\n    configuration: BaseJobConfiguration,\n    task_status: Optional[anyio.abc.TaskStatus] = None,\n) -> BaseWorkerResult:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Starting Local Telemetry Stack\nDESCRIPTION: Executes the script to start the local telemetry stack. This setup is required for collecting performance metrics and traces from the Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./load_testing/local-telemetry/start\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Definition for Deployment Schedule\nDESCRIPTION: YAML specification defining the API route for updating a deployment's schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/schedule-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/schedule\n```\n\n----------------------------------------\n\nTITLE: Sample Output from PrefectClient Flow Query\nDESCRIPTION: This snippet shows the expected output from running the PrefectClient flow query example. It displays the names and IDs of 5 flows retrieved from the Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncat-facts 58ed68b1-0201-4f37-adef-0ea24bd2a022\ndog-facts e7c0403d-44e7-45cf-a6c8-79117b7f3766\nsloth-facts 771c0574-f5bf-4f59-a69d-3be3e061a62d\ncapybara-facts fbadaf8b-584f-48b9-b092-07d351edd424\nlemur-facts 53f710e7-3b0f-4b2f-ab6b-44934111818c\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Definition - Install System Block Types\nDESCRIPTION: YAML definition for the API endpoint that handles installation of system block types\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/install-system-block-types.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_types/install_system_block_types\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Prefect Server and Worker\nDESCRIPTION: Commands to uninstall the Prefect server and worker Helm releases.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nhelm uninstall prefect-worker\nhelm uninstall prefect-server\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Branch\nDESCRIPTION: Git command to create and checkout a new branch for implementing fixes or features, with a naming convention that references the issue number.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/fork.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b fix-for-issue-NUM\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Flow Run Notification Policies Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the POST /api/flow_run_notification_policies/ endpoint. It outlines the structure and requirements for creating or updating flow run notification policies through the API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-run-notification-policies/create-flow-run-notification-policy.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/flow_run_notification_policies/\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Worker with Basic Authentication\nDESCRIPTION: YAML configuration for enabling basic authentication in the Prefect worker deployment.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nworker:\n  apiConfig: selfHostedServer\n  config:\n    workPool: kube-test\n  selfHostedServerApiConfig:\n    apiUrl: http://prefect-server.prefect.svc.cluster.local:4200/api\n    basicAuth:\n      enabled: true\n      existingSecret: worker-auth-secret\n```\n\n----------------------------------------\n\nTITLE: Install Modal package using pip\nDESCRIPTION: This command installs the `modal` package using pip, which is a prerequisite for using Modal as a serverless compute platform with Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/serverless.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"pip install modal\"\n```\n\n----------------------------------------\n\nTITLE: Base Deployments Command\nDESCRIPTION: Root command for managing Prefect deployments with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployments.mdx#2025-04-21_snippet_0\n\nLANGUAGE: command\nCODE:\n```\nprefect deployments [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Defining GET Endpoint for Block Document Retrieval in OpenAPI\nDESCRIPTION: This YAML snippet defines an OpenAPI specification for a GET endpoint. The endpoint retrieves block documents by combining a block type slug and a specific document name. It's designed to be part of a RESTful API for managing block types and their associated documents.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/read-block-document-by-name-for-block-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_types/slug/{slug}/block_documents/name/{block_document_name}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification - POST /api/concurrency_limits/tag/{tag}/reset\nDESCRIPTION: OpenAPI/Swagger specification defining the endpoint path and parameters for resetting concurrency limits by tag.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/reset-concurrency-limit-by-tag.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/concurrency_limits/tag/{tag}/reset\n```\n\n----------------------------------------\n\nTITLE: Starting Web Server for Minimal Local Setup\nDESCRIPTION: Starts the FastAPI web server using uvicorn with hot reloading enabled and the specified requirements.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/deferred-tasks.mdx#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nuv run --with-requirements requirements.txt uvicorn api:app --reload\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository for MLB Pipeline Tutorial\nDESCRIPTION: Command to clone the GitHub repository containing the code examples for the MLB pipeline tutorial.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/PrefectHQ/dev-day-zoom-out.git\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI GET Endpoint for Latest Artifact Retrieval in YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for a GET endpoint that retrieves the latest version of an artifact by its key. It specifies the path parameters and potentially other details of the API endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/read-latest-artifact.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/artifacts/{key}/latest\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Flow Run Resume Endpoint\nDESCRIPTION: Defines the HTTP POST endpoint for resuming a specific flow run identified by its unique ID in the Prefect system\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/resume-flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nopenapi: post /api/flow_runs/{id}/resume\n```\n\n----------------------------------------\n\nTITLE: Configuring Deployment Schedule in YAML\nDESCRIPTION: This YAML snippet sets the schedule for the Prefect deployment, specifying the entry point and how often the flow runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n  name: prefect-modal-example\n  description: \"Your first deployment which runs daily at 12:00 on Modal\"\n  entrypoint: prefect_modal.flows.flow1:main\n  schedules:\n  - cron: '0 12 * * *'\n    timezone: America/New_York\n    active: true\n```\n\n----------------------------------------\n\nTITLE: Exporting Blocks Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'blocks', containing links to the Prefect documentation for blocks, including the CLI, API, and Terraform resources.  This offers a centralized location to find documentation on managing blocks in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nexport const blocks = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/block\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Blocks\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/block\",\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing ML Training Pipeline with Mermaid Sequence Diagram\nDESCRIPTION: This diagram illustrates the flow of data and processes in the machine learning training pipeline, including interactions between the Data Engineer, S3, Prefect Cloud, and SageMaker.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    actor Data Engineer\n    Data Engineer->>S3: Upload training data\n    S3->>S3: Trigger EventBridge rule\n    S3->>Prefect Cloud: Send event to webhook\n    Note over Prefect Cloud: Start model training\n    Prefect Cloud->>Prefect Cloud: Trigger automation\n    Prefect Cloud->>Prefect Cloud: Run deployment\n    Prefect Cloud->>SageMaker: Train model\n    activate SageMaker\n    Note over SageMaker: Provision instance\n    SageMaker-->>Prefect Cloud: \n    deactivate SageMaker\n    Data Engineer-->>Prefect Cloud: View model performance in logs\n    Prefect Cloud->>S3: Save fitted model\n    S3->>S3: Trigger EventBridge rule\n    S3->>Prefect Cloud: Send event to webhook\n    Note over Prefect Cloud: Start model inference\n    Prefect Cloud->>Prefect Cloud: Trigger automation\n    Prefect Cloud->>Prefect Cloud: Run deployment\n    Data Engineer-->>Prefect Cloud: View predictions in logs\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Flow Run States Endpoint\nDESCRIPTION: OpenAPI specification for the GET /api/flow_run_states/ endpoint. Defines the API structure for retrieving flow run states.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-run-states/read-flow-run-states.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/flow_run_states/\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Definition for Flow Run Count\nDESCRIPTION: OpenAPI specification defining the POST endpoint at /api/flow_runs/count. This endpoint appears to be used for counting flow runs in the Prefect system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/count-flow-runs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/flow_runs/count\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Running WebSocket Proxy Test in Bash\nDESCRIPTION: These commands install the required dependencies using uv, build and start the Docker containers for the server and proxy, and then run the Python client to test the connection.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/scripts/proxy-test/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ uv pip install -r requirements.txt\n$ docker compose up --build\n$ python client.py\n```\n\n----------------------------------------\n\nTITLE: Defining DELETE Endpoint for Deployments in OpenAPI YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for a DELETE endpoint to remove a deployment. It specifies the path '/api/deployments/{id}' where {id} is the unique identifier of the deployment to be deleted.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/delete-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/deployments/{id}\n```\n\n----------------------------------------\n\nTITLE: Health Check API Endpoint\nDESCRIPTION: This snippet defines the API endpoint for a health check. It uses the HTTP GET method and specifies the endpoint path as /api/health.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/root/health-check.mdx#2025-04-21_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\n\"openapi: get /api/health\"\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI DELETE Endpoint for Block Document Removal\nDESCRIPTION: OpenAPI specification that defines the DELETE endpoint for removing a block document by its ID. The endpoint path includes the document ID parameter for targeting specific documents.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/delete-block-document.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/block_documents/{id}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Definition for GET Automations Related to a Resource Endpoint\nDESCRIPTION: OpenAPI specification for the GET endpoint that retrieves automations related to a specific resource identified by resource_id.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/read-automations-related-to-resource.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/automations/related-to/{resource_id}\n```\n\n----------------------------------------\n\nTITLE: Markdown Tables - Block Permissions\nDESCRIPTION: Defines the available permissions for blocks in custom roles within Prefect Cloud workspaces.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/manage-roles.mdx#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| Permission                      | Description                                                                                                                          |\n| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n| View blocks                     | User can see configured blocks within a workspace.                                                                                   |\n| View secret block data          | User can see configured blocks and their secrets within a workspace. Includes permissions of **View blocks**.                        |\n| Create, edit, and delete blocks | User can create, edit, and delete blocks within a workspace. Includes permissions of **View blocks** and **View secret block data**. |\n```\n\n----------------------------------------\n\nTITLE: Logging into Coiled\nDESCRIPTION: Logs the user into Coiled to manage cloud resources. Requires a Coiled account.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/coiled.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncoiled login\n```\n\n----------------------------------------\n\nTITLE: Resuming a Prefect work pool\nDESCRIPTION: Resumes a paused work pool, allowing it to accept new work items again.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_5\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool resume [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Flow Run History Endpoint\nDESCRIPTION: This snippet defines the OpenAPI specification for a POST endpoint that retrieves flow run history from the /api/ui/flow_runs/history endpoint. It likely outlines the request and response schemas required for interacting with this endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/read-flow-run-history.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nopenapi: post /api/ui/flow_runs/history\n---\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for GET Block Documents by Slug Endpoint\nDESCRIPTION: OpenAPI specification defining the GET endpoint for retrieving block documents by slug in the Prefect API. The endpoint path is '/api/block_types/slug/{slug}/block_documents'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/read-block-documents-for-block-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_types/slug/{slug}/block_documents\n```\n\n----------------------------------------\n\nTITLE: Displaying Project Badges in Markdown\nDESCRIPTION: This snippet shows how to create centered badges for PyPI version and download statistics using Markdown and HTML. It utilizes shields.io for generating the badge images.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-github/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-github/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-github?color=26272B&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-github/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-github?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Directory Navigation Command\nDESCRIPTION: Bash command to navigate to the rollbacks example directory.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/3_rollbacks\n```\n\n----------------------------------------\n\nTITLE: Defining DELETE Endpoint for Flow Run Notification Policies in OpenAPI\nDESCRIPTION: This YAML snippet specifies the OpenAPI route for deleting a flow run notification policy. It defines the HTTP method as DELETE and includes a path parameter for the policy ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-run-notification-policies/delete-flow-run-notification-policy.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/flow_run_notification_policies/{id}\n```\n\n----------------------------------------\n\nTITLE: Inspecting Work Pool Details Using Prefect CLI\nDESCRIPTION: The command to view detailed configuration metadata for a specific work pool identified by name, including ID, creation timestamp, type, and status.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/work-pools.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool inspect 'test-pool'\n```\n\n----------------------------------------\n\nTITLE: Building Production Bundle\nDESCRIPTION: Compiles and minifies the application for production deployment, creating optimized build artifacts.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Worker Heartbeat API Endpoint Definition\nDESCRIPTION: OpenAPI specification for registering worker heartbeats in a specific work pool, used to maintain worker connectivity and status tracking\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-pools/worker-heartbeat.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\nopenapi: post /api/work_pools/{work_pool_name}/workers/heartbeat\n```\n\n----------------------------------------\n\nTITLE: Exporting Deployments Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'deployments' that stores URLs to the Prefect CLI deployment documentation, the Prefect Cloud API documentation for deployments, and the Terraform resource documentation for deployments.  These links centralize access to deployment-related resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport const deployments = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/deployment\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Deployments\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/deployment\",\n}\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Concurrency Limit Increment Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI details for the POST endpoint used to increment concurrency limits in Prefect. It defines the API path, HTTP method, and likely includes request/response schemas and authentication requirements.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits-v2/bulk-increment-active-slots.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/v2/concurrency_limits/increment\n```\n\n----------------------------------------\n\nTITLE: Exporting Variables Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'variables' that contains links to the Prefect documentation for variables, including CLI commands, API references, and Terraform resources. It offers quick access to documentation for managing variables within Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport const variables = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/variable\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Variables\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/variable\",\n}\n```\n\n----------------------------------------\n\nTITLE: Starting the Prefect Server\nDESCRIPTION: Command to start a local Prefect server, which provides a UI for monitoring workflow executions at http://localhost:4200.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect server start\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Definition - GET Concurrency Limit\nDESCRIPTION: OpenAPI specification defining the endpoint path for retrieving concurrency limit details by ID. The endpoint uses a URL parameter for the concurrency limit ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/read-concurrency-limit.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/concurrency_limits/{id}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Run States API Endpoint\nDESCRIPTION: OpenAPI specification for accessing task run states, defining the HTTP GET method for querying task run state information in the Prefect platform\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/task-run-states/read-task-run-states.mdx#2025-04-21_snippet_0\n\nLANGUAGE: OpenAPI\nCODE:\n```\nopenapi: get /api/task_run_states/\n```\n\n----------------------------------------\n\nTITLE: Correct Module Import in __init__ Files\nDESCRIPTION: Demonstrates the correct way to use relative imports in __init__ files for exposing objects from submodules, which is required for type checkers to understand the exposed interface.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Correct\nfrom .flows import flow\n```\n\n----------------------------------------\n\nTITLE: Navigating to Tutorial Code Directory\nDESCRIPTION: Bash command to change directory to the location of the tutorial code within the cloned repository.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/resilience-and-deployment.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/\n```\n\n----------------------------------------\n\nTITLE: Cloning Forked Prefect Repository\nDESCRIPTION: Command to clone the forked Prefect repository to the local machine. This is the first step in contributing to an existing integration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/contribute-integrations.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/your-username/prefect.git\n```\n\n----------------------------------------\n\nTITLE: Provisioning infrastructure for a Prefect work pool\nDESCRIPTION: Provisions the necessary infrastructure for a work pool, if supported by the work pool type.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/work-pool.mdx#2025-04-21_snippet_7\n\nLANGUAGE: command\nCODE:\n```\nprefect work-pool provision-infrastructure [OPTIONS] NAME\n```\n\n----------------------------------------\n\nTITLE: Frontmatter Configuration for SDK Documentation\nDESCRIPTION: YAML frontmatter block defining metadata for the Prefect Kubernetes SDK documentation page, including the title and reference URL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_kubernetes/\"\n---\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint Specification for Counting Task Runs\nDESCRIPTION: YAML definition of a POST endpoint used to count task runs within flow runs. The endpoint path is /api/ui/flow_runs/count-task-runs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/count-task-runs-by-flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/ui/flow_runs/count-task-runs\n```\n\n----------------------------------------\n\nTITLE: Correct Submodule Import\nDESCRIPTION: Shows the correct way to expose submodules using relative imports in __init__ files.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Correct\nfrom . import flows\n```\n\n----------------------------------------\n\nTITLE: Example Windows Scripts Folder Path\nDESCRIPTION: Example path to the Python local packages Scripts folder on Windows, which may need to be added to the Path environment variable.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/get-started/install.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nC:\\Users\\MyUserNameHere\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts\n```\n\n----------------------------------------\n\nTITLE: Defining DELETE /api/artifacts/{id} Endpoint in OpenAPI\nDESCRIPTION: YAML specification for the DELETE endpoint that removes a specific artifact identified by its ID. This is part of the Prefect API for managing artifacts.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/delete-artifact.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/artifacts/{id}\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Namespace for Prefect\nDESCRIPTION: Commands to create a new namespace for Prefect and set the current context to use it.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/server/examples/helm.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create namespace prefect\nkubectl config set-context --current --namespace=prefect\n```\n\n----------------------------------------\n\nTITLE: DBT Core Settings Configuration\nDESCRIPTION: Example of configuring DBT Core settings using PrefectDbtSettings class.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-dbt/index.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt import PrefectDbtRunner, PrefectDbtSettings\n\n@flow\ndef run_dbt():\n    PrefectDbtRunner(\n        settings=PrefectDbtSettings(\n            project_dir=\"test\",\n            profiles_dir=\"examples/run_dbt\"\n        )\n    ).invoke([\"build\"])\n\nif __name__ == \"__main__\":\n    run_dbt()\n```\n\n----------------------------------------\n\nTITLE: Circular Dependency Resolution\nDESCRIPTION: Shows how to handle circular dependencies by deferring imports within functions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n## This function in `settings.py` requires a method from the global `context` but the context\n## uses settings\ndef from_context():\n    from prefect.context import get_profile_context\n\n    ...\n```\n\n----------------------------------------\n\nTITLE: OpenAPI DELETE Flow Run Endpoint Definition\nDESCRIPTION: OpenAPI/Swagger specification for the DELETE /api/flow_runs/{id} endpoint that allows removal of flow runs by their unique identifier.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/delete-flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/flow_runs/{id}\n```\n\n----------------------------------------\n\nTITLE: Exporting Events Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'events', containing links to the Prefect documentation for events, including CLI commands, API references, and Terraform resources. This allows for easy access to documentation related to Prefect events.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nexport const events = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/event\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Events\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/automation\",\n}\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI GET Endpoint for Retrieving Automation by ID\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for a GET endpoint to retrieve automation details by ID. It defines the path, parameters, and potential responses for the /api/automations/{id} endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/read-automation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/automations/{id}\n```\n\n----------------------------------------\n\nTITLE: Testing API Endpoints with Incorrect URL Format in Python\nDESCRIPTION: Example of a test function that will fail with a 307 redirect because it's missing a trailing slash in the API route URL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nasync def test_example(client):\n    response = await client.post(\"/my_route\")\n    assert response.status_code == 201\n```\n\n----------------------------------------\n\nTITLE: Setting Execute Permissions for Scripts\nDESCRIPTION: Commands to make the performance testing scripts executable. This step is necessary before running the scripts for starting the telemetry stack, running the server, and populating test data.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./load_testing/local-telemetry/start\n./load_testing/run-server.sh\n./load_testing/populate-server.sh\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Artifact Count Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the POST /api/artifacts/count endpoint. It includes the request body schema and response structure for retrieving the count of artifacts based on specified criteria.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/count-artifacts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/artifacts/count\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Endpoint for Artifacts Latest Count in YAML\nDESCRIPTION: YAML specification for the OpenAPI endpoint that counts the latest artifacts. The endpoint is defined with a POST method to the '/api/artifacts/latest/count' path.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/artifacts/count-latest-artifacts.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/artifacts/latest/count\n```\n\n----------------------------------------\n\nTITLE: Creating React Component for Helm Chart Reference\nDESCRIPTION: Exports a React functional component that takes name and href props to generate a paragraph with a link to Prefect Helm charts documentation. The component uses JSX syntax to combine HTML elements with dynamic JavaScript values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/helm.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const HELM = ({ name, href }) => (\n<p>You can manage {name} with the <a href={href}>Prefect Helm charts</a>.</p>\n);\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Endpoint Definition for Deployment Retrieval\nDESCRIPTION: OpenAPI specification for the GET /api/deployments/name/{flow_name}/{deployment_name} endpoint that retrieves deployment details based on flow name and deployment name path parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/read-deployment-by-name.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/deployments/name/{flow_name}/{deployment_name}\n```\n\n----------------------------------------\n\nTITLE: Registering prefect-redis block types\nDESCRIPTION: This command registers the block types in the prefect-redis module to make them available for use in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-redis/index.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect block register -m prefect_redis\n```\n\n----------------------------------------\n\nTITLE: Toggling Individual IP Entries\nDESCRIPTION: Command to toggle the status of individual IP addresses in the allowlist, enabling or disabling them without removal.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/manage-users/secure-access-by-ip-address.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nprefect cloud ip-allowlist toggle <ip-address>\n```\n\n----------------------------------------\n\nTITLE: Defining CLI Management Component in React\nDESCRIPTION: React functional component that takes name and href props to display CLI management information with a link to Prefect documentation. The component renders a paragraph with dynamic content referencing the CLI tool name.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/cli.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const CLI = ({ name, href }) => (\n<p>You can manage {name} with the <a href={href}>Prefect CLI</a>.</p>\n);\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Documents Patch Endpoint Definition\nDESCRIPTION: YAML definition for the PATCH /api/block_documents/{id} API endpoint that specifies the endpoint path and metadata.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/update-block-document-data.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/block_documents/{id}\n```\n\n----------------------------------------\n\nTITLE: Rendering API Reference Component in React/JSX\nDESCRIPTION: A React functional component that takes name and href props to render a paragraph with a dynamic API reference link. The component creates a text message that indicates how to manage a specific feature through the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/api.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\nexport const API = ({ name, href }) => (\n<p>You can manage {name} with the <a href={href}>Prefect API</a>.</p>\n);\n```\n\n----------------------------------------\n\nTITLE: Registering ECS Task Definition using AWS CLI\nDESCRIPTION: AWS CLI command to register the ECS task definition using the JSON file created earlier. This step is necessary before creating an ECS service.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\naws ecs register-task-definition --cli-input-json file://task-definition.json\n```\n\n----------------------------------------\n\nTITLE: Incorrect Module Import in __init__ Files\nDESCRIPTION: Shows the incorrect way of importing modules in __init__ files using absolute imports instead of relative imports.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Wrong\nfrom prefect.flows import flow\n```\n\n----------------------------------------\n\nTITLE: OpenAPI CSRF Token Endpoint Definition\nDESCRIPTION: OpenAPI specification for a GET endpoint that returns a CSRF token. The endpoint path is /api/csrf-token.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/create-csrf-token.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/csrf-token\n```\n\n----------------------------------------\n\nTITLE: Exporting Workers Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'workers' that contains a link to the Prefect Helm chart repository for workers. This provides a direct link to the Helm chart for deploying Prefect workers.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nexport const workers = {\n    helm: \"https://github.com/PrefectHQ/prefect-helm/tree/main/charts/prefect-server\",\n}\n```\n\n----------------------------------------\n\nTITLE: Using External Reference Snippets in Documentation\nDESCRIPTION: An example of how to import and use Terraform provider snippets for consistent resource documentation, demonstrating the snippet import syntax and implementation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/docs-contribute.mdx#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { TF } from \"/snippets/resource-management/terraform.mdx\"\nimport { deployments } from \"/snippets/resource-management/vars.mdx\"\n\n<TF name=\"deployments\" href={deployments.tf} />\n```\n\n----------------------------------------\n\nTITLE: Building and Testing Prefect Client Library\nDESCRIPTION: Process documentation for building prefect-client through three methods: automated PR creation, Github release publishing, and manual local build. Includes smoke testing and packaging configuration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/client/INFO.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Overview\n\nThis directory contains files for building and publishing the `prefect-client` \nlibrary. `prefect-client` is built by removing source code from `prefect` and \npackages its own `requirements.txt` and `setup.py`. This process can happen \nin one of three ways:\n\n- automatically whenever a PR is created (see \n`.github/workflows/prefect-client.yaml`)\n- automatically whenever a Github release is published (see \n`.github/workflows/prefect-client-publish.yaml`)\n- manually by running the `client/build_client.sh` script locally\n\nNote that whenever a Github release is published the `prefect-client` will \nnot only get built but will also be distributed to PyPI. `prefect-client` \nreleases will have the same versioning as `prefect` - only the package names \nwill be different.\n\nThis directory also includes a \"minimal\" flow that is used for smoke \ntests to ensure that the built `prefect-client` is functional.\n\nIn general, these builds, smoke tests, and publish steps should be transparent. \nIt these automated steps fail, use the `client/build_client.sh` script to run \nthe build and smoke test locally and iterate on a fix. The failures will likely \nbe from:\n\n- including a new dependency that is not installed in `prefect-client`\n- re-arranging or adding files in such a way that a necessary file is rm'd at \n  build time\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Schema Validation Endpoint Configuration\nDESCRIPTION: Defines a POST endpoint for validating OpenAPI schema configurations, allowing clients to submit schema data for server-side validation\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/ui/validate-obj.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/ui/schemas/validate\n```\n\n----------------------------------------\n\nTITLE: Creating Responsive Arcade Iframe Component in React\nDESCRIPTION: A React functional component that creates a responsive container for iframe content with specific aspect ratio and styling. The component accepts src and title props and implements proper iframe attributes for fullscreen and clipboard functionality.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/arcade.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const Arcade = ({ src, title }) => (\n    <div style={{\n      position: \"relative\",\n      paddingBottom: \"calc(58.259468170829976% + 41px)\",\n      height: \"0\",\n      width: \"100%\"\n    }}>\n      <iframe\n        src={src}\n        title={title}\n        frameborder=\"0\"\n        loading=\"lazy\"\n        webkitallowfullscreen=\"true\"\n        mozallowfullscreen=\"true\"\n        allowfullscreen=\"true\"\n        allow=\"clipboard-write\"\n        style={{\n          position: \"absolute\",\n          top: \"0\",\n          left: \"0\",\n          width: \"100%\",\n          height: \"100%\",\n          colorScheme: \"light\"\n        }}>\n      </iframe>\n    </div>\n)\n```\n\n----------------------------------------\n\nTITLE: Rendering Integration Cards Grid in JSX\nDESCRIPTION: A CardGroup component that displays a 4-column grid of integration cards. Each card shows an integration's logo, documentation link, and maintainer information. The component uses custom Card elements to organize the content.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/index.md#2025-04-21_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={4}  className=\"text-center\">\n    <Card title=\"AWS\">\n        <a href=\"/integrations/prefect-aws\"> <img src=\"/images/integrations/aws.png\" alt=\"prefect-aws\"/>\n        </a>\n        Maintained by <a href=\"https://prefect.io\"> Prefect </a>\n    </Card>\n    /* Additional cards omitted for brevity */\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Definition: DELETE Flow Endpoint\nDESCRIPTION: This snippet defines the OpenAPI specification for a DELETE endpoint that deletes a flow based on its ID. The endpoint path is `/api/flows/{id}`, where `{id}` is a path parameter representing the flow's identifier.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flows/delete-flow.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nopenapi: delete /api/flows/{id}\n---\n```\n\n----------------------------------------\n\nTITLE: CLI Placeholder Example\nDESCRIPTION: Demonstrates the proper format for showing CLI commands with placeholder values.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_10\n\nLANGUAGE: plaintext\nCODE:\n```\nCreate a work queue with tags:\n    prefect work-queue create '<WORK QUEUE NAME>' -t '<OPTIONAL TAG 1>' -t '<OPTIONAL TAG 2>'\n```\n\n----------------------------------------\n\nTITLE: Failed Test Output for Missing Trailing Slash in API Endpoint\nDESCRIPTION: Error output when a test fails due to missing trailing slash, showing a 307 Temporary Redirect instead of the expected 201 status code.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nE       assert 307 == 201\nE        +  where 307 = <Response [307 Temporary Redirect]>.status_code\n```\n\n----------------------------------------\n\nTITLE: Creating a Flow Database Fixture in Pytest\nDESCRIPTION: A pytest fixture example that creates a flow object in the database for testing purposes. The fixture uses the session parameter to interact with the database, creates a new flow using models.flows.create_flow, commits the session to make changes visible, and returns the model object.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/tests/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture\nasync def flow(session):\n    model = await models.flows.create_flow(\n        session=session, \n        flow=schemas.actions.FlowCreate(name=\"my-flow\"),\n    )\n    await session.commit()\n    return model\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect-Slack\nDESCRIPTION: This bash snippet demonstrates how to install the 'prefect-slack' package, which is necessary for integrating Slack with Prefect tasks. Ensure that you have Python 3.9+ installed and preferably use a virtual environment manager like pipenv, conda, or virtualenv before running the installation command.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-slack/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-slack\n```\n\n----------------------------------------\n\nTITLE: Block Types Management Command\nDESCRIPTION: Root command for managing block types with various subcommands.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks types [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for POST /api/events/count-by/{countable} Endpoint in YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the POST /api/events/count-by/{countable} endpoint. It specifies the endpoint's path, HTTP method, and other relevant metadata for API documentation and integration.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/events/count-account-events.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/events/count-by/{countable}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Endpoint - Admin Version\nDESCRIPTION: YAML specification for the admin version endpoint using OpenAPI format. This endpoint allows retrieving version information via GET request.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/admin/read-version.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/admin/version\n```\n\n----------------------------------------\n\nTITLE: OpenAPI DELETE Endpoint Definition for Deployment Schedule Removal\nDESCRIPTION: OpenAPI specification defining the endpoint path for deleting a specific schedule from a deployment. Uses path parameters for both deployment ID and schedule ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/delete-deployment-schedule.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: delete /api/deployments/{id}/schedules/{schedule_id}\n```\n\n----------------------------------------\n\nTITLE: Displaying Badges for Prefect Kubernetes Package in Markdown\nDESCRIPTION: This snippet shows how to display PyPI version and download statistics badges for the prefect-kubernetes package using Markdown syntax. It includes links to the PyPI page and download statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-kubernetes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-kubernetes/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-kubernetes?color=26272B&labelColor=090422\"></a>\n    <a href=\"https://pypistats.org/packages/prefect-kubernetes/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-kubernetes?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-gcp package using pip\nDESCRIPTION: This command installs the prefect-gcp package using pip, allowing users to integrate Google Cloud Platform services with Prefect workflows.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-gcp/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install prefect-gcp\n```\n\n----------------------------------------\n\nTITLE: Exporting Automations Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'automations' which holds links to Prefect's documentation concerning automation. The links cover the CLI, API, and Terraform, providing a consolidated point for accessing relevant resources.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nexport const automations = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/automation\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Automations\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/automation\",\n}\n```\n\n----------------------------------------\n\nTITLE: Patch Work Queue by ID using OpenAPI\nDESCRIPTION: This YAML snippet defines an OpenAPI endpoint for patching a work queue. It uses the PATCH method on the `/api/work_queues/{id}` endpoint, where `{id}` is a placeholder for the work queue's identifier. This allows for partial updates to an existing work queue.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-queues/update-work-queue.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"openapi: patch /api/work_queues/{id}\"\n```\n\n----------------------------------------\n\nTITLE: Markdown Frontmatter for SDK Documentation\nDESCRIPTION: YAML frontmatter defining title and URL for the Prefect Bitbucket integration SDK documentation page.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect-bitbucket/\"\n---\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI PATCH Endpoint for Automations in Prefect\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the PATCH /api/automations/{id} endpoint. It indicates that this is an API endpoint used for updating automation resources in the Prefect system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/patch-automation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/automations/{id}\n```\n\n----------------------------------------\n\nTITLE: Worker Base Job Template Structure\nDESCRIPTION: Example YAML structure showing the resulting base job template when combining worker configuration and template variables. Defines the schema for job configuration and variable properties.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\njob_configuration:\n    name: \"{{ name }}\"\n    env: \"{{ env }}\"\n    labels: \"{{ labels }}\"\n    command: \"{{ command }}\"\n    memory: \"{{ memory_request }}Mi\"\n    cpu: \"{{ cpu_request }}m\"\nvariables:\n    type: object\n    properties:\n        name:\n          title: Name\n          description: Name given to infrastructure created by a worker.\n          type: string\n        env:\n          title: Environment Variables\n          description: Environment variables to set when starting a flow run.\n          type: object\n          additionalProperties:\n            type: string\n        labels:\n          title: Labels\n          description: Labels applied to infrastructure created by a worker.\n          type: object\n          additionalProperties:\n            type: string\n        command:\n          title: Command\n          description: The command to use when starting a flow run. In most cases,\n            this should be left blank and the command will be automatically generated\n            by the worker.\n          type: string\n        memory_request:\n            title: Memory Request\n            description: Memory allocation for the execution environment.\n            type: integer\n            default: 1024\n        cpu_request:\n            title: CPU Request\n            description: CPU allocation for the execution environment.\n            type: integer\n            default: 500\n```\n\n----------------------------------------\n\nTITLE: Configuring Robot Access Rules in robots.txt\nDESCRIPTION: Basic robots.txt configuration that allows unrestricted access to all user agents. The empty Disallow directive indicates no paths are blocked from crawling.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui/public/robots.txt#2025-04-21_snippet_0\n\nLANGUAGE: robots.txt\nCODE:\n```\nUser-agent: *\nDisallow:\n```\n\n----------------------------------------\n\nTITLE: Exporting Task Run Concurrency Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'task_run_concurrency' containing links to Prefect's documentation on task run concurrency limits, including the CLI, API, and Terraform resources.  This helps users quickly access relevant documentation for managing concurrency.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nexport const task_run_concurrency = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/concurrency-limit\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Concurrency-Limits\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/task_run_concurrency_limit\",\n}\n```\n\n----------------------------------------\n\nTITLE: Resource Warning Error Message in FlowRunner Tests\nDESCRIPTION: Error output showing a ResourceWarning and PytestUnraisableExceptionWarning that occurs when connections to services like Docker or Kubernetes are not properly closed in tests.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/manage/cloud/troubleshoot-cloud.mdx#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nE               pytest.PytestUnraisableExceptionWarning: Exception ignored in: <ssl.SSLSocket fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>\nE\nE               Traceback (most recent call last):\nE                 File \".../pytest_asyncio/plugin.py\", line 306, in setup\nE                   res = await func(**_add_kwargs(func, kwargs, event_loop, request))\nE               ResourceWarning: unclosed <ssl.SSLSocket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 60605), raddr=('127.0.0.1', 6443)>\n\n.../_pytest/unraisableexception.py:78: PytestUnraisableExceptionWarning\n```\n\n----------------------------------------\n\nTITLE: Adding New Icons to Constants File in TypeScript\nDESCRIPTION: Demonstrates how to import icons from lucide-react and add them to the ICONS constant object. Icons should be imported without the 'Icon' suffix and added alphabetically to maintain organization.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui-v2/src/components/ui/icons/README.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n/** @/components/ui/icons/constants.ts */\nimport {\n\tAlignVerticalJustifyStart,\n\tBan,\n\tCheck, // <---- New Icon to add\n\tChevronDown,\n} from \"lucide-react\";\n\nexport const ICONS = {\n\tAlignVerticalJustifyStart,\n\tBan,\n\tCheck, // <---- New Icon to add\n\tChevronDown,\n} as const;\n```\n\n----------------------------------------\n\nTITLE: Displaying Package Badges in Markdown\nDESCRIPTION: This code snippet demonstrates how to display PyPI version and download statistics badges for the prefect-docker package using Markdown syntax. It includes links to the PyPI page and download statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-docker/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-docker/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-docker?color=26272B&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-docker/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-docker?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Exporting Global Concurrency Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object called 'global_concurrency' containing links to Prefect documentation about global concurrency limits. The links cover the CLI, API, and Terraform resources, making it easier to find the related documentation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nexport const global_concurrency = {\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/global-concurrency-limit\",\n    api: \"https://app.prefect.cloud/api/docs#tag/Concurrency-Limits-V2\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/global_concurrency_limit\",\n}\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Resuming Deployment in YAML\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for a POST endpoint used to resume a deployment. It includes the path with a deployment ID parameter and the HTTP method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/resume-deployment.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/resume_deployment\n```\n\n----------------------------------------\n\nTITLE: Displaying Badges in Markdown for Prefect-Ray Package\nDESCRIPTION: This markdown snippet shows how to display PyPI version and download badges for the prefect-ray package using shields.io. It also includes a centered alignment for the badges.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-ray/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <!--- Insert a cover image here -->\n    <!--- <br> -->\n    <a href=\"https://pypi.python.org/pypi/prefect-ray/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-ray?color=26272B&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-ray/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-ray?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining PUT /api/automations/{id} Endpoint in OpenAPI\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the PUT /api/automations/{id} endpoint. It includes the path parameters, request body schema, and possible response codes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/automations/update-automation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: put /api/automations/{id}\n```\n\n----------------------------------------\n\nTITLE: Defining Testing Scope for Prefect Public API\nDESCRIPTION: Documentation header explaining the scope and constraints for public API testing in Prefect. Tests should only cover user-facing APIs and avoid internal module imports or implementation details.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/tests/public/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Public tests\n\nTests in this module cover Prefect's user-facing API and should not import any internal modules or test any implementation details.\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Flow Module for Azure Container Instance\nDESCRIPTION: Example of a simple flow module that logs a hello message, designed to be run on an Azure Container Instance infrastructure.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect.logging import get_run_logger\n\n@flow\ndef log_hello_flow(name=\"Marvin\"):\n    logger = get_run_logger()\n    logger.info(f\"{name} said hello!\")\n\nif __name__ == \"__main__\":\n    log_hello_flow()\n```\n\n----------------------------------------\n\nTITLE: Markdown Configuration for SDK Documentation\nDESCRIPTION: Configuration metadata for the SDK documentation page, including description and display settings for hiding the table of contents.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/mkdocs/index.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ndescription: Prefect SDK documentation\nhide:\n  - toc\n---\n```\n\n----------------------------------------\n\nTITLE: Customizing DBT Cloud Job Task with Retries\nDESCRIPTION: Python example showing how to customize a pre-configured task from the Prefect DBT Cloud integration by adding retry configuration\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/use-integrations.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\ncustom_run_dbt_cloud_job = trigger_dbt_cloud_job_run_and_wait_for_completion.with_options(\n    name=\"Run My DBT Cloud Job\",\n    retries=2,\n    retry_delay_seconds=10\n)\n\n@flow\ndef run_dbt_job_flow():\n    run_result = custom_run_dbt_cloud_job(\n        dbt_cloud_credentials=DbtCloudCredentials.load(\"my-dbt-cloud-credentials\"),\n        job_id=1\n    )\n\n\nif __name__ == \"__main__\":  \n    run_dbt_job_flow()\n```\n\n----------------------------------------\n\nTITLE: Displaying Package Badges in Markdown\nDESCRIPTION: This code snippet shows how to create centered badges for PyPI version and download statistics using Markdown and HTML. It demonstrates the use of shields.io for generating dynamic badge images.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-shell/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-shell/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-shell?color=0052FF&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-shell/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-shell?color=0052FF&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for GET /api/block_capabilities/ Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the GET /api/block_capabilities/ endpoint. It includes the endpoint path, HTTP method, and likely contains details about request parameters and response structure for querying block capabilities in the Prefect system.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-capabilities/read-available-block-capabilities.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_capabilities/\n```\n\n----------------------------------------\n\nTITLE: Creating a Prefect Flow in Python\nDESCRIPTION: This Python code defines a simple Prefect flow with tasks for printing messages. It includes task and flow decorators for execution management.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-examples/modal.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task()\ndef do_print(param: str) -> None:\n    print(\"Doing the task\")\n    print(param)\n\n@flow(log_prints=True)\ndef run_my_flow(param: str) -> None:\n    print(\"flow 2\")\n    do_print(param)\n\n@flow(log_prints=True)\ndef main(name: str = \"world\", goodbye: bool = False):\n    print(f\"Hello {name} from Prefect! 🤗\")\n    run_my_flow(name)\n    if goodbye:\n        print(f\"Goodbye {name}!\")\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Documents Count Endpoint Definition\nDESCRIPTION: OpenAPI specification defining a POST endpoint for counting block documents. The endpoint path is '/api/block_documents/count'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-documents/count-block-documents.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_documents/count\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Dependencies with uv\nDESCRIPTION: Installs the required OpenTelemetry libraries using the uv package manager. These libraries are necessary for tracing and instrumentation of the Prefect server.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install opentelemetry-api \\\n                opentelemetry-sdk \\\n                opentelemetry-exporter-otlp \\\n                opentelemetry-instrumentation-sqlalchemy \\\n                opentelemetry-instrumentation-fastapi\n```\n\n----------------------------------------\n\nTITLE: Incorrect Module Import Syntax\nDESCRIPTION: Shows the incorrect way of importing modules using the from syntax.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Wrong\nfrom prefect.server import schemas\n```\n\n----------------------------------------\n\nTITLE: Configuring Markdown Frontmatter for Documentation Page\nDESCRIPTION: YAML frontmatter configuration for the documentation page, setting the title and page mode parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v2/get-started/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Prefect v2 documentation\nmode: wide\n---\n```\n\n----------------------------------------\n\nTITLE: Displaying Package Badges in Markdown\nDESCRIPTION: This code snippet shows how to embed badges for PyPI version and download statistics using Markdown and HTML. It utilizes shields.io for generating the badges.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-gitlab/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-gitlab/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-gitlab?color=26272B&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-gitlab/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-gitlab?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Creating Terraform Provider Link Component in React\nDESCRIPTION: A React functional component named TF that takes name and href props to create a paragraph with a link to Terraform provider documentation. The component uses JSX syntax to create a dynamic text message with an embedded link.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/terraform.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const TF = ({ name, href }) => (\n<p>You can manage {name} with the <a href={href}>Terraform provider for Prefect</a>.</p>\n);\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Concurrency Limits Filtering\nDESCRIPTION: This YAML snippet specifies an OpenAPI endpoint for filtering concurrency limits. It defines a POST request to '/api/concurrency_limits/filter', which is likely used to retrieve or filter concurrency limits based on specified criteria.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/concurrency-limits/read-concurrency-limits.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/concurrency_limits/filter\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with NPM\nDESCRIPTION: Clean installation of project dependencies using npm ci command, which ensures consistent installations across environments.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/ui/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm ci\n```\n\n----------------------------------------\n\nTITLE: Delete Block Command\nDESCRIPTION: Command to delete a configured block using either a slug or ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/blocks.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\nprefect blocks delete [OPTIONS] [SLUG]\n```\n\n----------------------------------------\n\nTITLE: Displaying Prefect Bitbucket Package Badges in Markdown\nDESCRIPTION: This code snippet shows how to display PyPI version and download count badges for the prefect-bitbucket package using Markdown and HTML. It includes links to PyPI and pepy.tech for up-to-date statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-bitbucket/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-bitbucket/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-bitbucket?color=0052FF&labelColor=090422\"></a>\n    <a href=\"https://pepy.tech/badge/prefect-bitbucket/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-bitbucket?color=0052FF&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining PATCH Flow Run API Endpoint in OpenAPI\nDESCRIPTION: OpenAPI/Swagger specification header defining the API endpoint for patching flow run details. This indicates the endpoint accepts PATCH requests to update flow run properties at the /api/flow_runs/{id} path.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/update-flow-run.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/flow_runs/{id}\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Deployment Schedules in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for a POST endpoint to manage schedules for a deployment. It includes the endpoint path with a deployment ID parameter and indicates that this is an OpenAPI specification.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/create-deployment-schedules.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/schedules\n```\n\n----------------------------------------\n\nTITLE: Exporting Home Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'home' that contains links to the Prefect documentation's getting started guide, CLI reference, API documentation, and Helm chart repository. This provides a quick reference to key resources for new Prefect users.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport const home = {\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/guides/getting-started\",\n    cli: \"https://docs.prefect.io/v3/api-ref/cli/index\",\n    api: \"https://app.prefect.cloud/api/docs\",\n    helm: \"https://github.com/PrefectHQ/prefect-helm/tree/main/charts\",\n}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI PATCH Endpoint Specification for Flow Run Notification Policies\nDESCRIPTION: OpenAPI/Swagger specification defining the PATCH endpoint for updating flow run notification policies using their unique identifier. The specification indicates this is for handling notification policy updates.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-run-notification-policies/update-flow-run-notification-policy.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/flow_run_notification_policies/{id}\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for POST /api/logs/\nDESCRIPTION: This snippet defines the OpenAPI specification for the POST /api/logs/ endpoint. It is used to document the API and can be used for generating client libraries or server stubs.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/logs/create-logs.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"openapi: post /api/logs/\\n---\n```\n\n----------------------------------------\n\nTITLE: Resume Schedule\nDESCRIPTION: Reactivate a paused deployment schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/deployment.mdx#2025-04-21_snippet_9\n\nLANGUAGE: command\nCODE:\n```\nprefect deployment schedule resume [OPTIONS] DEPLOYMENT_NAME SCHEDULE_ID\n```\n\n----------------------------------------\n\nTITLE: OpenAPI POST Endpoint for Work Queue Filtering\nDESCRIPTION: This snippet defines an OpenAPI specification for a POST endpoint used to filter work queues. It specifies the endpoint `/api/work_queues/filter`, implying that a request body will be used to specify filtering parameters. This allows clients to programmatically retrieve work queues based on specific criteria.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/work-queues/read-work-queues.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"openapi: post /api/work_queues/filter\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification - POST /api/events\nDESCRIPTION: OpenAPI specification header defining the endpoint path /api/events using POST method\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/events/create-events.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/events\n```\n\n----------------------------------------\n\nTITLE: Prefect Server Database Command\nDESCRIPTION: The main command for interacting with the Prefect database. It provides access to subcommands for resetting, upgrading, downgrading, revising and stamping the database.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_3\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database [OPTIONS] COMMAND [ARGS]...\"\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for GET /api/deployments/{id}/schedules Endpoint in YAML\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the GET /api/deployments/{id}/schedules endpoint. It includes the endpoint path, parameters, and expected responses. The endpoint retrieves schedules associated with a specific deployment identified by its ID.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/read-deployment-schedules.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/deployments/{id}/schedules\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Prefect API Deployments Pagination Endpoint\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the POST /api/deployments/paginate endpoint. It outlines the request and response structure for paginating deployment data in the Prefect API.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/paginate-deployments.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/paginate\n```\n\n----------------------------------------\n\nTITLE: Setting Up Project Directory Structure\nDESCRIPTION: Terminal commands to create the required directory structure for the MLB data project, including folders for storing raw data, processed parquet files, and analysis results.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/s3-motherduck.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmkdir mlb-data-project\ncd mlb-data-project\nmkdir boxscore_parquet\nmkdir raw_data\nmkdir boxscore_analysis\ntouch mlb_flow.py\n```\n\n----------------------------------------\n\nTITLE: Define OpenAPI POST endpoint for flow run input filtering\nDESCRIPTION: This snippet defines an OpenAPI endpoint for a POST request to filter input for a specific flow run, identified by its {id}.  It specifies the path `/api/flow_runs/{id}/input/filter` and uses the POST method. The id parameter refers to the flow run's identifier.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/flow-runs/filter-flow-run-input.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"openapi: post /api/flow_runs/{id}/input/filter\"\n```\n\n----------------------------------------\n\nTITLE: Markdown Frontmatter Configuration for SDK Documentation\nDESCRIPTION: YAML frontmatter metadata defining the documentation title and URL for Prefect's Docker SDK reference documentation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-docker/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_docker/\"\n---\n```\n\n----------------------------------------\n\nTITLE: Creating ECR Repository using AWS CLI\nDESCRIPTION: AWS CLI command to create an Elastic Container Registry (ECR) repository. This repository will be used to store the Docker image containing the flow code.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\naws ecr create-repository \\\n--repository-name <my-ecr-repo> \\\n--region <region>\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration for SDK Documentation\nDESCRIPTION: YAML frontmatter block that defines metadata for a documentation page, including the title 'SDK docs' and the URL pointing to the Prefect shell SDK reference documentation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-shell/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_shell/\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Prefect Deployment in YAML\nDESCRIPTION: YAML configuration for Prefect deployment, specifying build steps, push steps, and deployment details. This configuration is used to manage the deployment of the flow to the ECS worker.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-aws/ecs_guide.mdx#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nname: ecs-worker-guide\nprefect-version: 2.14.20\n\nbuild:\n- prefect_docker.deployments.steps.build_docker_image:\n    id: build_image\n    requires: prefect-docker>=0.3.1\n    image_name: <my-ecr-repo>\n    tag: latest\n    dockerfile: auto\n\npush:\n- prefect_docker.deployments.steps.push_docker_image:\n    requires: prefect-docker>=0.3.1\n    image_name: '{{ build_image.image_name }}'\n    tag: '{{ build_image.tag }}'\n\ndeployments:\n- name: my_ecs_deployment\n    version:\n    tags: []\n    description:\n    entrypoint: flow.py:my_flow\n    parameters: {}\n    work_pool:\n        name: ecs-dev-pool\n        work_queue_name:\n        job_variables:\n        image: '{{ build_image.image }}'\n    schedules: []\npull:\n    - prefect.deployments.steps.set_working_directory:\n        directory: /opt/prefect/ecs-worker-guide\n```\n\n----------------------------------------\n\nTITLE: Creating a Process Work Pool in Prefect Cloud\nDESCRIPTION: This command creates a new Process work pool named 'my-work-pool' in Prefect Cloud using the CLI.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/ml.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nprefect work-pool create my-work-pool --type process\n```\n\n----------------------------------------\n\nTITLE: Downgrading Prefect Server Database\nDESCRIPTION: Downgrades the Prefect database schema. This command is used to revert to a previous database schema version.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_6\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database downgrade [OPTIONS]\"\n```\n\n----------------------------------------\n\nTITLE: Deploying Flow Using flow.deploy with Workers (New Method)\nDESCRIPTION: Example of the new method for creating a flow deployment using flow.deploy in Prefect 3.0. This demonstrates how to deploy a flow to a work pool, specifying the source location and entrypoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-agents-to-workers.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef my_flow(name: str = \"world\"):\n    print(f\"Hello {name}! I'm a flow from a Python script!\")\n\n\nif __name__ == \"__main__\":\n    my_flow.from_source(\n        source=str(Path(__file__).parent),\n        entrypoint=\"example.py:my_flow\",\n    ).deploy(\n        name=\"my-deployment\",\n        parameters=dict(name=\"Marvin\"),\n        work_pool_name=\"local\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Specifying Multiple State Change Hooks for Prefect Tasks\nDESCRIPTION: This snippet shows how to specify multiple state change hooks for different state transitions in a Prefect task. It includes hooks for success, failure, and a combined hook for both success and failure states.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/manage-states.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef my_success_hook(task, task_run, state):\n    print(\"Task run succeeded!\")\n\ndef my_failure_hook(task, task_run, state):\n    print(\"Task run failed!\")\n\ndef my_succeed_or_fail_hook(task, task_run, state):\n    print(\"If the task run succeeds or fails, this hook runs.\")\n\n@task(\n    on_completion=[my_success_hook, my_succeed_or_fail_hook],\n    on_failure=[my_failure_hook, my_succeed_or_fail_hook]\n)\n```\n\n----------------------------------------\n\nTITLE: Stamping Prefect Server Database\nDESCRIPTION: Stamps the revision table with the given revision without running migrations. This command is useful for setting the current revision of the database without applying any changes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/server.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\n\"prefect server database stamp [OPTIONS] REVISION\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Global Concurrency Limit for API Requests\nDESCRIPTION: This bash command creates a global concurrency limit in Prefect to prevent API rate limiting. It configures a limit of 60 requests with a decay rate of 0.016 requests per second, matching GitHub's unauthenticated API rate limits.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/tutorials/pipelines.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# GitHub has a rate limit of 60 unauthenticated requests per hour (~0.016 requests per second)\nprefect gcl create github-api --limit 60 --slot-decay-per-second 0.016\n```\n\n----------------------------------------\n\nTITLE: Authenticating with AWS ECR using docker/login-action in YAML\nDESCRIPTION: This snippet demonstrates how to authenticate with AWS Elastic Container Registry (ECR) using the docker/login-action. It uses AWS credentials stored as GitHub secrets to log in to the specified ECR registry.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/deploy/infrastructure-concepts/deploy-ci-cd.mdx#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Login to ECR\n  uses: docker/login-action@v3\n  with:\n    registry: <aws-account-number>.dkr.ecr.<region>.amazonaws.com\n    username: ${{ secrets.AWS_ACCESS_KEY_ID }}\n    password: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n```\n\n----------------------------------------\n\nTITLE: Downloading Blobs from Azure Blob Storage with Prefect\nDESCRIPTION: Example flow showing how to download data from Azure Blob Storage using prefect-azure. It demonstrates credential setup and the blob_storage_download function.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\n\nfrom prefect_azure import AzureBlobStorageCredentials\nfrom prefect_azure.blob_storage import blob_storage_download\n\n@flow\ndef example_blob_storage_download_flow():\n    connection_string = \"connection_string\"\n    blob_storage_credentials = AzureBlobStorageCredentials(\n        connection_string=connection_string,\n    )\n    data = blob_storage_download(\n        blob=\"prefect.txt\",\n        container=\"prefect\",\n        azure_credentials=blob_storage_credentials,\n    )\n    return data\n\nexample_blob_storage_download_flow()\n```\n\n----------------------------------------\n\nTITLE: Inspect Concurrency Limit\nDESCRIPTION: Displays detailed information about a concurrency limit including active_slots showing TaskRun IDs currently using concurrency slots.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/concurrency-limit.mdx#2025-04-21_snippet_2\n\nLANGUAGE: command\nCODE:\n```\nprefect concurrency-limit inspect [OPTIONS] TAG\n```\n\n----------------------------------------\n\nTITLE: Exporting Webhooks Documentation Links in JavaScript\nDESCRIPTION: This snippet defines a JavaScript object named 'webhooks' that stores links to the Prefect documentation related to webhooks, specifically the API documentation and Terraform resources. This provides a convenient way to access webhook-related documentation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/vars.mdx#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nexport const webhooks = {\n    api: \"https://app.prefect.cloud/api/docs#tag/Webhooks\",\n    tf: \"https://registry.terraform.io/providers/PrefectHQ/prefect/latest/docs/resources/webhook\",\n}\n```\n\n----------------------------------------\n\nTITLE: Prefect Event Trigger Matching Example 3\nDESCRIPTION: This JSON configuration combines `match` and `match_related` for more restrictive filtering, targeting events whose primary resource is a flow run started by a specific deployment, and that flow run has a name starting with 'cute-' or 'radical-'. This provides a more precise way to select specific events for automation.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/custom-triggers.mdx#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n\"match\": {\n  \"prefect.resource.id\": \"prefect.flow-run.*\",\n  \"prefect.resource.name\": [\"cute-*\", \"radical-*\"]\n},\n\"match_related\": {\n  \"prefect.resource.id\": \"prefect.deployment.37ca4a08-e2d9-4628-a310-cc15a323378e\"\n},\n...\n```\n\n----------------------------------------\n\nTITLE: Setting Up Azure Container Instance Infrastructure for Prefect\nDESCRIPTION: Code to create and save an Azure Container Instance infrastructure block that can be used for Prefect deployments, using credentials loaded from a block.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-azure/README.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect_azure import AzureContainerInstanceCredentials\nfrom prefect_azure.container_instance import AzureContainerInstanceJob\n\ncontainer_instance_job = AzureContainerInstanceJob(\n    aci_credentials=AzureContainerInstanceCredentials.load(\"MY_BLOCK_NAME\"),\n    resource_group_name=\"azure_resource_group.example.name\",\n    subscription_id=\"<MY_AZURE_SUBSCRIPTION_ID>\",\n)\ncontainer_instance_job.save(\"aci-dev\")\n```\n\n----------------------------------------\n\nTITLE: Incorrect usage of await with task.submit() in Prefect 3.0\nDESCRIPTION: Example showing incorrect usage of await with task.submit(), which is always synchronous in Prefect 3.x and causes a TypeError. This highlights changes in the futures interface.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\nasync def my_task():\n    pass\n\n@flow\nasync def my_flow():\n    future = await my_task.submit() # TypeError: object PrefectConcurrentFuture can't be used in 'await' expression\n```\n\n----------------------------------------\n\nTITLE: Using _sync=True with async blocks in Prefect 3.0\nDESCRIPTION: Example showing how to use the _sync=True parameter with an asynchronous block load method to avoid awaiting. This provides an alternative to await for async functions.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.system import Secret\n\nasync def my_async_function():\n    my_secret = Secret.load(\"my-secret\", _sync=True)\n    print(my_secret.get()) # This will work\n```\n\n----------------------------------------\n\nTITLE: Accessing HTTP Request Body with Jinja2 Template\nDESCRIPTION: This Jinja2 code illustrates how to access URL-encoded form data from the request body. It highlights using both index and attribute access methods and notes limitations with keys that are not valid Python identifiers.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/automate/events/webhook-triggers.mdx#2025-04-21_snippet_6\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ body['friendly_name'] }}\n\n{{ body.friendly_name }}\n```\n\n----------------------------------------\n\nTITLE: Correct usage of awaiting async blocks in Prefect 3.0\nDESCRIPTION: Example showing the correct way to await an asynchronous block load method. This demonstrates the proper pattern for working with async functions in Prefect 3.0.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.blocks.system import Secret\n\nasync def my_async_function():\n    my_secret = await Secret.load(\"my-secret\")\n    print(my_secret.get()) # This will work\n```\n\n----------------------------------------\n\nTITLE: Reading AWS Secret with Prefect Integration\nDESCRIPTION: Python example demonstrating how to read a secret from AWS Secrets Manager using Prefect AWS integration tasks and credentials block\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/use-integrations.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow\nfrom prefect_aws import AwsCredentials\nfrom prefect_aws.secrets_manager import read_secret\n\n@flow\ndef connect_to_database():\n    aws_credentials = AwsCredentials.load(\"MY_BLOCK_NAME\")\n    secret_value = read_secret(\n        secret_name=\"db_password\",\n        aws_credentials=aws_credentials\n    )\n\n    # Then, use secret_value to connect to a database\n```\n\n----------------------------------------\n\nTITLE: Configuring Flow Schedule in Prefect 3.0\nDESCRIPTION: Demonstrates the updated way to schedule flows in Prefect 3.0 using the 'schedules' parameter with Interval. Shows the migration from single schedule to list of schedules.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timedelta\nfrom prefect import flow\nfrom prefect.schedules import Interval\n\n@flow\ndef my_flow():\n    pass\n\nmy_flow.serve(\n    name=\"my-flow\",\n    schedules=[Interval(timedelta(minutes=1))]\n)\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Block Types Slug Endpoint in YAML\nDESCRIPTION: OpenAPI specification that defines the GET endpoint for retrieving block type information by slug in Prefect. The specification indicates this is an API route for accessing block type data using a slug identifier.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/read-block-type-by-slug.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/block_types/slug/{slug}\n```\n\n----------------------------------------\n\nTITLE: Creating Management Links React Component\nDESCRIPTION: Renders a paragraph with multiple management links for a resource using destructured props for name and href values\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/snippets/resource-management/combined.mdx#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const COMBINED = ({ name, hrefTF, hrefAPI, hrefCLI }) => (\n<p>You can manage {name} with the <a href={hrefCLI}>Prefect CLI</a>, <a href={hrefTF}>Terraform provider</a>, or <a href={hrefAPI}>Prefect API</a>.</p>\n);\n```\n\n----------------------------------------\n\nTITLE: Correct usage of task.submit() without await in Prefect 3.0\nDESCRIPTION: Example showing the correct way to use task.submit() without await in Prefect 3.x. This demonstrates the synchronous futures interface in Prefect 3.0.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/resources/upgrade-to-prefect-3.mdx#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect import flow, task\n\n@task\nasync def my_task():\n    pass\n\n@flow\nasync def my_flow():\n    future = my_task.submit() # This will work\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Types Endpoint Specification\nDESCRIPTION: OpenAPI specification header defining the endpoint path for block types API operations. This specification is for the POST method on /api/block_types/ endpoint.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-types/create-block-type.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_types/\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Worker Result\nDESCRIPTION: Example of implementing a custom worker result class by extending BaseWorkerResult. Used to return execution information from the worker run method.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/develop-a-new-worker-type.mdx#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom prefect.workers.base import BaseWorkerResult\n\nclass MyWorkerResult(BaseWorkerResult):\n    \"\"\"Result returned by the MyWorker.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Result Persistence for Task Caching in Prefect\nDESCRIPTION: Sets the PREFECT_RESULTS_PERSIST_BY_DEFAULT configuration to true, which enables result persistence for all tasks. This is a prerequisite for task caching to work properly.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/task-caching.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_RESULTS_PERSIST_BY_DEFAULT=true\n```\n\n----------------------------------------\n\nTITLE: Mocking Runtime Values in Bash\nDESCRIPTION: Demonstrates how to mock runtime values using environment variables with a specific naming schema for testing purposes\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/develop/runtime-context.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport PREFECT__RUNTIME__TASK_RUN__FAKE_KEY='foo'\npython -c 'from prefect.runtime import task_run; print(task_run.fake_key)' # \"foo\"\n```\n\n----------------------------------------\n\nTITLE: Upgrade prefect and prefect-bitbucket\nDESCRIPTION: This command upgrades both Prefect and prefect-bitbucket to their latest versions.  This ensures you are using the most up-to-date features and fixes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-bitbucket/index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[bitbucket]\"\n```\n\n----------------------------------------\n\nTITLE: OpenAPI GET Saved Search Endpoint Definition\nDESCRIPTION: OpenAPI specification defining the endpoint for retrieving a saved search by ID. The path includes a required ID parameter in the URL.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/savedsearches/read-saved-search.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: get /api/saved_searches/{id}\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-kubernetes with pip\nDESCRIPTION: Commands to install and upgrade the prefect-kubernetes library using pip. These commands ensure compatibility with the installed version of Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-kubernetes/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[kubernetes]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[kubernetes]\"\n```\n\n----------------------------------------\n\nTITLE: Installing Prefect with pip\nDESCRIPTION: Command to install or upgrade to the latest version of Prefect using pip. Requires Python 3.9 or later.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U prefect\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Endpoint for Database Drop in Prefect\nDESCRIPTION: This snippet specifies the OpenAPI definition for a POST endpoint that handles database drop operations in Prefect's admin API. The endpoint path is '/api/admin/database/drop'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/admin/drop-database.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/admin/database/drop\n```\n\n----------------------------------------\n\nTITLE: Markdown Front Matter for SDK Documentation\nDESCRIPTION: YAML front matter block defining the title and URL for the Prefect Redis SDK documentation page\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-redis/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_redis/\"\n---\n```\n\n----------------------------------------\n\nTITLE: Incorrect Submodule Import\nDESCRIPTION: Shows the incorrect way of importing submodules using absolute imports in __init__ files.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/styles-practices.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Wrong\nimport prefect.flows\n```\n\n----------------------------------------\n\nTITLE: Specifying Prefect Version Requirement\nDESCRIPTION: Version constraint requiring Prefect version to be greater than 2. This is typically used in configuration or dependency management to ensure compatibility.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/tests/docker/contexts/requirements/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nprefect>2\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Block Schemas Filter Endpoint Definition\nDESCRIPTION: OpenAPI specification header indicating the POST endpoint path for filtering block schemas via the API\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/block-schemas/read-block-schemas.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/block_schemas/filter\n```\n\n----------------------------------------\n\nTITLE: Installing prefect-sqlalchemy Package\nDESCRIPTION: Commands to install and upgrade the prefect-sqlalchemy package along with its dependencies.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-sqlalchemy/index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"prefect[sqlalchemy]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"prefect[sqlalchemy]\"\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Specification for Setting Deployment Schedule Active\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for the POST /api/deployments/{id}/set_schedule_active endpoint. It specifies the request parameters, request body, and possible responses for activating or deactivating a deployment's schedule.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/resume-deployment-1.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/deployments/{id}/set_schedule_active\n```\n\n----------------------------------------\n\nTITLE: Database Migration Commands\nDESCRIPTION: Commands for generating and applying database migrations in Prefect.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/contribute/dev-contribute.mdx#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nprefect server database revision --autogenerate -m \"<migration name>\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nprefect server database upgrade -y\n```\n\n----------------------------------------\n\nTITLE: Defining PATCH Endpoint for Deployment Schedule Updates\nDESCRIPTION: OpenAPI specification for the PATCH endpoint that updates deployment schedules by their ID. The endpoint accepts deployment ID and schedule ID as path parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/deployments/update-deployment-schedule.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: patch /api/deployments/{id}/schedules/{schedule_id}\n```\n\n----------------------------------------\n\nTITLE: Inspect Block Type Command\nDESCRIPTION: Command to display details about a specific block type\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/block.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect block types inspect [OPTIONS] SLUG\n```\n\n----------------------------------------\n\nTITLE: Generating Kubernetes Manifest\nDESCRIPTION: Command to generate a Kubernetes manifest for development purposes.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/cli/dev.mdx#2025-04-21_snippet_8\n\nLANGUAGE: command\nCODE:\n```\nprefect dev kubernetes-manifest [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Define PUT endpoint for saved searches\nDESCRIPTION: This snippet defines a PUT endpoint in an OpenAPI specification.  It indicates that the /api/saved_searches/ endpoint should be accessed using the PUT method for creating or updating saved searches.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/savedsearches/create-saved-search.mdx#2025-04-21_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"openapi: put /api/saved_searches/\"\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Manual Server Run\nDESCRIPTION: Configures environment variables required for running the Prefect server manually with OpenTelemetry tracing. Includes settings for the API URL, service name, exporter configuration, and logging level.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/load_testing/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nprefect config set PREFECT_API_URL=http://localhost:4200/api\n\nunset $(env | grep OTEL_ | cut -d= -f1)\nexport OTEL_SERVICE_NAME=prefect-server\nexport OTEL_TRACES_EXPORTER=otlp\nexport OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317\nexport OTEL_EXPORTER_OTLP_PROTOCOL=grpc\nexport OTEL_LOG_LEVEL=debug\nexport PYTHONPATH=src\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI POST Endpoint for Admin Database Creation\nDESCRIPTION: Specifies the OpenAPI endpoint for creating a database through the administrative API. The endpoint uses the HTTP POST method at the path '/api/admin/database/create'.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/v3/api-ref/rest-api/server/admin/create-database.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: post /api/admin/database/create\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Resource Group\nDESCRIPTION: Creates a new Azure resource group using the Azure CLI. Takes resource group name and location as parameters.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-azure/aci_worker.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport RG_NAME=<resource-group-name> && \\\naz group create --name $RG_NAME --location <location>\n```\n\n----------------------------------------\n\nTITLE: Rendering Markdown Badges for prefect-dbt Package\nDESCRIPTION: This snippet displays badges for the PyPI version and download statistics of the prefect-dbt package using Markdown syntax. It also includes a centered paragraph with links to the package on PyPI and its download statistics.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/src/integrations/prefect-dbt/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect-dbt/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect-dbt?color=26272B&labelColor=090422\"></a>0\n    <a href=\"https://pepy.tech/badge/prefect-dbt/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect-dbt?color=26272B&labelColor=090422\" /></a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining Metadata for Prefect Email SDK Documentation in YAML\nDESCRIPTION: This YAML snippet defines metadata for the SDK documentation of the Prefect Email module. It specifies the title as 'SDK docs' and provides the URL where the reference documentation can be accessed.\nSOURCE: https://github.com/prefecthq/prefect/blob/main/docs/integrations/prefect-email/sdk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"SDK docs\"\nurl: \"https://reference.prefect.io/prefect_email/\"\n---\n```"
  }
]