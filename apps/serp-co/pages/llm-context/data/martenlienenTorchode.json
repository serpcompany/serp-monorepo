[
  {
    "owner": "martenlienen",
    "repo": "torchode",
    "content": "TITLE: Implementing ODE Solver with torchode\nDESCRIPTION: Example demonstrating how to use torchode to solve an ODE system with batch processing. Shows initialization of solver parameters, solving the ODE, and plotting results using matplotlib.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/README.md#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as pp\nimport torch\nimport torchode as to\n\ndef f(t, y):\n    return -0.5 * y\n\ny0 = torch.tensor([[1.2], [5.0]])\nn_steps = 10\nt_eval = torch.stack((torch.linspace(0, 5, n_steps), torch.linspace(3, 4, n_steps)))\n\nterm = to.ODETerm(f)\nstep_method = to.Dopri5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nsolver = to.AutoDiffAdjoint(step_method, step_size_controller)\njit_solver = torch.compile(solver)\n\nsol = jit_solver.solve(to.InitialValueProblem(y0=y0, t_eval=t_eval))\nprint(sol.stats)\n# => {'n_f_evals': tensor([26, 26]), 'n_steps': tensor([4, 2]),\n# =>  'n_accepted': tensor([4, 2]), 'n_initialized': tensor([10, 10])}\n\npp.plot(sol.ts[0], sol.ys[0])\npp.plot(sol.ts[1], sol.ys[1])\n```\n\n----------------------------------------\n\nTITLE: Using torchode ODE Solver with PyTorch\nDESCRIPTION: Example demonstrating how to use torchode to solve an ODE system with batch processing. Shows initialization, solver configuration, and plotting results using matplotlib\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/README.md#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as pp\nimport torch\nimport torchode as to\n\ndef f(t, y):\n    return -0.5 * y\n\ny0 = torch.tensor([[1.2], [5.0]])\nn_steps = 10\nt_eval = torch.stack((torch.linspace(0, 5, n_steps), torch.linspace(3, 4, n_steps)))\n\nterm = to.ODETerm(f)\nstep_method = to.Dopri5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nsolver = to.AutoDiffAdjoint(step_method, step_size_controller)\njit_solver = torch.compile(solver)\n\nsol = jit_solver.solve(to.InitialValueProblem(y0=y0, t_eval=t_eval))\nprint(sol.stats)\n# => {'n_f_evals': tensor([26, 26]), 'n_steps': tensor([4, 2]),\n# =>  'n_accepted': tensor([4, 2]), 'n_initialized': tensor([10, 10])}\n\npp.plot(sol.ts[0], sol.ys[0])\npp.plot(sol.ts[1], sol.ys[1])\n```\n\n----------------------------------------\n\nTITLE: Handling Multi-dimensional Tensors with torchode ODE Solver\nDESCRIPTION: Example demonstrating how to work with RGB images in torchode by manually flattening and reshaping tensors. The dynamics function takes additional arguments to preserve shape information needed for reshaping inside the function.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/nd-data.md#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Example with a batch of RGB images\nb, c, w, h = 8, 3, 72, 72\ny0 = torch.randn(b, w, h)\n\n# Setup solver etc.\n# ...\n\ndef f(t, y, args)\n    c, w, h = args\n\n    # Reshape 2D to B x C x W x H tensor and apply convolutional neural network\n    y = some_cnn(y.reshape((-1, c, w, h)))\n\n    # Flatten back to 2D when we return control back to torchode\n    return y.flatten(start_dim=1)\n\nterm = to.ODETerm(f, with_args=True)\nproblem = to.InitialValueProblem(y0=y0.flatten(start_dim=1), t_eval=..)\nsol = solver.solve(problem, args=(c, w, h))\n```\n\n----------------------------------------\n\nTITLE: Solving Decay Equations with Different Decay Rates using torchode\nDESCRIPTION: This code demonstrates how to solve multiple decay equations with different decay rates using torchode. The ODETerm is configured with with_args=True to allow passing custom parameters to the dynamics function. The example solves two decay problems with different decay rates and time spans, then plots the results.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-args.md#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as pp\nimport torch\nimport torchode as to\n\ndef f(t, y, decay_rate):\n    return -decay_rate[:, None] * y\n\nterm = to.ODETerm(f, with_args=True)\nstep_method = to.Tsit5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nsolver = to.AutoDiffAdjoint(step_method, step_size_controller)\n\ny0 = torch.tensor([[1.2], [5.0]])\nn_steps = 10\nt_eval = torch.stack((torch.linspace(0, 5, n_steps), torch.linspace(3, 4, n_steps)))\ndecay_rate = torch.tensor([0.1, 5.0])\n\nproblem = to.InitialValueProblem(y0=y0, t_eval=t_eval)\nsol = solver.solve(problem, args=decay_rate)\n\npp.plot(sol.ts[0], sol.ys[0])\npp.plot(sol.ts[1], sol.ys[1])\npp.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring TorchODE Components for ODE Solving\nDESCRIPTION: Sets up the components needed for torchode: the ODE term, step method (Dopri5), step size controller, and adjoint method for backpropagation. Uses discretize-then-optimize approach with automatic differentiation.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nterm = to.ODETerm(model)\nstep_method = to.Dopri5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-9, rtol=1e-7, term=term)\nadjoint = to.AutoDiffAdjoint(step_method, step_size_controller)\n```\n\n----------------------------------------\n\nTITLE: Solving ODE with TorchODE\nDESCRIPTION: Creates an initial value problem instance and solves it using the configured torchode solver. Note that t_eval is repeated for each sample in the batch since torchode solves separate ODEs for each sample.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nproblem = to.InitialValueProblem(y0=y0, t_eval=t_eval.repeat((batch_size, 1)))\nsol = adjoint.solve(problem)\n```\n\n----------------------------------------\n\nTITLE: Initializing ODE Solver with Adaptive Step Size using IntegralController in Python\nDESCRIPTION: This snippet demonstrates how to set up an ODE solver in torchode using the Tsit5 step method and IntegralController for adaptive step size control. It defines the ODE function, creates the solver components, and solves the initial value problem.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/step-size-controllers.md#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torchode as to\n\ndef f(t, y):\n    return -0.5 * y\n\nterm = to.ODETerm(f)\nstep_method = to.Tsit5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nsolver = to.AutoDiffAdjoint(step_method, step_size_controller)\nproblem = to.InitialValueProblem(...)\nsol = solver.solve(problem)\n```\n\n----------------------------------------\n\nTITLE: Solving the ODE with Tracked Information\nDESCRIPTION: Creates an initial value problem and solves it using the configured ODE solver with the custom tracking wrapper, which collects information about the solution process.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nt_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\nproblem = to.InitialValueProblem(y0=torch.zeros((batch_size, n_features)).to(dev), t_eval=t_eval.to(dev))\n\nsol = adjoint.solve(problem)\n```\n\n----------------------------------------\n\nTITLE: Setting up ODE Solver with Custom Tracker\nDESCRIPTION: Constructs the ODE solver by configuring the term, step method, step size controller, and adjoint method. The step size controller is wrapped with the custom tracker to log solver information.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndev = torch.device(\"cpu\")\nterm = to.ODETerm(model)\nstep_method = to.Dopri5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nstep_size_controller = StepSizeControllerTracker(step_size_controller)\nadjoint = to.AutoDiffAdjoint(step_method, step_size_controller).to(dev)\n```\n\n----------------------------------------\n\nTITLE: Configuring PIDController for Stiff Dynamics in ODE Solver in Python\nDESCRIPTION: This code snippet shows how to use the PIDController instead of IntegralController for step size control in torchode. It's recommended for stiff dynamics and allows fine-tuning of the controller coefficients.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/step-size-controllers.md#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nstep_size_controller = to.PIDController(atol=1e-6, rtol=1e-3, pcoeff=0.2, icoeff=0.5, dcoeff=0.0, term=term)\n```\n\n----------------------------------------\n\nTITLE: Setting Up ODE Solver with Fixed Step Size in Python\nDESCRIPTION: This example illustrates how to use a FixedStepController in torchode for constant step size ODE solving. It requires specifying an initial step size when calling the solve method, which will be used for all steps.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/step-size-controllers.md#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nstep_size_controller = to.FixedStepController()\nsolver = to.AutoDiffAdjoint(step_method, step_size_controller)\ndt0 = torch.full((batch_size,), 0.01)\nsol = solver.solve(problem, dt0=dt0)\n```\n\n----------------------------------------\n\nTITLE: Defining a Neural ODE Model Using PyTorch\nDESCRIPTION: Creates a two-layer MLP (Multilayer Perceptron) neural network class that will be used as the ODE function. The model takes an input of dimension n_features, processes it through hidden layers, and outputs a tensor of the same dimension as the input.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Model(nn.Module):\n    def __init__(self, n_features, n_hidden):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(n_features, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_features)\n        )\n    \n    def forward(self, t, y):\n        return self.layers(y)\n    \nn_features = 5\nmodel = Model(n_features, 16)\n```\n\n----------------------------------------\n\nTITLE: Defining Neural ODE Model\nDESCRIPTION: Creates a neural network model class with multiple layers that represents the ODE function. This model takes time and state as inputs and returns the derivative of the state.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Model(nn.Module):\n    def __init__(self, n_features, n_hidden):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(n_features, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_features)\n        )\n    \n    def forward(self, t, y):\n        return self.layers(y)\n```\n\n----------------------------------------\n\nTITLE: Defining Neural ODE Model Structure\nDESCRIPTION: Implements a neural ODE using an MLP with two hidden layers and softplus activation functions. The model takes n_features input and outputs the same dimension.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Model(nn.Module):\n    def __init__(self, n_features, n_hidden):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(n_features, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_hidden),\n            nn.Softplus(),\n            nn.Linear(n_hidden, n_features)\n        )\n    \n    def forward(self, t, y):\n        return self.layers(y)\n\nn_features = 5\nmodel = Model(n_features=n_features, n_hidden=32)\n```\n\n----------------------------------------\n\nTITLE: Configuring ODE Solver Components\nDESCRIPTION: Sets up the ODE solver components including term, step method, and step size controller with specified tolerances.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndev = torch.device(\"cpu\")\nterm = to.ODETerm(model)\nstep_method = to.Dopri5(term=term)\nstep_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\nadjoint = to.AutoDiffAdjoint(step_method, step_size_controller).to(dev)\n```\n\n----------------------------------------\n\nTITLE: Using AutoDiffAdjoint in TorchODE\nDESCRIPTION: Primary method for gradient computation that uses pytorch's autograd mechanism. Preferred when sufficient memory is available as it provides fast and accurate gradients.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/backprop.md#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nto.AutoDiffAdjoint\n```\n\n----------------------------------------\n\nTITLE: Comparing Solutions from TorchDiffEq and TorchODE\nDESCRIPTION: Calculates the absolute error between the solutions from torchdiffeq and torchode, displaying both the mean and maximum error to demonstrate their similarity.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nabs_err = (sol.ys - sol_tde.transpose(0, 1)).abs()\n\nabs_err.mean().item(), abs_err.max().item()\n```\n\n----------------------------------------\n\nTITLE: Solving ODE with TorchDiffEq\nDESCRIPTION: Uses torchdiffeq's odeint function to solve the ODE with the defined model, initial conditions, and evaluation time points.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsol_tde = tde.odeint(model, y0, t_eval)\n```\n\n----------------------------------------\n\nTITLE: Comparing Regular and JIT-Compiled Solutions\nDESCRIPTION: Solves the ODE using both regular and JIT-compiled solvers and compares their results.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsol = adjoint.solve(problem)\nsol_jit = adjoint_jit.solve(problem)\n\nprint(sol.stats)\nprint(sol_jit.stats)\nprint(\"Max absolute difference\", float((sol.ys - sol_jit.ys).abs().max()))\n```\n\n----------------------------------------\n\nTITLE: JIT Compiling the Solver\nDESCRIPTION: Applies PyTorch's JIT compilation to the solver for improved performance.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nadjoint_jit = torch.jit.script(adjoint)\n```\n\n----------------------------------------\n\nTITLE: Using BacksolveAdjoint for Memory-Efficient Gradients\nDESCRIPTION: Memory-efficient method that solves adjoint equations backwards using torch.func for gradient computation. Used when memory constraints prevent using AutoDiffAdjoint.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/backprop.md#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nto.BacksolveAdjoint\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Step Size Controller Tracker\nDESCRIPTION: Creates a wrapper class that logs information about step sizes and acceptance decisions during ODE solving. It tracks integration time points, step sizes, and whether each step was accepted while delegating actual control to another controller.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass StepSizeControllerTracker(StepSizeController):\n    \"\"\"A wrapper that collects time step and step acceptance information.\"\"\"\n\n    def __init__(self, controller: StepSizeController):\n        super().__init__()\n\n        self.controller = controller\n\n    def init(self, term, problem, method_order: int, dt0, *, stats, args):\n        stats[\"all_t\"] = []\n        stats[\"all_dt\"] = []\n        stats[\"all_accept\"] = []\n\n        return self.controller.init(\n            term, problem, method_order, dt0, stats=stats, args=args\n        )\n\n    def adapt_step_size(self, t0, dt, y0, step, state, stats):\n        accept, dt_next, state, status = self.controller.adapt_step_size(\n            t0, dt, y0, step, state, stats\n        )\n\n        stats[\"all_t\"].append(t0)\n        stats[\"all_dt\"].append(dt)\n        stats[\"all_accept\"].append(accept)\n\n        return accept, dt_next, state, status\n\n    def merge_states(self, running, current, previous):\n        return self.controller.merge_states(running, current, previous)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Initial Value Problem\nDESCRIPTION: Creates the initial value problem with batch processing capability, defining initial conditions and evaluation points.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 3\nt_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\nproblem = to.InitialValueProblem(y0=torch.zeros((batch_size, 5)).to(dev), t_eval=t_eval.to(dev))\n```\n\n----------------------------------------\n\nTITLE: Using JointBacksolveAdjoint as Fallback Method\nDESCRIPTION: Fallback method that uses pytorch's autograd for computing model gradients. Solves adjoint equations jointly, requiring same evaluation points for all ODEs in batch. Should be used as last resort due to coupling between solutions.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/backprop.md#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nto.JointBacksolveAdjoint\n```\n\n----------------------------------------\n\nTITLE: Setting Up Initial Conditions and Evaluation Time Points\nDESCRIPTION: Defines the initial conditions (y0) and time points (t_eval) for the ODE integration. Creates a batch of random initial values and a linear space of time points for evaluation.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbatch_size = 16\nn_steps = 10\ny0 = torch.randn((batch_size, n_features))\nt_eval = torch.linspace(0.0, 1.0, n_steps)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for PyTorch ODE Solvers\nDESCRIPTION: Imports the necessary libraries including torch, torch.nn, torchode, and torchdiffeq. Sets a random seed for reproducibility.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nimport torchode as to\nimport torchdiffeq as tde\n\ntorch.random.manual_seed(180819023);\n```\n\n----------------------------------------\n\nTITLE: Importing Required Dependencies for TorchODE JIT Compilation\nDESCRIPTION: Sets up the necessary imports for TorchODE and PyTorch, and initializes random seed for reproducibility.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nimport torchode as to\n\ntorch.random.manual_seed(180819023);\n```\n\n----------------------------------------\n\nTITLE: Importing Torchode Dependencies\nDESCRIPTION: Sets up the necessary imports for working with Torchode ODE solvers and PyTorch, while also setting a random seed for reproducibility.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nimport torchode as to\nfrom torchode.step_size_controllers import StepSizeController\n\ntorch.random.manual_seed(180819023);\n```\n\n----------------------------------------\n\nTITLE: Creating Model Instance\nDESCRIPTION: Initializes the neural ODE model with specified dimensions for features and hidden layers to be used in the ODE solver.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nn_features = 5\nbatch_size = 3\n\nmodel = Model(n_features=n_features, n_hidden=32)\n```\n\n----------------------------------------\n\nTITLE: Printing Tracked Step Sizes\nDESCRIPTION: Displays the step sizes that were used during the ODE solution process, which were collected by the custom step size controller wrapper.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(torch.stack(sol.stats[\"all_dt\"]))\n```\n\n----------------------------------------\n\nTITLE: Printing Tracked Time Points\nDESCRIPTION: Displays the time points that were tracked during the ODE solution process, which were collected by the custom step size controller wrapper.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(torch.stack(sol.stats[\"all_t\"]))\n```\n\n----------------------------------------\n\nTITLE: Examining TorchODE Solution Statistics\nDESCRIPTION: Displays the solution statistics provided by torchode, which can include information about step sizes, function evaluations, and other solver metrics.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/torchdiffeq.ipynb#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsol.stats\n```\n\n----------------------------------------\n\nTITLE: Printing Step Acceptance Decisions\nDESCRIPTION: Displays whether each step was accepted or rejected during the ODE solution process, as tracked by the custom step size controller wrapper.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/extra-stats.ipynb#2025-04-19_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(torch.stack(sol.stats[\"all_accept\"]))\n```\n\n----------------------------------------\n\nTITLE: Performance Timing Setup\nDESCRIPTION: Code blocks for measuring and comparing execution times between regular and JIT-compiled versions.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/jit.ipynb#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%%timeit\nadjoint.solve(problem)\n```\n\nLANGUAGE: python\nCODE:\n```\n# A second warm up run. For some reason the second call to the compiled solver triggers more compilation\n# which we don't want to measure.\nadjoint_jit.solve(problem);\n```\n\nLANGUAGE: python\nCODE:\n```\n%%timeit\nadjoint_jit.solve(problem)\n```\n\n----------------------------------------\n\nTITLE: Installing torchode via pip\nDESCRIPTION: Command to install the latest released version of torchode from PyPI using pip package manager.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/README.md#2025-04-19_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install torchode\n```\n\n----------------------------------------\n\nTITLE: Installing torchode via pip\nDESCRIPTION: Command to install the latest released version of torchode from PyPI\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/README.md#2025-04-19_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install torchode\n```\n\n----------------------------------------\n\nTITLE: Installing torchode development version\nDESCRIPTION: Commands to clone the torchode repository and install it in development mode using pip.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/README.md#2025-04-19_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ngit clone https://github.com/martenlienen/torchode\ncd torchode\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Installing torchode development version\nDESCRIPTION: Commands to clone the repository and install torchode in development mode\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/README.md#2025-04-19_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ngit clone https://github.com/martenlienen/torchode\ncd torchode\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Pip Requirements File with Documentation Dependencies\nDESCRIPTION: Comprehensive list of Python package dependencies and their specific versions required for documentation generation. The file is auto-generated using pip-compile and includes packages for MkDocs, Jupyter notebooks, and various documentation utilities.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/requirements.txt#2025-04-19_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\n#\n# This file is autogenerated by pip-compile with python 3.10\n# To update, run:\n#\n#    pip-compile --output-file=docs/requirements.txt docs/requirements.in\n#\nattrs==22.1.0\n    # via jsonschema\nbeautifulsoup4==4.11.1\n    # via nbconvert\nbleach==5.0.1\n    # via nbconvert\ncertifi==2022.12.7\n    # via requests\ncharset-normalizer==2.1.1\n    # via requests\nclick==8.1.3\n    # via mkdocs\ndefusedxml==0.7.1\n    # via nbconvert\nentrypoints==0.4\n    # via\n    #   jupyter-client\n    #   nbconvert\nfastjsonschema==2.16.2\n    # via nbformat\nghp-import==2.1.0\n    # via mkdocs\nidna==3.4\n    # via requests\njinja2==3.1.2\n    # via\n    #   mkdocs\n    #   mkdocs-material\n    #   nbconvert\njsonschema==4.17.0\n    # via nbformat\njupyter-client==7.4.4\n    # via nbclient\njupyter-core==4.11.2\n    # via\n    #   jupyter-client\n    #   nbconvert\n    #   nbformat\njupyterlab-pygments==0.2.2\n    # via nbconvert\njupytext==1.14.1\n    # via mkdocs-jupyter\nlxml==4.9.1\n    # via nbconvert\nmarkdown==3.3.7\n    # via\n    #   mkdocs\n    #   mkdocs-material\n    #   pymdown-extensions\nmarkdown-it-py==2.2.0\n    # via\n    #   jupytext\n    #   mdit-py-plugins\nmarkupsafe==2.1.1\n    # via\n    #   jinja2\n    #   nbconvert\nmdit-py-plugins==0.3.1\n    # via jupytext\nmdurl==0.1.2\n    # via markdown-it-py\nmergedeep==1.3.4\n    # via mkdocs\nmistune==0.8.4\n    # via nbconvert\nmkdocs==1.4.1\n    # via\n    #   -r requirements.in\n    #   mkdocs-jupyter\n    #   mkdocs-material\nmkdocs-jupyter==0.22.0\n    # via -r requirements.in\nmkdocs-material==8.5.7\n    # via mkdocs-jupyter\nmkdocs-material-extensions==1.1\n    # via mkdocs-material\nnbclient==0.7.0\n    # via nbconvert\nnbconvert==6.5.4\n    # via mkdocs-jupyter\nnbformat==5.7.0\n    # via\n    #   jupytext\n    #   nbclient\n    #   nbconvert\nnest-asyncio==1.5.6\n    # via\n    #   jupyter-client\n    #   nbclient\npackaging==21.3\n    # via\n    #   mkdocs\n    #   nbconvert\npandocfilters==1.5.0\n    # via nbconvert\npygments==2.13.0\n    # via\n    #   mkdocs-jupyter\n    #   mkdocs-material\n    #   nbconvert\npymdown-extensions==9.7\n    # via mkdocs-material\npyparsing==3.0.9\n    # via packaging\npyrsistent==0.19.1\n    # via jsonschema\npython-dateutil==2.8.2\n    # via\n    #   ghp-import\n    #   jupyter-client\npyyaml==6.0\n    # via\n    #   jupytext\n    #   mkdocs\n    #   pyyaml-env-tag\npyyaml-env-tag==0.1\n    # via mkdocs\npyzmq==24.0.1\n    # via jupyter-client\nrequests==2.28.1\n    # via mkdocs-material\nsix==1.16.0\n    # via\n    #   bleach\n    #   python-dateutil\nsoupsieve==2.3.2.post1\n    # via beautifulsoup4\ntinycss2==1.2.1\n    # via nbconvert\ntoml==0.10.2\n    # via jupytext\ntornado==6.2\n    # via jupyter-client\ntraitlets==5.5.0\n    # via\n    #   jupyter-client\n    #   jupyter-core\n    #   nbclient\n    #   nbconvert\n    #   nbformat\nurllib3==1.26.12\n    # via requests\nwatchdog==2.1.9\n    # via mkdocs\nwebencodings==0.5.1\n    # via\n    #   bleach\n    #   tinycss2\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for torchode\nDESCRIPTION: BibTeX entry for citing the torchode paper in academic work.\nSOURCE: https://github.com/martenlienen/torchode/blob/main/README.md#2025-04-19_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n@inproceedings{lienen2022torchode,\n  title = {torchode: A Parallel {ODE} Solver for PyTorch},\n  author = {Marten Lienen and Stephan G{\"u}nnemann},\n  booktitle = {The Symbiosis of Deep Learning and Differential Equations II, NeurIPS},\n  year = {2022},\n  url = {https://openreview.net/forum?id=uiKVKTiUYB0}\n}\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for torchode\nDESCRIPTION: BibTeX entry for citing the torchode paper in academic work\nSOURCE: https://github.com/martenlienen/torchode/blob/main/docs/README.md#2025-04-19_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n@inproceedings{lienen2022torchode,\n  title = {torchode: A Parallel {ODE} Solver for PyTorch},\n  author = {Marten Lienen and Stephan G{\"u}nnemann},\n  booktitle = {The Symbiosis of Deep Learning and Differential Equations II, NeurIPS},\n  year = {2022},\n  url = {https://openreview.net/forum?id=uiKVKTiUYB0}\n}\n```"
  }
]