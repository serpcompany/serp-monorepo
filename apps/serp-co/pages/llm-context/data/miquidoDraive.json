[
  {
    "owner": "miquido",
    "repo": "draive",
    "content": "TITLE: Building a Basic LLM Application with Draive and OpenAI\nDESCRIPTION: Demonstrates how to create a simple LLM-based application using Draive with OpenAI. The example shows how to define a tool function, create an execution context with configuration, and generate text responses using the TextGeneration abstraction.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx, TextGeneration, tool\nfrom draive.openai import OpenAI, OpenAIChatConfig\n\n\n@tool # simply annotate a function as a tool\nasync def current_time(location: str) -> str:\n    return f\"Time in {location} is 9:53:22\"\n\nasync with  ctx.scope( # create execution context\n    \"example\", # give it a name\n    OpenAIChatConfig(model=\"gpt-4o-mini\"), # prepare configuration\n    disposables=[OpenAI()], # define resources and service clients available\n):\n    result: str = await TextGeneration.generate( # choose a right generation abstraction\n        instruction=\"You are a helpful assistant\", # provide clear instructions\n        input=\"What is the time in Kraków?\", # give it some input (including multimodal)\n        tools=[current_time], # and select any tools you like\n    )\n\n    print(result) # to finally get the result!\n    # output: The current time in Kraków is 9:53:22.\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables for Draive in Python\nDESCRIPTION: This snippet demonstrates how to load environment variables from a .env file using Draive's load_env function. This is typically used to set up API keys and other configuration parameters.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicUsage.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env()  # load .env variables\n```\n\n----------------------------------------\n\nTITLE: Implementing a Search Tool and Generating Text with RAG\nDESCRIPTION: Creates a search tool that queries the vector index and integrates it with OpenAI's LLM to generate contextualized responses. The tool retrieves relevant document chunks that the LLM can use to answer questions more accurately.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicRAG.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import Toolbox, generate_text, tool\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\n\n@tool(name=\"search\") # prepare a simple tool for searching the index\nasync def index_search_tool(query: str) -> str:\n    results: Sequence[DocumentChunk] = await ctx.state(VectorIndex).search(\n        DocumentChunk,\n        query=query,\n        limit=3,\n    )\n\n    return \"\\n---\\n\".join(result.content for result in results)\n\n\nasync with ctx.scope(\n    \"searching\",\n    # define used dependencies and services\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),\n    OpenAI().lmm_invoking(),\n    OpenAIEmbeddingConfig(model=\"text-embedding-3-small\"),\n    # use our vector index\n    vector_index,\n):\n    # use the tool to augment LLM generation by suitable document parts\n    result: str = await generate_text(\n        instruction=\"Answer the questions based on provided data\",\n        input=\"Where is John Doe living?\",\n        # suggest the tool to ensure its usage\n        tools=Toolbox.of(index_search_tool, suggest=index_search_tool),\n    )\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Basic Data Extraction with OpenAI using Draive\nDESCRIPTION: Sets up a context for extraction using OpenAI's model and extracts structured personal data from the source text. This demonstrates using generate_model to convert unstructured text into a structured object.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicDataExtraction.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx, generate_model\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\nasync with ctx.scope(\n    \"data_extraction\",\n    # define used LMM to be OpenAI within the context\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\")\n):\n    result: PersonalData = await generate_model(\n        # define model to generate\n        PersonalData,\n        # provide additional instructions\n        # note that the data structure will be automatically explained to LLM\n        instruction=\"Please extract information from the given input\",\n        # we will provide the document as an input\n        input=document,\n    )\n\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI Context and Executing Text Completion in Python\nDESCRIPTION: This code sets up a context scope with OpenAI client, configures the model, and executes the text_completion function. It demonstrates how to use Draive's context management and OpenAI integration.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicUsage.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\nasync with ctx.scope(  # prepare new context\n    \"basics\",\n    OpenAI().lmm_invoking(),  # set currently used LMM to OpenAI\n    OpenAIChatConfig(model=\"gpt-4o-mini\"), # select used model\n):\n    result: str = await text_completion(\n        text=\"Roses are red...\",\n    )\n\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Creating Context Scope in Draive\nDESCRIPTION: Shows how to create and use context scopes for state management using the ctx helper. Context scopes are essential for managing contextual state and dependencies.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx\n\n# ctx.scope creates a new instance of the context scope\n# we can enter it by using async context manager:\nasync with ctx.scope(\"basics\"):\n    pass # now everything executed inside will use that scope\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Index for Document Chunks\nDESCRIPTION: Sets up an in-memory vector index using OpenAI embeddings to make document chunks searchable. The code initializes a volatile vector index and adds document chunks to it, specifying which content should be embedded.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicRAG.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom collections.abc import Sequence\n\nfrom draive import VectorIndex\nfrom draive.openai import OpenAIEmbeddingConfig, OpenAI\n\n# prepare vector index\nvector_index: VectorIndex = VectorIndex.volatile()\nasync with ctx.scope(\n    \"indexing\",\n    # define embedding provider for this context\n    OpenAI().text_embedding(),\n    OpenAIEmbeddingConfig(model=\"text-embedding-3-small\"),\n    # use vector index\n    vector_index,\n):\n    # add document chunks to the index\n    await vector_index.index(\n        DocumentChunk,\n        values=document_chunks,\n        # define what value will be embedded for each chunk\n        indexed_value=DocumentChunk._.content,\n    )\n```\n\n----------------------------------------\n\nTITLE: Generating Model Instances with OpenAI in Draive\nDESCRIPTION: Sets up a context with OpenAI configuration and generates a structured data instance based on the defined model. Uses the async context manager to manage dependencies and performs the generation with user input.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicModelGeneration.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx, generate_model\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\n# initialize dependencies and configuration\nasync with ctx.scope(\n    \"basics\",\n    OpenAI().lmm_invoking(),  # define used LMM use OpenAI\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),  # configure OpenAI model\n):\n    # request model generation\n    generated: InterestingPlace = await generate_model(\n        # define model to generate\n        InterestingPlace,\n        # provide a prompt instruction\n        instruction=\"You are a helpful assistant.\",\n        # add user input\n        input=\"What is the most interesting place to visit in London?\",\n    )\n    print(generated)\n```\n\n----------------------------------------\n\nTITLE: Setting up Draive Metrics Logging with OpenAI Integration\nDESCRIPTION: Demonstrates how to configure metrics logging for Draive with OpenAI integration, including tool usage tracking and text generation. Uses GPT-4 mini model and custom toolbox setup with metrics logging enabled.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import MetricsLogger, setup_logging\n\nsetup_logging(\"basics\")\n\nasync with ctx.scope(\n    \"basics\",\n    # define used LMM to be OpenAI within the context\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),\n    metrics=MetricsLogger.handler(),\n):\n    result: str = await generate_text(\n        instruction=\"You are a funny assistant\",\n        input=\"What is the funny thing about LLMs?\",\n        # we will now be able to see what tools were used\n        # and check the details about its execution\n        tools=Toolbox.of(\n            current_time,\n            customized,\n            suggest=customized,\n        ),\n    )\n\n    print(f\"\\nResult:\\n{result}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Using Tool within Context Scope in Python\nDESCRIPTION: Demonstrates how to execute a tool within the required Draive context scope. Shows basic function call pattern and scope requirements.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx\n\nasync with ctx.scope(\"basics\"):\n    print(await current_time(location=\"London\"))\n\n# await current_time(location=\"London\") # error! out of context\n```\n\n----------------------------------------\n\nTITLE: Setting up MCP Client with Draive to Access File System Using OpenAI\nDESCRIPTION: This code snippet demonstrates how to configure and use the ModelContextProtocol (MCP) client in Draive to connect to a filesystem server and query directory contents. It initializes OpenAI as the language model, sets up a stdio connection to a filesystem MCP server, and performs a conversation completion to list files in a directory.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicMCP.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import (\n    ConversationMessage,\n    Toolbox,\n    conversation_completion,\n    ctx,\n    load_env,\n    setup_logging,\n)\nfrom draive.mcp import MCPClient\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\nload_env() # load .env variables\nsetup_logging(\"mcp\")\n\n\n# initialize dependencies and configuration\nasync with ctx.scope(\n    \"mcp\",\n    OpenAI().lmm_invoking(),  # define used LMM to use OpenAI\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),  # configure OpenAI model\n    # prepare MCPClient, it will handle connection lifetime through context\n    # and provide associated state with MCP functionalities\n    disposables=[\n        # we are going to use stdio connection with one of the example servers\n        MCPClient.stdio(\n            command=\"npx\",\n            args=[\n                \"-y\",\n                \"@modelcontextprotocol/server-filesystem\",\n                \"/Users/myname/checkmeout\",\n            ],\n        ),\n    ]\n):\n    # request model using any appropriate method, i.e. conversation for chat\n    response: ConversationMessage = await conversation_completion(\n        # provide a prompt instruction\n        instruction=\"You can access files on behalf of the user on their machine using available tools.\"\n        \" Desktop directory path is `/Users/myname/checkmeout`\",\n        # add user input\n        input=\"What files are in checkmeout directory?\",\n        # define tools available to the model from MCP extensions\n        tools=await Toolbox.external(),\n    )\n    print(response.content)\n```\n\n----------------------------------------\n\nTITLE: Executing OpenAI Conversation Completion with Draive in Python\nDESCRIPTION: This snippet demonstrates how to set up and execute a conversation completion using OpenAI through the draive library. It initializes the OpenAI configuration, sets up the context, and sends a prompt to the model with a custom tool available.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicConversation.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ConversationMessage, conversation_completion, ctx\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\n# initialize dependencies and configuration\nasync with ctx.scope(\n    \"basics\",\n    OpenAI().lmm_invoking(),  # define used LMM to use OpenAI\n    OpenAIChatConfig(model=\"gpt-3.5-turbo-0125\"),  # configure OpenAI model\n):\n    # request conversation completion\n    response: ConversationMessage = await conversation_completion(\n        # provide a prompt instruction\n        instruction=\"You are a helpful assistant.\",\n        # add user input\n        input=\"Hi! What is the time now?\",\n        # define tools available to the model\n        tools=[utc_datetime],\n    )\n    print(response)\n```\n\n----------------------------------------\n\nTITLE: Customizing OpenAI Model Configuration in Draive Framework\nDESCRIPTION: This snippet shows how to customize the OpenAI model configuration, including model selection and temperature setting. It also demonstrates updating the configuration for nested contexts and individual function calls.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicUsage.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom draive.openai import OpenAIChatConfig\n\nasync with ctx.scope(  # prepare the new context\n    \"basics\",\n    OpenAI().lmm_invoking(),\n    # define GPT model configuration as a context scope state\n    OpenAIChatConfig(\n        model=\"gpt-3.5-turbo\",\n        temperature=0.4,\n    ),\n):\n    # now we are using gpt-3.5-turbo with temperature of 0.4\n    result: str = await text_completion(\n        text=\"Roses are red...\",\n    )\n\n    print(\"RESULT GPT 3.5 | temperature 0.4:\", result)\n\n    # we can update the configuration to change any parameter for nested context\n    with ctx.updated(\n        # we are updating the current context value instead of making a new one\n        # this allows to preserve other elements of the configuration\n        ctx.state(OpenAIChatConfig).updated(\n            model=\"gpt-4o\",\n        ),\n    ):\n        # now we are using gpt-4o with temperature of 0.4\n        result = await text_completion(\n            text=\"Roses are red...\",\n        )\n\n        print(\"RESULT GPT 4o | temperature 0.4:\", result)\n\n    # we can also update the configuration for a single call\n    # when using generate_text function directly\n    # here we are using gpt-3.5-turbo with temperature of 0.7\n    result = await generate_text(\n        instruction=\"Prepare simplest completion of given text\",\n        input=\"Roses are red...\",\n        temperature=0.7,\n    )\n\n    print(\"RESULT GPT 3.5 | temperature 0.7:\", result)\n```\n\n----------------------------------------\n\nTITLE: Customized Data Extraction with Schema Control in Draive\nDESCRIPTION: Demonstrates advanced control over the extraction process by manually specifying schema placement and using simplified schema description. Shows how to access both JSON and simplified schema representations.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicDataExtraction.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import ctx, generate_model\n\nasync with ctx.scope(\n    \"customized_extraction\",\n    # define used LMM to be OpenAI within the context\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\")\n):\n    result: PersonalData = await generate_model(\n        PersonalData,\n        instruction=(\n            # provide extended instructions and take full control over the prompt\n            \"Please extract information from the given input.\"\n            \" Put it into the JSON according to the following description:\\n\"\n            \"{schema}\"  # 'schema' is the name of the format argument used to fill in the schema\n        ),\n        input=document,\n        # we will use the simplified schema description\n        # you can also skip adding schema at all\n        schema_injection=\"simplified\",\n    )\n\n    print(f\"JSON schema:\\n{PersonalData.json_schema(indent=2)}\")\n    print(f\"Simplified schema:\\n{PersonalData.simplified_schema(indent=2)}\")\n    print(f\"Result:\\n{result}\")\n```\n\n----------------------------------------\n\nTITLE: Integrating Tool with OpenAI LLM in Python\nDESCRIPTION: Shows how to use a tool with OpenAI's GPT model for text generation. Includes environment setup and configuration of the OpenAI integration.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import generate_text, load_env\nfrom draive.openai import OpenAIChatConfig, OpenAI\n\nload_env()\n\nasync with ctx.scope(\n    \"basics\",\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),\n):\n    result: str = await generate_text(\n        instruction=\"You are a helpful assistant\",\n        input=\"What is the time in New York?\",\n        tools=[current_time],\n    )\n\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Using Toolbox for Tool Management in Python\nDESCRIPTION: Demonstrates how to use the Toolbox class to manage multiple tools, set execution limits, and suggest specific tools for LLM use.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import Toolbox\n\nasync with ctx.scope(\n    \"basics\",\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(model=\"gpt-4o-mini\"),\n):\n    result: str = await generate_text(\n        instruction=\"You are a funny assistant\",\n        input=\"What is the funny thing about LLMs?\",\n        tools=Toolbox.of(\n            current_time,\n            customized,\n            suggest=customized,\n            repeated_calls_limit=2,\n        ),\n    )\n\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Tool in Python using Draive\nDESCRIPTION: Shows how to define a basic async tool function that returns the current time for a given location. Uses the @tool decorator for tool definition.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import tool\n\n@tool\nasync def current_time(location: str) -> str:\n    return f\"Time in {location} is 9:53:22\"\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with Ollama Integration\nDESCRIPTION: Shows how to install Draive with Ollama integration to use Ollama services for local LLM deployment.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[ollama]'\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Completion with Draive's generate_text Function in Python\nDESCRIPTION: This snippet defines an asynchronous function for text completion using Draive's generate_text function. It takes a text input and returns a completion based on the provided instruction.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicUsage.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import generate_text\n\nasync def text_completion(text: str) -> str:\n    # generate_text is a simple interface for generating text\n    return await generate_text(\n        # We have to provide instructions / system prompt to instruct the model\n        instruction=\"Prepare the simplest completion of a given text\",\n        # input is provided separately\n        input=text,\n    )\n```\n\n----------------------------------------\n\nTITLE: Customizing Tool Arguments in Python\nDESCRIPTION: Demonstrates advanced tool customization using argument annotations, aliases, and descriptions. Shows how to specify tool metadata and argument handling.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import Argument\n\n@tool(\n    name=\"fun_fact\",\n    description=\"Find a fun fact in a given topic\",\n)\nasync def customized(\n    arg: str = Argument(\n        aliased=\"topic\",\n        description=\"Topic of a fact to find\",\n        default=\"random\",\n    ),\n) -> str:\n    return f\"{arg} is very funny on its own!\"\n\nprint(customized.specification)\n```\n\n----------------------------------------\n\nTITLE: Advanced Tool Configuration in Python\nDESCRIPTION: Shows additional tool customization options including direct result handling, result formatting, and availability checking.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicToolsUse.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@tool(\n    direct_result=True,\n    format_result=lambda result: f\"Formatted: {result}\",\n    availability_check=lambda: True\n)\nasync def customized_more() -> str:\n    return \"to be changed\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Logging and Metrics for Draive Execution in Python\nDESCRIPTION: This snippet demonstrates how to set up logging and metrics handling in Draive. It configures a logger and assigns a metrics handler to view detailed execution metrics for LLM operations.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicUsage.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import MetricsLogger, setup_logging\n\nsetup_logging(\"basics\")  # setup logger\n\nasync with ctx.scope(  # prepare the context and see the execution metrics report\n    \"basics\",\n    OpenAI().lmm_invoking(),\n    OpenAIChatConfig(  # define GPT model configuration\n        model=\"gpt-3.5-turbo\",\n        temperature=0.4,\n    ),\n    metrics=MetricsLogger.handler()\n):\n    await text_completion(\n        text=\"Roses are red...\",\n    )\n\n    with ctx.updated(\n        ctx.state(OpenAIChatConfig).updated(\n            model=\"gpt-4o\",\n        ),\n    ):\n        await text_completion(\n            text=\"Roses are red...\",\n        )\n```\n\n----------------------------------------\n\nTITLE: Splitting Text into Chunks for RAG Processing\nDESCRIPTION: Prepares document data by splitting it into smaller, manageable chunks with overlap for better context preservation. Uses Draive's text splitting utilities and defines a data structure to store both full document and chunk content.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicRAG.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import DataModel, count_text_tokens, ctx, split_text\nfrom draive.openai import OpenAI\n\n# document is a short text about John Doe\ndocument: str = \"\"\"\n...\n\"\"\"\n\n# define chunk data structure\nclass DocumentChunk(DataModel):\n    full_document: str\n    content: str\n\n# prepare data chunks\ndocument_chunks: list[DocumentChunk]\nasync with ctx.scope(\n    \"basic_rag\",\n    # define tokenizer for this context\n    await OpenAI().tokenizer(\"gpt-3.5-turbo\"),\n):\n    document_chunks = [\n        DocumentChunk(\n            full_document=document,\n            content=chunk,\n        )\n        # split document text into smaller parts\n        for chunk in split_text(\n            text=document,\n            separators=(\"\\n\\n\", \" \"),\n            part_size=64,\n            part_overlap_size=16,\n            count_size=count_text_tokens,\n        )\n    ]\n\nprint(f\"Prepared {len(document_chunks)} chunks:\\n---\")\nprint(\"\\n---\\n\".join(chunk.content for chunk in document_chunks))\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with OpenAI Integration\nDESCRIPTION: Demonstrates how to install Draive with OpenAI integration, which enables the use of OpenAI services including GPT, DALL-E, and embedding. Azure services are also supported.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[openai]'\n```\n\n----------------------------------------\n\nTITLE: Creating DataModel with JSON Serialization\nDESCRIPTION: Demonstrates creating a DataModel class with JSON serialization support, schema generation, and automatic validation. Includes example of JSON decoding and schema generation.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom collections.abc import Sequence\n\nfrom draive import DataModel\n\n\n# prepare a class, inherit from DataModel this time\nclass BasicModel(DataModel):\n    username: str\n    tags: Sequence[str] | None = None\n\n\njson: str = \"\"\"\\\n{\n  \"username\": \"John Doe\",\n  \"tags\": [\"example\", \"json\"]\n}\\\"\"\"\n\n# note that the model will be fully validated during decoding\ndecoded_model: BasicModel = BasicModel.from_json(json)\nprint(f\"Decoded model:\\n{decoded_model}\")\n\n# we can also get the json schema of the model\nprint(f\"JSON Schema:\\n{BasicModel.json_schema(indent=2)}\")\n```\n\n----------------------------------------\n\nTITLE: Logging and Metrics in Context Scopes\nDESCRIPTION: Demonstrates how to use logging and metrics features within context scopes, including custom metrics recording and metadata handling.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# we can assign label to the context to better identify it\nasync with ctx.scope(\"logging\"):\n    ctx.log_info(\"We can use associated logger with additional metadata\")\n    # finally we can record custom metrics based on the state we already know\n    # by using a subclass of `State`\n    ctx.record(BasicState(identifier=\"recorded\", value=42))\n```\n\n----------------------------------------\n\nTITLE: Defining a Data Model for OpenAI Generation in Draive\nDESCRIPTION: Creates a structured data model class that inherits from DataModel to define the schema for data to be generated by OpenAI. The model includes required and optional fields with type hints.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicModelGeneration.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import DataModel\n\n\n# define a Model class to describe the data\nclass InterestingPlace(DataModel):\n    name: str\n    description: str | None = None\n```\n\n----------------------------------------\n\nTITLE: Defining Data Model for Extraction with Draive\nDESCRIPTION: Creates a PersonalData class extending DataModel to define the structure for extracted information. The class specifies required fields and their types for the extraction process.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicDataExtraction.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import DataModel\n\nclass PersonalData(DataModel):\n    first_name: str\n    last_name: str\n    age: int | None = None\n    country: str | None = None\n```\n\n----------------------------------------\n\nTITLE: Generating Simplified Schema for DataModel in Python\nDESCRIPTION: Shows how to create a simplified schema representation of a DataModel using the simplified_schema() method. This can be helpful when working with LLMs for structured data generation.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(BasicModel.simplified_schema(indent=2))\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Validation for DataModel Fields in Python\nDESCRIPTION: Demonstrates how to implement custom validation for DataModel fields using the validator parameter in Field. This allows for complete control over field validation.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nfrom draive import ParameterValidationContext, ParameterValidationError\n\n\ndef validator(\n    # validator gets unknown type as an input, make sure to verify or convert it\n    value: Any,\n    /,\n    *,\n    # validator has also the current validation context which contains additional information\n    # i.e. what field actually is validated, it is very useful for preparing diagnostics information\n    context: ParameterValidationContext,\n) -> int:\n    if isinstance(value, int):\n        return value\n\n    else:\n        raise ParameterValidationError(f\"Expected int but received {type(value)}\")\n\n\nclass ValidatedModel(DataModel):\n    value: int = Field(validator=validator)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Tool for UTC DateTime in Python\nDESCRIPTION: This code defines a custom tool using the @tool decorator from draive. The tool returns the current UTC date and time as a formatted string.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicConversation.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import UTC, datetime\n\nfrom draive import tool\n\n\n# prepare a basic tool for getting current date and time\n@tool(description=\"UTC time and date now\")\nasync def utc_datetime() -> str:\n    return datetime.now(UTC).strftime(\"%A %d %B, %Y, %H:%M:%S\")\n```\n\n----------------------------------------\n\nTITLE: Defining Basic State in Python with Draive\nDESCRIPTION: Demonstrates how to create a basic state class by inheriting from draive's State base class. The state includes typed fields that are automatically converted to instance properties.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import State\n\n\n# inherit from the base class\nclass BasicState(State):\n    # fields are automatically converted to instance properties\n    identifier: str\n    value: int\n```\n\n----------------------------------------\n\nTITLE: Converting DataModel to and from Dictionary in Python\nDESCRIPTION: Demonstrates how to convert a DataModel instance to a dictionary and back using as_dict() and from_dict() methods. This feature allows easy serialization and deserialization of DataModel objects.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import BasicValue, DataModel\n\n\nclass DictConverted(DataModel):\n    name: str\n    value: int\n\n\n# all of this applies to the `DataModel` as well\ndict_converted: DictConverted = DictConverted(name=\"converted\", value=42)\ndict_converted_as_dict: dict[str, BasicValue] = dict_converted.as_dict()\ndict_converted_from_dict: DictConverted = DictConverted.from_dict(dict_converted_as_dict)\nprint(dict_converted_from_dict)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Schema for DataModel in Python\nDESCRIPTION: Demonstrates how to generate a JSON schema for a DataModel class using the json_schema() method. This feature is useful for documenting and validating data structures.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass BasicModel(DataModel):\n    field: str\n\nprint(BasicModel.json_schema(indent=2))\n```\n\n----------------------------------------\n\nTITLE: Setting Default Values for DataModel Fields in Python\nDESCRIPTION: Demonstrates various ways to set default values for DataModel fields, including direct assignment, using Field with default value, and using Field with a default value factory.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom collections.abc import Sequence\n\n\nclass CustomizedDefaultsModel(DataModel):\n    default: int = 42\n    field_default: int = Field(default=21)\n    field_default_factory: Sequence[str] = Field(default_factory=list)\n\n\n# since all fields have defaults we can initialize without arguments\nprint(CustomizedDefaultsModel())\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Verification to DataModel Fields in Python\nDESCRIPTION: Shows how to add custom verification to DataModel fields using the verifier parameter in Field. This allows for additional validation beyond type checking.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# verifier gets pre-validated value, it already have required type\ndef verifier(value: int) -> None:\n    if value < 0:\n        # raise an Exception if something is wrong with the value\n        raise ValueError(\"Value can't be less than zero!\")\n\n\nclass VerifiedModel(DataModel):\n    value: int = Field(verifier=verifier)\n```\n\n----------------------------------------\n\nTITLE: Using State Instances and Updates in Draive\nDESCRIPTION: Shows how to create and update State instances using the built-in validation and immutability features. Demonstrates proper state mutation using the updated method.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# create an instance of BasicState\nbasic_state: BasicState = BasicState(\n    identifier=\"basic\",\n    value=42,\n)\n\n# BasicState(\n#     identifier=0, # error! can't instantiate state with wrong data\n#     value=42,\n# )\n\n# prepare an update\nupdated_state: BasicState = basic_state.updated(\n    value=21\n)  # value of `identifier` field won't change\n\n# basic_state.value = 0 # error! can't mutate the state\n```\n\n----------------------------------------\n\nTITLE: Using AttributePath for Nested DataModel Access in Python\nDESCRIPTION: Illustrates the use of AttributePath to access nested fields in DataModel instances. This feature provides a type-safe way to reference and retrieve nested attributes.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import cast\n\nfrom draive import AttributePath\n\n\nclass NestedPathModel(DataModel):\n    values: Sequence[int]\n\n\nclass PathModel(DataModel):\n    nested: NestedPathModel\n    value: int\n\n\n# we can construct the path for any given field inside\npath: AttributePath[PathModel, Sequence[int]] = cast(\n    AttributePath[PathModel, Sequence[int]],\n    PathModel._.nested.values,\n)\npath_model_instance: PathModel = PathModel(\n    value=21,\n    nested=NestedPathModel(\n        values=[42, 21],\n    ),\n)\n# and use it to retrieve that field value from any instance\nprint(path(path_model_instance))\n```\n\n----------------------------------------\n\nTITLE: Accessing State in Functions through Context\nDESCRIPTION: Demonstrates how to access state within function scopes using both traditional argument passing and context-based access patterns.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef do_something(state: BasicState) -> None:\n    pass # use the state here\n```\n\n----------------------------------------\n\nTITLE: State Propagation in Context Scopes\nDESCRIPTION: Shows how to propagate and update state through context scopes, including local state updates and scope management.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync with ctx.scope(\"basics\", basic_state):\n    # here we have access to the state from the context\n    print(\"Initial:\")\n    do_something_contextually()\n\n    # then we can update it locally\n    with ctx.updated(basic_state.updated(identifier=\"updated\")):\n        print(\"Updated:\")\n        # and access its updated version\n        do_something_contextually()\n\n    print(\"Final:\")\n    # when leaving the updated scope we go back to previously defined state\n    do_something_contextually()\n\n# do_something_contextually() # calling it outside of any context scope will cause an error\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with Anthropic Integration\nDESCRIPTION: Shows how to install Draive with Anthropic integration to use Anthropic services including Claude LLMs.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[anthropic]'\n```\n\n----------------------------------------\n\nTITLE: Defining Source Text for Data Extraction\nDESCRIPTION: Creates a string variable containing text about John Doe that will be used as the source for information extraction.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicDataExtraction.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# load document contents for the extraction\ndocument: str = \"\"\"\nJohn Doe, originally from a small farm in Texas, has been living in Vancouver for more than three years. His fascination with Canada began when he first visited the country at the age of seven. The experience left a lasting impression on him, and he knew that one day he would make Canada his home.\n\nAt the age of 18, John made the bold decision to leave his rural life in Texas behind and move to Vancouver. The transition was not without its challenges, as he had to adapt to the fast-paced city life, which was a stark contrast to the slow, quiet days on the farm. However, John's determination and love for his new home helped him overcome any obstacles he faced.\n\nNow, at 21, John has fully embraced his life in Vancouver. He has made new friends, discovered his favorite local spots, and even started attending college to pursue his passion for environmental science. The city's stunning natural beauty, with its lush forests and pristine coastline, reminds him of why he fell in love with Canada in the first place.\n\nJohn's days are filled with exploring the city's diverse neighborhoods, trying new cuisines, and participating in various outdoor activities. He has become an avid hiker, taking advantage of the numerous trails in and around Vancouver. On weekends, he often finds himself hiking in the nearby mountains, breathing in the crisp air and marveling at the breathtaking views.\n\nDespite the occasional homesickness for his family and the familiarity of his Texas farm, John knows that Vancouver is where he belongs. The city has captured his heart, and he can't imagine living anywhere else. He dreams of one day working in the field of environmental conservation, helping to protect the natural wonders that made him fall in love with Canada.\n\nAs John reflects on his journey from a small farm in Texas to the vibrant city of Vancouver, he feels a sense of pride and accomplishment. He knows that his seven-year-old self would be proud of the life he has built in the country that captured his imagination all those years ago. With a smile on his face, John looks forward to the future and all the adventures that Vancouver has in store for him.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with VLLM Integration\nDESCRIPTION: Demonstrates how to install Draive with VLLM integration to use VLLM services through the OpenAI client interface.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[vllm]'\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with Gemini Integration\nDESCRIPTION: Demonstrates how to install Draive with Gemini integration to use Google AIStudio services including Gemini models.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[gemini]'\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with Mistral Integration\nDESCRIPTION: Shows how to install Draive with Mistral integration for using Mistral services. This integration also supports Azure services.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[mistral]'\n```\n\n----------------------------------------\n\nTITLE: Initializing Logging in Draive Framework (Python)\nDESCRIPTION: Sets up Python loggers and adds a new logger with a given name using the Draive framework's setup_logging function.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsetup_logging(\"logging\")\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with Cohere Integration\nDESCRIPTION: Demonstrates how to install Draive with Cohere integration to use Cohere LLM services.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install 'draive[cohere]'\n```\n\n----------------------------------------\n\nTITLE: Customizing Field Conversion for DataModel in Python\nDESCRIPTION: Demonstrates how to customize the conversion of DataModel fields to basic types using the converter parameter in Field. This affects dict conversion and serialization.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef converter(value: str, /,) -> int:\n    return len(value)\n\n\nclass CustomizedConversionModel(DataModel):\n    value: str = Field(converter=converter)\n\n\nprint(CustomizedConversionModel(value=\"integer?\"))\n```\n\n----------------------------------------\n\nTITLE: Mutating Immutable DataModel Instances in Python\nDESCRIPTION: Shows how to perform mutations on immutable DataModel instances using the updated() method. This method creates a new copy of the object with specified field changes.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Mutable(DataModel):\n    identifier: str\n    value: int\n\n\n# prepare an instance of state\ninitial: Mutable = Mutable(\n    identifier=\"pre\",\n    value=42,\n)\n# update one of the fields by creating a copy\nupdated: Mutable = initial.updated(identifier=\"post\")\n# update initial state once more - this will be another copy\nfinal: Mutable = initial.updated(value=21)\n\nprint(\"initial\", initial)\nprint(\"updated\", updated)\nprint(\"final\", final)\n```\n\n----------------------------------------\n\nTITLE: JSON Conversion for DataModel in Python\nDESCRIPTION: Illustrates how to serialize and deserialize DataModel instances to and from JSON format using as_json() and from_json() methods. This feature facilitates easy data exchange and storage.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import DataModel\n\n\nclass JSONConverted(DataModel):\n    name: str\n    value: int\n\n\njson_converted: JSONConverted = JSONConverted(name=\"converted\", value=42)\njson_converted_as_json: str = json_converted.as_json()\njson_converted_from_json: JSONConverted = JSONConverted.from_json(json_converted_as_json)\nprint(json_converted_from_json)\n```\n\n----------------------------------------\n\nTITLE: Customizing DataModel Fields with Aliases and Descriptions in Python\nDESCRIPTION: Explains how to use the Field class to customize DataModel fields with aliases and descriptions. This affects schema generation and provides more detailed field information.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import Field\n\n\nclass CustomizedSchemaModel(DataModel):\n    described: int = Field(description=\"Field description\")\n    aliased: str = Field(aliased=\"field_alias\")\n\n\nprint(f\"JSON schema:\\n{CustomizedSchemaModel.json_schema(indent=2)}\")\nprint(f\"Simplified schema:\\n{CustomizedSchemaModel.simplified_schema(indent=2)}\")\n```\n\n----------------------------------------\n\nTITLE: Customizing Schema Specification for DataModel Fields in Python\nDESCRIPTION: Shows how to provide a custom schema specification for DataModel fields using the specification parameter in Field. This allows for fine-grained control over the JSON schema generation.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass CustomizedSpecificationModel(DataModel):\n    value: int = Field(specification={\"type\": \"integer\", \"description\": \"Fully custom\"})\n\n\nprint(CustomizedSpecificationModel.json_schema(indent=2))\n```\n\n----------------------------------------\n\nTITLE: Installing Draive with pip\nDESCRIPTION: Shows how to install the core Draive library using pip. This provides the base functionality without any specific LLM integrations.\nSOURCE: https://github.com/miquido/draive/blob/main/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install draive\n```\n\n----------------------------------------\n\nTITLE: Using MetricsLogger for Metrics Handling in Draive Framework (Python)\nDESCRIPTION: Shows how to use the MetricsLogger to handle metrics, including creating context scopes, recording metrics, and generating execution summaries. It demonstrates nested scopes and custom metric recording.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import MetricsLogger\n\nasync with ctx.scope(\n    \"logging\",\n    metrics=MetricsLogger.handler(),\n):\n    ctx.log_info(\"Now we can see the logs!\")\n    ctx.record(BasicState(identifier=\"recorded\", value=42))\n\n    with ctx.scope(\"nested\"):\n        ctx.record(BasicState(identifier=\"recorded-nested\", value=11))\n```\n\n----------------------------------------\n\nTITLE: Examining and Combining Requirements\nDESCRIPTION: Shows how to inspect requirement components (lhs, operator, rhs) and combine multiple requirements using the & operator. Demonstrates creating a combined requirement that checks both equality and containment.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprint(\"lhs:\", requirement.lhs)\nprint(\"operator:\", requirement.operator)\nprint(\"rhs:\", requirement.rhs)\n\ncombined_requirement: AttributeRequirement[PathModel] = requirement & AttributeRequirement[\n    PathModel\n].contained_in(\n    [12, 21],\n    path=PathModel._.value,\n)\n\ncombined_requirement.check(path_model_instance)\n```\n\n----------------------------------------\n\nTITLE: Creating and Checking Path Model Requirement\nDESCRIPTION: Creates an AttributeRequirement for checking equality at a specific path in a PathModel instance. Demonstrates basic requirement creation and execution.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nrequirement: AttributeRequirement[PathModel] = AttributeRequirement[PathModel].equal(\n    42, # here we require value to be equal to 42\n    path=PathModel._.nested.values[0], # under this specific path\n)\n\n# requirement can be executed to check value on any instance\nrequirement.check(path_model_instance)\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables in Draive\nDESCRIPTION: Loads environment variables from a .env file, which should include the OPENAI_API_KEY for API access.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicDataExtraction.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env() # load .env variables\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables with Draive\nDESCRIPTION: Initializes the environment by loading variables from a .env file, which should contain the OpenAI API key for subsequent operations.\nSOURCE: https://github.com/miquido/draive/blob/main/cookbooks/BasicRAG.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env() # load .env variables\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables in Draive Framework (Python)\nDESCRIPTION: Demonstrates how to load environment variables from a .env file using the Draive framework's load_env function.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/Basics.md#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env()\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables for OpenAI in Python\nDESCRIPTION: This snippet demonstrates how to load environment variables, specifically the OPENAI_API_KEY, from a .env file using the draive library.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicConversation.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env()  # loads OPENAI_API_KEY from .env file\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables for OpenAI in Draive\nDESCRIPTION: Loads environment variables from a .env file, specifically the OPENAI_API_KEY needed for OpenAI service authentication.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/BasicModelGeneration.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom draive import load_env\n\nload_env()  # loads OPENAI_API_KEY from .env file\n```\n\n----------------------------------------\n\nTITLE: Accessing AttributePath as String in Python\nDESCRIPTION: Shows how to access the string representation of an AttributePath. This can be useful for debugging or generating dynamic queries.\nSOURCE: https://github.com/miquido/draive/blob/main/guides/AdvancedState.md#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprint(path)\n```"
  }
]