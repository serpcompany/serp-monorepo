[
  {
    "owner": "camel-ai",
    "repo": "camel",
    "content": "TITLE: Running and visualizing multi-agent conversation with tool usage\nDESCRIPTION: Executes a conversation between the two agents, displaying system messages, task prompts, and the agents' interactions. The code includes detailed output formatting that shows when tools are used and handles termination conditions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Set the limit for the chat turn\nchat_turn_limit=10\n\nprint(\n    Fore.GREEN\n    + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n)\nprint(\n    Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\"\n)\n\nprint(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\nprint(\n    Fore.CYAN\n    + \"Specified task prompt:\"\n    + f\"\\n{role_play_session.specified_task_prompt}\\n\"\n)\nprint(Fore.RED + f\"Final task prompt:\\n{role_play_session.task_prompt}\\n\")\n\nn = 0\ninput_msg = role_play_session.init_chat()\nwhile n < chat_turn_limit:\n    n += 1\n    assistant_response, user_response = role_play_session.step(input_msg)\n\n    if assistant_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI Assistant terminated. Reason: \"\n                f\"{assistant_response.info['termination_reasons']}.\" \n            )\n        )\n        break\n    if user_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI User terminated. \"\n                f\"Reason: {user_response.info['termination_reasons']}.\" \n            )\n        )\n        break\n\n    # Print output from the user\n    print_text_animated(\n        Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\"\n    )\n\n    if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n        break\n\n    # Print output from the assistant, including any function\n    # execution information\n    print_text_animated(Fore.GREEN + \"AI Assistant:\")\n    tool_calls: list[FunctionCallingRecord] = assistant_response.info[\n        'tool_calls'\n    ]\n    for func_record in tool_calls:\n        print_text_animated(f\"{func_record}\")\n    print_text_animated(f\"{assistant_response.msg.content}\\n\")\n\n\n    input_msg = assistant_response.msg\n```\n\n----------------------------------------\n\nTITLE: Running CAMEL's SelfImprovingCoTPipeline for Math Reasoning Data Generation\nDESCRIPTION: Initializes and executes CAMEL's SelfImprovingCoTPipeline to generate mathematical reasoning data with thought processes. It sets up the reasoning agent, loads problems from a JSON file, and saves the generated results to an output file.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nstart_time = time.time()\nproblems_path = \"downloaded_gsm8k_10.json\"\noutput_path = \"generated_data.json\"\n\n# Load problems from JSON file\nwith open(problems_path, 'r') as f:\n    problems = json.load(f)\n\n# Initialize agent\nreason_agent_system_message = \"\"\"Answer my question and give your\nfinal answer within \\boxed{}.\"\"\"\nevaluate_agent_system_message = \"\"\"You are a highly critical teacher who\nevaluates the student's answers with a meticulous and demanding approach.\n\"\"\"\n\n# Set up reason agent\nreason_agent = ChatAgent(\n    system_message=reason_agent_system_message,\n    model=[reason_model_1, reason_model_2], # add models to the list, You can also switch to other models\n)\n\n# # Set up evaluate agent(optional)\n# evaluate_agent = ChatAgent(\n#     system_message=evaluate_agent_system_message\n# )\n\n# # Initialize reward model (optional)\n# reward_model = NemotronRewardModel(\n#     model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n#     url=\"https://integrate.api.nvidia.com/v1\",\n#     api_key=os.environ.get(\"NVIDIA_API_KEY\"),\n# )\n\n# # Set score thresholds for different dimensions (optional)\n# score_threshold = {\n#     \"correctness\": 1.0,\n#     \"clarity\": 0.0,\n#     \"completeness\": 0.0,\n# }\n# # Or use a single threshold for all dimensions:\n# score_threshold = 0.9\n\n\n# Create and run pipeline\npipeline = SelfImprovingCoTPipeline(\n    reason_agent=reason_agent,\n    problems=problems,  # Pass problems list directly\n    output_path=output_path,\n    max_iterations=0,\n    batch_size=100, # Size of batch to process the data (optional)\n    # evaluate_agent=evaluate_agent, # To use evaluate agent(optional)\n    # score_threshold=score_threshold, # Score thresholds for agent evaluation (optional)\n    # reward_model=reward_model,  # To use a reward model (optional)\n)\n\nprint(\"Start generation! May take some time, please wait..\")\n\nresults = pipeline.generate(rationalization=False)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nprint(f\"\\nProcessed {len(results)} problems\")\nprint(f\"Results saved to: {output_path}\")\nprint(f\"Total execution time: {execution_time:.2f} seconds\")\n```\n\n----------------------------------------\n\nTITLE: Creating a ChatAgent with Tools from Multiple Toolkits\nDESCRIPTION: Setting up a ChatAgent with access to mathematical and search tools. This demonstrates how to equip an agent with external capabilities by integrating tools from MathToolkit and SearchToolkit.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Import the necessary tools\nfrom camel.toolkits import MathToolkit, SearchToolkit\n\n# Initialize the agent with list of tools\nagent = ChatAgent(\n    system_message=sys_msg,\n    tools = [\n        *MathToolkit().get_tools(),\n        *SearchToolkit().get_tools(),\n    ]\n    )\n\n# Let agent step the message\nresponse = agent.step(\"What is CAMEL AI?\")\n\n# Check tool calling\nprint(response.info['tool_calls'])\n\n# Get response content\nprint(response.msgs[0].content)\n```\n\n----------------------------------------\n\nTITLE: Setting up RolePlaying with tool-enabled agents\nDESCRIPTION: Creates a RolePlaying session with two agents: a Searcher (assistant) equipped with tools and a Professor (user). The task involves estimating Oxford University's age and adding 10 years to it, demonstrating inter-agent collaboration with tool use.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Set a task\ntask_prompt=(\"Assume now is 2024 in the Gregorian calendar, \"\n        \"estimate the current age of University of Oxford \"\n        \"and then add 10 more years to this age.\")\n\n# Set role playing\nrole_play_session = RolePlaying(\n    assistant_role_name=\"Searcher\",\n    user_role_name=\"Professor\",\n    assistant_agent_kwargs=dict(\n        model=ModelFactory.create(\n            model_platform=ModelPlatformType.OPENAI,\n            model_type=ModelType.GPT_4O_MINI,\n        ),\n        tools=tools_list,\n    ),\n    user_agent_kwargs=dict(\n        model=ModelFactory.create(\n            model_platform=ModelPlatformType.OPENAI,\n            model_type=ModelType.GPT_4O_MINI,\n        ),\n    ),\n    task_prompt=task_prompt,\n    with_task_specify=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Managing Agent Interaction Loop in CAMEL Framework\nDESCRIPTION: Implements a conversation loop between the assistant and user agents, with a maximum of 20 turns. The loop handles message exchange, termination conditions, and displays the conversation including function calls made by the assistant. Includes animated text output for better readability.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nn = 0\ninput_msg = role_play_session.init_chat()\nwhile n < 20: # Limit the chat to 20 turns\n    n += 1\n    assistant_response, user_response = role_play_session.step(input_msg)\n\n    if assistant_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI Assistant terminated. Reason: \"\n                f\"{assistant_response.info['termination_reasons']}.\" \n            )\n        )\n        break\n    if user_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI User terminated. \"\n                f\"Reason: {user_response.info['termination_reasons']}.\" \n            )\n        )\n        break\n    # Print output from the user\n    print_text_animated(\n        Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\",\n        0.01\n    )\n\n    if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n        break\n\n    # Print output from the assistant, including any function\n    # execution information\n    print_text_animated(Fore.GREEN + \"AI Assistant:\", 0.01)\n    tool_calls: List[FunctionCallingRecord] = [\n        FunctionCallingRecord(**call.as_dict())\n        for call in assistant_response.info['tool_calls']\n    ]\n    for func_record in tool_calls:\n        print_text_animated(f\"{func_record}\", 0.01)\n    print_text_animated(f\"{assistant_response.msg.content}\\n\", 0.01)\n\n    input_msg = assistant_response.msg\n```\n\n----------------------------------------\n\nTITLE: Initializing ChatAgent with tools and model configuration\nDESCRIPTION: Sets up a ChatAgent with the specified tools list, system message, and language model. Uses GPT-4o Mini from OpenAI as the model, which supports tool calling functionality.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Set the backend mode, this model should support tool calling\nmodel=ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI\n)\n\n# Set message for the assistant\nassistant_sys_msg =  \"\"\"You are a helpful assistant to do search task.\"\"\"\n\n\n# Set the agent\nagent = ChatAgent(\n    assistant_sys_msg,\n    model=model,\n    tools=tools_list\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Context Creator\nDESCRIPTION: Example of implementing a custom context creator by subclassing BaseContextCreator\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.memories import BaseContextCreator\n\nclass MyCustomContextCreator(BaseContextCreator):\n    @property\n    def token_counter(self):\n        # Implement your token counting logic\n        return\n\n    @property\n    def token_limit(self):\n        return 1000  # Or any other limit\n\n    def create_context(self, records):\n        # Implement your context creation logic\n        pass\n```\n\n----------------------------------------\n\nTITLE: Comparing Model Response Speeds using CAMEL Framework\nDESCRIPTION: Comprehensive implementation for measuring and comparing the response speed of different AI models. Creates model instances, initializes ChatAgent objects, measures token generation speed, and visualizes the results using matplotlib. Includes configurations for models from OpenAI and SambaNova platforms.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/model_speed_comparison.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport matplotlib.pyplot as plt\nfrom camel.agents import ChatAgent\nfrom camel.configs import SambaCloudAPIConfig, ChatGPTConfig\nfrom camel.messages import BaseMessage\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n\n# Create model instances\ndef create_models():\n    model_configs = [\n        (ModelPlatformType.OPENAI, ModelType.GPT_4O_MINI, ChatGPTConfig(temperature=0.0, max_tokens=2000), \"OpenAI GPT-4O Mini\"),\n        (ModelPlatformType.OPENAI, ModelType.GPT_4O, ChatGPTConfig(temperature=0.0, max_tokens=2000), \"OpenAI GPT-4O\"),\n        # NOTE: OpenAI O1 model requires additional additional credentials\n        (ModelPlatformType.OPENAI, ModelType.O1_PREVIEW, ChatGPTConfig(temperature=0.0), \"OpenAI O1 Preview\"),\n        (ModelPlatformType.SAMBA, \"Meta-Llama-3.1-8B-Instruct\", SambaCloudAPIConfig(temperature=0.0, max_tokens=2000), \"SambaNova Llama 8B\"),\n        (ModelPlatformType.SAMBA, \"Meta-Llama-3.1-70B-Instruct\", SambaCloudAPIConfig(temperature=0.0, max_tokens=2000), \"SambaNova Llama 70B\"),\n        (ModelPlatformType.SAMBA, \"Meta-Llama-3.1-405B-Instruct\", SambaCloudAPIConfig(temperature=0.0, max_tokens=2000), \"SambaNova Llama 405B\")\n    ]\n\n    models = [(ModelFactory.create(model_platform=platform, model_type=model_type, model_config_dict=config.as_dict(), url=\"https://api.sambanova.ai/v1\" if platform == ModelPlatformType.SAMBA else None), name)\n              for platform, model_type, config, name in model_configs]\n    return models\n\n# Define messages\ndef create_messages():\n    sys_msg = BaseMessage.make_assistant_message(role_name=\"Assistant\", content=\"You are a helpful assistant.\")\n    user_msg = BaseMessage.make_user_message(role_name=\"User\", content=\"Tell me a long story.\")\n    return sys_msg, user_msg\n\n# Initialize ChatAgent instances\ndef initialize_agents(models, sys_msg):\n    return [(ChatAgent(system_message=sys_msg, model=model), name) for model, name in models]\n\n# Measure response time for a given agent\ndef measure_response_time(agent, message):\n    start_time = time.time()\n    response = agent.step(message)\n    end_time = time.time()\n    tokens_per_second = response.info['usage'][\"completion_tokens\"] / (end_time - start_time)\n    return tokens_per_second\n\n# Visualize results\ndef plot_results(model_names, tokens_per_sec):\n    plt.figure(figsize=(10, 6))\n    plt.barh(model_names, tokens_per_sec, color='skyblue')\n    plt.xlabel(\"Tokens per Second\")\n    plt.title(\"Model Speed Comparison: Tokens per Second\")\n    plt.gca().invert_yaxis()\n    plt.show()\n\n# Main execution\nmodels = create_models()\nsys_msg, user_msg = create_messages()\nagents = initialize_agents(models, sys_msg)\n\n# Measure response times and collect data\nmodel_names = []\ntokens_per_sec = []\n\nfor agent, model_name in agents:\n    model_names.append(model_name)\n    tokens_per_sec.append(measure_response_time(agent, user_msg))\n\n# Visualize the results\nplot_results(model_names, tokens_per_sec)\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Generation Function\nDESCRIPTION: Defines a function to generate a list of instruction-input-response triplets based on given content. It uses CAMEL's ChatAgent with GPT-4 to create Alpaca-formatted items for later filtering with a reward model.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.configs import ChatGPTConfig\nfrom camel.agents import ChatAgent\n\ndef generate_alpaca_items(content: str, n_items: int, start_num: int = 1, examples: List[AlpacaItem] = None) -> List[AlpacaItem]:\n    system_msg = \"\"\"\nYou are an AI assistant generating detailed, accurate responses based on the provided content.\nYou will be given a reference content, and you must generate a specific number of AlpacaItems.\nThese are instruction-input-response triplets, where the input is the context or examples.\n\nAdd a number to the items to keep track of the order. Generate exactly that many.\n\nFor each instruction, imagine but do not include a real world scenario and real user in that scenario to inform realistic and varied instructions. Avoid common sense questions and answers.\n\nInclude multiple lines in the output as appropriate to provide sufficient detail. Cite the most relevant context verbatim in output fields, do not omit anything important.\n\nLeave the input field blank.\n\nEnsure all of the most significant parts of the context are covered.\n\nStart with open ended instructions, then move to more specific ones. Consider the starting number for an impression of what has already been generated.\n    \"\"\"\n\n    examples_str = \"\"\n    if examples:\n        examples_str = \"\\n\\nHere are some example items for reference:\\n\" + \\\n            \"\\n\".join(ex.model_dump_json() for ex in examples)\n\n    model = ModelFactory.create(\n        model_platform=ModelPlatformType.OPENAI,\n        model_type=ModelType.GPT_4O_MINI,\n        model_config_dict=ChatGPTConfig(\n            temperature=0.6, response_format=AlpacaItemResponse\n        ).as_dict(),\n    )\n\n    agent = ChatAgent(\n        system_message=system_msg,\n        model=model,\n    )\n\n    prompt = f\"Content reference:\\n{content}{examples_str}\\n\\n Generate {n_items} AlpacaItems. The first should start numbering at {start_num}.\"\n    response = agent.step(prompt)\n\n    # Parse the generated JSON to our wrapper class\n    alpaca_items = [n_item.item for n_item in\n                    AlpacaItemResponse.\n                    model_validate_json(response.msgs[0].content).items]\n\n    return alpaca_items\n\n# Few shot examples to ensure the right amount of detail\nexamples = [\n    AlpacaItem(\n        instruction=\"Explain the process for sprint planning and review in CAMEL.\",\n        input=\"\",\n        output=\"The process for sprint planning and review in CAMEL includes:\\n1. **Sprint Duration**: Each sprint lasts two weeks for development and one week for review.\\n2. **Planning Meeting**: Conducted biweekly, where the founder highlights the sprint goal and developers select items for the sprint.\\n3. **Review Meeting**: Stakeholders review the delivered features and provide feedback on the work completed during the sprint.\"\n    )\n]\n```\n\n----------------------------------------\n\nTITLE: Implementing RolePlaying Session Runner in Python\nDESCRIPTION: Defines a function to run the role-playing session with a specified round limit, handling agent interactions and termination conditions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef run(society, round_limit: int=10):\n\n    # Get the initial message from the ai assistant to the ai user\n    input_msg = society.init_chat()\n\n    # Starting the interactive session\n    for _ in range(round_limit):\n\n        # Get the both responses for this round\n        assistant_response, user_response = society.step(input_msg)\n\n        # Check the termination condition\n        if is_terminated(assistant_response) or is_terminated(user_response):\n            break\n\n        # Get the results\n        print(f'[AI User] {user_response.msg.content}.\\n')\n        print(f'[AI Assistant] {assistant_response.msg.content}.\\n')\n\n        # Check if the task is end\n        if 'CAMEL_TASK_DONE' in user_response.msg.content:\n            break\n\n        # Get the input message for the next round\n        input_msg = assistant_response.msg\n\n    return None\n```\n\n----------------------------------------\n\nTITLE: Executing CAMEL's Self-Improving CoT Pipeline for Mathematical Reasoning\nDESCRIPTION: Executes the SelfImprovingCoTPipeline on mathematical problems, using the configured reasoning and evaluation agents. The pipeline generates step-by-step solutions, evaluates them, and improves them iteratively up to the specified maximum number of iterations.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nstart_time = time.time()\nproblems_path = \"downloaded_gsm8k_10.json\"\noutput_path = \"generated_data.json\"\n\n# Load problems from JSON file\nwith open(problems_path, 'r') as f:\n    problems = json.load(f)\n\n# Initialize agent\nreason_agent_system_message = \"\"\"Answer my question and give your\nfinal answer within \\boxed{}.\"\"\"\nevaluate_agent_system_message = \"\"\"You are a highly critical teacher who\nevaluates the student's answers with a meticulous and demanding approach.\n\"\"\"\n\n# Set up reason agent\nreason_agent = ChatAgent(\n    system_message=reason_agent_system_message,\n    model=[reason_model_1, reason_model_2], # add models to the list\n)\n\n# Set up evaluate agent\nevaluate_agent = ChatAgent(\n    system_message=evaluate_agent_system_message,\n    model=evaluate_model,\n)\n\n# # Initialize reward model (optional)\n# reward_model = NemotronRewardModel(\n#     model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n#     url=\"https://integrate.api.nvidia.com/v1\",\n#     api_key=os.environ.get(\"NVIDIA_API_KEY\"),\n# )\n\n# Set score thresholds for different dimensions (optional)\nscore_threshold = {\n    \"correctness\": 1.0,\n    \"clarity\": 0.0,\n    \"completeness\": 0.0,\n}\n# # Or use a single threshold for all dimensions:\n# score_threshold = 0.9\n\n\n# Create and run pipeline\npipeline = SelfImprovingCoTPipeline(\n    reason_agent=reason_agent,\n    problems=problems,  # Pass problems list directly\n    output_path=output_path,\n    max_iterations=2,\n    batch_size=100, # Size of batch to process the data (optional)\n    evaluate_agent=evaluate_agent, # To use evaluate agent(optional)\n    score_threshold=score_threshold, # Score thresholds for agent evaluation (optional)\n    # reward_model=reward_model,  # To use a reward model (optional)\n)\nprint(\"Start generation! May take some time, please wait..\")\nresults = pipeline.generate(rationalization=True)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nprint(f\"\\nProcessed {len(results)} problems\")\nprint(f\"Results saved to: {output_path}\")\nprint(f\"Total execution time: {execution_time:.2f} seconds\")\n```\n\n----------------------------------------\n\nTITLE: Initializing the EmbodiedAgent\nDESCRIPTION: Creates an instance of the EmbodiedAgent with the generated system message. The agent uses default tool agents and code interpreter settings with verbose output enabled.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nembodied_agent = EmbodiedAgent(system_message=sys_msg,\n                               tool_agents=None,\n                               code_interpreter=None,\n                               verbose=True)\n```\n\n----------------------------------------\n\nTITLE: Filtering Generated Data Using Reward Model\nDESCRIPTION: Applies NVIDIA's Nemotron Reward Model to filter out low-quality instruction-input-response triplets. It uses defined thresholds for helpfulness and correctness to retain high-quality responses.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nthresholds = {\"helpfulness\": 2.5, \"correctness\": 2.5}\nfiltered_messages_lists = []\nfor messages_list in messages_lists:\n    response = evaluator.filter_data(messages_list, thresholds)\n    if response:\n        filtered_messages_lists.append(messages_list)\n\nprint(len(filtered_messages_lists))\n```\n\n----------------------------------------\n\nTITLE: Implementing Single Agent with Auto RAG in CAMEL\nDESCRIPTION: Defines a function that combines AutoRetriever with a ChatAgent to create a single agent capable of answering queries using RAG. This demonstrates how to integrate RAG into a conversational AI system.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\nfrom camel.types import RoleType\nfrom camel.retrievers import AutoRetriever\nfrom camel.types import StorageType\n\ndef single_agent(query: str) ->str :\n    # Set agent role\n    assistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n         I will give you the Original Query and Retrieved Context,\n        answer the Original Query based on the Retrieved Context,\n        if you can't answer the question just say I don't know.\"\"\"\n\n    # Add auto retriever\n    auto_retriever = AutoRetriever(\n            vector_storage_local_path=\"local_data2/\",\n            storage_type=StorageType.QDRANT,\n            embedding_model=embedding_instance)\n\n    retrieved_info = auto_retriever.run_vector_retriever(\n        query=query,\n        contents=[\n            \"local_data/camel_paper.pdf\",  # example local path\n            \"https://github.com/camel-ai/camel/wiki/Contributing-Guidlines\",  # example remote url\n        ],\n        top_k=1,\n        return_detailed_info=False,\n        similarity_threshold=0.5\n    )\n\n    # Pass the retrieved information to agent\n    user_msg = str(retrieved_info)\n    agent = ChatAgent(assistant_sys_msg)\n\n    # Get response\n    assistant_response = agent.step(user_msg)\n    return assistant_response.msg.content\n\nprint(single_agent(\"If I'm interest in contributing to the CAMEL project, what should I do?\"))\n```\n\n----------------------------------------\n\nTITLE: Creating and Using ChatAgent\nDESCRIPTION: Example showing how to create a ChatAgent instance with OpenAI model and DuckDuckGo search capability, then use it for queries.\nSOURCE: https://github.com/camel-ai/camel/blob/master/README.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.agents import ChatAgent\nfrom camel.toolkits import SearchToolkit\n\nmodel = ModelFactory.create(\n  model_platform=ModelPlatformType.OPENAI,\n  model_type=ModelType.GPT_4O,\n  model_config_dict={\"temperature\": 0.0},\n)\n\nsearch_tool = SearchToolkit().search_duckduckgo\n\nagent = ChatAgent(model=model, tools=[search_tool])\n\nresponse_1 = agent.step(\"What is CAMEL-AI?\")\nprint(response_1.msgs[0].content)\n# CAMEL-AI is the first LLM (Large Language Model) multi-agent framework\n# and an open-source community focused on finding the scaling laws of agents.\n# ...\n\nresponse_2 = agent.step(\"What is the Github link to CAMEL framework?\")\nprint(response_2.msgs[0].content)\n# The GitHub link to the CAMEL framework is\n# [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel).\n```\n\n----------------------------------------\n\nTITLE: Defining Task Prompt for NYC Travel Itinerary\nDESCRIPTION: Creates a detailed task prompt that defines the objective for the AI agents. The prompt instructs the agents to generate a 2-day travel itinerary for New York City based on real-time weather forecasts, including steps to determine dates, fetch weather data, and design appropriate activities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntask_prompt = \"\"\"Generate a 2-day travel itinerary for New York City, tailored to the real-time weather forecast for the upcoming weekend. Follow these steps:\n\nDetermine Current Date and Weekend:\nUse Dappier's real-time search to identify the current date and day. Calculate the dates of the upcoming weekend based on this information.\n\nFetch Weather Data:\nRetrieve the weather forecast for the identified weekend dates to understand the conditions for each day.\n\nDesign the Itinerary:\nUse the weather insights to plan activities and destinations that suit the expected conditions. For each suggested location:\n\nVerify whether it is free to visit or requires advance booking.\nCheck current traffic conditions to estimate travel times and feasibility.\nOutput:\nPresent a detailed 2-day itinerary, including timing, activities, and travel considerations. Ensure the plan is optimized for convenience and enjoyment.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple AI Agents for Hackathon Judging in Python\nDESCRIPTION: This code creates multiple AI agents using CAMEL-AI, including a researcher agent with search capabilities and judge agents with different personas and evaluation criteria. It demonstrates the setup of specialized agents for a collaborative judging system.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/multi_agent_society/workforce_judge_committee.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create helper agent\nsearch_toolkit = SearchToolkit()\nsearch_tools = [\n    FunctionTool(search_toolkit.search_google),\n    FunctionTool(search_toolkit.search_duckduckgo),\n]\n\nresearcher_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O,\n)\n\nresearcher_agent = ChatAgent(\n    system_message=BaseMessage.make_assistant_message(\n        role_name=\"Researcher\",\n        content=\"You are a researcher who does research on AI and Open\"\n        \"Sourced projects. You use web search to stay updated on the \"\n        \"latest innovations and trends.\",\n    ),\n    model=researcher_model,\n    tools=search_tools,\n)\n\n# Create venture capitalist judge\nvc_persona = (\n    'You are a venture capitalist who is obsessed with how projects can '\n    'be scaled into \"unicorn\" companies. You peppers your speech with '\n    'buzzwords like \"disruptive,\" \"synergistic,\" and \"market penetration.\"'\n    ' You do not concerned with technical details or innovation unless '\n    'it directly impacts the business model.'\n)\n\nvc_example_feedback = (\n    '\"Wow, this project is absolutely disruptive in the blockchain-enabled'\n    ' marketplace! I can definitely see synergistic applications in the '\n    'FinTech ecosystem. The scalability is through the roof--this is '\n    'revolutionary!'\n)\n\nvc_criteria = textwrap.dedent(\n    \"\"\"\\\n    ### **Applicability to Real-World Usage (1-4 points)**\n    - **4**: The project directly addresses a significant real-world problem with a clear, scalable application.\n    - **3**: The solution is relevant to real-world challenges but requires more refinement for practical or widespread use.\n    - **2**: Some applicability to real-world issues, but the solution is not immediately practical or scalable.\n    - **1**: Little or no relevance to real-world problems, requiring substantial changes for practical use.\n    \"\"\"  # noqa: E501\n)\n\nvc_agent = make_judge(\n    vc_persona,\n    vc_example_feedback,\n    vc_criteria,\n)\n\n# Create experience engineer judge\neng_persona = (\n    'You are an experienced engineer and a perfectionist. You are highly '\n    'detail-oriented and critical of any technical flaw, no matter how '\n    'small. He evaluates every project as though it were going into a '\n    'mission-critical system tomorrow, so his feedback is thorough but '\n    'often harsh.'\n)\n\neng_example_feedback = (\n    'There are serious code inefficiencies in this project. The '\n    'architecture is unstable, and the memory management is suboptimal. '\n    'I expect near-perfect performance, but this solution barely functions'\n    ' under stress tests. It has potential, but it is nowhere near '\n    'deployment-ready.'\n)\n\neng_criteria = textwrap.dedent(\n    \"\"\"\\\n    ### **Technical Implementation (1-4 points)**\n    - **4**: Flawless technical execution with sophisticated design, efficient performance, and robust architecture.\n    - **3**: Strong technical implementation, though there may be areas for improvement or further development.\n    - **2**: The project works, but technical limitations or inefficiencies hinder its overall performance.\n    - **1**: Poor technical implementation with major issues in functionality, coding, or structure.\n    \"\"\"  # noqa: E501\n)\n\neng_agent = make_judge(\n    eng_persona,\n    eng_example_feedback,\n    eng_criteria,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing a ChatAgent with System Message and Model\nDESCRIPTION: Creating a ChatAgent instance with a defined system message, language model, and message window size. This sets up the agent with the previously defined role and model configuration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nagent = ChatAgent(\n    system_message=sys_msg,\n    model=model,\n    message_window_size=10, # [Optional] the length for chat memory\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoRetriever for Qdrant Storage\nDESCRIPTION: Configures the AutoRetriever component for retrieving information from Qdrant storage, including system message setup and chat agent initialization\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.retrievers import AutoRetriever\nfrom camel.types import StorageType\n\nassistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n         I will give you the Original Query and Retrieved Context,\n        answer the Original Query based on the Retrieved Context,\n        if you can't answer the question just say I don't know.\n        Just give the answer to me directly, no more other words needed.\n        \"\"\"\nauto_retriever = AutoRetriever(\n              vector_storage_local_path=\"local_data2/\",\n              storage_type=StorageType.QDRANT,\n              embedding_model=sentence_encoder\n            )\nchat_agent_with_rag = ChatAgent(system_message=assistant_sys_msg, model=qwen_model)\n```\n\n----------------------------------------\n\nTITLE: Adding External Message to ChatAgent Memory\nDESCRIPTION: Creating a custom user message and adding it to the agent's memory. This demonstrates how to manually update the agent's conversation history with externally generated messages.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.messages import BaseMessage\n\nnew_user_msg = BaseMessage.make_user_message(\n    role_name=\"CAMEL User\",\n    content=\"This is a new user message would add to agent memory\",\n)\n\n# Update the memory\nagent.record_message(new_user_msg)\n```\n\n----------------------------------------\n\nTITLE: Generating Training Data from CAMEL Documentation\nDESCRIPTION: Scrapes documentation from the CAMEL GitHub repository and generates training data in batches of 50 items. Uses the previously defined functions to create high-quality instruction-response pairs in Alpaca format.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport random\nfirecrawl = Firecrawl()\n# Scrape and clean content from a specified URL\nresponse = firecrawl.scrape(\n    url=\"https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md\"\n)\n\n# Generate the items 50 a time up to 300\nalpaca_entries = []\nfor start in range(1, 301, 50):\n    # Combine default examples with random samples from previous generations\n    current_examples = examples + (random.sample(alpaca_entries,\n                                                 min(5, len(alpaca_entries)))\n                                                  if alpaca_entries else [])\n\n    batch = generate_alpaca_items(\n        content=response[\"markdown\"],\n        n_items=50,\n        start_num=start,\n        examples=current_examples\n    )\n    print(f\"Generated {len(batch)} items\")\n    alpaca_entries.extend(batch)\n\nprint(alpaca_entries)\nsave_json(alpaca_entries, 'alpaca_format_data.json')\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Agent with Real-Time Data Tools\nDESCRIPTION: Sets up the assistant agent with tools for retrieving real-time data, specifically the Dappier toolkit for real-time searches. This configuration includes setting the tool list and configuring the ChatGPT model with appropriate parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndappier_tool = FunctionTool(DappierToolkit().search_real_time_data)\n\ntool_list = [\n    dappier_tool\n]\n\nassistant_model_config = ChatGPTConfig(\n    tools=tool_list,\n    temperature=0.0,\n)\n```\n\n----------------------------------------\n\nTITLE: Combining built-in and custom tools for agent use\nDESCRIPTION: Creates a combined list of tools including both the built-in search toolkit from CAMEL and the custom math functions. The MathToolkit is commented out as custom math functions are being used instead.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntools_list = [\n    # *MathToolkit().get_tools(),\n    *SearchToolkit().get_tools(),\n    *MATH_FUNCS,\n]\n```\n\n----------------------------------------\n\nTITLE: Setting Up Language Model Using ModelFactory\nDESCRIPTION: Code to initialize a language model using CAMEL's ModelFactory. This example creates a GPT-4o-mini model with OpenAI platform configuration, which will be used as the backend for the ChatAgent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.configs import ChatGPTConfig\n\n# Define the model, here in this case we use gpt-4o-mini\nmodel = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n    model_config_dict=ChatGPTConfig().as_dict(), # [Optional] the config for model\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up Basic Chatbot Interaction Loop in Python\nDESCRIPTION: This Python code sets up a basic chatbot interaction loop. It continuously prompts for user input, processes it through the ChatAgent, and prints the assistant's response until the user types 'exit'.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Start chatting! Type 'exit' to end the conversation.\")\nwhile True:\n    user_input = input(\"User: \")\n\n    if user_input.lower() == \"exit\":\n        print(\"Ending conversation.\")\n        break\n\n    assistant_response = chat_agent.step(user_input)\n    print(f\"Assistant: {assistant_response.msgs[0].content}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing SentenceTransformer Encoder for Qdrant in CAMEL\nDESCRIPTION: Sets up a sentence encoder using the SentenceTransformer model 'intfloat/e5-large-v2' to create embeddings for vector search capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_with_agentic_RAG.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.embeddings import SentenceTransformerEncoder\n\nsentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n```\n\n----------------------------------------\n\nTITLE: Running the CAMEL Agent Society Conversation\nDESCRIPTION: Implements a function to run the society conversation for a specified number of rounds, handling agent responses and checking for task completion or termination conditions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef run(society, round_limit: int=10):\n\n    # Get the initial message from the ai assistant to the ai user\n    input_msg = society.init_chat()\n\n    # Starting the interactive session\n    for _ in range(round_limit):\n\n        # Get the both responses for this round\n        assistant_response, user_response = society.step(input_msg)\n\n        # Check the termination condition\n        if is_terminated(assistant_response) or is_terminated(user_response):\n            break\n\n        # Get the results\n        print(f'[AI User] {user_response.msg.content}.\\n')\n        # Check if the task is end\n        if 'CAMEL_TASK_DONE' in user_response.msg.content:\n            break\n        print(f'[AI Assistant] {assistant_response.msg.content}.\\n')\n\n\n\n        # Get the input message for the next round\n        input_msg = assistant_response.msg\n\n    return None\n```\n\n----------------------------------------\n\nTITLE: Inserting External Knowledge into ChatAgent in Python\nDESCRIPTION: This Python code reads the crawled knowledge from a file, creates a BaseMessage with the knowledge, and updates the ChatAgent's memory with this information.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith open('local_data/camel.md', 'r') as file:\n  knowledge = file.read()\n\nknowledge_message = BaseMessage.make_user_message(\n    role_name=\"User\", content=f\"Based on the following knowledge: {knowledge}\"\n)\nchat_agent.update_memory(knowledge_message, \"user\")\n```\n\n----------------------------------------\n\nTITLE: Loading Sample Data from arXiv PDF\nDESCRIPTION: Downloads a PDF file from arXiv and saves it locally. This creates a sample dataset for demonstrating RAG techniques.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\n\nos.makedirs('local_data', exist_ok=True)\n\nurl = \"https://arxiv.org/pdf/2303.17760.pdf\"\nresponse = requests.get(url)\nwith open('local_data/camel_paper.pdf', 'wb') as file:\n     file.write(response.content)\n```\n\n----------------------------------------\n\nTITLE: Executing the CAMEL Society Conversation\nDESCRIPTION: Calls the run function to start the society's conversation, initiating the collaborative task solving process between the agents.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nrun(society)\n```\n\n----------------------------------------\n\nTITLE: Running Inference with FastLanguageModel for CAMEL-AI\nDESCRIPTION: This code snippet demonstrates how to run inference with a CAMEL model using FastLanguageModel for 2x faster inference. It shows how to format input using AlpacaItem, generate text with specified parameters, and decode the outputs.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n\n    AlpacaItem(\n        instruction=\"Explain how can I stay up to date with the CAMEL community.\",\n        input=\"\",\n        output=\"\", # leave this blank for generation!\n    ).to_string()\n\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\n----------------------------------------\n\nTITLE: Implementing HuggingFace Dataset Upload Pipeline for Mathematical Reasoning Data\nDESCRIPTION: Defines functions to upload the generated mathematical reasoning data to Hugging Face, including loading data, creating dataset records, generating dataset metadata, and handling the upload process.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary modules and classes\nfrom camel.datahubs.huggingface import HuggingFaceDatasetManager  # Manages interactions with Hugging Face datasets\nfrom camel.datahubs.models import Record  # Represents a single record in the dataset\nfrom datetime import datetime  # Handles date and time operations\nimport json  # For reading JSON files\n\ndef load_star_output(file_path):\n    r\"\"\"Load and parse the star output JSON file.\n\n    Args:\n        file_path (str): Path to the star_output.json file.\n\n    Returns:\n        list: List of traces from the JSON file.\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data['traces']\n\n# Main function: Upload dataset to Hugging Face\ndef upload_to_huggingface(transformed_data, username, dataset_name=None):\n    r\"\"\"Uploads transformed data to the Hugging Face dataset platform.\n\n    Args:\n        transformed_data (list): Transformed data, typically a list of dictionaries.\n        username (str): Hugging Face username.\n        dataset_name (str, optional): Custom dataset name.\n\n    Returns:\n        str: URL of the uploaded dataset.\n    \"\"\"\n    # Initialize HuggingFaceDatasetManager to interact with Hugging Face datasets\n    manager = HuggingFaceDatasetManager()\n\n    # Generate or validate the dataset name\n    dataset_name = generate_or_validate_dataset_name(username, dataset_name)\n\n    # Create the dataset on Hugging Face and get the dataset URL\n    dataset_url = create_dataset(manager, dataset_name)\n\n    # Create a dataset card to add metadata\n    create_dataset_card(manager, dataset_name, username)\n\n    # Convert the transformed data into a list of Record objects\n    records = create_records(transformed_data)\n\n    # Add the Record objects to the dataset\n    add_records_to_dataset(manager, dataset_name, records)\n\n    # Return the dataset URL\n    return dataset_url\n\n# Generate or validate the dataset name\ndef generate_or_validate_dataset_name(username, dataset_name):\n    r\"\"\"Generates a default dataset name or validates and formats a user-provided name.\n\n    Args:\n        username (str): Hugging Face username.\n        dataset_name (str, optional): User-provided custom dataset name.\n\n    Returns:\n        str: Formatted dataset name.\n    \"\"\"\n    if dataset_name is None:\n        # If no dataset name is provided, generate a default name with the username and current date\n        current_date = datetime.now().strftime(\"%Y%m%d\")\n        dataset_name = f\"star_traces_{current_date}\"\n\n    # Format the dataset name to include the username\n    return f\"{username}/{dataset_name}\"\n\n# Create a dataset on Hugging Face\ndef create_dataset(manager, dataset_name):\n    r\"\"\"Creates a new dataset on Hugging Face and returns the dataset URL.\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n\n    Returns:\n        str: URL of the created dataset.\n    \"\"\"\n    dataset_url = manager.create_dataset(dataset_name)\n    return dataset_url\n\n# Create a dataset card with metadata\ndef create_dataset_card(manager, dataset_name, username):\n    r\"\"\"Creates a dataset card to add metadata\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n        username (str): Hugging Face username.\n    \"\"\"\n    manager.create_dataset_card(\n        dataset_name=dataset_name,\n        description=\"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.\",\n        license=\"mit\",  # Using lowercase 'mit' as required by HuggingFace\n        tags=[\"math\", \"problem-solving\", \"step-by-step\", \"traces\"],\n        authors=[username],\n        language=[\"en\"],\n        task_categories=[\"text-generation\"],\n        content=\"This dataset contains mathematical problem-solving traces generated using the CAMEL framework. Each entry includes:\\n\\n\"\n                \"- A mathematical problem statement\\n\"\n                \"- A detailed step-by-step solution\\n\"\n                \"- An improvement history showing how the solution was iteratively refined\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating FunctionTool list from custom math functions\nDESCRIPTION: Converts the custom math functions into CAMEL's FunctionTool objects, which can be used by AI agents. This creates a list of function tools from the previously defined add and subtract functions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.toolkits import FunctionTool\n\n\nMATH_FUNCS: list[FunctionTool] = [\n    FunctionTool(func) for func in [add, sub]\n]\n```\n\n----------------------------------------\n\nTITLE: Initializing RolePlaying Society in Python\nDESCRIPTION: Creates a RolePlaying object with the previously defined task and role parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsociety = RolePlaying(\n    **task_kwargs,             # The task arguments\n    **user_role_kwargs,        # The instruction sender's arguments\n    **assistant_role_kwargs,   # The instruction receiver's arguments\n    **critic_role_kwargs,      # The critic's arguments\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Critic Agent Specifications in Python\nDESCRIPTION: Sets up the role, task, and system message for the critic agent using CAMEL AI's SystemMessageGenerator.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the role name and the task\ncritic_role = 'a picky critic'\n\n# Create the meta_dict and the role_tuple\nmeta_dict = dict(critic_role=critic_role,\n                 criteria='Help better accomplish the task.')\n\n# Create the role tuple\nrole_tuple = (critic_role, RoleType.CRITIC)\n\n# Generate the system message\nsys_msg = sys_msg_gen().from_dict(meta_dict=meta_dict,\n                                  role_tuple=role_tuple)\n```\n\n----------------------------------------\n\nTITLE: Configuring Reasoning Models for Math Data Generation\nDESCRIPTION: Sets up two reasoning models using CAMEL's ModelFactory - one using DeepSeek R1 through Fireworks API and another through DeepSeek's native API. This provides redundancy in case one service is unstable.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Set DeepSeek R1 served by Fireworks as reason model 1\nreason_model_1 = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n    model_type=\"accounts/fireworks/models/deepseek-r1\",\n    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n    url=\"https://api.fireworks.ai/inference/v1\",\n    model_config_dict={\"max_tokens\": 4096}, # Config the max_token carefully\n)\n\n# Set DeepSeek R1 served by deepseek cloud as reason model 2\nreason_model_2 = ModelFactory.create(\n    model_platform=ModelPlatformType.DEEPSEEK,\n    model_type=ModelType.DEEPSEEK_REASONER,\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying agent's tool call results for calculation task\nDESCRIPTION: Prints the information about tool calls made by the agent when calculating the age of Oxford University. This demonstrates how the agent uses the custom mathematical tools.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(assistant_response_calculate.info['tool_calls'])\n```\n\n----------------------------------------\n\nTITLE: Uploading Local Data to HuggingFace Dataset Repository\nDESCRIPTION: Script that collects HuggingFace credentials, loads local JSON data from generated_data.json, and uploads it to HuggingFace's dataset platform. It requires HuggingFace authentication token and username, handles file path management, and provides feedback on successful upload.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Get HuggingFace token and username\nHUGGING_FACE_TOKEN = getpass('Enter your HUGGING_FACE_TOKEN: ')\nos.environ[\"HUGGING_FACE_TOKEN\"] = HUGGING_FACE_TOKEN\nusername = input(\"Enter your HuggingFace username: \")\ndataset_name = input(\"Enter your dataset name:\")\n\n# Load the star output data\ncurrent_dir = os.getcwd()\nstar_output_path = os.path.join(current_dir, './generated_data.json')\ntraces = load_star_output(star_output_path)\n\n# Upload the data to HuggingFace\ndataset_url = upload_to_huggingface(traces, username, dataset_name)\nprint(f\"\\nDataset uploaded successfully!\")\nprint(f\"You can view your dataset at: {dataset_url}\")\n```\n\n----------------------------------------\n\nTITLE: Creating and Using ChatAgent\nDESCRIPTION: Code to initialize and use a ChatAgent with the Mistral model for processing document content.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\n\nagent = ChatAgent(\n    system_message=\"You're a helpful assistant\",\n    message_window_size=10,\n    model=model\n)\n\nresponse = agent.step(f\"based on {chunkr_output[:4000]}, give me a conclusion of the content\")\n\nprint(response.msgs[0].content)\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Parameters for CAMEL Society\nDESCRIPTION: Defines the task parameters for the role-playing session, including the task prompt about time travel and configuration for task specification.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntask_kwargs = {\n    'task_prompt': 'Develop a plan to TRAVEL TO THE PAST and make changes.',\n    'with_task_specify': True,\n    'task_specify_agent_kwargs': {'model': model}\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoRetriever and ChatAgent for Qdrant\nDESCRIPTION: Initializes the AutoRetriever for Qdrant storage and configures a ChatAgent with RAG capabilities and system message\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.retrievers import AutoRetriever\nfrom camel.types import StorageType\n\nassistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n         I will give you the Original Query and Retrieved Context,\n        answer the Original Query based on the Retrieved Context,\n        if you can't answer the question just say I don't know.\n        Just give the answer to me directly, no more other words needed.\n        \"\"\"\nauto_retriever = AutoRetriever(\n              vector_storage_local_path=\"local_data2/\",\n              storage_type=StorageType.QDRANT,\n              embedding_model=sentence_encoder\n            )\nchat_agent_with_rag = ChatAgent(\n    system_message=assistant_sys_msg,\n    model=ollama_model,\n    token_limit=8192, #change base on your input size\n)\n```\n\n----------------------------------------\n\nTITLE: Inspecting ChatAgent Memory Context\nDESCRIPTION: Code to retrieve and display the current context in the agent's memory. This allows examination of what information the agent has stored from the conversation history.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nagent.memory.get_context()\n```\n\n----------------------------------------\n\nTITLE: Processing Language Data with CAMEL in Python\nDESCRIPTION: This code snippet shows how to use CAMEL agents to process and analyze natural language data. It demonstrates passing messages between agents and extracting insights.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresponse = agent2.process_message(\"Tell me about machine learning.\")\n\ninsights = agent1.extract_insights(response)\n\nfor insight in insights:\n    print(insight)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI GPT4-mini Model\nDESCRIPTION: Sets up the OpenAI GPT4-mini model using CAMEL's ModelFactory. This configures the model for use in the CAMEL environment.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.configs import ChatGPTConfig\n\n# Set up model\nopenai_gpt4o_mini = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n    model_config_dict=ChatGPTConfig(temperature=0.2).as_dict(),\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Task in CAMEL Framework (Python)\nDESCRIPTION: Demonstrates how to create a simple task by specifying its content (goal) and unique identifier. This is the basic building block for task management in CAMEL.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.tasks import Task\n\ntask = Task(\n    content=\"Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\",\n    id=\"0\",\n)\n```\n\n----------------------------------------\n\nTITLE: Using Self-Improving CoT Pipeline in Python\nDESCRIPTION: This code snippet demonstrates how to initialize and use the SelfImprovingCoTPipeline. It shows the setup of reason and evaluate agents, preparation of problems, and creation of the pipeline instance.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.datagen import SelfImprovingCoTPipeline\n\n# Initialize agents\nreason_agent = ChatAgent(\n    \"\"\"Answer my question and give your \n    final answer within \\\\boxed{}.\"\"\"\n)\n\nevaluate_agent = ChatAgent(\n    \"You are a highly critical teacher who evaluates the student's answers \"\n    \"with a meticulous and demanding approach.\"\n)\n\n# Prepare your problems\nproblems = [\n    {\"problem\": \"Your problem text here\"},\n    # Add more problems...\n]\n```\n\n----------------------------------------\n\nTITLE: Initializing Knowledge Graph Agent with Multiple AI Models\nDESCRIPTION: Sets up the Knowledge Graph Agent using Together, SambaVerse, and OpenAI models. It also configures Neo4j connection, clears the database, and prepares for processing PDF files to construct the knowledge graph.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nfrom tqdm import tqdm\n\nfrom camel.agents import KnowledgeGraphAgent\nfrom camel.configs import TogetherAIConfig, SambaCloudAPIConfig, ChatGPTConfig\nfrom camel.embeddings import MistralEmbedding\nfrom camel.loaders import UnstructuredIO\nfrom camel.models import ModelFactory\nfrom camel.storages import Neo4jGraph\nfrom camel.types import ModelPlatformType, ModelType\n\n# Set up Neo4j connection\nneo4j_graph = Neo4jGraph(\n    url=os.environ[\"NEO4J_URI\"],\n    username=os.environ[\"NEO4J_USERNAME\"],\n    password=os.environ[\"NEO4J_PASSWORD\"],\n)\n\n# Clear the Neo4j database before starting\nprint(\"Clearing Neo4j database...\")\nneo4j_graph.query(\"MATCH (n) DETACH DELETE n\")\nprint(\" Neo4j database cleared successfully.\")\n\n# Use TogetherAI model\ntogether_api_model = ModelFactory.create(\n    model_platform=ModelPlatformType.TOGETHER,\n    model_type=ModelType.TOGETHER_LLAMA_3_1_70B,\n    model_config_dict=TogetherAIConfig(temperature=0.2).as_dict(),\n)\n\n# Use Samba Verse model\nsambaverse_api_model = ModelFactory.create(\n    model_platform=ModelPlatformType.SAMBA,\n    model_type=\"Meta-Llama-3.1-405B-Instruct\",\n    model_config_dict=SambaCloudAPIConfig(max_tokens=2048).as_dict(),\n    api_key=os.environ[\"SAMBA_API_KEY\"],\n    url=\"https://api.sambanova.ai/v1\",\n)\n\n# Use OpenAI model\nopenai_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n    model_config_dict=ChatGPTConfig().as_dict(),\n)\n\n# Set up the example files\nexample_file_dir = Path(\"/home/mi/daily/fin-camel/pdf_kvue\")\nassert (\n    example_file_dir.exists()\n), \"Please set the correct path to the example pdf files.\"\n\nexample_pdf_files = list(example_file_dir.glob(\"*.pdf\"))\nprint(f\"Found {len(example_pdf_files)} PDF files.\")\n\n# UnstructuredIO is a tool to parse and chunk the documents.\nuio = UnstructuredIO()\n\n# Together is a model to generate the knowledge graph.\ntogether_kg_agent = KnowledgeGraphAgent(model=together_api_model)\n\n# Samba Verse model is a model to generate the knowledge graph.\nllama_405b_kg_agent = KnowledgeGraphAgent(model=sambaverse_api_model)\n\n# OpenAI model is a model to generate the knowledge graph.\nopenai_kg_agent = KnowledgeGraphAgent(model=openai_model)\n```\n\n----------------------------------------\n\nTITLE: Creating a RolePlaying Society in CAMEL\nDESCRIPTION: Initializes the RolePlaying society by combining all previously defined parameters: task, user role, and assistant role configurations.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsociety = RolePlaying(\n    **task_kwargs,             # The task arguments\n    **user_role_kwargs,        # The instruction sender's arguments\n    **assistant_role_kwargs,   # The instruction receiver's arguments\n)\n```\n\n----------------------------------------\n\nTITLE: Setting the Output Language for a ChatAgent\nDESCRIPTION: Setting the language that the agent should use for its responses. This example configures the agent to respond in French regardless of the input language.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nagent.set_output_language('french')\n```\n\n----------------------------------------\n\nTITLE: Initializing Sentence Transformer Encoder in Python\nDESCRIPTION: Sets up the embedding model using SentenceTransformerEncoder with the e5-large-v2 model for vector embeddings\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.embeddings import SentenceTransformerEncoder # CAMEL also support other embedding models\nfrom camel.types import EmbeddingModelType\n\nsentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n```\n\n----------------------------------------\n\nTITLE: Defining Function to Generate User Queries\nDESCRIPTION: Creates a function that generates human-like queries using a ChatAgent and specific tools. It leverages OpenAI's GPT-4 model to craft realistic and tool-specific user queries.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef generate_user_query(selected_tool: Union[Callable, FunctionTool],\n                        n: int = 1) -> List[str]:\n    r\"\"\"Generates user queries by leveraging specific tools, helping the\n    ChatAgent craft\n    human-like queries that take advantage of each tool's functionality.\n\n    Args:\n        selected_tool (Union[Callable, FunctionTool]): The tool to leverage for\n        query generation.\n        n (int, optional): The number of queries to generate. Defaults to 1.\n    \"\"\"\n\n    tool_call_sys_msg = (\n        \"You are a smart query generator designed to utilize specific tools \"\n        \"based on user needs. \"\n        \"Formulate queries as a human user would.\"\n\n        \"Instructions:\\n\"\n        \"1. Envision a real-world scenario, but don't say it out loud.\"\n        \"2. Craft a realistically phrased actionable query fitting that scenario\"\n        \" that could be satisfied with the provided tool(s)\\n\"\n        \"3. With the tool(s) in mind, phrase the query naturally and \"\n        \"informatively.\\n\"\n        \"4. Only rely on information from tools they appear likely to \"\n        \"provide\\n\"\n        \"5. Pose the query as if the user doesn't know what tools are \"\n        \"available.\"\n    )\n\n    # Convert to FunctionTool if necessary\n    if not isinstance(selected_tool, FunctionTool):\n        selected_tool = FunctionTool(selected_tool)\n\n    # Create a model instance for generating queries\n    query_model = ModelFactory.create(\n        model_platform=ModelPlatformType.OPENAI,\n        model_type=ModelType.GPT_4O_MINI,\n        model_config_dict={\"temperature\": 1}\n    )\n\n    # Initialize ChatAgent with the system message\n    query_agent = ChatAgent(\n        system_message=tool_call_sys_msg,\n        model=query_model,\n    )\n    queries = []\n\n    # Prepare tools info message for guiding query generation\n    tools_info_message = (\n            \"Generate a relevant query based on the following tool \"\n            \"details:\\n\\n\" +\n            \"\\n\".join(f\"Tool Schema: {selected_tool.get_openai_tool_schema()}\")\n    )\n\n    # Generate queries\n    for _ in range(n):\n        response = query_agent.step(tools_info_message)\n        queries.append(response.msgs[0].content)  # Extract the generated query\n\n    return queries\n```\n\n----------------------------------------\n\nTITLE: Initializing Self-Improving CoT Pipeline in Python\nDESCRIPTION: This snippet demonstrates how to create and run a SelfImprovingCoTPipeline. It initializes the pipeline with reason and evaluate agents, a list of problems, and specifies the maximum number of iterations and output path.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create and run the pipeline\npipeline = SelfImprovingCoTPipeline(\n    reason_agent=reason_agent,\n    evaluate_agent=evaluate_agent,\n    problems=problems,\n    max_iterations=3,\n    output_path=\"star_output.json\"\n)\n\nresults = pipeline.generate()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Qdrant Vector Storage in Python\nDESCRIPTION: Initializes a QdrantStorage instance for vector storage. This storage will be used to store and retrieve embedded text chunks in the RAG system.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.storages import QdrantStorage\n\nstorage_instance = QdrantStorage(\n    vector_dim=embedding_instance.get_output_dim(),\n    path=\"local_data\",\n    collection_name=\"camel_paper\",\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Sentence Transformer Encoder in Python\nDESCRIPTION: Sets up the embedding model using SentenceTransformerEncoder with the e5-large-v2 model for vector encoding.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.embeddings import SentenceTransformerEncoder # CAMEL also support other embedding\n\nsentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n```\n\n----------------------------------------\n\nTITLE: Initializing Qwen Model Configuration\nDESCRIPTION: Creates and configures a Qwen model instance using CAMEL's ModelFactory with specific model platform and type settings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/finance_discord_bot.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.configs import QwenConfig, MistralConfig\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n\nqwen_model = ModelFactory.create(\n    model_platform=ModelPlatformType.QWEN,\n    model_type=ModelType.QWEN_TURBO,\n    model_config_dict=QwenConfig(temperature=0.2).as_dict(),\n)\n```\n\n----------------------------------------\n\nTITLE: Using Code Generation Prompt Templates\nDESCRIPTION: Demonstration of using CodePromptTemplateDict for code-related tasks. This example shows how to generate programming languages, coding tasks, and create an AI coding assistant prompt for implementing a binary search algorithm.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.prompts import CodePromptTemplateDict\n\n# Generate programming languages\nlanguages_prompt = CodePromptTemplateDict.GENERATE_LANGUAGES.format(num_languages=5)\nprint(f\"Languages prompt:\\n{languages_prompt}\\n\")\n\n# Generate coding tasks\ntasks_prompt = CodePromptTemplateDict.GENERATE_TASKS.format(num_tasks=3)\nprint(f\"Tasks prompt:\\n{tasks_prompt}\\n\")\n\n# Create an AI coding assistant prompt\nassistant_prompt = CodePromptTemplateDict.ASSISTANT_PROMPT.format(\n    assistant_role=\"Python Expert\",\n    task_description=\"Implement a binary search algorithm\",\n)\nprint(f\"Assistant prompt:\\n{assistant_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Function to Create Judge Agents in Python\nDESCRIPTION: This function creates a ChatAgent with a specific persona, example feedback, and evaluation criteria for judging hackathon projects. It uses CAMEL-AI's ChatAgent, BaseMessage, and ModelFactory classes to set up the agent with GPT-4.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/multi_agent_society/workforce_judge_committee.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport textwrap\n\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\nfrom camel.models import ModelFactory\nfrom camel.tasks import Task\nfrom camel.toolkits import FunctionTool, SearchToolkit\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.societies.workforce import Workforce\n\ndef make_judge(\n    persona: str,\n    example_feedback: str,\n    criteria: str,\n) -> ChatAgent:\n    msg_content = textwrap.dedent(\n        f\"\"\"\\\n        You are a judge in a hackathon.\n        This is your persona that you MUST act with: {persona}\n        Here is an example feedback that you might give with your persona, you MUST try your best to align with this:\n        {example_feedback}\n        When evaluating projects, you must use the following criteria:\n        {criteria}\n        You also need to give scores based on these criteria, from 1-4. The score given should be like 3/4, 2/4, etc.\n        \"\"\"  # noqa: E501\n    )\n\n    sys_msg = BaseMessage.make_assistant_message(\n        role_name=\"Hackathon Judge\",\n        content=msg_content,\n    )\n\n    model = ModelFactory.create(\n        model_platform=ModelPlatformType.OPENAI,\n        model_type=ModelType.GPT_4O,\n    )\n\n    agent = ChatAgent(\n        system_message=sys_msg,\n        model=model,\n    )\n\n    return agent\n```\n\n----------------------------------------\n\nTITLE: Initializing Mistral Model\nDESCRIPTION: Code to create and configure a Mistral model instance for text processing.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.configs import MistralConfig\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n\nmistral_model = ModelFactory.create(\n    model_platform=ModelPlatformType.MISTRAL,\n    model_type=ModelType.MISTRAL_LARGE,\n    model_config_dict=MistralConfig(temperature=0.0).as_dict(),\n)\n\nmodel = mistral_model\n```\n\n----------------------------------------\n\nTITLE: Generating and Saving Tool Call Data to JSON in Python\nDESCRIPTION: Creates a dictionary to store generated queries and tool call data, iterates through selected tools to generate data, and saves the results to a JSON file. Uses json.dump() for writing data with proper formatting.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresults = {\n    \"generated_queries\": [],\n    \"tool_call_data\": []\n}\n\nfor selected_tool in selected_tools:\n    user_queries = generate_user_query(selected_tool=selected_tool, n=5)\n    tool_call_data = generate_tool_call_data(user_queries, selected_tool)\n\n    # Append results to the lists instead of overwriting\n    results[\"generated_queries\"].extend(user_queries)\n    results[\"tool_call_data\"].extend(tool_call_data)\n\n# Specify output file path\noutput_file = \"generated_tool_call_data.json\"\n\n# Save data to JSON file\nwith open(output_file, \"w\") as f:\n    json.dump(results, f, indent=4)\n\nprint(f\"Data saved to {output_file}\")\n```\n\n----------------------------------------\n\nTITLE: Generating System Message\nDESCRIPTION: Creates a system message for the agent based on the defined role and task, which will guide the agent's behavior and capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Generate the system message based on this\nsys_msg = sys_msg_gen().from_dict(meta_dict=meta_dict, role_tuple=role_tuple)\n```\n\n----------------------------------------\n\nTITLE: Importing modules for multi-agent AI society setup\nDESCRIPTION: Imports the necessary CAMEL modules for creating a multi-agent system (AI society), including RolePlaying, FunctionCallingRecord, and utility functions for text display.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.societies import RolePlaying\nfrom camel.agents.chat_agent import FunctionCallingRecord\nfrom camel.utils import print_text_animated\nfrom colorama import Fore\n```\n\n----------------------------------------\n\nTITLE: Implementing a Discord Bot with Qdrant-powered RAG using CAMEL\nDESCRIPTION: Creates a Discord bot that uses the AutoRetriever to fetch relevant information from Qdrant and passes it to the ChatAgent to generate responses. The implementation handles Discord's message length limits by chunking long responses.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_with_agentic_RAG.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.bots import DiscordApp\nimport nest_asyncio\nimport discord\n\nnest_asyncio.apply()\ndiscord_q_bot = DiscordApp(token=discord_bot_token)\n\n@discord_q_bot.client.event # triggers when a message is sent in the channel\nasync def on_message(message: discord.Message):\n    if message.author == discord_q_bot.client.user:\n        return\n\n    if message.type != discord.MessageType.default:\n        return\n\n    if message.author.bot:\n        return\n    user_input = message.content\n\n    retrieved_info = auto_retriever.run_vector_retriever(\n        query=user_input,\n        contents=[\n            \"local_data/qdrant_overview.md\",\n        ],\n        top_k=3,\n        return_detailed_info=False,\n        similarity_threshold=0.5\n    )\n\n    user_msg = str(retrieved_info)\n    assistant_response = qdrant_agent.step(user_msg)\n    response_content = assistant_response.msgs[0].content\n\n    if len(response_content) > 2000: # discord message length limit\n        for chunk in [response_content[i:i+2000] for i in range(0, len(response_content), 2000)]:\n            await message.channel.send(chunk)\n    else:\n        await message.channel.send(response_content)\n\ndiscord_q_bot.run()\n```\n\n----------------------------------------\n\nTITLE: Creating prompts and messages for agent testing\nDESCRIPTION: Defines two test prompts for the agent to process: one for searching when Oxford University was founded, and another for calculating its age. These are converted to BaseMessage objects for the agent to process.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Set prompt for the search task\nprompt_search = (\"\"\"When was University of Oxford set up\"\"\")\n# Set prompt for the calculation task\nprompt_calculate = (\"\"\"Assume now is 2024 in the Gregorian calendar, University of Oxford was set up in 1096, estimate the current age of University of Oxford\"\"\")\n\n# Convert the two prompt as message that can be accepted by the Agent\nuser_msg_search = BaseMessage.make_user_message(role_name=\"User\", content=prompt_search)\nuser_msg_calculate = BaseMessage.make_user_message(role_name=\"User\", content=prompt_calculate)\n\n# Get response\nassistant_response_search = agent.step(user_msg_search)\nassistant_response_calculate = agent.step(user_msg_calculate)\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Keys\nDESCRIPTION: Secure configuration of OpenAI API keys using environment variables\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Converting Transformed Data to Record Objects in Python\nDESCRIPTION: This function takes a list of trace dictionaries from star_output.json and converts them into Record objects. It extracts various fields from each trace and creates a Record instance with these attributes.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\ndef create_records(transformed_data):\n    r\"\"\"Converts transformed data into a list of Record objects.\n\n    Args:\n        transformed_data (list): List of trace dictionaries from star_output.json.\n\n    Returns:\n        list: List of Record objects.\n    \"\"\"\n    records = []\n    for trace in transformed_data:\n        record = Record(\n            id=trace['id'],\n            source_type=trace['type'],\n            problem=trace['problem'],\n            reasoning_solution=trace['final_trace'],\n            groud_truth_solution=trace['solution'],\n            agent_evaluate_success=trace['evaluate_success'],\n            boxed_answer_success=trace['boxed_answer_success'],\n            improvement_history=trace['improvement_history'],\n        )\n        records.append(record)\n    return records\n```\n\n----------------------------------------\n\nTITLE: Multi-Modal Message with ChatAgent\nDESCRIPTION: Example of using BaseMessage with image handling and ChatAgent integration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\n\nimport requests\nfrom PIL import Image\n\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\n# URL of the image\nurl = \"https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png\"\nresponse = requests.get(url)\nimg = Image.open(BytesIO(response.content))\n\n# Define system message\nsys_msg = BaseMessage.make_assistant_message(\n    role_name=\"Assistant\",\n    content=\"You are a helpful assistant.\",\n)\n\n# Set agent\ncamel_agent = ChatAgent(system_message=sys_msg)\n\n# Set user message\nuser_msg = BaseMessage.make_user_message(\n    role_name=\"User\", content=\"\"\"what's in the image?\"\"\", image_list=[img]\n)\n\n# Get response information\nresponse = camel_agent.step(user_msg)\nprint(response.msgs[0].content)\n```\n\n----------------------------------------\n\nTITLE: Testing NVIDIA Nemotron Reward Model\nDESCRIPTION: Demonstrates the use of NVIDIA's Nemotron Reward Model to evaluate the quality of generated responses. It tests the model on a subset of the generated data to understand its output format and set filtering criteria.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models.reward import Evaluator, NemotronRewardModel\nfrom camel.types import ModelType\n\nreward_model = NemotronRewardModel(\n    model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n    url=\"https://integrate.api.nvidia.com/v1\",\n)\nevaluator = Evaluator(reward_model=reward_model)\nresults = []  # To store results for comparison\nfor i in range(min(10, len(messages_lists))):\n    print(f\"Evaluating message list {i+1}:\")\n    print(messages_lists[i])  # Display the message list\n    scores = evaluator.evaluate(messages_lists[i])\n    print(f\"Scores: {scores}\\n\")  # Print the evaluation scores\n    results.append((i + 1, messages_lists[i], scores))\n\n# Print a summary of the results\nprint(\"\\nSummary of evaluations:\")\nfor index, messages, scores in results:\n    print(f\"Message List {index}:\")\n    print(messages)\n    print(f\"Scores: {scores}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Downloading and Transforming GSM8K Dataset for CAMEL Pipeline\nDESCRIPTION: This function downloads a subset of the GSM8K dataset from Hugging Face, transforms it to the required format for CAMEL's data distillation pipeline, and saves it as a JSON file. It converts the numerical answers to LaTeX boxed format.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom pathlib import Path\nimport uuid\nfrom datasets import load_dataset\n\ndef download_gsm8k_dataset():\n    try:\n        # Load the dataset using the datasets library\n        dataset = load_dataset(\"openai/gsm8k\", \"main\")\n\n        # Get the items from train split\n        data = dataset['train'].select(range(NUMBER_OF_PROBLEMS))\n\n        # Convert to the desired format\n        formatted_data = []\n        for item in data:\n            # Extract the final answer from the solution\n            solution = item['answer']\n            if solution:\n                # GSM8K solutions typically end with \"#### number\"\n                import re\n\n                match = re.search(r'####\\s*(\\d+)', solution)\n                if match:\n                    number = match.group(1)\n                    # Replace the \"#### number\" with \"\\boxed{number}\"\n                    solution = re.sub(\n                        r'####\\s*\\d+', f'\\\\\\\\boxed{{{number}}}', solution\n                    )\n\n            formatted_item = {\n                \"id\": str(uuid.uuid4()),  # GSM8K doesn't provide IDs\n                \"problem\": item['question'],\n                \"type\": \"openai/gsm8k\",  # All problems are from GSM8K\n                \"solution\": solution,  # Use the modified solution with \\boxed\n            }\n            formatted_data.append(formatted_item)\n\n        # Save to a file\n        output = formatted_data\n        output_file = \"downloaded_gsm8k_10.json\"\n        with open(output_file, \"w\") as f:\n            json.dump(output, f, indent=2)\n\n        print(f\"Successfully downloaded and saved GSM8K dataset to {output_file}\")\n    except Exception as e:\n        print(f\"Error downloading GSM8K dataset: {e}\")\n\nif __name__ == \"__main__\":\n    download_gsm8k_dataset()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for CAMEL Multi-Agent System\nDESCRIPTION: Imports necessary modules and classes from the CAMEL framework, including components for agent communication, role-playing session management, function tools, and utility functions for text display.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom colorama import Fore\n\nfrom camel.agents.chat_agent import FunctionCallingRecord\nfrom camel.societies import RolePlaying\nfrom camel.toolkits import FunctionTool\nfrom camel.utils import print_text_animated\n```\n\n----------------------------------------\n\nTITLE: Configuring CAMEL Agent with Search Tools\nDESCRIPTION: Sets up a CAMEL agent with a system message, search tools, and GPT-4o-mini as the LLM model.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Define system message\nsys_msg = BaseMessage.make_assistant_message(\n    role_name='Tools calling opertor', content='You are a helpful assistant'\n)\n\n# Set model config\ntools = [*SearchToolkit().get_tools()]\n\n\nmodel = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n)\n\n# Set agent\ncamel_agent = ChatAgent(\n    system_message=sys_msg,\n    model=model,\n    tools=tools,\n)\n```\n\n----------------------------------------\n\nTITLE: Loading and Configuring TinyLlama with Unsloth\nDESCRIPTION: Sets up the TinyLlama model using Unsloth for optimized training. Configures the model with 4-bit quantization and LoRA parameters for efficient fine-tuning with limited resources.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 4096\ndtype = None\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/tinyllama-bnb-4bit\", # \"unsloth/tinyllama\" for 16bit loading\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 32,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",\n                      \"embed_tokens\", \"lm_head\"],\n    lora_alpha = 32,\n    use_gradient_checkpointing = False, # @@@ IF YOU GET OUT OF MEMORY - set to True @@@\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)\n```\n\n----------------------------------------\n\nTITLE: Executing CAMEL Agent Conversation with Composio Tools\nDESCRIPTION: This snippet runs the conversation between the user and assistant agents, including the execution of Composio tools for GitHub actions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nn = 0\ninput_msg = role_play_session.init_chat()\nwhile n < 50:\n    n += 1\n    assistant_response, user_response = role_play_session.step(input_msg)\n\n    if assistant_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI Assistant terminated. Reason: \"\n                f\"{assistant_response.info['termination_reasons']}.\"\n            )\n        )\n        break\n    if user_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI User terminated. \"\n                f\"Reason: {user_response.info['termination_reasons']}.\"\n            )\n        )\n        break\n\n    # Print output from the user\n    print_text_animated(\n        Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\"\n    )\n\n    # Print output from the assistant, including any function\n    # execution information\n    print_text_animated(Fore.GREEN + \"AI Assistant:\")\n    tool_calls: List[FunctionCallingRecord] = assistant_response.info[\n        'tool_calls'\n    ]\n    for func_record in tool_calls:\n        print_text_animated(f\"{func_record}\")\n    print_text_animated(f\"{assistant_response.msg.content}\\n\")\n\n    if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n        break\n\n    input_msg = assistant_response.msg\n```\n\n----------------------------------------\n\nTITLE: Web Scraping with Firecrawl in CAMEL Framework\nDESCRIPTION: Code that demonstrates how to use the Firecrawl loader to scrape and clean content from a specific URL. It returns the cleaned content in markdown format for use with LLMs.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.loaders import Firecrawl\n\nfirecrawl = Firecrawl()\n\n# Scrape and clean content from a specified URL\nresponse = firecrawl.scrape(\n    url=\"https://www.camel-ai.org/post/crab\"\n)\n\nprint(response[\"markdown\"])\n```\n\n----------------------------------------\n\nTITLE: Integrating Memory with ChatAgent\nDESCRIPTION: Example of adding LongtermAgentMemory to a ChatAgent and processing messages\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\n\n# Define system message for the agent\nsys_msg = \"You are a curious agent wondering about the universe.\"\n\n# Initialize agent\nagent = ChatAgent(system_message=sys_msg)\n\n# Set memory to the agent\nagent.memory = memory\n\n\n# Define a user message\nusr_msg = \"Tell me which is the 1st LLM multi-agent framework based on what we have discussed\"\n\n# Sending the message to the agent\nresponse = agent.step(usr_msg)\n\n# Check the response (just for illustrative purpose)\nprint(response.msgs[0].content)\n```\n\n----------------------------------------\n\nTITLE: Using AutoRetriever for RAG in CAMEL\nDESCRIPTION: Sets up and runs an AutoRetriever instance for automated RAG. This demonstrates how to use CAMEL's auto RAG feature with multiple content sources.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.retrievers import AutoRetriever\nfrom camel.types import StorageType\n\nauto_retriever = AutoRetriever(\n        vector_storage_local_path=\"local_data2/\",\n        storage_type=StorageType.QDRANT,\n        embedding_model=embedding_instance)\n\nretrieved_info = auto_retriever.run_vector_retriever(\n    query=\"If I'm interest in contributing to the CAMEL project, what should I do?\",\n    contents=[\n        \"local_data/camel_paper.pdf\",  # example local path\n        \"https://github.com/camel-ai/camel/wiki/Contributing-Guidlines\",  # example remote url\n    ],\n    top_k=1,\n    return_detailed_info=True,\n    similarity_threshold=0.5\n)\n\nprint(retrieved_info)\n```\n\n----------------------------------------\n\nTITLE: Printing Token Count\nDESCRIPTION: Display the token count from memory context\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(token_count)\n```\n\n----------------------------------------\n\nTITLE: Interacting with a ChatAgent using the step() Method\nDESCRIPTION: Code demonstrating how to send a message to the ChatAgent and receive a response using the step() method. This shows the basic interaction pattern for communication with the agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define a user message\nusr_msg = 'what is information in your mind?'\n\n# Sending the message to the agent\nresponse = agent.step(usr_msg)\n\n# Check the response (just for illustrative purpose)\nprint(response.msgs[0].content)\n```\n\n----------------------------------------\n\nTITLE: Printing Critic Agent System Message in Python\nDESCRIPTION: Displays the content of the system message assigned to the critic agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(critic_agent.system_message.content)\n```\n\n----------------------------------------\n\nTITLE: Adding Record Objects to Dataset using HuggingFaceDatasetManager in Python\nDESCRIPTION: This function adds a list of Record objects to a specified dataset using a HuggingFaceDatasetManager instance. It takes the manager, dataset name, and list of records as parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\ndef add_records_to_dataset(manager, dataset_name, records):\n    r\"\"\"Adds a list of Record objects to the dataset.\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n        records (list): List of Record objects.\n    \"\"\"\n    manager.add_records(dataset_name, records)\n```\n\n----------------------------------------\n\nTITLE: Defining Function to Generate Structured Tool Call Data\nDESCRIPTION: Creates a function that generates structured tool call data based on user queries. It uses a ChatAgent to process queries and generate responses using the specified tools, formatting the output in the Hermes JSON format.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef generate_tool_call_data(user_messages: List[str],\n                            selected_tool: Union[Callable, FunctionTool]) -> \\\n        list[Any]:\n    r\"\"\"Generates structured tool call data for a list of user messages by\n    using each specified tool in selected_tools.\n    \"\"\"\n\n    # Convert to FunctionTool if necessary\n    if not isinstance(selected_tool, FunctionTool):\n        selected_tool = FunctionTool(selected_tool)\n\n    # Define system message guiding ChatAgent on function calls\n    base_system_msg = \"You are a function calling AI model. \"\n    hermes_tool_call_sys_msg = (\n        f\"You are a function calling AI model. You are provided with \"\n        f\"function signatures within <tools> </tools> XML tags. You may call \"\n        f\"one or more functions to assist with the user query. If available \"\n        f\"tools are not relevant in assisting with user query, just respond \"\n        f\"in natural conversational language. Don't make assumptions about \"\n        f\"what values to plug into functions. After calling & executing the \"\n        f\"functions, you will be provided with function results within \"\n        f\"<tool_response> </tool_response> XML tags.\"\n        f\"\\n <tools> \\n\"\n        f\"{[selected_tool.get_openai_tool_schema()]}\"\n        f\"\\n </tools>\\n\"\n        \"For each function call return a JSON object, with the following \"\n        \"pydantic model json schema:{'title': 'FunctionCall', 'type': \"\n        \"'object', 'properties': {'name': {'title': 'Name', 'type': \"\n        \"'string'}, 'arguments': {'title': 'Arguments', 'type': 'object'}}, \"\n        \"'required': ['arguments', 'name']}\\n\"\n        f\"Each function call should be enclosed within <tool_call> \"\n        f\"</tool_call> XML tags.\\n\"\n        f\"Example:\\n\"\n        f\"<tool_call>\\n\"\n        \"{'name': <function-name>, 'arguments': <args-dict>}\\n\"\n        \"</tool_call>\"\n        f\"\")\n    sys_hermes = ShareGPTMessage(from_='system',\n                                 value=hermes_tool_call_sys_msg)\n    # Initialize model for tool call data generation\n    tool_model = ModelFactory.create(\n        model_platform=ModelPlatformType.OPENAI,\n        model_type=ModelType.GPT_4O_MINI,\n    )\n\n    all_tool_data = {}\n\n    tool_output_data = []\n    for user_message in user_messages:\n        # Set up ChatAgent with the system message, model, and the single tool\n        tool_agent = ChatAgent(\n            system_message=base_system_msg,\n            model=tool_model,\n            tools=[selected_tool],\n        )\n\n        # Generate response using ChatAgent and structured output\n        try:\n            tool_agent.step(user_message)\n        except Exception as e:\n            print(f\"Error: {e}\")\n            continue\n        messages = [record.memory_record.message for record in\n                    tool_agent.memory.retrieve()]\n\n        sharegpt_hermes_msgs = \\\n            [sys_hermes] + [msg.to_sharegpt(HermesFunctionFormatter()) for msg\n                            in messages[1:]]\n\n        # Only include conversations with function calls\n        if any(type(message) == FunctionCallingMessage for message in\n               messages):\n            tool_output_data.append(\n                json.loads(\n                    ShareGPTConversation(sharegpt_hermes_msgs)\n                    .model_dump_json(by_alias=True))\n            )\n\n    # Add generated data to the dictionary with tool name as the key\n    all_tool_data[selected_tool.func.__name__] = tool_output_data\n\n    return tool_output_data\n```\n\n----------------------------------------\n\nTITLE: Generating Alpaca Data from Web Content\nDESCRIPTION: Uses CAMEL's Firecrawl integration to scrape content from a specified URL and generate Alpaca-formatted data items. It generates items in batches of 50 up to a total of 50 items, incorporating examples for consistency.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport random\nfrom camel.loaders.firecrawl_reader import Firecrawl\nfirecrawl = Firecrawl()\n# Scrape and clean content from a specified URL\nresponse = firecrawl.scrape(\n    url=\"https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md\"\n)\n\n# Generate the items 50 a time up to 50\nalpaca_entries = []\nfor start in range(1, 51, 50):\n    # Combine default examples with random samples from previous generations\n    current_examples = examples + (random.sample(alpaca_entries,\n                            min(5, len(alpaca_entries)))\n                            if alpaca_entries else [])\n\n    batch = generate_alpaca_items(\n        content=response[\"markdown\"],\n        n_items=50,\n        start_num=start,\n        examples=current_examples\n    )\n    print(f\"Generated {len(batch)} items\")\n    alpaca_entries.extend(batch)\n\nprint(alpaca_entries)\n```\n\n----------------------------------------\n\nTITLE: Creating Evaluation Prompts with EvaluationPromptTemplateDict\nDESCRIPTION: Example of using EvaluationPromptTemplateDict to generate evaluation questions for Machine Learning. This demonstrates how to create structured evaluation prompts with examples for specific fields.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.prompts import EvaluationPromptTemplateDict\n\n# Generate evaluation questions\nquestions_prompt = EvaluationPromptTemplateDict.GENERATE_QUESTIONS.format(\n    num_questions=5,\n    field=\"Machine Learning\",\n    examples=\"1. What is the difference between supervised and unsupervised learning?\\n2. Explain the concept of overfitting.\",\n)\nprint(f\"Evaluation questions prompt:\\n{questions_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Discord Bot with Qdrant Integration\nDESCRIPTION: Complete Discord bot implementation with message handling, vector retrieval, and response generation using CAMEL and Qdrant\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.bots import DiscordApp\nimport nest_asyncio\nimport discord\n\nnest_asyncio.apply()\ndiscord_q_bot = DiscordApp(token=discord_bot_token)\n\n@discord_q_bot.client.event # triggers when a message is sent in the channel\nasync def on_message(message: discord.Message):\n    if message.author == discord_q_bot.client.user:\n        return\n\n    if message.type != discord.MessageType.default:\n        return\n\n    if message.author.bot:\n        return\n    user_input = message.content\n\n    query_and_retrieved_info = auto_retriever.run_vector_retriever(\n        query=user_input,\n        contents=[ # don't add a local path if you are connecting to a local runtime\n            \"https://docs.camel-ai.org/\", #replace with your knowledge base\n        ],\n        top_k=3,\n        return_detailed_info=False,\n        similarity_threshold=0.5\n    )\n\n    user_msg = str(query_and_retrieved_info)\n    assistant_response = chat_agent_with_rag.step(user_msg)\n    response_content = assistant_response.msgs[0].content\n    print(3)\n    if len(response_content) > 2000: # discord message length limit\n        for chunk in [response_content[i:i+2000] for i in range(0, len(response_content), 2000)]:\n            await message.channel.send(chunk)\n    else:\n        await message.channel.send(response_content)\n\ndiscord_q_bot.run()\n```\n\n----------------------------------------\n\nTITLE: Processing PDF Files for Knowledge Graph Construction in Python\nDESCRIPTION: Iterates through PDF files, parsing content and chunking elements by titles with a character limit. For each chunk, it generates graph elements using an OpenAI agent, normalizes node IDs, adjusts node types for Neo4j compatibility, and prepares node texts for embedding-based deduplication.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom tqdm import tqdm\n\nnode_texts = []\ngraph_element_list = []\nfor file in example_pdf_files:\n    elements = uio.parse_file_or_url(str(file))\n    chunk_elements = uio.chunk_elements(\n        elements, chunk_type=\"chunk_by_title\", max_characters=2048\n    )\n\n    for element in tqdm(chunk_elements):\n        graph_element = openai_kg_agent.run(\n            element, parse_graph_elements=True, prompt=custom_prompt\n        )\n\n        # Add processing logic to rename 'Date' type\n        for node in graph_element.nodes:\n            if node.type == \"Date\":\n                node.type = \"TimePoint\"  # or another name that is not a reserved keyword\n            elif node.type == \"{self.type}\":\n                node.type = \"Node\"  # Set default type\n            node.id = normalize_name(\n                node.id, max_length=64\n            )  # Ensure VID length does not exceed 64\n\n        # Prepare texts for embedding\n        node_texts.extend([node.id for node in graph_element.nodes])\n        graph_element_list.append(graph_element)\n```\n\n----------------------------------------\n\nTITLE: Submitting Document Processing Task\nDESCRIPTION: Code to initialize ChunkrReader and submit a PDF document for processing.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.loaders import ChunkrReader\n\nchunkr_reader = ChunkrReader()\n\nchunkr_reader.submit_task(file_path=\"local_data/camel_paper.pdf\")\n```\n\n----------------------------------------\n\nTITLE: Loading LoRA Adapters for Inference in Python\nDESCRIPTION: Shows how to load previously saved LoRA adapters for inference. It uses the FastLanguageModel from Unsloth to load the model and enable faster inference.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif True:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"zjrwtxtechstudio/qwen2.5-1.5b-cot\", # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\n# alpaca_prompt = You MUST copy from above!\n\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"which one is bigger between 9.11 and 9.9\", # instruction\n        \"\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 4098)\n```\n\n----------------------------------------\n\nTITLE: Initializing Role-Playing Session with CAMEL Agents\nDESCRIPTION: Creates a role-playing session between an assistant agent and a user agent with specific configurations. The assistant is equipped with tools for real-time data retrieval, and both agents use the GPT-4o-mini model. The session is initialized with the defined task prompt.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the role-playing session\nrole_play_session = RolePlaying(\n    assistant_role_name=\"CAMEL Assistant\",\n    user_role_name=\"CAMEL User\",\n    assistant_agent_kwargs=dict(\n        model=ModelFactory.create(\n            model_platform=ModelPlatformType.OPENAI,\n            model_type=ModelType.GPT_4O_MINI,\n            model_config_dict=assistant_model_config.as_dict(),\n        ),\n        tools=tool_list,\n    ),\n    user_agent_kwargs=dict(model=openai_gpt4o_mini),\n    task_prompt=task_prompt,\n    with_task_specify=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Discord Bot Message Handler\nDESCRIPTION: Implementation of a Discord bot using DiscordApp class that handles incoming messages, processes them through a chat agent, and sends responses while handling Discord's message length limitations\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.bots import DiscordApp\nimport nest_asyncio\nimport discord\n\nnest_asyncio.apply()\ndiscord_bot = DiscordApp(token=discord_bot_token)\n\n@discord_bot.client.event\nasync def on_message(message: discord.Message):\n    if message.author == discord_bot.client.user:\n        return\n\n    if message.type != discord.MessageType.default:\n        return\n\n    if message.author.bot:\n        return\n\n    user_input = message.content\n    chat_agent.reset()\n    chat_agent.update_memory(knowledge_message, \"user\")\n    assistant_response = chat_agent.step(user_input)\n\n    response_content = assistant_response.msgs[0].content\n\n    if len(response_content) > 2000: # discord message length limit\n        for chunk in [response_content[i:i+2000] for i in range(0, len(response_content), 2000)]:\n            await message.channel.send(chunk)\n    else:\n        await message.channel.send(response_content)\n\ndiscord_bot.run()\n```\n\n----------------------------------------\n\nTITLE: Adding Unique Relationships to Neo4j Graph\nDESCRIPTION: This snippet adds unique relationships to a Neo4j graph, generating timestamps for each relationship and adding them as triplets. It uses a loop to iterate through unique relationships and the neo4j_graph.add_triplet() method to add each one.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nfor rel in unique_relationships:\n    current_time = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime())\n    timestamp = rel.timestamp if rel.timestamp is not None else current_time\n    neo4j_graph.add_triplet(\n        subj=rel.subj.id,\n        obj=rel.obj.id,\n        rel=rel.type,\n        timestamp=timestamp,\n    )\n```\n\n----------------------------------------\n\nTITLE: GSM8K Dataset Processing Function\nDESCRIPTION: Downloads and processes GSM8K math problems from Hugging Face, converting them into a format compatible with CAMEL's data distillation pipeline\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Set the number of problems to download from GSM8K in huggingface\nNUMBER_OF_PROBLEMS=5\n```\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom pathlib import Path\nimport uuid\nfrom datasets import load_dataset\n\ndef download_gsm8k_dataset():\n    try:\n        # Load the dataset using the datasets library\n        dataset = load_dataset(\"openai/gsm8k\", \"main\")\n\n        # Get the first 5 items from train split\n        data = dataset['train'].select(range(NUMBER_OF_PROBLEMS))\n\n        # Convert to the desired format\n        formatted_data = []\n        for item in data:\n            # Extract the final answer from the solution\n            solution = item['answer']\n            if solution:\n                # GSM8K solutions typically end with \"#### number\"\n                import re\n\n                match = re.search(r'####\\s*(\\d+)', solution)\n                if match:\n                    number = match.group(1)\n                    # Replace the \"#### number\" with \"\\boxed{number}\"\n                    solution = re.sub(\n                        r'####\\s*\\d+', f'\\\\\\\\boxed{{{number}}}', solution\n                    )\n\n            formatted_item = {\n                \"id\": str(uuid.uuid4()),  # GSM8K doesn't provide IDs\n                \"problem\": item['question'],\n                \"type\": \"openai/gsm8k\",  # All problems are from GSM8K\n                \"solution\": solution,  # Use the modified solution with \\boxed\n            }\n            formatted_data.append(formatted_item)\n\n        # Save to a file\n        output = formatted_data\n        output_file = \"downloaded_gsm8k_10.json\"\n        with open(output_file, \"w\") as f:\n            json.dump(output, f, indent=2)\n\n        print(f\"Successfully downloaded and saved GSM8K dataset to {output_file}\")\n    except Exception as e:\n        print(f\"Error downloading GSM8K dataset: {e}\")\n\nif __name__ == \"__main__\":\n    download_gsm8k_dataset()\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Function Tool in Python\nDESCRIPTION: Example showing how to define a custom tool by creating a function and wrapping it with FunctionTool. This particular example creates a tool that adds two numbers.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.toolkits import FunctionTool\n\ndef add(a: int, b: int) -> int:\n    r\"\"\"Adds two numbers.\n\n    Args:\n        a (int): The first number to be added.\n        b (int): The second number to be added.\n\n    Returns:\n        integer: The sum of the two numbers.\n    \"\"\"\n    return a + b\n\n# Wrap the function with FunctionTool\nadd_tool = FunctionTool(add)\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Size for Processing\nDESCRIPTION: Sets the number of mathematical problems to download from the GSM8K dataset on Hugging Face, controlling the size of the dataset that will be processed.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Set the number of problems to download from GSM8K in huggingface\nNUMBER_OF_PROBLEMS=10\n```\n\n----------------------------------------\n\nTITLE: Setting Up Reasoning and Evaluation Models for Mathematical Problem Solving\nDESCRIPTION: Configures three models for the pipeline: a Llama3.3 70B model for evaluation and two DeepSeek R1 models for reasoning, with one served by Fireworks and another by DeepSeek cloud.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Set llama3.3 70b as evaluate model\nevaluate_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n    model_type=\"accounts/fireworks/models/llama-v3p3-70b-instruct\",\n    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n    url=\"https://api.fireworks.ai/inference/v1\",\n)\n\n\n# Set DeepSeek R1 served by Fireworks as reason model 1\nreason_model_1 = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n    model_type=\"accounts/fireworks/models/deepseek-r1\",\n    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n    url=\"https://api.fireworks.ai/inference/v1\",\n    model_config_dict={\"max_tokens\": 2000}, # Config the max_token carefully\n)\n\n# Set DeepSeek R1 served by deepseek cloud as reason model 2\nreason_model_2 = ModelFactory.create(\n    model_platform=ModelPlatformType.DEEPSEEK,\n    model_type=ModelType.DEEPSEEK_REASONER,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing AgentOps for AI Agent Monitoring\nDESCRIPTION: Initializes AgentOps for monitoring AI agents, setting default tags for the CAMEL cookbook.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport agentops\nagentops.init(default_tags=[\"CAMEL cookbook\"])\n```\n\n----------------------------------------\n\nTITLE: Configuring and Initializing InstructionFilter in Python for CAMEL-AI\nDESCRIPTION: This code shows how to configure and initialize an InstructionFilter with multiple filter functions. It demonstrates setting up filter configurations for length, keyword, non-English, and ROUGE similarity filters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfilter_config = {\n  \"length\": {\"min_len\": 5, \"max_len\": 100},\n  \"keyword\": {\"keywords\": [\"image\", \"video\"]},\n  \"non_english\": {},\n  \"rouge_similarity\": {\n      \"existing_instructions\": [\"Some existing instructions\"],\n      \"threshold\": 0.6\n  }\n}\n\nfrom camel.datagen.self_instruct import InstructionFilter\nfilters = InstructionFilter(filter_config)\n```\n\n----------------------------------------\n\nTITLE: Initializing Self-Improving CoT Pipeline in Python\nDESCRIPTION: This code snippet defines the SelfImprovingCoTPipeline class, which sets up the pipeline for generating and refining Chain-of-Thought (CoT) data. It includes parameters for the reasoning agent, evaluation methods, and various configuration options.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass SelfImprovingCoTPipeline:\n    def __init__(\n        self,\n        reason_agent: ChatAgent,\n        problems: List[Dict],\n        max_iterations: int = 3,\n        score_threshold: Union[float, Dict[str, float]] = 0.7,\n        evaluate_agent: Optional[ChatAgent] = None,\n        reward_model: Optional[BaseRewardModel] = None,\n        output_path: Optional[str] = None,\n        few_shot_examples: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        max_workers: Optional[int] = None,\n        solution_pattern: str = r'\\\\boxed{(.*?)}',\n        trace_pattern: Optional[str] = None,\n    ):\n        r\"\"\"Initialize the STaR pipeline.\n\n        Args:\n            reason_agent (ChatAgent): The chat agent used for generating and\n                improving reasoning traces.\n            problems (List[Dict]): List of problem dictionaries to process.\n            max_iterations (int, optional): Maximum number of improvement\n                iterations. If set to `0`, the pipeline will generate an\n                initial trace without any improvement iterations.\n                (default: :obj:`3`)\n            score_threshold (Union[float, Dict[str, float]], optional):\n                Quality threshold. Can be either a single float value applied\n                to average score, or a dictionary mapping score dimensions to\n                their thresholds. For example: {\"correctness\": 0.8,\n                \"coherence\": 0.7}. If using reward model and threshold for a\n                dimension is not specified, will use the default value 0.7.\n                (default: :obj:`0.7`)\n            evaluate_agent (Optional[ChatAgent]): The chat agent used for\n                evaluating reasoning traces. (default: :obj:`None`)\n            reward_model (BaseRewardModel, optional): Model used to evaluate\n                reasoning traces. If `None`, uses Agent self-evaluation.\n                (default: :obj:`None`)\n            output_path (str, optional): Output path for saving traces. If\n                `None`, results will only be returned without saving to file.\n                (default: :obj:`None`)\n            few_shot_examples (str, optional): Examples to use for few-shot\n                generation. (default: :obj:`None`)\n            batch_size (int, optional): Batch size for parallel processing.\n                (default: :obj:`None`)\n            max_workers (int, optional): Maximum number of worker threads.\n                (default: :obj:`None`)\n            solution_pattern (str, optional): Regular expression pattern with\n                one capture group to extract answers from solution text.\n                (default: :obj:`r'\\\\boxed{(.*?)}'`)\n            trace_pattern (str, optional): Regular expression pattern with one\n                capture group to extract answers from trace text. If `None`,\n                uses the same pattern as solution_pattern.\n                (default: :obj:`None`)\n        \"\"\"\n        ...\n```\n\n----------------------------------------\n\nTITLE: Initializing CAMEL Model with GPT-4o-mini\nDESCRIPTION: Code that imports necessary CAMEL classes and initializes a model using ModelFactory with OpenAI's GPT-4o-mini, configuring it with a temperature of 0.0.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary classes\nfrom camel.societies import RolePlaying\nfrom camel.types import TaskType, ModelType, ModelPlatformType\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\n\nmodel = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n    model_config_dict=ChatGPTConfig(temperature=0.0).as_dict(), # [Optional] the config for model\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Tools from a Toolkit in Python\nDESCRIPTION: Example of extracting specific individual tools from a toolkit by wrapping them with FunctionTool, focusing on search capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.toolkits import FunctionTool, SearchToolkit\n\ngoogle_tool = FunctionTool(SearchToolkit().search_google)\nwiki_tool = FunctionTool(SearchToolkit().search_wiki)\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL and Dependencies in Python\nDESCRIPTION: This snippet installs the CAMEL package with all its dependencies, including starlette and nest_asyncio.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n!pip install starlette\n!pip install nest_asyncio\n```\n\n----------------------------------------\n\nTITLE: Initializing RolePlaying Session for CAMEL Agents\nDESCRIPTION: This snippet sets up the RolePlaying session with the configured agent models and task prompt.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nrole_play_session = RolePlaying(\n    assistant_role_name=\"Developer\",\n    user_role_name=\"CAMEL User\",\n    assistant_agent_kwargs=dict(\n        model=assistant_agent_model,\n        tools=tools,\n    ),\n    user_agent_kwargs=dict(\n        model=user_agent_model,\n    ),\n    task_prompt=task_prompt,\n    with_task_specify=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Hugging Face Dataset Upload Pipeline in Python\nDESCRIPTION: A comprehensive implementation for uploading CAMEL-generated mathematical problem-solving traces to Hugging Face datasets. The code handles loading JSON data, transforming it into Record objects, creating and configuring datasets on Hugging Face, and managing the entire upload process with proper metadata.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary modules and classes\nfrom camel.datahubs.huggingface import HuggingFaceDatasetManager  # Manages interactions with Hugging Face datasets\nfrom camel.datahubs.models import Record  # Represents a single record in the dataset\nfrom datetime import datetime  # Handles date and time operations\nimport json  # For reading JSON files\n\ndef load_star_output(file_path):\n    r\"\"\"Load and parse the star output JSON file.\n\n    Args:\n        file_path (str): Path to the star_output.json file.\n\n    Returns:\n        list: List of traces from the JSON file.\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data['traces']\n\n# Main function: Upload dataset to Hugging Face\ndef upload_to_huggingface(transformed_data, username, dataset_name=None):\n    r\"\"\"Uploads transformed data to the Hugging Face dataset platform.\n\n    Args:\n        transformed_data (list): Transformed data, typically a list of dictionaries.\n        username (str): Hugging Face username.\n        dataset_name (str, optional): Custom dataset name.\n\n    Returns:\n        str: URL of the uploaded dataset.\n    \"\"\"\n    # Initialize HuggingFaceDatasetManager to interact with Hugging Face datasets\n    manager = HuggingFaceDatasetManager()\n\n    # Generate or validate the dataset name\n    dataset_name = generate_or_validate_dataset_name(username, dataset_name)\n\n    # Create the dataset on Hugging Face and get the dataset URL\n    dataset_url = create_dataset(manager, dataset_name)\n\n    # Create a dataset card to add metadata\n    create_dataset_card(manager, dataset_name, username)\n\n    # Convert the transformed data into a list of Record objects\n    records = create_records(transformed_data)\n\n    # Add the Record objects to the dataset\n    add_records_to_dataset(manager, dataset_name, records)\n\n    # Return the dataset URL\n    return dataset_url\n\n# Generate or validate the dataset name\ndef generate_or_validate_dataset_name(username, dataset_name):\n    r\"\"\"Generates a default dataset name or validates and formats a user-provided name.\n\n    Args:\n        username (str): Hugging Face username.\n        dataset_name (str, optional): User-provided custom dataset name.\n\n    Returns:\n        str: Formatted dataset name.\n    \"\"\"\n    if dataset_name is None:\n        # If no dataset name is provided, generate a default name with the username and current date\n        current_date = datetime.now().strftime(\"%Y%m%d\")\n        dataset_name = f\"star_traces_{current_date}\"\n\n    # Format the dataset name to include the username\n    return f\"{username}/{dataset_name}\"\n\n# Create a dataset on Hugging Face\ndef create_dataset(manager, dataset_name):\n    r\"\"\"Creates a new dataset on Hugging Face and returns the dataset URL.\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n\n    Returns:\n        str: URL of the created dataset.\n    \"\"\"\n    dataset_url = manager.create_dataset(dataset_name)\n    return dataset_url\n\n# Create a dataset card with metadata\ndef create_dataset_card(manager, dataset_name, username):\n    r\"\"\"Creates a dataset card to add metadata\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n        username (str): Hugging Face username.\n    \"\"\"\n    manager.create_dataset_card(\n        dataset_name=dataset_name,\n        description=\"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.\",\n        license=\"mit\",  # Using lowercase 'mit' as required by HuggingFace\n        tags=[\"math\", \"problem-solving\", \"step-by-step\", \"traces\"],\n        authors=[username],\n        language=[\"en\"],\n        task_categories=[\"text-generation\"],\n        content=\"This dataset contains mathematical problem-solving traces generated using the CAMEL framework. Each entry includes:\\n\\n\"\n                \"- A mathematical problem statement\\n\"\n                \"- A detailed step-by-step solution\\n\"\n    )\n\n# Convert transformed data into Record objects\ndef create_records(transformed_data):\n    r\"\"\"Converts transformed data into a list of Record objects.\n\n    Args:\n        transformed_data (list): List of trace dictionaries from star_output.json.\n\n    Returns:\n        list: List of Record objects.\n    \"\"\"\n    records = []\n    for trace in transformed_data:\n        record = Record(\n            source_type=trace['type'],\n            problem=trace['problem'],\n            solution=trace['final_trace'],\n        )\n        records.append(record)\n    return records\n\n# Add Record objects to the dataset\ndef add_records_to_dataset(manager, dataset_name, records):\n    r\"\"\"Adds a list of Record objects to the dataset.\n\n    Args:\n        manager (HuggingFaceDatasetManager): Instance of HuggingFaceDatasetManager.\n        dataset_name (str): Name of the dataset.\n        records (list): List of Record objects.\n    \"\"\"\n    manager.add_records(dataset_name, records)\n\n```\n\n----------------------------------------\n\nTITLE: Setting up Single Step Environment and Resetting\nDESCRIPTION: This snippet initializes a SingleStepEnv with the filtered dataset and verifier, then resets the environment to get an initial observation.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/loong/single_step_env.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.environments import Action, SingleStepEnv\n\nenv = SingleStepEnv(filtered_dataset, verifier)\n\nobs = await env.reset(seed=42)\n\nprint(obs)\n```\n\n----------------------------------------\n\nTITLE: Running Inference with CAMEL-AI Model in Python\nDESCRIPTION: This code snippet demonstrates how to run inference using the CAMEL-AI model. It enables faster inference, tokenizes input, generates output, and decodes the result. The example uses an instruction to explain how to stay up to date with the CAMEL community.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n\n    AlpacaItem(\n        instruction=\"Explain how can I stay up to date with the CAMEL community.\",\n        input=\"\",\n        output=\"\", # leave this blank for generation!\n    ).to_string()\n\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\n----------------------------------------\n\nTITLE: Initializing AgentOps Tracking\nDESCRIPTION: Initializes AgentOps tracking with the API key and tags, and imports the SearchToolkit after initialization to enable tool usage tracking.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nAGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\")\nagentops.init(AGENTOPS_API_KEY, default_tags=[\"CAMEL X AgentOps Single Agent with Tool Example\"])\n\nfrom camel.toolkits import SearchToolkit\n```\n\n----------------------------------------\n\nTITLE: Executing Multi-Agent Conversation Loop\nDESCRIPTION: Implements the main conversation loop between AI agents, including tool usage and termination conditions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nn = 0\ninput_msg = role_play_session.init_chat()\nwhile n < 50:\n    n += 1\n    assistant_response, user_response = role_play_session.step(input_msg)\n\n    if assistant_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI Assistant terminated. Reason: \"\n                f\"{assistant_response.info['termination_reasons']}.\"\n            )\n        )\n        break\n    if user_response.terminated:\n        print(\n            Fore.GREEN\n            + (\n                \"AI User terminated. \"\n                f\"Reason: {user_response.info['termination_reasons']}.\"\n            )\n        )\n        break\n\n    # Print output from the user\n    print_text_animated(\n        Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\"\n    )\n\n    # Print output from the assistant, including any function\n    # execution information\n    print_text_animated(Fore.GREEN + \"AI Assistant:\")\n    tool_calls: List[FunctionCallingRecord] = assistant_response.info[\n        'tool_calls'\n    ]\n    for func_record in tool_calls:\n        print_text_animated(f\"{func_record}\")\n    print_text_animated(f\"{assistant_response.msg.content}\\n\")\n\n    if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n        break\n\n    input_msg = assistant_response.msg\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoRetriever and ChatAgent for Qdrant Integration in CAMEL\nDESCRIPTION: Sets up the AutoRetriever for accessing information from Qdrant storage and configures a ChatAgent with appropriate system message for handling retrieved information.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_with_agentic_RAG.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.retrievers import AutoRetriever\nfrom camel.types import StorageType\n\nassistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n         I will give you the Original Query and Retrieved Context,\n        answer the Original Query based on the Retrieved Context,\n        if you can't answer the question just say I don't know.\"\"\"\nauto_retriever = AutoRetriever(\n              vector_storage_local_path=\"local_data2/\",\n              storage_type=StorageType.QDRANT,\n              embedding_model=sentence_encoder\n            )\nqdrant_agent = ChatAgent(system_message=assistant_sys_msg, model=model)\n```\n\n----------------------------------------\n\nTITLE: Accessing Tool OpenAI Tool Schema in Python\nDESCRIPTION: Code to retrieve the complete OpenAI tool schema representation using the get_openai_tool_schema method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(add_tool.get_openai_tool_schema())\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Generation Functions with CAMEL and Firecrawl\nDESCRIPTION: Defines functions to generate training data in Alpaca format using CAMEL's ChatAgent and GPT-4o-mini. The functions handle creating instruction-input-response triplets from source content with proper tracking and formatting.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom camel.loaders import Firecrawl\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.configs import ChatGPTConfig\nfrom camel.agents import ChatAgent\nimport json\n\n\ndef generate_alpaca_items(content: str, n_items: int, start_num: int = 1, examples: List[AlpacaItem] = None) -> List[AlpacaItem]:\n    system_msg = \"\"\"\nYou are an AI assistant generating detailed, accurate responses based on the provided content.\nYou will be given a reference content, and you must generate a specific number of AlpacaItems.\nThese are instruction-input-response triplets, where the input is the context or examples.\n\nAdd a number to the items to keep track of the order. Generate exactly that many.\n\nFor each instruction, imagine but do not include a real world scenario and real user in that scenario to inform realistic and varied instructions. Avoid common sense questions and answers.\n\nInclude multiple lines in the output as appropriate to provide sufficient detail. Cite the most relevant context verbatim in output fields, do not omit anything important.\n\nLeave the input field blank.\n\nEnsure all of the most significant parts of the context are covered.\n\nStart with open ended instructions, then move to more specific ones. Consider the starting number for an impression of what has already been generated.\n    \"\"\"\n\n    examples_str = \"\"\n    if examples:\n        examples_str = \"\\n\\nHere are some example items for reference:\\n\" + \\\n            \"\\n\".join(ex.model_dump_json() for ex in examples)\n\n    model = ModelFactory.create(\n        model_platform=ModelPlatformType.OPENAI,\n        model_type=ModelType.GPT_4O_MINI,\n        model_config_dict=ChatGPTConfig(\n            temperature=0.6, response_format=AlpacaItemResponse\n        ).as_dict(),\n    )\n\n    agent = ChatAgent(\n        system_message=system_msg,\n        model=model,\n    )\n\n    prompt = f\"Content reference:\\n{content}{examples_str}\\n\\n Generate {n_items} AlpacaItems. The first should start numbering at {start_num}.\"\n    response = agent.step(prompt)\n\n    # Parse the generated JSON to our wrapper class\n    alpaca_items = [n_item.item for n_item in\n                    AlpacaItemResponse.\n                    model_validate_json(response.msgs[0].content).items]\n\n    return alpaca_items\n\n\ndef save_json(data: List, filename: str):\n    with open(filename, 'w', encoding='utf-8') as f:\n        json.dump([entry.model_dump() for entry in data], f, indent=2,\n                  ensure_ascii=False)\n\n\n# Few shot examples to ensure the right amount of detail\nexamples = [\n    AlpacaItem(\n        instruction=\"Explain the process for sprint planning and review in CAMEL.\",\n        input=\"\",\n        output=\"The process for sprint planning and review in CAMEL includes:\\n1. **Sprint Duration**: Each sprint lasts two weeks for development and one week for review.\\n2. **Planning Meeting**: Conducted biweekly, where the founder highlights the sprint goal and developers select items for the sprint.\\n3. **Review Meeting**: Stakeholders review the delivered features and provide feedback on the work completed during the sprint.\"\n    )\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Translation Prompts with TranslationPromptTemplateDict\nDESCRIPTION: Example of using TranslationPromptTemplateDict to create a translation assistant prompt for Spanish. This template can be customized for different target languages to facilitate translation tasks.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.prompts import TranslationPromptTemplateDict\n\n# Create a translation assistant prompt\ntranslation_prompt = TranslationPromptTemplateDict.ASSISTANT_PROMPT.format(target_language=\"Spanish\")\nprint(f\"Translation prompt:\\n{translation_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Self-Instruct Pipeline\nDESCRIPTION: Sets up and executes the self-instruction generation pipeline with specified parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npipeline = SelfInstructPipeline(\n    agent=agent,\n    seed=seed_path,\n    num_machine_instructions=target_num_instructions,\n    data_output_path=data_output_path,\n    human_to_machine_ratio=(num_human_sample, num_machine_sample),\n)\n\npipeline.generate()\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Processing for CoT Problems in Python\nDESCRIPTION: This asynchronous function demonstrates how to batch process multiple problems in parallel. It uses a ThreadPoolExecutor to submit tasks for each problem in the batch, dynamically adjusting the batch size based on performance metrics.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync def _batch_process_problems(\n    self, problems: List[Dict], rationalization: bool\n) -> List[ProblemResult]:\n    results = []\n    total_problems = len(problems)\n    processed = 0\n\n    while processed < total_problems:\n        batch_size = self.batch_processor.batch_size\n        batch = problems[processed : processed + batch_size]\n        batch_start_time = time.time()\n\n        with ThreadPoolExecutor(max_workers=self.batch_processor.max_workers) as executor:\n            futures = [\n                executor.submit(\n                    self.process_problem,\n                    problem=problem,\n                    rationalization=rationalization,\n                )\n                for problem in batch\n            ]\n            ...\n        processed += len(batch)\n        ...\n        # Log progress & performance\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL and Required Dependencies for Math Reasoning Data Generation\nDESCRIPTION: This code installs the CAMEL AI package from GitHub, along with datasets and rouge libraries needed for the math reasoning data generation pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n!pip install \"git+https://github.com/camel-ai/camel.git@f028e39fb2fbedcd30f43036899d3d13e5c25b01#egg=camel-ai\"\n!pip install datasets\n!pip install rouge\n```\n\n----------------------------------------\n\nTITLE: Configuring Tools for AI Assistant\nDESCRIPTION: Sets up math and search tools for the AI Assistant to use during the task execution.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntools = [\n    *MathToolkit().get_tools(),\n    *SearchToolkit().get_tools(),\n]\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL Memory Modules\nDESCRIPTION: Import statements for required CAMEL memory components and utilities\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.memories import (\n    ChatHistoryBlock,\n    LongtermAgentMemory,\n    MemoryRecord,\n    ScoreBasedContextCreator,\n    VectorDBBlock,\n)\nfrom camel.messages import BaseMessage\nfrom camel.types import ModelType, OpenAIBackendRole\nfrom camel.utils import OpenAITokenCounter\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Decorator for API Error Handling in Python\nDESCRIPTION: This decorator function implements a retry mechanism with exponential backoff for handling API instability. It attempts to execute the decorated function multiple times, increasing the delay between attempts after each failure.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef retry_on_error(\n    max_retries: int = 3, initial_delay: float = 1.0\n) -> Callable:\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            delay = initial_delay\n            for attempt in range(max_retries + 1):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    if attempt == max_retries:\n                        raise\n                    time.sleep(delay)\n                    delay *= 2\n            raise\n        return wrapper\n    return decorator\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Chatbot Loop\nDESCRIPTION: Creates an interactive chat loop that processes user input and generates responses using the configured ChatAgent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/finance_discord_bot.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Start chatting! Type 'exit' to end the conversation.\")\nwhile True:\n    user_input = input(\"User: \")\n\n    if user_input.lower() == \"exit\":\n        print(\"Ending conversation.\")\n        break\n\n    assistant_response = openbb_agent.step(user_input)\n    print(f\"Tool call: {assistant_response.info['tool_calls']}\")\n    print(f\"Assistant: {assistant_response.msgs[0].content}\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Mocked Hackathon Project Description in Python\nDESCRIPTION: This code creates a multi-line string containing a detailed description of a mocked hackathon project. The project is an AI-powered adaptive learning assistant that uses CAMEL-AI's capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/multi_agent_society/workforce_judge_committee.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nproj_content = textwrap.dedent(\n    \"\"\"\\\n    Project name: CAMEL-Powered Adaptive Learning Assistant\n    How does your project address a real problem: Our CAMEL-Powered Adaptive Learning Assistant addresses the challenge of personalized education in an increasingly diverse and fast-paced learning environment. Traditional one-size-fits-all approaches to education often fail to meet the unique needs of individual learners, leading to gaps in understanding and reduced engagement. Our project leverages CAMEL-AI's advanced capabilities to create a highly adaptive, intelligent tutoring system that can understand and respond to each student's learning style, pace, and knowledge gaps in real-time.\n    Explain your tech and which parts work: Our system utilizes CAMEL-AI's in-context learning and multi-domain application features to create a versatile learning assistant. The core components include:\n    1. Learner Profile Analysis: Uses natural language processing to assess the student's current knowledge, learning preferences, and goals.\n    2. Dynamic Content Generation: Leverages CAMEL-AI to create personalized learning materials, explanations, and practice questions tailored to each student's needs.\n    3. Adaptive Feedback Loop: Continuously analyzes student responses and adjusts the difficulty and style of content in real-time.\n    4. Multi-Modal Integration: Incorporates text, images, and interactive elements to cater to different learning styles.\n    5. Progress Tracking: Provides detailed insights into the student's learning journey, identifying strengths and areas for improvement.\n    Currently, we have successfully implemented the Learner Profile Analysis and Dynamic Content Generation modules. The Adaptive Feedback Loop is partially functional, while the Multi-Modal Integration and Progress Tracking features are still in development.\n    \"\"\"  # noqa: E501\n)\n```\n\n----------------------------------------\n\nTITLE: Decomposing Tasks with AI Agents in CAMEL (Python)\nDESCRIPTION: Demonstrates how to automatically break down a complex task into simpler subtasks using an AI agent. The example uses a template prompt for task decomposition and creates a ChatAgent to perform the decomposition.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.tasks import Task\nfrom camel.tasks.task_prompt import (\n    TASK_COMPOSE_PROMPT,\n    TASK_DECOMPOSE_PROMPT,\n)\nfrom camel.messages import BaseMessage\n\nsys_msg = BaseMessage.make_assistant_message(\n    role_name=\"Assistant\", content=\"You're a helpful assistant\"\n)\n# Set up an agent\nagent = ChatAgent(system_message=sys_msg)\n\ntask = Task(\n    content=\"Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\",\n    id=\"0\",\n)\n\n\nnew_tasks = task.decompose(agent=agent, template=TASK_DECOMPOSE_PROMPT)\nfor t in new_tasks:\n    print(t.to_string())\n```\n\n----------------------------------------\n\nTITLE: Querying Vector Retriever in CAMEL\nDESCRIPTION: Demonstrates how to query the vector retriever with a specific question. This retrieves the most relevant text chunk based on cosine similarity.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nretrieved_info = vector_retriever.query(\n    query=\"To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing .\",\n    top_k=1\n)\nprint(retrieved_info)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing MATH Dataset for Camel Single Step Environment\nDESCRIPTION: This snippet loads the MATH dataset, renames columns, removes unnecessary ones, and creates a StaticDataset for use in a SingleStepEnv. It also prints an example datapoint.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/loong/single_step_env.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\n\nfrom camel.datasets import StaticDataset\nfrom camel.logger import get_logger\n\nlogger = get_logger(__name__)\n\n\ndataset = load_dataset(\"EleutherAI/hendrycks_math\", \"algebra\")\n\n# Preprocess\ndataset[\"train\"] = dataset[\"train\"].rename_column(\"problem\", \"question\")\ndataset[\"train\"] = dataset[\"train\"].rename_column(\"solution\", \"final_answer\")\ndataset[\"train\"] = dataset[\"train\"].remove_columns([\"type\", \"level\"])\n\n# This should now print \"['question', 'final_answer']\"\nprint(dataset[\"train\"].column_names)\nseed_dataset = StaticDataset(dataset['train'])\n\nprint(\"Example datapoint:\", seed_dataset[0])\n```\n\n----------------------------------------\n\nTITLE: Creating ChatAgent in Python using CAMEL\nDESCRIPTION: This Python code creates a ChatAgent using CAMEL, setting up the system message, message window size, model, and token limit.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.logger import disable_logging\n\ndisable_logging()\nchat_agent = ChatAgent(\n    system_message=\"You're a helpful assistant\",\n    message_window_size=10,\n    model=ollama_model,\n    token_limit=8192, #change base on your input size\n)\n```\n\n----------------------------------------\n\nTITLE: Evolving Tasks with TaskManager (Python)\nDESCRIPTION: Shows how to use the TaskManager to evolve a task into a new, related task. This is useful for data generation and creating variations of existing tasks.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntask_manager = TaskManager(task)\nevolved_task = task_manager.evolve(task, agent=agent)\nprint(evolved_task.to_string())\n```\n\n----------------------------------------\n\nTITLE: Filtering Relationships Between Unique Nodes in Python\nDESCRIPTION: Filters relationships in a graph by keeping only those where both the subject and object nodes are in the unique_node_ids set. This ensures that only relationships between deduplicated nodes are retained.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nunique_relationships = []\nfor graph_unit in graph_element_list:\n    for rel in graph_unit.relationships:\n        if (\n            rel.subj.id in unique_node_ids\n            and rel.obj.id in unique_node_ids\n        ):\n            unique_relationships.append(rel)\n```\n\n----------------------------------------\n\nTITLE: Extracting Unique Nodes from Deduplication Results in Python\nDESCRIPTION: Creates a set of unique node IDs from the deduplication results. These IDs are extracted from the node_texts dictionary using the unique_ids from the deduplication results.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Get unique nodes\nunique_node_ids = {node_texts[i] for i in deduplication_result.unique_ids}\n```\n\n----------------------------------------\n\nTITLE: Generating Instructions and Pretty Printing Results in Python\nDESCRIPTION: This code demonstrates how to generate instructions using the SelfInstructPipeline and then pretty print the generated data content. It uses the json module to load and format the output data.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npipeline.generate()\n\nimport json\n\nwith open(data_output_path, 'r') as file:\n    data = json.load(file)\n    print(json.dumps(data, indent=4))\n```\n\n----------------------------------------\n\nTITLE: Processing Content with Vector Retriever in CAMEL\nDESCRIPTION: Processes the content of the downloaded PDF file using the vector retriever. This step embeds the text chunks and stores them in the vector database for later retrieval.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nvector_retriever.process(\n    content=\"local_data/camel_paper.pdf\",\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Custom Prompt Templates\nDESCRIPTION: Example of creating a custom prompt template with TextPrompt and using it with a TaskSpecifyAgent. This demonstrates how to tailor prompts to specific needs, in this case helping a Software Engineer get a promotion.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import TaskSpecifyAgent\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\nfrom camel.prompts import TextPrompt\nfrom camel.types import ModelPlatformType, ModelType\n\n# Set up the model\nmodel = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n)\n\n# Create a custom prompt template\nmy_prompt_template = TextPrompt(\n    'Here is a task: I\\'m a {occupation} and I want to {task}. Help me to make this task more specific.'\n)\n\n# Create a task specify agent with the custom prompt\ntask_specify_agent = TaskSpecifyAgent(\n    model=model, task_specify_prompt=my_prompt_template\n)\n\n# Run the agent with a task prompt\nresponse = task_specify_agent.run(\n    task_prompt=\"get promotion\",\n    meta_dict=dict(occupation=\"Software Engineer\"),\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Running the Camel-AI Agents App Locally with OpenAI API Key\nDESCRIPTION: Command to run the Agents app locally using Python. Requires an OpenAI API key to be provided as a command-line argument.\nSOURCE: https://github.com/camel-ai/camel/blob/master/apps/agents/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython agents.py --api-key=YOUR-OPENAI-API-KEY\n```\n\n----------------------------------------\n\nTITLE: Using Object Recognition Prompt Templates\nDESCRIPTION: Code snippet showing how to use ObjectRecognitionPromptTemplateDict to create an object recognition assistant prompt. This template can be used to guide AI models in identifying objects in images.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.prompts import ObjectRecognitionPromptTemplateDict\n\n# Create an object recognition assistant prompt\nrecognition_prompt = ObjectRecognitionPromptTemplateDict.ASSISTANT_PROMPT\nprint(f\"Object recognition prompt:\\n{recognition_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Ending an AgentOps Session in Python\nDESCRIPTION: This code demonstrates how to properly end an AgentOps session by calling the end_session method with a status message. This marks the completion of a tracking session in AgentOps.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# End the AgentOps session\nagentops.end_session(\"Success\")\n```\n\n----------------------------------------\n\nTITLE: Querying All Triplets from Neo4j Graph\nDESCRIPTION: This code snippet retrieves all triplets from the Neo4j graph and prints them. It uses the neo4j_graph.get_triplet() method to fetch the data and then iterates through the results, printing each triplet's subject, object, relationship, and timestamp.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Query all triplets\nall_triplets = neo4j_graph.get_triplet()\nif all_triplets:\n    for triplet in all_triplets:\n        print(\n            f\"Subject: {triplet['subj']}, Object: {triplet['obj']}, \"\n            f\"Relationship: {triplet['rel']}, \"\n            f\"Timestamp: {triplet['timestamp']}\"\n        )\nelse:\n    print(\"No triplets found in the database.\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Vector Retriever in CAMEL\nDESCRIPTION: Creates a VectorRetriever instance using the previously set up embedding model and storage. This retriever will be used for querying the vector database in the RAG pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.retrievers import VectorRetriever\n\nvector_retriever = VectorRetriever(embedding_model=embedding_instance,\n                                   storage=storage_instance)\n```\n\n----------------------------------------\n\nTITLE: Ending AgentOps Session in Python\nDESCRIPTION: Code to end an AgentOps monitoring session with a success status. This marks the completion of the monitoring period and allows accessing session records.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nagentops.end_session(\"Success\")\n```\n\n----------------------------------------\n\nTITLE: Creating Critic Agent in Python\nDESCRIPTION: Instantiates a CriticAgent object with the previously configured system message.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncritic_agent = CriticAgent(system_message=sys_msg, verbose=True)\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys for OpenAI, Firecrawl, and NVIDIA\nDESCRIPTION: Securely inputs and stores API keys for OpenAI, Firecrawl, and NVIDIA services as environment variables. These keys are essential for accessing the required services in the data generation and filtering process.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n\nopenai_api_key = getpass('Enter your OpenAI API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\n# Generate an API key at https://www.firecrawl.dev/app/api-keys\nfirecrawl_api_key = getpass('Enter your Firecrawl API key: ')\nos.environ[\"FIRECRAWL_API_KEY\"] = firecrawl_api_key\n\n# Generate an API key at https://build.nvidia.com/nvidia/nemotron-4-340b-reward\nnvidia_api_key = getpass('Enter your NVIDIA API key: ')\nos.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing CAMEL Agents in Python\nDESCRIPTION: This code snippet demonstrates how to initialize CAMEL agents for natural language processing tasks. It sets up the necessary dependencies and creates agent objects.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom camel import Agent\n\nagent1 = Agent(\"Human\")\nagent2 = Agent(\"AI Assistant\")\n\n# Initialize conversation\nconversation = agent1.start_conversation(agent2)\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Key Environment Variables for Model Access\nDESCRIPTION: Imports necessary modules for handling API keys and sets up environment variables for accessing Fireworks and DeepSeek models used in the data generation pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n```\n\nLANGUAGE: python\nCODE:\n```\nFIREWORKS_API_KEY = getpass('Enter your FIREWORKS_API_KEY: ')\nos.environ[\"FIREWORKS_API_KEY\"] = FIREWORKS_API_KEY\n```\n\nLANGUAGE: python\nCODE:\n```\nDEEPSEEK_API_KEY = getpass('Enter your DEEPSEEK_API_KEY: ')\nos.environ[\"DEEPSEEK_API_KEY\"] = DEEPSEEK_API_KEY\n```\n\nLANGUAGE: python\nCODE:\n```\n#to make deepseek r1 responds with thought process content,we should set the following environment variable\nos.environ[\"GET_REASONING_CONTENT\"]=\"True\"\n```\n\n----------------------------------------\n\nTITLE: API Key Setup and Environment Configuration\nDESCRIPTION: Configures API keys for Fireworks and Deepseek services, and sets environment variables for reasoning content\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n```\n\nLANGUAGE: python\nCODE:\n```\nFIREWORKS_API_KEY = getpass('Enter your FIREWORKS_API_KEY: ')\nos.environ[\"FIREWORKS_API_KEY\"] = FIREWORKS_API_KEY\n```\n\nLANGUAGE: python\nCODE:\n```\nDEEPSEEK_API_KEY = getpass('Enter your DEEPSEEK_API_KEY: ')\nos.environ[\"DEEPSEEK_API_KEY\"] = DEEPSEEK_API_KEY\n```\n\nLANGUAGE: python\nCODE:\n```\n#to make deepseek r1 responds with thought process content,we should set the following environment variable\nos.environ[\"GET_REASONING_CONTENT\"]=\"True\"\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Embedding Model in Python\nDESCRIPTION: Creates an instance of OpenAIEmbedding using the TEXT_EMBEDDING_3_LARGE model type. This embedding model will be used for vector representations in the RAG pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.embeddings import OpenAIEmbedding\nfrom camel.types import EmbeddingModelType\n\nembedding_instance = OpenAIEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_LARGE)\n```\n\n----------------------------------------\n\nTITLE: Creating a Task Specify Agent with Pre-defined Templates\nDESCRIPTION: Code to create a TaskSpecifyAgent using CAMEL's pre-defined prompt templates. This example uses the AI_SOCIETY task type to create a prompt for a Musician teaching a Student about improving stage presence.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import TaskSpecifyAgent\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType, TaskType\n\n# Set up the model\nmodel = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n)\n\n# Create a task specify agent\ntask_specify_agent = TaskSpecifyAgent(\n    model=model, task_type=TaskType.AI_SOCIETY\n)\n\n# Run the agent with a task prompt\nspecified_task_prompt = task_specify_agent.run(\n    task_prompt=\"Improving stage presence and performance skills\",\n    meta_dict=dict(\n        assistant_role=\"Musician\", user_role=\"Student\", word_limit=100\n    ),\n)\n\nprint(f\"Specified task prompt:\\n{specified_task_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dappier API Key\nDESCRIPTION: Securely prompts for and sets the Dappier API key as an environment variable. This allows secure interaction with Dappier services.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the Dappier API key securely\ndappier_api_key = getpass('Enter your API key: ')\nos.environ[\"DAPPIER_API_KEY\"] = dappier_api_key\n```\n\n----------------------------------------\n\nTITLE: Loading Local Data for HuggingFace Upload in Python\nDESCRIPTION: This code segment determines the current working directory, constructs the path to the generated data file, and loads the star output data from a JSON file.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# Load the star output data\ncurrent_dir = os.getcwd()\nstar_output_path = os.path.join(current_dir, './generated_data.json')\ntraces = load_star_output(star_output_path)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Qwen API Key Environment\nDESCRIPTION: Configures the Qwen API key by prompting the user for input and setting it as an environment variable.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/finance_discord_bot.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nqwen_api_key = getpass('Enter your API key: ')\nos.environ[\"QWEN_API_KEY\"] = qwen_api_key\n```\n\n----------------------------------------\n\nTITLE: Customizing Vector Database Block\nDESCRIPTION: Configuration example for VectorDBBlock with custom embedding models and storage\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.embeddings import OpenAIEmbedding\nfrom camel.memories import VectorDBBlock\nfrom camel.storages import QdrantStorage\n\nvector_db = VectorDBBlock(\n    embedding=OpenAIEmbedding(),\n    storage=QdrantStorage(vector_dim=OpenAIEmbedding().get_output_dim()),\n)\n```\n\n----------------------------------------\n\nTITLE: Building Hierarchical Task Structures in CAMEL (Python)\nDESCRIPTION: Shows how to create a hierarchical task structure with parent-child relationships. This example creates a root task with multiple subtasks, and some subtasks have their own children, demonstrating nesting capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Creating the root task\nroot_task = Task(content=\"Prepare a meal\", id=\"0\")\n\n# Creating subtasks for the root task\nsub_task_1 = Task(content=\"Shop for ingredients\", id=\"1\")\nsub_task_2 = Task(content=\"Cook the meal\", id=\"2\")\nsub_task_3 = Task(content=\"Set the table\", id=\"3\")\n\n# Creating subtasks under \"Cook the meal\"\nsub_task_2_1 = Task(content=\"Chop vegetables\", id=\"2.1\")\nsub_task_2_2 = Task(content=\"Cook rice\", id=\"2.2\")\n\n# Adding subtasks to their respective parent tasks\nroot_task.add_subtask(sub_task_1)\nroot_task.add_subtask(sub_task_2)\nroot_task.add_subtask(sub_task_3)\n\nsub_task_2.add_subtask(sub_task_2_1)\nsub_task_2.add_subtask(sub_task_2_2)\n\n# Printing the hierarchical task structure\nprint(root_task.to_string())\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for CAMEL Self-Improving CoT Pipeline\nDESCRIPTION: Imports necessary Python libraries including nest_asyncio for async operations, json and os for file handling, and CAMEL's modules for agents, data generation, models, and type definitions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\nnest_asyncio.apply()\n\nimport json\nimport os\nimport time\n\nfrom camel.agents import ChatAgent\nfrom camel.datagen import SelfImprovingCoTPipeline\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n```\n\n----------------------------------------\n\nTITLE: Setting Up AgentOps API Key in Python Environment\nDESCRIPTION: Script that securely prompts for an AgentOps API key and sets it as an environment variable. This allows secure authentication with the AgentOps service.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the AgentOps API key securely\nagentops_api_key = getpass('Enter your API key: ')\nos.environ[\"AGENTOPS_API_KEY\"] = agentops_api_key\n```\n\n----------------------------------------\n\nTITLE: Loading PDF File from URL\nDESCRIPTION: Code to download and save a PDF file from arXiv as example data.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\n\nos.makedirs('local_data', exist_ok=True)\n\nurl = \"https://arxiv.org/pdf/2303.17760.pdf\"\nresponse = requests.get(url)\nwith open('local_data/camel_paper.pdf', 'wb') as file:\n     file.write(response.content)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Chunkr API Key\nDESCRIPTION: Code to securely set up the Chunkr API key as an environment variable using getpass.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n# Prompt for the Chunkr API key securely\n\nchunkr_api_key = getpass('Enter your API key: ')\nos.environ[\"CHUNKR_API_KEY\"] = chunkr_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing LongtermAgentMemory\nDESCRIPTION: Setup and configuration of LongtermAgentMemory with record creation and context retrieval\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the memory\nmemory = LongtermAgentMemory(\n    context_creator=ScoreBasedContextCreator(\n        token_counter=OpenAITokenCounter(ModelType.GPT_4O_MINI),\n        token_limit=1024,\n    ),\n    chat_history_block=ChatHistoryBlock(),\n    vector_db_block=VectorDBBlock(),\n)\n\n# Create and write new records\nrecords = [\n    MemoryRecord(\n        message=BaseMessage.make_user_message(\n            role_name=\"User\",\n            content=\"What is CAMEL AI?\",\n        ),\n        role_at_backend=OpenAIBackendRole.USER,\n    ),\n    MemoryRecord(\n        message=BaseMessage.make_assistant_message(\n            role_name=\"Agent\",\n            content=\"CAMEL-AI.org is the 1st LLM multi-agent framework and \"\n            \"an open-source community dedicated to finding the scaling law \"\n            \"of agents.\",\n        ),\n        role_at_backend=OpenAIBackendRole.ASSISTANT,\n    ),\n]\nmemory.write_records(records)\n\n# Get context for the agent\ncontext, token_count = memory.get_context()\n\nprint(context)\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Role and Task\nDESCRIPTION: Sets up the role and task for the agent, creating a meta dictionary and role tuple that will be used to generate the system message for the embodied agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the role name and the task\nrole = 'Programmer'\ntask = 'Writing and executing codes.'\n\n# Create the meta_dict and the role_tuple\nmeta_dict = dict(role=role, task=task)\nrole_tuple = (role, RoleType.EMBODIMENT)\n```\n\n----------------------------------------\n\nTITLE: Verifying JSON Output in Python\nDESCRIPTION: Loads the generated JSON file and displays sample data to verify correct data generation and storage. Uses json.load() to read the file and json.dumps() to format the output for display.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Load and display data to ensure correctness\nwith open(output_file, \"r\") as f:\n    data = json.load(f)\n\nprint(\"Sample data:\", json.dumps(data[\"generated_queries\"][:100], indent=4))  # Display sample queries\nprint(\"\\nSample tool call data:\", json.dumps(data[\"tool_call_data\"][:100], indent=4))  # Display sample tool call data\n```\n\n----------------------------------------\n\nTITLE: Setting up AgentOps API Key\nDESCRIPTION: Code to securely set up AgentOps API credentials using environment variables.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the AgentOps API key securely\nagentops_api_key = getpass('Enter your API key: ')\nos.environ[\"AGENTOPS_API_KEY\"] = agentops_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Task Prompt for Multi-Agent Interaction\nDESCRIPTION: Defines the task prompt that specifies the goal for the AI agents to accomplish.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntask_prompt = (\n    \"Assume now is 2024 in the Gregorian calendar, \"\n    \"estimate the current age of University of Oxford \"\n    \"and then add 10 more years to this age, \"\n    \"and get the current weather of the city where \"\n    \"the University is located.\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring ChatAgent with OpenBB Tools\nDESCRIPTION: Sets up a ChatAgent with OpenBB toolkit and date tools, including system prompt configuration for financial data retrieval.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/finance_discord_bot.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\nfrom camel.toolkits import OpenBBToolkit, FunctionTool\nfrom datetime import date\n\nOPENBB_AGENT_SYSTEM_PROMPT = \"\"\"\n[...]\"\"\"\n\ndef get_today_date():\n  r\"\"\"Get the date of today.\"\"\"\n  return date.today()\n\nopenbb_toolkit = OpenBBToolkit()\nopenbb_tools = openbb_toolkit.get_tools()\ndate_tool = [FunctionTool(get_today_date)]\n\nopenbb_agent = ChatAgent(\n    system_message=OPENBB_AGENT_SYSTEM_PROMPT,\n    model=qwen_model,\n    tools=openbb_tools + date_tool\n)\n```\n\n----------------------------------------\n\nTITLE: Writing Python Docstrings with Raw String Format\nDESCRIPTION: Example showing how to format class docstrings using raw string notation. This format prevents issues with special characters and ensures consistent formatting for documentation tools like Sphinx.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nr\"\"\"Class for managing conversations of CAMEL Chat Agents.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Crawling Website and Storing Content using Firecrawl in Python\nDESCRIPTION: This Python code uses Firecrawl to crawl a website and store the content in a markdown file. It creates a directory for local data and writes the crawled content to a file.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom camel.loaders import Firecrawl\nfrom camel.messages import BaseMessage\n\nos.makedirs('local_data', exist_ok=True)\n\nfirecrawl = Firecrawl(api_url=firecrawl_api_url, api_key=\"_\")\n\ncrawl_response = firecrawl.crawl(\n    url=\"https://docs.camel-ai.org/\"\n)\n\nwith open('local_data/camel.md', 'w') as file:\n     file.write(crawl_response[\"data\"][0][\"markdown\"])\n```\n\n----------------------------------------\n\nTITLE: Documenting Function Parameters in Markdown Format\nDESCRIPTION: Example showing how to document function parameters in docstrings using the Args section. It demonstrates proper formatting for parameter names, types, descriptions, and default values while maintaining the 79-character line limit.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nArgs:\n    system_message (BaseMessage): The system message for initializing \n        the agent's conversation context.\n    model (BaseModelBackend, optional): The model backend to use for \n        response generation. Defaults to :obj:`OpenAIModel` with \n        `GPT_4O_MINI`. (default: :obj:`OpenAIModel` with `GPT_4O_MINI`)\n```\n\n----------------------------------------\n\nTITLE: Setting Task Prompt for GitHub Repository Starring\nDESCRIPTION: This snippet defines the task prompt for starring a GitHub repository.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntask_prompt = (\n    \"I have created a new Github Repo,\"\n    \"Please star my github repository: camel-ai/camel\"\n)\n```\n\n----------------------------------------\n\nTITLE: Starting Jupyter Notebook Server in Bash\nDESCRIPTION: This bash command starts a Jupyter Notebook server with specific configurations for allowing access from Google Colab.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\njupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' \\\n                 --port=8888 \\\n                 --no-browser\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for CAMEL-AI Training\nDESCRIPTION: Installs the necessary packages for training including Unsloth (for efficient fine-tuning), CAMEL-AI (core package), and Firecrawl (for content scraping).\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n!pip install unsloth\n# Install CAMEL-AI with no optional dependencies\n!pip install camel-ai==0.2.16\n# Get Unsloth\n!pip install --upgrade --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git@0de54572525788d09a6a9ef1efc7611e65dd7547\"\n!pip install firecrawl\n```\n\n----------------------------------------\n\nTITLE: Initializing Toolkits and Defining Tools List\nDESCRIPTION: Sets up the toolkits to be used in the data generation process. It includes MathToolkit and selected tools from SearchToolkit. Additional toolkits can be added with appropriate API keys.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# API keys can be setup in the notebook like this\n# google_api_key = getpass('Enter your API key: ')\n# os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n# weather_api_key = getpass('Enter your API key: ')\n# os.environ[\"OPENWEATHERMAP_API_KEY\"] = weather_api_key\n\nselected_tools = [\n    *MathToolkit().get_tools(),\n    # Add more tools as needed, though they require API keys\n    *[  # Search tools with no API keys required\n        FunctionTool(SearchToolkit().search_duckduckgo),\n        FunctionTool(SearchToolkit().search_wiki),\n    ],\n    # FunctionTool(SearchToolkit().search_google),\n    # *ArxivToolkit().get_tools(),\n    # *GoogleMapsToolkit().get_tools(),\n    # *WeatherToolkit().get_tools(),\n]\n```\n\n----------------------------------------\n\nTITLE: Composing Task Results from Subtasks (Python)\nDESCRIPTION: Shows how to compose the final result of a task by aggregating the results of its subtasks. This uses an AI agent with a template prompt to synthesize the subtask results into a cohesive final answer.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# compose task result by the sub-tasks.\ntask.compose(agent=agent, template=TASK_COMPOSE_PROMPT)\nprint(task.result)\n```\n\n----------------------------------------\n\nTITLE: Pulling Ollama Model in Bash\nDESCRIPTION: This bash command pulls the 'qwq' model using Ollama, a tool for running large language models locally.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nollama pull qwq\n```\n\n----------------------------------------\n\nTITLE: Collecting HuggingFace Credentials and Dataset Information in Python\nDESCRIPTION: This snippet prompts the user for their HuggingFace token, username, and desired dataset name. It sets the token as an environment variable for authentication purposes.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n# Get HuggingFace token and username\nHUGGING_FACE_TOKEN = getpass('Enter your HUGGING_FACE_TOKEN: ')\nos.environ[\"HUGGING_FACE_TOKEN\"] = HUGGING_FACE_TOKEN\nusername = input(\"Enter your HuggingFace username: \")\ndataset_name = input(\"Enter your dataset name:\")\n```\n\n----------------------------------------\n\nTITLE: Installing Latest CAMEL Version from GitHub for Cookbook Development\nDESCRIPTION: Command to install the latest version of CAMEL directly from GitHub's master branch with all optional extras. This allows cookbook writers to use the latest codebase or in-progress features.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install \"git+https://github.com/camel-ai/camel.git@master#egg=camel-ai[all]\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys for OpenAI and SambaNova\nDESCRIPTION: Securely prompts the user to enter API keys for OpenAI and SambaNova services and sets them as environment variables. Uses getpass for secure input of sensitive credentials.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/model_speed_comparison.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your OpenAI API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nsambanova_api_key = getpass('Enter your SambaNova API key: ')\nos.environ[\"SAMBA_API_KEY\"] = sambanova_api_key\n```\n\n----------------------------------------\n\nTITLE: Defining custom math functions for CAMEL tools\nDESCRIPTION: Creates two custom mathematical functions (add and subtract) with detailed docstrings to be used as tools by the AI agent. The docstrings explain parameters, purpose, and return values for proper tool understanding.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef add(a: int, b: int) -> int:\n    r\"\"\"Adds two numbers.\n\n    Args:\n        a (int): The first number to be added.\n        b (int): The second number to be added.\n\n    Returns:\n        integer: The sum of the two numbers.\n    \"\"\"\n    return a + b\n\ndef sub(a: int, b: int) -> int:\n    r\"\"\"Do subtraction between two numbers.\n\n    Args:\n        a (int): The minuend in subtraction.\n        b (int): The subtrahend in subtraction.\n\n    Returns:\n        integer: The result of subtracting :obj:`b` from :obj:`a`.\n    \"\"\"\n    return a - b\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Command to set the OpenAI API key as an environment variable.\nSOURCE: https://github.com/camel-ai/camel/blob/master/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='your_openai_api_key'\n```\n\n----------------------------------------\n\nTITLE: Implementing Instruction Filters\nDESCRIPTION: Demonstrates various filter implementations for instruction quality control including length, keyword, and punctuation filters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.datagen.self_instruct import LengthFilter, KeywordFilter, PunctuationFilter\n\nlength_filter = LengthFilter(min_len=5, max_len=50)\nkeyword_filter = KeywordFilter(keywords=[\"ban\", \"prohibit\", \"forbid\"])\npunctuation_filter = PunctuationFilter()\n\ninstructions = [\n    \"Sort the numbers in ascending order.\",\n    \"Calculate the sum.\",\n    \"Create a report that details the monthly expenses and savings in a spreadsheet.\"\n]\n\nfiltered_instructions = [instr for instr in instructions if length_filter.apply(instr)]\n```\n\n----------------------------------------\n\nTITLE: Printing Decoded Output in Python\nDESCRIPTION: Simple print statement to display the first element of decoded outputs array.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(decoded_outputs[0])  # Print the first (and only) output\n```\n\n----------------------------------------\n\nTITLE: Downloading Seed Data\nDESCRIPTION: Downloads and saves seed instruction data from CAMEL's GitHub repository.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\n\nos.makedirs('local_data', exist_ok=True)\n\nurl = \"https://raw.githubusercontent.com/camel-ai/camel/master/examples/datagen/self_instruct/seed_tasks.jsonl\"\n\nresponse = requests.get(url)\n\nwith open('local_data/seed_tasks.jsonl', 'wb') as file:\n    file.write(response.content)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running SFT Training with TRL and Unsloth\nDESCRIPTION: Sets up the SFTTrainer with appropriate training arguments and runs the training process. Uses batch size 2, gradient accumulation, and adaptive learning rate with 40 epochs for thorough training on the generated dataset.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = 512,\n    dataset_num_proc = 2,\n    packing = True, # Packs short sequences together to save time!\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_ratio = 0.1,\n        num_train_epochs = 40,\n        learning_rate = 2e-3,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.1,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use this for WandB etc\n    ),\n)\n# Ensure model is fully back in training mode\nmodel = FastLanguageModel.for_training(model)\n```\n\n----------------------------------------\n\nTITLE: Displaying agent's tool call results for search task\nDESCRIPTION: Prints the information about tool calls made by the agent when answering the question about when Oxford University was founded. This shows the search tool in action.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(assistant_response_search.info['tool_calls'])\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mistral API Integration\nDESCRIPTION: Code to configure Mistral API key for AI model integration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nmistral_api_key = getpass('Enter your API key')\nos.environ[\"MISTRAL_API_KEY\"] = mistral_api_key\n```\n\n----------------------------------------\n\nTITLE: Running All Tests in CAMEL Project\nDESCRIPTION: Command to execute all tests in the CAMEL project, including those that require the OpenAI API.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npytest .\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API Key\nDESCRIPTION: Code to securely set up OpenAI API credentials using environment variables.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Building Documentation Locally for CAMEL Project\nDESCRIPTION: Commands to build the Sphinx-based documentation for the CAMEL project locally.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake html\n```\n\n----------------------------------------\n\nTITLE: Importing Basic Modules for API Setup\nDESCRIPTION: Imports the necessary modules for setting up API keys, including agentops for tracking, os for environment variables, and getpass for secure input.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport agentops\nimport os\nfrom getpass import getpass\n```\n\n----------------------------------------\n\nTITLE: Processing User Request with Agent\nDESCRIPTION: Sends the user message to the agent, which will analyze the tasks, compose code to implement them, and execute the code after obtaining permission.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresponse = embodied_agent.step(usr_msg)\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL-AI and Nest AsyncIO Dependencies in Python\nDESCRIPTION: This snippet installs the required CAMEL-AI package and Nest AsyncIO for handling coroutines in notebook environments. It also applies Nest AsyncIO to enable asynchronous operations.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/multi_agent_society/workforce_judge_committee.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"camel-ai[all]==0.2.16\"\n```\n\nLANGUAGE: python\nCODE:\n```\n%pip install nest_asyncio\nimport nest_asyncio\nnest_asyncio.apply()\n```\n\n----------------------------------------\n\nTITLE: Setting Up CAMEL Agent Models with Composio Tools\nDESCRIPTION: This snippet creates and configures the assistant and user agent models, incorporating the Composio tools for the assistant.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nassistant_agent_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_3_5_TURBO,\n    model_config_dict=ChatGPTConfig(tools=tools).as_dict(),\n)\n\nuser_agent_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_3_5_TURBO,\n    model_config_dict=ChatGPTConfig().as_dict(),\n)\n```\n\n----------------------------------------\n\nTITLE: Running Data Explorer Script\nDESCRIPTION: Command line instructions for launching the Gradio web UI data explorer tool for CAMEL datasets. Includes both direct Python execution and help command options.\nSOURCE: https://github.com/camel-ai/camel/blob/master/apps/data_explorer/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install gradio\n```\n\nLANGUAGE: bash\nCODE:\n```\npython data_explorer.py\n```\n\nLANGUAGE: bash\nCODE:\n```\npython data_explorer.py --help\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mistral AI API Key in Python Environment\nDESCRIPTION: Script that securely prompts for a Mistral AI API key and sets it as an environment variable. This enables authentication with Mistral AI services.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the API key securely\nmistral_api_key = getpass('Enter your API key: ')\nos.environ[\"MISTRAL_API_KEY\"] = mistral_api_key\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Framework with All Dependencies\nDESCRIPTION: Command to install the CAMEL AI framework with all optional dependencies using pip. This installs version 0.2.16 with the [all] option to include all supplementary packages.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Tools Package\nDESCRIPTION: Command to install the additional tools package for CAMEL to enable enhanced agent capabilities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install 'camel-ai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Creating User Message for Agent Interaction\nDESCRIPTION: Creates a user message containing instructions for the agent to perform multiple tasks: installing numpy, computing a dot product, and checking weather data using wttr.in.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nusr_msg = bm.make_user_message(\n    role_name='user',\n    content=('1. write a bash script to install numpy. '\n             '2. then write a python script to compute '\n             'the dot product of [8, 9] and [5, 4], '\n             'and print the result. '\n             '3. then write a script to search for '\n             'the weather at london with wttr.in/london.'))\n```\n\n----------------------------------------\n\nTITLE: Configuring Mistral Large 2 Model with CAMEL ModelFactory\nDESCRIPTION: Code to set up the Mistral Large 2 model using CAMEL's ModelFactory. It configures the model platform, type, and temperature settings for optimal performance.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.configs import MistralConfig\n\n# Set up model\nmistral_large_2 = ModelFactory.create(\n    model_platform=ModelPlatformType.MISTRAL,\n    model_type=ModelType.MISTRAL_LARGE,\n    model_config_dict=MistralConfig(temperature=0.2).as_dict(),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package in Python\nDESCRIPTION: Installs the CAMEL AI package with all dependencies using pip. This step is necessary to use the CAMEL framework for RAG implementations.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package\nDESCRIPTION: Installation command for CAMEL AI framework with all dependencies\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_memory.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package with Dependencies in Python\nDESCRIPTION: Command to install the CAMEL package version 0.2.16 with all its dependencies using pip.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/roleplaying_scraper.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Connecting GitHub Account and Checking Available Apps\nDESCRIPTION: These commands connect the user's GitHub account to Composio and list available apps.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n!composio add github\n\n# Check all different apps which you can connect with\n!composio apps\n```\n\n----------------------------------------\n\nTITLE: Defining Termination Check Function in Python\nDESCRIPTION: Creates a helper function to check if the role-playing session should be terminated based on agent responses.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef is_terminated(response):\n    \"\"\"\n    Give alerts when the session should be terminated.\n    \"\"\"\n    if response.terminated:\n        role = response.msg.role_type.name\n        reason = response.info['termination_reasons']\n        print(f'AI {role} terminated due to {reason}')\n\n    return response.terminated\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package with Dependencies\nDESCRIPTION: Installs the CAMEL package with all its dependencies using pip. This is the first step in setting up the CAMEL AI environment.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Normalizing Names for Neo4j Compliance in Python\nDESCRIPTION: Normalizes label names to comply with Neo4j's naming rules by replacing special characters with underscores, ensuring no numeric prefixes, removing extra underscores, and applying SHA-1 hashing for length control. The function enforces a maximum 64-character limit while preserving uniqueness and readability.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport hashlib\n\ndef normalize_name(name: str, max_length: int = 64) -> str:\n    \"\"\"Normalize the label name to comply with Neo4j's naming rules\"\"\"\n    # Remove special characters and replace spaces with underscores\n    normalized = \"\".join(c if c.isalnum() else \"_\" for c in name)\n    # Ensure it does not start with a digit\n    if normalized[0].isdigit():\n        normalized = \"id_\" + normalized\n    # Remove extra underscores\n    normalized = \"_\".join(filter(None, normalized.split(\"_\")))\n\n    # If the VID is too long, use a hash function to generate a fixed-length VID\n    if len(normalized) > max_length:\n        # Use the SHA-1 hash function to generate a fixed-length VID\n        hash_value = hashlib.sha1(normalized.encode()).hexdigest()\n        # Truncate to max_length\n        normalized = hash_value[:max_length]\n\n    return normalized\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package in Python\nDESCRIPTION: Command to install the CAMEL AI library using pip. This installs version 0.2.16 of the package, which is required to use the functionality demonstrated in this cookbook.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Web Tools Extension\nDESCRIPTION: Installation command for CAMEL web tools additional package.\nSOURCE: https://github.com/camel-ai/camel/blob/master/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install 'camel-ai[web_tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package\nDESCRIPTION: Installs the CAMEL AI package version 0.2.16 using pip, which is required to use the EmbodiedAgent functionality.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Setting Task and Agent Parameters in Python\nDESCRIPTION: Defines the task, user role, assistant role, and critic role parameters for the RolePlaying session.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntask_kwargs = {\n    'task_prompt': 'Develop a plan to TRAVEL TO THE PAST and make changes.',\n    'with_task_specify': True,\n    'task_specify_agent_kwargs': {'model': model}\n}\n\nuser_role_kwargs = {\n    'user_role_name': 'an ambitious aspiring TIME TRAVELER',\n    'user_agent_kwargs': {'model': model}\n}\n\nassistant_role_kwargs = {\n    'assistant_role_name': 'the best-ever experimental physicist',\n    'assistant_agent_kwargs': {'model': model}\n}\n\ncritic_role_kwargs = {\n    'with_critic_in_the_loop': True,\n    'critic_criteria': 'improve the task performance',\n    'critic_kwargs': dict(verbose=True)\n}\n```\n\n----------------------------------------\n\nTITLE: Examining Generated Mathematical Reasoning Data\nDESCRIPTION: Loads and displays the generated mathematical reasoning data from the JSON output file for inspection.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith open('generated_data.json', 'r') as f:\n    data = json.load(f)\n    print(json.dumps(data, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Generating Test-Only Code Coverage Report in CAMEL Project\nDESCRIPTION: Command to generate a code coverage report that includes only the tested files in the CAMEL project.\nSOURCE: https://github.com/camel-ai/camel/blob/master/CONTRIBUTING.md#2025-04-07_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npytest --cov --cov-report=html\n```\n\n----------------------------------------\n\nTITLE: Accessing Tool OpenAI Function Schema in Python\nDESCRIPTION: Code to retrieve the OpenAI function schema representation of a tool using the get_openai_function_schema method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(add_tool.get_openai_function_schema())\n```\n\n----------------------------------------\n\nTITLE: Generating RST Documentation Files with Sphinx\nDESCRIPTION: Command to generate RST documentation files from the CAMEL Python package using sphinx-apidoc.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsphinx-apidoc -o docs camel/\n```\n\n----------------------------------------\n\nTITLE: Accessing Tool Function Description in Python\nDESCRIPTION: Code to retrieve the description of a function tool using the get_function_description method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(add_tool.get_function_description())\n```\n\n----------------------------------------\n\nTITLE: Configuring RolePlaying Environment in Python\nDESCRIPTION: Sets up the necessary components for the RolePlaying class, including model configuration and role specifications.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.societies import RolePlaying\nfrom camel.configs import ChatGPTConfig\nfrom camel.types import TaskType, ModelType, ModelPlatformType\nfrom colorama import Fore\nfrom camel.utils import print_text_animated\nfrom camel.models import ModelFactory\n\n# Set the LLM model type and model config\nmodel_platform = ModelPlatformType.OPENAI\nmodel_type = ModelType.GPT_4O_MINI\nmodel_config = ChatGPTConfig(\n    temperature=0.8,  # the sampling temperature; the higher the more random\n    n=3,              # the no. of completion choices to generate for each input\n    )\n\n# Create the backend model\nmodel = ModelFactory.create(\n    model_platform=model_platform,\n    model_type=model_type,\n    model_config_dict=model_config.as_dict())\n```\n\n----------------------------------------\n\nTITLE: Local Documentation URL\nDESCRIPTION: URL to access the locally served documentation in a web browser.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n127.0.0.1:8000\n```\n\n----------------------------------------\n\nTITLE: Displaying System Messages and Task Prompt\nDESCRIPTION: Prints the system messages for both the assistant and user agents, as well as the original task prompt. Uses colored output with Colorama's Fore module to distinguish between different message types.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Print system and task messages\nprint(\n    Fore.GREEN\n    + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n)\nprint(Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\")\n\nprint(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Evolved Task Output (Markdown)\nDESCRIPTION: Displays the output of the evolved task, showing how the original task was transformed into a more complex variant while maintaining the core problem domain.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n>>>Task 0.0: Weng earns $12 an hour for babysitting. Yesterday, she babysat for 1 hour and 45 minutes. If she also received a $5 bonus for exceptional service, how much did she earn in total for that day?\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: Lists required Python packages including cloud SQL Python connector with PyMySQL driver and SQLAlchemy ORM library with specific version constraints.\nSOURCE: https://github.com/camel-ai/camel/blob/master/apps/dilemma/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ncloud-sql-python-connector[\"pymysql\"]\nSQLAlchemy==2.0.7\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool Function Name Output\nDESCRIPTION: Expected output from retrieving a tool's function name.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n>>> add\n```\n\n----------------------------------------\n\nTITLE: Configuring Composio Toolset for GitHub Actions\nDESCRIPTION: This snippet sets up the Composio toolset with the specific GitHub star repository action.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncomposio_toolset = ComposioToolSet()\n\ntools = composio_toolset.get_actions(\n    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Role-Playing Session with CAMEL\nDESCRIPTION: Initializes a RolePlaying session with specified roles, models, and tools for the AI agents.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nrole_play_session = RolePlaying(\n    assistant_role_name=\"Searcher\",\n    user_role_name=\"Professor\",\n    assistant_agent_kwargs=dict(\n        model=ModelFactory.create(\n            model_platform=ModelPlatformType.OPENAI,\n            model_type=ModelType.GPT_4O_MINI,\n        ),\n        tools=tools,\n    ),\n    user_agent_kwargs=dict(\n        model=ModelFactory.create(\n            model_platform=ModelPlatformType.OPENAI,\n            model_type=ModelType.GPT_4O_MINI,\n        ),\n    ),\n    task_prompt=task_prompt,\n    with_task_specify=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Table of Contents for Camel Project in reStructuredText\nDESCRIPTION: A toctree directive that configures the documentation structure for the camel project. It sets the maximum depth of the table of contents to 4 levels and includes a reference to the camel module.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/modules.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 4\n\n   camel\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool OpenAI Function Schema Output\nDESCRIPTION: Expected output showing the OpenAI function schema format for a tool, including name, description, and parameter specifications.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n>>> \n{'name': 'add',\n 'description': 'Adds two numbers.',\n 'parameters': {'properties': {'a': {'type': 'integer',\n    'description': 'The first number to be added.'},\n   'b': {'type': 'integer', 'description': 'The second number to be added.'}},\n  'required': ['a', 'b'],\n  'type': 'object'}}\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for CAMEL Memories Package\nDESCRIPTION: Sphinx documentation structure defining the hierarchy and documentation settings for the camel.memories package and its submodules. Uses RST (reStructuredText) format to specify package organization and automodule directives.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.memories.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 4\n\n   camel.memories.blocks\n   camel.memories.context_creators\n\n.. automodule:: camel.memories.agent_memories\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.memories.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.memories.records\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.memories\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Setting Up SelfInstructPipeline with Custom InstructionFilter in Python\nDESCRIPTION: This snippet demonstrates how to set up a SelfInstructPipeline using a custom InstructionFilter. It shows the initialization of the pipeline with various parameters including the custom filters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\npipeline = SelfInstructPipeline(\n    agent=agent,\n    seed=seed_path,\n    num_machine_instructions=target_num_instructions,\n    data_output_path=data_output_path,\n    human_to_machine_ratio=(num_human_sample, num_machine_sample),\n    instruction_filter=filters,    # pass in your InstructionFilter\n)\n```\n\n----------------------------------------\n\nTITLE: Documenting camel.datasets Package in reStructuredText\nDESCRIPTION: This snippet outlines the structure of the camel.datasets package documentation. It includes sections for submodules and module contents, using Sphinx autodoc directives to generate documentation from docstrings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.datasets.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ncamel.datasets package\n======================\n\nSubmodules\n----------\n\ncamel.datasets.base module\n--------------------------\n\n.. automodule:: camel.datasets.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.datasets\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Math Reasoning Data Distillation\nDESCRIPTION: Imports necessary libraries from CAMEL and other packages to set up the mathematical reasoning data distillation pipeline, including the nest_asyncio library to allow nested event loops.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\nnest_asyncio.apply()\n\nimport json\nimport os\nimport time\n\nfrom camel.agents import ChatAgent\nfrom camel.datagen import SelfImprovingCoTPipeline\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n```\n\n----------------------------------------\n\nTITLE: Sphinx Documentation Directives\nDESCRIPTION: Sphinx documentation configuration directives for auto-documenting the CAMEL workforce package and its submodules.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.societies.workforce.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: camel.societies.workforce\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Documenting Tasks Package Contents with Sphinx\nDESCRIPTION: Sphinx autodoc directive to document the main camel.tasks package contents, showing all members, undocumented members, and inheritance relationships.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.tasks.rst#2025-04-07_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.tasks\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Instruction Filter in Python for CAMEL-AI\nDESCRIPTION: This snippet demonstrates how to create a custom filter function by subclassing FilterFunction from CAMEL-AI. It provides a template for implementing custom logic in the apply method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.datagen.self_instruct import FilterFunction\n\nclass CustomFilter(FilterFunction):\n\n    def apply(self, instruction: str) -> bool:\n        # apply your logic here\n        logic = ...\n        return logic\n```\n\n----------------------------------------\n\nTITLE: Resetting a ChatAgent to Initial State\nDESCRIPTION: Code to reset a ChatAgent to its initial state, clearing conversation history. This allows starting a fresh conversation with the agent while maintaining its original role and configuration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nagent.reset()\n```\n\n----------------------------------------\n\nTITLE: Sphinx documentation for camel.environments package\nDESCRIPTION: Sphinx documentation structure that outlines the camel.environments package, its submodules, and specifically highlights the base module. The documentation uses automodule directives to automatically generate documentation from docstrings in the code.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.environments.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ncamel.environments package\n==========================\n\nSubmodules\n----------\n\ncamel.environments.base module\n------------------------------\n\n.. automodule:: camel.environments.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.environments\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Base Storage Module Documentation\nDESCRIPTION: Documentation for the base key-value storage module that defines core interfaces and functionality.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.storages.key_value_storages.rst#2025-04-07_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.storages.key_value_storages.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Implementing ROUGE Similarity Filtering for Instructions in Python\nDESCRIPTION: This code shows how to use the RougeSimilarityFilter from CAMEL-AI to filter instructions based on their similarity to existing instructions. It sets a threshold for similarity and applies the filter to a list of new instructions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.datagen.self_instruct import RougeSimilarityFilter\n\nexisting_instructions = [\n    \"Summarize the article.\",\n    \"Write a brief overview of the text.\"\n]\n\nsimilarity_filter = RougeSimilarityFilter(existing_instructions, threshold=0.5)\n\ninstructions = [\n    \"Summarize the content.\",\n    \"Create a summary for the text.\",\n    \"Provide an analysis of the text.\"\n]\n\nfiltered_instructions = [instr for instr in instructions if similarity_filter.apply(instr)]\nprint(filtered_instructions)\n```\n\n----------------------------------------\n\nTITLE: In-Memory Storage Module Documentation\nDESCRIPTION: Documentation for the in-memory implementation of key-value storage.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.storages.key_value_storages.rst#2025-04-07_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.storages.key_value_storages.in_memory\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Printing System Messages and Task Prompts\nDESCRIPTION: Outputs the system messages for both AI agents and the various forms of the task prompt.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(\n    Fore.GREEN\n    + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n)\nprint(Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\")\n\nprint(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\nprint(\n    Fore.CYAN\n    + \"Specified task prompt:\"\n    + f\"\\n{role_play_session.specified_task_prompt}\\n\"\n)\nprint(Fore.RED + f\"Final task prompt:\\n{role_play_session.task_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: JSON Storage Module Documentation\nDESCRIPTION: Documentation for the JSON-based implementation of key-value storage.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.storages.key_value_storages.rst#2025-04-07_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.storages.key_value_storages.json\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Redis Storage Module Documentation\nDESCRIPTION: Documentation for the Redis-based implementation of key-value storage.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.storages.key_value_storages.rst#2025-04-07_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.storages.key_value_storages.redis\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Task Decomposition Output (Markdown)\nDESCRIPTION: Shows the output of a task decomposition operation, displaying the subtasks created from breaking down the main task.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n>>>\nTask 0.0: Convert 51 minutes into hours.\n\nTask 0.1: Calculate Weng's earnings for the converted hours at the rate of $12 per hour.\n\nTask 0.2: Provide the final earnings amount based on the calculation.\n```\n\n----------------------------------------\n\nTITLE: Filtering Non-English Instructions in Python using CAMEL-AI\nDESCRIPTION: This snippet demonstrates how to use the NonEnglishFilter from CAMEL-AI to filter out instructions that don't begin with English letters. It initializes the filter and applies it to a list of instructions.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.datagen.self_instruct import NonEnglishFilter\n\nnon_english_filter = NonEnglishFilter()\n\ninstructions = [\n    \"Analyze the performance metrics.\",\n    \".\",\n    \"Test the new algorithm.\"\n]\n\nfiltered_instructions = [instr for instr in instructions if non_english_filter.apply(instr)]\nprint(filtered_instructions)\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Role Parameters for CAMEL Society\nDESCRIPTION: Defines the assistant role parameters, setting the role as 'the best-ever experimental physicist' and passing the model for the assistant agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nassistant_role_kwargs = {\n    'assistant_role_name': 'the best-ever experimental physicist',\n    'assistant_agent_kwargs': {'model': model}\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Table of Contents in ReStructuredText\nDESCRIPTION: This RST code configures a table of contents for the data processing and analysis section, listing documentation pages for video analysis, PDF parsing with ChunkR, and website data ingestion with Firecrawl.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   video_analysis\n   agent_with_chunkr_for_pdf_parsing\n   ingest_data_from_websites_with_Firecrawl\n```\n\n----------------------------------------\n\nTITLE: Citation BibTeX Entry for CAMEL Project\nDESCRIPTION: BibTeX citation entry for the CAMEL research paper presented at the Neural Information Processing Systems conference.\nSOURCE: https://github.com/camel-ai/camel/blob/master/README.md#2025-04-07_snippet_4\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{li2023camel,\n  title={CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society},\n  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},\n  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},\n  year={2023}\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting camel.types Package Structure in reStructuredText\nDESCRIPTION: This snippet defines the documentation structure for the camel.types package using reStructuredText format. It includes section headers and automodule directives that automatically generate documentation from the Python module docstrings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.types.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ncamel.types package\n===================\n\nSubmodules\n----------\n\ncamel.types.enums module\n------------------------\n\n.. automodule:: camel.types.enums\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\ncamel.types.openai\\_types module\n--------------------------------\n\n.. automodule:: camel.types.openai_types\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.types\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Formatting Data for Training with Alpaca Format\nDESCRIPTION: Defines a formatting function to convert the dataset rows into the expected input format for training. Uses the AlpacaItem's to_string method to properly format each example with instruction, input, and output fields.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nEOS_TOKEN = tokenizer.eos_token\n\n# Provide function showing how to convert dataset row into inference text\ndef formatting_prompts_func(dataset_row):\n    return {\n        \"text\": [\n            AlpacaItem(instruction=inst, input=inp, output=out)\n                        .to_string() + EOS_TOKEN # Use handy to_string method\n            for inst, inp, out in zip(\n                dataset_row[\"instruction\"],\n                dataset_row[\"input\"],\n                dataset_row[\"output\"]\n            )\n        ]\n    }\n\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"json\", data_files=\"alpaca_format_data.json\", split=\"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True,)\n```\n\n----------------------------------------\n\nTITLE: Configuring User Role Parameters for CAMEL Society\nDESCRIPTION: Sets up the user role parameters, defining the role as 'an ambitious aspiring TIME TRAVELER' and passing the model for the user agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nuser_role_kwargs = {\n    'user_role_name': 'an ambitious aspiring TIME TRAVELER',\n    'user_agent_kwargs': {'model': model}\n}\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Camel Bots Package\nDESCRIPTION: Sphinx/RST documentation structure defining the layout and organization of the camel.bots package documentation, including subpackages for Discord and Slack, and a module for Telegram bot functionality.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.bots.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ncamel.bots package\n==================\n\nSubpackages\n-----------\n\n.. toctree::\n   :maxdepth: 4\n\n   camel.bots.discord\n   camel.bots.slack\n\nSubmodules\n----------\n\ncamel.bots.telegram_bot module\n-------------------------------\n\n.. automodule:: camel.bots.telegram_bot\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.bots\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Node Deduplication with Sentence Transformer Embeddings in Python\nDESCRIPTION: Performs internal deduplication on node texts using sentence transformer embeddings from the 'intfloat/e5-large-v2' model. The deduplication process uses a similarity threshold of 0.65 and employs a 'top1' strategy to identify and consolidate similar nodes in batches.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.utils import deduplicate_internally\nfrom camel.embeddings import SentenceTransformerEncoder\n\n# Perform internal deduplication\nsentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\ndeduplication_result = deduplicate_internally(\n    texts=node_texts,\n    threshold=0.65,\n    embedding_instance=sentence_encoder,\n    strategy=\"top1\",\n    batch_size=10,  # Adjust batch size as needed\n)\n```\n\n----------------------------------------\n\nTITLE: Investigating Chunk Elements with Different Max Characters\nDESCRIPTION: This snippet investigates the chunk_elements function by applying it with different max_characters values. It parses a PDF file, then chunks the elements using different maximum character limits, printing the number of resulting chunks for each limit.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nelements = uio.parse_file_or_url(str(example_pdf_files[0]))\nprint(\n    colorama.Fore.YELLOW\n    + \"The number of elements is: \"\n    + colorama.Fore.RESET\n    + str(len(elements))\n)\n\n# Investigation of the chunk_elements function.\nfor max_characters in [512, 1024, 2048]:\n    chunk_elements = uio.chunk_elements(\n        elements,\n        chunk_type=\"chunk_by_title\",\n        max_characters=max_characters,\n    )\n    print(\n        colorama.Fore.BLUE\n        + f\"[max_characters: {max_characters:>4}] \"\n        + colorama.Fore.YELLOW\n        + f\"The number of chunk elements is: {len(chunk_elements)}\"\n        + colorama.Fore.RESET\n    )\n```\n\n----------------------------------------\n\nTITLE: Documenting CAMEL Data Collector Package with Sphinx\nDESCRIPTION: This snippet uses Sphinx autodoc directives to generate documentation for the camel.data_collector package and its submodules. It includes all members, undocumented members, and inheritance information for each module.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.data_collector.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ncamel.data\\_collector package\n=============================\n\nSubmodules\n----------\n\ncamel.data\\_collector.alpaca\\_collector module\n----------------------------------------------\n\n.. automodule:: camel.data_collector.alpaca_collector\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\ncamel.data\\_collector.base module\n---------------------------------\n\n.. automodule:: camel.data_collector.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\ncamel.data\\_collector.sharegpt\\_collector module\n------------------------------------------------\n\n.. automodule:: camel.data_collector.sharegpt_collector\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.data_collector\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Custom Prompt for Dynamic Knowledge Graph Generation in Python\nDESCRIPTION: Defines a prompt template for extracting nodes and relationships from content, including timestamp information in the relationship elements. The prompt guides an AI agent to identify entities, categorize them as nodes, and determine relationships between entities with appropriate timestamps.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncustom_prompt = \"\"\"\nYou are tasked with extracting nodes and relationships from given content and structuring them into Node and Relationship objects. Here's the outline of what you need to do:\n\nContent Extraction: You should be able to process input content and identify entities mentioned within it.\n\nEntities can be any noun phrases or concepts that represent distinct entities in the context of the given content.\n\nNode Extraction: For each identified entity, you should create a Node object. Each Node object should have a unique identifier (id) and a type (type).\n\nAdditional properties associated with the node can also be extracted and stored.\n\nRelationship Extraction: You should identify relationships between entities mentioned in the content. For each relationship, create a Relationship object.\n\nA Relationship object should have a subject (subj) and an object (obj) which are Node objects representing the entities involved in the relationship.\n\nEach relationship should also have a type (type), and additional properties if applicable.\n\nTimestamp Requirement: For each relationship, you must assign a timestamp that reflects the time the relationship was established or mentioned based on the context of the provided content.\n\nIf the timestamp cannot be derived from the content, assign None instead. The timestamp format should be: YYYY-MM-DDTHH:MM:SS (e.g., \"2025-02-13T19:41:48\").\n\nOutput Formatting: The extracted nodes and relationships should be formatted as instances of the provided Node and Relationship classes.\n\nEnsure that the extracted data adheres to the structure defined by the classes. Output the structured data in a format that can be easily validated against the provided code.\n\nInstructions for you:\n\nRead the provided content thoroughly.\nIdentify distinct entities mentioned in the content and categorize them as nodes.\nDetermine relationships between these entities and represent them as directed relationships, including a timestamp for each relationship (or None if not applicable).\nProvide the extracted nodes and relationships in the specified format below.\nExample for you:\n\nExample Content: \"John works at XYZ Corporation since 2020. He is a software engineer. The company is located in New York City.\"\n\nExpected Output:\n\nNodes:\n\nNode(id='John', type='Person')\nNode(id='XYZ Corporation', type='Organization')\nNode(id='New York City', type='Location')\nRelationships:\n\nRelationships:\n\nRelationship(subj=Node(id='John', type='Person'), obj=Node(id='XYZ Corporation', type='Organization'), type='WorksAt', timestamp='2025-02-13T19:41:48')\nRelationship(subj=Node(id='John', type='Person'), obj=Node(id='New York City', type='Location'), type='ResidesIn', timestamp='2025-02-13T19:47:39')\n\n===== TASK ===== Please extract nodes and relationships from the given content and structure them into Node and Relationship objects.\n\n{task}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL modules for tool integration\nDESCRIPTION: Imports necessary modules from CAMEL to create agents and use toolkits, including SearchToolkit and other available toolkits (commented out). Also imports message and model factory components.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.configs import ChatGPTConfig\nfrom camel.toolkits import (\n    SearchToolkit,\n    # MathToolkit,\n    # GoogleMapsToolkit,\n    # TwitterToolkit,\n    # WeatherToolkit,\n    # RetrievalToolkit,\n    # TwitterToolkit,\n    # SlackToolkit,\n    # LinkedInToolkit,\n    # RedditToolkit,\n)\nfrom camel.messages import BaseMessage\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n```\n\n----------------------------------------\n\nTITLE: Sphinx Module Documentation\nDESCRIPTION: ReStructuredText documentation defining the structure and autodoc settings for the camel.toolkits package and its submodules. Each submodule is documented with members, undocumented members, and inheritance information exposed.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.toolkits.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.toolkits\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Task Manager Initial Task Output (Markdown)\nDESCRIPTION: Shows the string representation of the initial task before evolution with the TaskManager.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n>>>Task 0: Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL Agent Modules\nDESCRIPTION: Imports the necessary classes from CAMEL library for creating and configuring a chat agent with tools.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.configs import ChatGPTConfig\nfrom camel.messages import BaseMessage\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\n```\n\n----------------------------------------\n\nTITLE: Package Structure Declaration in RST\nDESCRIPTION: ReStructuredText markup defining the package structure and documentation organization for the CAMEL datagen package.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.datagen.rst#2025-04-07_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 4\n\n   camel.datagen.self_instruct\n   camel.datagen.source2synth\n```\n\n----------------------------------------\n\nTITLE: Initializing a ChatAgent with Tools in Python\nDESCRIPTION: Example of creating a ChatAgent with tools and interacting with it. This shows how to enhance an agent with custom capabilities by passing tools during initialization.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\n\n# Initialize a ChatAgent with your custom tools\ntool_agent = ChatAgent(\n    tools=tools,\n)\n\n# Interact with the agent\nresponse = tool_agent.step(\"A query related to the tool you added\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for CAMEL Multi-Agent Task\nDESCRIPTION: Imports necessary modules from CAMEL library and other dependencies for setting up the multi-agent task environment.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom colorama import Fore\n\nfrom camel.agents.chat_agent import FunctionCallingRecord\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\nfrom camel.societies import RolePlaying\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.utils import print_text_animated\n\nimport agentops\n```\n\n----------------------------------------\n\nTITLE: Documenting Ignore Risk Toolkit Module\nDESCRIPTION: RST documentation block for the ignore_risk_toolkit module that uses automodule directive to generate documentation from docstrings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.runtime.utils.rst#2025-04-07_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.runtime.utils.ignore_risk_toolkit\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Performing a Step in the Single Step Environment\nDESCRIPTION: This snippet demonstrates how to perform a step in the SingleStepEnv by providing an action (answer) and receiving the next observation, reward, and additional information.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/loong/single_step_env.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait env.step(Action(index=0, llm_response=\"\\\\boxed{5}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using a Toolkit in Python\nDESCRIPTION: Example of initializing a SearchToolkit and retrieving its tools. Toolkits provide collections of related tools designed to work together for specific tasks.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.toolkits import SearchToolkit\n\n# Initialize a toolkit\ntoolkit = SearchToolkit()\n\n# Get list of tools\ntools = toolkit.get_tools()\n```\n\n----------------------------------------\n\nTITLE: RST Navigation Structure Definition\nDESCRIPTION: Defines the navigation structure and table of contents for the agentic data generation documentation using reStructuredText directives.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. raw:: html\n\n   <div class=\"prev-next-nav\">\n     <a class=\"left-nav\" href=\"../applications/index.html\"> Applications</a>\n     <a class=\"right-nav\" href=\"../data_processing/index.html\">Data Processing </a>\n   </div>\n\n.. toctree::\n   :maxdepth: 1\n\n   sft_data_generation_and_unsloth_finetuning_mistral_7b_instruct\n   sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B\n   sft_data_generation_and_unsloth_finetuning_tinyllama\n   data_gen_with_real_function_calls_and_hermes_format\n   self_instruct_data_generation\n   cot_data_gen_sft_qwen_unsolth_upload_huggingface\n   synthetic_dataevaluation&filter_with_reward_model\n   data_model_generation_and_structured_output_with_qwen\n   distill_math_reasoning_data_from_deepseek_r1\n   self_improving_math_reasoning_data_distillation_from_deepSeek_r1\n   self_improving_cot_generation\n```\n\n----------------------------------------\n\nTITLE: Initializing Python Verifier for Answer Comparison\nDESCRIPTION: This snippet creates a PythonVerifier using the previously defined extractor. The verifier will be used to compare answers in the single step environment.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/loong/single_step_env.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.verifiers import PythonVerifier\n\nverifier = PythonVerifier(extractor=extractor)\nawait verifier.setup(uv=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Assistant Message\nDESCRIPTION: Example of creating an assistant message using BaseMessage factory method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.messages import BaseMessage\n\nassistant_message = BaseMessage.make_assistant_message(\n    role_name=\"assistant_name\",\n    content=\"test content for assistant\",\n)\n```\n\n----------------------------------------\n\nTITLE: Traditional Documentation Build and Serve\nDESCRIPTION: Alternative commands for building and serving documentation using make and Python's built-in HTTP server when autobuild doesn't work.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/README.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake html\ncd _build/html\npython -m http.server\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Models for Alpaca Format\nDESCRIPTION: Creates Pydantic models to ensure well-structured, type-safe, and validated data in the Alpaca format. These models are used to manage items systematically throughout the data generation process.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom camel.messages.conversion import AlpacaItem\n\nclass NumberedAlpacaItem(BaseModel):\n    number: int\n    item: AlpacaItem\n\n\nclass AlpacaItemResponse(BaseModel):\n    \"\"\"\n    Represents an instruction-response item in the Alpaca format.\n    \"\"\"\n    items: list[NumberedAlpacaItem]\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL Components\nDESCRIPTION: Imports the necessary classes and types from the CAMEL AI framework, including EmbodiedAgent, SystemMessageGenerator, BaseMessage, and RoleType.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import EmbodiedAgent\nfrom camel.generators import SystemMessageGenerator as sys_msg_gen\nfrom camel.messages import BaseMessage as bm\nfrom camel.types import RoleType\n```\n\n----------------------------------------\n\nTITLE: Implementing Safe JSON File Writing in Python\nDESCRIPTION: This function demonstrates a safe way to write JSON data to a file. It writes to a temporary file first, then replaces the original file, ensuring data integrity in case of interruptions during the write process.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef safe_write_json(self, file_path, data):\n    temp_path = file_path + \".tmp\"\n    with open(temp_path, \"w\") as f:\n        json.dump(data, f, indent=2)\n    os.replace(temp_path, file_path)\n```\n\n----------------------------------------\n\nTITLE: Defining System Message for ChatAgent Role\nDESCRIPTION: Setting up a system message that defines the role and behavior of a ChatAgent. This simple example creates a curious stone character that will guide the agent's responses.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsys_msg = 'You are a curious stone wondering about the universe.'\n```\n\n----------------------------------------\n\nTITLE: Configuring ChatAgent with Multiple Models in Python\nDESCRIPTION: This snippet shows how to create multiple model instances and add them to a ChatAgent. This setup allows for flexible model switching, enhancing the system's ability to handle errors and maintain reasoning continuity.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_cot_generation.md#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel1 = ModelFactory.create(\n    model_platform=ModelPlatformType.DEEPSEEK,\n    model_type=\"deepseek-reasoner\",\n    ...\n)\n\nmodel2 = ModelFactory.create(\n    model_platform=ModelPlatformType.TOGETHER,\n    model_type=\"deepseek-reasoner\",\n    ...\n)\n\nagent = ChatAgent(\n    system_message,\n    model=[model1, model2]\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing AgentOps for Task Tracking\nDESCRIPTION: Starts an AgentOps session to track the multi-agent task and imports necessary toolkits after initialization.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nagentops.start_session(tags=[\"CAMEL X AgentOps Multi-agent with Tools\"])\n\nfrom camel.toolkits import (\n    SearchToolkit,\n    MathToolkit,\n)\n```\n\n----------------------------------------\n\nTITLE: Viewing Generated Math Reasoning Data\nDESCRIPTION: Loads and displays the generated mathematical reasoning data from the output JSON file to review the results of the data distillation pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith open('generated_data.json', 'r') as f:\n    data = json.load(f)\n    print(json.dumps(data, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Defining Data Models for Tracking Generated Items\nDESCRIPTION: Creates Pydantic models to handle the Alpaca format items with numbering for tracking progress during generation. These models help maintain structure when generating multiple training examples.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nclass NumberedAlpacaItem(BaseModel):\n    number: int\n    item: AlpacaItem\n\n\nclass AlpacaItemResponse(BaseModel):\n    \"\"\"\n    Represents an instruction-response item in the Alpaca format.\n    \"\"\"\n    items: list[NumberedAlpacaItem]\n```\n\n----------------------------------------\n\nTITLE: Saving LoRA Adapters in Python\nDESCRIPTION: Demonstrates how to save the fine-tuned LoRA adapters locally or push them to Hugging Face's model hub. This only saves the LoRA adapters, not the full model.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel.save_pretrained(\"lora_model\") # Local saving\ntokenizer.save_pretrained(\"lora_model\")\nmodel.push_to_hub(\"zjrwtxtechstudio/qwen2.5-1.5b-cot\", token = \"  \") # Online saving\ntokenizer.push_to_hub(\"zjrwtxtechstudio/qwen2.5-1.5b-cot\", token = \"  \") # Online saving\n```\n\n----------------------------------------\n\nTITLE: Using TaskManager to Manage Tasks (Python)\nDESCRIPTION: Demonstrates how to use the TaskManager class to manage tasks, including initializing a TaskManager with a root task. The TaskManager provides methods for topological sorting, setting task dependencies, and evolving tasks.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.tasks import (\n    Task,\n    TaskManager,\n)\n\nsys_msg = \"You're a helpful assistant\"\n\n# Set up an agent\nagent = ChatAgent(system_message=sys_msg)\n\n\ntask = Task(\n    content=\"Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\",\n    id=\"0\",\n)\nprint(task.to_string())\n```\n\n----------------------------------------\n\nTITLE: Uploading Dataset to HuggingFace\nDESCRIPTION: Handles the upload of a transformed dataset to HuggingFace. Prompts for username and optional dataset name, then attempts to upload using a helper function. Includes error handling and success confirmation.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Set your personal huggingface config, then upload to HuggingFace\nusername = input(\"Enter your HuggingFace username: \")\ndataset_name = input(\"Enter dataset name (press Enter to use default): \").strip()\nif not dataset_name:\n    dataset_name = None\n\ntry:\n    dataset_url = upload_to_huggingface(transformed_data, username, dataset_name)\n    print(f\"\\nData successfully uploaded to HuggingFace!\")\n    print(f\"Dataset URL: {dataset_url}\")\nexcept Exception as e:\n    print(f\"Error uploading to HuggingFace: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Creating User Message\nDESCRIPTION: Example of creating a user message using BaseMessage factory method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.messages import BaseMessage\n\nuser_message = BaseMessage.make_user_message(\n    role_name=\"user_name\",\n    content=\"test content for user\",\n)\n```\n\n----------------------------------------\n\nTITLE: Markdown Data Preview Header\nDESCRIPTION: Section header for displaying a data preview screenshot reference in markdown format\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n##  Final Uploaded Data Preview\n```\n\n----------------------------------------\n\nTITLE: Creating BaseMessage Instance\nDESCRIPTION: Example of creating a BaseMessage instance with basic parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.messages import BaseMessage\nfrom camel.types import RoleType\n\nmessage = BaseMessage(\n    role_name=\"test_user\",\n    role_type=RoleType.USER,\n    content=\"test content\",\n    meta_dict={}\n)\n```\n\n----------------------------------------\n\nTITLE: Uploading Data to HuggingFace and Displaying Results in Python\nDESCRIPTION: This snippet uploads the loaded data to HuggingFace using the provided credentials and dataset name. It then prints a success message and the URL where the uploaded dataset can be viewed.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\n# Upload the data to HuggingFace\ndataset_url = upload_to_huggingface(traces, username, dataset_name)\nprint(f\"\\nDataset uploaded successfully!\")\nprint(f\"You can view your dataset at: {dataset_url}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Neo4j Connection Details\nDESCRIPTION: Prompts for and sets the Neo4j connection details including URI, username, and password. This configuration is essential for connecting to the Neo4j database where the knowledge graph will be stored.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for Neo4j securely\nos.environ[\"NEO4J_URI\"] = getpass('Enter NEO4J_URI: ')\nos.environ[\"NEO4J_USERNAME\"] = getpass('Enter NEO4J_USERNAME: ')\nos.environ[\"NEO4J_PASSWORD\"] = getpass('Enter NEO4J_PASSWORD: ')\n```\n\n----------------------------------------\n\nTITLE: Structuring JSON Response for Code Documentation\nDESCRIPTION: Defines the schema for returning structured code documentation as a JSON object. Includes fields for page metadata, code snippets, and error handling.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_10\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"page_title\": \"string\",      \n  \"page_description\": \"string\",    \n  \"page_summary\": \"string\",    \n  \"languages\": [\"string\"],\n  \"codeSnippets\": [\n    {\n      \"title\": \"string\",         \n      \"description\": \"string\",   \n      \"language\": \"string\",   \n      \"codeList\": [{\n          \"language\": \"string\",\n          \"code\": \"string\"\n      }]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Printing System Messages and Task Prompts\nDESCRIPTION: This snippet prints the system messages for both agents and the various forms of the task prompt.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(\n    Fore.GREEN\n    + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n)\nprint(Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\")\n\nprint(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\nprint(\n    Fore.CYAN\n    + \"Specified task prompt:\"\n    + f\"\\n{role_play_session.specified_task_prompt}\\n\"\n)\nprint(Fore.RED + f\"Final task prompt:\\n{role_play_session.task_prompt}\\n\")\n```\n\n----------------------------------------\n\nTITLE: Executing RolePlaying Session in Python\nDESCRIPTION: Calls the run function to start the role-playing session with the configured society.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nrun(society)\n```\n\n----------------------------------------\n\nTITLE: Converting Alpaca Format to Reward Model Format\nDESCRIPTION: Transforms Alpaca-style entries into a format compatible with the reward model. Each entry is converted into a structured list of instruction-input-response pairs for evaluation by the reward model.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/synthetic_dataevaluation&filter_with_reward_model.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmessages_lists=[]\nfor item in alpaca_entries:\n    messages_list =[]\n    user_content = item.instruction\n    if item.input:\n        user_content += f\"\\nInput: {item.input}\"\n    messages_list.append({\"role\": \"user\", \"content\": user_content})\n    messages_list.append({\"role\": \"assistant\", \"content\": item.output})\n    messages_lists.append(messages_list)\n```\n\n----------------------------------------\n\nTITLE: Displaying Agent Response\nDESCRIPTION: Prints the content of the agent's response message, which will contain the results of the executed code and any additional information provided by the agent.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(response.msg.content)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Ollama Model in Bash\nDESCRIPTION: This bash script pulls a base model and creates a custom model using a ModelFile. It sets parameters and a custom system message for the chat assistant.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/zsh\n\n# variables\nmodel_name=\"qwq\"\ncustom_model_name=\"camel-qwq\"\n\n#get the base model\nollama pull $model_name\n\n#create the model file\nollama create $custom_model_name -f ./ModelFile\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package\nDESCRIPTION: Installs the CAMEL AI Python package version 0.2.16 using pip, which is required to run the code examples in this cookbook.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/model_speed_comparison.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Handling Non-English Content Error\nDESCRIPTION: Defines the JSON structure for returning an error when the content is not in English.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_11\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"error\": \"non-english-content\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Termination Checker Function for CAMEL Society\nDESCRIPTION: Defines a helper function to check if a response from an agent indicates termination, printing the role and reason for termination.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef is_terminated(response):\n    \"\"\"\n    Give alerts when the session should be terminated.\n    \"\"\"\n    if response.terminated:\n        role = response.msg.role_type.name\n        reason = response.info['termination_reasons']\n        print(f'AI {role} terminated due to {reason}')\n\n    return response.terminated\n```\n\n----------------------------------------\n\nTITLE: Testing Untrained Model on CAMEL-specific Question\nDESCRIPTION: Runs a simple inference test on the untrained model using the AlpacaItem format from CAMEL. This establishes a baseline to compare with after training is complete.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.messages.conversion import AlpacaItem\n\ntemp_model = FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n\n   AlpacaItem(\n       instruction=\"Explain how can I stay up to date with the CAMEL community.\",\n       input=\"\",\n       output=\"\", # leave this blank for generation!\n   ).to_string()\n\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = temp_model.generate(**inputs, max_new_tokens = 512, use_cache = True)\ntemp_model = None\ntokenizer.batch_decode(outputs)\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package\nDESCRIPTION: Command to install the CAMEL AI library using pip, specifying version 0.2.16.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Keys in Python Environment\nDESCRIPTION: Script to securely prompt for and set the OpenAI API key as an environment variable, which is required for the CAMEL agents to communicate with OpenAI's models.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_prompting.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Checking Updated ChatAgent Memory\nDESCRIPTION: Retrieving the agent's memory context after adding a custom message. This confirms that the external message was successfully added to the conversation history.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Check the current memory\nagent.memory.get_context()\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Keys in Environment Variables\nDESCRIPTION: Code snippet to securely prompt for an OpenAI API key and set it as an environment variable. This uses getpass to hide the key input and sets the environment variable needed for OpenAI API access.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agent.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting up Mistral AI API Key\nDESCRIPTION: Code to securely set up Mistral AI API credentials using environment variables.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the API key securely\nmistral_api_key = getpass('Enter your API key: ')\nos.environ[\"MISTRAL_API_KEY\"] = mistral_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: Code to securely input and set the OpenAI API key as an environment variable using getpass for secure input.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/create_your_first_agents_society.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Up Chat Agent\nDESCRIPTION: Initializes a chat agent using the configured Qwen model.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import ChatAgent\nfrom camel.datagen.self_instruct import SelfInstructPipeline\n\nagent = ChatAgent(\n    model=qwen_model,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for Embedding Model\nDESCRIPTION: Securely prompts the user to enter their OpenAI API key and sets it as an environment variable. This is required for using OpenAI's embedding model in the RAG pipeline.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_rag.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\n# Prompt for the OpenAI API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing Qwen Model Configuration\nDESCRIPTION: Creates and configures the Qwen model instance with specific parameters.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.configs import QwenConfig\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\n\nqwen_model = ModelFactory.create(\n    model_platform=ModelPlatformType.QWEN,\n    model_type=ModelType.QWEN_TURBO,\n    model_config_dict=QwenConfig(temperature=0.2).as_dict(),\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: Securely prompts for the OpenAI API key and sets it as an environment variable for later use with the LLM.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the OpenAI API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries and Modules\nDESCRIPTION: Imports necessary libraries and modules from the CAMEL library, including ChatAgent, various message types, ModelFactory, and toolkits.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom typing import Callable, List, Union, Any\n\n# Import necessary classes and functions from camel library\nfrom camel.agents import ChatAgent\nfrom camel.messages import FunctionCallingMessage\nfrom camel.messages import HermesFunctionFormatter\nfrom camel.messages import ShareGPTConversation\nfrom camel.messages import ShareGPTMessage\nfrom camel.models import ModelFactory\nfrom camel.toolkits import FunctionTool, MathToolkit, SearchToolkit, \\\n    RetrievalToolkit\nfrom camel.types import ModelPlatformType, ModelType\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys for AI Services\nDESCRIPTION: Securely prompts for and sets API keys for Together, Sambanova, and OpenAI. These keys are necessary for accessing the respective AI services used in knowledge graph construction.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport dotenv\nimport colorama\nfrom getpass import getpass\n\ndotenv.load_dotenv()\n\n# Prompt for the TogetherAI API key securely\ntogether_api_key = getpass('Enter Together API key: ')\nos.environ[\"TOGETHER_API_KEY\"] = together_api_key\n\n# Prompt for the SambanovaAI API key securely\nsambanova_api_key = getpass('Enter Sambanova API key: ')\nos.environ[\"SAMBA_API_KEY\"] = sambanova_api_key\n\n# Prompt for the OpenAI API key securely\nopenai_api_key = getpass('Enter OpenAI API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\n    colorama.Fore.GREEN\n    + \" Loading environment variables successfully.\"\n    + colorama.Fore.RESET\n)\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI and Dependencies\nDESCRIPTION: Installs the CAMEL AI library and its dependencies, including optional features for RAG and web tools.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install 'camel-ai[rag,web_tools]==0.2.18'\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL and Composio Libraries\nDESCRIPTION: This snippet imports the necessary libraries from CAMEL and Composio, and sets up the OpenAI API key.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom colorama import Fore\nfrom composio_camel import Action, ComposioToolSet\n\nfrom camel.agents.chat_agent import FunctionCallingRecord\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\nfrom camel.societies import RolePlaying\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.utils import print_text_animated\n\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Output\nDESCRIPTION: Code to retrieve the processed output from a submitted Chunkr task.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nchunkr_output = chunkr_reader.get_task_output(task_id=\"902e686a-d6f5-413d-8a8d-241a3f43d35b\", max_retries=10)\nprint(chunkr_output)\n```\n\n----------------------------------------\n\nTITLE: Launching Neo4j Service for Graph Database\nDESCRIPTION: Starts the Neo4j service in the background using Ubuntu. This step is necessary to have a running Neo4j instance for storing and querying the knowledge graph.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nneo4j start\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package\nDESCRIPTION: Command to install the CAMEL package with all dependencies using pip.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npip install \"camel-ai[all]==0.2.11\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: Sets up the OpenAI API key by securely prompting the user for input and storing it as an environment variable, which is required for the agent to function.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/embodied_agents.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Accessing Real-Time Data with Dappier\nDESCRIPTION: Demonstrates how to use Dappier to search for real-time data, specifically the latest news related to CAMEL AI.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.toolkits import DappierToolkit\n\n# Search for real time data from a given user query.\nresponse = DappierToolkit().search_real_time_data(\n    query=\"latest news on CAMEL AI\"\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Qwen API Key\nDESCRIPTION: Configures the Qwen API key as an environment variable using secure input.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nqwen_api_key = getpass('Enter your Qwen API key: ')\nos.environ[\"QWEN_API_KEY\"] = qwen_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Up AgentOps API Key\nDESCRIPTION: Securely prompts for and sets the AgentOps API key as an environment variable. This is required for using AgentOps services.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the AgentOps API key securely\nagentops_api_key = getpass('Enter your API key: ')\nos.environ[\"AGENTOPS_API_KEY\"] = agentops_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: Prompts the user to enter their OpenAI API key securely and sets it as an environment variable.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n# Prompt for the OpenAI API key securely\nopenai_api_key = getpass('Enter your OpenAI API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: Securely prompts for and sets the OpenAI API key as an environment variable. This is necessary for using OpenAI's services.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/dynamic_travel_planner.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for OpenAI and Firecrawl\nDESCRIPTION: Sets up the necessary API keys for OpenAI (used for data generation) and Firecrawl (used for content scraping). Keys are securely captured using getpass and stored as environment variables.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n\nopenai_api_key = getpass('Enter your OpenAI API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\n# Generate an API key at https://www.firecrawl.dev/app/api-keys\nfirecrawl_api_key = getpass('Enter your Firecrawl API key: ')\nos.environ[\"FIRECRAWL_API_KEY\"] = firecrawl_api_key\n```\n\n----------------------------------------\n\nTITLE: Setting Discord Bot Token\nDESCRIPTION: Script to securely obtain and store the Discord bot token as an environment variable using getpass for secure input\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\ndiscord_bot_token = getpass('Enter your Discord bot token: ')\nos.environ[\"DISCORD_BOT_TOKEN\"] = discord_bot_token\n```\n\n----------------------------------------\n\nTITLE: Setting Up AgentOps API Key\nDESCRIPTION: Securely prompts for the AgentOps API key and sets it as an environment variable for tracking agent activities.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Prompt for the AgentOps API key securely\nagentops_api_key = getpass('Enter your API key: ')\nos.environ[\"AGENTOPS_API_KEY\"] = agentops_api_key\n```\n\n----------------------------------------\n\nTITLE: Creating Ollama Model in Python using CAMEL\nDESCRIPTION: This Python code creates an Ollama model using CAMEL's ModelFactory. It specifies the model platform, type, URL, and configuration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType\n\nollama_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OLLAMA,\n    model_type=\"qwq\",\n    url=\"http://localhost:11434/v1\", #optional\n    model_config_dict={\"temperature\": 0.4},\n)\n```\n\n----------------------------------------\n\nTITLE: HTML Link Buttons for CAMEL-AI Resources\nDESCRIPTION: HTML div containing centered button links to CAMEL-AI website and Discord server, along with Github star request and social media links\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.ipynb#2025-04-07_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"align-center\">\n  <a href=\"https://www.camel-ai.org/\"><img src=\"https://i.postimg.cc/KzQ5rfBC/button.png\"width=\"150\"></a>\n  <a href=\"https://discord.camel-ai.org\"><img src=\"https://i.postimg.cc/L4wPdG9N/join-2.png\"  width=\"150\"></a></a>\n  \n <i>Star us on <a href=\"https://github.com/camel-ai/camel\">Github</a> </i>, join our [*Discord*](https://discord.camel-ai.org) or follow our [*X*](https://x.com/camelaiorg)  \n</div>\n```\n\n----------------------------------------\n\nTITLE: Installing Jupyter Notebook for Local Runtime in Bash\nDESCRIPTION: This bash command installs Jupyter Notebook for setting up a local runtime environment.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install notebook\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package with pip\nDESCRIPTION: Basic installation command for the CAMEL framework using pip package manager.\nSOURCE: https://github.com/camel-ai/camel/blob/master/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install camel-ai\n```\n\n----------------------------------------\n\nTITLE: Setting up Firecrawl API URL in Python\nDESCRIPTION: This code prompts the user to enter the Firecrawl API URL and stores it in a variable for later use.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\n\nfirecrawl_api_url = getpass('Enter your API url: ')\n```\n\n----------------------------------------\n\nTITLE: Updating Composio Apps\nDESCRIPTION: This command updates the Composio apps to ensure the latest versions are used.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n! composio apps update\n```\n\n----------------------------------------\n\nTITLE: Importing CAMEL AI Modules in Python\nDESCRIPTION: Imports necessary modules from the CAMEL AI package, including CriticAgent, SystemMessageGenerator, BaseMessage, and RoleType.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom camel.agents import CriticAgent\nfrom camel.generators import SystemMessageGenerator as sys_msg_gen\nfrom camel.messages import BaseMessage as bm\nfrom camel.types import RoleType\n```\n\n----------------------------------------\n\nTITLE: RST Navigation Structure with Table of Contents\nDESCRIPTION: ReStructuredText markup defining the navigation structure and table of contents for the basic concepts documentation section.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nBasic Concepts\n=============\n\n.. raw:: html\n\n   <div class=\"prev-next-nav\">\n     <a class=\"right-nav\" href=\"../applications/index.html\">Applications </a>\n   </div>\n\n.. toctree::\n   :maxdepth: 1\n\n   create_your_first_agent\n   create_your_first_agents_society\n   agents_message\n   agents_prompting\n   model_speed_comparison\n```\n\n----------------------------------------\n\nTITLE: Logging into Composio\nDESCRIPTION: This command logs the user into Composio.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n!composio login\n```\n\n----------------------------------------\n\nTITLE: Accessing Tool Function Name in Python\nDESCRIPTION: Code to retrieve the name of a function tool using the get_function_name method.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(add_tool.get_function_name())\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL and Composio Packages\nDESCRIPTION: This snippet installs the required packages for CAMEL and Composio integration.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools_from_Composio.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"camel-ai[all]==0.1.6.5\"\n%pip install \"composio-camel -U\"\n\nimport composio\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenBB Authentication\nDESCRIPTION: Configures OpenBB authentication by setting the personal access token as an environment variable.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/finance_discord_bot.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nopenbb_pat = getpass(\"Enter your OpenBB PAT: \")\nos.environ[\"OPENBB_TOKEN\"] = openbb_pat\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API key for CAMEL\nDESCRIPTION: Securely sets up the OpenAI API key as an environment variable, prompting the user to enter their key without displaying it in plain text.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt for the API key securely\nopenai_api_key = getpass('Enter your API key: ')\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool OpenAI Tool Schema Output\nDESCRIPTION: Expected output showing the OpenAI tool schema format, which wraps the function schema in a structure specifying the type as 'function'.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n>>> \n{'type': 'function',\n 'function': {'name': 'add',\n  'description': 'Adds two numbers.',\n  'parameters': {'properties': {'a': {'type': 'integer',\n     'description': 'The first number to be added.'},\n    'b': {'type': 'integer', 'description': 'The second number to be added.'}},\n   'required': ['a', 'b'],\n   'type': 'object'}}}\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL with all dependencies\nDESCRIPTION: Installs the CAMEL package with all optional dependencies using pip, specifically version 0.2.16.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_tools.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL and AgentOps Packages\nDESCRIPTION: Installs the CAMEL AI package with all dependencies and AgentOps tracking library using pip.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install camel-ai[all]==0.2.16\n%pip install agentops==0.3.10\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package for Knowledge Graph Construction\nDESCRIPTION: Installs the CAMEL package with all its dependencies using pip. This setup is required for dynamic knowledge graph construction from financial reports.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_with_dkg.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npip install \"camel-ai[rag]==0.2.22\"\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package\nDESCRIPTION: Installs the CAMEL package with all required dependencies using pip.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_instruct_data_generation.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai[all]==0.2.18\"\n```\n\n----------------------------------------\n\nTITLE: Defining Project Structure in Python\nDESCRIPTION: This snippet defines a project structure, likely for the CAMEL project. It includes references to various modules and components.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\nProject: /camel-ai/camel\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL Package\nDESCRIPTION: Installation command for the CAMEL package with dependencies.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/basic_concepts/agents_message.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Initializing AgAABAgQIECDQgYAgbwdNsAQCBL4SiINoQd6vaHyCAAECBAgQIECBAgQIECBA\nDESCRIPTION: This code snippet appears to be a base64 encoded string or binary data. It's not clear what specific functionality it represents without decoding.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_16\n\nLANGUAGE: unknown\nCODE:\n```\nAgAABAgQIECDQgYAgbwdNsAQCBL4SiINoQd6vaHyCAAECBAgQIECBAgQIECBA\n```\n\n----------------------------------------\n\nTITLE: Installing CAMEL AI Package in Python\nDESCRIPTION: Installs the CAMEL AI package version 0.2.16 using pip.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/critic_agents_and_tree_search.ipynb#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"camel-ai==0.2.16\"\n```\n\n----------------------------------------\n\nTITLE: Ending AgentOps Session\nDESCRIPTION: Concludes the AgentOps tracking session for the multi-agent task.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/agents_tracking.ipynb#2025-04-07_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nagentops.end_session(\"Success\")\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Navigation and TOC\nDESCRIPTION: RST markup for configuring navigation links and table of contents structure for the advanced features documentation section.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/advanced_features/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. raw:: html\n\n   <div class=\"prev-next-nav\">\n     <a class=\"left-nav\" href=\"../multi_agent_society/index.html\"> Multi-agent Society</a>\n     <a class=\"right-nav\" href=\"../data_processing/index.html\">Data Processing </a>\n   </div>\n\n.. toctree::\n   :maxdepth: 1\n\n   agents_with_tools\n   agents_with_tools_from_Composio\n   agents_with_human_in_loop_and_tool_approval\n   agents_with_memory\n   agents_with_rag\n   agents_with_graph_rag\n   agents_tracking\n   critic_agents_and_tree_search\n   embodied_agents\n```\n\n----------------------------------------\n\nTITLE: Module Documentation Structure in RST\nDESCRIPTION: Sphinx documentation structure showing the key-value storage package organization and its submodules using reStructuredText format.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.storages.key_value_storages.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.storages.key_value_storages\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: RST Table of Contents Structure\nDESCRIPTION: Defines a table of contents tree using reStructuredText format with maxdepth of 1, listing various application examples\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/index.rst#2025-04-07_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   roleplaying_scraper\n   dynamic_travel_planner\n   customer_service_Discord_bot_with_agentic_RAG\n   customer_service_Discord_bot_using_SambaNova_with_agentic_RAG\n   customer_service_Discord_bot_using_local_model_with_agentic_RAG\n   finance_discord_bot\n```\n\n----------------------------------------\n\nTITLE: Submodule Documentation Directive\nDESCRIPTION: Sphinx directive for documenting individual workforce submodules with member and inheritance details.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.societies.workforce.rst#2025-04-07_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: camel.societies.workforce.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: HTML Community Links Section with Buttons and Star Instructions\nDESCRIPTION: HTML code for rendering community links section with buttons for the CAMEL-AI website and Discord, along with instructions to star the GitHub repository and follow on social media platforms.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.ipynb#2025-04-07_snippet_16\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"align-center\">\n  <a href=\"https://www.camel-ai.org/\"><img src=\"https://i.postimg.cc/KzQ5rfBC/button.png\"width=\"150\"></a>\n  <a href=\"https://discord.camel-ai.org\"><img src=\"https://i.postimg.cc/L4wPdG9N/join-2.png\"  width=\"150\"></a></a>\n  \n <i>Star us on [*Github*](https://github.com/camel-ai/camel), join our [*Discord*](https://discord.camel-ai.org) or follow our [*X*](https://x.com/camelaiorg)\n</div>\n```\n\n----------------------------------------\n\nTITLE: Documenting Module Contents\nDESCRIPTION: RST documentation block for the main camel.runtime.utils package that uses automodule directive to generate documentation from docstrings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.runtime.utils.rst#2025-04-07_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.runtime.utils\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: HTML Navigation Structure\nDESCRIPTION: Defines previous and next navigation links using HTML div structure with left and right navigation arrows\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/applications/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"prev-next-nav\">\n  <a class=\"left-nav\" href=\"../basic_concepts/index.html\"> Basic Concepts</a>\n  <a class=\"right-nav\" href=\"../data_generation/index.html\">Model Training </a>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Documenting Function Risk Toolkit Module\nDESCRIPTION: RST documentation block for the function_risk_toolkit module that uses automodule directive to generate documentation from docstrings.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.runtime.utils.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.runtime.utils.function_risk_toolkit\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool Function Description Output\nDESCRIPTION: Expected output from retrieving a tool's function description.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tools.md#2025-04-07_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n>>> Adds two numbers.\n```\n\n----------------------------------------\n\nTITLE: Documenting camel.personas Package in reStructuredText\nDESCRIPTION: This snippet uses reStructuredText directives to document the camel.personas package, including its submodules and module contents. It specifies automodule directives for generating comprehensive documentation of the package's components.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.personas.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ncamel.personas package\n======================\n\nSubmodules\n----------\n\ncamel.personas.persona module\n-----------------------------\n\n.. automodule:: camel.personas.persona\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\ncamel.personas.persona_hub module\n----------------------------------\n\n.. automodule:: camel.personas.persona_hub\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.personas\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Hierarchical Task Structure Output (Markdown)\nDESCRIPTION: Shows the output of printing a hierarchical task structure, displaying the parent-child relationships in a readable format.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/key_modules/tasks.md#2025-04-07_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n>>>\n    Task 0: Prepare a meal\n    Task 1: Shop for ingredients\n    Task 2: Cook the meal\n        Task 2.1: Chop vegetables\n        Task 2.2: Cook rice\n    Task 3: Set the table\n```\n\n----------------------------------------\n\nTITLE: Building and Serving Documentation with Autobuild\nDESCRIPTION: Command to build and serve documentation using sphinx-autobuild, which automatically rebuilds on changes and serves on port 8000.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nsphinx-autobuild . _build/html --port 8000\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Navigation and Table of Contents\nDESCRIPTION: Sets up the navigation structure and table of contents for the multi-agent society documentation section using reStructuredText directives. Includes previous/next navigation links and defines document hierarchy.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/multi_agent_society/index.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. raw:: html\n\n   <div class=\"prev-next-nav\">\n     <a class=\"left-nav\" href=\"../data_processing/index.html\"> Data Processing</a>\n     <a class=\"right-nav\" href=\"../advanced_features/index.html\">Advanced Features </a>\n   </div>\n\n.. toctree::\n   :maxdepth: 1\n\n   agents_society\n   workforce_judge_committee\n   task_generation\n```\n\n----------------------------------------\n\nTITLE: Copyright and Apache License 2.0 Header for CAMEL-AI.org\nDESCRIPTION: Standard license header that appears at the top of source files in the CAMEL-AI.org project. It indicates that the code is licensed under Apache License 2.0 and includes the terms and conditions for usage.\nSOURCE: https://github.com/camel-ai/camel/blob/master/licenses/license_template.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n```\n\n----------------------------------------\n\nTITLE: Sphinx Documentation Structure for Camel Terminators\nDESCRIPTION: RST-formatted documentation structure that defines the layout and organization of the camel.terminators package documentation using Sphinx automodule directives.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.terminators.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.terminators.base\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.terminators.response_terminator\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.terminators.token_limit_terminator\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.terminators\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Documenting Task Module with Sphinx\nDESCRIPTION: Sphinx autodoc directive to document the camel.tasks.task module, showing all members, undocumented members, and inheritance relationships.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.tasks.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.tasks.task\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Module Documentation Directives in RST\nDESCRIPTION: ReStructuredText directives for auto-documenting the CAMEL datagen modules including chain-of-thought and self-improving implementations.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.datagen.rst#2025-04-07_snippet_1\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: camel.datagen.cot_datagen\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.datagen.self_improving_cot\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\n.. automodule:: camel.datagen\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Creating Navigation Controls in HTML\nDESCRIPTION: This embedded HTML code creates previous and next navigation controls for the documentation page, with links to 'Advanced Features' and 'Multi-agent Society' pages respectively.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/cookbooks/data_processing/index.rst#2025-04-07_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"prev-next-nav\">\n  <a class=\"left-nav\" href=\"../advanced_features/index.html\"> Advanced Features</a>\n  <a class=\"right-nav\" href=\"../multi_agent_society/index.html\">Multi-agent Society </a>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Documenting Task Prompt Module with Sphinx\nDESCRIPTION: Sphinx autodoc directive to document the camel.tasks.task_prompt module, showing all members, undocumented members, and inheritance relationships.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.tasks.rst#2025-04-07_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: camel.tasks.task_prompt\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Defining ShareGPT Package Structure in Sphinx Documentation\nDESCRIPTION: Sphinx documentation structure for the camel.messages.conversion.sharegpt package. It defines the package hierarchy, including subpackages like hermes and modules like function_call_formatter.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.messages.conversion.sharegpt.rst#2025-04-07_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ncamel.messages.conversion.sharegpt package\n==========================================\n\nSubpackages\n-----------\n\n.. toctree::\n   :maxdepth: 4\n\n   camel.messages.conversion.sharegpt.hermes\n\nSubmodules\n----------\n\ncamel.messages.conversion.sharegpt.function\\_call\\_formatter module\n-------------------------------------------------------------------\n\n.. automodule:: camel.messages.conversion.sharegpt.function_call_formatter\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.messages.conversion.sharegpt\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Documenting camel.memories.context_creators Package in reStructuredText\nDESCRIPTION: This snippet defines the structure and content of the documentation for the camel.memories.context_creators package. It includes section headers, submodule references, and automodule directives for generating comprehensive documentation.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.memories.context_creators.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ncamel.memories.context\\_creators package\n========================================\n\nSubmodules\n----------\n\ncamel.memories.context\\_creators.score\\_based module\n----------------------------------------------------\n\n.. automodule:: camel.memories.context_creators.score_based\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel.memories.context_creators\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Defining CAMEL Package Structure in reStructuredText\nDESCRIPTION: This snippet outlines the structure of the CAMEL package, listing its subpackages and modules using reStructuredText syntax for Sphinx documentation.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/camel.rst#2025-04-07_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ncamel package\n=============\n\nSubpackages\n-----------\n\n.. toctree::\n   :maxdepth: 4\n\n   camel.agents\n   camel.configs\n   camel.datagen\n   camel.embeddings\n   camel.interpreters\n   camel.loaders\n   camel.memories\n   camel.messages\n   camel.models\n   camel.prompts\n   camel.responses\n   camel.retrievers\n   camel.societies\n   camel.storages\n   camel.tasks\n   camel.terminators\n   camel.toolkits\n   camel.types\n   camel.utils\n\nSubmodules\n----------\n\ncamel.generators module\n-----------------------\n\n.. automodule:: camel.generators\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\ncamel.human module\n------------------\n\n.. automodule:: camel.human\n   :members:\n   :undoc-members:\n   :show-inheritance:\n\nModule contents\n---------------\n\n.. automodule:: camel\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Installing Documentation Dependencies\nDESCRIPTION: Commands to install required Python packages for building documentation including Sphinx, sphinx_book_theme, sphinx-autobuild, myst_parser, and nbsphinx.\nSOURCE: https://github.com/camel-ai/camel/blob/master/docs/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install sphinx\npip install sphinx_book_theme\npip install sphinx-autobuild\npip install myst_parser\npip install nbsphinx\n```"
  }
]