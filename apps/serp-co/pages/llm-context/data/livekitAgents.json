[
  {
    "owner": "livekit",
    "repo": "agents",
    "content": "TITLE: Installing LiveKit Agents with Dependencies\nDESCRIPTION: Command to install the core Agents library along with plugins for popular model providers including OpenAI, Silero, Deepgram, Cartesia, and turn detector.\nSOURCE: https://github.com/livekit/agents/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"livekit-agents[openai,silero,deepgram,cartesia,turn-detector]~=1.0\"\n```\n\n----------------------------------------\n\nTITLE: Running LiveKit Transcriber with Environment Setup\nDESCRIPTION: Bash commands to set up environment variables for LiveKit URL, API credentials, and OpenAI API key, followed by launching the transcriber script.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/speech-to-text/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport LIVEKIT_URL=wss://yourhost.livekit.cloud\nexport LIVEKIT_API_KEY=livekit-api-key\nexport LIVEKIT_API_SECRET=your-api-secret\nexport OPENAI_API_KEY=your-api-key\n\npython3 transcriber.py start\n```\n\n----------------------------------------\n\nTITLE: Integrating Gladia STT with LiveKit Agents Framework\nDESCRIPTION: Demonstrates how to incorporate the Gladia STT component into a LiveKit Agent configuration, showing the integration pattern for the broader framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-gladia/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.agents import Agent\nfrom livekit.plugins.gladia.stt import STT as GladiaSTT\n\nagent = Agent(\n    stt=GladiaSTT(\n        api_key=\"your-api-key-here\",\n        languages=[\"en\"],\n        translation_enabled=True,\n        translation_target_languages=[\"es\"]\n    )\n)\n\n# Rest of your agent setup...\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple Voice Agent\nDESCRIPTION: Example implementation of a basic voice agent using LiveKit Agents framework. The agent uses Silero for VAD, Deepgram for STT, OpenAI for LLM and TTS, and includes a weather lookup tool function.\nSOURCE: https://github.com/livekit/agents/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.agents import (\n    Agent,\n    AgentSession,\n    JobContext,\n    RunContext,\n    WorkerOptions,\n    cli,\n    function_tool,\n)\nfrom livekit.plugins import deepgram, openai, silero\n\n@function_tool\nasync def lookup_weather(\n    context: RunContext,\n    location: str,\n):\n    \"\"\"Used to look up weather information.\"\"\"\n\n    return {\"weather\": \"sunny\", \"temperature\": 70}\n\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n\n    agent = Agent(\n        instructions=\"You are a friendly voice assistant built by LiveKit.\",\n        tools=[lookup_weather],\n    )\n    session = AgentSession(\n        vad=silero.VAD.load(),\n        # any combination of STT, LLM, TTS, or realtime API can be used\n        stt=deepgram.STT(model=\"nova-3\"),\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=openai.TTS(voice=\"ash\"),\n    )\n\n    await session.start(agent=agent, room=ctx.room)\n    await session.generate_reply(instructions=\"greet the user and ask about their day\")\n\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\n----------------------------------------\n\nTITLE: Implementing Gemini Multimodal Live with Video Input in Python\nDESCRIPTION: This code snippet demonstrates how to use Gemini Multimodal Live with the MultimodalAgent class, including handling live video input. It shows how to subscribe to video tracks, create a video stream, sample frames, and push them into a RealtimeSession.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Make sure you subscribe to audio and video tracks\nawait ctx.connect(auto_subscribe=AutoSubscribe.SUBSCRIBE_ALL)\n\n# Create your RealtimeModel and store a reference\nmodel = google.beta.realtime.RealtimeModel(\n    # ...\n)\n\n# Create your MultimodalAgent as usual\nagent = MultimodalAgent(\n    model=model,\n    # ...\n)\n\n# Async method to process the video track and push frames to Gemini\nasync def _process_video_track(self, track: Track):\n    video_stream = VideoStream(track)\n    last_frame_time = 0\n    \n    async for event in video_stream:\n        current_time = asyncio.get_event_loop().time()\n        \n        # Sample at 1 FPS\n        if current_time - last_frame_time < 1.0: \n            continue\n            \n        last_frame_time = current_time\n        frame = event.frame\n        \n        # Push the frame into the RealtimeSession\n        model.sessions[0].push_video(frame)\n        \n    await video_stream.aclose()\n\n# Subscribe to new tracks and process them\n@ctx.room.on(\"track_subscribed\")\ndef _on_track_subscribed(track: Track, pub, participant):\n    if track.kind == TrackKind.KIND_VIDEO:\n        asyncio.create_task(self._process_video_track(track))\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit OpenAI Plugin via pip\nDESCRIPTION: Command to install the LiveKit OpenAI plugin package using pip package manager.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-openai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-openai\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for LiveKit Agents\nDESCRIPTION: This requirements file lists the necessary Python packages for the LiveKit Agents project. It specifies the LiveKit Agents package with specific AI components, environment variable management via python-dotenv, and web search functionality through duckduckgo-search.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/voice_agents/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nlivekit-agents[openai, cartesia, elevenlabs, deepgram, silero, turn-detector]>=1.0\npython-dotenv>=1.0\nduckduckgo-search>=8.0\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual RAG with LlamaIndex Retriever in Python\nDESCRIPTION: This method manually injects retrieved context into the system prompt using LlamaIndex's retriever. It provides fine-grained control but involves more complex prompt engineering.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/voice_agents/llamaindex-rag/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nretrieval.py\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG with LlamaIndex's as_chat_engine in Python\nDESCRIPTION: This snippet uses LlamaIndex's as_chat_engine for a straightforward, integrated RAG solution. It offers simplicity but lacks function calling support, which may limit advanced interactions.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/voice_agents/llamaindex-rag/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nchat_engine.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Speechmatics with LiveKit Agent Session\nDESCRIPTION: Example of initializing an AgentSession with Speechmatics STT and English turn detection model. Includes configuration for minimum and maximum endpointing delays.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-speechmatics/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.agents import AgentSession\nfrom livekit.plugins.turn_detector.english import EnglishModel\nfrom livekit.plugins import speechmatics\n\nagent = AgentSession(\n    stt=speechmatics.STT(),\n    turn_detector=EnglishModel(),\n    min_endpointing_delay=0.5,\n    max_endpointing_delay=5.0,\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for LiveKit Agents Project\nDESCRIPTION: This requirements file lists all the necessary Python packages for a LiveKit Agents project. It specifies version constraints for each package to ensure compatibility. The dependencies include the core LiveKit Agents package, various integration plugins, and the python-dotenv package for managing environment variables.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/text-to-speech/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nlivekit-agents>=0.12.18\nlivekit-plugins-openai>=0.12.2\nlivekit-plugins-cartesia>=0.4.11\nlivekit-plugins-elevenlabs>=0.8.1\nlivekit-plugins-speechify>=0.1.0\npython-dotenv~=1.0\n```\n\n----------------------------------------\n\nTITLE: Starting the LiveKit Moderation Agent\nDESCRIPTION: Command to launch the LiveKit agent that performs visual moderation using Hive's API. The agent will automatically join all new LiveKit rooms and begin monitoring video content.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/hive-moderation-agent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 agent.py start\n```\n\n----------------------------------------\n\nTITLE: Advanced Configuration of Gladia STT in LiveKit\nDESCRIPTION: Demonstrates comprehensive configuration of the Gladia STT component with multiple options including language settings, code switching, audio parameters, and translation settings.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-gladia/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# With more options\nstt = GladiaSTT(\n    languages=[\"en\", \"fr\"],  # Specify languages or let Gladia auto-detect\n    code_switching=True,     # Allow switching between languages during recognition\n    sample_rate=16000,       # Audio sample rate in Hz\n    bit_depth=16,            # Audio bit depth\n    channels=1,              # Number of audio channels\n    encoding=\"wav/pcm\",      # Audio encoding format\n    energy_filter=True,      # Enable voice activity detection\n    translation_enabled=True,\n    translation_target_languages=[\"en\"],\n    translation_model=\"base\",\n    translation_match_original_utterances=True\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI STT Client in Python\nDESCRIPTION: Code snippet showing how to initialize the OpenAI STT (Speech-to-Text) client. This can be modified to use alternative STT plugins.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/speech-to-text/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nstt = openai.STT()\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for LiveKit Agents\nDESCRIPTION: This snippet defines the required Python packages for the LiveKit agents project. It specifies a version constraint for bithuman and includes opencv-python without a version specification.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bithuman/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nbithuman~=0.5.3\nopencv-python\n```\n\n----------------------------------------\n\nTITLE: Specifying LiveKit Agent Dependencies\nDESCRIPTION: Defines the required Python package dependencies with version constraints. Requires livekit-agents version 0.12.18 or higher and python-dotenv version 1.0.x.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/simple-color/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nlivekit-agents>=0.12.18\npython-dotenv~=1.0\n```\n\n----------------------------------------\n\nTITLE: Using TTS with Async Context Manager in Python\nDESCRIPTION: This example demonstrates the recommended way to use the TTS class from the livekit.plugins.resemble module. It shows how to initialize the TTS object, perform one-off synthesis, collect audio chunks, and use real-time streaming synthesis. The async context manager ensures proper resource cleanup.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-resemble/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom livekit.plugins.resemble import TTS\n\nasync def run_tts_example():\n    # Use TTS with async context manager for automatic resource cleanup\n    async with TTS(\n        api_key=\"your_api_key\",  # or set RESEMBLE_API_KEY environment variable\n        voice_uuid=\"your_voice_uuid\",\n        # Optional parameters\n        sample_rate=44100,  # Sample rate in Hz (default: 44100)\n        precision=\"PCM_16\",  # Audio precision (PCM_32, PCM_24, PCM_16, MULAW)\n        output_format=\"wav\",  # Output format (wav or mp3)\n    ) as tts:\n        # One-off synthesis (uses REST API)\n        audio_stream = tts.synthesize(\"Hello, world!\")\n        \n        # Process chunks as they arrive\n        async for chunk in audio_stream:\n            # Audio data is in the 'frame.data' attribute of SynthesizedAudio objects\n            audio_data = chunk.frame.data\n            print(f\"Received chunk: {len(audio_data)} bytes\")\n        \n        # Alternative: collect all audio at once into a single AudioFrame\n        audio_stream = tts.synthesize(\"Another example sentence.\")\n        audio_frame = await audio_stream.collect()\n        print(f\"Collected complete audio: {len(audio_frame.data)} bytes\")\n        \n        # Real-time streaming synthesis (uses WebSocket API)\n        # Only available for Business plan users in Resemble AI\n        stream = tts.stream()\n        await stream.synthesize_text(\"Hello, world!\")\n        \n\n\n# Run the example\nasyncio.run(run_tts_example())\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins for Beyond Presence in Python\nDESCRIPTION: This command installs the LiveKit plugin for Beyond Presence integration using pip. It allows developers to add speech-to-video capabilities for human avatars in their LiveKit projects.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-bey/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-bey\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Agent Handoff System\nDESCRIPTION: Implementation of a multi-agent system that demonstrates agent handoff functionality. Includes an IntroAgent that gathers user information and hands off to a StoryAgent for storytelling.\nSOURCE: https://github.com/livekit/agents/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass IntroAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=f\"You are a story teller. Your goal is to gather a few pieces of information from the user to make the story personalized and engaging.\"\n            \"Ask the user for their name and where they are from\"\n        )\n\n    async def on_enter(self):\n        self.session.generate_reply(instructions=\"greet the user and gather information\")\n\n    @function_tool\n    async def information_gathered(\n        self,\n        context: RunContext,\n        name: str,\n        location: str,\n    ):\n        \"\"\"Called when the user has provided the information needed to make the story personalized and engaging.\n\n        Args:\n            name: The name of the user\n            location: The location of the user\n        \"\"\"\n\n        context.userdata.name = name\n        context.userdata.location = location\n\n        story_agent = StoryAgent(name, location)\n        return story_agent, \"Let's start the story!\"\n\n\nclass StoryAgent(Agent):\n    def __init__(self, name: str, location: str) -> None:\n        super().__init__(\n            instructions=f\"You are a storyteller. Use the user's information in order to make the story personalized.\"\n            f\"The user's name is {name}, from {location}\"\n            # override the default model, switching to Realtime API from standard LLMs\n            llm=openai.realtime.RealtimeModel(voice=\"echo\"),\n            chat_ctx=chat_ctx,\n        )\n\n    async def on_enter(self):\n        self.session.generate_reply()\n\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n\n    userdata = StoryData()\n    session = AgentSession[StoryData](\n        vad=silero.VAD.load(),\n        stt=deepgram.STT(model=\"nova-3\"),\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=openai.TTS(voice=\"echo\"),\n        userdata=userdata,\n    )\n\n    await session.start(\n        agent=IntroAgent(),\n        room=ctx.room,\n    )\n```\n\n----------------------------------------\n\nTITLE: Running the LiveKit Agent Worker\nDESCRIPTION: This command starts the LiveKit agent worker using the participant_entrypoint.py script in development mode.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/participant-entrypoint/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython participant_entrypoint.py dev\n```\n\n----------------------------------------\n\nTITLE: Downloading Model Files Command\nDESCRIPTION: Command to download required model files before first use or during Docker image building.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-turn-detector/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython my_agent.py download-files\n```\n\n----------------------------------------\n\nTITLE: Defining Copyright and License Terms for LiveKit Agents\nDESCRIPTION: This code snippet outlines the copyright holders, conditions for redistribution, and disclaimers for the LiveKit agents project. It specifies the terms under which the software can be used and modified.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/LICENSE.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n// Copyright (c) 2008-2016 Marshall A. Greenblatt. Portions Copyright (c)\n// 2006-2009 Google Inc. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of Google Inc. nor the name Chromium Embedded\n// Framework nor the names of its contributors may be used to endorse\n// or promote products derived from this software without specific prior\n// written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n```\n\n----------------------------------------\n\nTITLE: Configuring Turn Detection with RealtimeModel\nDESCRIPTION: Configuration example showing turn detector integration with OpenAI's Realtime API and Deepgram STT for speech-to-speech models.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-turn-detector/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsession = AgentSession(\n    ...\n    stt=deepgram.STT(model=\"nova-3\", language=\"multi\"),\n    llm=openai.realtime.RealtimeModel(),\n    turn_detection=MultilingualModel(),\n)\n```\n\n----------------------------------------\n\nTITLE: Setting LiveKit Environment Variables\nDESCRIPTION: These export commands set the necessary environment variables for connecting to a LiveKit server, including the URL, API key, and API secret.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/participant-entrypoint/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport LIVEKIT_URL=<your LiveKit server URL>\nexport LIVEKIT_API_KEY=<your API Key>\nexport LIVEKIT_API_SECRET=<your API Secret>\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Azure Package via pip\nDESCRIPTION: Command to install the LiveKit Plugins Azure package using pip. This package enables integration between LiveKit Agent Framework and Azure Cognitive Services for speech functionalities.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-azure/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-azure\n```\n\n----------------------------------------\n\nTITLE: Configuring Linux-Specific Build Settings in CMake\nDESCRIPTION: Sets up Linux-specific build configurations for the helper executable and main library. It defines targets, dependencies, and resource copying.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(OS_LINUX)\n  # Helper executable target.\n  add_executable(lkcef_helper ${LKCEF_HELPER_SRCS})\n  set_executable_target_properties(lkcef_helper)\n  add_dependencies(lkcef_helper libcef_dll_wrapper)\n  target_link_libraries(lkcef_helper libcef_lib libcef_dll_wrapper\n                        ${CEF_STANDARD_LIBS})\n\n  # Set rpath so that libraries can be placed next to the executable.\n  set_target_properties(lkcef_helper PROPERTIES INSTALL_RPATH \"$ORIGIN\")\n  set_target_properties(lkcef_helper PROPERTIES BUILD_WITH_INSTALL_RPATH TRUE)\n\n  # library target.\n  add_library(lkcef SHARED ${LKCEF_SRCS})\n  set_library_target_properties(lkcef)\n  add_dependencies(lkcef libcef_dll_wrapper lkcef_helper)\n  target_link_libraries(lkcef libcef_lib libcef_dll_wrapper\n                        ${CEF_STANDARD_LIBS})\n\n  # Set rpath so that libraries can be placed next to the library.\n  set_target_properties(lkcef PROPERTIES INSTALL_RPATH \"$ORIGIN\")\n  set_target_properties(lkcef PROPERTIES BUILD_WITH_INSTALL_RPATH TRUE)\n\n  # Copy binary and resource files to the target output directory.\n  copy_files(\"lkcef\" \"${CEF_BINARY_FILES}\" \"${CEF_BINARY_DIR}\"\n             \"${CEF_TARGET_OUT_DIR}\")\n  copy_files(\"lkcef\" \"${CEF_RESOURCE_FILES}\" \"${CEF_RESOURCE_DIR}\"\n             \"${CEF_TARGET_OUT_DIR}\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Google with pip\nDESCRIPTION: Command to install the LiveKit Plugins Google package using pip. This is the first step to integrate Google Cloud services into your LiveKit project.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-google\n```\n\n----------------------------------------\n\nTITLE: Building RAG with LlamaIndex and Function Calling in Python\nDESCRIPTION: This approach uses an LLM that supports function calling (e.g., OpenAI's models) to define custom functions like query_info for retrieval. It requires additional setup but offers greater flexibility in interactions.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/voice_agents/llamaindex-rag/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nquery_engine.py\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Speechmatics Plugin\nDESCRIPTION: Command to install the LiveKit Speechmatics plugin using pip package manager.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-speechmatics/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-speechmatics\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration\nDESCRIPTION: Environment variables configuration for BitHuman API secret and model path in .env file.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bithuman/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nBITHUMAN_API_SECRET=your_api_secret_here\nBITHUMAN_MODEL_PATH=/path/to/model.imx\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Rime via pip\nDESCRIPTION: This command installs the LiveKit Plugins Rime package using pip. It allows users to add the Rime voice synthesis capability to their LiveKit Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-rime/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-rime\n```\n\n----------------------------------------\n\nTITLE: Installing the LiveKit Neuphonic Plugin with pip\nDESCRIPTION: Command to install the LiveKit Plugins Neuphonic package via pip. This package enables voice synthesis capabilities in the LiveKit Agent Framework using the Neuphonic API.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-neuphonic/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-neuphonic\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python Virtual Environment\nDESCRIPTION: These commands create a new Python virtual environment and activate it for the project.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/participant-entrypoint/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\n```\n\nLANGUAGE: bash\nCODE:\n```\nsource venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Elevenlabs via pip\nDESCRIPTION: This command installs the LiveKit Plugins Elevenlabs package using pip. It allows users to add ElevenLabs voice synthesis capabilities to their LiveKit Agent Framework projects.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-elevenlabs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-elevenlabs\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins NLTK via pip\nDESCRIPTION: This command installs the LiveKit Plugins NLTK package using pip, the Python package installer. It allows users to easily add the NLTK-based text processing capabilities to their project.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-nltk/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-nltk\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Silero via pip\nDESCRIPTION: Command to install the LiveKit Plugins Silero package using pip package manager. This installation is required before using the Voice Activity Detection functionality.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-silero/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-silero\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Cartesia via pip\nDESCRIPTION: Command to install the LiveKit Plugins Cartesia package using pip. The package enables voice synthesis functionality using the Cartesia API within the LiveKit Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-cartesia/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-cartesia\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins AssemblyAI via pip\nDESCRIPTION: This command installs the LiveKit Plugins AssemblyAI package using pip. It allows users to add the AssemblyAI plugin functionality to their LiveKit Agent Framework setup.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-assemblyai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-assemblyai\n```\n\n----------------------------------------\n\nTITLE: Basic Initialization of Gladia STT with LiveKit\nDESCRIPTION: Shows how to initialize the Gladia speech-to-text component with a simple configuration, providing just an API key and enabling interim results.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-gladia/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.stt import STT\nfrom livekit.plugins.gladia.stt import STT as GladiaSTT\n\n# Basic initialization\nstt = GladiaSTT(\n    api_key=\"your-api-key-here\",  # or use GLADIA_API_KEY env var\n    interim_results=True\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for LiveKit Agents\nDESCRIPTION: This snippet defines the required Python packages and their versions for the LiveKit Agents project. It includes livekit-agents, livekit-plugins-deepgram, and python-dotenv with specific version constraints.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/speech-to-text/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nlivekit-agents>=0.12.18\nlivekit-plugins-deepgram>=0.7.2\npython-dotenv~=1.0\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins fal Package using pip\nDESCRIPTION: Command to install the LiveKit Plugins fal package via pip, which enables integration of fal.ai models with the LiveKit Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-fal/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-fal\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Anthropic via pip\nDESCRIPTION: Command to install the LiveKit Plugins Anthropic package using pip. This installs the necessary dependencies to integrate Anthropic AI services with LiveKit's Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-anthropic/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-anthropic\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Groq Package\nDESCRIPTION: Command to install the LiveKit Plugins Groq package using pip package manager. This installation is required to use Groq services with LiveKit.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-groq/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-groq\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Clova Package via pip\nDESCRIPTION: Command to install the livekit-plugins-clova package using pip. This package allows integration with Clova's speech-to-text API within the Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-clova/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-clova\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit PlayAI Plugin using pip\nDESCRIPTION: Command to install the LiveKit PlayAI plugin package using Python's package manager pip. This package enables voice synthesis capabilities through the PlayAI/PlayHT API.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-playai/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-playai\n```\n\n----------------------------------------\n\nTITLE: Setting Beyond Presence API Key in Bash Environment\nDESCRIPTION: This command sets the BEY_API_KEY environment variable with the developer API key obtained from the Beyond Presence creator dashboard. This step is necessary for authenticating and using the Beyond Presence API within the LiveKit plugin.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-bey/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport BEY_API_KEY=<your-bey-api-key>\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Turn Detector Plugin via pip\nDESCRIPTION: Command to install the LiveKit turn detector plugin using pip package manager.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-turn-detector/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-turn-detector\n```\n\n----------------------------------------\n\nTITLE: Downloading BitHuman Avatar Model\nDESCRIPTION: Command to download a sample BitHuman avatar model file (.imx) for Einstein character.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bithuman/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget https://repo.one.bithuman.io/resources/rt_models/samples/albert_einstein.imx\n```\n\n----------------------------------------\n\nTITLE: Installing BitHuman Dependencies\nDESCRIPTION: Command to install the required BitHuman Python package using pip.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bithuman/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install bithuman\n```\n\n----------------------------------------\n\nTITLE: Running BitHuman Agent Worker\nDESCRIPTION: Command to start the BitHuman avatar agent worker in development mode.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bithuman/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython examples/avatar_agents/bithuman/agent_worker.py dev\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins DeepGram Package\nDESCRIPTION: Command to install the LiveKit Plugins DeepGram package using pip. This package enables speech-to-text functionality via DeepGram's API within the LiveKit Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-deepgram/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-deepgram\n```\n\n----------------------------------------\n\nTITLE: Starting the Tavus Avatar Agent Worker (Python/Bash)\nDESCRIPTION: This command starts the agent worker using a Python script.  The `dev` argument likely indicates a development environment setting. The script is located in the `examples/avatar_agents/tavus/` directory.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/tavus/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython examples/avatar_agents/tavus/agent_worker.py dev\n```\n\n----------------------------------------\n\nTITLE: Running the Avatar Agent Worker with Python\nDESCRIPTION: This bash command demonstrates how to start the agent worker using a Python script. The script is located in the examples/avatar_agents/bey directory and is named agent_worker.py.  The \"dev\" argument specifies a development environment.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bey/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# You can specify a different avatar if you want\n# export BEY_AVATAR_ID=your-avatar-id\npython examples/avatar_agents/bey/agent_worker.py dev\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: This command installs the required Python packages for the project from the requirements.txt file.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/participant-entrypoint/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Starting Agent Worker (Bash)\nDESCRIPTION: This command starts the agent worker script with the 'dev' environment configuration. It assumes that the necessary Python environment and dependencies are already set up.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/datastream-audio/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython examples/other/datastream-audio/agent_worker.py dev\n```\n\n----------------------------------------\n\nTITLE: Starting Audio Receiver (Bash)\nDESCRIPTION: This command starts the audio receiver script, requiring a room name as a command-line argument. The receiver connects to the specified LiveKit room.  Replace <room-name> with the desired LiveKit room name.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/datastream-audio/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython examples/other/datastream-audio/audio_receiver.py <room-name>\n```\n\n----------------------------------------\n\nTITLE: Starting Avatar Dispatcher Server in Bash\nDESCRIPTION: This command starts the avatar dispatcher server. It uses Python to run the dispatcher script, with an optional port specification.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/audio_wave/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython examples/avatar/dispatcher.py [--port 8089]\n```\n\n----------------------------------------\n\nTITLE: Specifying Dependencies for LiveKit Agents Project in Python\nDESCRIPTION: This snippet defines the required Python packages and their version constraints for the LiveKit Agents project. It specifies livekit-agents version 0.12.18 or higher, and python-dotenv version 1.0 or compatible.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/participant-entrypoint/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nlivekit-agents>=0.12.18\npython-dotenv~=1.0\n```\n\n----------------------------------------\n\nTITLE: Launching Agent Worker in Bash\nDESCRIPTION: This command starts the agent worker. It runs the agent_worker.py script with 'dev' as an argument and an optional avatar URL parameter.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/audio_wave/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython examples/avatar/agent_worker.py dev [--avatar-url http://localhost:8089/launch]\n```\n\n----------------------------------------\n\nTITLE: Setting Tavus and LiveKit Environment Variables (Bash)\nDESCRIPTION: This snippet shows the environment variables that need to be set for the Tavus avatar agent to function. It includes API keys and replica IDs for Tavus, OpenAI, and LiveKit. These variables are essential for authentication and connecting to the respective services.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/tavus/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Tavus Config\nexport TAVUS_API_KEY=\"...\"\nexport TAVUS_REPLICA_ID=\"...\"\n\n# OpenAI config (or other models, tts, stt)\nexport OPENAI_API_KEY=\"...\"\n\n# LiveKit config\nexport LIVEKIT_API_KEY=\"...\"\nexport LIVEKIT_API_SECRET=\"...\"\nexport LIVEKIT_URL=\"...\"\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Speechify via pip\nDESCRIPTION: Command to install the LiveKit Plugins Speechify package using pip package manager. This installs the necessary dependencies to integrate Speechify voice synthesis with the LiveKit Agent Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-speechify/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-speechify\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Beyond Presence, OpenAI, and LiveKit\nDESCRIPTION: This bash script shows how to set environment variables required for configuring Beyond Presence, OpenAI, and LiveKit. The variables include API keys and URLs necessary for authentication and accessing the services.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/avatar_agents/bey/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Beyond Presence Config\nexport BEY_API_KEY=\"...\"\n\n# OpenAI config (or other models, tts, stt)\nexport OPENAI_API_KEY=\"...\"\n\n# LiveKit config\nexport LIVEKIT_API_KEY=\"...\"\nexport LIVEKIT_API_SECRET=\"...\"\nexport LIVEKIT_URL=\"...\"\n```\n\n----------------------------------------\n\nTITLE: Updating Gladia STT Options at Runtime\nDESCRIPTION: Shows how to modify the configuration of an existing Gladia STT instance after initialization, allowing for dynamic adjustment of language and translation settings.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-gladia/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Update options after initialization\nstt.update_options(\n    languages=[\"ja\", \"en\"],\n    translation_enabled=True,\n    translation_target_languages=[\"fr\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Installing livekit-plugins-hume\nDESCRIPTION: Installs the livekit-plugins-hume package using pip. This package provides integration with the Hume AI Text-to-Speech API within the LiveKit Agents Framework.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-hume/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-hume\n```\n\n----------------------------------------\n\nTITLE: Implementing Multilingual Turn Detection Model\nDESCRIPTION: Integration of the multilingual turn detection model supporting 13 languages, requiring 400MB RAM with ~25ms inference time.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-turn-detector/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\n\nsession = AgentSession(\n    ...\n    turn_detection=MultilingualModel(),\n)\n```\n\n----------------------------------------\n\nTITLE: Running Code Quality Checks in Python\nDESCRIPTION: Commands to run Ruff for code formatting and best practices checks before committing changes.\nSOURCE: https://github.com/livekit/agents/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nruff check --fix\nruff format\n```\n\n----------------------------------------\n\nTITLE: Implementing English Turn Detection Model\nDESCRIPTION: Integration of the English turn detection model which requires 200MB RAM and has ~10ms inference time. Used with AgentSession configuration.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-turn-detector/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom livekit.plugins.turn_detector.english import EnglishModel\n\nsession = AgentSession(\n    ...\n    turn_detection=EnglishModel(),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins Resemble with pip\nDESCRIPTION: This snippet shows how to install the LiveKit Plugins Resemble package using pip. It's a simple one-line command to add the package to your Python environment.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-resemble/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-resemble\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Bindings in CMake\nDESCRIPTION: Sets up the Python bindings for the LiveKit Agents project using pybind11. It configures the target, dependencies, and linking options.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\n# TODO(theomonnom): should be pretty similar for NodeJS\npybind11_add_module(lkcef_python ${LKCEF_PYTHON_SRCS})\n\nset_target_properties(lkcef_python PROPERTIES INSTALL_RPATH \"$ORIGIN\")\nset_target_properties(lkcef_python PROPERTIES BUILD_WITH_INSTALL_RPATH TRUE)\n\ntarget_include_directories(lkcef_python PRIVATE ${CEF_INCLUDE_PATH})\ntarget_link_libraries(lkcef_python PUBLIC lkcef)\ntarget_link_libraries(lkcef_python PUBLIC libcef_dll_wrapper ${CEF_STANDARD_LIBS})\nadd_dependencies(lkcef_python libcef_dll_wrapper)\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows-Specific Build Settings in CMake\nDESCRIPTION: Sets up Windows-specific build configurations for the helper executable and main library. It defines targets, dependencies, and handles manifest files and resource copying.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(OS_WINDOWS)\n  # Helper executable target.\n  add_executable(lkcef_helper WIN32 ${LKCEF_HELPER_SRCS})\n  set_executable_target_properties(lkcef_helper)\n  add_dependencies(lkcef_helper libcef_dll_wrapper)\n  target_link_libraries(lkcef_helper libcef_lib libcef_dll_wrapper\n                        ${CEF_STANDARD_LIBS})\n\n  # library target.\n  add_library(lkcef SHARED ${LKCEF_SRCS})\n  set_library_target_properties(lkcef)\n  add_dependencies(lkcef libcef_dll_wrapper lkcef_helper)\n  target_link_libraries(lkcef libcef_lib libcef_dll_wrapper\n                        ${CEF_STANDARD_LIBS})\n\n  # Add the custom manifest files to the DLL and helper EXE.\n  add_windows_manifest(\"${CMAKE_CURRENT_SOURCE_DIR}\" \"lkcef\" \"dll\")\n  add_windows_manifest(\"${CMAKE_CURRENT_SOURCE_DIR}\" \"lkcef_helper\" \"exe\")\n\n  # Copy binary and resource files to the target output directory.\n  copy_files(\"lkcef\" \"${CEF_BINARY_FILES}\" \"${CEF_BINARY_DIR}\"\n             \"${CEF_TARGET_OUT_DIR}\")\n  copy_files(\"lkcef\" \"${CEF_RESOURCE_FILES}\" \"${CEF_RESOURCE_DIR}\"\n             \"${CEF_TARGET_OUT_DIR}\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies and Build Setup\nDESCRIPTION: Sets up CMake modules, downloads CEF binary distribution, configures Python dependencies, and adds required subdirectories for the build process.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/CMakeLists.txt#2025-04-22_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\n\n# Download and extract the CEF binary distribution (executes DownloadCEF.cmake).\ninclude(DownloadCEF)\ndownloadcef(\"${CEF_PLATFORM}\" \"${CEF_VERSION}\"\n            \"${CMAKE_SOURCE_DIR}/third_party/cef\")\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \"${CEF_ROOT}/cmake\")\n\n# Load the CEF configuration (executes FindCEF.cmake).\nfind_package(CEF REQUIRED)\n\n# Python\nfind_package(PythonInterp REQUIRED)\nfind_package(pybind11 REQUIRED)\n\nmessage(STATUS \"Using Python: ${PYTHON_EXECUTABLE}\")\n\nadd_subdirectory(${CEF_LIBCEF_DLL_WRAPPER_PATH} libcef_dll_wrapper)\nadd_subdirectory(src)\n\nprint_cef_config()\n```\n\n----------------------------------------\n\nTITLE: Using TTS with Custom HTTP Session in Python\nDESCRIPTION: This example demonstrates how to use the TTS class with a custom aiohttp ClientSession. It shows how to create a session and pass it to the TTS constructor, ensuring proper resource management with context managers.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-resemble/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport aiohttp\n\nasync def with_custom_session():\n    async with aiohttp.ClientSession() as session:\n        async with TTS(\n            api_key=\"your_api_key\",\n            voice_uuid=\"your_voice_uuid\",\n            http_session=session\n        ) as tts:\n            # Use TTS...\n            # No need to manually close anything - context managers handle it all\n```\n\n----------------------------------------\n\nTITLE: Defining Source Files and Platform-Specific Settings in CMake\nDESCRIPTION: Defines source files for the main library, helper executables, and Python bindings. It also sets up platform-specific source files and CMake variables.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(LKCEF_SRCS app.cpp app.hpp handler.hpp handler.cpp dev_renderer.hpp dev_renderer.cpp gleq.h browser_handle.hpp browser_handle.cpp)\nset(LKCEF_SRCS_LINUX main_linux.cpp)\nset(LKCEF_SRCS_MAC app_mac.mm)\nset(LKCEF_SRCS_WINDOWS main_win.cpp )\nappend_platform_sources(LKCEF_SRCS)\nsource_group(lkcef FILES ${LKCEF_SRCS})\n\nset(LKCEF_HELPER_SRCS )\nset(LKCEF_HELPER_SRCS_LINUX helper_main_linux.cpp)\nset(LKCEF_HELPER_SRCS_MAC helper_main_mac.mm)\nset(LKCEF_HELPER_SRCS_WINDOWS helper_main_win.cpp)\nappend_platform_sources(LKCEF_HELPER_SRCS)\nsource_group(lkcef FILES ${LKCEF_HELPER_SRCS})\n\nset(LKCEF_PYTHON_SRCS agents_python.hpp\n               agents_python.cpp)\n\nif(OS_LINUX OR OS_WINDOWS)\n  # Logical target used to link the libcef library on Linux and Windows. On\n  # macOS the CEF framework is loaded dynamically at startup.\n  add_logical_target(\"libcef_lib\" \"${CEF_LIB_DEBUG}\" \"${CEF_LIB_RELEASE}\")\nendif()\n\nset_cef_target_out_dir() # Determine the target output directory.\n```\n\n----------------------------------------\n\nTITLE: Configuring macOS-Specific Build Settings in CMake\nDESCRIPTION: Sets up macOS-specific build configurations, including app bundle creation, framework copying, and helper app generation. It handles multiple helper app variants.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(OS_MAC)\n  # Avoid CMP0042 policy errors.\n  set(CMAKE_MACOSX_RPATH 1)\n\n  # Avoid CMP0068 policy errors.\n  if(POLICY CMP0068)\n    cmake_policy(SET CMP0068 NEW)\n  endif()\n\n  add_executable(lkcef_app MACOSX_BUNDLE dummy.cpp) # dummy app\n  set_target_properties(lkcef_app PROPERTIES\n          MACOSX_BUNDLE_INFO_PLIST \"${CMAKE_CURRENT_SOURCE_DIR}/resources/lkcefapp-Info.plist\"\n          OUTPUT_NAME \"lkcef_app\"\n  )\n\n\n  # library target.\n  add_library(lkcef STATIC ${LKCEF_SRCS})\n  set_library_target_properties(lkcef)\n  add_dependencies(lkcef libcef_dll_wrapper)\n  target_include_directories(lkcef PRIVATE ${GLFW_INCLUDE_DIR})\n  target_link_libraries(lkcef libcef_dll_wrapper ${CEF_STANDARD_LIBS} glfw imgui)\n\n  add_custom_command(\n    TARGET lkcef\n    POST_BUILD\n    # Copy the CEF framework into the main app bundle.\n    COMMAND\n      ${CMAKE_COMMAND} -E copy_directory\n      \"${CEF_BINARY_DIR}/Chromium Embedded Framework.framework\"\n      \"$<TARGET_BUNDLE_DIR:lkcef_app>/Contents/Frameworks/Chromium Embedded Framework.framework\"\n    VERBATIM)\n\n  # Create the multiple Helper app bundle targets.\n  foreach(_suffix_list ${CEF_HELPER_APP_SUFFIXES})\n    # Convert to a list and extract the suffix values.\n    string(REPLACE \":\" \";\" _suffix_list ${_suffix_list})\n    list(GET _suffix_list 0 _name_suffix)\n    list(GET _suffix_list 1 _target_suffix)\n    list(GET _suffix_list 2 _plist_suffix)\n\n    # Define Helper target and output names.\n    set(_helper_target \"lkcef_Helper${_target_suffix}\")\n    set(_helper_output_name \"lkcef Helper${_name_suffix}\")\n\n    # Create Helper-specific variants of the helper-Info.plist file.\n    set(_helper_info_plist\n        \"${CMAKE_CURRENT_BINARY_DIR}/lkcef-Info${_target_suffix}.plist\")\n    file(READ \"${CMAKE_CURRENT_SOURCE_DIR}/resources/lkcefhelper-Info.plist\"\n         _plist_contents)\n    string(REPLACE \"\\${EXECUTABLE_NAME}\" \"${_helper_output_name}\"\n                   _plist_contents ${_plist_contents})\n    string(REPLACE \"\\${PRODUCT_NAME}\" \"${_helper_output_name}\" _plist_contents\n                   ${_plist_contents})\n    string(REPLACE \"\\${BUNDLE_ID_SUFFIX}\" \"${_plist_suffix}\" _plist_contents\n                   ${_plist_contents})\n    file(WRITE ${_helper_info_plist} ${_plist_contents})\n\n    # Create Helper executable target.\n    add_executable(${_helper_target} MACOSX_BUNDLE ${LKCEF_HELPER_SRCS})\n    set_executable_target_properties(${_helper_target})\n    add_dependencies(${_helper_target} libcef_dll_wrapper)\n    target_link_libraries(${_helper_target} libcef_dll_wrapper\n                          ${CEF_STANDARD_LIBS})\n\n\n    set_target_properties(\n      ${_helper_target}\n      PROPERTIES MACOSX_BUNDLE_INFO_PLIST ${_helper_info_plist}\n                 OUTPUT_NAME ${_helper_output_name})\n\n    # Add the Helper as a dependency of the main executable target.\n    add_dependencies(lkcef \"${_helper_target}\")\n\n    # Copy the Helper app bundle into the Frameworks directory.\n    add_custom_command(\n      TARGET lkcef\n      POST_BUILD\n      COMMAND\n        ${CMAKE_COMMAND} -E copy_directory\n        \"${CEF_TARGET_OUT_DIR}/${_helper_output_name}.app\"\n        \"$<TARGET_BUNDLE_DIR:lkcef_app>/Contents/Frameworks/${_helper_output_name}.app\"\n      VERBATIM)\n  endforeach()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Publishing Solid Color Video Frame with LiveKit in Python\nDESCRIPTION: This code snippet demonstrates how to create and publish a solid color video frame using LiveKit. It initializes a LiveKit room, creates a video track with a solid color frame, and publishes it to the room.\nSOURCE: https://github.com/livekit/agents/blob/main/examples/other/simple-color/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport cv2\nimport numpy as np\n\nfrom livekit import api, rtc\n\n\nasync def publish_color():\n    # create a room\n    room = rtc.Room()\n    await room.connect('ws://localhost:7880', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDYzNzA3OTYsImlzcyI6IkFQSUtleUlEIiwibmFtZSI6InVzZXIxIiwibmJmIjoxNjkwODg3NTk2LCJzdWIiOiJ1c2VyMSIsInZpZGVvIjp7InJvb20iOiJteXJvb20iLCJyb29tSm9pbiI6dHJ1ZX19.mhf7PzaPcI0gThEpkY_z6CDq-I9J1vXm2QVSi7uYJXI', 'myroom')\n    await room.local_participant.set_name('user1')\n\n    # create video source\n    vs = rtc.VideoSource()\n\n    # create a blue frame\n    frame = np.zeros((480, 640, 3), dtype=np.uint8)\n    frame[:] = (255, 0, 0)\n\n    # convert frame to a VideoFrame\n    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    vf = rtc.VideoFrame.from_ndarray(img, rtc.VideoFormatType.RGBx)\n\n    # capture the frame\n    vs.capture_frame(vf)\n\n    # create a video track\n    track = rtc.LocalVideoTrack.create_video_track('blue', vs)\n\n    # publish video\n    await room.local_participant.publish_track(track)\n\n    # wait until ctrl+c\n    try:\n        await asyncio.Event().wait()\n    except KeyboardInterrupt:\n        pass\n\n    await room.disconnect()\n\n\nif __name__ == '__main__':\n    asyncio.run(publish_color())\n```\n\n----------------------------------------\n\nTITLE: Setting CEF Version and Platform Detection\nDESCRIPTION: Configures CEF version and determines platform-specific settings based on the target system architecture. Handles macOS (arm64/x86_64), Linux (32/64-bit), and Windows (32/64-bit) platforms.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/CMakeLists.txt#2025-04-22_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif(NOT DEFINED CEF_VERSION)\n  # set(CEF_VERSION \"122.1.10+gc902316+chromium-122.0.6261.112\")\n  set(CEF_VERSION \"127.3.5+g114ea2a+chromium-127.0.6533.120\")\nendif()\n\nif(\"${CMAKE_SYSTEM_NAME}\" STREQUAL \"Darwin\")\n  if(\"${PROJECT_ARCH}\" STREQUAL \"arm64\")\n    set(CEF_PLATFORM \"macosarm64\")\n  elseif(\"${PROJECT_ARCH}\" STREQUAL \"x86_64\")\n    set(CEF_PLATFORM \"macosx64\")\n  elseif(\"${CMAKE_HOST_SYSTEM_PROCESSOR}\" STREQUAL \"arm64\")\n    set(PROJECT_ARCH \"arm64\")\n    set(CEF_PLATFORM \"macosarm64\")\n  else()\n    set(PROJECT_ARCH \"x86_64\")\n    set(CEF_PLATFORM \"macosx64\")\n  endif()\nelseif(\"${CMAKE_SYSTEM_NAME}\" STREQUAL \"Linux\")\n  if(CMAKE_SIZEOF_VOID_P MATCHES 8)\n    set(CEF_PLATFORM \"linux64\")\n  else()\n    set(CEF_PLATFORM \"linux32\")\n  endif()\nelseif(\"${CMAKE_SYSTEM_NAME}\" STREQUAL \"Windows\")\n  if(CMAKE_SIZEOF_VOID_P MATCHES 8)\n    set(CEF_PLATFORM \"windows64\")\n  else()\n    set(CEF_PLATFORM \"windows32\")\n  endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Manual Resource Management for TTS in Python\nDESCRIPTION: This example shows how to use the TTS class with manual resource management. It demonstrates initializing the TTS object, performing synthesis, and ensuring proper cleanup of resources using a try-finally block.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-resemble/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom livekit.plugins.resemble import TTS\n\nasync def run_tts_example():\n    # Initialize TTS with your credentials\n    tts = TTS(\n        api_key=\"your_api_key\", \n        voice_uuid=\"your_voice_uuid\",\n    )\n\n    try:\n        # TTS operations\n        audio_stream = tts.synthesize(\"Hello, world!\")\n        async for chunk in audio_stream:\n            # Access audio data correctly\n            process_audio(chunk.frame.data)\n    finally:\n        # Always clean up resources when done\n        await tts.aclose()\n\n# Run the example\nasyncio.run(run_tts_example())\n```\n\n----------------------------------------\n\nTITLE: Installing LiveKit Plugins AWS via pip\nDESCRIPTION: This command installs the LiveKit Plugins AWS package using pip. It allows users to integrate AWS services into their LiveKit Agent Framework projects.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-aws/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-aws\n```\n\n----------------------------------------\n\nTITLE: Describing LiveKit Plugins BitHuman Avatar Runtime in Markdown\nDESCRIPTION: This markdown snippet provides the title and a brief description of the LiveKit Plugins BitHuman Avatar Runtime project. It explains that the project is an Agent Framework Plugin for avatars using BitHuman's local runtime SDK.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-bithuman/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# LiveKit Plugins BitHuman Avatar Runtime\n\nAgent Framework Plugin for avatars with [bitHuman](https://www.bithuman.ai/)'s local runtime SDK.\n```\n\n----------------------------------------\n\nTITLE: Installing Gladia Plugin for LiveKit\nDESCRIPTION: Command to install the LiveKit Gladia plugin via pip.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-gladia/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install livekit-plugins-gladia\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project Settings for LiveKit CEF\nDESCRIPTION: Initial CMake configuration that sets project properties, C++ standard, and basic build options. Disables sandbox functionality for simplified development.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/CMakeLists.txt#2025-04-22_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.19)\nset(CMAKE_CONFIGURATION_TYPES Debug Release)\n\nproject(livekit-cef)\nset_property(GLOBAL PROPERTY OS_FOLDERS ON)\n\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON) # useful for clangd as the language server\nset(USE_SANDBOX OFF) # TODO(theomonnom): I don't think we want to enable sandbox\n                     # for now, it add complexity\n```\n\n----------------------------------------\n\nTITLE: Configuring FetchContent and Dependencies in CMake\nDESCRIPTION: Sets up FetchContent for managing external dependencies like GLFW and ImGui. It configures build options and declares the repositories to be fetched.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-browser/src/CMakeLists.txt#2025-04-22_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ninclude(FetchContent)\n\nset(FETCHCONTENT_QUIET off)\n\n# I don't want to write a different code per platform for the dev mode.\n# so use glfw and imgui like I do for my other side projects...\nset(GLFW_BUILD_DOCS OFF CACHE BOOL \"\" FORCE)\nset(GLFW_BUILD_EXAMPLES OFF CACHE BOOL \"\" FORCE)\nset(GLFW_BUILD_TESTS OFF CACHE BOOL \"\" FORCE)\nset(GLFW_INSTALL OFF CACHE BOOL \"\" FORCE)\nFetchContent_Declare(glfw GIT_REPOSITORY https://github.com/glfw/glfw.git GIT_TAG 3.4)\nFetchContent_MakeAvailable(glfw)\n\nFetchContent_Declare(\n  imgui \n  GIT_REPOSITORY https://github.com/ocornut/imgui \n  GIT_TAG origin/docking\n  GIT_SHALLOW TRUE\n)\nFetchContent_GetProperties(imgui)\nFetchContent_Populate(imgui)\n\nFetchContent_MakeAvailable(imgui)\nfile(GLOB IMGUI_SOURCES ${imgui_SOURCE_DIR}/*.cpp)\nadd_library(imgui STATIC ${IMGUI_SOURCES}\n        ${imgui_SOURCE_DIR}/backends/imgui_impl_glfw.cpp\n        ${imgui_SOURCE_DIR}/backends/imgui_impl_opengl3.cpp\n        ${imgui_SOURCE_DIR}/misc/cpp/imgui_stdlib.cpp\n)\nset_target_properties(imgui PROPERTIES CXX_STANDARD 17)\ntarget_include_directories(imgui PUBLIC ${imgui_SOURCE_DIR} ${imgui_SOURCE_DIR}/misc/cpp ${imgui_SOURCE_DIR}/backends ${GLFW_INCLUDE_DIR})\ntarget_link_libraries(imgui PRIVATE glfw)\n```\n\n----------------------------------------\n\nTITLE: Configuring package.json for LiveKit Plugins\nDESCRIPTION: Example package.json configuration for a LiveKit plugin package. The configuration shows the proper naming convention required for CI integration, where the package name follows the 'livekit-plugins-<name>' pattern and is marked as private.\nSOURCE: https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-minimal/README.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"livekit-plugins-<name>\",\n  \"private\": true\n}\n```"
  }
]